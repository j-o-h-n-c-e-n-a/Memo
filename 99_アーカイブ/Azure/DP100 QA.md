# テスト
## MS

### Q. 1. 
    shape (2,20) の NumPy 配列があります。 配列内の要素については、どのようなことがわかりますか?
1. 配列は 2 次元で、それぞれ 20 個の要素を持つ 2 つの配列で構成されます
2. 配列には 2 つの要素が含まれ、値は 2 と 20 です
3. 配列には 20 個の要素が含まれ、それらの値はすべて 2 です
<details><div>
    答え：１
     (2,20) の shape は、それぞれ 20 個の要素を含む 2 つの配列を持つ多次元配列を示します。
</div></details>

### Q. 2. 
    df_sales という名前の Pandas DataFrame があり、毎日の売上データが含まれています。 この DataFrame には、year、month、day_of_month、sales_total の各列が含まれています。 sales_total 値の平均を求めたいと思います。 使用すべきコードは次のうちどれですか?
1. df_sales['sales_total'].avg()
2. df_sales['sales_total'].mean()
3. mean(df_sales['sales_total'])
<details><div>
    答え：２
    このコードは、sales_total 列の値の平均を返します。
</div></details>

### Q. 3. 
    毎日のアイス クリームの売上に関するデータを含む DataFrame があります。 corr メソッドを使用して、avg_temp と units_sold 列を比較すると、0.97 の結果が得られます。 この結果は何を示していますか?
1. units_sold 値が最大だった日の avg_temp 値は 0.97 でした
2. avg_temp 値が高い日は、units_sold 値が大きい日と一致する傾向があります
3. 平均すると、units_sold 値は、avg_temp 値の 97% です
<details><div>
    答え：２
     corr メソッドは相関関係を返し、1 に近い値は正の相関関係を示します。
</div></details>

### Q. 1. 
    Scikit-learn を使用して、売上データのデータセットから回帰モデルをトレーニングしています。 モデルを評価して、新しいデータで正確に予測できるようにする必要があります。 何をする必要がありますか?
1. すべてのデータを使用してモデルをトレーニングします。 次に、すべてのデータを使用してモデルを評価します。
2. 特徴量の列のみを使用してモデルをトレーニングし、ラベルの列のみを使用してモデルを評価します。
3. データをランダムに 2 つのサブセットに分割します。 1 つのサブセットを使用してモデルをトレーニングし、もう一方を使用してモデルを評価します。
<details><div>
    答え：３
    モデルをトレーニングして評価する一般的な方法では、トレーニング時に評価データセットを取っておきます。
</div></details>

### Q. 2. 
    Scikit-learn LinearRegression クラスを使用してモデル オブジェクトを作成しました。 モデルをトレーニングするには、何をする必要がありますか?
1. モデル オブジェクトの predict() メソッドを呼び出して、トレーニングする特徴量とラベルの配列を指定します。
2. モデル オブジェクトの fit() メソッドを呼び出して、トレーニングする特徴量とラベルの配列を指定します。
3. モデル オブジェクトの score() メソッドを呼び出して、トレーニングする特徴量とテスト特徴量の配列を指定します。
<details><div>
    答え：２
    モデルをトレーニングするには、fit() メソッドを使用します。
</div></details>

### Q. 3. 
    Scikit-learn を使用して回帰モデルをトレーニングします。 テスト データを使用して評価すると、モデルが R の 2 乗メトリック 0.95 を達成したと判断されます。 このメトリックからは、モデルについて何がわかりますか?
1. このモデルでは、予測値と実際の値の間の分散の大部分が説明されます。
2. モデルの精度は 95% です。
3. 平均すると、予測は実際の値より 0.95 大きくなります。
<details><div>
    答え：１
    R の 2 乗メトリックは、モデルでどの程度の分散を説明できるかを示す尺度です。
</div></details>

### Q. 1. 
    Scikit-learn を使用して、信用破綻リスクを予測するモデルをトレーニングすることを計画しています。 モデルでは、自動的に承認される融資申請の場合は値 0 を、人間による検討が必要な不履行のリスクがある申請の場合は 1 を予測する必要があります。 どのような種類のモデルが必要ですか。
1. 二項分類モデル
2. 多クラス分類モデル
3. 線形回帰モデル
<details><div>
    答え：１
    二項分類モデルは、2 つのクラスについての確率を予測します。
</div></details>

### Q. 2. 
    Scikit-learn の LogisticRegression クラスを使用して分類モデルをトレーニングしました。 モデルを使用して、x_new 配列内の新しいデータのラベルを返す必要があります。 使用すべきコードは次のうちどれですか?
1. model.predict(x_new)
2. model.fit(x_new)
3. model.score(x_new, y_new)
<details><div>
    答え：１
    新しいデータのラベルを推論するには、predict メソッドを使用します。
</div></details>

### Q. 3. 
    Scikit-learn を使用して二項分類モデルをトレーニングします。 テスト データを使用して評価すると、モデルの総合リコール メトリックが 0.81 だったことがわかりました。 このメトリックは何を示していますか。
1. モデルはテスト ケースのうち 81% を正しく予測した
2. モデルによって陽性だと予測されたケースのうち 81% が実際に陽性だった
3. モデルは陽性のケースのうち 81% を陽性として正しく識別した
<details><div>
    答え：３
    リコールは、分類子が正しく識別した実際の陽性のケースの割合を示します。
</div></details>

### Q. 
    1. K-Means クラスタリングは、機械学習のどの種類の例ですか?
1. 教師あり機械学習
2. 教師なし機械学習
3. 強化学習
<details><div>
    答え：２
    クラスタリングは、トレーニング データに既知のラベルが含まれていない、教師なし機械学習の形式です。
</div></details>

### Q. 
    2. Scikit-learn を使用して、3 つのクラスターに観察をグループ化する K-Means クラスタリング モデルをトレーニングしています。 この目的を達成するには、KMeans オブジェクトをどのように作成する必要がありますか?
1. model = KMeans(n_clusters=3)
2. model = KMeans(n_init=3)
3. model = KMeans(max_iter=3)
<details><div>
    答え：１
     n_clusters パラメーターにより、クラスターの数が決まります。
</div></details>

### Q. 
    1. ディープ ニューラル ネットワークを作成し、10 個の数値の特徴量に基づいて、観測対象が 3 つのクラスのうちのどれに属するかを予測する分類モデルをトレーニングします。 ネットワーク アーキテクチャには、次のどの記述が当てはまりますか?
1. 入力層には 3 つのノードが含まれている必要があります。
2. ネットワークには 3 つの非表示層が含まれている必要があります。
3. 出力層には 3 つのノードが含まれている必要があります。
<details><div>
    答え：３
    出力層には、可能性のあるクラス値ごとに 1 つのノードが含まれている必要があります。
</div></details>

### Q. 
    2. ディープ ニューラル ネットワークをトレーニングしています。 50 エポックを使用するようにトレーニング プロセスを構成します。 この構成にはどのような効果がありますか?
1. トレーニング データセット全体がネットワーク経由で 50 回渡されます。
2. トレーニング データは 50 のサブセットに分割され、各サブセットはネットワーク経由で渡されます。
3. 最初の 50 行のデータがモデルのトレーニングに使用され、残りの行が検証に使用されます。
<details><div>
    答え：１
    エポックの数によって、完全なデータセットに対するトレーニング パスの数が決まります。
</div></details>

### Q. 
    3. ディープ ニューラル ネットワークを作成しています。 学習率パラメーターを大きくします。 この設定にはどのような効果がありますか?
1. ネットワーク経由で渡される各バッチに含まれるレコードの数が増加します。
2. 逆伝播中に重みの値に対する調整が大きくなります。
3. ネットワークに非表示層が追加されます。
<details><div>
    答え：２
    学習率を上げると、逆伝播による重みの調整が大きくなります。
</div></details>

### Q. 
    4. 畳み込みニューラル ネットワークを作成しようとしています。 畳み込み層によって生成される特徴マップのサイズを小さくする必要があります。 何をする必要がありますか?
1. 畳み込み層で使用されるフィルター カーネルのサイズを小さくします。
2. 畳み込み層のフィルターの数を増やします。
3. 畳み込み層の後にプーリング層を追加します。
<details><div>
    答え：３
    プーリング層を利用すると、特徴マップ内の特徴の数を減らすことができます。
</div></details>

### Q. 
    1. ある車の販売代理店が、車の売上履歴データを使用して機械学習モデルをトレーニングしたいと考えています。 このモデルでは、車名、車種、排気量、走行距離などに基づいて、事前に所有されている自動車の価格を予測する必要があります。 この販売代理店では、自動機械学習を使用してどのような種類の機械学習モデルを作成する必要がありますか?
1. 分類
2. 回帰
3. 時系列予測
<details><div>
    答え：２
    数値を予測するには、回帰モデルを使用します。
</div></details>

### Q. 
    2. ある銀行が、ローンの再支払い履歴レコードを使用して、ローン金額、借り手の収入、ローン期間などの特性に基づいて、ローン申請を低リスクまたは高リスクとして分類したいと考えています。 この銀行では、自動機械学習を使用してどのような種類の機械学習モデルを作成する必要がありますか?
1. 分類
2. 回帰
3. 時系列予測
<details><div>
    答え：１
    カテゴリまたはクラスを予測するには、分類モデルを使用します。
</div></details>

### Q. 
    3. 自動機械学習を使用して、考えられる最良の R2 スコアを持つ回帰モデルをトレーニングする必要があります。 自動機械学習の実験をどのように構成すればよいですか?
1. プライマリ メトリックを R2 スコアに設定する
2. GradientBoosting 以外のすべてのアルゴリズムをブロックする
3. 特徴量化を有効にする
<details><div>
    答え：１
    プライマリ メトリックによって、最適なパフォーマンスのモデルを評価するために使用するメトリックが決定されます。
</div></details>

### Q. 
    1. Azure Machine Learning スタジオでは、ドラッグ アンド ドロップ インターフェイスを使って回帰機械学習パイプラインを作成するために何を使用できますか?
1. ノートブック
2. 自動化された機械学習
3. デザイナー
<details><div>
    答え：3
    デザイナーを使って、ドラッグ アンド ドロップ インターフェイスを使用して回帰パイプラインを作成できます。
</div></details>

### Q. 
    2. 回帰モデルのトレーニング パイプラインを作成しており、 値のスケールが異なる複数の数値列があるデータセットを使用します。 すべての値が同様のスケールになるように、数値列を変換する必要があります。 また、各列の最小値と最大値を基準にして、変換をスケールする必要もあります。 どのモジュールをパイプラインに追加する必要がありますか?
1. Select Columns in a Dataset (データセット内の列の選択)
2. 見つからないデータのクリーンアップ
3. データの正規化
<details><div>
    答え：3
    同様のスケールになるように数値データを変換する場合は、[データの正規化] モジュールを使用します
</div></details>

### Q. 
    3. データをトレーニング セットと検証セットに分割する理由は何ですか?
1. データは 2 つのモデルを作成するために 2 つのセットに分割されます。1 つはトレーニング セットを使用するモデルで、もう 1 つは検証セットを使用するモデルです。
2. データを 2 つのセットに分割すると、モデルで予測されるラベルを元のデータセット内の実際の既知のラベルと比較できるようになります。
3. データを分割するのは Azure Machine Learning デザイナーを使用する場合のみで、他の機械学習シナリオでは分割しません。
<details><div>
    答え：2
     モデルが、トレーニングされなかったデータをどのように適切に処理できるかを確認するには、トレーニング データを使用して作成されたモデルを検証データでテストする必要があります。
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
    1. あなたは、Azure Machine Learning デザイナーを使用して、二項分類モデルのトレーニング パイプラインを作成しています。 特徴とラベルを含むデータセット、2 クラス デシジョン フォレスト モジュール、モデルのトレーニング モジュールを追加しました。 [Score Model] (モデルのスコア付け) モジュールと [Evaluate Mode] (モデル評価) モジュールを使用して、トレーニングに使用されていないデータセットのサブセットで、トレーニング済みモデルをテストする予定です。 他にどのモジュールを追加する必要がありますか?
1. データの結合
2. データの分割
3. データセット内の列の選択
<details><div>
    答え：２
     [データの分割] モジュールを使用して、データセットをトレーニングと検証のサブセットにランダムに分割します。
</div></details>

### Q. 
    2. Azure Machine Learning デザイナー パイプラインを使用して、二項分類モデルのトレーニングとテストを行います。 [Evaluate Mode] (モデル評価) モジュール内でモデルのパフォーマンス メトリックを確認します。 AUC スコアが 0.3 であることに注意してください。 モデルに関する結論はどのようになりますか?
1. モデルでは、真と予測のラベルの差が 30% であると説明できます。
2. モデルでは、テスト ケースの 70% が正確に予測されます。
3. このモデルのパフォーマンスは、ランダムな推測よりも低くなります。
<details><div>
    答え：３
    二項モデルのランダム予測で期待される AUC は 0.5 です。
</div></details>

### Q. 
    3. Azure Machine Learning デザイナーを使用して、分類モデルのトレーニング パイプラインを作成します。 モデルをサービスとしてデプロイする前に何を行う必要がありますか?
1. トレーニング パイプラインから推論パイプラインを作成する
2. トレーニング パイプラインに [Evaluate Mode](モデル評価) モジュールを追加する
3. 別の名前でトレーニング パイプラインを複製する
<details><div>
    答え：１
    サービスとしてデプロイするには、推論パイプラインを作成する必要があります。
</div></details>

### Q. 
    1. Azure Machine Learning デザイナー パイプラインを使用して、K-Means クラスタリング モデルのトレーニングとテストを行っています。 そのモデルでは、3 つのクラスターのいずれかに項目を割り当てます。 これを実現するには、K-Means クラスタリング モジュールのどの構成プロパティを設定する必要がありますか?
1. 重心の数を 3 に設定する
2. 乱数シードを 3 に設定する
3. 反復を 3 に設定する
<details><div>
    答え：１
     K クラスターを作成するには、重心の数を K に設定する必要があります
</div></details>

### Q. 
    2. Azure Machine Learning デザイナーを使用して、クラスタリング モデルのトレーニング パイプラインを作成します。 推論パイプラインでモデルを使用しようとしています。 モデルからクラスターの予測を推測するには、どのモジュールを使用する必要がありますか?
1. モデルのスコア付け
2. クラスターへのデータの割り当て
3. クラスタリング モデルのトレーニング
<details><div>
    答え：２
     トレーニング済みのクラスタリング モデルからクラスターの予測を生成するには、クラスターへのデータの割り当てモジュールを使用します
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>


## Kindle
### Q. 1
    あなたのチームは、データエンジニアリングとデータサイエンスの開発環境を構築しています。PythonとScalaをサポートし、データの保存、移動、処理サービスを自動化されたデータパイプラインに構成します。
    データエンジニアリングとデータサイエンスの両方のオーケストレーションに同じツールを使用する必要があり、ワークロードの分離とインタラクティブなワークロードをサポートして、マシンのクラスタ全体でスケーリングを可能にします。あなたは何をすべきですか？
1. Apache Hive for HDInsightで環境を構築し、Azure Data Factoryをオーケストレーションに使用します。
2. Azure Databricksで環境を構築し、オーケストレーションにAzure Data Factoryを使用します。
3. Apache Spark for HDInsightで環境を構築し、Azure Container Instancesでオーケストレーションを行う。
4. Azure Databricksで環境を構築し、オーケストレーションにAzure Container Instancesを使用します。
<details><div>
    答え：２
    Azure Databricksでは、2つの異なるタイプのクラスタを作成することができます。スタンダード、これらはデフォルトのクラスタで、Python、R、Scala、SQLで使用できます。 ハイコンカレンシー Azure Databricksは、Azure Data Factoryと完全に統合されています。
</div></details>

### Q. 2
    チームでデータサイエンス環境を構築する予定の方。機械学習パイプラインでモデルを学習するためのデータは、20GB以上のサイズになる予定です。以下のような要件があります。
    ①モデルはCaffe2またはChainerフレームワークを使用して構築する必要があります。
    ②データサイエンティストは、データサイエンス環境を使用して、接続されたネットワーク環境と切断されたネットワーク環境の両方で、個人のデバイスで機械学習パイプラインの構築とモデルのトレーニングを行うことができる必要があります。
    ③個人所有のデバイスは、ネットワーク接続時に機械学習パイプラインの更新をサポートしている必要があります。データサイエンス環境を選択する必要があります。
    あなたはどの環境を使用する必要がありますか？
1. Azure Machine Learning Service 
2. Azure Machine Learning Studio 
3. Azure Databricks 
4. Azure Kubernetes Service (AKS)
<details><div>
    答え：１
    データサイエンスバーチャルマシン（DSVM）は、データサイエンスに特化したMicrosoft Azureクラウド上のカスタマイズされたVMイメージである。Caffe2とChainerはDSVMでサポートされています。DSVMは、Azure Machine Learningと統合されています。
    不正解です。B：機械学習モデルを迅速かつ容易に実験したい場合、機械学習スタジオを使用し、組み込みの機械学習アルゴリズムがあなたのソリューションに十分である。
</div></details>

### Q. 3
    あなたは、株価を予測するための機械学習モデルを実装しています。このモデルはPostgreSQLデータベースを使用し、GPU処理を必要とします。あなたは、必要なツールで事前に構成された仮想マシンを作成する必要があります。あなたは何をする必要がありますか？
1. データサイエンスバーチャルマシン（DSVM）Windows版を作成します。
2. Geo Alデータサイエンスバーチャルマシン（Geo-DSVM）Windows版を作成します。
3. ディープラーニング仮想マシン(DLVM)Linux版を作成します。
4. ディープラーニング仮想マシン(DLVM) Windows版を作成する。
5. データサイエンスバーチャルマシン(DSVM)Linux版の作成。
<details><div>
    答え：5
    A、C：PostgreSQL（CentOS）はLinux Editionのみ
    B：Azure Geo AI Data Science VM（Geo-DSVM）は、MicrosoftのData Science VMから地理空間解析機能を提供します。具体的には、このVMは、ESRIの市場をリードするArcGIS Pro地理情報システムを追加することにより、Data Science VMのAIおよびデータサイエンスツールキットを拡張します。
    D：DLVMは、DSVMイメージの上にあるテンプレートです。すべてのパッケージ、GPUドライバなどは、DSVMイメージ内に含まれています。DLVMは、作成時の利便性を考慮して、Azure上のGPU VMインスタンス上にのみ作成が許可されています。
</div></details>

### Q. 4
    あなたは、半構造化、非構造化、および構造化データ型を分析するためのディープラーニングモデルを開発しています。モデル構築に利用できるデータは以下の通りです。スポーツイベントのビデオ録画 イベントに関するラジオ解説のトランスクリプト スポーツイベント中に取得された関連するソーシャルメディアフィードのログモデルを作成するための環境を選択する必要があります。どの環境を使用する必要がありますか？
1. Azure Cognitive Services 
2. Azure Data Lake Analytics 
3. Azure HDInsight with Spark MLib 
4. Azure Machine Learning Studio
<details><div>
    答え：1
    Azure Cognitive Servicesは、Microsoftの機械学習APIの進化したポートフォリオを拡張し、開発者が感情やビデオの検出、顔、音声、視覚認識、音声や言語の理解などの認知機能をアプリケーションに簡単に追加できるようにするものです。Azure Cognitive Servicesの目標は、開発者が見たり、聞いたり、話したり、理解したり、さらには推論を始めることができるアプリケーションを作成するのを支援することです。Azure Cognitive Services内のサービスのカタログは、ビジョン、スピーチ、言語、検索、ナレッジの5つの主要な柱に分類することができます。
</div></details>

### Q. 5
    Azure Machine Learningをサポートするためには、Azure Blob Storageにデータを保存する必要があります。あなたはAzure Blob Storageにデータを転送する必要があります。目標を達成するための3つの可能な方法は何ですか？各正解は完全な解決策を提示します。
1. Bulk Insert SQL Query 
2. AzCopy 
3. Python script 
4. Azure Storage Explorer 
5. Bulk Copy Program (BCP)
<details><div>
    答え：234
    Azure Blobストレージとの間で、さまざまなテクノロジーを使ってデータを移動することができます。
</div></details>

### Q. 6
    Azure Machine Learning StudioからWeka環境に大きなデータセットを移動します。あなたは、Weka環境用にデータをフォーマットする必要があります。どのモジュールを使用する必要がありますか？
1. CSVに変換する 
2. データセットに変換する 
3. ARFFに変換する 
4. SVMLightに変換する
<details><div>
    答え：3
    Azure Machine Learning StudioのConvert to ARFFモジュールを使用して、Azure Machine Learningのデータセットと結果を、Wekaツールセットで使用される属性-関連ファイル形式に変換します。このフォーマットは、ARFFとして知られています。WekaのARFFデータ仕様は、データの前処理、分類、特徴選択など、複数の機械学習タスクをサポートしています。このフォーマットでは、データはエントリとその属性によって整理され、1つのテキストファイルに収められています。
</div></details>

### Q. 7
    あなたは音声認識ディープラーニングモデルを作成する予定です。このモデルは、最新バージョンのPythonをサポートする必要があります。データサイエンスバーチャルマシン（DSVM）に含める音声認識用の深層学習フレームワークを推奨する必要があります。あなたは何を推奨すべきですか？
1. Rattle
2. TensorFlow 
3. Weka
4. Deeplearning4j
<details><div>
    答え：2
    TensorFlowは、数値計算と大規模な機械学習のためのオープンソースライブラリです。Pythonを使用し、フレームワークでアプリケーションを構築するための便利なフロントエンドAPIを提供します。TensorFlowは、手書きの数字分類、画像認識、単語埋め込み、リカレントニューラルネットワーク、機械翻訳の配列間モデル、自然言語処理、PDE（偏微分方程式）ベースのシミュレーションのための深いニューラルネットワークを訓練し実行することが可能です。不正解です。
        A：Rattleは、データ解析と機械学習を始めるためのR分析ツールです。
        C：Wekaは、Javaによるビジュアルデータマイニングと機械学習ソフトウェアに使用されています。
</div></details>

### Q. 8
    あなたは、Compute Unified Device Architecture（CUDA）計算を使用して深層学習モデルを訓練するために、深層学習仮想マシン（DLVM）を使用することを計画しています。あなたは、CUDAをサポートするためにDLVMを構成する必要があります。あなたは何を実装する必要がありますか？
1. SSD
2. オーバークロックによるCPU（Computer Processing Unit）の高速化 
3. グラフィック・プロセッシング・ユニット(GPU) 
4. 高ランダムアクセスメモリ（RAM）構成 
5. インテル® ソフトウェア・エクステンション（インテル® SGX）技術
<details><div>
    答え：3

</div></details>

### Q. 9
    あなたは、いくつかの列に欠損値を含む数値データセットを分析しています。特徴セットの次元に影響を与えることなく、適切な操作で欠損値を除去する必要があります。すべての値を含む完全なデータセットを分析する必要があります。解決策 連鎖式による多重インピュテーション（MICE）法を使用して、各欠損値を置き換えます。解決策は目標を達成しているか？
1. はい
2. いいえ
<details><div>
    答え：１
    MICEを使用して置換する。このオプションは，各欠損値について，統計文献に "Multivariate Imputation using Chained Equations" または "Multiple Imputation by Chained Equations" として記載されている方法を用いて計算された新しい値を割り当てる．Multiple imputation 法では，欠損値を埋める前に，欠損データを持つ各変数が，データ中の他の変数を用いて条件付きでモデル化される．
        注：連鎖式による多変量インピュテーション（MICE）は，時に "完全条件付き仕様" または "逐次回帰多重インピュテーション" と呼ばれ，欠損データに対処する原理的な方法の1つとして統計文献に現れている．シングルインピュテーションとは対照的にマルチプルインピュテーションを作成することで、インピュテーションにおける統計的不確実性を説明する。また、連鎖式アプローチは非常に柔軟で、様々なタイプの変数（例えば、連続またはバイナリ）だけでなく、境界や調査のスキップパターンなどの複雑なものを扱うことができます。
</div></details>

### Q. 10
    あなたは、いくつかの列で欠損値を含む数値データセットを分析しています。特徴セットの次元に影響を与えることなく、適切な操作で欠損値を除去する必要があります。あなたは、すべての値を含む完全なデータセットを分析する必要があります。解決策 列の中央値を計算し、その中央値を列の欠損値の置き換えとして使用する。解決策は目標を達成しているか？
1. はい
2. いいえ
<details><div>
    答え：２
    MICE（Multiple Imputation by Chained Equations）法を使用する。
</div></details>

### Q. 11
    Azure Machine Learning Studioを使用するデータサイエンティストですね。
    あなたは、ターゲット列を予測するために、ビンに出力列を生成するために値を正規化する必要があります。解決策 カスタム開始と停止ビンニングモードを持つ等幅を適用します。ソリューションは目標を満たしていますか？
1. はい
2. いいえ
<details><div>
    答え：２
    ターゲットカラムを持つ Entropy MDL binning モードを使用します。
</div></details>

### Q. 12
    あなたは、Azure Machine Learning Studioを使用するデータサイエンティストです。あなたは、ターゲット列を予測するために、ビンに出力列を生成するために値を正規化する必要があります。解決策 PQuantile正規化でQuantilesビンニングモードを適用します。解決策は目標を達成していますか？
1. はい
2. いいえ
<details><div>
    答え：２
    ターゲットカラムを持つ Entropy MDL binning モードを使用します。
</div></details>

### Q. 13
    あなたは分類タスクを解いています。k-foldクロスバリデーションを用いて、限られたデータサンプルでモデルを評価する必要があります。あなたは、分割数としてkパラメータを設定することから始めます。クロスバリデーションのためにkパラメータを設定する必要があります。どの値を使うべきでしょうか？
1. K=0.5
2. K=0
3. K=5
4. K=1
<details><div>
    答え：3
    LOO (Leave One Out) クロスバリデーション K = n (オブザベーションの数)を設定すると，n-フォールドとなり，K-フォールド・アプローチの特別なケースとして，LOO (leave-one out cross-validation)と呼ばれる．LOO CVは有用な場合もありますが、一般的にはデータを十分に揺さぶることができません。各フォールドからの推定値は相関が高く、それゆえ、それらの平均は高い分散を持つことがあります。このため、通常、K=5または10が選択されます。これは、バイアスと分散のトレードオフのための良い妥協点を提供します。
</div></details>

### Q. 14
    Azure Machine Learning Studioを使用して、機械学習実験を構築します。あなたは、データを2つの異なるデータセットに分割する必要があります。あなたはどのモジュールを使用する必要がありますか？
1. データのクラスタへの割り当て 
2. 学習済みモデルのロード 
3. パーティションとサンプル
4. モデルのチューニング-ハイパーパラメータ
<details><div>
    答え：３
    Partition and Sample with Stratified split オプションは、指定したルールで分割された複数のデータセットを出力します。
</div></details>

### Q. 15
    あなたは、Azure Machine Learning Studioを使用して実験を作成しています。あなたは、評価のためにデータを4つのサブセットに分割する必要があります。データには高度な欠測値があります。あなたは、分析のためにデータを準備する必要があります。あなたは実験を生成するための適切な方法を選択する必要があります。どの3つのモジュールを順番に実行する必要がありますか？回答するには、アクションのリストから適切なアクションを回答エリアに移動し、正しい順番で並べます。
1. ビルドカウント変換
2. 欠損値スクラバー
3. フィーチャーハッシュ
4. 欠損データの除去
5. 不連続値の置き換え
6. インポートデータ
7. 潜在的ディリクレ変換
8. パーティションとサンプル
<details><div>
    答え：６４８
    Azure Machine Learning StudioのClean Missing Dataモジュールで、欠損値を削除、置換、または推論するためのものです。
    不正解です。
        潜在的ディリクレ変換。Azure Machine Learning Studio の Latent Dirichlet Allocation モジュールで、分類されていないテキストをいくつかのカテゴリにグループ化する。潜在的ディリクレ配分（LDA）は、しばしば自然言語処理（NLP）で使用され、類似しているテキストを見つけるために使用されます。もう一つの一般的な用語は、トピックモデリングです。ビルド・カウンティング・トランスフォーム Azure Machine Learning Studio の Build Counting Transform モジュールで、トレーニングデータを分析します。このデータから、このモジュールは、予測モデルで使用することができるカウントベースの特徴のセットと同様に、カウントテーブルを構築します。
        Missing Value Scrubber: Missing Values Scrubber モジュールは非推奨です。
        Feature hashing: Feature hashingは言語学に使用され、ユニークなトークンを整数に変換することで機能する。
        離散値の置き換え：Azure Machine Learning Studioの離散値の置き換えモジュールは、離散値を表すために使用できる確率のスコアを生成するために使用されます。このスコアは、離散値の情報価値を理解するために有用である。
</div></details>

### Q. 16
    あなたは、機械学習モデルを作成している。あなたは、NULL行を含むデータセットを持っています。あなたは、Azure Machine Learning StudioのClean Missing Dataモジュールを使用して、データセット内のNULLおよび欠損データを識別して解決する必要があります。あなたはどのパラメータを使用する必要がありますか？
1. 平均で置き換える 
2. 列全体を削除する 
3. 行全体を削除する 
4. ホットデッキ 
5. カスタム置換値 
6. モードで置換する
<details><div>
    答え：３
    行全体を削除する。データセット内の1つ以上の欠損値を持つ任意の行を完全に削除します。これは、欠損値がランダムに欠損していると考えられる場合に有効である。
</div></details>

### Q. 17
    Azure Machine Learning Studio を使用して、データセットのフィーチャーエンジニアリングを実行します。あなたは、ビンにグループ化された特徴カラムを生成するために値を正規化する必要があります。
    解決策：Entropy Minimum Description Length（MDL）ビンニングモードを適用する。
    解決策は目標を達成しているか？
1. はい
2. いいえ
<details><div>
    答え：１
    エントロピーのMDLビン化モード。この方法では、予測したい列と、ビンにグループ化したい列を選択する必要があります。そして、データ上を通過し、エントロピーを最小化するビンの数を決定しようとする。言い換えれば、データ列がターゲット列を最もよく予測できるビンの数を選択するのである。そして、データの各行に関連するビン番号を<colname>quantizedというカラムで返します。
</div></details>

### Q. 18
    あなたは、Azure Machine Learning Studioを使用するデータサイエンティストです。あなたは、ターゲット列を予測するために、ビンに出力列を生成するために値を正規化する必要があります。
    解決策：QuantileIndex正規化でQuantiles正規化を適用する。ソリューションは目標を満たしていますか？
1. はい
2. いいえ
<details><div>
    答え：２
    ターゲットカラムを持つEntropy MDL binning modeを使用します。
</div></details>

### Q. 
    Azure Machine Learning Studioで新しい実験を作成しているところです。あるクラスは、トレーニングセット内の他のクラスよりもはるかに少ない数のオブザベーションを持っています。あなたは、クラスの不均衡を補償するために、適切なデータサンプリング戦略を選択する必要があります。
    解決策 あなたは、SMOTE（Synthetic Minority Oversampling Technique）サンプリングモードを使用します。この解決策は目標を達成しているか？
1. はい
2. いいえ
<details><div>
    答え：１
    SMOTEは、機械学習に使用するデータセットにおいて、未提示の事例を増やすために使用される。SMOTEは、単に既存の事例を複製するよりも、希少な事例を増やすのに有効な方法である。
</div></details>

### Q. 
#### ケーススタディ概要 
    あなたは、プロスポーツイベントのデータサイエンスを提供する会社のデータサイエンティストです。モデルは、グローバルおよびローカルな市場データを使用して、以下のビジネス目標を達成します。スポーツイベントにおけるモバイルデバイスユーザーの感情を、観衆の反応から得た音声に基づいて理解する。広告に対するユーザーの反応傾向を把握する。モバイル端末に配信される広告のスタイルをカスタマイズする。ビデオによるペナルティイベントの検出 現状ペナルティイベントの検出に使用されるメディアは、コンシューマーデバイスから提供されます。メディアには、スポーツイベント中に撮影され、ソーシャルメディア上で共有される画像や動画が含まれることがあります。画像や動画のサイズや形式はさまざまです。モデル構築のために利用できるデータは、7年分のスポーツイベントメディアから構成されています。スポーツイベントのメディアには、録画されたビデオやラジオの解説、スポーツイベント中に撮影された関連するソーシャルメディアフィードのログが含まれます。群集心理には、イベント参加者から提出されたモノラルとステレオの両方の音声記録が含まれます。ペナルティ検出とセンチメント データサイエンティストは、ペナルティイベント検出のための複数の機械学習モデルを使用して、インテリジェントなソリューションを構築する必要があります。データサイエンティストは、機械学習パイプラインの自動特徴エンジニアリングとモデル構築を使って、ローカル環境でノートブックを構築する必要があります。ノートブックは、動的ワーカー割り当てのSparkインスタンスを使用して、再トレーニングのためにデプロイされなければなりません。ノートブックは、新しいSparkインスタンスで同じコードで実行し、データのソースのみを再コード化する必要があります。グローバルなペナルティ検出モデルは、学習時に動的な実行時グラフ計算を使用して学習する必要があります。ローカルペナルティ検出モデルは、BrainScriptを用いて記述すること。ローカルな群衆感情モデルの実験では、ローカルなペナルティ検出データを組み合わせる必要があります。群集感情モデルは、歓声やキャッチフレーズなどの既知の音を識別しなければならない。個々の群衆感情モデルは、類似した音を検出する。ローカルモデルで共有する素性は全て連続変数である。共有される特徴量は倍精度を使用しなければならない。後続のレイヤーは、実行平均と標準偏差のメトリクスを利用できるようにする必要があります。広告 運用開始後数週間の間に、以下のようなことが観察されました。広告のレスポンス率が低下した。広告のレスポンス評価は低下し、広告スタイル間で一貫性がない。トレーニングデータと本番データ間の特徴量の分布が一致しない分析の結果、ユーザーの位置と行動に関する100個の数値特徴のうち、位置情報ソースに由来する47個の特徴が生の特徴として利用されていることがわかった。偏りと分散の問題を改善するために提案された実験は、線形的に相関のない10個の特徴を設計することである。初期データ発見では、群衆感情モデルに使用される学習データにおいて、対象状態の密度が広範囲に渡っていることが示されている。すべてのペナルティ検出モデルにおいて、SGD（Stochastic Gradient Descent）を用いた推論フェーズが遅すぎることがわかる。音声サンプルでは、キャッチフレーズの長さが地域によって25%～47%異なることが示された グローバルペナルティ検出モデルの性能は、トレーニングセットと検証セットを比較すると、分散は小さいがバイアスが大きいことが示された。機能変更を実施する前に、すべてのトレーニングケースと検証ケースを使用して、バイアスと分散を確認する必要があります。広告レスポンスモデルは、各イベントの開始時にトレーニングし、スポーツイベント中に適用する必要があります。市場セグメンテーションモデルは、類似した広告レスポンス履歴に対して最適化されなければなりません。サンプリングは、同じ特徴を共有するローカルとグローバルのセグメンテーションモデル間で相互的かつ集団的な排他性を保証しなければならない。ローカル・マーケット・セグメンテーション・モデルは、ユーザーの広告反応傾向を判断する前に適用される。広告反応モデルは、特徴の非線形境界をサポートする必要がある。広告傾向モデルは、カットスレッショルドを0.45とし、重み付きカッパが0.1±5%から逸脱した場合に再トレーニングを行う。広告傾向モデルは、以下の図に示すようなコスト要因を用いる。

### Q. 
    群衆感情ローカルモデルのための特徴エンジニアリング戦略を実装する必要があります。どうすればいいのでしょうか？
1. 分散分析(ANOVA)を行う。
2. ピアソン相関係数を適用する。
3. スピアマン相関係数を適用する。
4. 線形判別分析を適用する。
<details><div>
    答え：４
    線形判別分析法は、連続変数にのみ作用し、カテゴリー変数や順序変数には作用しない。線形判別分析は、変数の平均を比較することによって動作するという点で、分散分析（ANOVA）に似ています。シナリオ データサイエンティストは、機械学習パイプラインの自動特徴エンジニアリングとモデル構築を使用して、ローカル環境でノートブックを構築する必要があります。ローカル群衆感情モデルの実験では、ローカルペナルティ検出データを組み合わせる必要があります。ローカルモデルのための共有された特徴はすべて連続変数である。
    不正解です。
        B：ピアソン相関係数（ピアソンのR検定と呼ばれることもある）は、2つの変数間の線形関係を測定する統計値である。係数の値を調べることで、2つの変数の関係の強さや、正の相関があるか負の相関があるかなどを推測することができます。
        C：スピアマンの相関係数は、ノンパラメトリックかつ正規分布によらないデータで使用するために設計されています。スピアマンの係数は、2つの変数間の統計的依存性のノンパラメトリック尺度であり、ギリシャ文字のrhoで表記されることもある。スピアマン係数は、2つの変数が単調に関係している度合いを表します。順序変数でも使用できるため、スピアマン順位相関とも呼ばれる。
</div></details>

### Q. 
    あなたは、あるイベント中の通話数を推定するための回帰モデルを構築しています。あなたは、特徴値がポアソン回帰モデルを構築するための条件を達成しているかどうかを判断する必要があります。特徴量セットにはどの2つの条件が含まれていなければならないか？各正解は、ソリューションの一部を提示します。注：各正解の選択は1点の価値があります。
1. ラベルデータは負の値でなければならない。
2. ラベルデータは整数でなければならない。
3. ラベルデータは非離散値でなければならない。
4. ラベルデータは正の値でなければならない。
5. ラベルデータは正または負の値である。
<details><div>
    答え：24
    ポアソン回帰は、数値（通常はカウント）を予測するために使用される回帰モデルでの使用を意図しています。したがって、予測しようとする値が以下の条件に適合する場合のみ、このモジュールを使用して回帰モデルを作成する必要があります。応答変数がポアソン分布である。カウントは負であってはならない。負のラベルで使用しようとすると、このメソッドは完全に失敗します。ポアソン分布は離散分布なので、整数でない数でこの方法を使っても意味がない。
</div></details>

### Q. 
    あなたは、あるデータセットに対してフィーチャーエンジニアリングを行っています。CityName という名前のフィーチャーを追加して、列の値に London というテキストを入力する必要があります。あなたは、データセットに新しいフィーチャーを追加する必要があります。どのAzure Machine Learning Studioモジュールを使用する必要がありますか？
1. メタデータの編集 
2. テキストの前処理 
3. Python スクリプトの実行 
4. Latent Dirichlet Allocation (潜在的ディリクレ配分)
<details><div>
    答え：１
    典型的なメタデータの変更には、カラムを機能としてマークすることが含まれるかもしれません。
</div></details>

### Q. 

#### ケーススタディ概要 
    あなたは、プロスポーツイベントのデータサイエンスを提供する会社のデータサイエンティストです。モデルは、グローバルおよびローカルな市場データを使用して、以下のビジネス目標を達成します。スポーツイベントにおけるモバイルデバイスユーザーの感情を、観衆の反応から得た音声に基づいて理解する。広告に対するユーザーの反応傾向を把握する。モバイル端末に配信される広告のスタイルをカスタマイズする。ビデオを使用して、ペナルティイベントを検出する
#### 現在の環境 
    ペナルティ事象の検出に使用されるメディアは、コンシューマ機器から提供される。メディアには、スポーツイベント中に撮影され、ソーシャルメディアを使って共有される画像や動画が含まれる場合があります。画像や動画のサイズや形式はさまざまです。モデル構築のために利用できるデータは、7年分のスポーツイベントメディアから構成されています。スポーツイベントのメディアには、録画されたビデオやラジオの解説、スポーツイベント中に撮影された関連するソーシャルメディアフィードのログが含まれます。群集心理には、イベント参加者から提出されたモノラルとステレオの両方の形式の音声記録が含まれます。
#### ペナルティ検出とセンチメント 
    データサイエンティストは、ペナルティイベント検出のために複数の機械学習モデルを使用して、インテリジェントなソリューションを構築する必要があります。データサイエンティストは、機械学習パイプラインの自動特徴エンジニアリングとモデル構築を使って、ローカル環境でノートブックを構築する必要があります。ノートブックは、動的ワーカー割り当てのSparkインスタンスを使用して、再トレーニングのためにデプロイされなければなりません。ノートブックは、新しいSparkインスタンスで同じコードで実行し、データのソースのみを再コード化する必要があります。グローバルなペナルティ検出モデルは、学習時に動的な実行時グラフ計算を使用して学習する必要があります。ローカルペナルティ検出モデルは、BrainScriptを用いて記述すること。ローカルな群衆感情モデルの実験では、ローカルなペナルティ検出データを組み合わせる必要があります。群集感情モデルは、歓声やキャッチフレーズなどの既知の音を識別しなければならない。個々の群衆感情モデルは、類似した音を検出する。ローカルモデルで共有する素性は全て連続変数である。共有される特徴量は倍精度を使用しなければならない。後続のレイヤーでは、実行平均と標準偏差のメトリックスが利用可能でなければならない。
#### 広告制作 
    当初の数週間は、以下のような状況が見られました。広告のレスポンス率が低下した。広告のスタイルによって、低下幅が一定しない。学習データと本番データの特徴量の分布が一致しない
    分析によると、ユーザーの位置と行動に関する100個の数値特徴のうち、位置情報ソースに由来する47個の特徴が生の特徴として使用されていることがわかりました。偏りと分散の問題を改善するために提案された実験は、線形的に相関のない10個の特徴を設計することです。初期データ発見では、群衆感情モデルに使用されるトレーニングデータにおいて、ターゲット状態の密度が広範囲に渡っていることが示された。すべてのペナルティ検出モデルにおいて、SGD（Stochastic Gradient Descent）を用いた推論フェーズが遅すぎることがわかる。音声サンプルでは、キャッチフレーズの長さが地域によって25%～47%異なることが示された グローバルペナルティ検出モデルの性能は、トレーニングセットと検証セットを比較すると、分散は小さいがバイアスが大きいことが示された。機能変更を実施する前に、すべてのトレーニングケースと検証ケースを使用して、バイアスと分散を確認する必要があります。広告レスポンスモデルは、各イベントの開始時にトレーニングし、スポーツイベント中に適用する必要があります。市場セグメンテーションモデルは、類似した広告レスポンス履歴に対して最適化されなければなりません。サンプリングは、同じ特徴を共有するローカルとグローバルのセグメンテーションモデル間で相互的かつ集団的な排他性を保証しなければならない。ローカル・マーケット・セグメンテーション・モデルは、ユーザーの広告反応傾向を判断する前に適用される。広告反応モデルは、特徴の非線形境界をサポートする必要がある。広告傾向モデルは、カットスレッショルドを0.45とし、重み付きカッパが0.1±5%から逸脱した場合に再トレーニングを行う。広告傾向モデルは、以下の図に示すようなコスト要因を用いる。

### Q. 
    あなたは、広告に反応するユーザーの傾向を判断するために、モデル開発戦略を実行する必要があります。あなたはどのテクニックを使用する必要がありますか？
1. セントロイド距離に基づいてデータを分割するために、相対式分割モジュールを使用します。
2. イベントへの移動距離に基づいてデータを分割するために、相対式分割モジュールを使用します。
3. 行分割モジュールを使用して、イベントまでの移動距離に基づいてデータを分割します。
4. 行分割モジュールを使用して、セントロイドの距離に基づいてデータを分割します。
<details><div>
    答え：１
    データ分割は、データセットの行を2つの異なるセットに分割します。Azure Machine Learning Studio の Split Data モジュールの Relative Expression Split オプションは、数式を使用してデータセットをトレーニングデータセットとテストデータセットに分割する必要がある場合に便利です。相対式分割。このオプションは、数値カラムに条件を適用したい場合に使用します。数値には、日付/時刻フィールド、年齢や金額を含む列、あるいはパーセンテージが含まれることがあります。たとえば、アイテムの価格によってデータセットを分割したり、年齢層によって人々をグループ化したり、カレンダーの日付によってデータを分離したりすることができます。シナリオ 広告に反応するユーザーの傾向を決定する前に、ローカル市場のセグメンテーションモデルを適用する。学習データと本番データの特徴量の分布が一致していない
</div></details>

### Q. 
    パフォーマンス曲線に示されているように、広告レスポンスモデルに新しいコスト要因のシナリオを実装する必要があります。どのテクニックを使うべきですか？
1. しきい値を 0.5 に設定し、重み付きカッパが 0.45 から±5%逸脱した場合に再トレーニングを行います。
2. しきい値を0.05に設定し、重み付きカッパが0.5から±5%乖離した場合に再トレーニングを行う。
3. しきい値を0.2に設定し、重み付きカッパが0.6から±5%乖離した場合に再トレーニングを行う。
4. しきい値を0.75に設定し、重み付きカッパが0.15から+/-5%乖離した場合に再トレーニングを行う。
<details><div>
    答え：１
    現在のコストファクターシナリオと提案するコストファクターシナリオのパフォーマンスカーブを下図に示す。
    広告傾向モデルはカット閾値を0.45とし、重み付きカッパが0.1±5%から逸脱した場合に再トレーニングが発生する。
</div></details>

### Q. 
#### 概要 
    あなたは、米国内の優良な個人・商業用不動産を専門に扱うファブリカム・レジデンス社のデータサイエンティストである。Fabrikam Residencesはヨーロッパへの進出を検討しており、ヨーロッパの主要都市における個人住宅の価格を調査するよう依頼されました。あなたは、Azure Machine Learning Studioを使用して、不動産の中央値を測定します。あなたは、線形回帰とベイズ線形回帰モジュールを使用して、不動産価格を予測する回帰モデルを作成します。
#### データセット 
    ロンドンとパリという2つの都市の物件詳細を含むCSV形式のデータセットが2つあります。両方のファイルを別々のデータセットとしてAzure Machine Learning Studioに追加して、実験の開始点とします。どちらのデータセットも、以下のカラムを含んでいます。
    最初の調査では、MedianValueの列を除けば、両データセットは同じ構造であることがわかった。小さい方のParisデータセットにはテキスト形式のMedianValueが含まれ、大きい方のLondonデータセットには数値形式のMedianValueが含まれる。
#### 値 
    両データセットのAccessibilityToHighwayの列には欠損値がある。欠損値を埋める前に、データ中の他の変数を用いて条件付きでモデル化するように、欠損データを新しいデータに置き換える必要があります。各データセットのカラムには欠損値やヌル値が含まれている。また、データセットには多くの外れ値が含まれている。年齢列は外れ値の割合が高い。Age 列に外れ値がある行を削除する必要があります。MedianValue と AvgRoomsInHouse 列は、両方とも数値形式のデータを保持しています。あなたは、2つの列の間の関係をより詳細に分析するために、特徴選択アルゴリズムを選択する必要があります。
#### モデル適合性 
    モデルにはオーバーフィッティングの兆候がある。オーバーフィッティングを抑える、より洗練された回帰モデルを作成する必要があります。
#### 実験要件 
    線形回帰モジュールとベイズ線形回帰モジュールを交差検証し、性能を評価するために、実験を設定する必要があります。それぞれのケースで、データセットの予測変数はMedianValueという名前の列です。パリのデータセットの MedianValue カラムのデータ型が、ロンドンのデータセットの構造と一致することを確認する必要があります。結果を予測するために、データの列に優先順位をつけなければなりません。あなたは、関係を測定するために、ノンパラメトリック統計学を使用しなければなりません。MediaValue と AvgRoomsinHouse 列間の関係を分析するために、特徴選択アルゴリズムが必要である。
#### モデルトレーニング
#### Permutation Feature Importance 
    学習済みモデルとテストデータセットが与えられたとき、特徴変数のPermutation Feature Importanceスコアを計算する必要があります。あなたは、モデルの絶対的な適合度を決定しなければなりません。
#### ハイパーパラメータ 
    学習フェーズを高速化するために、モデルの学習プロセスでハイパーパラメータを設定する必要があります。さらに、この構成では、評価間隔ごとにパフォーマンスの低い実行をキャンセルし、成功する可能性が高いモデルに労力とリソースを振り向ける必要があります。モデルがハイパーパラメータのチューニングで計算資源を効率的に使用できないことを懸念している。また、モデルによって全体のチューニング時間が増加することを懸念しています。したがって、有望なジョブを終了させることなく節約できるような早期停止基準をモデルに実装する必要があります。
#### テスト 
    Azure Machine Learning StudioのPartition and Sampleモジュールを使用して、サンプリングに基づくデータセットの複数のパーティションを生成する必要があります。
#### クロスバリデーション 
    クロスバリデーションのために、3つの均等なパーティションを作成する必要があります。また、テストとトレーニングのデータセットの行が、各都市の主要河川に近い物件で均等に分けられるように、クロスバリデーションの処理を設定する必要があります。このタスクは、データがサンプリングプロセスを通過する前に完了させる必要があります。
#### Linear Regression 
    モジュール Linear Regression モジュールをトレーニングする場合、モデルで使用する最適なフィーチャーを決定する必要があります。フィーチャー重要性プロセスが完了する前と後のパフォーマンスを測定するために提供される標準的なメトリックを選択することができます。複数の学習モデルにおける特徴の分布は一貫している必要があります。
#### データの視覚化 
    テスト結果をFabrikam Residencesチームに提供する必要があります。あなたは、結果を提示するのに役立つデータビジュアライゼーションを作成します。
    モデルの診断テスト評価を実施するために、ROC（Receiver Operating Characteristic）曲線を作成する必要があります。2クラス決定林モジュールと2クラス決定ジャングルモジュールを互いに比較するために、Azure Learning StudioでROC曲線を生成するための適切な方法を選択する必要があります。

### Q. 
    あなたは、モデルのトレーニングのための早期停止基準ポリシーを実装する必要があります。その解決策を開発するために、どの 3 つのコードセグメントを使うべきですか？回答するには、コードセグメントのリストから適切なコードセグメントを回答エリアに移動し、正しい順番で並べます。注意: 回答の選択肢の順番は1つ以上でも正解です。あなたが選択した正しい順序のいずれかに単位が与えられます。
1. 
2. 
3. 
4. 
<details><div>
    答え：
    有望なジョブを終了させることなく節約できるような、モデルに対する早期停止基準を実装する必要があります。切り捨て選択では、評価間隔ごとに、パフォーマンスが最も低いランを所定の割合でキャンセルします。ランは、主要なメトリックのパフォーマンスに基づいて比較され、最も低いX％が終了されます。例： from azureml.train.hyperdrive import TruncationSelectionPolicy early_termination_policy = TruncationSelectionPolicy(evaluation_interval=1, truncation_percentage=20, delay_evaluation=5) 
    
    不正解です。Banditは、スラックファクター/スラック量と評価間隔に基づく終了ポリシーです。このポリシーは、主な指標が、最もパフォーマンスの高いトレーニング実行に対して、指定されたスラックファクター/スラック量以内でない実行を早期に終了させます。例： from azureml.train.hyperdrive import BanditPolicy early_termination_policy = BanditPolicy(slack_factor = 0.1, evaluation_interval=1, delay_evaluation=5)
</div></details>

### Q. 
    あなたは、学生の教育期間、学位タイプ、および芸術形式という変数に応じて、学生の芸術作品の価格を予測するモデルを作成します。あなたは、線形回帰モデルを作成することから始めます。あなたは、この線形回帰モデルを評価する必要があります。解決策 次の測定基準を使用する。精度、プレシジョン、リコール、F1スコア、AUC。解答は目標を達成しているか？
1. はい
2. いいえ
<details><div>
    答え：２
    これらは分類モデルを評価するための指標であり、代わりに使用します。平均絶対誤差、ルート平均絶対誤差、相対絶対誤差、相対2乗誤差、決定係数。
</div></details>

### Q. 
    あなたは、学生の教育期間、学位の種類、および芸術形式という変数に応じて、学生の芸術作品の価格を予測するモデルを作成しています。
    あなたは、線形回帰モデルを作成することから始めます。あなたは、この線形回帰モデルを評価する必要があります。解決策 次の測定基準を使用します。相対2乗誤差，決定係数，精度，プレシジョン，リコール，F1スコア，およびAUC．解答は目標を達成しているか？
1. はい
2. いいえ
<details><div>
    答え：２
    Relative Squared Error, Coefficient of Determinationは線形回帰モデルを評価するのに適した指標ですが、その他は分類モデル用の指標です。
</div></details>

### Q. 
    あなたは、線形回帰モデルを作成するデータサイエンティストです。あなたは、データが回帰線にどれだけ近いかを判断する必要があります。あなたはどのメトリックをレビューする必要がありますか？
1. 二乗平均平方根誤差 
2. 決定係数 
3. 回収率 
4. 精度
5. 平均絶対誤差 
<details><div>
    答え：２
    R2 と呼ばれる決定係数は、モデルの予測力を 0 から 1 の間の値で表し、0 はモデルがランダムであること（何も説明しない）、1 は完全にフィットしていることを意味します。しかし、R2 値の解釈には注意が必要です。低い値は完全に正常であり、高い値は疑わしい可能性があるからです。
    不正解です。
        A: 平均二乗誤差（RMSE）は、モデルの誤差を要約した1つの値を作成します。差を二乗することで、この指標は過剰予測と過小予測の差を無視する。C: 回収率は、モデルによって返されたすべての正しい結果の割合です。
        D: Precisionは、すべての肯定的な結果に対する真の結果の割合である。
        E: 平均絶対誤差(MAE)は、予測が実際の結果にどれだけ近いかを測定する。したがって、スコアが低ければ低いほど良い。
</div></details>

### Q. 
    あなたは、2クラスロジスティック回帰モデルを使用して、バイナリ分類を作成しています。あなたは、アンバランスのためにモデル結果を評価する必要があります。どの評価指標を使うべきですか？
1. 相対絶対誤差 
2. AUC曲線 
3. 平均絶対誤差 
4. 相対二乗誤差 
5. 精度 
6. 二乗平均平方根誤差
<details><div>
    答え：２
    真陽性率と偽陽性率の関係は，ROC（Receiver Operating Characteristic）曲線とそれに対応するAUC（Area Under the Curve）値で見ることができます．この曲線が左上隅に近いほど，分類器の性能が優れていることを意味します（つまり，偽陽性率を最小にしながら真陽性率を最大にすることです）．プロットの対角線に近い曲線は，ランダムな推測に近い予測をする傾向のある分類器から生じます．
</div></details>

### Q. 
    トレーニング誤差と検証誤差の値が大きく異なるモデルがあります。新しいモデルを作成し、クロスバリデーションを実行する必要があります。Azure Machine Learning Studioを使用して、新しいモデルのパラメータセットを特定する必要があります。各ステップでどのモジュールを使用する必要がありますか？答えるために、適切なモジュールを正しいステップにドラッグします。各モジュールは、1回または複数回使用することができ、全く使用しないこともできます。ペイン間の分割バーをドラッグしたり、コンテンツを表示するためにスクロールする必要がある場合があります。
A:データの分割 
B:分割とサンプル 
C:2クラス・ブースト決定木 
D:チューニング
1. パラメータスコープを定義する
2. クロスバリデーションの定義
3. メトリックを定義する
4. 学習・評価・比較
<details><div>
    答え：1.a,2.b,3.c,4.d
    統合された学習と調整。使用するパラメータを設定し、モジュールが複数の組み合わせを繰り返し、「最適」なモデルを見つけるまで精度を測定します。ほとんどの学習モジュールでは、学習プロセス中に変更するパラメータと、固定するパラメータを選択することができます。指定されたパラメータでモデルの良し悪しを判断するために、モデル交差検証を使用することをお勧めします。Tune Model Hyperparameters を使用して、最適なパラメータを特定します。
</div></details>

### Q. 
    あなたは、英語のテキストコンテンツをフランス語のテキストコンテンツに翻訳するための機械学習モデルを構築している。あなたは、テキストコンテンツの順序を学習するために、機械学習モデルを構築し、訓練する必要があります。
    どのタイプのニューラルネットワークを使うべきでしょうか？
1. 多層知覚（MLP） 
2. 畳み込みニューラルネットワーク（CNN） 
3. リカレントニューラルネットワーク（RNN） 
4. Generative Adversarial Networks (GANs)
<details><div>
    答え：３
    英語テキストのコーパスをフランス語に翻訳するために、リカレントニューラルネットワーク（RNN）を構築する必要がある。注：RNNは、入力としてテキストのシーケンスを取るか、出力としてテキストのシーケンスを返すか、またはその両方を行うように設計されている。ネットワークの隠れ層は、各時間ステップの出力とセルの状態が次の時間ステップの入力となるループを持つため、再帰と呼ばれる。このリカレントは一種の記憶として機能する。これにより、文脈情報がネットワークを通じて流れ、前の時間ステップからの関連出力を現在の時間ステップのネットワーク操作に適用することができる。
</div></details>

### Q. 
    あなたは、2値分類モデルを作成します。あなたはモデルの性能を評価する必要があります．あなたはどの2つの測定基準を使うことができますか？各正解は完全な解決策を提示します。注：各正解の選択は1点の価値があります。
1. 相対絶対誤差 
2. 精度 
3. 正確さ 
4. 平均絶対誤差 
5. 決定係数
<details><div>
    答え：23
    バイナリ分類モデルで利用可能な評価指標は以下の通りである。Accuracy, Precision, Recall, F1 Score, and AUC. 注意: 非常に自然な疑問は，「モデルに該当する個体のうち，いくつが正しく分類されたのか（TP）」である．この質問は、正しく分類された陽性の割合であるモデルのPrecisionを見ることによって答えることができる。
</div></details>

### Q. 
    Azure Machine Learning Studio の Two-Class Neural Network モジュールを使用して、バイナリ分類モデルを構築します。Tune Model Hyperparameters モジュールを使用して、モデルの精度をチューニングします。Tune Model Hyperparameters モジュールを構成する必要があります。どの2つの値を使用する必要がありますか？各正解は、解答の一部を示しています。注：各正解は 1 ポイントに相当します。
1. 隠れ節の数 
2. 学習速度 
3. 正規化器のタイプ 
4. 学習反復の数 
5. 隠れ層の仕様
<details><div>
    答え：45
    D: Number of learning iterationsで、アルゴリズムが学習ケースを処理する最大回数を指定します。
    E: Hidden layer specificationで、作成するネットワークアーキテクチャの種類を選択する。入力層と出力層の間に、複数の隠れ層を挿入することができる。ほとんどの予測タスクは、1つまたはいくつかの隠れ層だけで簡単に達成することができます。
</div></details>

### Q. 
    あなたは、次のように定義された6つのデータポイントを含むPython NumPy配列を評価しています： data = [10, 20, 30, 40, 50, 60] Python Scikit-learn 機械学習ライブラリのk-foldアルゴリズムの移植を使用して、次の出力を生成する必要があります： train: [10 40 50 60], test: [20 30] train: [20 30 40 60], test: [10 50] train: [10 20 30 50], test: [40 60] あなたは、出力を生成するために、クロスバリデーションを実装する必要があります。どのようにコードセグメントを完成させるべきでしょうか？回答するには、回答領域のダイアログボックスで適切なコードセグメントを選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
    Azure Machine Learning Studioを使用して、バイナリ分類モデルを作成します。モデルのパラメータスイープを実行して、ハイパーパラメータを調整する必要があります。パラメータスイープは、次の要件を満たす必要があります：ハイパーパラメータの可能なすべての組み合わせを繰り返し実行すること。どのパラメータ掃引モードを使用する必要がありますか？
1. ランダムスイープ 
2. スイープクラスタリング 
3. グリッド全体 
4. ランダムグリッド 
5. ランダムシード
<details><div>
    答え：4
    ランダムグリッドでの最大実行回数。このオプションもパラメータ値のランダムサンプリングに対する反復回数を制御しますが、値は指定した範囲からランダムに生成されるのではなく、パラメータ値のすべての可能な組み合わせの行列が作成され、その行列に対してランダムサンプリングが行われます。この方法は、より効率的で、地域的なオーバーサンプリングやアンダーサンプリングが発生しにくい方法です。統合されたパラメータスイープをサポートするモデルをトレーニングする場合、使用するシード値の範囲を設定し、ランダムシードを反復することも可能です。これはオプションですが、種子の選択によって生じるバイアスを回避するのに有効です。
    不正解です。
        B: クラスタリングモデルを構築する場合、Sweep Clusteringを使用して、最適なクラスタ数とその他のパラメータを自動的に決定します。
        C: グリッド全体。このオプションを選択すると、モジュールはシステムによって事前に定義されたグリッド上でループし、さまざまな組み合わせを試し、最適な学習者を特定します。このオプションは、最適なパラメータ設定が何かわからず、可能な限りの値の組み合わせを試したい場合に有効です。E: ランダムスイープを選択した場合、パラメータ値のランダムな組み合わせを使用して、モデルを何回学習させるかを指定することができます。
</div></details>

### Q. 
    あなたは、2値分類を実行するリカレントニューラルネットワークを構築しています。各トレーニングエポックのトレーニングロス、バリデーションロス、トレーニング精度、およびバリデーション精度が提供されています。あなたは、分類モデルが過剰適合しているかどうかを識別する必要があります。次のうち正しいものはどれですか？
1. モデルを訓練するとき、訓練損失は一定で、検証損失は一定値で訓練損失の値に近い。
2. モデルを学習させる際、学習損失は減少し、検証損失は増加する。
3. モデル学習の際、トレーニングロスは一定で、バリデーションロスは減少する。
4. モデルを学習させると、学習損失は増加し、検証損失は減少する。
<details><div>
    答え：2
    オーバーフィットモデルとは，訓練セットでの性能が良好で，さらに向上し続けるのに対し，検証セットでの性能がある時点まで向上し，その後低下し始めるようなモデルのことである．
</div></details>

### Q. 
    あなたは、K-means アルゴリズムを使用してクラスタリングを実行しています。あなたは可能な終了条件を定義する必要がある。あなたはどの3つの条件を使うことができますか？各正解は完全な解決策を提示します。注：各正解の選択は1点の価値があります。
1. セントロイドは反復間で変化しない。
2. 残差平方和(RSS)が閾値より上に上昇する。
3. 残差平方和(RSS)が閾値を下回る。
4. 一定回数繰り返される。
5. セントロイド間の距離の和が最大となる。
<details><div>
    答え：134
    AD: セントロイドが安定したとき，あるいは指定された回数の反復が終了したときに，このアルゴリズムは終了する．
    C: セントロイドがクラスタのメンバーをどれだけよく表しているかの指標は，残差平方和（RSS）であり，すべてのベクトルにわたって合計されたセントロイドからの各ベクトルの2乗距離である．RSSは目的関数であり、我々の目標はそれを最小化することである。
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

## Udemiy
