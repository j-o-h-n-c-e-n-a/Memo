
## Q. 1-1
同じVPC（仮想プライベートクラウド）内の複数のクライアントから呼び出される必要がある、Compute Engine仮想マシンインスタンス上でホストされるHTTP APIを開発しています。クライアントがサービスのIPアドレスを取得できるようにしたい。どうすればよいでしょうか？
1. 静的な外部IPアドレスを予約し、HTTP(S)負荷分散サービスの転送ルールに割り当てる。クライアントはこのIPアドレスを使ってサービスに接続する。
2. 静的な外部IPアドレスを予約し、HTTP(S)ロードバランシングサービスの転送ルールに割り当てる。次に、クラウドDNSでAレコードを定義する。クライアントはAレコードの名前を使用してサービスに接続する。
3. クライアントが、https://[INSTANCE_NAME].[ZONE].c.[PROJECT_ID].internal/.というURLでインスタンス名に接続し、Compute Engineの内部DNSを使用するようにします。
4. クライアントが、https://[API_NAME]/[API_VERSION]/のURLでインスタンス名に接続して、Compute Engineの内部DNSを使用するようにします。
<details><div>
    答え：3
A. 
1．静的外部IPアドレスは、クライアントがサービスに接続するために使用できる固定IPアドレスを提供します。インスタンスが再起動されたり、インスタンスがオートスケーリンググループの一部である場合、インスタンスのIPアドレスが変更される可能性があるため、これは重要です。
2．HTTP(S)ロードバランシング・サービスは、トラフィックを複数のインスタンスに分散させることができ、サービスのパフォーマンスと可用性を向上させることができます。また、利用可能なインスタンスのプールから不健康なインスタンスを自動的に削除するヘルスチェックも処理できる。
3．転送ルールを使用することで、URLまたはIPアドレスに基づいて、トラフィックを適切なインスタンスに誘導することができる。これにより、複数のサービスを単一のIPアドレスとポートの組み合わせでホストすることができる。
4．クライアントは、転送ルールに割り当てられたIPアドレスを使用してサービスに接続できる。
結論として、この複雑なソリューションは "非最適 "と評価できる。
B. 説明
このオプションはオプションAと似ていますが、サービスに接続するためにIPアドレスを使用する代わりに、クライアントはクラウドDNSで定義されたAレコードの名前を使用します。これは、サービスによりユーザーフレンドリーな名前を提供できますが、セットアップにさらなる複雑さが加わります。
さらに、クラウドDNSを使用すると、構成および管理する必要がある別のサービスが追加されるため、問題やダウンタイムが発生する可能性が高まります。
D. 説明
このオプションはオプションCと似ていますが、URLでインスタンス名を使用する代わりに、API名とバージョンを使用します。これは、より使いやすいURLを提供できますが、Compute Engineが提供する内部DNSサービスに依存します。
また、カスタムのAPI名とバージョンを使用すると、セットアップがさらに複雑になり、追加の設定と管理が必要になる場合があります。
正解
C. このオプションは、Compute Engineが提供する内部DNSサービスを使用して、サービスをホストするインスタンスのIPアドレスを解決します。これは、すべてのクライアントが同じVPC内にあり、内部DNSサービスにアクセスできる場合に機能します。
まとめると、同じVPC内のクライアントがCompute Engineの仮想マシンインスタンス上でホストされているHTTP APIのIPアドレスを取得できるようにするための最良の選択肢は、クライアントが、https://[INSTANCE_NAME].[ZONE].c.[PROJECT_ID].internal/というURLでインスタンス名に接続してCompute Engineの内部DNSを使用するようにすることです。
Links: 

https://cloud.google.com/compute/docs/internal-dns
</div></details>

## Q. 1-2
Webアプリケーションは企業のイントラネットにデプロイされています。このWebアプリケーションをGoogle Cloudに移行する必要があります。ウェブアプリケーションは、会社の従業員だけが利用でき、従業員が移動中にアクセスできる必要があります。アプリケーションの変更を最小限に抑えながら、Webアプリケーションのセキュリティとアクセシビリティを確保する必要があります。

どのような対応が必要ですか？
1. アプリケーションへの HTTP(S)リクエストごとに認証情報をチェックするようにアプリケーションを構成する。
2. 従業員がパブリックIPアドレス経由でアプリケーションにアクセスできるように、Identity-Aware Proxyを構成する。
3. ユーザーに企業アカウントへのログインを要求するCompute Engineインスタンスを構成します。WebアプリケーションのDNSをプロキシのCompute Engineインスタンスを指すように変更します。認証後、Compute EngineインスタンスはWebアプリケーションとの間でリクエストを転送します。
4. ユーザーに企業アカウントへのログインを要求するCompute Engineインスタンスを構成する。WebアプリケーションのDNSをプロキシのCompute Engineインスタンスを指すように変更します。認証後、Compute Engineは、WebアプリケーションをホストするパブリックIPアドレスにHTTPリダイレクトを発行します。
<details><div>
    答え：3
A. このオプションでは、HTTP(S)リクエストごとに認証チェックを実装するために、アプリケーションに大幅な変更が必要になる可能性が高く、アプリケーションの変更を最小限に抑えるという要件に反する。
B. IAP（Identity-Aware Proxy）は、Google Cloud Platformの機能であり、IDおよびコンテキストベースのアクセス制御を使用してリソースへのアクセスを保護することができます。IAPを使用すると、リソース（ウェブ・アプリケーションなど）へのアクセスを、認証され許可されたユーザーまたはサービス・アカウントのみに制限することができます。
しかし、このシナリオでは、ウェブ・アプリケーションは企業のイントラネット上でホストされているため、パブリックIPアドレスを持たず、インターネットからアクセスすることはできません。また、IAP を使用して、イントラネットでホストされているアプリケーションへのアクセスを、その IP アドレスによって制限することはできません。
D. これらのオプションには、プロキシとして機能するCompute Engineインスタンスを設定し、企業アカウントを通じてユーザーを認証することが含まれます。また、WebアプリケーションをホストするパブリックIPアドレスへのHTTPリダイレクトが含まれるため、従業員のみにアクセスを制限する必要性に合致しない可能性があります。
正解
C. このアプローチでは、Google Cloudのインフラストラクチャを利用して、Webアプリケーションへのアクセスを許可する前に、企業のイントラネットを通じてユーザーを認証することができます。プロキシとして動作するCompute Engineインスタンスを設定し、WebアプリケーションのDNSをこのプロキシを指すように変更することで、Webアプリケーションへのアクセスは、企業イントラネットで認証された従業員のみに制限されます。さらに、この方法では、従業員がインターネットにアクセスできる環境であれば、出張中でもWebアプリケーションにアクセスすることができます。
Links:
https://cloud.google.com/compute/docs

https://cloud.google.com/iam
</div></details>

## Q. 1-3
あなたは、Google Cloud上で実行されるあなたの会社のeコマースプラットフォームの決済システムを管理しています。貴社は、内部監査目的で1年間、コンプライアンス要件を満たすために3年間、ユーザーログを保持する必要があります。オンプレミスのストレージ使用量を削減し、ログを簡単に検索できるようにするために、新しいユーザーログをGoogle Cloudに保存する必要があります。

ログが正しく保存されていることを確認しながら、労力を最小限に抑えるために、どのような行動を取るべきでしょうか？
1. バケットロックをオンにして、ログをクラウドストレージのバケットに保存する。
2. ログをCloud Storageバケットに保存し、保存期間を3年にする。
3. Cloud Loggingに、カスタム保存期間を持つカスタムログとしてログを保存します。
4. 保存期間1年のCloud Storageバケットにログを保存する。1年後、ログを保存期間2年の別のバケットに移動する。
<details><div>
    答え：3
要件では、ログを簡単に検索できるようにする必要があります。これはクラウドストレージでは容易に実現できないため、選択肢A、B、Dは除外されます。
正解
Cloud Loggingは、ログが保存されているログバケットタイプに適用される保持ルールに従ってログを保持します。
Cloud Logging は、ログを 1 日から 365 日の範囲で保持するように構成できます。カスタム保持ルールは、ログタイプやログが別の場所からコピーされたかどうかに関係なく、バケット内のすべてのログに適用されます。
Links:
https://cloud.google.com/logging/docs/buckets#custom-retention

https://cloud.google.com/logging/docs/routing/overview#logs-retention

https://cloud.google.com/logging/docs/audit/best-practices#custom-retention

https://cloud.google.com/logging/docs/central-log-storage
</div></details>

## Q. 1-4
アプリケーションは、Compute Engine上で実行されるコードによってオーケストレーションされた、疎結合のサービス群で構成されています。アプリケーションは、サービスの特定のバージョンを見つけて使用する新しいCompute Engineインスタンスを簡単に起動できるようにしたい。
これはどのように設定すべきでしょうか？
1. 実行時に取得され、目的のサービスに接続するために使用されるメタデータとして、サービス・エンドポイント情報を定義します。
2. 実行時に取得され、目的のサービスに接続するために使用されるラベル・データとして、サービス・エンドポイント情報を定義する。
3. 実行時に環境変数から取得し、目的のサービスに接続するために使用するサービス・エンドポイント情報を定義する。
4. 固定ホスト名とポートを使用して目的のサービスに接続するようにサービスを定義する。エンドポイントのサービスを新しいバージョンに置き換えます。
<details><div>
    答え：1
B. ラベルは通常、実行時の設定ではなく、リソースの整理に使用されます。
C. 環境変数に依存すると、結合が密になり、サービスのバージョンを管理するための柔軟性が得られない可能性がある。
D. 固定のホスト名とポートを使用することは、サービスの異なるバージョンで動作するために必要な柔軟性を提供しない可能性があります。
答え
A. オプションAでは、エンドポイント情報をメタデータとして保存し、実行時にCompute Engineインスタンスから取得することができます。この方法では、インスタンスを変更することなくエンドポイント情報を変更することができるため、疎結合サービスをサポートし、異なるバージョンのサービスを管理するプロセスが容易になります。
Links:

https://cloud.google.com/apis/design/glossary#api_service_endpoint

https://cloud.google.com/compute/docs/metadata/overview

https://cloud.google.com/service-infrastructure/docs/service-metadata/reference/rest#service-endpoint

</div></details>

## Q. 1-5
以下のgcloudコマンドを使用してHTTP(s) Load Balancerをデプロイしました。


Compute Engine仮想マシンインスタンスのポート80へのヘルスチェックが失敗し、インスタンスにトラフィックが送信されません。この問題を解決することが目的です。
1. gcloud compute instances add-access-config ${NAME}-backend-instance-1
2. gcloud compute instances add-tags ${NAME}-backend-instance-1 --tags http-server
3. gcloud compute firewall-rules create allow-lb --network load-balancer --allow tcp --source-ranges 130.211.0.0/22,35.191.0.0/16 --direction INGRESS。
4. gcloud compute firewall-rules create allow-lb --network load-balancer --allow tcp --destination-ranges 130.211.0.0/22,35.191.0.0/16 --direction EGRESS
<details><div>
    答え：3
A. オプションAは、インスタンスに外部IPアドレスを追加するために使用されるため、役に立ちません。
B. Bはインスタンスにタグを追加することに関連するが、対応するファイアウォールルールがなければ、問題は解決しない。このコマンドはインスタンスにメタデータを適用するために使われ、ロードバランサーとは関係ありません。
D. Dは発信(EGRESS)トラフィック用のファイアウォールルールを作成していますが、ここでの問題は着信(INGRESS)のヘルスチェックです。
答え:
このコマンドは、指定されたソース範囲（Googleのロードバランサーがヘルスチェックに使用するIPアドレス範囲）からのポート80の着信TCPトラフィックを許可するファイアウォールルールを作成する。
正しいコマンドは、上記の修正されたオプションに示されているように、TCPポート80を指定する必要があることに注意してください。

Link: https://cloud.google.com/vpc/docs/special-configurations
</div></details>

## Q. 1-6
あなたは他のGoogle Cloudリソースにアクセスするクラウド関数を書きました。あなたは最小特権の原則を使用して環境を保護したいと思います。

どのようなアクションが必要ですか？
1. リソースにアクセスするエディタ権限を持つ新しいサービスアカウントを作成します。デプロイヤーにアクセストークンを取得する権限を与えます。
2. リソースにアクセスするためのカスタムIAMロールを持つ新しいサービスアカウントを作成します。デプロイ先にはアクセストークンを取得する権限が与えられる。
3. リソースにアクセスする編集権限を持つ新しいサービスアカウントを作成する。デプロイ担当者には、新しいサービスアカウントとして行動する権限が与えられます。
4. リソースにアクセスするためのカスタムIAMロールを持つ新しいサービスアカウントを作成します。デプロイ担当者には、新しいサービスアカウントとして行動する権限が与えられます。
<details><div>
    答え：4
A. エディター権限は一般的に、プロジェクト内の多くのリソースやアクションへの広範なアクセスを提供します。Editor権限を与えることで、クラウド機能が実行する特定のタスクに実際に必要な以上の権限を与えている可能性があります。これは最小特権の原則に違反します。
B. このオプションではカスタムIAMロールを作成するため、最小特権の原則に沿う可能性がありますが、デプロイ者に与えられる権限は「アクセストークンを取得する」ことです。これは、デプロイ者がサービスアカウントを "act as "することを許可するよりも安全性が低く、あまり一般的ではありません。慎重に扱わなければ、トークンの誤用につながる可能性がある。
C. 選択肢Aと同様に、この選択肢ではリソースへの広範なアクセスを提供するEditor権限を付与します。この場合も、必要以上の権限を与えることになり、最小権限の原則と矛盾する可能性があります。
正解
D. このオプションは、必要なリソースへのアクセスに必要な権限のみを含むように正確に定義できるカスタムIAMロールを作成することで、最小特権の原則に従います。こうすることで、クラウド機能はセキュリティリスクにつながる不必要なパーミッションを持つことがなくなる。デプロイヤーに新しいサービスアカウントとして動作する権限を与えることで、デプロイ時にクラウド機能がこの役割を引き受けることができます。
他のオプションはより広い権限（Editor権限）を与えるか、役割のカスタム性を強調しない。
Links:

https://cloud.google.com/functions/docs/securing/function-identity

https://cloud.google.com/blog/products/application-development/least-privilege-for-cloud-functions-using-cloud-iam

https://cloud.google.com/functions/docs/securing/function-identity#per-function_identity
</div></details>

## Q. 1-7
あなたは、顧客、注文、在庫データをCloud Spanner内のリレーショナル・テーブルとして格納するeコマース・アプリケーションを開発しています。最近の負荷テスト中に、Spanner のパフォーマンスが期待どおりに線形にスケーリングされていないことがわかりました。

次のうちどれが原因ですか？
1. 32ビットの数値に64ビットの数値型を使用すること。
2. 単調に増加する主キーとしてバージョン1のUUIDを使用すること。
3. STRINGデータ型の任意精度値への使用。
4. パラメータ化されたSQL問い合わせで、STARTS_WITHキーワードの代わりにLIKEを使用すること。
<details><div>
    答え：2
A. ストレージの効率は悪くなるかもしれないが、Spannerのリニアスケーリング機能に大きな影響を与えることはないだろう。
C. 任意精度の値にSTRINGデータ型を使用することは最適な選択ではないかもしれませんが、リニアスケーリングに大きな影響を与えることはないでしょう。
D. これはクエリ・パフォーマンスに影響する可能性がありますが、通常、システム全体の線形スケーリングには影響しません。
正解
B. Cloud Spannerでは、単調に増加するVersion 1 UUIDを主キーとして使用すると、均等に分散されないためパフォーマンスの問題が発生する可能性があります。このため、特定のノードまたはノードの範囲に不釣り合いな数のリクエストが送信されるホットリージョンが発生し、そのノードが過負荷になり、パフォーマンスが低下する可能性があります。パフォーマンスを改善するには、ハッシュベースのキーやランダムな整数など、より均等に分散されたプライマリ・キーの使用を検討すべきである。

Links:

https://cloud.google.com/spanner/docs/schema-and-data-model#choosing_a_primary_key

https://cloud.google.com/spanner/docs/schema-design#primary-key-prevent-hotspots
</div></details>

## Q. 1-8
あなたのチームは、Cloud Identityによって管理されるユーザーIDで実行されるGoogle Cloudアプリケーションを開発しています。アプリケーションの各ユーザは、メッセージが発行される関連する Pub/Sub トピックと、同じユーザが発行されたメッセージを取得する Pub/Sub サブスクリプションを持ちます。

許可されたユーザのみが、特定のPub/Subトピックとサブスクリプションにパブリッシュおよびサブスクライブできるようにする必要があります。
1. ユーザ ID に、pubsub.topics.create および pubsub.subscriptions.create 許可を含むカスタム・ロールを付与する。
2. pubsub.publisherおよびpubsub.subscriberロールを持つサービスアカウントとしてアプリケーションを実行するように構成する。
3. リソース・レベルでユーザ ID を pubsub.publisher および pubsub.subscriber ロールにバインドします。
4. プロジェクトレベルで、ユーザ ID に pubsub.publisher および pubsub.subscriber ロールを付与します。
<details><div>
    答え：3
A. pubsub.topics.create および pubsub.subscriptions.create パーミッションを含むカスタム・ロールをユーザ ID に付与すると、ユーザはトピックおよびサブスクリプションを作成できますが、特定のトピックまたはサブスクリプションへのアクセス権は付与されません。
B. pubsub.publisherロールとpubsub.subscriberロールを持つサービスアカウントとしてアプリケーションを実行するように構成すると、ユーザのきめ細かな権限管理ができません。
D. プロジェクト・レベルでユーザ ID に pubsub.publisher および pubsub.subscriber ロールを付与すると、ユーザはプロジェクト内のすべてのトピックおよびサブスクリプションにアクセスできるようになります。
正解
C. リソースレベルでユーザ ID を pubsub.publisher および pubsub.subscriber ロールにバインドすることで、各ユーザが特定の Pub/Sub トピックおよびサブスクリプションに対してのみパブリッシュおよびサブスクライブできるようにできます。このアプローチにより、きめ細かな権限管理が可能になり、各ユーザが許可されたリソースのみにアクセスできるようになります。
Link:

https://cloud.google.com/pubsub/docs/access-control
</div></details>

## Q. 1-9
最近、アプリケーションに影響する政府規制が可決されました。コンプライアンス目的のために、アプリケーションのプロジェクトからセキュリティチームに限定されたプロジェクトに、特定のアプリケーションログの複製を送信することが要求されるようになりました。

あなたは何をすべきでしょうか？
1. セキュリティチームのプロジェクトにユーザー定義のログバケットを作成する。クラウドロギングシンクを構成して、アプリケーションのログをセキュリティチームのプロジェクト内のログバケットにルーティングする。
2. 必要なログバケツからセキュリティチームのプロジェクトのログバケツにログをコピーするジョブを作成する。
3. デフォルトのログバケツのシンクルールを変更し、ログをセキュリティチームのログバケツに再ルーティングする。
4. 必要なログバケツのシステムイベントログを、セキュリティチームのプロジェクトのログバケツにコピーするジョブを作成する。
<details><div>
    答え：1
オプションB、C、およびDは、最も効果的な解決策ではありません。エラーが発生しやすい手動ジョブ（BとD）を含むか、デフォルトのバケツ（C）を変更するため、この規制の遵守に関連しない他のログに影響を与える可能性があります。
正解
このソリューションは、特定のアプリケーションのログを複製し、セキュリティチームのプロジェクトに送信するための直接的かつ自動化されたソリューションを提供します。この方法は、ログをログバケットや Pub/Sub トピックなどの他の宛先にルーティングするための強力なツールである Cloud Logging のシンク機能を使用します。シンクを使用することで、ログの複製がリアルタイムかつ自動的に実行され、手作業による介入とエラーのリスクを最小限に抑えることができます。

Links:

https://cloud.google.com/architecture/security-log-analytics
</div></details>

## Q. 1-10
あなたのチームはあなたの会社のためにeコマースプラットフォームを開発しています。ユーザーはウェブサイトにログインし、ショッピングカートに商品を追加します。ユーザーは30分間操作しないと自動的にログアウトします。ユーザーが再びログインすると、ショッピングカートが保存されます。

Googleが推奨するベストプラクティスに従い、ユーザーのセッション情報とショッピングカート情報をどのように保存すべきでしょうか？
1. Pub/Subにセッション情報を格納し、Cloud SQLにショッピングカート情報を格納する。
2. クラウドストレージ上のファイルにショッピングカート情報を保存する。
3. セッションとショッピングカートの情報を、複数のCompute Engineインスタンス上で動作するMySQLデータベースに保存します。
4. セッション情報をMemorystore for RedisまたはMemcachedに保存し、ショッピングカート情報をFirestoreに保存します。

<details><div>
    答え：4
A. Pub/Subはイベント・ストリーミングとメッセージング用に設計されており、セッション情報を管理するためのものではありません。Pub/Subにセッションデータを格納することは、効率的でない、あるいは従来のサービスの使い方ではないでしょう。Cloud SQLは完全に管理されたリレーショナルデータベースサービスであり、ショッピングカート情報を格納するために使用できますが、オプションDで述べたようにFirestoreを使用する方が適しています。
B. クラウドストレージのバケットにアクセスすると、セッション情報に対して時間がかかり、コストもかかります。これはGoogle Cloudのベストプラクティスではありません。
C. C. Compute Engineインスタンス間でMySQLデータベースを管理することはできますが、Memorystoreのようなスケーラビリティとセッション情報の低レイテンシアクセスを提供することはできません。これはGoogle Cloudのベストプラクティスではありません。
正解
D. eコマースプラットフォームのセッション情報とショッピングカート情報を保存する場合、スケーラビリティ、信頼性、セキュリティを考慮することが重要です。Googleが推奨するベストプラクティスに従ったソリューションの1つは、セッション情報の保存にMemorystore for RedisまたはMemcachedを使用し、ショッピングカート情報の保存にFirestoreを使用することです。

Memorystoreはセッション情報を保存し、大量の同時接続を簡単に処理することができます。これは、ユーザーが頻繁にログインし、ショッピングカートに商品を追加するeコマースプラットフォームにとって非常に重要です。

Firestoreは、ショッピングカート内のアイテムのような大量の半構造化データを容易に扱うことができます。また、Firestoreはスケーラブルで信頼性の高いソリューションであり、自動スケーリングとレプリケーションをサポートしています。

セッション情報とショッピングカート情報を異なるサービスに分離することで、セキュリティを高め、潜在的なデータ侵害を回避することができます。また、異なるサービスを使用することで、それらを独立して拡張することができます。

このことから、回答Dが最良の選択肢となります。

Links:

https://cloud.google.com/memorystore/docs/redis/redis-overview
</div></details>

## Q. 1-11
POSTで呼び出されるHTTPクラウド関数があります。各サブミッションのリクエストボディには、数値とテキストデータを含むフラットでネストされていない JSON 構造があります。クラウド関数が完了した後、収集されたデータは、多くのユーザーが並行して継続的かつ複雑な分析を行うためにすぐに利用できる必要があります。

どのようにサブミッションを永続化しますか？
1. 各POSTリクエストのJSONデータをDatastoreに直接永続化する。
2. POSTリクエストのJSONデータを変換し、BigQueryにストリームします。
3. POSTリクエストのJSONデータを変換し、地域のCloud SQLクラスタに格納する。
4. 各POSTリクエストのJSONデータを、リクエスト識別子を含むファイル名で、Cloud Storage内に個別のファイルとして永続化する
<details><div>
    答え：2
A. 各POSTリクエストのJSONデータをDatastoreに直接永続化する。DatastoreはNoSQLのドキュメントデータベースであり、構造化されたデータを格納するために使用できますが、ほぼリアルタイムで分析する必要がある大量のデータを処理するようには設計されていません。また、分析に使えるようにするには、追加の処理が必要になる。
C. Cloud SQLはデータの永続性を処理できるが、多数の並列ユーザーを持つ複雑な分析にはBigQueryほど効率的ではないかもしれない。
D. 各 POST リクエストの JSON データを個別のファイルとして Cloud Storage 内に保存することは、即時かつ複雑な分析には非効率的です。
正解
B. BigQueryは拡張性の高いデータウェアハウスであり、大量のデータや複雑な分析をほぼリアルタイムで処理するのに適しています。クラウド機能からのJSONデータを直接BigQueryにストリーミングすることで、収集したデータを即座に多くのユーザーが並行して分析できるようになります。BigQueryはJSONを含む様々なデータ型をサポートしているため、リクエストボディを変換することなく保存できます。
Links:

https://cloud.google.com/bigquery/docs/streaming-data-into-bigquery
</div></details>

## Q. 1-12
あなたは複数のルームをホストし、各ルームのメッセージ履歴を保持するチャットルームアプリケーションを設計しています。あなたはデータベースとしてFirestoreを選択しました。

Firestoreのデータをどのように表現する必要がありますか？



A. ルーム用のコレクションを作成します。各ルームについて、メッセージの内容をリストするドキュメントを作成します。
1. 部屋のコレクションを作成する。各部屋に対して、メッセージの内容をリストしたドキュメントを作成する。
2. 部屋ごとにコレクションを作成する。部屋ごとに、各メッセージのドキュメントを含むコレクションを作成する。
3. 部屋用のコレクションを作成する。各部屋に対して、ドキュメント用のコレクションを含むドキュメントを作成し、各ドキュメントにはメッセージが含まれます。
4. 部屋用のコレクションを作成し、各部屋用のドキュメントを作成する。メッセージ用に別のコレクションを作成し、メッセージごとに1つのドキュメントを作成します。各部屋のドキュメントには、メッセージへの参照のリストが含まれます。
<details><div>
    答え：3
A. この方法は、各部屋のメッセージ数が多い場合、全てのメッセージを一つのドキュメントに収めようとするため、うまく拡張できません。
B. 部屋用のコレクションは、それぞれメッセージのサブコレクションを持ち、多対多のリレーションシップを作成します。
D. このアプローチでは、部屋とメッセージを異なるコレクションに分離しますが、それらの間の参照を維持する必要があります。
正解
C. このシナリオでメッセージを格納する最善の方法は、サブコレクションを使用することです。サブコレクションは、特定のドキュメントに関連付けられたコレクションです。
Links:

https://firebase.google.com/docs/firestore/data-model#hierarchical-data

https://firebase.google.com/docs/firestore/data-model#subcollections
</div></details>

## Q. 1-13
本番環境にデプロイされたアプリケーションがあります。新しいバージョンがデプロイされたとき、いくつかの問題は、アプリケーションが本番環境のユーザからトラフィックを受けるまで発生しません。影響と影響を受けるユーザ数の両方を減らしたい。

どのデプロイメント戦略を使用すべきですか?
1. ブルー／グリーン・デプロイメント
2. カナリア展開
3. ローリングデプロイメント
4. デプロイメントの再作成
<details><div>
    答え：2
A. このアプローチでは、2つの別々の環境（実行中のバージョンはブルー、新しいバージョンはグリーン）を切り替えることができます。全員にロールアウトする前に、問題を検出するために一部のユーザーでテストすることは特にできません。
C. ローリング デプロイメントでは、インスタンスを次々に段階的に更新します。段階的なロールアウトが可能ですが、Canaryデプロイメントのように特定のユーザ サブセットを対象としていないため、ユーザ固有の問題を検出するのには適していません。
D. この方法では、古いバージョンを削除し、新しいバージョンをデプロイする。すべてのインスタンスが同時に置き換えられるため、影響を軽減し、ユーザーのサブセットでテストするという要件には適合しません。
正解
B. カナリア配置では、新バージョンを少人数のユーザに徐々にリリースしてから、すべてのユーザに使用できるようにします。これにより、本番環境の実際のユーザーで新バージョンの動作をテストできますが、対象者が限定されるため、潜在的な問題の影響と影響を受けるユーザー数の両方を減らすことができます。これは、説明した状況に適しています。
Links:

https://cloud.google.com/architecture/application-deployment-and-testing-strategies#canary_test_pattern
</div></details>

## Q. 1-14
Stackdriver Logging Agentを使用して、アプリケーションのログファイルをCompute Engine仮想マシンインスタンスからStackdriverに送信したいとします。
Stackdriver Logging Agentをインストールした後、最初に何をすべきですか？
1. プロジェクトのエラー報告APIを有効にする。
2. インスタンスにすべてのクラウドAPIへのフルアクセスを許可する。
3. アプリケーションログファイルをカスタムソースとして設定します。
4. アプリケーションのログエントリに一致するフィルタを使用して、Stackdriver ログエクスポートシンクを作成します。
<details><div>
    答え：3
A. これはコンテキストによっては便利ですが、Stackdriver にログを送信するためのロギングエージェントをインストールした直後のステップではありません。
B. すべてのクラウドAPIへのフルアクセスを許可するのは過剰であり、Stackdriverにログを送信するために必要ではない。ロギングに関連する特定のパーミッションが必要ですが、通常これらはインスタンスに関連するサービスアカウントに割り当てられたロールとパーミッションによって管理されます。
D. シンクを使用してログをエクスポートすることは、ログを異なる宛先（BigQuery、Pub/Sub など）にルーティングする方法であり、特定のアプリケーションログファイルからログを収集するためにエージェントを設定するタスクとは関係ありません。
正解
C. これは正しい次のステップです。ログファイルをカスタムソースとして構成することで、エージェントはログを探す場所と処理方法を知ることができます。したがって、オプション C は、Stackdriver Logging Agent をインストールした後に実行する最も適切なステップです。
Links:

https://cloud.google.com/logging/docs/agent/configuration

https://cloud.google.com/logging/docs/agent/configuration#streaming_logs_from_additional_inputs
</div></details>

## Q. 1-15
あなたの会社には「Master」という名前のBigQueryデータセットがあり、そこには従業員の部署別に整理された、従業員の出張と経費に関する情報が含まれています。従業員は各部門の情報しか閲覧できないようにする必要があるため、セキュリティフレームワークを適用して、最小限のステップ数でこの要件を実施したいとします。

どうすればよいでしょうか。
1. 部門ごとに個別のデータセットを作成する。適切なWHERE句を指定してビューを作成し、特定の部門の特定のデータセットからレコードを選択する。このビューに、マスターデータセットからレコードにアクセスする権限を与える。従業員にこの部門別データセットへのアクセス権限を与える。
2. 部門ごとに個別のデータセットを作成する。部門ごとにデータパイプラインを作成し、マスターデータセットから部門固有のデータセットに適切な情報をコピーする。従業員にこの部門別データセットへのアクセス権を与える。
3. マスター」データセットという名前のデータセットを作成する。マスターデータセットの中に、部署ごとに個別のビューを作成する。従業員に、所属する部署に特化したビューへのアクセス権を与える。
4. マスター・データセットという名前のデータセットを作成する。マスター・データセットの中に、部門ごとに個別のテーブルを作成する。従業員には、所属する部門のテーブルにアクセスできるようにする。
<details><div>
    答え：3
A.この方法では、データセットとビューを別々に作成し、適切なアクセス制御を行います。柔軟なアプローチですが、特に基礎となるデータ構造が変更された場合、管理が複雑になる可能性があります。
B.オプションAと同様に、部署ごとに個別のデータセットを作成する。データパイプラインの使用は複雑さを増し、データが重複することで整合性に問題が生じる可能性がある。
D.この方法では、「マスター」データセット内に個別のテーブルを作成する。オプションCと同様に、すべてを単一のデータセット内に保持しますが、テーブルごとのアクセス制御をより慎重に管理する必要があります。
正解
C.この方法では、既存の「マスター」データセットの中にビューを作成し、部門ごとのニーズに合わせてアクセスできるようにします。実装と管理が最も簡単で、セキュリティと使いやすさのバランスがよく、ステップ数も最小限で済む。
Links:

https://cloud.google.com/bigquery/docs/share-access-views
</div></details>

## Q. 1-16
あなたのチームは、クラウドストレージイベントをトリガーとするクラウド機能を開発しています。Googleが推奨するベストプラクティスに従いつつ、クラウド機能のテストと開発を加速したい。

どうすればよいでしょうか？
1. クラウド監査ログが元のクラウド関数のcloudfunctions.functions.sourceCodeSet操作を検出したときにトリガされる新しいクラウド関数を作成します。新しい関数にモック要求を送信して、機能を評価します。
2. クラウド関数のコピーを作成し、HTTPトリガーになるようにコードを書き換えます。新しいバージョンを編集し、HTTPエンドポイントをトリガーしてテストする。新しい関数にモックリクエストを送り、機能を評価する。
3. Functions Frameworksライブラリをインストールし、localhost上でCloud Functionを構成します。関数のコピーを作成し、新しいバージョンに編集します。curlを使用して新しいバージョンをテストします。
4. Google CloudコンソールでCloud Functionのコピーを作成する。クラウド コンソールのインライン エディタを使用して、新しい関数にソース コードを変更します。新しい関数を呼び出すように Web アプリケーションを変更し、新しいバージョンを実運用環境でテストします。
<details><div>
    答え：3
不正解
A. 特定の操作でトリガーされる新しいクラウド関数を作成することは、元の関数をテストする間接的な方法であり、この目的には効率的でないかもしれません。
B. クラウド関数のコピーを作成し、HTTPトリガーに書き換えることで、テストにHTTPリクエストを使用できます。ただし、この方法では元のクラウド ストレージ イベント動作を複製するための追加作業が必要になる場合があります。
D. Google Cloud コンソールでクラウド関数のコピーを作成し、新しいバージョンを本番環境でテストすることは、テストと開発のベストプラクティスに合致しません。本番環境にエラーをもたらすリスクがあります。
正解
C. Functions Frameworks ライブラリを使用すると、Cloud Function をローカルで実行してテストすることができ、実際の Cloud Function ランタイムに似た環境を提供できます。関数に変更を加え、curl などのツールを使用してテストできるので、開発サイクルを短縮できます。
Links:

https://cloud.google.com/functions/docs/running/calling#cloudevent_functions

https://cloud.google.com/functions/docs/running/overview#choosing_an_abstraction_layer
</div></details>

## Q. 1-17
あなたは、Cloud RunとFirestoreのDatastoreモードで動作する新しい小売システムの開発リーダーです。Web UI の要件は、ユーザーがシステムにアクセスしたときに利用可能な商品のリストを表示し、ユーザーがすべての商品を閲覧できることです。この要件は、最小実行可能製品（MVP）の段階で、Firestoreに格納されているすべての利用可能な製品のリストを返すことによって実装されました。



本稼働から数カ月後、Cloud Run インスタンスが HTTP 500 で終了していることに気づきました： Container instances are exceeding memory limits エラーで終了することに気づきました。このエラーは、データストア・エンティティの読み取り数の急増と一致します。Cloud Runのクラッシュを防ぎ、Datastoreエンティティの読み取り回数を減らす必要があります。システムパフォーマンスを最適化するソリューションを使用したい。

どうすればよいでしょうか？
1. 整数オフセットを使用して商品リストを返すクエリを修正してください。
2. 制限を使用して、商品リストを返すクエリを変更します。
3. Cloud Runの設定を変更してメモリ制限を増やす。
4. カーソルを使用して商品リストを返すクエリを修正します。
<details><div>
    答え：4
不正解
A. データ・ストア・モードのデータベースは整数オフセットをサポートしていますが、オフセットの使用は避けて、代わりにカーソルを使用してください。オフセットを使用すると、アプリケーションにスキップされたエンティティを返さずに済みますが、これらのエンティティは内部的に取得されます。これらのスキップされたエンティティはクエリの待ち時間に影響し、アプリケーションはそれらを取得するために必要な読み取り操作に対して課金されます。オフセットの代わりにカーソルを使用することで、これらのコストを全て回避することができます。
B. クエリで制限を使用すると、1回の応答で返される結果の数が制限されますが、複数の要求間の状態は管理されません。そのため、多くの商品があり、ユーザーがそれらすべてを閲覧できるようにしたい場合、単に結果を制限するだけでは、リスト全体を効率的にページ分割する方法は提供されません。それぞれの新しいリクエストは最初から始まり、最後のリクエストの続きから続ける効率的な方法はありません。
C. クラウド・ラン・インスタンスのメモリ制限を増やすことで、この問題を一時的に軽減することはできますが、問題の根本的な原因（ビジー時のデータストア・エンティティの読み取り数の多さ）には対処できません。時間が経つにつれて、より多くの製品がシステムに追加されるにつれて、この問題はより深刻になり、Cloud Runがクラッシュするのを防ぐためにメモリ制限を継続的に増やす必要があります。
正解
D. カーソルを使用して結果をページ分割し、一度に限られた数の製品を取得することは、より持続可能なソリューションを提供します。データストアから読み込む必要があるデータ量を減らし、Cloud Runインスタンスのメモリ使用量を減らします。このようにして、システムのパフォーマンスを維持し、時間の経過とともに製品が追加されてもクラッシュするのを防ぐことができます。
Links:

https://cloud.google.com/datastore/docs/concepts/queries#cursors
</div></details>

## Q. 1-18
貴社は新しいAPIをCompute Engineインスタンスにデプロイしました。テスト中、APIが期待通りに動作しません。アプリケーションを再デプロイすることなく、アプリケーションコード内の問題を診断するために、12時間にわたってアプリケーションを監視したい。

どのツールを使用すべきでしょうか？
1. クラウドトレース
2. クラウド監視
3. クラウドデバッガーのログポイント
4. クラウド・デバッガ・スナップショット
<details><div>
    答え：3
A. レイテンシの分析に重点を置いており、再デプロイせずにアプリケーションコード内の問題を診断することに特化して設計されていないため、質問の要件を満たしていない。
B. システムのパフォーマンスを監視するのに便利ですが、シナリオが求めている、ログステートメントを挿入したり、再デプロイせずにアプリケーションコードの動作を分析したりすることはできません。
D. スナップショットは、12時間にわたって監視するよりも、特定の時点でのアプリケーションの状態を分析するのに適しています。このシナリオにはあまり適していません。
正解
C. アプリケーションをデプロイまたは起動した後、Google Cloud コンソールで Cloud Debugger を開くことができます。Cloud Debugger Logpoints を使用すると、サービスの通常の機能を再起動または妨害することなく、実行中のサービスにロギングを注入できます。これは、ログステートメントを追加して再デプロイすることなく、運用上の問題をデバッグするのに便利です。
Link: https://cloud.google.com/debugger/docs/using/logpoints
</div></details>

## Q. 1-19
御社の開発チームは、プロジェクトでCloud Buildを使用してDockerイメージをビルドし、Container Registryにプッシュしたいと考えています。運用チームは、すべてのDockerイメージを、運用チームが管理する一元化された安全に管理されたDockerレジストリに公開する必要があります。

どうすればいいでしょうか？
1. Container Registryを使用して、各開発チームのプロジェクトにレジストリを作成します。プロジェクトのレジストリにDockerイメージをプッシュするようにCloud Buildビルドを構成します。運用チームに各開発チームのレジストリへのアクセス権を付与します。
2. Container Registryを設定した運用チーム用の別のプロジェクトを作成します。各開発チームのプロジェクトのCloud Buildサービスアカウントに適切な権限を割り当て、運用チームのレジストリへのアクセスを許可する。
3. Container Registryを設定した運用チーム用の別のプロジェクトを作成します。各開発チームにサービスアカウントを作成し、運用チームのレジストリへのアクセスを許可する適切な権限を割り当てます。サービスアカウントのキーファイルをソースコードリポジトリに格納し、運用チームのレジストリに対する認証に使用します。
4. Compute Engineの仮想マシンインスタンス上にオープンソースのDockerレジストリをデプロイした、運用チーム用の別のプロジェクトを作成します。開発チームごとにユーザー名とパスワードを作成します。ユーザー名とパスワードをソースコードリポジトリに保存し、運用チームのDockerレジストリに対する認証に使用する。

<details><div>
    答え：2
不正解
オプションA：運用チームに各開発チームのレジストリへのアクセスを許可する必要があり、安全でない可能性があるため、理想的ではありません。
オプションC：サービスアカウントのキーファイルをソースコードリポジトリに保存する必要があり、安全でない可能性があるため、最適な選択ではない。
オプションD：オープンソースのDockerレジストリを使用し、各開発チームのユーザー名とパスワードを作成する必要があるため、これは最良の選択ではありません。
正解
Bは、運用チームが集中管理され安全に管理されたDockerレジストリを制御できる一方で、開発チームがプロジェクトでCloud Buildを使用できるようになるため、最良の選択です。このオプションでは、運用チームはContainer Registryが設定された別のプロジェクトを作成し、各開発チームのプロジェクトでCloud Buildサービスアカウントに適切な権限を付与して、運用チームのレジストリへのアクセスを許可することができます。このアプローチにより、開発チームは運用チームの要件を順守しながら、Dockerイメージをビルドして集中レジストリにプッシュすることができます。
Links:

https://cloud.google.com/container-registry/

https://stackoverflow.com/questions/48602546/google-cloud-functions-how-to-securely-store-service-account-private-key-when
</div></details>

## Q. 1-20
アプリケーションは複数のGoogle Kubernetes Engineクラスタで実行されている。各クラスタの Deployment によって管理されています。Deploymentは各クラスタにPodの複数のレプリカを作成しています。あなたは、すべてのクラスタのあなたのDeployment内のすべてのレプリカの標準出力に送信されたログを表示したいと思います。

どのコマンドを使用する必要がありますか?
1. kubectl logs [PARAM].
2. gcloud logging read [PARAM].
3. kubectl exec -it [PARAM] journalctl
4. gcloud compute ssh [PARAM] --command='sudo journalctl' 
<details><div>
    答え：2
不正解
A. すべてのクラスタのすべてのレプリカのログを表示する機能はありません。
C. は特定のPod内でコマンドを実行するために使用され、Deployment内のすべてのレプリカからログを取得するために使用されるわけではありません。
D. は、Compute EngineインスタンスにSSH接続してコマンドを実行するために使用され、GKEデプロイメントからログを取得するために使用されません。
正解
https://cloud.google.com/blog/products/management-tools/using-logging-your-apps-running-kubernetes-engine: "gcloud コマンドラインツール - gcloud logging read コマンドを使用して、適切なクラスタ、ノード、ポッド、およびコンテナのログを選択します。"
Links:

https://cloud.google.com/logging/docs/reference/tools/gcloud-logging#examples_2

https://cloud.google.com/blog/products/management-tools/using-logging-your-apps-running-kubernetes-engine

https://stackoverflow.com/questions/62007471/how-to-view-container-logs-via-stackdriver-on-gke
</div></details>

## Q. 1-21
あなたは最近新しいアプリケーションを開発し、Dockerfileを使わずにCloud Run上にデプロイしたいと考えています。

すべてのコンテナイメージは一元管理されたコンテナリポジトリにプッシュされなければならないという組織の要件を考慮すると、Google Cloudサービスを使ってどのようにコンテナを構築すべきでしょうか？(2つの選択肢を選んでください)
1. ソースコードをArtifact Registryにプッシュします。
2. イメージをプッシュするためにクラウドビルドジョブを送信します。
3. pack CLIでpack buildコマンドを使用します。
4. gcloud run deploy CLIコマンドに-sourceフラグを含める。
5. gcloud run deploy CLIコマンドに--platform=kubernetesフラグを含める。
<details><div>
    答え：3,4
不正解
選択肢A：Artifact Registryはソースコードではなくコンテナイメージ用に設計されているため、不正解です。
選択肢B：ビルドされたイメージのみをCloud Runにデプロイする必要があるため、不正解です。一元管理されたコンテナリポジトリ」はGoogleの外部にある可能性があるため、ビルドツールは必ずしもCloud Buildとは限らない。
オプション E：Kubernetes（K8S）は設問に関係ないので、この場合は関係ありません。
正解
オプション C：Google Cloud は buildpacks をサポートしています。これは、Dockerfile を必要とせず、ソース コードから安全で本番環境に適したコンテナ イメージを迅速かつ容易に作成するオープン ソース テクノロジーです。https://cloud.google.com/blog/products/containers-kubernetes/google-cloud-now-supports-buildpacks

オプションD：ソースコードからのデプロイはCloud Runで可能です。単一のgcloud CLIコマンド、gcloud run deploy、-sourceフラグを使用して、ソースコードから新しいサービスや新しいリビジョンを直接デプロイできます。

Links:

https://cloud.google.com/run/docs/deploying-source-code

https://cloud.google.com/blog/products/containers-kubernetes/google-cloud-now-supports-buildpacks
</div></details>

## Q. 1-22
あなたは最近Cloud Runで新しいサービスを開発しました。新しいサービスはカスタムサービスを使用して認証し、トランザクション情報をCloud Spannerデータベースに書き込みます。発生する可能性のあるボトルネックを特定しながら、アプリケーションが1秒あたり最大5,000の読み取りトランザクションと1,000の書き込みトランザクションをサポートできることを検証する必要があります。また、テストインフラはオートスケールできなければなりません。

どうすればよいでしょうか？
1. リクエストを生成するテストハーネスを構築し、Cloud Runにデプロイします。クラウドロギングを使用してVPCフローログを分析します。
2. 負荷テストを動的に生成するために、LocustまたはJMeterイメージを実行しているGoogle Kubernetes Engineクラスタを作成します。Cloud Traceを使用して結果を分析します。
3. テスト負荷を生成するためにクラウドタスクを作成します。Cloud Schedulerを使用して、毎分60,000のCloud Taskトランザクションを10分間実行します。Cloud Monitoringを使用して結果を分析します。
4. マーケットプレイスからLAMPスタックイメージを使用するCompute Engineインスタンスを作成し、Apache Benchを使用してサービスに対する負荷テストを生成する。Cloud Traceを使って結果を分析する。
<details><div>
    答え：2
不正解
A. テストハーネスをCloud Runにデプロイすることは、負荷テストにとって理想的なアプローチではありません。また、VPCフローログは、アプリケーションのパフォーマンス分析よりもむしろネットワークのモニタリングに適しています。
C. Cloud TaskとCloud Schedulerを使用すると、特に異なるシナリオをテストするために負荷を動的に変化させる必要がある場合、1秒間に必要な読み取りと書き込みのトランザクション数をシミュレートするには柔軟性に欠ける可能性があります。
D. Apache Benchを使用する単一のCompute Engineインスタンスでは、必要な1秒あたりのトランザクション数に達するのに十分な負荷を生成できない可能性があります。さらに、マーケットプレイスからのLAMPスタックイメージは、Cloud Runサービスのテストの要件とは無関係です。
正解
B. アプリケーションが1秒あたり最大5,000の読み取りトランザクションと1,000の書き込みトランザクションをサポートできることを確認し、発生する可能性のあるボトルネックを特定するには、LocustやJMeterなどの負荷テストツールを使用してCloud Runサービスの負荷テストを生成します。これらのツールを使用すると、多数の同時リクエストをシミュレートすることができ、サービスが処理できる最大リクエスト数を決定するのに役立ちます。

負荷テストツールをGoogle Kubernetes Engine (GKE)クラスタ上で実行することで、オートスケール機能を提供することができます。こうすることで、大量のリクエストを管理し、Cloud Traceを使って結果を分析することができる。この分析により、パフォーマンスに関する洞察が得られ、ボトルネックの特定に役立つ。
Links:

https://cloud.google.com/architecture/distributed-load-testing-using-gke
</div></details>

## Q. 1-23
あなたは、ユーザーに静的コンテンツを提供する、高可用性でグローバルにアクセス可能なアプリケーションを構築しています。ストレージとサービング・コンポーネントを構成する必要があります。管理オーバーヘッドとレイテンシを最小限に抑えつつ、ユーザーの信頼性を最大化したい。

どうすればよいでしょうか。
1. 
2. 
3. 
4. ① Standardストレージクラスで、マルチリージョンのCloud Storageバケットを作成します。静的コンテンツをバケットに入れます。② 外部IPアドレスを予約し、外部HTTP(S)ロードバランサーを作成する。③ Cloud CDNを有効にし、バックエンドバケットにトラフィックを送る。
<details><div>
    答え：4
正解
オプションAおよびオプションB：インスタンスグループ（管理対象か非管理対象かにかかわらず）に依存すると、VM間で静的コンテンツを複製して維持するために、より多くの管理オーバーヘッドが必要になります。また、提供された問題ではスケーリングは必要ありません。
選択肢C：リージョナルバケットを使用すると、データがリージョン内の2つの特定の場所に制限されるため、世界中のユーザーに対するグローバルなアクセシビリティと低レイテンシが保証されません。
正解
オプション D.
1. Standardストレージクラスで、マルチリージョンのCloud Storageバケットを作成します。静的コンテンツをバケットに入れます。
2. 外部IPアドレスを予約し、外部HTTP(S)ロードバランサーを作成する。
3. Cloud CDNを有効にし、バックエンドバケットにトラフィックを送る。
静的コンテンツをグローバルに、レイテンシと管理オーバーヘッドを最小限に抑えて配信するには、マルチリージョンのCloud StorageバケットのようにGoogle Cloudのグローバル分散システムを活用し、Cloud CDNでキャッシュするのが最適なソリューションです。オプションDが最良の選択である理由は以下の通りです：
* マルチリージョンのバケットは、コンテンツが複数のリージョンに冗長的に保存されることを保証し、高可用性と低レイテンシーでのグローバルアクセスを提供します。
* 外部のHTTP(S)ロードバランサーは、ユーザーのリクエストを最も近いグローバルロケーションに自動的にルーティングする。
* Cloud CDNは、Googleの高度に分散されたエッジキャッシングを活用し、エンドユーザーの待ち時間を最小限に抑えます。
Links:

https://cloud.google.com/storage/docs/hosting-static-website

https://cloud.google.com/load-balancing/docs/https
</div></details>

## Q. 1-24
オンプレミスのLinux仮想マシン（VM）で稼働しているスタンドアロンJavaアプリケーションを、費用対効果の高い方法でGoogle Cloudに移行する必要があります。リフト・アンド・シフトのアプローチはとらず、コンテナに変換してアプリケーションを最新化することにしました。

このタスクをどのように達成すべきでしょうか。
1. Migrate for Anthosを使用して、VMをコンテナとしてGoogle Kubernetes Engine（GKE）クラスタに移行します。
2. VM を raw ディスクとしてエクスポートし、イメージとしてインポートします。インポートしたイメージからCompute Engineインスタンスを作成します。
3. Migrate for Compute Engineを使用してVMをCompute Engineインスタンスにマイグレートし、Cloud Buildを使用してコンテナに変換する。
4. Jibを使用してソースコードからDockerイメージを構築し、Artifact Registryにアップロードします。アプリケーションをGKEクラスタにデプロイし、アプリケーションをテストします。
<details><div>
    答え：4
不正解
Migrate for Anthosを使用するオプションAは、VMをGKEに移行しますが、これはリフト・アンド・シフトのアプローチであり、必ずしもアプリケーションの近代化を伴うものではありません。

オプションBは、VMをRAWディスクとしてエクスポートし、イメージとしてインポートするもので、コンテナ化を伴わず、VMをクラウドに複製することに関連します。

Migrate for Compute Engineを使用してVMをCompute Engineに移行し、Cloud Buildを使用するオプションCは、コンテナ化されたソリューションにつながるかもしれませんが、指定されたタスクにとって必要以上に複雑です。
正解
Jibを使用してソースコードからDockerイメージを構築するオプションDは、ソースコードから直接コンテナ化されたイメージを構築することで、より現代的なアプローチを可能にします。また、GKEでのデプロイも含まれており、コンテナベースのアーキテクチャに移行するという目標に合致しています。Jibは、Javaコンテナ・イメージを構築するために特別に設計されたMaven/Gradleプラグインであり、このJavaアプリケーションの移行に適した選択肢となっている。

指定されたシナリオでは、VMを単に持ち上げて移行するのではなく、コンテナに変換することでアプリケーションを最新化することが目標であるため、オプションDが最も適切なアプローチとなります。
Links:

https://cloud.google.com/blog/products/application-development/introducing-jib-build-java-docker-images-better
</div></details>

## Q. 1-25
Compute Engineにアプリケーションをデプロイしています。Compute Engineインスタンスの1つが起動に失敗しました。

あなたは何をすべきですか？(2つのオプションを選択してください)
1. ファイルシステムが壊れているかどうかを判断します。
2. 別のSSHユーザーとしてCompute Engineにアクセスします。
3. インスタンスのファイアウォールルールまたはルートをトラブルシューティングします。
4. インスタンスのブートディスクが完全に一杯になっていないか確認してください。
5. インスタンスへの、またはインスタンスからのネットワークトラフィックがドロップされていないかチェックする。
<details><div>
    答え：1,4
不正解：
オプションAは文脈によっては関連するかもしれませんが、インスタンスの起動に失敗する原因である可能性は低いです。
オプションBは、SSHユーザーが起動プロセスに影響を与えることはないため、インスタンスの起動失敗を解決する可能性は低い。
オプションEは、起動そのものというよりも、起動後のネットワーク通信に関連しています。
正解です：

Links:

https://cloud.google.com/compute/docs/troubleshooting/vm-startup
</div></details>

## Q. 1-26
500 MB のファイル サイズ制限がある内部ファイル アップロード API を App Engine に移行する必要があります。

どうすればよいでしょうか。
1. FTPを使用してファイルをアップロードします。
2. CPanelを使用してファイルをアップロードします。
3. 署名付きURLを使用してファイルをアップロードする。
4. APIをマルチパートのファイルアップロードAPIに変更する。
<details><div>
    答え：3
不正解
オプションA（FTP）は、App Engineのようなクラウド環境における一般的なプラクティスに合致しません。
オプションB（CPanel）は、プログラムでファイルアップロードを処理することとは関係ありません。
オプションD（マルチパートファイルアップロードAPI）は可能な解決策かもしれませんが、特に指定されたファイルサイズ制限やApp Engine環境に対応していません。
正解
署名付きURLを使用してファイルをアップロードするオプションCは、これらの選択肢の中で最良のアプローチです。署名付きURLは、特に大きなファイルを扱う場合に、ファイルアップロードを安全かつ効率的に処理する方法を提供します。これにより、特定のクラウドリソース（この場合はファイルをアップロードする機能）への一時的なアクセスをユーザーに与えることができます。Google Cloud Storageは署名付きURLをサポートしており、App Engineと組み合わせてファイルアップロードを処理できます。署名付きURLを作成することで、App Engineサーバーでファイルを処理することなく、クライアントがCloud Storageのバケットに直接ファイルをアップロードすることを許可できます。

したがって、正解は C
Links:

https://cloud.google.com/storage/docs/access-control/signed-urls

https://cloud.google.com/appengine/docs/standard/php/googlestorage/user_upload
</div></details>

## Q. 1-27
アプリケーションは Stackdriver にログを記録している。すべての /api/alpha/* エンドポイント上のすべてのリクエストのカウントを取得したい。

どうすればいいでしょうか？
1. path:/api/alpha/のStackdriverカウンタ・メトリックを追加します。
2. endpoint:/api/alpha/*のStackdriverカウンタ・メトリックを追加します。
3. ログをクラウドストレージにエクスポートし、/api/alphaに一致する行を数えます。
4. ログをCloud Pub/Subにエクスポートし、/api/alphaに一致する行をカウントする。
<details><div>
    答え：2
不正解
A. このオプションは、ワイルドカード文字を使用せずに特定のパスを参照するため、意図したとおりに動作しない可能性があります。
C. ログをクラウドストレージにエクスポートして行数をカウントすることは、これを達成するための非効率的な方法であり、オペレーションスイートのリアルタイムの監視およびアラート機能を活用することはできない。
D. ログをCloud Pub/Subにエクスポートして行数をカウントすることは、同様に非効率的であり、オペレーション・スイート内で利用可能なツールをフルに活用できません。
正解
B. オプションBは、指定されたエンドポイントに対する要求のカウントを取得するためにGoogle Cloud Loggingでカウンターメトリックを作成するための正しい答えです。

Links:

https://cloud.google.com/logging/docs/logs-based-metrics/counter-metrics#console
</div></details>

## Q. 1-28
Google Kubernetes Engine（GKE）にデプロイメントを設定する必要がある。コンテナがデータベースに接続できることを確認するチェックを含めたい。Podが接続に失敗した場合、コンテナ上でスクリプトを実行し、グレースフル・シャットダウンを完了させたい。

デプロイはどのように構成すればよいですか？
1. 1つはコンテナがデータベースに接続できるかどうかをチェックするジョブ、もう1つはPodが失敗している場合にシャットダウンスクリプトを実行するジョブです。
2. コンテナがデータベースに接続できない場合に失敗する、コンテナ用の livenessProbe を含む配置を作成します。コンテナが失敗している場合にシャットダウンスクリプトを実行する Prestop ライフサイクルハンドラを構成します。
3. サービスの可用性をチェックするPostStartライフサイクル・ハンドラを使用してデプロイメントを作成します。コンテナに障害が発生した場合にシャットダウンスクリプトを実行するPreStopライフサイクルハンドラを構成する。
4. サービスの可用性をチェックする initContainer を使用して配置を作成します。Pod に障害が発生した場合にシャットダウン スクリプトを実行する Prestop ライフサイクル ハンドラを構成します。
<details><div>
    答え：2
不正解
A. ジョブは通常バッチ処理に使用され、継続的な監視や実行中のコンテナのグレースフル・シャットダウンの処理には適していません。
C. PostStart ハンドラーは、コンテナの起動直後に 1 回だけ実行され、データベースへの接続を継続的に監視することはない。また、条件（たとえば、ライブネス・プローブの失敗）なしで PreStop ハンドラを構成することは、コンテナが失敗している場合にのみシャットダウン・スクリプトを実行する必要性に合致しない。
D. そのため、initContainer を使用すると、コンテナの実行後にデータベース接続を継続的に監視できなくなります。また、Podが初期化された後に失敗している場合にスクリプトを実行するという要件にも合致しません。
正解
B. コンテナがデータベースに接続できない場合に失敗するコンテナ用の livenessProbe を使用して、配置を作成します。liveness probeを利用することで、Kubernetesはデータベースへの接続を継続的にチェックできる。コンテナがデータベースへの接続に失敗すると、livenessプローブが失敗し、Kubernetesがコンテナを再起動するトリガーとなる。

コンテナが失敗している場合にシャットダウンスクリプトを実行するPreStopライフサイクルハンドラを設定する。Kubernetesのドキュメントによると、PreStopフックは、APIリクエスト、livenessプローブの失敗、その他の管理イベントなど、さまざまな理由でコンテナが終了する直前に呼び出される。PreStopフックは、Google Cloudのベストプラクティスで言及されているように、アプリケーションを修正せずにグレースフル・シャットダウンをトリガーするための良い選択肢です。 このフックは、コンテナを停止するTERMシグナルを送信する前に完了する必要があります。Podの終了猶予期間のカウントダウンは、PreStopフックが実行される前に始まるため、ハンドラの結果にかかわらず、コンテナは最終的にPodの終了猶予期間内に終了します。

これら2つの機能を組み合わせることで、コンテナがデータベースへの接続性を継続的に監視し、コンテナに障害が発生した場合にグレースフル・シャットダウンスクリプトが実行されるようにすることができます。
Links:

https://cloud.google.com/architecture/best-practices-for-running-cost-effective-kubernetes-applications-on-gke#make_sure_your_applications_are_shutting_down_in_accordance_with_kubernetes_expectations



https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#hook-details
</div></details>

## Q. 1-29
アプリケーションを、Stackdriver Monitoring AgentがインストールされたCompute Engine仮想マシンインスタンスにデプロイしています。アプリケーションはインスタンス上のunixプロセスです。unixプロセスが少なくとも5分間実行されなかった場合、アラートが必要です。メトリクスやログを生成するようにアプリケーションを変更することはできません。

どのアラート条件を構成しますか?
1. アップタイム・チェック
2. プロセスの健全性（Process health）
3. メトリックの不在（Metric absence）
4. メトリックしきい値（Metric threshold）
<details><div>
    答え：2
不正解
A. これは、マシン上の特定のプロセスではなく、Webサーバなどのネットワーク・エンドポイントの可用性を監視するために使用されます。
C. これは、プロセスの不在ではなく、特定のメトリックのデータの不在を指す。これはより複雑なシナリオで使用されるかもしれないが、プロセスの健全性を監視するようには直接設計されていない。
D. これは、特定のメトリック値が特定のしきい値を超えたことに基づいてアラートを設定することができますが、特定のプロセスが実行されているかどうかをチェックするようには設計されていません。
正解
B. 説明するシナリオでは、特定のUnixプロセスを監視し、そのプロセスが少なくとも5分間実行されていない場合にアラートを出したいとします。プロセスの有無を監視しているので、適切なアラート条件はプロセスの健全性です。

Stackdriverモニタリング・エージェントは、システムとプロセスのメトリクスを監視することができ、このタイプのアラートは、特にUnixプロセスの健全性を追跡します。

Links:

Behavior of metric-based alerting policies | Cloud Monitoring
</div></details>

## Q. 1-30
貴社は新しい API を App Engine Standard 環境にデプロイしました。テスト中、API が期待どおりに動作しません。アプリケーションを再デプロイすることなく、アプリケーション コード内の問題を診断するために、アプリケーションを長期にわたって監視したいとします。

どのツールを使用すべきでしょうか?
1. スタックドライバートレース
2. スタックドライバ・モニタリング
3. Stackdriver デバッグ・スナップショット
4. スタックドライバ・デバッグ・ログポイント
<details><div>
    答え：4
不正解
A. Stackdriver Trace は、リクエストがアプリケーションをどのように伝搬するかを分析し、これらのリクエストの待ち時間を測定するために使用されます。アプリケーションコード内の問題の診断に直接焦点を当てるものではありません。
B. システムの健全性、パフォーマンス、カスタムメトリクスの監視には最適ですが、Stackdriver Monitoringでは、再デプロイせずにアプリケーションコード内の特定の問題をピンポイントで診断することはできません。
C. スナップショットは、コード内の特定の場所でローカル変数とコールスタックをキャプチャします。このツールは、実行中のアプリケーションを停止させたり速度を落としたりすることなく、プログラムの状態を調べるために使用される。役に立ちますが、ログポイントほど直接シナリオに合わせたものではありません。
正解
D. Logpoints を使えば、実行中のアプリケーションを停止したり再デプロイしたりすることなく、リアルタイムでログ文を追加することができるので、これは正しい選択です。これを使用して、問題が発生していると思われる特定のポイントのログを検査することで、アプリケーションコード内の問題を診断することができます。オプション D は、アプリケーションを再デプロイすることなく、アプリケーションコード内の問題を診断するた めに、アプリケーションを長期にわたって監視するための最良の選択です。

Links:

https://cloud.google.com/debugger/docs/using/logpoints
</div></details>

## Q. 1-31
あなたは、XMLHttpRequestを使用してサードパーティAPIとコンテンツ通信を行う、ユーザーインターフェースを持つ単一ページのWebアプリケーションを書いています。APIの結果によってUIに表示されるデータは、同じWebページに表示される他のデータよりも重要度が低いため、リクエストによってはAPIのデータがUIに表示されなくても構いません。しかし、APIへの呼び出しによって、ユーザーインターフェースの他の部分のレンダリングが遅れてはならない。APIレスポンスがエラーまたはタイムアウトの場合、アプリケーションのパフォーマンスを向上させたい。
どうすればよいでしょうか？
1. APIへのリクエストの非同期オプションをfalseに設定し、タイムアウトまたはエラーが発生したときにAPI結果を表示するウィジェットを省略します。
2. APIへのリクエストの非同期オプションをtrueに設定し、タイムアウトまたはエラーが発生したときにAPI結果を表示するウィジェットを省略する。
3. APIコールからのタイムアウトまたはエラー例外をキャッチし、API応答が成功するまで指数関数バックオフで試行を続ける。
4. APIコールのタイムアウトまたはエラー例外をキャッチし、UIウィジェットにエラー・レスポンスを表示する。
<details><div>
    答え：2
不正解
A. この場合、リクエストは同期的に処理され、リクエストが完了するまでUIの他の部分のレンダリングがブロックされます。
C. これは不必要な遅延を引き起こし、APIが失敗し続ければ無限にトライし続ける可能性がある。データはそれほど重要ではないので、繰り返しフェッチしようとするのは要件に合致しない。
D. UIにエラー・レスポンスを表示することは、特にデータの重要度が低い場合、望ましくないかもしれない。また、これは呼び出しを非同期にするという要件には対応していません。
正解
B. このシナリオでは、サードパーティAPIへの呼び出しがUIの他の部分のレンダリングを遅らせないようにすることに重点を置いています。

したがって、ここでの最良の選択は、UI の他の部分のレンダリングをブロックしないようにリクエストを非同期（オプション B）にすることです。

https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest
</div></details>

## Q. 1-32
App Engineでアプリケーションを実行しています。

アプリケーションは Stackdriver Trace でインスツルメンテーションされています。product-detailsリクエストは、以下のように/sku-detailsにある4つの既知のユニークな商品に関する詳細をレポートします。リクエストが完了するまでの時間を短縮したい。

どうすればよいでしょうか？
1. インスタンスクラスのサイズを大きくする。
2. 永続ディスクのタイプをSSDに変更する。
3. リクエストを並行して実行するように/product-detailsを変更する。
4. sku-details情報をデータベースに保存し、Webサービスコールをデータベースクエリに置き換える。
<details><div>
    答え：3
A. インスタンスクラスのサイズを大きくすることで、より多くのリソースを提供できるかもしれませんが、シーケンシャルなリクエスト処理という核心的な問題には必ずしも対処できないでしょう。
B. 永続ディスク・タイプをSSDに変更すると、ディスクI/Oパフォーマンスが向上するかもしれないが、ここで説明する問題はネットワーク・リクエストに関連するものであり、ディスク操作に関連するものではない。
D. データベースに/sku-details情報を格納することで、シナリオによってはパフォーマンスが向上する可能性がありますが、説明した問題とは必ずしも一致しません。sku-detailsデータが頻繁に変更され、サードパーティによって管理されている場合、データベースの保存は適切ではないかもしれません。
正解
C. リクエストを並列に実行することで、/product-detailsリクエスト全体が完了するまでの時間を短縮できます。

Links:

https://cloud.google.com/appengine/docs/standard/java/datastore/queries
</div></details>

## Q. 1-33
App Engineの標準設定は以下のとおりです：

- サービス: production

- インスタンスクラス B1

アプリケーションを5インスタンスに制限したい。

どのコードスニペットを構成に含める必要がありますか？
1. manual_scaling: インスタンス： 5 min_pending_latency: 30ms
2. manual_scaling: max_instances： 5 idle_timeout： 10m
3. basic_scaling: インスタンス数： 5 min_pending_latency: 30ms
4. basic_scaling: max_instances： 5 idle_timeout： 10m
<details><div>
    答え：4
不正解
manual_scalingではインスタンスの最大数を設定できない（固定数である）ため、これらの他の選択肢は正しくありません。また、選択肢Cはbasic_scalingに対して誤った構文を使用しています。
正解です：
App Engineでインスタンス数を制限したい場合、特定の最大インスタンス数でbasic scalingを使用できます。
この設定の正しいコードスニペットは以下の通り：
basic_scaling: max_instances： 5 idle_timeout： 10m
この設定により、App Engineは最大5つのインスタンスを実行し続け、10分以上アイドル状態のインスタンスを自動的にシャットダウンします。
Links:

https://cloud.google.com/appengine/docs/legacy/standard/python/how-instances-are-managed#scaling_types
</div></details>

## Q. 1-34
アプリケーションはCompute Engine上で実行されており、少数のリクエストで持続的な障害が発生しています。原因を1つのCompute Engineインスタンスに絞り込みましたが、そのインスタンスはSSHに応答しません。

次に何をすべきでしょうか?
1. マシンを再起動します。
2. シリアルポート出力を有効にして確認してください。
3. マシンを削除し、新しいマシンを作成する。
4. ディスクのスナップショットを取り、新しいマシンに添付する。
<details><div>
    答え：2
不正解
A. 一時的に問題は解決するかもしれませんが、問題の原因を知ることができないので、再発する可能性があります。
C. 一時的に問題は解決するかもしれないが、根本的な原因を調査しない限り、再発を防ぐことはできない。
D. より抜本的な対策を後で検討することになるかもしれませんが、シリアルポートの出力をチェックすることは、問題を診断するのにより簡単で直接的な方法です。
正解
B. 次のステップは正しいです。これにより、ブート・ログやシステム・ログを見ることができ、何が問題だったのかを知る手がかりになります。
Links:

https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-ssh#debug_with_serial_console
</div></details>

## Q. 1-35
データはCloud Storageのバケットに保存されます。

他の開発者から、Cloud StorageからダウンロードしたデータによってAPIのパフォーマンスが低下しているという報告を受けています。Google Cloudのサポートチームに詳細を報告するために、この問題を調査したいと思います。

どのコマンドを実行すべきですか？
1. gsutil test -o output.json gs://my-bucket
2. gsutil perfdiag -o output.json gs://my-bucket
3. gcloud compute scp example-instance:~/test-data -o output.json gs://my-bucket
4. gcloud services test -o output.json gs://my-bucket
<details><div>
    答え：2
説明
不正解
A. このコマンドはgsutilコマンドラインツールに存在せず、オプション "test "が認識されないため、正しく実行されません。
C. gcloud compute scpコマンドは、ローカルマシンと仮想マシン間、または2つの仮想マシン間でファイルをコピーするために使用されます。クラウドストレージのパフォーマンス問題の診断とは関係ないので、今回のタスクには当てはまらない。
D. このコマンドはgcloudコマンドラインツールには存在しません。gcloud servicesの下に「test」コマンドはないので、この行はエラーになります。
正しい答え
B. gsutil perfdiagコマンドは、Google Cloud Storageのパフォーマンスの問題を診断するために使用できます。一連の診断テストを実行し、パフォーマンス問題の原因を特定するのに役立つ情報を収集します。
Links:

https://cloud.google.com/storage/docs/gsutil/commands/perfdiag#providing-diagnostic-output-to-cloud-storage-team
</div></details>

## Q. 1-36
あなたは、Compute Engine上で財務部門向けの企業ツールを開発しています。このツールでは、ユーザーを認証し、財務部門に所属していることを確認する必要があります。全社員がG Suiteを使用しています。

あなたは何をすべきですか?
1. HTTPロードバランサーでCloud Identity-Aware Proxyを有効にし、財務部門のユーザーを含むGoogleグループへのアクセスを制限します。提供された JSON Web トークンをアプリケーション内で確認します。
2. HTTP(s)ロードバランサーでCloud Identity-Aware Proxyを有効にし、財務部門のユーザーを含むGoogleグループへのアクセスを制限する。財務チームの全員にクライアント側証明書を発行し、アプリケーションで証明書を検証します。
3. Cloud Armor Security Policies を構成して、企業 IP アドレス範囲のみにアクセスを制限する。提供された JSON Web トークンをアプリケーション内で検証する。
4. Cloud Armor Security Policiesを構成して、企業IPアドレス範囲のみにアクセスを制限する。財務チームの全員にクライアント側証明書を発行し、アプリケーションで証明書を検証する。
<details><div>
    答え：1
説明
不正解
B. このケースでは、明確な要件もメリットもないのにクライアント側証明書を発行することで、不必要な複雑さを追加する。
C. D. 
オプション C と D は、IP アドレスに基づいてアクセスを制限する Cloud Armor Security Policies に依存しています。また、会社の全従業員がG Suiteを使用しているという事実を利用しておらず、財務部門のみにアクセスを制限するにはIPベースの制限では不十分かもしれません。
正解
A. HTTP(s)ロードバランサーでCloud Identity-Aware Proxy (IAP)を有効にする： IAP は Google Cloud 上で動作するクラウドアプリケーションへのアクセスを制御します。ID とコンテキストを検証してアプリケーションへのアクセスを許可するかどうかを判断することで、適切な人だけがアクセスできるようにします。
財務部門のユーザーを含むGoogleグループへのアクセスを制限する： これにより、財務部門の特定のグループのメンバーだけがアクセスできるようになります。IAP は、Google Workspace グループに基づいてアクセスを許可するように設定できます。
提供された JSON Web Token をアプリケーション内で確認します： IAP は JSON Web Token（JWT）を設定し、アプリケーションはこの JWT を検証して、リクエストが IAP によって承認されたことを確認できます。
Links:

https://cloud.google.com/iap/docs/signed-headers-howto#securing_iap_headers
</div></details>

## Q. 1-37
既存のApache/MySQL/PHPアプリケーションスタックをシングルマシンからGoogle

Kubernetes Engineに移植しようとしています。アプリケーションをコンテナ化する方法を決定する必要があります。あなたのアプローチは、Googleが推奨する可用性のベストプラクティスに従う必要があります。

あなたは何をすべきでしょうか？
1. 各コンポーネントを個別のコンテナにパッケージする。レディネス・プローブとライブネス・プローブを実装する。
2. アプリケーションを単一のコンテナにパッケージ化する。プロセス管理ツールを使用して、各コンポーネントを管理する。
3. 各コンポーネントを個別のコンテナにパッケージする。スクリプトを使用して、コンポーネントの起動をオーケストレーションする。
4. アプリケーションを1つのコンテナにパッケージする。コンテナへのエントリポイントとしてbashスクリプトを使用し、各コンポーネントをバックグラウンドジョブとしてスポーンする。
<details><div>
    答え：1
説明
不正解
B. このアプローチは、コンテナごとに1プロセスという原則に反するため、システムの管理、拡張、トラブルシューティングが困難になります。1つのプロセスに障害が発生すると、コンテナ全体に影響する可能性があるため、ダウンタイムが長くなり、問題の切り分けが複雑になる。
C. 各コンポーネントを別のコンテナに分離することはベストプラクティスに合致するが、オーケストレーションにカスタムスクリプトを使用すると、コンテナを管理するためのKubernetesのネイティブ機能が活用されない。このため、Kubernetesの組み込みオーケストレーション機能を使用する場合と比較して、メンテナンスコストが高くなり、効率的な管理ができなくなる可能性がある。
D. 繰り返しますが、このオプションは1コンテナ1プロセスの原則に従いません。1つのコンテナ内で複数のバックグラウンドジョブを管理すると、依存関係がもつれ、問題の診断が困難になる可能性がある。1つのバックグラウンド・ジョブに障害が発生すると、コンテナ全体に影響が及ぶ可能性がある。また、管理にbashスクリプトを使用すると、Kubernetesのオーケストレーション機能を活用できず、より脆弱でスケーラビリティの低いシステムになってしまいます。
正解
A. 各コンポーネントを個別のコンテナにパッケージ化し、レディネス・プローブとライブネス・プローブを実装することで、コンテナ化のベストプラクティスに沿い、Kubernetesの機能を活用してコンテナを効率的かつ効果的に管理できます。
Links:

https://cloud.google.com/architecture/best-practices-for-building-containers#package_a_single_app_per_container
</div></details>

## Q. 1-38
あなたはCloud Storage APIを使用するアプリケーションをサポートしています。ログを確認し、APIからの複数のHTTP 503 Service Unavailableエラー応答を発見しました。アプリケーションはエラーをログに記録し、それ以上のアクションは取りません。Googleが推奨する再試行ロジックを実装し、成功率を向上させたいと考えています。

どのアプローチを取るべきでしょうか？
1. 設定された数の失敗が記録された後、バッチで失敗を再試行する。
2. 設定された時間間隔で、最大回数まで各失敗を再試行する。
3. 失敗するたびに、最大トライ回数まで時間間隔を空けてリトライします。
4. 最大トライ回数まで、時間間隔を狭めて各障害をリトライする。
<details><div>
    答え：3
説明
不正解
A. このアプローチでは、503エラーの一過性の性質を考慮していないため、すべての再試行が一度に行われ、問題が悪化する可能性があります。
B. この方法は状況に適応せず、すでに苦戦しているサービスに負荷をかけ続ける可能性がある。
D. リトライの間隔を短くすることは、苦戦しているサービスの負荷を増加させ、状況を改善するどころか悪化させる可能性があります。
正解
C. すでに問題が発生しているシステムに負荷をかけるリスクを軽減し、各再試行の間に回復する時間を確保できるため、このシナリオではベストプラクティスです。
Links:

https://cloud.google.com/storage/docs/retry-strategy
</div></details>

## Q. 1-39
トラフィックの大幅な増加に対応できるように、認証サービスからの監査イベントの取り込みを再設計する必要があります。現在、監査サービスと認証システムは、同じCompute Engine仮想マシンで実行されています。新しいアーキテクチャでは、以下のGoogle Cloudツールを使用する予定です：

複数のCompute Engineマシンで、それぞれが認証サービスのインスタンスを実行している。

複数のCompute Engineマシンで、それぞれ監査サービスのインスタンスを実行する。

認証サービスからイベントを送信するためのPub/Sub。

システムが大量のメッセージを処理し、効率的に拡張できるようにするには、トピックとサブスクリプションをどのように設定すればよいですか？
1. 1つのPub/Subトピックを作成する。監査サービスがメッセージを共有できるように、1つのプル・サブスクリプションを作成します。
2. 1つのPub/Subトピックを作成します。監査サービスインスタンスごとに1つのプル・サブスクリプションを作成し、サービスがメッセージを共有できるようにします。
3. 1つのPub/Subトピックを作成する。監査サービスの前にロードバランサーを指すエンドポイントを持つプッシュサブスクリプションを1つ作成する。
4. 認証サービスごとに1つのPub/Subトピックを作成する。1つの監査サービスによって使用されるために、1つのトピックごとに1つのプルサブスクリプションを作成する。
<details><div>
    答え：1
説明
不正解
B. これは、監査サービスごとに個別のサブスクリプションを作成することになります。これらはすべて同じトピックから消費されるため、同じメッセージが複数のサブスクリプションに送信され、重複処理が発生する可能性があります。
C. このアプローチには利点がありますが、ロードバランサーとプッシュサブスクリプションを使用することは、より複雑になる可能性があり、オプションAほどこの特定のユースケースに適していないかもしれません。
D. このセットアップは、各認証サービスと監査サービスの間の緊密な結合をもたらし、潜在的なボトルネックとリソースの非効率的な使用をもたらします。
正解
A. この設定では、すべての監査サービスが同じサブスクリプションからメッセージをプルできます。これは、各メッセージが利用可能な監査サービスの 1 つによって 1 回処理されることを保証し、メッセージを重複させることなくスケーラブルなソリューションを提供します。
Links:

https://cloud.google.com/pubsub/docs/subscriber
</div></details>

## Q. 1-40
あなたは、Google Kubernetes Engine (GKE)クラスタ内の顧客に専用のブログソフトウェアをデプロイするSaaSプロバイダーです。各顧客が自分のブログのみにアクセスでき、他の顧客のワークロードに影響を与えないように、セキュアなマルチテナント・プラットフォームを構成したいと考えています。

あなたは何をすべきでしょうか？
1. クラスタを保護するために、GKEクラスタでアプリケーションレイヤーシークレットを有効にします。
2. テナントごとにネームスペースをデプロイし、各ブログのデプロイメントでネットワークポリシーを使用します。
3. GKE監査ロギングを使用して、悪意のあるコンテナを特定し、発見時に削除する。
4. ブログ・ソフトウェアのカスタム・イメージを構築し、Binary Authorizationを使用して信頼できないイメージのデプロイを防止する。
<details><div>
    答え：2
説明
不正解
A. これは、テナントを分離するというよりも、シークレットを保護することを目的としているため、マルチテナントの要件には対応していません。
C. 監査ロギングは疑わしい活動や不正な活動の特定に役立ちますが、テナント間の隔離や制限を直接的に提供するものではありません。
D. バイナリ認証は、信頼できるコンテナイメージのみがデプロイされることを保証しますが、異なるテナント間の分離や個々のブログへのアクセスの制御は提供しません。
正解
B. テナントごとに個別のネームスペースを作成することで、Kubernetesレベルでリソースを分離し、各テナントのワークロードを他のテナントから確実に分離できます。
Network Policiesを実装すると、異なるテナント間の通信がさらに制限され、ネットワークレベルでの分離が強制され、あるテナントのワークロードが他のテナントのワークロードと相互作用できないようになります。
Links:

https://cloud.google.com/kubernetes-engine/docs/concepts/multitenancy-overview#network_policies
</div></details>

## Q. 1-41
あなたは、従業員が社内でコミュニティイベントを開催するための社内アプリケーションを開発しています。アプリケーションは1つのCompute Engineインスタンスにデプロイしました。あなたの会社はGoogle Workspace（旧G Suite）を使用しており、会社の従業員がどこからでもアプリケーションに認証できるようにする必要があります。

どうすればいいでしょうか？
1. インスタンスにパブリックIPアドレスを追加し、ファイアウォールルールを使用してインスタンスへのアクセスを制限します。会社のプロキシを唯一のソースIPアドレスとして許可します。
2. インスタンスの前にHTTP(S)ロードバランサーを追加し、Identity-Aware Proxy(IAP)を設定する。会社のドメインがウェブサイトにアクセスできるようにIAP設定を構成する。
3. 社内ネットワークとGoogle Cloud上のインスタンスのVPCロケーションの間にVPNトンネルを設定します。オンプレミスとGoogle Cloudの両方のネットワークに対して、必要なファイアウォールルールとルーティング情報を設定する。
4. インスタンスにパブリックIPアドレスを追加し、インターネットからのトラフィックを許可する。ランダムなハッシュを生成し、このハッシュを含み、インスタンスを指すサブドメインを作成します。このDNSアドレスを会社の従業員に配布する。
<details><div>
    答え：2
説明
不正解
A. この方法では、会社のドメインに基づく認証がないため、従業員が会社のネットワーク外からアプリケーションにアクセスしようとすると問題が発生する可能性があります。
C. この方法では、社内ネットワークまたはVPN接続からのみアプリケーションにアクセスできるため、従業員が他の場所からアプリケーションにアクセスできない可能性がある。
D. この方法では、ユーザーの身元に基づく認証は行われない。共有秘密（サブドメインのハッシュ）に依存し、ユーザーが従業員であることを検証しません。
正解
B. Identity-Aware Proxy（IAP）：Googleクラウド上で動作するアプリケーションへのアクセスを制御し、ユーザー（企業ドメインなど）のIDやグループメンバーシップに基づいてアクセスレベルを設定できます。

HTTP(S)ロードバランサー： HTTP(S)トラフィックを様々なパラメータに基づいて異なるインスタンスにルーティングすることができ、スケーラビリティと制御性を高めることができます。

したがって、ユーザーのアイデンティティに基づいたアクセスを可能にし、会社ドメインの従業員だけがアプリケーションを認証できるようにするオプションBが最良のアプローチです。
Links:

https://cloud.google.com/iap/docs/concepts-overview#how_iap_works

https://cloud.google.com/blog/topics/developers-practitioners/control-access-your-web-sites-identity-aware-proxy
</div></details>

## Q. 1-42
最近Google Kubernetes Engineにアプリケーションをデプロイし、新しいバージョンのアプリケーションをリリースする必要があります。新しいバージョンで問題が発生した場合に備えて、以前のバージョンに即座にロールバックする機能が必要です。

どのデプロイモデルを使うべきでしょうか？
1. ローリングデプロイメントを実行し、デプロイメント完了後に新しいアプリケーションをテストします。
2. A/Bテストを実施し、新しいテストが実施された後、定期的にアプリケーションをテストする。
3. ブルー/グリーンデプロイメントを実行し、デプロイメント完了後に新しいアプリケーションをテストします。
4. カナリアデプロイメントを実行し、新しいバージョンがデプロイされた後、新しいアプリケーションを定期的にテストしてください。
<details><div>
    答え：3
説明
不正解
A. ローリングデプロイメントでは、古いバージョンのインスタンスを新しいバージョンに徐々に置き換えます。これによってダウンタイムをゼロにすることができますが、システムが段階的な変更を元に戻さなければならないため、即座にロールバックすることはより複雑になる可能性があります。
B. A/Bテストは、ユーザーを異なるグループに分け、アプリケーションの異なるバージョンをテストすることを含みます。これは、即座にロールバックする仕組みを提供するというよりも、パフォーマンスやユーザビリティを比較するためのものです。
D. カナリアデプロイメントでは、完全なロールアウトの前に、新バージョンを一部のユーザーにリリースします。問題を早期に検出するのに役立ちますが、すべてのユーザーに対して以前のバージョンに即座にロールバックするメカニズムが提供されない可能性があります。
正解
C. ブルー/グリーンのデプロイメントでは、2つの別々の環境を持つことになります。1つは古いバージョン（ブルー）を実行し、もう1つは新しいバージョン（グリーン）を実行します。トラフィックをリダイレクトするだけで、これらのバージョンを切り替えることができます。グリーン環境で何か問題があれば、即座にブルー環境に戻すことができる。このように、ブルー／グリーンのデプロイメント・モデルは、新しいバージョンに問題があれば、即座に以前のバージョンにロールバックするという要件に最も適している。
Links:

https://cloud.google.com/architecture/application-deployment-and-testing-strategies#choosing_the_right_strategy
</div></details>

## Q. 1-43
コンテナ化したアプリケーションの新バージョンのテストが完了し、Google Kubernetes Engine上で本番環境にデプロイする準備が整いました。
本番前の環境では新バージョンの負荷テストを十分に行うことができなかったため、デプロイ後のパフォーマンスに問題がないことを確認する必要があります。デプロイは自動化する必要があります。
あなたは何をすべきでしょうか？
1. クラウドロードバランシングを使用して、バージョン間のトラフィックを徐々に増加させます。クラウドモニタリングを使用してパフォーマンスの問題を探します。
2. カナリアデプロイメントを使用して、継続的デリバリーパイプライン経由でアプリケーションをデプロイする。クラウドモニタリングを使用してパフォーマンスの問題を調べ、メトリクスがサポートするようにトラフィックを増加させる。
3. ブルー／グリーン・デプロイメントを使用して、継続的デリバリー・パイプラインを介してアプリケーションをデプロイする。クラウド監視を使用してパフォーマンスの問題を探し、メトリクスがそれをサポートするときに完全に起動します。
4. kubectlを使用してアプリケーションをデプロイし、spec.updateStrategv.typeをRollingUpdateに設定します。Cloud Monitoringを使用してパフォーマンスの問題を探し、問題があればkubectl rollbackコマンドを実行します。
<details><div>
    答え：4
説明
不正解
A. クラウドロードバランシングは、Kubernetes環境における新しいアプリケーションバージョンの制御されたロールアウトに適したツールではありません。
B. カナリア・デプロイは、少数のサブセット・ユーザーで新バージョンをテストする良い方法ですが、この選択肢は選択された正解には一致しません。
C. ブルー／グリーン・デプロイメントは、バージョン間の迅速な切り替えを可能にしますが、新しいバージョンへの露出を徐々に増やすことには適していません。
正解
D. KubernetesのRollingUpdateでは、アプリケーションを徐々に更新することができます。Cloud Monitoringを通じてパフォーマンスの問題が検出された場合、kubectl rollbackを使用してデプロイメントをロールバックできます。これにより、問題を検出するために必要な段階的な露出と、デプロイを効率的に管理するための自動化の両方が提供される。
Links:

https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/

https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps#overview
</div></details>

## Q. 1-44
クラウドランでホストしているウェブサイトがトラフィック急増時に反応が遅すぎるとユーザーから苦情が来ています。
トラフィックのピーク時に、より良いユーザーエクスペリエンスを提供したいと考えています。
どうすればよいでしょうか？
1. アプリケーションの起動時にデータベースからアプリケーション構成と静的データを読み込みます。
2. ビルド時にアプリケーション構成と静的データをアプリケーション・イメージにパッケージする。
3. レスポンスがユーザーに返された後、できるだけ多くの作業をバックグラウンドで実行する。
4. タイムアウト例外やエラーによってCloud Runインスタンスが迅速に終了し、代替インスタンスが開始できるようにする。
<details><div>
    答え：2
説明
不正解
A. 特に、新しいインスタンスが頻繁に起動される可能性が高いトラフィック急増時には、待ち時間が増加する可能性があります。
C. バックグラウンド・タスクをオフロードすることで、ユーザーが認識するパフォーマンスは向上しますが、トラフィック急増時の応答時間の遅さという問題には特に対処できません。バックグラウンド・タスクは、入ってくるリクエストの処理に使えるリソースをさらに消費する可能性さえある。
D. 障害が発生したインスタンスを迅速に交換することは一般的に良いプラクティスですが、これはトラフィックが多いときの応答時間の低下の問題には特に対処していません。さらに、常にインスタンスを交換することは、追加のオーバーヘッドにつながり、応答時間をさらに遅くする可能性があります。
正解
B. 構成データと静的データをアプリケーション・イメージにバンドルすることで、実行時に外部ソースからデータを取得する必要性を減らすことができます。これにより、特にシステムの負荷が増大するトラフィック・ピーク時に、応答時間を短縮することができます。
Links:

https://cloud.google.com/blog/topics/developers-practitioners/3-ways-optimize-cloud-run-response-times
</div></details>

## Q. 1-45
アプリケーションは、複数のゾーンにある管理インスタンスグループ（MIG）内の数百のCompute Engineインスタンスにデプロイされています。重要な脆弱性を直ちに修正するために新しいインスタンステンプレートをデプロイする必要がありますが、サービスへの影響は避けなければなりません。

インスタンステンプレートを更新した後、MIGにどのような設定を行う必要がありますか？
1. Max Surgeを100%に設定します。
2. 更新モードをオポチュニスティックに設定する。
3. 最大利用不可を100%に設定する。
4. 最小待機時間を0秒に設定します。
<details><div>
    答え：4
説明
不正解
A. Max Surgeは、アップデート中に作成できる追加インスタンス数を定義します。100%に設定すると、インスタンス数が一時的に2倍になります。更新プロセスを高速化できますが、コストの増加など別の結果も発生する可能性があり、個々のインスタンスの更新間隔を制御できません。
B. 前述したように、このモードは、他のアクティビティによってインスタンスが再作成された場合にのみインスタンスを更新します。このモードでは、重大な脆弱性を修正するためにインスタンスを直ちに更新する方法は提供されないため、このシナリオで必要とされる緊急の更新には適していません。
C. この設定では、アップデート中にグループ内のすべてのインスタンスが同時に利用できなくなり、サービスへの影響を避けるという要件に直接反してしまいます。このオプションはダウンタイムにつながるため、この状況には適していません。
正解
D. この設定により、個々のインスタンスの更新の間に待機することなく、更新プロセスを可能な限り迅速に行うことができ、サービスを中断することなく重要な脆弱性を緊急に修正する必要性に沿う。
Links:

https://cloud.google.com/compute/docs/instance-groups/rolling-out-updates-to-managed-instance-groups#minimum_wait_time
</div></details>

## Q. 1-46
Google Kubernetes Engine（GKE）にデプロイされたアプリケーションの1つに、断続的なパフォーマンスの問題が発生しています。あなたのチームはサードパーティのロギングソリューションを使用しています。このソリューションをGKEクラスタの各ノードにインストールして、ログを表示できるようにしたいと思います。

あなたは何をすべきですか？
1. サードパーティのソリューションをDaemonSetとしてデプロイする
2. コンテナイメージを変更し、監視ソフトウェアを含める
3. SSH を使用して GKE ノードに接続し、ソフトウェアを手動でインストールする。
4. Terraformを使用してサードパーティソリューションをデプロイし、KubernetesデプロイメントとしてロギングPodをデプロイする。
<details><div>
    答え：1
説明
不正解
B. これは、アプリケーションコンテナ自体にロギングソリューションを組み込むことになります。特定のアプリケーションを実行していないノードも含め、クラスタ内のすべてのノードにロギング・ソリューションをデプロイする必要がある場合、この方法は機能しません。
C. 手動インストールは、特にKubernetesでは、インフラストラクチャを維持するためのベストプラクティスに従わない。ノード間の一貫性の維持や、ノードの障害からの復旧に困難が生じます。また、GKEノードは管理されていることが多く、このような変更のための直接アクセスを許可しない場合があることも注目に値する。
D. 標準的なデプロイメントとしてロギングソリューションをデプロイしても、ロギングソリューションのインスタンスがすべてのノードで実行されていることは保証されません。デプロイは、アプリケーションの指定された数のレプリカが実行されていることを保証するように設計されており、アプリケーションがクラスタ内のすべてのノードで実行されていることを強制するものではありません。
正解
A. DaemonSetは、すべてまたは一部のワーカーノードがPodのコピーを実行するようにします。クラスタにノードが追加されると、Podがノードに追加されます。クラスタ内のすべてのノードに監視またはロギングエージェントをデプロイする場合は、DaemonSetが正しい方法です。
Links:

https://kubernetes.io/docs/concepts/workloads/controllers/daemonset

https://cloud.google.com/kubernetes-engine/docs/concepts/daemonset#usage_patterns
</div></details>

## Q. 1-47
あなたは最近、オンプレミスのモノリシック・アプリケーションをGoogle Kubernetes Engine（GKE）上のマイクロサービス・アプリケーションに移行しました。このアプリケーションは、CRMシステムや個人を特定できる情報（PII）を含むMySQLデータベースなど、オンプレミスのバックエンドサービスに依存しています。バックエンド・サービスは、規制要件を満たすためにオンプレミスのままでなければなりません。

オンプレミスのデータセンターとGoogle Cloudの間にクラウドVPN接続を確立しました。GKE上のマイクロサービス・アプリケーションからバックエンド・サービスへのリクエストの一部が、帯域幅の変動によるレイテンシの問題で失敗し、アプリケーションのクラッシュを引き起こしていることに気づきました。

レイテンシーの問題にどのように対処すべきでしょうか？
1. Memorystoreを使用して、オンプレミスのMySQLデータベースから頻繁にアクセスされるPIIデータをキャッシュします。
2. Istio を使用して、GKE 上のマイクロサービスとオンプレミスのサービスを含むサービスメッシュを作成する。
3. Google Cloudとオンプレミスのサービス間の接続にクラウドVPNトンネルの数を増やす
4. クラウドVPNのMTU（Maximum Transmission Unit）値をデフォルト値から下げることで、ネットワーク層のパケットサイズを小さくする。
<details><div>
    答え：3
説明
不正解
A. キャッシュは一部のデータアクセスではレイテンシーを削減できますが、PIIデータには規制要件により適用できない場合があります。また、帯域幅の変動が問題を引き起こしているという根本的な問題には対処できない。
B. Istioのようなサービスメッシュは、より良い制御、観測可能性、ルーティングを提供できる。しかし、帯域幅が変動するという問題を本質的に解決しているわけではないので、レイテンシーの問題は続く可能性が高い。
D. MTUを小さくすることで、より多くのパケットを送信することができますが、必ずしも帯域幅の変動の問題を解決することはできません。
正解
C. VPNトンネルの数を増やすことで、より多くの帯域幅を提供でき、遅延の問題を軽減できる可能性があります。このアプローチは、問題の根本原因に直接対処します。
Links:

https://cloud.google.com/network-connectivity/docs/vpn/concepts/topologies#more-bandwidth
</div></details>

## Q. 1-48
GoアプリケーションからCloud Spannerデータベースに書き込んでいます。Google が推奨するベストプラクティスを使用して、アプリケーションのパフォーマンスを最適化したいと考えています。

どうすればよいでしょうか？
1. Cloud Client Librariesを使用してCloud Spannerに書き込みます。
2. Google API クライアント ライブラリを使用して Cloud Spanner に書き込む。
3. カスタムgRPCクライアント・ライブラリを使用してCloud Spannerに書き込む。
4. サードパーティのHTTPクライアント・ライブラリを使用してCloud Spannerに書き込む。
<details><div>
    答え：1
説明
不正解です：
B. 技術的には可能ですが、Cloud Client Librariesはサービスに特化しているため、開発が簡単で効率的です。
C. カスタム gRPC クライアント ライブラリを作成することは、公式にサポートされているライブラリを使用することに比べて、エラーが発生しやすく、時間がかかる可能性があります。
D. サードパーティのライブラリに依存すると、互換性とサポートのリスクが発生し、Cloud Spanner用に最適化されていない可能性があります。
正解
A. GoアプリケーションからCloud Spannerを使用する場合、GoogleはCloud Client Librariesの使用を推奨します。これらのライブラリは、Google API Client Libraries よりも高レベルで便利な抽象化を提供し、Google Cloud サービスとの統合を容易にします。

GoからCloud Spannerを操作する慣用的で最適化された方法を提供するため、オプションAが推奨されるアプローチです。
Links:

https://cloud.google.com/apis/docs/client-libraries-explained

https://cloud.google.com/go/docs/reference
</div></details>

## Q. 1-49
Google Kubernetes Engine（GKE）にデプロイされたアプリケーションがあります。Google Cloudのマネージドサービスに認可されたリクエストを行うために、アプリケーションをアップデートする必要があります。これは一度だけのセットアップであり、セキュリティキーの自動ローテーションと暗号化されたストアへの保存というセキュリティのベストプラクティスに従う必要があります。Google Cloud サービスへの適切なアクセス権を持つサービスアカウントは作成済みです。

次に何をすべきでしょうか？
1. Workload Identityを使用して、GKEポッドにGoogleクラウドサービスアカウントを割り当てます。
2. Google Cloudサービスアカウントをエクスポートし、KubernetesシークレットとしてPodと共有します。
3. Google Cloudサービスアカウントをエクスポートし、アプリケーションのソースコードに埋め込みます。
4. Google Cloudのサービスアカウントをエクスポートし、HashiCorp Vaultにアップロードして、アプリケーション用の動的なサービスアカウントを生成します。
<details><div>
    答え：1
説明
不正解
B. サービスアカウントキーの保存にKubernetesシークレットを使用すると、自動ローテーションが提供されず、正しく処理されないとセキュリティリスクを引き起こす可能性があります。
C. ソースコードにサービスアカウントを埋め込むことは悪い習慣であり、重大なセキュリティリスクをもたらす。
D. HashiCorp Vaultはシークレット管理のための強力なツールですが、Google Cloudサービスと相互作用するGKEワークロードのIDを処理するには、ワークロードアイデンティティを使用する方がより簡単で推奨される方法です。
正解
A. Workload Identityは、GKE内からGoogle Cloudサービスにアクセスするための推奨方法です。KubernetesサービスアカウントをGoogleサービスアカウントにバインドすることができ、このバインドによってKubernetesサービスアカウントがGoogleサービスアカウントとして機能します。Workload Identityを使用すると、サービスアカウントのキーを管理する必要がなく、ベストプラクティスに沿った自動ローテーションが行われます。
Links:

https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity
</div></details>

## Q. 1-50
アプリケーションにユニット・テストを追加することを計画しています。発行された Pub/Sub メッセージがサブスクライバによって順番に処理されることを保証できるようにする必要があります。あなたは、ユニット・テストを費用対効果が高く、信頼できるものにしたいと考えています。

あなたは何をすべきでしょうか？
1. モッキングフレームワークを実装する。
2. テスターごとにトピックとサブスクリプションを作成する。
3. サブスクリプションにテスターによるフィルタを追加する。
4. Pub/Subエミュレータを使用する。
<details><div>
    答え：4
説明
不正解
A. モッキング・フレームワークを実装することは有効な選択肢ですが、Pub/Subエミュレータを使用する方がよりシンプルで正確です。
B. テスターごとにトピックとサブスクリプションを作成すると、実際の Pub/Sub サービスとやり取りすることになり、テストにコストや複雑さ、信頼性の問題が生じる可能性があります。
C. サブスクリプションにテスターによるフィルタを追加することも、実際の Pub/Sub サービスとのやりとりを伴います。
正解です：
D. オプションDの「Pub/Subエミュレータを使用する」は、ここでの最も適切なアプローチです。Pub/Subエミュレータを使用すると、実際のPub/Subサービスを実際に使用することなく、Pub/Subと相互作用するコードをユニットテストすることができます。これはローカルで実行され、Pub/Sub の動作をシミュレートするため、テストが高速になり、コストもかかりません。
Links:

https://cloud.google.com/pubsub/docs/emulator
</div></details>

## Q. 2-1
Google Kubernetes Engine（GKE）に、ライブストリームを配信するマイクロサービス・アプリケーションをデプロイしようとしています。予測不可能なトラフィックパターンと同時ユーザー数の大きな変動が予想されます。アプリケーションは以下の要件を満たす必要があります：

- 人気のあるイベント時に自動的にスケールし、高可用性を維持する。

- ハードウェア障害が発生した場合の回復力

デプロイメントパラメータはどのように構成しますか? (2つのオプションを選択してください)
1. マルチゾーンノードプールを使用してワークロードを均等に分散します。
2. 複数のゾーンノードプールを使用してワークロードを均等に分散します。
3. クラスターオートスケーラーを使用してノードプールのノード数をリサイズし、ホリゾンタルポッドオートスケーラーを使用してワークロードをスケールします。
4. クラスタノードでCompute Engine用のマネージドインスタンスグループを作成します。マネージドインスタンスグループのオートスケーリングルールを設定します。
5. GKEのCPUとメモリの使用率に基づいて、Cloud Monitoringでアラートポリシーを作成する。CPUとメモリの使用率が事前に定義したしきい値を超えたら、スクリプトを実行してワークロードをスケールするよう、当番のエンジニアに依頼する。
<details><div>
    答え：1,3
説明
不正解
B. 複数のゾーンノードプールを使用すると、管理が複雑になる可能性があります。一般的に、マルチゾーナルノードプールは、より簡単な構成で同じ利点を提供します。
D. マネージドインスタンスグループは一般的にKubernetesの外部で使用され、GKEと直接統合されないため、このオプションは説明したシナリオには適していません。
E. アラートポリシーの作成とワークロードの手動スケーリングは自動プロセスではなく、手動介入に依存するとエラーが発生しやすく、スケーリングが遅れる可能性があります。
正解
A. これにより、ノードがリージョン内の複数のゾーンに分散され、ゾーンの1つに障害が発生した場合のフォールトトレランスが確保されます。また、ゾーン間のリソースの利用率も向上します。
C. クラスタオートスケーラは、リソース要件に基づいてノードプールのサイズを自動的に調整し、必要なときにノードが追加され、不要なときにノードが削除されるようにします。Horizontal Pod Autoscalerは、観測されたCPUまたはメモリの使用量に基づいてデプロイメント内のPodの数を自動的に調整し、アプリケーションがさまざまな負荷に対応できるようにします。
Links:

https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-creating-a-highly-available

https://cloud.google.com/kubernetes-engine/docs/concepts/types-of-clusters#multi-zonal_clusters
</div></details>

## Q. 2-2
Cloud Shellからkubectlを使ってGoogle Kubernetes Engine (GKE)クラスタに接続しようとしています。
GKEクラスターをパブリックエンドポイントでデプロイしています。Cloud Shellから以下のコマンドを実行します：

gcloud container clusters get-credentials <cluster-name> ￤ -zone <none
---zone <none> --project <プロジェクト名> \
kubectl コマンドがエラーメッセージを返さずにタイムアウトしていることに気付きます。

この問題の最も可能性の高い原因は何ですか。
1. ユーザーアカウントには、kubectlを使用してクラスタと対話する権限がありません。
2. Cloud Shellの外部IPアドレスはクラスタの許可されたネットワークの一部ではありません。
3. クラウドシェルが GKE クラスターと同じ VPC に属していない。
4. VPCファイアウォールがクラスタのエンドポイントへのアクセスをブロックしている。
<details><div>
    答え：2
説明
不正解
A. ユーザーアカウントに権限がない場合、通常はタイムアウトではなく、権限に関連するエラーメッセージが表示されます。
C. パブリックエンドポイントに接続しているため、クラウドシェルが同じ VPC に属していなくてもこの問題は発生しません。
D. VPC ファイアウォールは、Cloud Shell が VPC の外側にあるため、Cloud Shell からクラスタのパブリックエンドポイントへの接続には影響しません。
正解
B. パブリックエンドポイントを持つGKEクラスタを設定するとき、Kubernetes APIサーバーへの接続が許可される許可されたネットワークを設定することができます。Cloud Shellの外部IPアドレスがこれらの許可されたネットワークの一部でない場合、クラスタに接続しようとするとブロックされ、説明されているようなタイムアウトの問題が発生します。
Links:

https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#cloud_shell
</div></details>

## Q. 2-3
あなたのチームはCloud Functionsコードのユニットテストを開発しています。

コードは Cloud Source Repositories リポジトリに保存されています。あなたはテストを実装する責任があります。特定のサービスアカウントだけが、コードを Cloud Functions にデプロイするのに必要な権限を持っています。最初にテストに合格しないとコードがデプロイできないようにしたい。

ユニットテストプロセスをどのように構成しますか？
1. Cloud Build を構成してクラウド関数をデプロイします。コードがテストに合格すると、デプロイ承認が送信されます。
2. 特定のサービス アカウントをビルド エージェントとして使用して、Cloud Functions をデプロイするように Cloud Build を構成します。デプロイ成功後にユニットテストを実行する。
3. ユニット テストを実行するように Cloud Build を構成します。コードがテストに合格すると、開発者は Cloud Functions をデプロイします。
4. 特定のサービスアカウントをビルドエージェントとして使用して、ユニットテストを実行するようにCloud Buildを構成します。コードがテストに合格すると、Cloud BuildはCloud Functionsをデプロイします。
<details><div>
    答え：4
説明
不正解
A. このオプションは、デプロイの前に単体テストを実行することについては特定されていません。
B. このオプションはデプロイ後にユニットテストを実行しますが、これは必要なことではありません。テストはデプロイ前にパスする必要があります。
C. このオプションは、開発者がクラウド機能をデプロイすることを可能にしますが、特定のサービスアカウントがデプロイ権限を持つ必要があります。
正解
D. 目標は、まずテストに合格しなければコードをデプロイできないようにすることであり、特定のサービスアカウントだけがCloud Functionsにコードをデプロイするのに必要な権限を持っています。

このセットアップにより、デプロイの前にユニットテストが実行され、コードがテストに合格した場合のみ、特定のサービスアカウントを使用して Cloud Build によってデプロイが実行されることが保証されます。これにより、テストの前提条件とデプロイの正しい権限処理の両方が保証されます。
Links:

https://firebase.google.com/docs/functions/unit-testing
</div></details>

## Q. 2-4
あなたは、MySQLリレーショナル・データベース・スキーマを使用するGoogle Cloud上でホストされるアプリケーションを開発しています。このアプリケーションでは、データベースへの大量の読み取りと書き込みが発生するため、バックアップと継続的なキャパシティプランニングが必要になります。あなたのチームにはデータベースを完全に管理する時間はありませんが、小さな管理タスクを引き受けることはできます。

どのようにデータベースをホストすべきでしょうか？
1. データベースをホストするためにCloud SQLを構成し、スキーマをCloud SQLにインポートする。
2. クライアントを使用してGoogle Cloud MarketplaceからデータベースにMySQLをデプロイし、スキーマをインポートします。
3. データベースをホストするためにBigtableを設定し、データをBigtableにインポートする。
4. データベースをホストするためにCloud Spannerを構成し、スキーマをCloud Spannerにインポートする。
<details><div>
    答え：1
説明
不正解
B. Google Cloud MarketplaceからMySQLをデプロイする必要があり、管理オーバーヘッドが増えるため、管理タスクを最小限に抑えたいチームには適していません。
C. Bigtableを使うことを提案するが、BigtableはNoSQLデータベースであり、MySQLのリレーショナルデータベーススキーマには適していない。
D. Cloud Spannerを提案するが、Spannerはリージョン間の水平スケーリング用に設計されたグローバル分散データベースであり、従来のMySQLデータベースのホスティングには適していない。
正解
A. Google Cloud SQLは、MySQLをサポートするフルマネージドデータベースサービスを提供し、スケーリング、バックアップ、メンテナンスを容易にします。
Links:

https://cloud.google.com/spanner/docs/migrating-mysql-to-spanner#migration-process

https://cloud.google.com/sql/docs/mysql
</div></details>

## Q. 2-5
新しい Go アプリケーションを Cloud Run にデプロイする予定です。ソース コードはクラウド ソース リポジトリに格納されています。ソース コードのコミットが行われたときに実行される、完全に管理された自動継続デプロイ パイプラインを構成する必要があります。最も単純なデプロイメントソリューションを使用したい。

どうすればいいでしょうか？
1. ワークステーション上でcronジョブを構成して、作業ディレクトリでgcloud run deploy --sourceを定期的に実行します。
2. Jenkins トリガーを構成して、クラウド・ソース・リポジトリへのソース・コードのコミットごとに、コンテナのビルドとデプロイ処理を実行する。
3. ビルドパックを使用して、Cloud Run用ソースリポジトリからの新しいリビジョンの継続的デプロイを構成する。
4. Cloud Source Repositoriesへのソースコードのコミットごとにコンテナビルドとデプロイプロセスを実行するように構成されたトリガーでCloud Buildを使用する。
<details><div>
    答え：4
説明
不正解
A. オプションAは、ワークステーション上でcronジョブを構成する必要があるため、完全に管理または自動化されません。
B. オプションBは、Jenkinsのセットアップを伴うため、Google独自のマネージドサービスを使用する場合と比較すると、最も単純なソリューションではない。
C. 
正解
D. GoogleによるフルマネージドサービスであるCloud Buildを使用したエンドツーエンドのソリューションを提供し、Cloud Source RepositoriesおよびCloud Runとの容易な統合を可能にする。Cloud Buildでトリガーを設定し、ソースコードリポジトリに新しいコミットが行われたときにコンテナを自動的にビルドおよびデプロイし、質問の要件を満たすことができる。
Links:

https://cloud.google.com/run/docs/continuous-deployment-with-cloud-build
</div></details>

## Q. 2-6
ベスト・プラクティスに準拠するために、クラウド構築手順を見直し、更新しています。現在、ビルド手順には以下が含まれています：

1. ソース リポジトリからソース コードをプルします。

2. コンテナ・イメージをビルドする。

3. ビルドしたイメージを Artifact Registry にアップロードする。

ビルドしたコンテナイメージの脆弱性スキャンを実行するステップを追加する必要があり、スキャンの結果を Google Cloud で実行中のデプロイパイプラインで利用できるようにしたい。他のチームのプロセスを混乱させる可能性のある変更は最小限に抑えたい。どうすればいいでしょうか？
1. バイナリ認証を有効にし、コンテナイメージに脆弱性が存在しないことを証明するように構成します。
2. ビルドしたコンテナイメージをDocker Hubインスタンスにアップロードし、脆弱性をスキャンする。
3. ArtifactレジストリでコンテナスキャンAPIを有効にし、構築されたコンテナイメージの脆弱性をスキャンします。
4. Aqua SecurityインスタンスにArtifact Registryを追加し、ビルドされたコンテナイメージの脆弱性をスキャンする。
<details><div>
    答え：3
説明
不正解
A. Binary Authorizationとは、コンテナのデプロイ時に署名検証を実施するために使用されるものであり、脆弱性のスキャンに使用されるものではありません。
B. 外部サービス（Docker Hub）を使用することになり、既存のプロセスに大幅な変更が必要になる可能性があります。
D. サードパーティツール（Aqua Security）との統合が必要で、既存のプロセスを混乱させる可能性があります。
正解
C. Google Cloud 内、特に Artifact Registry 内で脆弱性スキャンを実行でき、コンテナ イメージのビルド方法や保存方法を変更する必要がありません。Container Analysis API は、脆弱性スキャンを含むコンテナイメージの分析とメタデータの生成に使用され、Artifact Registry で有効にすることができます。
Links:

https://cloud.google.com/container-analysis/docs/automated-scanning-howto#view_the_image_vulnerabilities
</div></details>

## Q. 2-7
あなたのチームはCloud Run上でサーバーレスWebアプリケーションを作成しています。このアプリケーションは、プライベートクラウドストレージバケットに保存された画像にアクセスする必要があります。アプリケーションにバケット内の画像にアクセスするIAM（Identity and Access Management）権限を与えると同時に、Googleが推奨するベストプラクティスを使ってサービスを保護したい。

どうすればよいでしょうか？
1. 目的のバケットに対して署名付きURLを強制します。Compute Engineのデフォルトのサービスアカウントに、バケットのStorage Object Viewer IAMロールを付与します。
2. 目的のバケットに対して、パブリックアクセス防止を強制します。Compute Engineのデフォルトのサービスアカウントに、バケットのStorage Object Viewer IAMロールを付与する。
3. 目的のバケットに対して署名付きURLを強制します。ユーザー管理サービスアカウントを使用するようにCloud Runサービスを作成し、更新します。サービスアカウントに、バケット上のStorage Object Viewer IAMロールを付与する。
4. 目的のバケットに対してパブリックアクセス防止を実施します。ユーザー管理サービスアカウントを使用するようにCloud Runサービスを作成し、更新します。バケット上のStorage Object Viewer IAMロールをサービスアカウントに付与します。
<details><div>
    答え：4
説明
不正解
オプションAとBは、Compute Engineのデフォルトのサービスアカウントに関係しており、Cloud Runサービスに特有ではないため、最小特権の原則に合致していません。
C. オプションCは署名付きURLを利用し、バケット内のオブジェクトへの一時的なアクセスを提供する。これはアクセスを許可する有効な方法ですが、選択肢Dほど説明したシナリオには適合しません。
正解
D. パブリックアクセス防止を実施することで、バケットが誤って公開されないようにし、プライバシーを維持します。

ユーザが管理するサービスアカウントを使用するようにCloud Runサービスを作成・更新することで、特定のサービスに必要な権限のみを付与する最小権限の原則に従うことになります。

サービスアカウントにStorage Object Viewer IAMロールを付与することで、Cloud Runサービスはより広範な権限を与えることなく、指定されたバケットからオブジェクトを読み取ることができます。
Links:
https://cloud.google.com/run/docs/securing/service-identity#user-managed_service_account
https://cloud.google.com/storage/docs/public-access-prevention
https://cloud.google.com/storage/docs/access-control/using-iam-permissions
</div></details>

## Q. 2-8
あなたは、グローバルなeコマースWebアプリケーションをホストするためにCloud Runを使用しています。あなたの会社のデザインチームは、ウェブアプリケーションの新しい配色を作成しています。あなたは、新しい配色が売上を増加させるかどうかを判断する任務を与えられています。あなたは、本番のトラフィックでテストを実施したいと考えています。

どのように調査を設計すべきでしょうか？
1. 外部のHTTP(S)ロードバランサーを使用して、あらかじめ決められた割合のトラフィックを、アプリケーションの2つの異なるカラースキームにルーティングします。結果を分析して、売上に統計的に有意な差があるかどうかを判断する。
2. 外部のHTTP(S)ロードバランサーを使用して、新しい配備を作成してテストしている間、トラフィックを元の配色にルーティングします。テストが完了したら、すべてのトラフィックを新しい配色にルーティングし直します。結果を分析し、売上に統計的に有意な差があるかどうかを判断する。
3. 外部の HTTP(S)ロードバランサーを使用して、新しいバージョンのアプリケーションにトラフィックをミラーリングする。その結果を分析し、売上に統計的に有意な差があるかどうかを判断する。
4. 全ユーザーの半数に新しい配色を表示する機能フラグを有効にする。このユーザーグループの売上が増加するかどうかをモニターする。
<details><div>
    答え：1
説明
不正解
B. C. 
オプションBとCでは同時比較ができません。また、トラフィックをミラーリング（オプションC）しても、新しいデザインとの実際のユーザーインタラクションが得られないため、ユーザーの行動を正確に反映することができません。
D. オプションDは実行可能なように見えるかもしれませんが、HTTP(S)ロードバランサーが提供するような制御された環境がありません。機能フラグを実装することは、さらなる複雑さをもたらす可能性があり、テストが均一に配布されないかもしれません。
正解です：
A. これはA/Bテストを可能にし、ユーザーベースの一部がサイトのあるバージョンを取得し、別の一部が異なるバージョンを取得します。これは、2つのバージョンを比較し、どちらがより良いパフォーマンスかを確認するための一般的なアプローチです。

既存の配色と新しい配色の両方に所定の割合のトラフィックをルーティングすることで、同じ条件下で直接比較することができ、より信頼性の高い結果が得られます。

つまり、このような研究を管理された体系的な方法で実施し、2つの配色間で売上に統計的に有意な差があるかどうかを判断しやすくするためには、選択肢Aが最良の方法ということになる。
Links:

https://cloud.google.com/load-balancing/docs/l7-internal/traffic-management#traffic_actions_weight-based_traffic_splitting

https://cloud.google.com/load-balancing/docs/https/setting-up-https-serverless
</div></details>

## Q. 2-9
あなたは大企業の開発者です。Google Cloud上で3つのGoogle Kubernetes Engineクラスタを管理しています。あなたのチームの開発者は、好みの開発ツールへのアクセスを失うことなく、クラスタを定期的に切り替える必要があります。あなたは、Googleが推奨するベストプラクティスに従いながら、これらの複数のクラスタへのアクセスを設定したいと考えています。

どうすればよいでしょうか？
1. 開発者にCloud Shellを使用するように依頼し、gcloud container clusters get-credentialを実行して別のクラスタに切り替えます。
2. 設定ファイルで、クラスタ、ユーザー、コンテキストを定義します。このファイルを開発者と共有し、kubectl configを使用してクラスタ、ユーザー、コンテキストの詳細を追加するように依頼します。
3. 開発者にワークステーションにgcloud CLIをインストールしてもらい、gcloud container clusters get-credentialsを実行して別のクラスターに切り替える。
4. 開発者にワークステーション上で3つのターミナルを開いてもらい、kubectl configを使用して各クラスタへのアクセスを設定する。
<details><div>
    答え：2
説明
不正解
A. C. 
オプションCも有効な方法ですが、共有設定ファイルに定義済みのコンテキストがあるのとは対照的に、開発者は切り替えが必要なたびにコマンドを実行する必要があるかもしれません。
D. 選択肢AとDは、Bに比べて利便性と柔軟性に劣ります。
正解
B. 設定ファイルでクラスタ、ユーザー、コンテキストを定義することで、開発者は適切なパーミッションが設定されていることを前提に、kubectl config use-contextを使用して異なる環境をすばやく切り替えることができます。

適切な詳細を含む設定ファイルを共有することで、開発者は複数のクラスタへの接続をより簡単に管理できるようになります。

異なるクラスタにコンテキストを定義することで、開発者は単純なコマンドでクラスタ間を素早く切り替えることができ、クラスタを定期的に切り替える必要があるという要件に沿う。
Links:

https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/
</div></details>

## Q. 2-10
あなたは大企業の開発者です。あなたのチームはソースコード管理（SCM）にGitを使っています。Google が推奨するベストプラクティスに従ってコードを管理し、ソフトウェアの納品率を上げたいと考えています。

あなたのチームはどのSCMプロセスを使うべきでしょうか？
1. 各開発者は、各製品のリリース前にコードをメインブランチにコミットし、テストを実施し、統合の問題が検出された場合はロールバックします。
2. 各開発者グループがリポジトリをコピーし、自分のリポジトリに変更をコミットし、各製品リリースの前にメインリポジトリにコードをマージする。
3. 各開発者は自分の作業用のブランチを作成し、そのブランチに変更をコミットし、毎日そのコードをメインブランチにマージします。
4. 各開発者グループは、自分たちの作業用にメインブランチからフィーチャーブランチを作成し、自分たちのブランチに変更をコミットし、変更諮問委員会が承認した後にコードをメインブランチにマージする。
<details><div>
    答え：3
説明
不正解
A. 製品リリースの直前まで待って統合テストを行うと、予期せぬ重大な問題が発生する可能性があるため、リスクが高い。
B. 各開発者グループがリポジトリをコピーし、各自のリポジトリに変更をコミットし、各自のコードをメインリポジトリにマージする。
D. 変更は外部の変更諮問委員会の承認を待つことになるため、統合が遅れ、継続的インテグレーションを真に受け入れることにはなりません。
正解
C. このアプローチによって、次のことが保証されます：

頻繁な統合： 毎日コードをメインブランチにマージすることで、統合に関する問題を早期に発見し修正することができます。

短命なブランチ： 開発者は機能の小さな塊に取り組むため、変更の管理がシンプルになり、マージ時にコンフリクトが発生する可能性が最小限になります。

継続的なフィードバックループ： 継続的インテグレーションでは通常、新しいコードを変更するたびに自動テストを実行します。定期的にメインブランチにマージすることで、開発者は変更に対するフィードバックを即座に得ることができ、問題に迅速に対処することができます。

継続的インテグレーションで短期間のフィーチャーブランチを使用することは、最新のソフトウェア開発の基本原則です。これはDevOps文化を支えるものであり、小規模でインクリメンタルな変更を効率的かつ確実にリリースすることに重点を置いている。

Links:
https://cloud.google.com/solutions/devops/devops-culture-westrum-organizational-culture
https://www.atlassian.com/git/tutorials/comparing-workflows
</div></details>

## Q. 2-11
最近、OpenTelemetry で新しいアプリケーションをインスツルメンテーションし、アプリケーションのリクエストのレイテンシを Trace でチェックしたいとします。特定のリクエストが常にトレースされるようにしたい。

どうすればいいでしょうか？
1. リクエストにX-Cloud-Trace-Contextヘッダを適切なパラメータとともに追加します。
2. 開発プロジェクトからこのタイプのリクエストを繰り返し送信するカスタムスクリプトを記述します。
3. Trace API を使用して、カスタム属性をトレースに適用する。
4. 10 分待ってから、Trace がそれらのタイプのリクエストを自動的に捕捉することを確認してください。
<details><div>
    答え：1
説明
不正解です：
B. カスタムスクリプトを書いてリクエストを繰り返し送信しても、 オプション A のように特定のトレースヘッダを組み込まない限り、 特定のリクエストが常にトレースされるわけではありません。
C. Trace API を使用してカスタム属性をトレースに適用すると、 トレースに注釈をつけることができますが、 特定のリクエストをトレースするかどうかを直接制御することはできません。
D. トレースはサンプリングやその他の設定に依存している可能性があるため、一定時間待っても特定のリクエストが常にトレースされるとは限りません。
正解
A. このヘッダーは、HTTPリクエストのトレースの動作を制御することができます。このヘッダーに適切なパラメーターを含めることで、特定のリクエストを確実にトレースすることができます。
Links:

https://cloud.google.com/trace/docs/setup#force-trace
</div></details>

## Q. 2-12
Google Kubernetes Engineの導入と、VS CodeやIntelliJを含む開発環境との統合を促進するために、開発者ツールを評価しています。

あなたは何をすべきでしょうか？
1. アプリケーションの開発には Cloud Code を使用します。
2. コードと設定ファイルを編集するには、Cloud Shell統合コードエディタを使用します。
3. Cloud Notebook インスタンスを使用して、データを取り込んで処理し、モデルをデプロイします。
4. Cloud Shellを使用して、コマンドラインからインフラストラクチャとアプリケーションを管理する。
<details><div>
    答え：1
説明
不正解
B. Cloud Shell 統合コード エディタを使用してコードと構成ファイルを編集できますが、GKE 開発用に特別に調整されているわけではなく、VS Code や IntelliJ と直接統合することはできません。
C. Cloud Notebookインスタンスは、Kubernetesの開発やデプロイよりも、データサイエンス、機械学習、アナリティクスのタスクに重点を置いている。
D. Cloud Shell は、コマンドラインからインフラストラクチャとアプリケーションを管理するために使用できますが、Cloud Code のような GKE との統合開発環境エクスペリエンスを提供しません。
正解
A. Cloud Codeは、VS CodeとIntelliJのためのプラグインのセットであり、KubernetesとGoogle Cloudで作業するための統合開発エクスペリエンスを提供します。このプラグインには、インタラクティブなクラスタとリソースの管理、ワンクリックでのKubernetesクラスタの作成、組み込みのデバッグと診断などの機能が含まれています。また、KubernetesとGoogle Cloud SDKを使用したアプリケーションの迅速なデプロイとデバッグもサポートする。さらにCloud Codeでは、開発者はアプリケーションのデプロイやデバッグ、リソースの管理、ローカル開発環境の実行などのタスクを簡単に実行できる。Cloud Codeは、KubernetesとGoogle Cloudの開発プロセスを効率化したいチームにとって最適なツールだ。
Links:

https://cloud.google.com/code
</div></details>

## Q. 2-13
Google Kubernetes Engine（GKE）への新しいコンテナイメージのデプロイを自動化するために、Cloud Buildを使用して継続的インテグレーションパイプラインを構成しています。パイプラインはソースコードからアプリケーションをビルドし、単体テストと統合テストを別々のステップで実行し、コンテナを Container Registry にプッシュします。アプリケーションはPythonウェブサーバ上で実行される。
Dockerfileは以下の通りです：

FROM python:3.7-alpine
FROM python:3.7-alpine
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
CMD [ "gunicorn", "-w 4", "main:app" ]。

Cloud Buildの実行に予想以上に時間がかかっていることに気づきました。ビルド時間を短縮したい。どうしますか？(選択肢を2つ選んでください。）
1. Cloud Buildの実行には、CPUが高い仮想マシン（VM）サイズを選択します。
2. VPC内のCompute Engine VM上にContainer Registryをデプロイし、最終イメージを保存するために使用します。
3. ビルド設定ファイルの--cache-from引数を使用して、後続のビルド用にDockerイメージをキャッシュします。
4. Dockerfileのベースイメージをubuntu:latestに変更し、パッケージマネージャユーティリティを使ってPython 3.7をインストールする。
5. アプリケーションのソースコードをクラウドストレージに保存し、gsutil を使用してソースコードをダウンロードするようにパイプラインを設定します。
<details><div>
    答え：1,3
説明
不正解
B. VM上のContainer Registryは、ビルドをスピードアップしません。
D. ubuntuコンテナイメージはpython:3.7-alpineイメージよりかなり大きくなります。
E. アプリケーション・ソース・コードをクラウド・ストレージに保存しても、アプリケーションのビルド時間は短縮されません。
正解
A. C. 
CPUの高い仮想マシンタイプはビルド速度を向上させることができるため、Aが正しい。
Cは、テストやレジストリへのプッシュのために、後続のステップで同じコンテナが使用されるため、正しい。
Links:

https://cloud.google.com/cloud-build/docs/speeding-up-builds

https://cloud.google.com/build/docs/optimize-builds/increase-vcpu-for-builds
</div></details>

## Q. 2-14
あなたは、エンドユーザーからのリクエストを処理するアプリケーションを開発しています。アプリケーションから呼び出されるクラウド関数を保護し、許可されたエンドユーザーがアプリケーション経由で関数に認証できるようにする一方で、許可されていないユーザーからのアクセスを制限する必要があります。Googleサインインをソリューションの一部として統合し、Googleが推奨するベストプラクティスに従いたいと考えています。

どうすればよいでしょうか？
1. ソースコードリポジトリからデプロイし、ユーザーにroles/cloudfunctions.viewerロールを付与します。
2. ソースコードリポジトリからデプロイし、ユーザーにroles/cloudfunctions.invokerロールを付与します。
3. gcloudを使用してローカルマシンからデプロイし、ユーザーにroles/cloudfunctions.adminロールを付与します。
4. gcloudを使用してローカルマシンからデプロイし、ユーザーにroles/cloudfunctions.developerロールを付与します。
<details><div>
    答え：2
説明
不正解
A. このロールは、ユーザーに関数を表示する権限だけを与え、関数を呼び出す権限は与えません。要件は、許可されたユーザが認証して関数を起動できるようにすることなので、このロールは基準を満たしていません。
C. このロールは、関数を削除または変更する能力を含め、関数に対する管理者権限をユーザーに付与します。これは、単にエンドユーザーが関数を呼び出すことができるようにしたい、説明したシナリオには寛容すぎる可能性があります。
D. このロールは、Cloud Functionsを開発およびデプロイする権限を付与しますが、繰り返しますが、認証して特定の関数を呼び出す必要があるだけのエンドユーザーに与えたいものではありません。
正解
B. これにより、roles/cloudfunctions.invokerロールが付与され、権限のあるユーザが関数を呼び出すために必要な正確なパーミッションが提供されます。
Links:

https://cloud.google.com/functions/docs/securing/authenticating#authenticating_function_to_function_calls
</div></details>

## Q. 2-15
アプリケーションは顧客のコンテンツをCloud Storageバケットに保存し、各オブジェクトは顧客の暗号化キーで暗号化されます。Cloud Storageの各オブジェクトのキーは、顧客がアプリケーションに入力します。あなたは、アプリケーションがCloud Storageからオブジェクトを読み取るときにHTTP 4xxエラーを受け取っていることに気づきました。

このエラーの原因として何が考えられますか？
1. あなたは顧客のbase64エンコードされたキーでオブジェクトの読み取り操作を試みました。
2. あなたは暗号化キーのBase64エンコードされたSHA256ハッシュなしで読み取り操作を試みました。
3. 顧客によって指定された暗号化アルゴリズムを、読み取り操作の際に入力した。
4. 顧客の鍵のSHA256ハッシュをbase64エンコードしたオブジェクトに対して読み取り操作を試みた。
<details><div>
    答え：2
説明
不正解
A. これが読み取り操作を実行する正しい方法です。
C. 使用されたアルゴリズムは、このコンテキストでは通常4xxエラーを引き起こさない。
D. この説明は、クラウド・ストレージにおけるCSEK(Customer-Supplied Encryption Keys)の期待される動作とは一致しません。
正解です：
B. CSEK（Customer-Supplied Encryption Keys）を使用する場合、リクエストに暗号化キーのSHA256ハッシュを含める必要があります。ハッシュを含めないとHTTP 4xxエラーになります。これは正しいオプションです。
Links:

https://cloud.google.com/storage/docs/encryption/customer-supplied-keys#response
</div></details>

## Q. 2-16
あなたは、クライアントが特定の期間、あなたのウェブサイトからファイルをダウンロードできるようにするアプリケーションを開発しています。Googleが推奨するベストプラクティスに従いつつ、このタスクを完了するためにアプリケーションをどのように設計すべきでしょうか？
1. ファイルを電子メールの添付ファイルとしてクライアントに送信するようにアプリケーションを設定する。
2. ファイルにクラウドストレージ署名付きURLを生成して割り当てます。そのURLをクライアントがダウンロードできるようにする。
3. 有効期限を指定した一時的なクラウドストレージバケットを作成し、そのバケットにダウンロード権限を与えます。ファイルをコピーし、クライアントに送信する。
4. 有効期限を指定してHTTPクッキーを生成する。時間が有効であれば、Cloud Storageバケットからファイルをコピーし、クライアントがダウンロードできるようにする。
<details><div>
    答え：2
説明
不正解
A. 電子メールの添付ファイルとしてファイルを送信することは、一時的なファイルアクセスのためのスケーラブルで安全なソリューションではなく、電子メールのサイズ制限やフィルタリングの問題につながる可能性があります。
C. 期限を指定して一時的なCloud Storageバケットを作成するのは、不必要に複雑です。多数のバケットを管理することになるかもしれませんし、個々のファイルの有効期限を処理する簡単な方法を提供しません。
D. 有効期限付きのHTTPクッキーを生成することは、本質的にクラウド・ストレージと結びついていません。また、クラウド・ストレージ・バケットからファイルをコピーすることは、署名付きURLのようなクラウド・ストレージの組み込みの安全な機能を活用することなく、複雑さを追加します。
正解
B. クラウドストレージでファイルへの一時的なアクセスを提供するための推奨アプローチは、署名付きURLを生成することです。このURLはクライアントにファイルをダウンロードするための一時的なアクセスを与え、指定された期間が経過すると失効します。
Links:

https://cloud.google.com/storage/docs/access-control/signed-urls
</div></details>

## Q. 2-17


1. 
2. 
3. 
4. 
<details><div>
    答え：
    
Links:

https://cloud.google.com/pubsub/docs/overview
</div></details>

## Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>
