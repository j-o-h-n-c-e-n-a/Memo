
## Q. 1-1
同じVPC（仮想プライベートクラウド）内の複数のクライアントから呼び出される必要がある、Compute Engine仮想マシンインスタンス上でホストされるHTTP APIを開発しています。クライアントがサービスのIPアドレスを取得できるようにしたい。どうすればよいでしょうか？
1. 静的な外部IPアドレスを予約し、HTTP(S)負荷分散サービスの転送ルールに割り当てる。クライアントはこのIPアドレスを使ってサービスに接続する。
2. 静的な外部IPアドレスを予約し、HTTP(S)ロードバランシングサービスの転送ルールに割り当てる。次に、クラウドDNSでAレコードを定義する。クライアントはAレコードの名前を使用してサービスに接続する。
3. クライアントが、https://[INSTANCE_NAME].[ZONE].c.[PROJECT_ID].internal/.というURLでインスタンス名に接続し、Compute Engineの内部DNSを使用するようにします。
4. クライアントが、https://[API_NAME]/[API_VERSION]/のURLでインスタンス名に接続して、Compute Engineの内部DNSを使用するようにします。
<details><div>
    答え：3
A. 
1．静的外部IPアドレスは、クライアントがサービスに接続するために使用できる固定IPアドレスを提供します。インスタンスが再起動されたり、インスタンスがオートスケーリンググループの一部である場合、インスタンスのIPアドレスが変更される可能性があるため、これは重要です。
2．HTTP(S)ロードバランシング・サービスは、トラフィックを複数のインスタンスに分散させることができ、サービスのパフォーマンスと可用性を向上させることができます。また、利用可能なインスタンスのプールから不健康なインスタンスを自動的に削除するヘルスチェックも処理できる。
3．転送ルールを使用することで、URLまたはIPアドレスに基づいて、トラフィックを適切なインスタンスに誘導することができる。これにより、複数のサービスを単一のIPアドレスとポートの組み合わせでホストすることができる。
4．クライアントは、転送ルールに割り当てられたIPアドレスを使用してサービスに接続できる。
結論として、この複雑なソリューションは "非最適 "と評価できる。
B. 説明
このオプションはオプションAと似ていますが、サービスに接続するためにIPアドレスを使用する代わりに、クライアントはクラウドDNSで定義されたAレコードの名前を使用します。これは、サービスによりユーザーフレンドリーな名前を提供できますが、セットアップにさらなる複雑さが加わります。
さらに、クラウドDNSを使用すると、構成および管理する必要がある別のサービスが追加されるため、問題やダウンタイムが発生する可能性が高まります。
D. 説明
このオプションはオプションCと似ていますが、URLでインスタンス名を使用する代わりに、API名とバージョンを使用します。これは、より使いやすいURLを提供できますが、Compute Engineが提供する内部DNSサービスに依存します。
また、カスタムのAPI名とバージョンを使用すると、セットアップがさらに複雑になり、追加の設定と管理が必要になる場合があります。
正解
C. このオプションは、Compute Engineが提供する内部DNSサービスを使用して、サービスをホストするインスタンスのIPアドレスを解決します。これは、すべてのクライアントが同じVPC内にあり、内部DNSサービスにアクセスできる場合に機能します。
まとめると、同じVPC内のクライアントがCompute Engineの仮想マシンインスタンス上でホストされているHTTP APIのIPアドレスを取得できるようにするための最良の選択肢は、クライアントが、https://[INSTANCE_NAME].[ZONE].c.[PROJECT_ID].internal/というURLでインスタンス名に接続してCompute Engineの内部DNSを使用するようにすることです。
Links: 

https://cloud.google.com/compute/docs/internal-dns
</div></details>

## Q. 1-2
Webアプリケーションは企業のイントラネットにデプロイされています。このWebアプリケーションをGoogle Cloudに移行する必要があります。ウェブアプリケーションは、会社の従業員だけが利用でき、従業員が移動中にアクセスできる必要があります。アプリケーションの変更を最小限に抑えながら、Webアプリケーションのセキュリティとアクセシビリティを確保する必要があります。

どのような対応が必要ですか？
1. アプリケーションへの HTTP(S)リクエストごとに認証情報をチェックするようにアプリケーションを構成する。
2. 従業員がパブリックIPアドレス経由でアプリケーションにアクセスできるように、Identity-Aware Proxyを構成する。
3. ユーザーに企業アカウントへのログインを要求するCompute Engineインスタンスを構成します。WebアプリケーションのDNSをプロキシのCompute Engineインスタンスを指すように変更します。認証後、Compute EngineインスタンスはWebアプリケーションとの間でリクエストを転送します。
4. ユーザーに企業アカウントへのログインを要求するCompute Engineインスタンスを構成する。WebアプリケーションのDNSをプロキシのCompute Engineインスタンスを指すように変更します。認証後、Compute Engineは、WebアプリケーションをホストするパブリックIPアドレスにHTTPリダイレクトを発行します。
<details><div>
    答え：3
A. このオプションでは、HTTP(S)リクエストごとに認証チェックを実装するために、アプリケーションに大幅な変更が必要になる可能性が高く、アプリケーションの変更を最小限に抑えるという要件に反する。
B. IAP（Identity-Aware Proxy）は、Google Cloud Platformの機能であり、IDおよびコンテキストベースのアクセス制御を使用してリソースへのアクセスを保護することができます。IAPを使用すると、リソース（ウェブ・アプリケーションなど）へのアクセスを、認証され許可されたユーザーまたはサービス・アカウントのみに制限することができます。
しかし、このシナリオでは、ウェブ・アプリケーションは企業のイントラネット上でホストされているため、パブリックIPアドレスを持たず、インターネットからアクセスすることはできません。また、IAP を使用して、イントラネットでホストされているアプリケーションへのアクセスを、その IP アドレスによって制限することはできません。
D. これらのオプションには、プロキシとして機能するCompute Engineインスタンスを設定し、企業アカウントを通じてユーザーを認証することが含まれます。また、WebアプリケーションをホストするパブリックIPアドレスへのHTTPリダイレクトが含まれるため、従業員のみにアクセスを制限する必要性に合致しない可能性があります。
正解
C. このアプローチでは、Google Cloudのインフラストラクチャを利用して、Webアプリケーションへのアクセスを許可する前に、企業のイントラネットを通じてユーザーを認証することができます。プロキシとして動作するCompute Engineインスタンスを設定し、WebアプリケーションのDNSをこのプロキシを指すように変更することで、Webアプリケーションへのアクセスは、企業イントラネットで認証された従業員のみに制限されます。さらに、この方法では、従業員がインターネットにアクセスできる環境であれば、出張中でもWebアプリケーションにアクセスすることができます。
Links:
https://cloud.google.com/compute/docs

https://cloud.google.com/iam
</div></details>

## Q. 1-3
あなたは、Google Cloud上で実行されるあなたの会社のeコマースプラットフォームの決済システムを管理しています。貴社は、内部監査目的で1年間、コンプライアンス要件を満たすために3年間、ユーザーログを保持する必要があります。オンプレミスのストレージ使用量を削減し、ログを簡単に検索できるようにするために、新しいユーザーログをGoogle Cloudに保存する必要があります。

ログが正しく保存されていることを確認しながら、労力を最小限に抑えるために、どのような行動を取るべきでしょうか？
1. バケットロックをオンにして、ログをクラウドストレージのバケットに保存する。
2. ログをCloud Storageバケットに保存し、保存期間を3年にする。
3. Cloud Loggingに、カスタム保存期間を持つカスタムログとしてログを保存します。
4. 保存期間1年のCloud Storageバケットにログを保存する。1年後、ログを保存期間2年の別のバケットに移動する。
<details><div>
    答え：3
要件では、ログを簡単に検索できるようにする必要があります。これはクラウドストレージでは容易に実現できないため、選択肢A、B、Dは除外されます。
正解
Cloud Loggingは、ログが保存されているログバケットタイプに適用される保持ルールに従ってログを保持します。
Cloud Logging は、ログを 1 日から 365 日の範囲で保持するように構成できます。カスタム保持ルールは、ログタイプやログが別の場所からコピーされたかどうかに関係なく、バケット内のすべてのログに適用されます。
Links:
https://cloud.google.com/logging/docs/buckets#custom-retention

https://cloud.google.com/logging/docs/routing/overview#logs-retention

https://cloud.google.com/logging/docs/audit/best-practices#custom-retention

https://cloud.google.com/logging/docs/central-log-storage
</div></details>

## Q. 1-4
アプリケーションは、Compute Engine上で実行されるコードによってオーケストレーションされた、疎結合のサービス群で構成されています。アプリケーションは、サービスの特定のバージョンを見つけて使用する新しいCompute Engineインスタンスを簡単に起動できるようにしたい。
これはどのように設定すべきでしょうか？
1. 実行時に取得され、目的のサービスに接続するために使用されるメタデータとして、サービス・エンドポイント情報を定義します。
2. 実行時に取得され、目的のサービスに接続するために使用されるラベル・データとして、サービス・エンドポイント情報を定義する。
3. 実行時に環境変数から取得し、目的のサービスに接続するために使用するサービス・エンドポイント情報を定義する。
4. 固定ホスト名とポートを使用して目的のサービスに接続するようにサービスを定義する。エンドポイントのサービスを新しいバージョンに置き換えます。
<details><div>
    答え：1
B. ラベルは通常、実行時の設定ではなく、リソースの整理に使用されます。
C. 環境変数に依存すると、結合が密になり、サービスのバージョンを管理するための柔軟性が得られない可能性がある。
D. 固定のホスト名とポートを使用することは、サービスの異なるバージョンで動作するために必要な柔軟性を提供しない可能性があります。
答え
A. オプションAでは、エンドポイント情報をメタデータとして保存し、実行時にCompute Engineインスタンスから取得することができます。この方法では、インスタンスを変更することなくエンドポイント情報を変更することができるため、疎結合サービスをサポートし、異なるバージョンのサービスを管理するプロセスが容易になります。
Links:

https://cloud.google.com/apis/design/glossary#api_service_endpoint

https://cloud.google.com/compute/docs/metadata/overview

https://cloud.google.com/service-infrastructure/docs/service-metadata/reference/rest#service-endpoint

</div></details>

## Q. 1-5
以下のgcloudコマンドを使用してHTTP(s) Load Balancerをデプロイしました。


Compute Engine仮想マシンインスタンスのポート80へのヘルスチェックが失敗し、インスタンスにトラフィックが送信されません。この問題を解決することが目的です。
1. gcloud compute instances add-access-config ${NAME}-backend-instance-1
2. gcloud compute instances add-tags ${NAME}-backend-instance-1 --tags http-server
3. gcloud compute firewall-rules create allow-lb --network load-balancer --allow tcp --source-ranges 130.211.0.0/22,35.191.0.0/16 --direction INGRESS。
4. gcloud compute firewall-rules create allow-lb --network load-balancer --allow tcp --destination-ranges 130.211.0.0/22,35.191.0.0/16 --direction EGRESS
<details><div>
    答え：3
A. オプションAは、インスタンスに外部IPアドレスを追加するために使用されるため、役に立ちません。
B. Bはインスタンスにタグを追加することに関連するが、対応するファイアウォールルールがなければ、問題は解決しない。このコマンドはインスタンスにメタデータを適用するために使われ、ロードバランサーとは関係ありません。
D. Dは発信(EGRESS)トラフィック用のファイアウォールルールを作成していますが、ここでの問題は着信(INGRESS)のヘルスチェックです。
答え:
このコマンドは、指定されたソース範囲（Googleのロードバランサーがヘルスチェックに使用するIPアドレス範囲）からのポート80の着信TCPトラフィックを許可するファイアウォールルールを作成する。
正しいコマンドは、上記の修正されたオプションに示されているように、TCPポート80を指定する必要があることに注意してください。

Link: https://cloud.google.com/vpc/docs/special-configurations
</div></details>

## Q. 1-6
あなたは他のGoogle Cloudリソースにアクセスするクラウド関数を書きました。あなたは最小特権の原則を使用して環境を保護したいと思います。

どのようなアクションが必要ですか？
1. リソースにアクセスするエディタ権限を持つ新しいサービスアカウントを作成します。デプロイヤーにアクセストークンを取得する権限を与えます。
2. リソースにアクセスするためのカスタムIAMロールを持つ新しいサービスアカウントを作成します。デプロイ先にはアクセストークンを取得する権限が与えられる。
3. リソースにアクセスする編集権限を持つ新しいサービスアカウントを作成する。デプロイ担当者には、新しいサービスアカウントとして行動する権限が与えられます。
4. リソースにアクセスするためのカスタムIAMロールを持つ新しいサービスアカウントを作成します。デプロイ担当者には、新しいサービスアカウントとして行動する権限が与えられます。
<details><div>
    答え：4
A. エディター権限は一般的に、プロジェクト内の多くのリソースやアクションへの広範なアクセスを提供します。Editor権限を与えることで、クラウド機能が実行する特定のタスクに実際に必要な以上の権限を与えている可能性があります。これは最小特権の原則に違反します。
B. このオプションではカスタムIAMロールを作成するため、最小特権の原則に沿う可能性がありますが、デプロイ者に与えられる権限は「アクセストークンを取得する」ことです。これは、デプロイ者がサービスアカウントを "act as "することを許可するよりも安全性が低く、あまり一般的ではありません。慎重に扱わなければ、トークンの誤用につながる可能性がある。
C. 選択肢Aと同様に、この選択肢ではリソースへの広範なアクセスを提供するEditor権限を付与します。この場合も、必要以上の権限を与えることになり、最小権限の原則と矛盾する可能性があります。
正解
D. このオプションは、必要なリソースへのアクセスに必要な権限のみを含むように正確に定義できるカスタムIAMロールを作成することで、最小特権の原則に従います。こうすることで、クラウド機能はセキュリティリスクにつながる不必要なパーミッションを持つことがなくなる。デプロイヤーに新しいサービスアカウントとして動作する権限を与えることで、デプロイ時にクラウド機能がこの役割を引き受けることができます。
他のオプションはより広い権限（Editor権限）を与えるか、役割のカスタム性を強調しない。
Links:

https://cloud.google.com/functions/docs/securing/function-identity

https://cloud.google.com/blog/products/application-development/least-privilege-for-cloud-functions-using-cloud-iam

https://cloud.google.com/functions/docs/securing/function-identity#per-function_identity
</div></details>

## Q. 1-7
あなたは、顧客、注文、在庫データをCloud Spanner内のリレーショナル・テーブルとして格納するeコマース・アプリケーションを開発しています。最近の負荷テスト中に、Spanner のパフォーマンスが期待どおりに線形にスケーリングされていないことがわかりました。

次のうちどれが原因ですか？
1. 32ビットの数値に64ビットの数値型を使用すること。
2. 単調に増加する主キーとしてバージョン1のUUIDを使用すること。
3. STRINGデータ型の任意精度値への使用。
4. パラメータ化されたSQL問い合わせで、STARTS_WITHキーワードの代わりにLIKEを使用すること。
<details><div>
    答え：2
A. ストレージの効率は悪くなるかもしれないが、Spannerのリニアスケーリング機能に大きな影響を与えることはないだろう。
C. 任意精度の値にSTRINGデータ型を使用することは最適な選択ではないかもしれませんが、リニアスケーリングに大きな影響を与えることはないでしょう。
D. これはクエリ・パフォーマンスに影響する可能性がありますが、通常、システム全体の線形スケーリングには影響しません。
正解
B. Cloud Spannerでは、単調に増加するVersion 1 UUIDを主キーとして使用すると、均等に分散されないためパフォーマンスの問題が発生する可能性があります。このため、特定のノードまたはノードの範囲に不釣り合いな数のリクエストが送信されるホットリージョンが発生し、そのノードが過負荷になり、パフォーマンスが低下する可能性があります。パフォーマンスを改善するには、ハッシュベースのキーやランダムな整数など、より均等に分散されたプライマリ・キーの使用を検討すべきである。

Links:

https://cloud.google.com/spanner/docs/schema-and-data-model#choosing_a_primary_key

https://cloud.google.com/spanner/docs/schema-design#primary-key-prevent-hotspots
</div></details>

## Q. 1-8
あなたのチームは、Cloud Identityによって管理されるユーザーIDで実行されるGoogle Cloudアプリケーションを開発しています。アプリケーションの各ユーザは、メッセージが発行される関連する Pub/Sub トピックと、同じユーザが発行されたメッセージを取得する Pub/Sub サブスクリプションを持ちます。

許可されたユーザのみが、特定のPub/Subトピックとサブスクリプションにパブリッシュおよびサブスクライブできるようにする必要があります。
1. ユーザ ID に、pubsub.topics.create および pubsub.subscriptions.create 許可を含むカスタム・ロールを付与する。
2. pubsub.publisherおよびpubsub.subscriberロールを持つサービスアカウントとしてアプリケーションを実行するように構成する。
3. リソース・レベルでユーザ ID を pubsub.publisher および pubsub.subscriber ロールにバインドします。
4. プロジェクトレベルで、ユーザ ID に pubsub.publisher および pubsub.subscriber ロールを付与します。
<details><div>
    答え：3
A. pubsub.topics.create および pubsub.subscriptions.create パーミッションを含むカスタム・ロールをユーザ ID に付与すると、ユーザはトピックおよびサブスクリプションを作成できますが、特定のトピックまたはサブスクリプションへのアクセス権は付与されません。
B. pubsub.publisherロールとpubsub.subscriberロールを持つサービスアカウントとしてアプリケーションを実行するように構成すると、ユーザのきめ細かな権限管理ができません。
D. プロジェクト・レベルでユーザ ID に pubsub.publisher および pubsub.subscriber ロールを付与すると、ユーザはプロジェクト内のすべてのトピックおよびサブスクリプションにアクセスできるようになります。
正解
C. リソースレベルでユーザ ID を pubsub.publisher および pubsub.subscriber ロールにバインドすることで、各ユーザが特定の Pub/Sub トピックおよびサブスクリプションに対してのみパブリッシュおよびサブスクライブできるようにできます。このアプローチにより、きめ細かな権限管理が可能になり、各ユーザが許可されたリソースのみにアクセスできるようになります。
Link:

https://cloud.google.com/pubsub/docs/access-control
</div></details>

## Q. 1-9
最近、アプリケーションに影響する政府規制が可決されました。コンプライアンス目的のために、アプリケーションのプロジェクトからセキュリティチームに限定されたプロジェクトに、特定のアプリケーションログの複製を送信することが要求されるようになりました。

あなたは何をすべきでしょうか？
1. セキュリティチームのプロジェクトにユーザー定義のログバケットを作成する。クラウドロギングシンクを構成して、アプリケーションのログをセキュリティチームのプロジェクト内のログバケットにルーティングする。
2. 必要なログバケツからセキュリティチームのプロジェクトのログバケツにログをコピーするジョブを作成する。
3. デフォルトのログバケツのシンクルールを変更し、ログをセキュリティチームのログバケツに再ルーティングする。
4. 必要なログバケツのシステムイベントログを、セキュリティチームのプロジェクトのログバケツにコピーするジョブを作成する。
<details><div>
    答え：1
オプションB、C、およびDは、最も効果的な解決策ではありません。エラーが発生しやすい手動ジョブ（BとD）を含むか、デフォルトのバケツ（C）を変更するため、この規制の遵守に関連しない他のログに影響を与える可能性があります。
正解
このソリューションは、特定のアプリケーションのログを複製し、セキュリティチームのプロジェクトに送信するための直接的かつ自動化されたソリューションを提供します。この方法は、ログをログバケットや Pub/Sub トピックなどの他の宛先にルーティングするための強力なツールである Cloud Logging のシンク機能を使用します。シンクを使用することで、ログの複製がリアルタイムかつ自動的に実行され、手作業による介入とエラーのリスクを最小限に抑えることができます。

Links:

https://cloud.google.com/architecture/security-log-analytics
</div></details>

## Q. 1-10
あなたのチームはあなたの会社のためにeコマースプラットフォームを開発しています。ユーザーはウェブサイトにログインし、ショッピングカートに商品を追加します。ユーザーは30分間操作しないと自動的にログアウトします。ユーザーが再びログインすると、ショッピングカートが保存されます。

Googleが推奨するベストプラクティスに従い、ユーザーのセッション情報とショッピングカート情報をどのように保存すべきでしょうか？
1. Pub/Subにセッション情報を格納し、Cloud SQLにショッピングカート情報を格納する。
2. クラウドストレージ上のファイルにショッピングカート情報を保存する。
3. セッションとショッピングカートの情報を、複数のCompute Engineインスタンス上で動作するMySQLデータベースに保存します。
4. セッション情報をMemorystore for RedisまたはMemcachedに保存し、ショッピングカート情報をFirestoreに保存します。

<details><div>
    答え：4
A. Pub/Subはイベント・ストリーミングとメッセージング用に設計されており、セッション情報を管理するためのものではありません。Pub/Subにセッションデータを格納することは、効率的でない、あるいは従来のサービスの使い方ではないでしょう。Cloud SQLは完全に管理されたリレーショナルデータベースサービスであり、ショッピングカート情報を格納するために使用できますが、オプションDで述べたようにFirestoreを使用する方が適しています。
B. クラウドストレージのバケットにアクセスすると、セッション情報に対して時間がかかり、コストもかかります。これはGoogle Cloudのベストプラクティスではありません。
C. C. Compute Engineインスタンス間でMySQLデータベースを管理することはできますが、Memorystoreのようなスケーラビリティとセッション情報の低レイテンシアクセスを提供することはできません。これはGoogle Cloudのベストプラクティスではありません。
正解
D. eコマースプラットフォームのセッション情報とショッピングカート情報を保存する場合、スケーラビリティ、信頼性、セキュリティを考慮することが重要です。Googleが推奨するベストプラクティスに従ったソリューションの1つは、セッション情報の保存にMemorystore for RedisまたはMemcachedを使用し、ショッピングカート情報の保存にFirestoreを使用することです。

Memorystoreはセッション情報を保存し、大量の同時接続を簡単に処理することができます。これは、ユーザーが頻繁にログインし、ショッピングカートに商品を追加するeコマースプラットフォームにとって非常に重要です。

Firestoreは、ショッピングカート内のアイテムのような大量の半構造化データを容易に扱うことができます。また、Firestoreはスケーラブルで信頼性の高いソリューションであり、自動スケーリングとレプリケーションをサポートしています。

セッション情報とショッピングカート情報を異なるサービスに分離することで、セキュリティを高め、潜在的なデータ侵害を回避することができます。また、異なるサービスを使用することで、それらを独立して拡張することができます。

このことから、回答Dが最良の選択肢となります。

Links:

https://cloud.google.com/memorystore/docs/redis/redis-overview
</div></details>

## Q. 1-11
POSTで呼び出されるHTTPクラウド関数があります。各サブミッションのリクエストボディには、数値とテキストデータを含むフラットでネストされていない JSON 構造があります。クラウド関数が完了した後、収集されたデータは、多くのユーザーが並行して継続的かつ複雑な分析を行うためにすぐに利用できる必要があります。

どのようにサブミッションを永続化しますか？
1. 各POSTリクエストのJSONデータをDatastoreに直接永続化する。
2. POSTリクエストのJSONデータを変換し、BigQueryにストリームします。
3. POSTリクエストのJSONデータを変換し、地域のCloud SQLクラスタに格納する。
4. 各POSTリクエストのJSONデータを、リクエスト識別子を含むファイル名で、Cloud Storage内に個別のファイルとして永続化する
<details><div>
    答え：2
A. 各POSTリクエストのJSONデータをDatastoreに直接永続化する。DatastoreはNoSQLのドキュメントデータベースであり、構造化されたデータを格納するために使用できますが、ほぼリアルタイムで分析する必要がある大量のデータを処理するようには設計されていません。また、分析に使えるようにするには、追加の処理が必要になる。
C. Cloud SQLはデータの永続性を処理できるが、多数の並列ユーザーを持つ複雑な分析にはBigQueryほど効率的ではないかもしれない。
D. 各 POST リクエストの JSON データを個別のファイルとして Cloud Storage 内に保存することは、即時かつ複雑な分析には非効率的です。
正解
B. BigQueryは拡張性の高いデータウェアハウスであり、大量のデータや複雑な分析をほぼリアルタイムで処理するのに適しています。クラウド機能からのJSONデータを直接BigQueryにストリーミングすることで、収集したデータを即座に多くのユーザーが並行して分析できるようになります。BigQueryはJSONを含む様々なデータ型をサポートしているため、リクエストボディを変換することなく保存できます。
Links:

https://cloud.google.com/bigquery/docs/streaming-data-into-bigquery
</div></details>

## Q. 1-12
あなたは複数のルームをホストし、各ルームのメッセージ履歴を保持するチャットルームアプリケーションを設計しています。あなたはデータベースとしてFirestoreを選択しました。

Firestoreのデータをどのように表現する必要がありますか？



A. ルーム用のコレクションを作成します。各ルームについて、メッセージの内容をリストするドキュメントを作成します。
1. 部屋のコレクションを作成する。各部屋に対して、メッセージの内容をリストしたドキュメントを作成する。
2. 部屋ごとにコレクションを作成する。部屋ごとに、各メッセージのドキュメントを含むコレクションを作成する。
3. 部屋用のコレクションを作成する。各部屋に対して、ドキュメント用のコレクションを含むドキュメントを作成し、各ドキュメントにはメッセージが含まれます。
4. 部屋用のコレクションを作成し、各部屋用のドキュメントを作成する。メッセージ用に別のコレクションを作成し、メッセージごとに1つのドキュメントを作成します。各部屋のドキュメントには、メッセージへの参照のリストが含まれます。
<details><div>
    答え：3
A. この方法は、各部屋のメッセージ数が多い場合、全てのメッセージを一つのドキュメントに収めようとするため、うまく拡張できません。
B. 部屋用のコレクションは、それぞれメッセージのサブコレクションを持ち、多対多のリレーションシップを作成します。
D. このアプローチでは、部屋とメッセージを異なるコレクションに分離しますが、それらの間の参照を維持する必要があります。
正解
C. このシナリオでメッセージを格納する最善の方法は、サブコレクションを使用することです。サブコレクションは、特定のドキュメントに関連付けられたコレクションです。
Links:

https://firebase.google.com/docs/firestore/data-model#hierarchical-data

https://firebase.google.com/docs/firestore/data-model#subcollections
</div></details>

## Q. 1-13
本番環境にデプロイされたアプリケーションがあります。新しいバージョンがデプロイされたとき、いくつかの問題は、アプリケーションが本番環境のユーザからトラフィックを受けるまで発生しません。影響と影響を受けるユーザ数の両方を減らしたい。

どのデプロイメント戦略を使用すべきですか?
1. ブルー／グリーン・デプロイメント
2. カナリア展開
3. ローリングデプロイメント
4. デプロイメントの再作成
<details><div>
    答え：2
A. このアプローチでは、2つの別々の環境（実行中のバージョンはブルー、新しいバージョンはグリーン）を切り替えることができます。全員にロールアウトする前に、問題を検出するために一部のユーザーでテストすることは特にできません。
C. ローリング デプロイメントでは、インスタンスを次々に段階的に更新します。段階的なロールアウトが可能ですが、Canaryデプロイメントのように特定のユーザ サブセットを対象としていないため、ユーザ固有の問題を検出するのには適していません。
D. この方法では、古いバージョンを削除し、新しいバージョンをデプロイする。すべてのインスタンスが同時に置き換えられるため、影響を軽減し、ユーザーのサブセットでテストするという要件には適合しません。
正解
B. カナリア配置では、新バージョンを少人数のユーザに徐々にリリースしてから、すべてのユーザに使用できるようにします。これにより、本番環境の実際のユーザーで新バージョンの動作をテストできますが、対象者が限定されるため、潜在的な問題の影響と影響を受けるユーザー数の両方を減らすことができます。これは、説明した状況に適しています。
Links:

https://cloud.google.com/architecture/application-deployment-and-testing-strategies#canary_test_pattern
</div></details>

## Q. 1-14
Stackdriver Logging Agentを使用して、アプリケーションのログファイルをCompute Engine仮想マシンインスタンスからStackdriverに送信したいとします。
Stackdriver Logging Agentをインストールした後、最初に何をすべきですか？
1. プロジェクトのエラー報告APIを有効にする。
2. インスタンスにすべてのクラウドAPIへのフルアクセスを許可する。
3. アプリケーションログファイルをカスタムソースとして設定します。
4. アプリケーションのログエントリに一致するフィルタを使用して、Stackdriver ログエクスポートシンクを作成します。
<details><div>
    答え：3
A. これはコンテキストによっては便利ですが、Stackdriver にログを送信するためのロギングエージェントをインストールした直後のステップではありません。
B. すべてのクラウドAPIへのフルアクセスを許可するのは過剰であり、Stackdriverにログを送信するために必要ではない。ロギングに関連する特定のパーミッションが必要ですが、通常これらはインスタンスに関連するサービスアカウントに割り当てられたロールとパーミッションによって管理されます。
D. シンクを使用してログをエクスポートすることは、ログを異なる宛先（BigQuery、Pub/Sub など）にルーティングする方法であり、特定のアプリケーションログファイルからログを収集するためにエージェントを設定するタスクとは関係ありません。
正解
C. これは正しい次のステップです。ログファイルをカスタムソースとして構成することで、エージェントはログを探す場所と処理方法を知ることができます。したがって、オプション C は、Stackdriver Logging Agent をインストールした後に実行する最も適切なステップです。
Links:

https://cloud.google.com/logging/docs/agent/configuration

https://cloud.google.com/logging/docs/agent/configuration#streaming_logs_from_additional_inputs
</div></details>

## Q. 1-15
あなたの会社には「Master」という名前のBigQueryデータセットがあり、そこには従業員の部署別に整理された、従業員の出張と経費に関する情報が含まれています。従業員は各部門の情報しか閲覧できないようにする必要があるため、セキュリティフレームワークを適用して、最小限のステップ数でこの要件を実施したいとします。

どうすればよいでしょうか。
1. 部門ごとに個別のデータセットを作成する。適切なWHERE句を指定してビューを作成し、特定の部門の特定のデータセットからレコードを選択する。このビューに、マスターデータセットからレコードにアクセスする権限を与える。従業員にこの部門別データセットへのアクセス権限を与える。
2. 部門ごとに個別のデータセットを作成する。部門ごとにデータパイプラインを作成し、マスターデータセットから部門固有のデータセットに適切な情報をコピーする。従業員にこの部門別データセットへのアクセス権を与える。
3. マスター」データセットという名前のデータセットを作成する。マスターデータセットの中に、部署ごとに個別のビューを作成する。従業員に、所属する部署に特化したビューへのアクセス権を与える。
4. マスター・データセットという名前のデータセットを作成する。マスター・データセットの中に、部門ごとに個別のテーブルを作成する。従業員には、所属する部門のテーブルにアクセスできるようにする。
<details><div>
    答え：3
A.この方法では、データセットとビューを別々に作成し、適切なアクセス制御を行います。柔軟なアプローチですが、特に基礎となるデータ構造が変更された場合、管理が複雑になる可能性があります。
B.オプションAと同様に、部署ごとに個別のデータセットを作成する。データパイプラインの使用は複雑さを増し、データが重複することで整合性に問題が生じる可能性がある。
D.この方法では、「マスター」データセット内に個別のテーブルを作成する。オプションCと同様に、すべてを単一のデータセット内に保持しますが、テーブルごとのアクセス制御をより慎重に管理する必要があります。
正解
C.この方法では、既存の「マスター」データセットの中にビューを作成し、部門ごとのニーズに合わせてアクセスできるようにします。実装と管理が最も簡単で、セキュリティと使いやすさのバランスがよく、ステップ数も最小限で済む。
Links:

https://cloud.google.com/bigquery/docs/share-access-views
</div></details>

## Q. 1-16
あなたのチームは、クラウドストレージイベントをトリガーとするクラウド機能を開発しています。Googleが推奨するベストプラクティスに従いつつ、クラウド機能のテストと開発を加速したい。

どうすればよいでしょうか？
1. クラウド監査ログが元のクラウド関数のcloudfunctions.functions.sourceCodeSet操作を検出したときにトリガされる新しいクラウド関数を作成します。新しい関数にモック要求を送信して、機能を評価します。
2. クラウド関数のコピーを作成し、HTTPトリガーになるようにコードを書き換えます。新しいバージョンを編集し、HTTPエンドポイントをトリガーしてテストする。新しい関数にモックリクエストを送り、機能を評価する。
3. Functions Frameworksライブラリをインストールし、localhost上でCloud Functionを構成します。関数のコピーを作成し、新しいバージョンに編集します。curlを使用して新しいバージョンをテストします。
4. Google CloudコンソールでCloud Functionのコピーを作成する。クラウド コンソールのインライン エディタを使用して、新しい関数にソース コードを変更します。新しい関数を呼び出すように Web アプリケーションを変更し、新しいバージョンを実運用環境でテストします。
<details><div>
    答え：3
不正解
A. 特定の操作でトリガーされる新しいクラウド関数を作成することは、元の関数をテストする間接的な方法であり、この目的には効率的でないかもしれません。
B. クラウド関数のコピーを作成し、HTTPトリガーに書き換えることで、テストにHTTPリクエストを使用できます。ただし、この方法では元のクラウド ストレージ イベント動作を複製するための追加作業が必要になる場合があります。
D. Google Cloud コンソールでクラウド関数のコピーを作成し、新しいバージョンを本番環境でテストすることは、テストと開発のベストプラクティスに合致しません。本番環境にエラーをもたらすリスクがあります。
正解
C. Functions Frameworks ライブラリを使用すると、Cloud Function をローカルで実行してテストすることができ、実際の Cloud Function ランタイムに似た環境を提供できます。関数に変更を加え、curl などのツールを使用してテストできるので、開発サイクルを短縮できます。
Links:

https://cloud.google.com/functions/docs/running/calling#cloudevent_functions

https://cloud.google.com/functions/docs/running/overview#choosing_an_abstraction_layer
</div></details>

## Q. 1-17
あなたは、Cloud RunとFirestoreのDatastoreモードで動作する新しい小売システムの開発リーダーです。Web UI の要件は、ユーザーがシステムにアクセスしたときに利用可能な商品のリストを表示し、ユーザーがすべての商品を閲覧できることです。この要件は、最小実行可能製品（MVP）の段階で、Firestoreに格納されているすべての利用可能な製品のリストを返すことによって実装されました。



本稼働から数カ月後、Cloud Run インスタンスが HTTP 500 で終了していることに気づきました： Container instances are exceeding memory limits エラーで終了することに気づきました。このエラーは、データストア・エンティティの読み取り数の急増と一致します。Cloud Runのクラッシュを防ぎ、Datastoreエンティティの読み取り回数を減らす必要があります。システムパフォーマンスを最適化するソリューションを使用したい。

どうすればよいでしょうか？
1. 整数オフセットを使用して商品リストを返すクエリを修正してください。
2. 制限を使用して、商品リストを返すクエリを変更します。
3. Cloud Runの設定を変更してメモリ制限を増やす。
4. カーソルを使用して商品リストを返すクエリを修正します。
<details><div>
    答え：4
不正解
A. データ・ストア・モードのデータベースは整数オフセットをサポートしていますが、オフセットの使用は避けて、代わりにカーソルを使用してください。オフセットを使用すると、アプリケーションにスキップされたエンティティを返さずに済みますが、これらのエンティティは内部的に取得されます。これらのスキップされたエンティティはクエリの待ち時間に影響し、アプリケーションはそれらを取得するために必要な読み取り操作に対して課金されます。オフセットの代わりにカーソルを使用することで、これらのコストを全て回避することができます。
B. クエリで制限を使用すると、1回の応答で返される結果の数が制限されますが、複数の要求間の状態は管理されません。そのため、多くの商品があり、ユーザーがそれらすべてを閲覧できるようにしたい場合、単に結果を制限するだけでは、リスト全体を効率的にページ分割する方法は提供されません。それぞれの新しいリクエストは最初から始まり、最後のリクエストの続きから続ける効率的な方法はありません。
C. クラウド・ラン・インスタンスのメモリ制限を増やすことで、この問題を一時的に軽減することはできますが、問題の根本的な原因（ビジー時のデータストア・エンティティの読み取り数の多さ）には対処できません。時間が経つにつれて、より多くの製品がシステムに追加されるにつれて、この問題はより深刻になり、Cloud Runがクラッシュするのを防ぐためにメモリ制限を継続的に増やす必要があります。
正解
D. カーソルを使用して結果をページ分割し、一度に限られた数の製品を取得することは、より持続可能なソリューションを提供します。データストアから読み込む必要があるデータ量を減らし、Cloud Runインスタンスのメモリ使用量を減らします。このようにして、システムのパフォーマンスを維持し、時間の経過とともに製品が追加されてもクラッシュするのを防ぐことができます。
Links:

https://cloud.google.com/datastore/docs/concepts/queries#cursors
</div></details>

## Q. 1-18
貴社は新しいAPIをCompute Engineインスタンスにデプロイしました。テスト中、APIが期待通りに動作しません。アプリケーションを再デプロイすることなく、アプリケーションコード内の問題を診断するために、12時間にわたってアプリケーションを監視したい。

どのツールを使用すべきでしょうか？
1. クラウドトレース
2. クラウド監視
3. クラウドデバッガーのログポイント
4. クラウド・デバッガ・スナップショット
<details><div>
    答え：3
A. レイテンシの分析に重点を置いており、再デプロイせずにアプリケーションコード内の問題を診断することに特化して設計されていないため、質問の要件を満たしていない。
B. システムのパフォーマンスを監視するのに便利ですが、シナリオが求めている、ログステートメントを挿入したり、再デプロイせずにアプリケーションコードの動作を分析したりすることはできません。
D. スナップショットは、12時間にわたって監視するよりも、特定の時点でのアプリケーションの状態を分析するのに適しています。このシナリオにはあまり適していません。
正解
C. アプリケーションをデプロイまたは起動した後、Google Cloud コンソールで Cloud Debugger を開くことができます。Cloud Debugger Logpoints を使用すると、サービスの通常の機能を再起動または妨害することなく、実行中のサービスにロギングを注入できます。これは、ログステートメントを追加して再デプロイすることなく、運用上の問題をデバッグするのに便利です。
Link: https://cloud.google.com/debugger/docs/using/logpoints
</div></details>

## Q. 1-19
御社の開発チームは、プロジェクトでCloud Buildを使用してDockerイメージをビルドし、Container Registryにプッシュしたいと考えています。運用チームは、すべてのDockerイメージを、運用チームが管理する一元化された安全に管理されたDockerレジストリに公開する必要があります。

どうすればいいでしょうか？
1. Container Registryを使用して、各開発チームのプロジェクトにレジストリを作成します。プロジェクトのレジストリにDockerイメージをプッシュするようにCloud Buildビルドを構成します。運用チームに各開発チームのレジストリへのアクセス権を付与します。
2. Container Registryを設定した運用チーム用の別のプロジェクトを作成します。各開発チームのプロジェクトのCloud Buildサービスアカウントに適切な権限を割り当て、運用チームのレジストリへのアクセスを許可する。
3. Container Registryを設定した運用チーム用の別のプロジェクトを作成します。各開発チームにサービスアカウントを作成し、運用チームのレジストリへのアクセスを許可する適切な権限を割り当てます。サービスアカウントのキーファイルをソースコードリポジトリに格納し、運用チームのレジストリに対する認証に使用します。
4. Compute Engineの仮想マシンインスタンス上にオープンソースのDockerレジストリをデプロイした、運用チーム用の別のプロジェクトを作成します。開発チームごとにユーザー名とパスワードを作成します。ユーザー名とパスワードをソースコードリポジトリに保存し、運用チームのDockerレジストリに対する認証に使用する。

<details><div>
    答え：2
不正解
オプションA：運用チームに各開発チームのレジストリへのアクセスを許可する必要があり、安全でない可能性があるため、理想的ではありません。
オプションC：サービスアカウントのキーファイルをソースコードリポジトリに保存する必要があり、安全でない可能性があるため、最適な選択ではない。
オプションD：オープンソースのDockerレジストリを使用し、各開発チームのユーザー名とパスワードを作成する必要があるため、これは最良の選択ではありません。
正解
Bは、運用チームが集中管理され安全に管理されたDockerレジストリを制御できる一方で、開発チームがプロジェクトでCloud Buildを使用できるようになるため、最良の選択です。このオプションでは、運用チームはContainer Registryが設定された別のプロジェクトを作成し、各開発チームのプロジェクトでCloud Buildサービスアカウントに適切な権限を付与して、運用チームのレジストリへのアクセスを許可することができます。このアプローチにより、開発チームは運用チームの要件を順守しながら、Dockerイメージをビルドして集中レジストリにプッシュすることができます。
Links:

https://cloud.google.com/container-registry/

https://stackoverflow.com/questions/48602546/google-cloud-functions-how-to-securely-store-service-account-private-key-when
</div></details>

## Q. 1-20
アプリケーションは複数のGoogle Kubernetes Engineクラスタで実行されている。各クラスタの Deployment によって管理されています。Deploymentは各クラスタにPodの複数のレプリカを作成しています。あなたは、すべてのクラスタのあなたのDeployment内のすべてのレプリカの標準出力に送信されたログを表示したいと思います。

どのコマンドを使用する必要がありますか?
1. kubectl logs [PARAM].
2. gcloud logging read [PARAM].
3. kubectl exec -it [PARAM] journalctl
4. gcloud compute ssh [PARAM] --command='sudo journalctl' 
<details><div>
    答え：2
不正解
A. すべてのクラスタのすべてのレプリカのログを表示する機能はありません。
C. は特定のPod内でコマンドを実行するために使用され、Deployment内のすべてのレプリカからログを取得するために使用されるわけではありません。
D. は、Compute EngineインスタンスにSSH接続してコマンドを実行するために使用され、GKEデプロイメントからログを取得するために使用されません。
正解
https://cloud.google.com/blog/products/management-tools/using-logging-your-apps-running-kubernetes-engine: "gcloud コマンドラインツール - gcloud logging read コマンドを使用して、適切なクラスタ、ノード、ポッド、およびコンテナのログを選択します。"
Links:

https://cloud.google.com/logging/docs/reference/tools/gcloud-logging#examples_2

https://cloud.google.com/blog/products/management-tools/using-logging-your-apps-running-kubernetes-engine

https://stackoverflow.com/questions/62007471/how-to-view-container-logs-via-stackdriver-on-gke
</div></details>

## Q. 1-21
あなたは最近新しいアプリケーションを開発し、Dockerfileを使わずにCloud Run上にデプロイしたいと考えています。

すべてのコンテナイメージは一元管理されたコンテナリポジトリにプッシュされなければならないという組織の要件を考慮すると、Google Cloudサービスを使ってどのようにコンテナを構築すべきでしょうか？(2つの選択肢を選んでください)
1. ソースコードをArtifact Registryにプッシュします。
2. イメージをプッシュするためにクラウドビルドジョブを送信します。
3. pack CLIでpack buildコマンドを使用します。
4. gcloud run deploy CLIコマンドに-sourceフラグを含める。
5. gcloud run deploy CLIコマンドに--platform=kubernetesフラグを含める。
<details><div>
    答え：3,4
不正解
選択肢A：Artifact Registryはソースコードではなくコンテナイメージ用に設計されているため、不正解です。
選択肢B：ビルドされたイメージのみをCloud Runにデプロイする必要があるため、不正解です。一元管理されたコンテナリポジトリ」はGoogleの外部にある可能性があるため、ビルドツールは必ずしもCloud Buildとは限らない。
オプション E：Kubernetes（K8S）は設問に関係ないので、この場合は関係ありません。
正解
オプション C：Google Cloud は buildpacks をサポートしています。これは、Dockerfile を必要とせず、ソース コードから安全で本番環境に適したコンテナ イメージを迅速かつ容易に作成するオープン ソース テクノロジーです。https://cloud.google.com/blog/products/containers-kubernetes/google-cloud-now-supports-buildpacks

オプションD：ソースコードからのデプロイはCloud Runで可能です。単一のgcloud CLIコマンド、gcloud run deploy、-sourceフラグを使用して、ソースコードから新しいサービスや新しいリビジョンを直接デプロイできます。

Links:

https://cloud.google.com/run/docs/deploying-source-code

https://cloud.google.com/blog/products/containers-kubernetes/google-cloud-now-supports-buildpacks
</div></details>

## Q. 1-22
あなたは最近Cloud Runで新しいサービスを開発しました。新しいサービスはカスタムサービスを使用して認証し、トランザクション情報をCloud Spannerデータベースに書き込みます。発生する可能性のあるボトルネックを特定しながら、アプリケーションが1秒あたり最大5,000の読み取りトランザクションと1,000の書き込みトランザクションをサポートできることを検証する必要があります。また、テストインフラはオートスケールできなければなりません。

どうすればよいでしょうか？
1. リクエストを生成するテストハーネスを構築し、Cloud Runにデプロイします。クラウドロギングを使用してVPCフローログを分析します。
2. 負荷テストを動的に生成するために、LocustまたはJMeterイメージを実行しているGoogle Kubernetes Engineクラスタを作成します。Cloud Traceを使用して結果を分析します。
3. テスト負荷を生成するためにクラウドタスクを作成します。Cloud Schedulerを使用して、毎分60,000のCloud Taskトランザクションを10分間実行します。Cloud Monitoringを使用して結果を分析します。
4. マーケットプレイスからLAMPスタックイメージを使用するCompute Engineインスタンスを作成し、Apache Benchを使用してサービスに対する負荷テストを生成する。Cloud Traceを使って結果を分析する。
<details><div>
    答え：2
不正解
A. テストハーネスをCloud Runにデプロイすることは、負荷テストにとって理想的なアプローチではありません。また、VPCフローログは、アプリケーションのパフォーマンス分析よりもむしろネットワークのモニタリングに適しています。
C. Cloud TaskとCloud Schedulerを使用すると、特に異なるシナリオをテストするために負荷を動的に変化させる必要がある場合、1秒間に必要な読み取りと書き込みのトランザクション数をシミュレートするには柔軟性に欠ける可能性があります。
D. Apache Benchを使用する単一のCompute Engineインスタンスでは、必要な1秒あたりのトランザクション数に達するのに十分な負荷を生成できない可能性があります。さらに、マーケットプレイスからのLAMPスタックイメージは、Cloud Runサービスのテストの要件とは無関係です。
正解
B. アプリケーションが1秒あたり最大5,000の読み取りトランザクションと1,000の書き込みトランザクションをサポートできることを確認し、発生する可能性のあるボトルネックを特定するには、LocustやJMeterなどの負荷テストツールを使用してCloud Runサービスの負荷テストを生成します。これらのツールを使用すると、多数の同時リクエストをシミュレートすることができ、サービスが処理できる最大リクエスト数を決定するのに役立ちます。

負荷テストツールをGoogle Kubernetes Engine (GKE)クラスタ上で実行することで、オートスケール機能を提供することができます。こうすることで、大量のリクエストを管理し、Cloud Traceを使って結果を分析することができる。この分析により、パフォーマンスに関する洞察が得られ、ボトルネックの特定に役立つ。
Links:

https://cloud.google.com/architecture/distributed-load-testing-using-gke
</div></details>

## Q. 1-23
あなたは、ユーザーに静的コンテンツを提供する、高可用性でグローバルにアクセス可能なアプリケーションを構築しています。ストレージとサービング・コンポーネントを構成する必要があります。管理オーバーヘッドとレイテンシを最小限に抑えつつ、ユーザーの信頼性を最大化したい。

どうすればよいでしょうか。
1. 
2. 
3. 
4. ① Standardストレージクラスで、マルチリージョンのCloud Storageバケットを作成します。静的コンテンツをバケットに入れます。② 外部IPアドレスを予約し、外部HTTP(S)ロードバランサーを作成する。③ Cloud CDNを有効にし、バックエンドバケットにトラフィックを送る。
<details><div>
    答え：4
正解
オプションAおよびオプションB：インスタンスグループ（管理対象か非管理対象かにかかわらず）に依存すると、VM間で静的コンテンツを複製して維持するために、より多くの管理オーバーヘッドが必要になります。また、提供された問題ではスケーリングは必要ありません。
選択肢C：リージョナルバケットを使用すると、データがリージョン内の2つの特定の場所に制限されるため、世界中のユーザーに対するグローバルなアクセシビリティと低レイテンシが保証されません。
正解
オプション D.
1. Standardストレージクラスで、マルチリージョンのCloud Storageバケットを作成します。静的コンテンツをバケットに入れます。
2. 外部IPアドレスを予約し、外部HTTP(S)ロードバランサーを作成する。
3. Cloud CDNを有効にし、バックエンドバケットにトラフィックを送る。
静的コンテンツをグローバルに、レイテンシと管理オーバーヘッドを最小限に抑えて配信するには、マルチリージョンのCloud StorageバケットのようにGoogle Cloudのグローバル分散システムを活用し、Cloud CDNでキャッシュするのが最適なソリューションです。オプションDが最良の選択である理由は以下の通りです：
* マルチリージョンのバケットは、コンテンツが複数のリージョンに冗長的に保存されることを保証し、高可用性と低レイテンシーでのグローバルアクセスを提供します。
* 外部のHTTP(S)ロードバランサーは、ユーザーのリクエストを最も近いグローバルロケーションに自動的にルーティングする。
* Cloud CDNは、Googleの高度に分散されたエッジキャッシングを活用し、エンドユーザーの待ち時間を最小限に抑えます。
Links:

https://cloud.google.com/storage/docs/hosting-static-website

https://cloud.google.com/load-balancing/docs/https
</div></details>

## Q. 1-24
オンプレミスのLinux仮想マシン（VM）で稼働しているスタンドアロンJavaアプリケーションを、費用対効果の高い方法でGoogle Cloudに移行する必要があります。リフト・アンド・シフトのアプローチはとらず、コンテナに変換してアプリケーションを最新化することにしました。

このタスクをどのように達成すべきでしょうか。
1. Migrate for Anthosを使用して、VMをコンテナとしてGoogle Kubernetes Engine（GKE）クラスタに移行します。
2. VM を raw ディスクとしてエクスポートし、イメージとしてインポートします。インポートしたイメージからCompute Engineインスタンスを作成します。
3. Migrate for Compute Engineを使用してVMをCompute Engineインスタンスにマイグレートし、Cloud Buildを使用してコンテナに変換する。
4. Jibを使用してソースコードからDockerイメージを構築し、Artifact Registryにアップロードします。アプリケーションをGKEクラスタにデプロイし、アプリケーションをテストします。
<details><div>
    答え：4
不正解
Migrate for Anthosを使用するオプションAは、VMをGKEに移行しますが、これはリフト・アンド・シフトのアプローチであり、必ずしもアプリケーションの近代化を伴うものではありません。

オプションBは、VMをRAWディスクとしてエクスポートし、イメージとしてインポートするもので、コンテナ化を伴わず、VMをクラウドに複製することに関連します。

Migrate for Compute Engineを使用してVMをCompute Engineに移行し、Cloud Buildを使用するオプションCは、コンテナ化されたソリューションにつながるかもしれませんが、指定されたタスクにとって必要以上に複雑です。
正解
Jibを使用してソースコードからDockerイメージを構築するオプションDは、ソースコードから直接コンテナ化されたイメージを構築することで、より現代的なアプローチを可能にします。また、GKEでのデプロイも含まれており、コンテナベースのアーキテクチャに移行するという目標に合致しています。Jibは、Javaコンテナ・イメージを構築するために特別に設計されたMaven/Gradleプラグインであり、このJavaアプリケーションの移行に適した選択肢となっている。

指定されたシナリオでは、VMを単に持ち上げて移行するのではなく、コンテナに変換することでアプリケーションを最新化することが目標であるため、オプションDが最も適切なアプローチとなります。
Links:

https://cloud.google.com/blog/products/application-development/introducing-jib-build-java-docker-images-better
</div></details>

## Q. 1-25
Compute Engineにアプリケーションをデプロイしています。Compute Engineインスタンスの1つが起動に失敗しました。

あなたは何をすべきですか？(2つのオプションを選択してください)
1. ファイルシステムが壊れているかどうかを判断します。
2. 別のSSHユーザーとしてCompute Engineにアクセスします。
3. インスタンスのファイアウォールルールまたはルートをトラブルシューティングします。
4. インスタンスのブートディスクが完全に一杯になっていないか確認してください。
5. インスタンスへの、またはインスタンスからのネットワークトラフィックがドロップされていないかチェックする。
<details><div>
    答え：1,4
不正解：
オプションAは文脈によっては関連するかもしれませんが、インスタンスの起動に失敗する原因である可能性は低いです。
オプションBは、SSHユーザーが起動プロセスに影響を与えることはないため、インスタンスの起動失敗を解決する可能性は低い。
オプションEは、起動そのものというよりも、起動後のネットワーク通信に関連しています。
正解です：

Links:

https://cloud.google.com/compute/docs/troubleshooting/vm-startup
</div></details>

## Q. 1-26
500 MB のファイル サイズ制限がある内部ファイル アップロード API を App Engine に移行する必要があります。

どうすればよいでしょうか。
1. FTPを使用してファイルをアップロードします。
2. CPanelを使用してファイルをアップロードします。
3. 署名付きURLを使用してファイルをアップロードする。
4. APIをマルチパートのファイルアップロードAPIに変更する。
<details><div>
    答え：3
不正解
オプションA（FTP）は、App Engineのようなクラウド環境における一般的なプラクティスに合致しません。
オプションB（CPanel）は、プログラムでファイルアップロードを処理することとは関係ありません。
オプションD（マルチパートファイルアップロードAPI）は可能な解決策かもしれませんが、特に指定されたファイルサイズ制限やApp Engine環境に対応していません。
正解
署名付きURLを使用してファイルをアップロードするオプションCは、これらの選択肢の中で最良のアプローチです。署名付きURLは、特に大きなファイルを扱う場合に、ファイルアップロードを安全かつ効率的に処理する方法を提供します。これにより、特定のクラウドリソース（この場合はファイルをアップロードする機能）への一時的なアクセスをユーザーに与えることができます。Google Cloud Storageは署名付きURLをサポートしており、App Engineと組み合わせてファイルアップロードを処理できます。署名付きURLを作成することで、App Engineサーバーでファイルを処理することなく、クライアントがCloud Storageのバケットに直接ファイルをアップロードすることを許可できます。

したがって、正解は C
Links:

https://cloud.google.com/storage/docs/access-control/signed-urls

https://cloud.google.com/appengine/docs/standard/php/googlestorage/user_upload
</div></details>

## Q. 1-27
アプリケーションは Stackdriver にログを記録している。すべての /api/alpha/* エンドポイント上のすべてのリクエストのカウントを取得したい。

どうすればいいでしょうか？
1. path:/api/alpha/のStackdriverカウンタ・メトリックを追加します。
2. endpoint:/api/alpha/*のStackdriverカウンタ・メトリックを追加します。
3. ログをクラウドストレージにエクスポートし、/api/alphaに一致する行を数えます。
4. ログをCloud Pub/Subにエクスポートし、/api/alphaに一致する行をカウントする。
<details><div>
    答え：2
不正解
A. このオプションは、ワイルドカード文字を使用せずに特定のパスを参照するため、意図したとおりに動作しない可能性があります。
C. ログをクラウドストレージにエクスポートして行数をカウントすることは、これを達成するための非効率的な方法であり、オペレーションスイートのリアルタイムの監視およびアラート機能を活用することはできない。
D. ログをCloud Pub/Subにエクスポートして行数をカウントすることは、同様に非効率的であり、オペレーション・スイート内で利用可能なツールをフルに活用できません。
正解
B. オプションBは、指定されたエンドポイントに対する要求のカウントを取得するためにGoogle Cloud Loggingでカウンターメトリックを作成するための正しい答えです。

Links:

https://cloud.google.com/logging/docs/logs-based-metrics/counter-metrics#console
</div></details>

## Q. 1-28
Google Kubernetes Engine（GKE）にデプロイメントを設定する必要がある。コンテナがデータベースに接続できることを確認するチェックを含めたい。Podが接続に失敗した場合、コンテナ上でスクリプトを実行し、グレースフル・シャットダウンを完了させたい。

デプロイはどのように構成すればよいですか？
1. 1つはコンテナがデータベースに接続できるかどうかをチェックするジョブ、もう1つはPodが失敗している場合にシャットダウンスクリプトを実行するジョブです。
2. コンテナがデータベースに接続できない場合に失敗する、コンテナ用の livenessProbe を含む配置を作成します。コンテナが失敗している場合にシャットダウンスクリプトを実行する Prestop ライフサイクルハンドラを構成します。
3. サービスの可用性をチェックするPostStartライフサイクル・ハンドラを使用してデプロイメントを作成します。コンテナに障害が発生した場合にシャットダウンスクリプトを実行するPreStopライフサイクルハンドラを構成する。
4. サービスの可用性をチェックする initContainer を使用して配置を作成します。Pod に障害が発生した場合にシャットダウン スクリプトを実行する Prestop ライフサイクル ハンドラを構成します。
<details><div>
    答え：2
不正解
A. ジョブは通常バッチ処理に使用され、継続的な監視や実行中のコンテナのグレースフル・シャットダウンの処理には適していません。
C. PostStart ハンドラーは、コンテナの起動直後に 1 回だけ実行され、データベースへの接続を継続的に監視することはない。また、条件（たとえば、ライブネス・プローブの失敗）なしで PreStop ハンドラを構成することは、コンテナが失敗している場合にのみシャットダウン・スクリプトを実行する必要性に合致しない。
D. そのため、initContainer を使用すると、コンテナの実行後にデータベース接続を継続的に監視できなくなります。また、Podが初期化された後に失敗している場合にスクリプトを実行するという要件にも合致しません。
正解
B. コンテナがデータベースに接続できない場合に失敗するコンテナ用の livenessProbe を使用して、配置を作成します。liveness probeを利用することで、Kubernetesはデータベースへの接続を継続的にチェックできる。コンテナがデータベースへの接続に失敗すると、livenessプローブが失敗し、Kubernetesがコンテナを再起動するトリガーとなる。

コンテナが失敗している場合にシャットダウンスクリプトを実行するPreStopライフサイクルハンドラを設定する。Kubernetesのドキュメントによると、PreStopフックは、APIリクエスト、livenessプローブの失敗、その他の管理イベントなど、さまざまな理由でコンテナが終了する直前に呼び出される。PreStopフックは、Google Cloudのベストプラクティスで言及されているように、アプリケーションを修正せずにグレースフル・シャットダウンをトリガーするための良い選択肢です。 このフックは、コンテナを停止するTERMシグナルを送信する前に完了する必要があります。Podの終了猶予期間のカウントダウンは、PreStopフックが実行される前に始まるため、ハンドラの結果にかかわらず、コンテナは最終的にPodの終了猶予期間内に終了します。

これら2つの機能を組み合わせることで、コンテナがデータベースへの接続性を継続的に監視し、コンテナに障害が発生した場合にグレースフル・シャットダウンスクリプトが実行されるようにすることができます。
Links:

https://cloud.google.com/architecture/best-practices-for-running-cost-effective-kubernetes-applications-on-gke#make_sure_your_applications_are_shutting_down_in_accordance_with_kubernetes_expectations



https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#hook-details
</div></details>

## Q. 1-29
アプリケーションを、Stackdriver Monitoring AgentがインストールされたCompute Engine仮想マシンインスタンスにデプロイしています。アプリケーションはインスタンス上のunixプロセスです。unixプロセスが少なくとも5分間実行されなかった場合、アラートが必要です。メトリクスやログを生成するようにアプリケーションを変更することはできません。

どのアラート条件を構成しますか?
1. アップタイム・チェック
2. プロセスの健全性（Process health）
3. メトリックの不在（Metric absence）
4. メトリックしきい値（Metric threshold）
<details><div>
    答え：2
不正解
A. これは、マシン上の特定のプロセスではなく、Webサーバなどのネットワーク・エンドポイントの可用性を監視するために使用されます。
C. これは、プロセスの不在ではなく、特定のメトリックのデータの不在を指す。これはより複雑なシナリオで使用されるかもしれないが、プロセスの健全性を監視するようには直接設計されていない。
D. これは、特定のメトリック値が特定のしきい値を超えたことに基づいてアラートを設定することができますが、特定のプロセスが実行されているかどうかをチェックするようには設計されていません。
正解
B. 説明するシナリオでは、特定のUnixプロセスを監視し、そのプロセスが少なくとも5分間実行されていない場合にアラートを出したいとします。プロセスの有無を監視しているので、適切なアラート条件はプロセスの健全性です。

Stackdriverモニタリング・エージェントは、システムとプロセスのメトリクスを監視することができ、このタイプのアラートは、特にUnixプロセスの健全性を追跡します。

Links:

Behavior of metric-based alerting policies | Cloud Monitoring
</div></details>

## Q. 1-30
貴社は新しい API を App Engine Standard 環境にデプロイしました。テスト中、API が期待どおりに動作しません。アプリケーションを再デプロイすることなく、アプリケーション コード内の問題を診断するために、アプリケーションを長期にわたって監視したいとします。

どのツールを使用すべきでしょうか?
1. スタックドライバートレース
2. スタックドライバ・モニタリング
3. Stackdriver デバッグ・スナップショット
4. スタックドライバ・デバッグ・ログポイント
<details><div>
    答え：4
不正解
A. Stackdriver Trace は、リクエストがアプリケーションをどのように伝搬するかを分析し、これらのリクエストの待ち時間を測定するために使用されます。アプリケーションコード内の問題の診断に直接焦点を当てるものではありません。
B. システムの健全性、パフォーマンス、カスタムメトリクスの監視には最適ですが、Stackdriver Monitoringでは、再デプロイせずにアプリケーションコード内の特定の問題をピンポイントで診断することはできません。
C. スナップショットは、コード内の特定の場所でローカル変数とコールスタックをキャプチャします。このツールは、実行中のアプリケーションを停止させたり速度を落としたりすることなく、プログラムの状態を調べるために使用される。役に立ちますが、ログポイントほど直接シナリオに合わせたものではありません。
正解
D. Logpoints を使えば、実行中のアプリケーションを停止したり再デプロイしたりすることなく、リアルタイムでログ文を追加することができるので、これは正しい選択です。これを使用して、問題が発生していると思われる特定のポイントのログを検査することで、アプリケーションコード内の問題を診断することができます。オプション D は、アプリケーションを再デプロイすることなく、アプリケーションコード内の問題を診断するた めに、アプリケーションを長期にわたって監視するための最良の選択です。

Links:

https://cloud.google.com/debugger/docs/using/logpoints
</div></details>

## Q. 1-31
あなたは、XMLHttpRequestを使用してサードパーティAPIとコンテンツ通信を行う、ユーザーインターフェースを持つ単一ページのWebアプリケーションを書いています。APIの結果によってUIに表示されるデータは、同じWebページに表示される他のデータよりも重要度が低いため、リクエストによってはAPIのデータがUIに表示されなくても構いません。しかし、APIへの呼び出しによって、ユーザーインターフェースの他の部分のレンダリングが遅れてはならない。APIレスポンスがエラーまたはタイムアウトの場合、アプリケーションのパフォーマンスを向上させたい。
どうすればよいでしょうか？
1. APIへのリクエストの非同期オプションをfalseに設定し、タイムアウトまたはエラーが発生したときにAPI結果を表示するウィジェットを省略します。
2. APIへのリクエストの非同期オプションをtrueに設定し、タイムアウトまたはエラーが発生したときにAPI結果を表示するウィジェットを省略する。
3. APIコールからのタイムアウトまたはエラー例外をキャッチし、API応答が成功するまで指数関数バックオフで試行を続ける。
4. APIコールのタイムアウトまたはエラー例外をキャッチし、UIウィジェットにエラー・レスポンスを表示する。
<details><div>
    答え：2
不正解
A. この場合、リクエストは同期的に処理され、リクエストが完了するまでUIの他の部分のレンダリングがブロックされます。
C. これは不必要な遅延を引き起こし、APIが失敗し続ければ無限にトライし続ける可能性がある。データはそれほど重要ではないので、繰り返しフェッチしようとするのは要件に合致しない。
D. UIにエラー・レスポンスを表示することは、特にデータの重要度が低い場合、望ましくないかもしれない。また、これは呼び出しを非同期にするという要件には対応していません。
正解
B. このシナリオでは、サードパーティAPIへの呼び出しがUIの他の部分のレンダリングを遅らせないようにすることに重点を置いています。

したがって、ここでの最良の選択は、UI の他の部分のレンダリングをブロックしないようにリクエストを非同期（オプション B）にすることです。

https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest
</div></details>

## Q. 1-32
App Engineでアプリケーションを実行しています。

アプリケーションは Stackdriver Trace でインスツルメンテーションされています。product-detailsリクエストは、以下のように/sku-detailsにある4つの既知のユニークな商品に関する詳細をレポートします。リクエストが完了するまでの時間を短縮したい。

どうすればよいでしょうか？
1. インスタンスクラスのサイズを大きくする。
2. 永続ディスクのタイプをSSDに変更する。
3. リクエストを並行して実行するように/product-detailsを変更する。
4. sku-details情報をデータベースに保存し、Webサービスコールをデータベースクエリに置き換える。
<details><div>
    答え：3
A. インスタンスクラスのサイズを大きくすることで、より多くのリソースを提供できるかもしれませんが、シーケンシャルなリクエスト処理という核心的な問題には必ずしも対処できないでしょう。
B. 永続ディスク・タイプをSSDに変更すると、ディスクI/Oパフォーマンスが向上するかもしれないが、ここで説明する問題はネットワーク・リクエストに関連するものであり、ディスク操作に関連するものではない。
D. データベースに/sku-details情報を格納することで、シナリオによってはパフォーマンスが向上する可能性がありますが、説明した問題とは必ずしも一致しません。sku-detailsデータが頻繁に変更され、サードパーティによって管理されている場合、データベースの保存は適切ではないかもしれません。
正解
C. リクエストを並列に実行することで、/product-detailsリクエスト全体が完了するまでの時間を短縮できます。

Links:

https://cloud.google.com/appengine/docs/standard/java/datastore/queries
</div></details>

## Q. 1-33
App Engineの標準設定は以下のとおりです：

- サービス: production

- インスタンスクラス B1

アプリケーションを5インスタンスに制限したい。

どのコードスニペットを構成に含める必要がありますか？
1. manual_scaling: インスタンス： 5 min_pending_latency: 30ms
2. manual_scaling: max_instances： 5 idle_timeout： 10m
3. basic_scaling: インスタンス数： 5 min_pending_latency: 30ms
4. basic_scaling: max_instances： 5 idle_timeout： 10m
<details><div>
    答え：4
不正解
manual_scalingではインスタンスの最大数を設定できない（固定数である）ため、これらの他の選択肢は正しくありません。また、選択肢Cはbasic_scalingに対して誤った構文を使用しています。
正解です：
App Engineでインスタンス数を制限したい場合、特定の最大インスタンス数でbasic scalingを使用できます。
この設定の正しいコードスニペットは以下の通り：
basic_scaling: max_instances： 5 idle_timeout： 10m
この設定により、App Engineは最大5つのインスタンスを実行し続け、10分以上アイドル状態のインスタンスを自動的にシャットダウンします。
Links:

https://cloud.google.com/appengine/docs/legacy/standard/python/how-instances-are-managed#scaling_types
</div></details>

## Q. 1-34
アプリケーションはCompute Engine上で実行されており、少数のリクエストで持続的な障害が発生しています。原因を1つのCompute Engineインスタンスに絞り込みましたが、そのインスタンスはSSHに応答しません。

次に何をすべきでしょうか?
1. マシンを再起動します。
2. シリアルポート出力を有効にして確認してください。
3. マシンを削除し、新しいマシンを作成する。
4. ディスクのスナップショットを取り、新しいマシンに添付する。
<details><div>
    答え：2
不正解
A. 一時的に問題は解決するかもしれませんが、問題の原因を知ることができないので、再発する可能性があります。
C. 一時的に問題は解決するかもしれないが、根本的な原因を調査しない限り、再発を防ぐことはできない。
D. より抜本的な対策を後で検討することになるかもしれませんが、シリアルポートの出力をチェックすることは、問題を診断するのにより簡単で直接的な方法です。
正解
B. 次のステップは正しいです。これにより、ブート・ログやシステム・ログを見ることができ、何が問題だったのかを知る手がかりになります。
Links:

https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-ssh#debug_with_serial_console
</div></details>

## Q. 1-35
データはCloud Storageのバケットに保存されます。

他の開発者から、Cloud StorageからダウンロードしたデータによってAPIのパフォーマンスが低下しているという報告を受けています。Google Cloudのサポートチームに詳細を報告するために、この問題を調査したいと思います。

どのコマンドを実行すべきですか？
1. gsutil test -o output.json gs://my-bucket
2. gsutil perfdiag -o output.json gs://my-bucket
3. gcloud compute scp example-instance:~/test-data -o output.json gs://my-bucket
4. gcloud services test -o output.json gs://my-bucket
<details><div>
    答え：2
説明
不正解
A. このコマンドはgsutilコマンドラインツールに存在せず、オプション "test "が認識されないため、正しく実行されません。
C. gcloud compute scpコマンドは、ローカルマシンと仮想マシン間、または2つの仮想マシン間でファイルをコピーするために使用されます。クラウドストレージのパフォーマンス問題の診断とは関係ないので、今回のタスクには当てはまらない。
D. このコマンドはgcloudコマンドラインツールには存在しません。gcloud servicesの下に「test」コマンドはないので、この行はエラーになります。
正しい答え
B. gsutil perfdiagコマンドは、Google Cloud Storageのパフォーマンスの問題を診断するために使用できます。一連の診断テストを実行し、パフォーマンス問題の原因を特定するのに役立つ情報を収集します。
Links:

https://cloud.google.com/storage/docs/gsutil/commands/perfdiag#providing-diagnostic-output-to-cloud-storage-team
</div></details>

## Q. 1-36
あなたは、Compute Engine上で財務部門向けの企業ツールを開発しています。このツールでは、ユーザーを認証し、財務部門に所属していることを確認する必要があります。全社員がG Suiteを使用しています。

あなたは何をすべきですか?
1. HTTPロードバランサーでCloud Identity-Aware Proxyを有効にし、財務部門のユーザーを含むGoogleグループへのアクセスを制限します。提供された JSON Web トークンをアプリケーション内で確認します。
2. HTTP(s)ロードバランサーでCloud Identity-Aware Proxyを有効にし、財務部門のユーザーを含むGoogleグループへのアクセスを制限する。財務チームの全員にクライアント側証明書を発行し、アプリケーションで証明書を検証します。
3. Cloud Armor Security Policies を構成して、企業 IP アドレス範囲のみにアクセスを制限する。提供された JSON Web トークンをアプリケーション内で検証する。
4. Cloud Armor Security Policiesを構成して、企業IPアドレス範囲のみにアクセスを制限する。財務チームの全員にクライアント側証明書を発行し、アプリケーションで証明書を検証する。
<details><div>
    答え：1
説明
不正解
B. このケースでは、明確な要件もメリットもないのにクライアント側証明書を発行することで、不必要な複雑さを追加する。
C. D. 
オプション C と D は、IP アドレスに基づいてアクセスを制限する Cloud Armor Security Policies に依存しています。また、会社の全従業員がG Suiteを使用しているという事実を利用しておらず、財務部門のみにアクセスを制限するにはIPベースの制限では不十分かもしれません。
正解
A. HTTP(s)ロードバランサーでCloud Identity-Aware Proxy (IAP)を有効にする： IAP は Google Cloud 上で動作するクラウドアプリケーションへのアクセスを制御します。ID とコンテキストを検証してアプリケーションへのアクセスを許可するかどうかを判断することで、適切な人だけがアクセスできるようにします。
財務部門のユーザーを含むGoogleグループへのアクセスを制限する： これにより、財務部門の特定のグループのメンバーだけがアクセスできるようになります。IAP は、Google Workspace グループに基づいてアクセスを許可するように設定できます。
提供された JSON Web Token をアプリケーション内で確認します： IAP は JSON Web Token（JWT）を設定し、アプリケーションはこの JWT を検証して、リクエストが IAP によって承認されたことを確認できます。
Links:

https://cloud.google.com/iap/docs/signed-headers-howto#securing_iap_headers
</div></details>

## Q. 1-37
既存のApache/MySQL/PHPアプリケーションスタックをシングルマシンからGoogle

Kubernetes Engineに移植しようとしています。アプリケーションをコンテナ化する方法を決定する必要があります。あなたのアプローチは、Googleが推奨する可用性のベストプラクティスに従う必要があります。

あなたは何をすべきでしょうか？
1. 各コンポーネントを個別のコンテナにパッケージする。レディネス・プローブとライブネス・プローブを実装する。
2. アプリケーションを単一のコンテナにパッケージ化する。プロセス管理ツールを使用して、各コンポーネントを管理する。
3. 各コンポーネントを個別のコンテナにパッケージする。スクリプトを使用して、コンポーネントの起動をオーケストレーションする。
4. アプリケーションを1つのコンテナにパッケージする。コンテナへのエントリポイントとしてbashスクリプトを使用し、各コンポーネントをバックグラウンドジョブとしてスポーンする。
<details><div>
    答え：1
説明
不正解
B. このアプローチは、コンテナごとに1プロセスという原則に反するため、システムの管理、拡張、トラブルシューティングが困難になります。1つのプロセスに障害が発生すると、コンテナ全体に影響する可能性があるため、ダウンタイムが長くなり、問題の切り分けが複雑になる。
C. 各コンポーネントを別のコンテナに分離することはベストプラクティスに合致するが、オーケストレーションにカスタムスクリプトを使用すると、コンテナを管理するためのKubernetesのネイティブ機能が活用されない。このため、Kubernetesの組み込みオーケストレーション機能を使用する場合と比較して、メンテナンスコストが高くなり、効率的な管理ができなくなる可能性がある。
D. 繰り返しますが、このオプションは1コンテナ1プロセスの原則に従いません。1つのコンテナ内で複数のバックグラウンドジョブを管理すると、依存関係がもつれ、問題の診断が困難になる可能性がある。1つのバックグラウンド・ジョブに障害が発生すると、コンテナ全体に影響が及ぶ可能性がある。また、管理にbashスクリプトを使用すると、Kubernetesのオーケストレーション機能を活用できず、より脆弱でスケーラビリティの低いシステムになってしまいます。
正解
A. 各コンポーネントを個別のコンテナにパッケージ化し、レディネス・プローブとライブネス・プローブを実装することで、コンテナ化のベストプラクティスに沿い、Kubernetesの機能を活用してコンテナを効率的かつ効果的に管理できます。
Links:

https://cloud.google.com/architecture/best-practices-for-building-containers#package_a_single_app_per_container
</div></details>

## Q. 1-38
あなたはCloud Storage APIを使用するアプリケーションをサポートしています。ログを確認し、APIからの複数のHTTP 503 Service Unavailableエラー応答を発見しました。アプリケーションはエラーをログに記録し、それ以上のアクションは取りません。Googleが推奨する再試行ロジックを実装し、成功率を向上させたいと考えています。

どのアプローチを取るべきでしょうか？
1. 設定された数の失敗が記録された後、バッチで失敗を再試行する。
2. 設定された時間間隔で、最大回数まで各失敗を再試行する。
3. 失敗するたびに、最大トライ回数まで時間間隔を空けてリトライします。
4. 最大トライ回数まで、時間間隔を狭めて各障害をリトライする。
<details><div>
    答え：3
説明
不正解
A. このアプローチでは、503エラーの一過性の性質を考慮していないため、すべての再試行が一度に行われ、問題が悪化する可能性があります。
B. この方法は状況に適応せず、すでに苦戦しているサービスに負荷をかけ続ける可能性がある。
D. リトライの間隔を短くすることは、苦戦しているサービスの負荷を増加させ、状況を改善するどころか悪化させる可能性があります。
正解
C. すでに問題が発生しているシステムに負荷をかけるリスクを軽減し、各再試行の間に回復する時間を確保できるため、このシナリオではベストプラクティスです。
Links:

https://cloud.google.com/storage/docs/retry-strategy
</div></details>

## Q. 1-39
トラフィックの大幅な増加に対応できるように、認証サービスからの監査イベントの取り込みを再設計する必要があります。現在、監査サービスと認証システムは、同じCompute Engine仮想マシンで実行されています。新しいアーキテクチャでは、以下のGoogle Cloudツールを使用する予定です：

複数のCompute Engineマシンで、それぞれが認証サービスのインスタンスを実行している。

複数のCompute Engineマシンで、それぞれ監査サービスのインスタンスを実行する。

認証サービスからイベントを送信するためのPub/Sub。

システムが大量のメッセージを処理し、効率的に拡張できるようにするには、トピックとサブスクリプションをどのように設定すればよいですか？
1. 1つのPub/Subトピックを作成する。監査サービスがメッセージを共有できるように、1つのプル・サブスクリプションを作成します。
2. 1つのPub/Subトピックを作成します。監査サービスインスタンスごとに1つのプル・サブスクリプションを作成し、サービスがメッセージを共有できるようにします。
3. 1つのPub/Subトピックを作成する。監査サービスの前にロードバランサーを指すエンドポイントを持つプッシュサブスクリプションを1つ作成する。
4. 認証サービスごとに1つのPub/Subトピックを作成する。1つの監査サービスによって使用されるために、1つのトピックごとに1つのプルサブスクリプションを作成する。
<details><div>
    答え：1
説明
不正解
B. これは、監査サービスごとに個別のサブスクリプションを作成することになります。これらはすべて同じトピックから消費されるため、同じメッセージが複数のサブスクリプションに送信され、重複処理が発生する可能性があります。
C. このアプローチには利点がありますが、ロードバランサーとプッシュサブスクリプションを使用することは、より複雑になる可能性があり、オプションAほどこの特定のユースケースに適していないかもしれません。
D. このセットアップは、各認証サービスと監査サービスの間の緊密な結合をもたらし、潜在的なボトルネックとリソースの非効率的な使用をもたらします。
正解
A. この設定では、すべての監査サービスが同じサブスクリプションからメッセージをプルできます。これは、各メッセージが利用可能な監査サービスの 1 つによって 1 回処理されることを保証し、メッセージを重複させることなくスケーラブルなソリューションを提供します。
Links:

https://cloud.google.com/pubsub/docs/subscriber
</div></details>

## Q. 1-40
あなたは、Google Kubernetes Engine (GKE)クラスタ内の顧客に専用のブログソフトウェアをデプロイするSaaSプロバイダーです。各顧客が自分のブログのみにアクセスでき、他の顧客のワークロードに影響を与えないように、セキュアなマルチテナント・プラットフォームを構成したいと考えています。

あなたは何をすべきでしょうか？
1. クラスタを保護するために、GKEクラスタでアプリケーションレイヤーシークレットを有効にします。
2. テナントごとにネームスペースをデプロイし、各ブログのデプロイメントでネットワークポリシーを使用します。
3. GKE監査ロギングを使用して、悪意のあるコンテナを特定し、発見時に削除する。
4. ブログ・ソフトウェアのカスタム・イメージを構築し、Binary Authorizationを使用して信頼できないイメージのデプロイを防止する。
<details><div>
    答え：2
説明
不正解
A. これは、テナントを分離するというよりも、シークレットを保護することを目的としているため、マルチテナントの要件には対応していません。
C. 監査ロギングは疑わしい活動や不正な活動の特定に役立ちますが、テナント間の隔離や制限を直接的に提供するものではありません。
D. バイナリ認証は、信頼できるコンテナイメージのみがデプロイされることを保証しますが、異なるテナント間の分離や個々のブログへのアクセスの制御は提供しません。
正解
B. テナントごとに個別のネームスペースを作成することで、Kubernetesレベルでリソースを分離し、各テナントのワークロードを他のテナントから確実に分離できます。
Network Policiesを実装すると、異なるテナント間の通信がさらに制限され、ネットワークレベルでの分離が強制され、あるテナントのワークロードが他のテナントのワークロードと相互作用できないようになります。
Links:

https://cloud.google.com/kubernetes-engine/docs/concepts/multitenancy-overview#network_policies
</div></details>

## Q. 1-41
あなたは、従業員が社内でコミュニティイベントを開催するための社内アプリケーションを開発しています。アプリケーションは1つのCompute Engineインスタンスにデプロイしました。あなたの会社はGoogle Workspace（旧G Suite）を使用しており、会社の従業員がどこからでもアプリケーションに認証できるようにする必要があります。

どうすればいいでしょうか？
1. インスタンスにパブリックIPアドレスを追加し、ファイアウォールルールを使用してインスタンスへのアクセスを制限します。会社のプロキシを唯一のソースIPアドレスとして許可します。
2. インスタンスの前にHTTP(S)ロードバランサーを追加し、Identity-Aware Proxy(IAP)を設定する。会社のドメインがウェブサイトにアクセスできるようにIAP設定を構成する。
3. 社内ネットワークとGoogle Cloud上のインスタンスのVPCロケーションの間にVPNトンネルを設定します。オンプレミスとGoogle Cloudの両方のネットワークに対して、必要なファイアウォールルールとルーティング情報を設定する。
4. インスタンスにパブリックIPアドレスを追加し、インターネットからのトラフィックを許可する。ランダムなハッシュを生成し、このハッシュを含み、インスタンスを指すサブドメインを作成します。このDNSアドレスを会社の従業員に配布する。
<details><div>
    答え：2
説明
不正解
A. この方法では、会社のドメインに基づく認証がないため、従業員が会社のネットワーク外からアプリケーションにアクセスしようとすると問題が発生する可能性があります。
C. この方法では、社内ネットワークまたはVPN接続からのみアプリケーションにアクセスできるため、従業員が他の場所からアプリケーションにアクセスできない可能性がある。
D. この方法では、ユーザーの身元に基づく認証は行われない。共有秘密（サブドメインのハッシュ）に依存し、ユーザーが従業員であることを検証しません。
正解
B. Identity-Aware Proxy（IAP）：Googleクラウド上で動作するアプリケーションへのアクセスを制御し、ユーザー（企業ドメインなど）のIDやグループメンバーシップに基づいてアクセスレベルを設定できます。

HTTP(S)ロードバランサー： HTTP(S)トラフィックを様々なパラメータに基づいて異なるインスタンスにルーティングすることができ、スケーラビリティと制御性を高めることができます。

したがって、ユーザーのアイデンティティに基づいたアクセスを可能にし、会社ドメインの従業員だけがアプリケーションを認証できるようにするオプションBが最良のアプローチです。
Links:

https://cloud.google.com/iap/docs/concepts-overview#how_iap_works

https://cloud.google.com/blog/topics/developers-practitioners/control-access-your-web-sites-identity-aware-proxy
</div></details>

## Q. 1-42
最近Google Kubernetes Engineにアプリケーションをデプロイし、新しいバージョンのアプリケーションをリリースする必要があります。新しいバージョンで問題が発生した場合に備えて、以前のバージョンに即座にロールバックする機能が必要です。

どのデプロイモデルを使うべきでしょうか？
1. ローリングデプロイメントを実行し、デプロイメント完了後に新しいアプリケーションをテストします。
2. A/Bテストを実施し、新しいテストが実施された後、定期的にアプリケーションをテストする。
3. ブルー/グリーンデプロイメントを実行し、デプロイメント完了後に新しいアプリケーションをテストします。
4. カナリアデプロイメントを実行し、新しいバージョンがデプロイされた後、新しいアプリケーションを定期的にテストしてください。
<details><div>
    答え：3
説明
不正解
A. ローリングデプロイメントでは、古いバージョンのインスタンスを新しいバージョンに徐々に置き換えます。これによってダウンタイムをゼロにすることができますが、システムが段階的な変更を元に戻さなければならないため、即座にロールバックすることはより複雑になる可能性があります。
B. A/Bテストは、ユーザーを異なるグループに分け、アプリケーションの異なるバージョンをテストすることを含みます。これは、即座にロールバックする仕組みを提供するというよりも、パフォーマンスやユーザビリティを比較するためのものです。
D. カナリアデプロイメントでは、完全なロールアウトの前に、新バージョンを一部のユーザーにリリースします。問題を早期に検出するのに役立ちますが、すべてのユーザーに対して以前のバージョンに即座にロールバックするメカニズムが提供されない可能性があります。
正解
C. ブルー/グリーンのデプロイメントでは、2つの別々の環境を持つことになります。1つは古いバージョン（ブルー）を実行し、もう1つは新しいバージョン（グリーン）を実行します。トラフィックをリダイレクトするだけで、これらのバージョンを切り替えることができます。グリーン環境で何か問題があれば、即座にブルー環境に戻すことができる。このように、ブルー／グリーンのデプロイメント・モデルは、新しいバージョンに問題があれば、即座に以前のバージョンにロールバックするという要件に最も適している。
Links:

https://cloud.google.com/architecture/application-deployment-and-testing-strategies#choosing_the_right_strategy
</div></details>

## Q. 1-43
コンテナ化したアプリケーションの新バージョンのテストが完了し、Google Kubernetes Engine上で本番環境にデプロイする準備が整いました。
本番前の環境では新バージョンの負荷テストを十分に行うことができなかったため、デプロイ後のパフォーマンスに問題がないことを確認する必要があります。デプロイは自動化する必要があります。
あなたは何をすべきでしょうか？
1. クラウドロードバランシングを使用して、バージョン間のトラフィックを徐々に増加させます。クラウドモニタリングを使用してパフォーマンスの問題を探します。
2. カナリアデプロイメントを使用して、継続的デリバリーパイプライン経由でアプリケーションをデプロイする。クラウドモニタリングを使用してパフォーマンスの問題を調べ、メトリクスがサポートするようにトラフィックを増加させる。
3. ブルー／グリーン・デプロイメントを使用して、継続的デリバリー・パイプラインを介してアプリケーションをデプロイする。クラウド監視を使用してパフォーマンスの問題を探し、メトリクスがそれをサポートするときに完全に起動します。
4. kubectlを使用してアプリケーションをデプロイし、spec.updateStrategv.typeをRollingUpdateに設定します。Cloud Monitoringを使用してパフォーマンスの問題を探し、問題があればkubectl rollbackコマンドを実行します。
<details><div>
    答え：4
説明
不正解
A. クラウドロードバランシングは、Kubernetes環境における新しいアプリケーションバージョンの制御されたロールアウトに適したツールではありません。
B. カナリア・デプロイは、少数のサブセット・ユーザーで新バージョンをテストする良い方法ですが、この選択肢は選択された正解には一致しません。
C. ブルー／グリーン・デプロイメントは、バージョン間の迅速な切り替えを可能にしますが、新しいバージョンへの露出を徐々に増やすことには適していません。
正解
D. KubernetesのRollingUpdateでは、アプリケーションを徐々に更新することができます。Cloud Monitoringを通じてパフォーマンスの問題が検出された場合、kubectl rollbackを使用してデプロイメントをロールバックできます。これにより、問題を検出するために必要な段階的な露出と、デプロイを効率的に管理するための自動化の両方が提供される。
Links:

https://kubernetes.io/docs/tutorials/kubernetes-basics/update/update-intro/

https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps#overview
</div></details>

## Q. 1-44
クラウドランでホストしているウェブサイトがトラフィック急増時に反応が遅すぎるとユーザーから苦情が来ています。
トラフィックのピーク時に、より良いユーザーエクスペリエンスを提供したいと考えています。
どうすればよいでしょうか？
1. アプリケーションの起動時にデータベースからアプリケーション構成と静的データを読み込みます。
2. ビルド時にアプリケーション構成と静的データをアプリケーション・イメージにパッケージする。
3. レスポンスがユーザーに返された後、できるだけ多くの作業をバックグラウンドで実行する。
4. タイムアウト例外やエラーによってCloud Runインスタンスが迅速に終了し、代替インスタンスが開始できるようにする。
<details><div>
    答え：2
説明
不正解
A. 特に、新しいインスタンスが頻繁に起動される可能性が高いトラフィック急増時には、待ち時間が増加する可能性があります。
C. バックグラウンド・タスクをオフロードすることで、ユーザーが認識するパフォーマンスは向上しますが、トラフィック急増時の応答時間の遅さという問題には特に対処できません。バックグラウンド・タスクは、入ってくるリクエストの処理に使えるリソースをさらに消費する可能性さえある。
D. 障害が発生したインスタンスを迅速に交換することは一般的に良いプラクティスですが、これはトラフィックが多いときの応答時間の低下の問題には特に対処していません。さらに、常にインスタンスを交換することは、追加のオーバーヘッドにつながり、応答時間をさらに遅くする可能性があります。
正解
B. 構成データと静的データをアプリケーション・イメージにバンドルすることで、実行時に外部ソースからデータを取得する必要性を減らすことができます。これにより、特にシステムの負荷が増大するトラフィック・ピーク時に、応答時間を短縮することができます。
Links:

https://cloud.google.com/blog/topics/developers-practitioners/3-ways-optimize-cloud-run-response-times
</div></details>

## Q. 1-45
アプリケーションは、複数のゾーンにある管理インスタンスグループ（MIG）内の数百のCompute Engineインスタンスにデプロイされています。重要な脆弱性を直ちに修正するために新しいインスタンステンプレートをデプロイする必要がありますが、サービスへの影響は避けなければなりません。

インスタンステンプレートを更新した後、MIGにどのような設定を行う必要がありますか？
1. Max Surgeを100%に設定します。
2. 更新モードをオポチュニスティックに設定する。
3. 最大利用不可を100%に設定する。
4. 最小待機時間を0秒に設定します。
<details><div>
    答え：4
説明
不正解
A. Max Surgeは、アップデート中に作成できる追加インスタンス数を定義します。100%に設定すると、インスタンス数が一時的に2倍になります。更新プロセスを高速化できますが、コストの増加など別の結果も発生する可能性があり、個々のインスタンスの更新間隔を制御できません。
B. 前述したように、このモードは、他のアクティビティによってインスタンスが再作成された場合にのみインスタンスを更新します。このモードでは、重大な脆弱性を修正するためにインスタンスを直ちに更新する方法は提供されないため、このシナリオで必要とされる緊急の更新には適していません。
C. この設定では、アップデート中にグループ内のすべてのインスタンスが同時に利用できなくなり、サービスへの影響を避けるという要件に直接反してしまいます。このオプションはダウンタイムにつながるため、この状況には適していません。
正解
D. この設定により、個々のインスタンスの更新の間に待機することなく、更新プロセスを可能な限り迅速に行うことができ、サービスを中断することなく重要な脆弱性を緊急に修正する必要性に沿う。
Links:

https://cloud.google.com/compute/docs/instance-groups/rolling-out-updates-to-managed-instance-groups#minimum_wait_time
</div></details>

## Q. 1-46
Google Kubernetes Engine（GKE）にデプロイされたアプリケーションの1つに、断続的なパフォーマンスの問題が発生しています。あなたのチームはサードパーティのロギングソリューションを使用しています。このソリューションをGKEクラスタの各ノードにインストールして、ログを表示できるようにしたいと思います。

あなたは何をすべきですか？
1. サードパーティのソリューションをDaemonSetとしてデプロイする
2. コンテナイメージを変更し、監視ソフトウェアを含める
3. SSH を使用して GKE ノードに接続し、ソフトウェアを手動でインストールする。
4. Terraformを使用してサードパーティソリューションをデプロイし、KubernetesデプロイメントとしてロギングPodをデプロイする。
<details><div>
    答え：1
説明
不正解
B. これは、アプリケーションコンテナ自体にロギングソリューションを組み込むことになります。特定のアプリケーションを実行していないノードも含め、クラスタ内のすべてのノードにロギング・ソリューションをデプロイする必要がある場合、この方法は機能しません。
C. 手動インストールは、特にKubernetesでは、インフラストラクチャを維持するためのベストプラクティスに従わない。ノード間の一貫性の維持や、ノードの障害からの復旧に困難が生じます。また、GKEノードは管理されていることが多く、このような変更のための直接アクセスを許可しない場合があることも注目に値する。
D. 標準的なデプロイメントとしてロギングソリューションをデプロイしても、ロギングソリューションのインスタンスがすべてのノードで実行されていることは保証されません。デプロイは、アプリケーションの指定された数のレプリカが実行されていることを保証するように設計されており、アプリケーションがクラスタ内のすべてのノードで実行されていることを強制するものではありません。
正解
A. DaemonSetは、すべてまたは一部のワーカーノードがPodのコピーを実行するようにします。クラスタにノードが追加されると、Podがノードに追加されます。クラスタ内のすべてのノードに監視またはロギングエージェントをデプロイする場合は、DaemonSetが正しい方法です。
Links:

https://kubernetes.io/docs/concepts/workloads/controllers/daemonset

https://cloud.google.com/kubernetes-engine/docs/concepts/daemonset#usage_patterns
</div></details>

## Q. 1-47
あなたは最近、オンプレミスのモノリシック・アプリケーションをGoogle Kubernetes Engine（GKE）上のマイクロサービス・アプリケーションに移行しました。このアプリケーションは、CRMシステムや個人を特定できる情報（PII）を含むMySQLデータベースなど、オンプレミスのバックエンドサービスに依存しています。バックエンド・サービスは、規制要件を満たすためにオンプレミスのままでなければなりません。

オンプレミスのデータセンターとGoogle Cloudの間にクラウドVPN接続を確立しました。GKE上のマイクロサービス・アプリケーションからバックエンド・サービスへのリクエストの一部が、帯域幅の変動によるレイテンシの問題で失敗し、アプリケーションのクラッシュを引き起こしていることに気づきました。

レイテンシーの問題にどのように対処すべきでしょうか？
1. Memorystoreを使用して、オンプレミスのMySQLデータベースから頻繁にアクセスされるPIIデータをキャッシュします。
2. Istio を使用して、GKE 上のマイクロサービスとオンプレミスのサービスを含むサービスメッシュを作成する。
3. Google Cloudとオンプレミスのサービス間の接続にクラウドVPNトンネルの数を増やす
4. クラウドVPNのMTU（Maximum Transmission Unit）値をデフォルト値から下げることで、ネットワーク層のパケットサイズを小さくする。
<details><div>
    答え：3
説明
不正解
A. キャッシュは一部のデータアクセスではレイテンシーを削減できますが、PIIデータには規制要件により適用できない場合があります。また、帯域幅の変動が問題を引き起こしているという根本的な問題には対処できない。
B. Istioのようなサービスメッシュは、より良い制御、観測可能性、ルーティングを提供できる。しかし、帯域幅が変動するという問題を本質的に解決しているわけではないので、レイテンシーの問題は続く可能性が高い。
D. MTUを小さくすることで、より多くのパケットを送信することができますが、必ずしも帯域幅の変動の問題を解決することはできません。
正解
C. VPNトンネルの数を増やすことで、より多くの帯域幅を提供でき、遅延の問題を軽減できる可能性があります。このアプローチは、問題の根本原因に直接対処します。
Links:

https://cloud.google.com/network-connectivity/docs/vpn/concepts/topologies#more-bandwidth
</div></details>

## Q. 1-48
GoアプリケーションからCloud Spannerデータベースに書き込んでいます。Google が推奨するベストプラクティスを使用して、アプリケーションのパフォーマンスを最適化したいと考えています。

どうすればよいでしょうか？
1. Cloud Client Librariesを使用してCloud Spannerに書き込みます。
2. Google API クライアント ライブラリを使用して Cloud Spanner に書き込む。
3. カスタムgRPCクライアント・ライブラリを使用してCloud Spannerに書き込む。
4. サードパーティのHTTPクライアント・ライブラリを使用してCloud Spannerに書き込む。
<details><div>
    答え：1
説明
不正解です：
B. 技術的には可能ですが、Cloud Client Librariesはサービスに特化しているため、開発が簡単で効率的です。
C. カスタム gRPC クライアント ライブラリを作成することは、公式にサポートされているライブラリを使用することに比べて、エラーが発生しやすく、時間がかかる可能性があります。
D. サードパーティのライブラリに依存すると、互換性とサポートのリスクが発生し、Cloud Spanner用に最適化されていない可能性があります。
正解
A. GoアプリケーションからCloud Spannerを使用する場合、GoogleはCloud Client Librariesの使用を推奨します。これらのライブラリは、Google API Client Libraries よりも高レベルで便利な抽象化を提供し、Google Cloud サービスとの統合を容易にします。

GoからCloud Spannerを操作する慣用的で最適化された方法を提供するため、オプションAが推奨されるアプローチです。
Links:

https://cloud.google.com/apis/docs/client-libraries-explained

https://cloud.google.com/go/docs/reference
</div></details>

## Q. 1-49
Google Kubernetes Engine（GKE）にデプロイされたアプリケーションがあります。Google Cloudのマネージドサービスに認可されたリクエストを行うために、アプリケーションをアップデートする必要があります。これは一度だけのセットアップであり、セキュリティキーの自動ローテーションと暗号化されたストアへの保存というセキュリティのベストプラクティスに従う必要があります。Google Cloud サービスへの適切なアクセス権を持つサービスアカウントは作成済みです。

次に何をすべきでしょうか？
1. Workload Identityを使用して、GKEポッドにGoogleクラウドサービスアカウントを割り当てます。
2. Google Cloudサービスアカウントをエクスポートし、KubernetesシークレットとしてPodと共有します。
3. Google Cloudサービスアカウントをエクスポートし、アプリケーションのソースコードに埋め込みます。
4. Google Cloudのサービスアカウントをエクスポートし、HashiCorp Vaultにアップロードして、アプリケーション用の動的なサービスアカウントを生成します。
<details><div>
    答え：1
説明
不正解
B. サービスアカウントキーの保存にKubernetesシークレットを使用すると、自動ローテーションが提供されず、正しく処理されないとセキュリティリスクを引き起こす可能性があります。
C. ソースコードにサービスアカウントを埋め込むことは悪い習慣であり、重大なセキュリティリスクをもたらす。
D. HashiCorp Vaultはシークレット管理のための強力なツールですが、Google Cloudサービスと相互作用するGKEワークロードのIDを処理するには、ワークロードアイデンティティを使用する方がより簡単で推奨される方法です。
正解
A. Workload Identityは、GKE内からGoogle Cloudサービスにアクセスするための推奨方法です。KubernetesサービスアカウントをGoogleサービスアカウントにバインドすることができ、このバインドによってKubernetesサービスアカウントがGoogleサービスアカウントとして機能します。Workload Identityを使用すると、サービスアカウントのキーを管理する必要がなく、ベストプラクティスに沿った自動ローテーションが行われます。
Links:

https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity
</div></details>

## Q. 1-50
アプリケーションにユニット・テストを追加することを計画しています。発行された Pub/Sub メッセージがサブスクライバによって順番に処理されることを保証できるようにする必要があります。あなたは、ユニット・テストを費用対効果が高く、信頼できるものにしたいと考えています。

あなたは何をすべきでしょうか？
1. モッキングフレームワークを実装する。
2. テスターごとにトピックとサブスクリプションを作成する。
3. サブスクリプションにテスターによるフィルタを追加する。
4. Pub/Subエミュレータを使用する。
<details><div>
    答え：4
説明
不正解
A. モッキング・フレームワークを実装することは有効な選択肢ですが、Pub/Subエミュレータを使用する方がよりシンプルで正確です。
B. テスターごとにトピックとサブスクリプションを作成すると、実際の Pub/Sub サービスとやり取りすることになり、テストにコストや複雑さ、信頼性の問題が生じる可能性があります。
C. サブスクリプションにテスターによるフィルタを追加することも、実際の Pub/Sub サービスとのやりとりを伴います。
正解です：
D. オプションDの「Pub/Subエミュレータを使用する」は、ここでの最も適切なアプローチです。Pub/Subエミュレータを使用すると、実際のPub/Subサービスを実際に使用することなく、Pub/Subと相互作用するコードをユニットテストすることができます。これはローカルで実行され、Pub/Sub の動作をシミュレートするため、テストが高速になり、コストもかかりません。
Links:

https://cloud.google.com/pubsub/docs/emulator
</div></details>

## Q. 2-1
Google Kubernetes Engine（GKE）に、ライブストリームを配信するマイクロサービス・アプリケーションをデプロイしようとしています。予測不可能なトラフィックパターンと同時ユーザー数の大きな変動が予想されます。アプリケーションは以下の要件を満たす必要があります：

- 人気のあるイベント時に自動的にスケールし、高可用性を維持する。

- ハードウェア障害が発生した場合の回復力

デプロイメントパラメータはどのように構成しますか? (2つのオプションを選択してください)
1. マルチゾーンノードプールを使用してワークロードを均等に分散します。
2. 複数のゾーンノードプールを使用してワークロードを均等に分散します。
3. クラスターオートスケーラーを使用してノードプールのノード数をリサイズし、ホリゾンタルポッドオートスケーラーを使用してワークロードをスケールします。
4. クラスタノードでCompute Engine用のマネージドインスタンスグループを作成します。マネージドインスタンスグループのオートスケーリングルールを設定します。
5. GKEのCPUとメモリの使用率に基づいて、Cloud Monitoringでアラートポリシーを作成する。CPUとメモリの使用率が事前に定義したしきい値を超えたら、スクリプトを実行してワークロードをスケールするよう、当番のエンジニアに依頼する。
<details><div>
    答え：1,3
説明
不正解
B. 複数のゾーンノードプールを使用すると、管理が複雑になる可能性があります。一般的に、マルチゾーナルノードプールは、より簡単な構成で同じ利点を提供します。
D. マネージドインスタンスグループは一般的にKubernetesの外部で使用され、GKEと直接統合されないため、このオプションは説明したシナリオには適していません。
E. アラートポリシーの作成とワークロードの手動スケーリングは自動プロセスではなく、手動介入に依存するとエラーが発生しやすく、スケーリングが遅れる可能性があります。
正解
A. これにより、ノードがリージョン内の複数のゾーンに分散され、ゾーンの1つに障害が発生した場合のフォールトトレランスが確保されます。また、ゾーン間のリソースの利用率も向上します。
C. クラスタオートスケーラは、リソース要件に基づいてノードプールのサイズを自動的に調整し、必要なときにノードが追加され、不要なときにノードが削除されるようにします。Horizontal Pod Autoscalerは、観測されたCPUまたはメモリの使用量に基づいてデプロイメント内のPodの数を自動的に調整し、アプリケーションがさまざまな負荷に対応できるようにします。
Links:

https://cloud.google.com/blog/products/containers-kubernetes/best-practices-for-creating-a-highly-available

https://cloud.google.com/kubernetes-engine/docs/concepts/types-of-clusters#multi-zonal_clusters
</div></details>

## Q. 2-2
Cloud Shellからkubectlを使ってGoogle Kubernetes Engine (GKE)クラスタに接続しようとしています。
GKEクラスターをパブリックエンドポイントでデプロイしています。Cloud Shellから以下のコマンドを実行します：

gcloud container clusters get-credentials <cluster-name> ￤ -zone <none
---zone <none> --project <プロジェクト名> \
kubectl コマンドがエラーメッセージを返さずにタイムアウトしていることに気付きます。

この問題の最も可能性の高い原因は何ですか。
1. ユーザーアカウントには、kubectlを使用してクラスタと対話する権限がありません。
2. Cloud Shellの外部IPアドレスはクラスタの許可されたネットワークの一部ではありません。
3. クラウドシェルが GKE クラスターと同じ VPC に属していない。
4. VPCファイアウォールがクラスタのエンドポイントへのアクセスをブロックしている。
<details><div>
    答え：2
説明
不正解
A. ユーザーアカウントに権限がない場合、通常はタイムアウトではなく、権限に関連するエラーメッセージが表示されます。
C. パブリックエンドポイントに接続しているため、クラウドシェルが同じ VPC に属していなくてもこの問題は発生しません。
D. VPC ファイアウォールは、Cloud Shell が VPC の外側にあるため、Cloud Shell からクラスタのパブリックエンドポイントへの接続には影響しません。
正解
B. パブリックエンドポイントを持つGKEクラスタを設定するとき、Kubernetes APIサーバーへの接続が許可される許可されたネットワークを設定することができます。Cloud Shellの外部IPアドレスがこれらの許可されたネットワークの一部でない場合、クラスタに接続しようとするとブロックされ、説明されているようなタイムアウトの問題が発生します。
Links:

https://cloud.google.com/kubernetes-engine/docs/how-to/private-clusters#cloud_shell
</div></details>

## Q. 2-3
あなたのチームはCloud Functionsコードのユニットテストを開発しています。

コードは Cloud Source Repositories リポジトリに保存されています。あなたはテストを実装する責任があります。特定のサービスアカウントだけが、コードを Cloud Functions にデプロイするのに必要な権限を持っています。最初にテストに合格しないとコードがデプロイできないようにしたい。

ユニットテストプロセスをどのように構成しますか？
1. Cloud Build を構成してクラウド関数をデプロイします。コードがテストに合格すると、デプロイ承認が送信されます。
2. 特定のサービス アカウントをビルド エージェントとして使用して、Cloud Functions をデプロイするように Cloud Build を構成します。デプロイ成功後にユニットテストを実行する。
3. ユニット テストを実行するように Cloud Build を構成します。コードがテストに合格すると、開発者は Cloud Functions をデプロイします。
4. 特定のサービスアカウントをビルドエージェントとして使用して、ユニットテストを実行するようにCloud Buildを構成します。コードがテストに合格すると、Cloud BuildはCloud Functionsをデプロイします。
<details><div>
    答え：4
説明
不正解
A. このオプションは、デプロイの前に単体テストを実行することについては特定されていません。
B. このオプションはデプロイ後にユニットテストを実行しますが、これは必要なことではありません。テストはデプロイ前にパスする必要があります。
C. このオプションは、開発者がクラウド機能をデプロイすることを可能にしますが、特定のサービスアカウントがデプロイ権限を持つ必要があります。
正解
D. 目標は、まずテストに合格しなければコードをデプロイできないようにすることであり、特定のサービスアカウントだけがCloud Functionsにコードをデプロイするのに必要な権限を持っています。

このセットアップにより、デプロイの前にユニットテストが実行され、コードがテストに合格した場合のみ、特定のサービスアカウントを使用して Cloud Build によってデプロイが実行されることが保証されます。これにより、テストの前提条件とデプロイの正しい権限処理の両方が保証されます。
Links:

https://firebase.google.com/docs/functions/unit-testing
</div></details>

## Q. 2-4
あなたは、MySQLリレーショナル・データベース・スキーマを使用するGoogle Cloud上でホストされるアプリケーションを開発しています。このアプリケーションでは、データベースへの大量の読み取りと書き込みが発生するため、バックアップと継続的なキャパシティプランニングが必要になります。あなたのチームにはデータベースを完全に管理する時間はありませんが、小さな管理タスクを引き受けることはできます。

どのようにデータベースをホストすべきでしょうか？
1. データベースをホストするためにCloud SQLを構成し、スキーマをCloud SQLにインポートする。
2. クライアントを使用してGoogle Cloud MarketplaceからデータベースにMySQLをデプロイし、スキーマをインポートします。
3. データベースをホストするためにBigtableを設定し、データをBigtableにインポートする。
4. データベースをホストするためにCloud Spannerを構成し、スキーマをCloud Spannerにインポートする。
<details><div>
    答え：1
説明
不正解
B. Google Cloud MarketplaceからMySQLをデプロイする必要があり、管理オーバーヘッドが増えるため、管理タスクを最小限に抑えたいチームには適していません。
C. Bigtableを使うことを提案するが、BigtableはNoSQLデータベースであり、MySQLのリレーショナルデータベーススキーマには適していない。
D. Cloud Spannerを提案するが、Spannerはリージョン間の水平スケーリング用に設計されたグローバル分散データベースであり、従来のMySQLデータベースのホスティングには適していない。
正解
A. Google Cloud SQLは、MySQLをサポートするフルマネージドデータベースサービスを提供し、スケーリング、バックアップ、メンテナンスを容易にします。
Links:

https://cloud.google.com/spanner/docs/migrating-mysql-to-spanner#migration-process

https://cloud.google.com/sql/docs/mysql
</div></details>

## Q. 2-5
新しい Go アプリケーションを Cloud Run にデプロイする予定です。ソース コードはクラウド ソース リポジトリに格納されています。ソース コードのコミットが行われたときに実行される、完全に管理された自動継続デプロイ パイプラインを構成する必要があります。最も単純なデプロイメントソリューションを使用したい。

どうすればいいでしょうか？
1. ワークステーション上でcronジョブを構成して、作業ディレクトリでgcloud run deploy --sourceを定期的に実行します。
2. Jenkins トリガーを構成して、クラウド・ソース・リポジトリへのソース・コードのコミットごとに、コンテナのビルドとデプロイ処理を実行する。
3. ビルドパックを使用して、Cloud Run用ソースリポジトリからの新しいリビジョンの継続的デプロイを構成する。
4. Cloud Source Repositoriesへのソースコードのコミットごとにコンテナビルドとデプロイプロセスを実行するように構成されたトリガーでCloud Buildを使用する。
<details><div>
    答え：4
説明
不正解
A. オプションAは、ワークステーション上でcronジョブを構成する必要があるため、完全に管理または自動化されません。
B. オプションBは、Jenkinsのセットアップを伴うため、Google独自のマネージドサービスを使用する場合と比較すると、最も単純なソリューションではない。
C. 
正解
D. GoogleによるフルマネージドサービスであるCloud Buildを使用したエンドツーエンドのソリューションを提供し、Cloud Source RepositoriesおよびCloud Runとの容易な統合を可能にする。Cloud Buildでトリガーを設定し、ソースコードリポジトリに新しいコミットが行われたときにコンテナを自動的にビルドおよびデプロイし、質問の要件を満たすことができる。
Links:

https://cloud.google.com/run/docs/continuous-deployment-with-cloud-build
</div></details>

## Q. 2-6
ベスト・プラクティスに準拠するために、クラウド構築手順を見直し、更新しています。現在、ビルド手順には以下が含まれています：

1. ソース リポジトリからソース コードをプルします。

2. コンテナ・イメージをビルドする。

3. ビルドしたイメージを Artifact Registry にアップロードする。

ビルドしたコンテナイメージの脆弱性スキャンを実行するステップを追加する必要があり、スキャンの結果を Google Cloud で実行中のデプロイパイプラインで利用できるようにしたい。他のチームのプロセスを混乱させる可能性のある変更は最小限に抑えたい。どうすればいいでしょうか？
1. バイナリ認証を有効にし、コンテナイメージに脆弱性が存在しないことを証明するように構成します。
2. ビルドしたコンテナイメージをDocker Hubインスタンスにアップロードし、脆弱性をスキャンする。
3. ArtifactレジストリでコンテナスキャンAPIを有効にし、構築されたコンテナイメージの脆弱性をスキャンします。
4. Aqua SecurityインスタンスにArtifact Registryを追加し、ビルドされたコンテナイメージの脆弱性をスキャンする。
<details><div>
    答え：3
説明
不正解
A. Binary Authorizationとは、コンテナのデプロイ時に署名検証を実施するために使用されるものであり、脆弱性のスキャンに使用されるものではありません。
B. 外部サービス（Docker Hub）を使用することになり、既存のプロセスに大幅な変更が必要になる可能性があります。
D. サードパーティツール（Aqua Security）との統合が必要で、既存のプロセスを混乱させる可能性があります。
正解
C. Google Cloud 内、特に Artifact Registry 内で脆弱性スキャンを実行でき、コンテナ イメージのビルド方法や保存方法を変更する必要がありません。Container Analysis API は、脆弱性スキャンを含むコンテナイメージの分析とメタデータの生成に使用され、Artifact Registry で有効にすることができます。
Links:

https://cloud.google.com/container-analysis/docs/automated-scanning-howto#view_the_image_vulnerabilities
</div></details>

## Q. 2-7
あなたのチームはCloud Run上でサーバーレスWebアプリケーションを作成しています。このアプリケーションは、プライベートクラウドストレージバケットに保存された画像にアクセスする必要があります。アプリケーションにバケット内の画像にアクセスするIAM（Identity and Access Management）権限を与えると同時に、Googleが推奨するベストプラクティスを使ってサービスを保護したい。

どうすればよいでしょうか？
1. 目的のバケットに対して署名付きURLを強制します。Compute Engineのデフォルトのサービスアカウントに、バケットのStorage Object Viewer IAMロールを付与します。
2. 目的のバケットに対して、パブリックアクセス防止を強制します。Compute Engineのデフォルトのサービスアカウントに、バケットのStorage Object Viewer IAMロールを付与する。
3. 目的のバケットに対して署名付きURLを強制します。ユーザー管理サービスアカウントを使用するようにCloud Runサービスを作成し、更新します。サービスアカウントに、バケット上のStorage Object Viewer IAMロールを付与する。
4. 目的のバケットに対してパブリックアクセス防止を実施します。ユーザー管理サービスアカウントを使用するようにCloud Runサービスを作成し、更新します。バケット上のStorage Object Viewer IAMロールをサービスアカウントに付与します。
<details><div>
    答え：4
説明
不正解
オプションAとBは、Compute Engineのデフォルトのサービスアカウントに関係しており、Cloud Runサービスに特有ではないため、最小特権の原則に合致していません。
C. オプションCは署名付きURLを利用し、バケット内のオブジェクトへの一時的なアクセスを提供する。これはアクセスを許可する有効な方法ですが、選択肢Dほど説明したシナリオには適合しません。
正解
D. パブリックアクセス防止を実施することで、バケットが誤って公開されないようにし、プライバシーを維持します。

ユーザが管理するサービスアカウントを使用するようにCloud Runサービスを作成・更新することで、特定のサービスに必要な権限のみを付与する最小権限の原則に従うことになります。

サービスアカウントにStorage Object Viewer IAMロールを付与することで、Cloud Runサービスはより広範な権限を与えることなく、指定されたバケットからオブジェクトを読み取ることができます。
Links:
https://cloud.google.com/run/docs/securing/service-identity#user-managed_service_account
https://cloud.google.com/storage/docs/public-access-prevention
https://cloud.google.com/storage/docs/access-control/using-iam-permissions
</div></details>

## Q. 2-8
あなたは、グローバルなeコマースWebアプリケーションをホストするためにCloud Runを使用しています。あなたの会社のデザインチームは、ウェブアプリケーションの新しい配色を作成しています。あなたは、新しい配色が売上を増加させるかどうかを判断する任務を与えられています。あなたは、本番のトラフィックでテストを実施したいと考えています。

どのように調査を設計すべきでしょうか？
1. 外部のHTTP(S)ロードバランサーを使用して、あらかじめ決められた割合のトラフィックを、アプリケーションの2つの異なるカラースキームにルーティングします。結果を分析して、売上に統計的に有意な差があるかどうかを判断する。
2. 外部のHTTP(S)ロードバランサーを使用して、新しい配備を作成してテストしている間、トラフィックを元の配色にルーティングします。テストが完了したら、すべてのトラフィックを新しい配色にルーティングし直します。結果を分析し、売上に統計的に有意な差があるかどうかを判断する。
3. 外部の HTTP(S)ロードバランサーを使用して、新しいバージョンのアプリケーションにトラフィックをミラーリングする。その結果を分析し、売上に統計的に有意な差があるかどうかを判断する。
4. 全ユーザーの半数に新しい配色を表示する機能フラグを有効にする。このユーザーグループの売上が増加するかどうかをモニターする。
<details><div>
    答え：1
説明
不正解
B. C. 
オプションBとCでは同時比較ができません。また、トラフィックをミラーリング（オプションC）しても、新しいデザインとの実際のユーザーインタラクションが得られないため、ユーザーの行動を正確に反映することができません。
D. オプションDは実行可能なように見えるかもしれませんが、HTTP(S)ロードバランサーが提供するような制御された環境がありません。機能フラグを実装することは、さらなる複雑さをもたらす可能性があり、テストが均一に配布されないかもしれません。
正解です：
A. これはA/Bテストを可能にし、ユーザーベースの一部がサイトのあるバージョンを取得し、別の一部が異なるバージョンを取得します。これは、2つのバージョンを比較し、どちらがより良いパフォーマンスかを確認するための一般的なアプローチです。

既存の配色と新しい配色の両方に所定の割合のトラフィックをルーティングすることで、同じ条件下で直接比較することができ、より信頼性の高い結果が得られます。

つまり、このような研究を管理された体系的な方法で実施し、2つの配色間で売上に統計的に有意な差があるかどうかを判断しやすくするためには、選択肢Aが最良の方法ということになる。
Links:

https://cloud.google.com/load-balancing/docs/l7-internal/traffic-management#traffic_actions_weight-based_traffic_splitting

https://cloud.google.com/load-balancing/docs/https/setting-up-https-serverless
</div></details>

## Q. 2-9
あなたは大企業の開発者です。Google Cloud上で3つのGoogle Kubernetes Engineクラスタを管理しています。あなたのチームの開発者は、好みの開発ツールへのアクセスを失うことなく、クラスタを定期的に切り替える必要があります。あなたは、Googleが推奨するベストプラクティスに従いながら、これらの複数のクラスタへのアクセスを設定したいと考えています。

どうすればよいでしょうか？
1. 開発者にCloud Shellを使用するように依頼し、gcloud container clusters get-credentialを実行して別のクラスタに切り替えます。
2. 設定ファイルで、クラスタ、ユーザー、コンテキストを定義します。このファイルを開発者と共有し、kubectl configを使用してクラスタ、ユーザー、コンテキストの詳細を追加するように依頼します。
3. 開発者にワークステーションにgcloud CLIをインストールしてもらい、gcloud container clusters get-credentialsを実行して別のクラスターに切り替える。
4. 開発者にワークステーション上で3つのターミナルを開いてもらい、kubectl configを使用して各クラスタへのアクセスを設定する。
<details><div>
    答え：2
説明
不正解
A. C. 
オプションCも有効な方法ですが、共有設定ファイルに定義済みのコンテキストがあるのとは対照的に、開発者は切り替えが必要なたびにコマンドを実行する必要があるかもしれません。
D. 選択肢AとDは、Bに比べて利便性と柔軟性に劣ります。
正解
B. 設定ファイルでクラスタ、ユーザー、コンテキストを定義することで、開発者は適切なパーミッションが設定されていることを前提に、kubectl config use-contextを使用して異なる環境をすばやく切り替えることができます。

適切な詳細を含む設定ファイルを共有することで、開発者は複数のクラスタへの接続をより簡単に管理できるようになります。

異なるクラスタにコンテキストを定義することで、開発者は単純なコマンドでクラスタ間を素早く切り替えることができ、クラスタを定期的に切り替える必要があるという要件に沿う。
Links:

https://kubernetes.io/docs/tasks/access-application-cluster/configure-access-multiple-clusters/
</div></details>

## Q. 2-10
あなたは大企業の開発者です。あなたのチームはソースコード管理（SCM）にGitを使っています。Google が推奨するベストプラクティスに従ってコードを管理し、ソフトウェアの納品率を上げたいと考えています。

あなたのチームはどのSCMプロセスを使うべきでしょうか？
1. 各開発者は、各製品のリリース前にコードをメインブランチにコミットし、テストを実施し、統合の問題が検出された場合はロールバックします。
2. 各開発者グループがリポジトリをコピーし、自分のリポジトリに変更をコミットし、各製品リリースの前にメインリポジトリにコードをマージする。
3. 各開発者は自分の作業用のブランチを作成し、そのブランチに変更をコミットし、毎日そのコードをメインブランチにマージします。
4. 各開発者グループは、自分たちの作業用にメインブランチからフィーチャーブランチを作成し、自分たちのブランチに変更をコミットし、変更諮問委員会が承認した後にコードをメインブランチにマージする。
<details><div>
    答え：3
説明
不正解
A. 製品リリースの直前まで待って統合テストを行うと、予期せぬ重大な問題が発生する可能性があるため、リスクが高い。
B. 各開発者グループがリポジトリをコピーし、各自のリポジトリに変更をコミットし、各自のコードをメインリポジトリにマージする。
D. 変更は外部の変更諮問委員会の承認を待つことになるため、統合が遅れ、継続的インテグレーションを真に受け入れることにはなりません。
正解
C. このアプローチによって、次のことが保証されます：

頻繁な統合： 毎日コードをメインブランチにマージすることで、統合に関する問題を早期に発見し修正することができます。

短命なブランチ： 開発者は機能の小さな塊に取り組むため、変更の管理がシンプルになり、マージ時にコンフリクトが発生する可能性が最小限になります。

継続的なフィードバックループ： 継続的インテグレーションでは通常、新しいコードを変更するたびに自動テストを実行します。定期的にメインブランチにマージすることで、開発者は変更に対するフィードバックを即座に得ることができ、問題に迅速に対処することができます。

継続的インテグレーションで短期間のフィーチャーブランチを使用することは、最新のソフトウェア開発の基本原則です。これはDevOps文化を支えるものであり、小規模でインクリメンタルな変更を効率的かつ確実にリリースすることに重点を置いている。

Links:
https://cloud.google.com/solutions/devops/devops-culture-westrum-organizational-culture
https://www.atlassian.com/git/tutorials/comparing-workflows
</div></details>

## Q. 2-11
最近、OpenTelemetry で新しいアプリケーションをインスツルメンテーションし、アプリケーションのリクエストのレイテンシを Trace でチェックしたいとします。特定のリクエストが常にトレースされるようにしたい。

どうすればいいでしょうか？
1. リクエストにX-Cloud-Trace-Contextヘッダを適切なパラメータとともに追加します。
2. 開発プロジェクトからこのタイプのリクエストを繰り返し送信するカスタムスクリプトを記述します。
3. Trace API を使用して、カスタム属性をトレースに適用する。
4. 10 分待ってから、Trace がそれらのタイプのリクエストを自動的に捕捉することを確認してください。
<details><div>
    答え：1
説明
不正解です：
B. カスタムスクリプトを書いてリクエストを繰り返し送信しても、 オプション A のように特定のトレースヘッダを組み込まない限り、 特定のリクエストが常にトレースされるわけではありません。
C. Trace API を使用してカスタム属性をトレースに適用すると、 トレースに注釈をつけることができますが、 特定のリクエストをトレースするかどうかを直接制御することはできません。
D. トレースはサンプリングやその他の設定に依存している可能性があるため、一定時間待っても特定のリクエストが常にトレースされるとは限りません。
正解
A. このヘッダーは、HTTPリクエストのトレースの動作を制御することができます。このヘッダーに適切なパラメーターを含めることで、特定のリクエストを確実にトレースすることができます。
Links:

https://cloud.google.com/trace/docs/setup#force-trace
</div></details>

## Q. 2-12
Google Kubernetes Engineの導入と、VS CodeやIntelliJを含む開発環境との統合を促進するために、開発者ツールを評価しています。

あなたは何をすべきでしょうか？
1. アプリケーションの開発には Cloud Code を使用します。
2. コードと設定ファイルを編集するには、Cloud Shell統合コードエディタを使用します。
3. Cloud Notebook インスタンスを使用して、データを取り込んで処理し、モデルをデプロイします。
4. Cloud Shellを使用して、コマンドラインからインフラストラクチャとアプリケーションを管理する。
<details><div>
    答え：1
説明
不正解
B. Cloud Shell 統合コード エディタを使用してコードと構成ファイルを編集できますが、GKE 開発用に特別に調整されているわけではなく、VS Code や IntelliJ と直接統合することはできません。
C. Cloud Notebookインスタンスは、Kubernetesの開発やデプロイよりも、データサイエンス、機械学習、アナリティクスのタスクに重点を置いている。
D. Cloud Shell は、コマンドラインからインフラストラクチャとアプリケーションを管理するために使用できますが、Cloud Code のような GKE との統合開発環境エクスペリエンスを提供しません。
正解
A. Cloud Codeは、VS CodeとIntelliJのためのプラグインのセットであり、KubernetesとGoogle Cloudで作業するための統合開発エクスペリエンスを提供します。このプラグインには、インタラクティブなクラスタとリソースの管理、ワンクリックでのKubernetesクラスタの作成、組み込みのデバッグと診断などの機能が含まれています。また、KubernetesとGoogle Cloud SDKを使用したアプリケーションの迅速なデプロイとデバッグもサポートする。さらにCloud Codeでは、開発者はアプリケーションのデプロイやデバッグ、リソースの管理、ローカル開発環境の実行などのタスクを簡単に実行できる。Cloud Codeは、KubernetesとGoogle Cloudの開発プロセスを効率化したいチームにとって最適なツールだ。
Links:

https://cloud.google.com/code
</div></details>

## Q. 2-13
Google Kubernetes Engine（GKE）への新しいコンテナイメージのデプロイを自動化するために、Cloud Buildを使用して継続的インテグレーションパイプラインを構成しています。パイプラインはソースコードからアプリケーションをビルドし、単体テストと統合テストを別々のステップで実行し、コンテナを Container Registry にプッシュします。アプリケーションはPythonウェブサーバ上で実行される。
Dockerfileは以下の通りです：

FROM python:3.7-alpine
FROM python:3.7-alpine
COPY . /app
WORKDIR /app
RUN pip install -r requirements.txt
CMD [ "gunicorn", "-w 4", "main:app" ]。

Cloud Buildの実行に予想以上に時間がかかっていることに気づきました。ビルド時間を短縮したい。どうしますか？(選択肢を2つ選んでください。）
1. Cloud Buildの実行には、CPUが高い仮想マシン（VM）サイズを選択します。
2. VPC内のCompute Engine VM上にContainer Registryをデプロイし、最終イメージを保存するために使用します。
3. ビルド設定ファイルの--cache-from引数を使用して、後続のビルド用にDockerイメージをキャッシュします。
4. Dockerfileのベースイメージをubuntu:latestに変更し、パッケージマネージャユーティリティを使ってPython 3.7をインストールする。
5. アプリケーションのソースコードをクラウドストレージに保存し、gsutil を使用してソースコードをダウンロードするようにパイプラインを設定します。
<details><div>
    答え：1,3
説明
不正解
B. VM上のContainer Registryは、ビルドをスピードアップしません。
D. ubuntuコンテナイメージはpython:3.7-alpineイメージよりかなり大きくなります。
E. アプリケーション・ソース・コードをクラウド・ストレージに保存しても、アプリケーションのビルド時間は短縮されません。
正解
A. C. 
CPUの高い仮想マシンタイプはビルド速度を向上させることができるため、Aが正しい。
Cは、テストやレジストリへのプッシュのために、後続のステップで同じコンテナが使用されるため、正しい。
Links:

https://cloud.google.com/cloud-build/docs/speeding-up-builds

https://cloud.google.com/build/docs/optimize-builds/increase-vcpu-for-builds
</div></details>

## Q. 2-14
あなたは、エンドユーザーからのリクエストを処理するアプリケーションを開発しています。アプリケーションから呼び出されるクラウド関数を保護し、許可されたエンドユーザーがアプリケーション経由で関数に認証できるようにする一方で、許可されていないユーザーからのアクセスを制限する必要があります。Googleサインインをソリューションの一部として統合し、Googleが推奨するベストプラクティスに従いたいと考えています。

どうすればよいでしょうか？
1. ソースコードリポジトリからデプロイし、ユーザーにroles/cloudfunctions.viewerロールを付与します。
2. ソースコードリポジトリからデプロイし、ユーザーにroles/cloudfunctions.invokerロールを付与します。
3. gcloudを使用してローカルマシンからデプロイし、ユーザーにroles/cloudfunctions.adminロールを付与します。
4. gcloudを使用してローカルマシンからデプロイし、ユーザーにroles/cloudfunctions.developerロールを付与します。
<details><div>
    答え：2
説明
不正解
A. このロールは、ユーザーに関数を表示する権限だけを与え、関数を呼び出す権限は与えません。要件は、許可されたユーザが認証して関数を起動できるようにすることなので、このロールは基準を満たしていません。
C. このロールは、関数を削除または変更する能力を含め、関数に対する管理者権限をユーザーに付与します。これは、単にエンドユーザーが関数を呼び出すことができるようにしたい、説明したシナリオには寛容すぎる可能性があります。
D. このロールは、Cloud Functionsを開発およびデプロイする権限を付与しますが、繰り返しますが、認証して特定の関数を呼び出す必要があるだけのエンドユーザーに与えたいものではありません。
正解
B. これにより、roles/cloudfunctions.invokerロールが付与され、権限のあるユーザが関数を呼び出すために必要な正確なパーミッションが提供されます。
Links:

https://cloud.google.com/functions/docs/securing/authenticating#authenticating_function_to_function_calls
</div></details>

## Q. 2-15
アプリケーションは顧客のコンテンツをCloud Storageバケットに保存し、各オブジェクトは顧客の暗号化キーで暗号化されます。Cloud Storageの各オブジェクトのキーは、顧客がアプリケーションに入力します。あなたは、アプリケーションがCloud Storageからオブジェクトを読み取るときにHTTP 4xxエラーを受け取っていることに気づきました。

このエラーの原因として何が考えられますか？
1. あなたは顧客のbase64エンコードされたキーでオブジェクトの読み取り操作を試みました。
2. あなたは暗号化キーのBase64エンコードされたSHA256ハッシュなしで読み取り操作を試みました。
3. 顧客によって指定された暗号化アルゴリズムを、読み取り操作の際に入力した。
4. 顧客の鍵のSHA256ハッシュをbase64エンコードしたオブジェクトに対して読み取り操作を試みた。
<details><div>
    答え：2
説明
不正解
A. これが読み取り操作を実行する正しい方法です。
C. 使用されたアルゴリズムは、このコンテキストでは通常4xxエラーを引き起こさない。
D. この説明は、クラウド・ストレージにおけるCSEK(Customer-Supplied Encryption Keys)の期待される動作とは一致しません。
正解です：
B. CSEK（Customer-Supplied Encryption Keys）を使用する場合、リクエストに暗号化キーのSHA256ハッシュを含める必要があります。ハッシュを含めないとHTTP 4xxエラーになります。これは正しいオプションです。
Links:

https://cloud.google.com/storage/docs/encryption/customer-supplied-keys#response
</div></details>

## Q. 2-16
あなたは、クライアントが特定の期間、あなたのウェブサイトからファイルをダウンロードできるようにするアプリケーションを開発しています。Googleが推奨するベストプラクティスに従いつつ、このタスクを完了するためにアプリケーションをどのように設計すべきでしょうか？
1. ファイルを電子メールの添付ファイルとしてクライアントに送信するようにアプリケーションを設定する。
2. ファイルにクラウドストレージ署名付きURLを生成して割り当てます。そのURLをクライアントがダウンロードできるようにする。
3. 有効期限を指定した一時的なクラウドストレージバケットを作成し、そのバケットにダウンロード権限を与えます。ファイルをコピーし、クライアントに送信する。
4. 有効期限を指定してHTTPクッキーを生成する。時間が有効であれば、Cloud Storageバケットからファイルをコピーし、クライアントがダウンロードできるようにする。
<details><div>
    答え：2
説明
不正解
A. 電子メールの添付ファイルとしてファイルを送信することは、一時的なファイルアクセスのためのスケーラブルで安全なソリューションではなく、電子メールのサイズ制限やフィルタリングの問題につながる可能性があります。
C. 期限を指定して一時的なCloud Storageバケットを作成するのは、不必要に複雑です。多数のバケットを管理することになるかもしれませんし、個々のファイルの有効期限を処理する簡単な方法を提供しません。
D. 有効期限付きのHTTPクッキーを生成することは、本質的にクラウド・ストレージと結びついていません。また、クラウド・ストレージ・バケットからファイルをコピーすることは、署名付きURLのようなクラウド・ストレージの組み込みの安全な機能を活用することなく、複雑さを追加します。
正解
B. クラウドストレージでファイルへの一時的なアクセスを提供するための推奨アプローチは、署名付きURLを生成することです。このURLはクライアントにファイルをダウンロードするための一時的なアクセスを与え、指定された期間が経過すると失効します。
Links:

https://cloud.google.com/storage/docs/access-control/signed-urls
</div></details>

## Q. 2-17
あなたは、給与計算用の社内アプリケーションを開発している開発者です。あなたは、従業員がタイムシートを提出し、いくつかのステップが開始されるアプリケーションのコンポーネントを構築しています：

- タイムシートが提出されたことを通知するメールが、従業員とマネージャーに送信されます。
- タイムシートがベンダーのAPIの給与処理に送信されます。
- タイムシートがデータウェアハウスに送信され、人員計画のために使用される。

これらのステップは互いに依存しておらず、どの順番で完了してもよい。新たなステップが検討されており、異なる開発チームによって実装される予定である。各開発チームは、それぞれのステップに固有のエラー処理を実装します。

あなたは何をすべきでしょうか？
1. 必要なアクションを完了するために対応するダウンストリームシステムを呼び出すクラウド関数を、ステップごとにデプロイします。
2. ステップごとにPub/Subトピックを作成する。下流の開発チームごとにサブスクリプションを作成し、そのステップのトピックをサブスクライブします。
3. タイムシート提出用のPub/Subトピックを作成する。各下流開発チームがトピックをサブスクライブするためのサブスクリプションを作成します。
4. Google Kubernetes Engineにデプロイされたタイムシートマイクロサービスを作成する。マイクロサービスはダウンストリームの各ステップを呼び出し、成功した応答を待ってから次のステップを呼び出します。
<details><div>
    答え：3
説明
不正解
A. 各ステップにクラウド関数をデプロイすると、密結合になる可能性があり、複数のクラウド関数を管理するのは面倒です。また、既存のシステムを変更することなく新しいステップに対応する明確な方法も提供しない。
B. 各ステップに個別の Pub/Sub トピックを作成すると、1 つのワークフローに対して複数のトピックを管理する必要があり、新しいステップを追加するには新しいトピックを作成する必要があるため、不要な複雑さが生じます。
D. 各ステップからの正常な応答を待ってから処理を進めるタイムシートマイクロサービスを作成することは、ステップを任意の順序で完了させることができるという要件に沿ったものではありません。このアプローチは逐次処理を導入し、ステップの1つが失敗した場合に単一障害点となり、プロセス全体に影響を与える可能性があります。
正解
C. が最も適切な選択です。これは、各ステップを異なるチームによって独立して実装し、そのステップに固有のエラー処理を行うことを可能にします。また、Pub/Subは並列処理を可能にするので、ステップを互いに待つことなく同時に処理することができます。さらに、既存のアーキテクチャを変更することなく新しいサブスクリプションを追加できるため、新しいステップの追加も簡単です。

リンク

https://cloud.google.com/pubsub/docs/overview</div></details>

## Q. 2-18
あなたはシンプルなHTMLアプリケーションをインターネット上で公開することを計画しています。このサイトは、あなたのアプリケーションの FAQ に関する情報を保持します。アプリケーションは静的で、画像、HTML、CSS、Javascript を含んでいます。あなたは、できるだけ少ないステップで、このアプリケーションをインターネット上で利用できるようにしたいと考えています。

あなたは何をすべきでしょうか？
1. アプリケーションをCloud Storageにアップロードする。
2. アプリケーションをApp Engine環境にアップロードします。
3. Apache WebサーバーがインストールされたCompute Engineインスタンスを作成する。アプリケーションをホストするためにApacheウェブサーバーを設定する。
4. まずアプリケーションをコンテナ化する。このコンテナをGoogle Kubernetes Engine（GKE）にデプロイし、アプリケーションをホストするGKEポッドに外部IPアドレスを割り当てる。
<details><div>
    答え：1
説明
不正解
B. App Engineは確かにWebアプリケーションをホストできますが、サーバー側の処理を必要とする、より動的なアプリケーション向けに設計されています。単純な静的ウェブサイトの場合、これは複雑になりすぎ、不必要なコストと管理オーバーヘッドにつながります。
C. このオプションは確かに実現可能だが、仮想マシンとウェブサーバーの設定とメンテナンスを手動で行う必要がある。単純に静的ファイルをクラウドストレージにホストするのに比べて、より複雑で時間がかかる。
D. このアプローチもまたより複雑で、オーケストレーションとスケーリングを必要とするアプリケーションに適している。単純な静的Webサイトの場合、アプリケーションをコンテナ化してKubernetesクラスタを管理するのはやりすぎで、追加のコストと複雑さが発生します。
正解
A. Cloud Storageは、画像、HTML、CSS、JavaScriptを含む静的ウェブサイトをホストするシンプルな方法を提供するので、正解です。ユーザーは、静的ファイルをクラウド・ストレージに簡単にアップロードでき、最小限の構成でインターネット上に提供できます。クラウド・ストレージは高い可用性と信頼性を提供し、高速で安全なユーザー体験を保証します。

そのため、選択肢Aは、問題で説明した静的HTMLアプリケーションをインターネット上で利用可能にするための、最もシンプルで、費用対効果が高く、効率的な方法として際立っています。

リンク

https://cloud.google.com/storage/docs/hosting-static-website

</div></details>

## Q. 2-19
低レベルのLinux設定ファイルにタイプミスがあり、Compute Engineインスタンスが通常のランレベルで起動できない。あなたは今日Compute Engineインスタンスを作成したばかりで、ファイルを微調整する以外に他のメンテナンスを行っていません。

このエラーをどのように修正すべきでしょうか？
1. scpを使用してファイルをダウンロードし、ファイルを変更し、変更したバージョンをアップロードします。
2. SSHでCompute Engineインスタンスに設定、ログインし、ファイルを変更する。
3. シリアルポートからCompute Engineインスタンスに設定、ログインし、ファイルを変更する。
4. リモートデスクトップクライアントを使用してCompute Engineインスタンスを構成し、ログインし、ファイルを変更する。
<details><div>
    答え：3
説明
不正解
A. 設定エラーのためにインスタンスが正しく起動できないので、標準的なSSHおよびSCP（Secure Copy Protocol）アクセスはおそらく利用できません。この状態では、SCPを使用してファイルをダウンロードまたはアップロードすることはできません。
B. この場合も、インスタンスは通常のランレベルにブートしていないため、SSHアクセスはおそらく無効になり、この方法でログインしてファイルを変更することはできません。
D. リモートデスクトップアクセスは、インスタンスが正しく起動し、必要なサービスが実行されていることにも依存します。インスタンスが正常な状態に起動していないため、リモートデスクトップクライアントを使用して接続してファイルを変更することはできません。
正解
C. Google Compute Engineは、期待通りに動作しないインスタンスのトラブルシューティングのために、シリアルコンソール出力へのアクセスを提供します。インスタンスが正しく起動しない場合、シリアルコンソールを使用して、物理マシンのようにインスタンスと直接対話することができます。これにより、低レベルの設定ファイルを変更し、エラーを修正することができます。

リンク

https://cloud.google.com/compute/docs/troubleshooting/troubleshooting-using-serial-console

</div></details>

## Q. 2-20
あなたの組織は最近、レガシー・アプリケーションをGoogle Kubernetes Engineにリプラットフォームする取り組みを始めました。モノリシックなアプリケーションをマイクロサービスに分解する必要があります。複数のインスタンスは、共有ファイルシステム上に保存されている設定ファイルへの読み取りと書き込みのアクセス権を持っています。この移行管理に必要な労力を最小限に抑え、アプリケーションコードの書き換えを避けたい。

アプリケーション・コードの書き換えは避けたい。
1. 新しいCloud Storageバケットを作成し、コンテナ内にFUSE経由でマウントします。
2. 新しい永続ディスクを作成し、そのボリュームを共有PersistentVolumeとしてマウントします。
3. 新しいFilestoreインスタンスを作成し、ボリュームをNFS PersistentVolumeとしてマウントします。
4. 新しいConfigMapとvolumeMountを作成して、構成ファイルの内容を保存します。
<details><div>
    答え：3
説明
不正解
A. Cloud Storageはファイルの共有に使用できますが、FUSEを使用してコンテナ内にマウントすると待ち時間が発生する可能性があり、共有ファイルシステムが必要な場合は通常推奨されません。また、FUSEはPOSIX準拠のファイルシステムを提供しないため、複数のインスタンスからの読み取り/書き込み操作に対応する際に不整合が生じる可能性があります。
B. GKE の永続ディスクは、複数のインスタンスが同時に読み書きアクセスでマウントするようには設計されていません。そうしようとすると、データの破損やその他の問題が発生する可能性があります。
D. ConfigMapは、コンテナ・イメージから切り離された方法で構成データを管理するためのものです。ConfigMapは読み取り専用でマウントされるため、読み取りおよび書き込みアクセスによる共有ファイルシステムの使用には適していません。
正解
C. 対照的に、オプションCは、マネージドファイルストレージサービスであるFilestoreを活用して、KubernetesのPersistentVolumeサブシステムと完全に互換性のあるNFS（ネットワークファイルシステム）を作成します。これは、複数のインスタンスが読み取りと書き込みアクセスでマウントできる共有ファイルシステムを提供し、アプリケーションコードを書き換えることなく要件に適合する。

リンク
https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes
https://cloud.google.com/filestore/docs/accessing-fileshares
https://cloud.google.com/storage/docs/gcs-fuse
</div></details>

## Q. 2-21
あなたのチームはGoogle Kubernetes Engine上で動作するサービスを開発しており、Googleが推奨するプラクティスを使用してログデータを標準化する必要があります。

最も効率的な方法でデータをより有用にするために取るべき2つのステップは何ですか？(2つの選択肢を選んでください)
1. アプリケーション・ログをBigQueryに集約してエクスポートし、ログ分析を容易にします。
2. アプリケーション・ログの集約エクスポートをクラウド・ストレージに作成し、ログ分析を容易にします。
3. ログ出力を標準出力（stdout）に単一行JSONとして書き込み、構造化ログとしてCloud Loggingに取り込む。
4. Cloud Loggingに構造化ログを書き込むために、アプリケーションコードでLogging APIを使用することを義務付ける。
5. Pub/Sub APIを使用して構造化データをPub/Subに書き込むことを義務付け、Dataflowストリーミングパイプラインを作成してログを正規化し、分析のためにBigQueryに書き込む。
<details><div>
    答え：3,4
説明
不正解
A. B. E. 
他の選択肢（A,B,E）は、特定の文脈では有効であるが、ログデータの効率的な標準化に直接関係しないか、不必要な複雑さをもたらす可能性がある（例えば、選択肢EはPub/SubやDataflowのような追加のコンポーネントを導入する）。選択肢 A と B は、より広範なログ戦略の一部かもしれませんが、システム内でログデータを標準化し利用する最も効率的な方法であるとは限りません。
正解
C. D. 
KubernetesとGoogle Cloudで作業するためのベストプラクティスに基づくと、オプションCとDは、通常、ログデータの効率的な標準化と構造化に沿ったステップになります：
C. C. ログ出力を単一行のJSONとして標準出力（stdout）に書き込むことで、KubernetesとCloud Loggingはログを構造化されたデータとして認識し、扱うことができます。この標準化により、ログの取り込みプロセスが簡素化され、下流の分析やクエリが容易になります。
D. Logging APIを直接使用して構造化ログを記述することで、ログエントリが確実にフォーマットされ、Cloud Loggingのプラクティスと一致する方法で処理されます。構造化されたログは、ログのクエリーと分析を容易にします。
リンク
https://cloud.google.com/stackdriver/docs/solutions/gke/managing-logs#best_practices
</div></details>

## Q. 2-22
あなたの会社の製品チームは、Google Kubernetes Engine (GKE)クラスターで稼働するステートレス分散サービスをオートスケールさせるという、顧客からの要求に基づく新しい要件を持っています。あなたは、この機能が2週間後に本番稼働するため、変更を最小限に抑えるソリューションを見つけたいと考えています。

あなたは何をすべきでしょうか？
1. Vertical Pod Autoscalerをデプロイし、CPU負荷に基づいてスケーリングします。
2. Vertical Pod Autoscalerをデプロイし、カスタムメトリックに基づいてスケーリングする。
3. 水平ポッドオートスケーラーをデプロイし、CPU負荷に基づいてスケーリングします。
4. 水平Pod Autoscalerをデプロイし、カスタムメトリックに基づいてスケーリングする。
<details><div>
    答え：3
説明
不正解
A. Vertical Pod Autoscalerをデプロイすると、既存のPodのサイズを変更することになり、スケールアウトまたはスケールインによって変動する負荷に対応する必要があるステートレス分散サービスには理想的ではありません。
B. オプションAと同様に、カスタムメトリックでVertical Pod Autoscalerを使用することになるが、水平スケーリングが必要なステートレスサービスには最適ではないかもしれない。
D. このオプションは正確な要件によっては有効なアプローチかもしれませんが、CPU負荷（オプションC）に基づくスケーリングは、ステートレスアプリケーションの自動スケーリングではより一般的なメトリックです。カスタムメトリックは、追加の設定を必要とする可能性があり、2週間の期限で変更を最小限に抑えようとする場合、最良の選択肢ではないかもしれません。
正解
C. このシナリオでは、ステートレスで分散したサービスのオートスケールに関する問題です。通常、負荷に応じてスケールアウト（インスタンスの追加）またはスケールイン（インスタンスの削除）を行う必要があります。需要に応じてスケールする必要があるステートレス・サービスの正しいアプローチは、CPU負荷などのメトリクスに基づいてサービスのインスタンス（ポッド）を追加または削除するHPA（Horizontal Pod Autoscaler）を使用することです。これは、未知の新しい要件を考慮すると、オートスケールのための最もシンプルでエントリーレベルのソリューションであるため、正しい選択である。
リンク
https://cloud.google.com/kubernetes-engine/docs/concepts/horizontalpodautoscaler
https://cloud.google.com/kubernetes-engine/docs/how-to/vertical-pod-autoscaling
https://cloud.google.com/kubernetes-engine/docs/concepts/verticalpodautoscaler
https://cloud.google.com/kubernetes-engine/docs/tutorials/autoscaling-metrics
</div></details>

## Q. 2-23
あなたは最近、Google Kubernetes Engine（GKE）にGoアプリケーションをデプロイしました。運用チームは、運用トラフィックが少ないときでもアプリケーションのCPU使用率が高いことに気づきました。運用チームは、アプリケーションのCPUリソース消費を最適化するようあなたに依頼しました。どの Go 関数が最も大量の CPU を消費しているかを特定する必要があります。

あなたは何をすべきですか？
1. GKEクラスタにFluent Bitデーモンセットをデプロイして、Cloud Loggingにデータを記録します。ログを分析して、アプリケーション・コードのパフォーマンスに関する洞察を得ます。
2. アプリケーションの CPU パフォーマンス・メトリクスを評価するために、Cloud Monitoring でカスタム・ダッシュボードを作成します。
3. SSH を使用して GKE ノードに接続します。シェルで top コマンドを実行して、アプリケーションの CPU 使用率を抽出します。
4. プロファイリング・データを取得するようにGoアプリケーションを修正します。Profilerのフレーム・グラフを使用して、アプリケーションのCPUメトリクスを分析します。
<details><div>
    答え：4
説明
不正解
A. データをロギングするためにFluent Bitデーモンセットをデプロイすると、一般的なログデータをキャプチャしてCloud Loggingに送信することができますが、Goアプリケーションのパフォーマンスを分析するために必要な関数レベルのCPU消費の詳細を具体的に提供することはできません。
B. Cloud Monitoring でカスタム・ダッシュボードを作成すると、アプリケーション・レベルで CPU パフォーマンス・メトリクスを監視できます。しかし、CPUを消費している特定のGo関数に関する詳細な洞察は得られません。
C. SSH を使用して GKE ノードに接続し、top コマンドを実行すると、さまざまなプロセスの CPU 使用率に関する情報が得られます。しかし、このアプローチでは、特定のGo関数を掘り下げて、どれが最もCPUを消費しているかを判断することはできません。
正解
D. プロファイリングデータを取得するようにGoアプリケーションを修正するのが、ここでの正しいアプローチです。Goにはプロファイリングのサポートが組み込まれており、関数レベルで詳細なCPUメトリクスを取得できます。Profilerのようなツールのフレームグラフを使ってプロファイリング・データを分析することで、どのGo関数が最もCPUを消費しているかを正確に判断し、最適化の対象とすることができます。この方法によって、観測された問題に特化した、集中的かつ効果的な最適化作業が可能になります。
リンク
https://cloud.google.com/profiler/docs
https://cloud.google.com/profiler/docs/about-profiler
</div></details>

## Q. 2-24
あなたはGoogle Kubernetes Engineクラスタにデプロイされるマイクロサービスベースのアプリケーションを開発しています。このアプリケーションはSpannerデータベースを読み書きする必要があります。あなたは、コードの変更を最小限に抑えながら、セキュリティのベストプラクティスに従いたいと考えています。

Spanner認証情報を取得するために、アプリケーションをどのように構成すべきでしょうか？
1. 適切なサービスアカウントを構成し、Workload Identity を使用してポッドを実行する。
2. アプリケーションの認証情報をKubernetesシークレットとして保存し、環境変数として公開します。
3. 適切なルーティングルールを設定し、VPCネイティブクラスタを使用してデータベースに直接接続する。
4. クラウド鍵管理サービスを使用してアプリケーション認証情報を保存し、データベース接続が行われるたびにそれを取得する。
<details><div>
    答え：1
説明
不正解
B. このオプションは機能するかもしれませんが、Workload Identityを使用するほど安全ではないと考えられます。Kubernetesシークレットはクレデンシャルをハードコーディングするよりは良いが、クラスタ内で公開される可能性がある。Workload Identityは、これらの権限をより安全に管理する方法です。
C. これでは資格情報の問題にまったく対処できません。ルーティングルールを構成し、VPCネイティブクラスタを使用することは、優れたネットワーク設計の一部になり得ますが、Spannerデータベースにアクセスするための資格情報を安全に取り扱うという問題を解決するものではありません。
D. このアプローチは不必要な複雑さを追加することになる。クラウド鍵管理サービス（KMS）は暗号化鍵を管理するための強力なツールですが、このユースケースでデータベースの資格情報の保存と取得に使用するのはやりすぎです。Workload Identityは、問題で説明されているユースケースのために特別に設計されており、より簡単なソリューションを提供します。
正解
A. GKE 上で実行されるアプリケーションは、Compute Engine API、BigQuery Storage API、Machine Learning API などの Google Cloud API にアクセスする必要があります。Workload Identity を使用すると、GKE クラスタ内の Kubernetes サービスアカウントを IAM サービスアカウントとして動作させることができます。設定された Kubernetes サービスアカウントを使用する Pod は、Google Cloud API にアクセスするときに自動的に IAM サービスアカウントとして認証されます。Workload Identityを使用すると、クラスタ内の各アプリケーションに個別のきめ細かいIDと権限を割り当てることができます。Google では、可能な限りサービスアカウントと Workload Identity を使用することを推奨しています。
リンク
https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity#what_is
https://kubernetes.io/docs/concepts/configuration/secret/#alternatives-to-secrets
</div></details>

## Q. 2-25
Google Cloudのさまざまなプロジェクトでコンテナを作成し、実行しています。開発中のアプリケーションは、Google Kubernetes Engine (GKE) 内から Google Cloud サービスにアクセスする必要があります。

あなたは何をすべきでしょうか？
1. GKEノードにGoogleサービスアカウントを割り当てます。
2. Workload Identityを使用してポッドを実行するには、Googleサービスアカウントを使用します。
3. Googleサービスアカウントの認証情報をKubernetesシークレットとして保存する。
4. GKE ロールベースアクセス制御（RBAC）で Google サービスアカウントを使用する。
<details><div>
    答え：2
説明
不正解
A. このアプローチでは、パーミッションを個々のポッドではなくGKEノードに関連付けるため、柔軟性が低くなり、これらのノードで実行されているすべてのポッドに過度に広範なパーミッションを付与する可能性があります。最小特権の原則に従わない。
C. 認証情報をKubernetes Secretとして保存すると、クラスタ内で機密情報が公開されます。ポッドが侵害された場合、これらの認証情報の漏洩につながる可能性があります。このアプローチは、Workload Identityを使用する場合と比較して、セキュリティのベストプラクティスに準拠していません。
D. GKE RBACはクラスタ内のアクセスを制御し、Googleクラウドサービスへの認証は制御しません。このアプローチはGoogle Cloud APIに直接アクセスする方法を提供しないため、この特定の要件に適したソリューションではありません。
正解
B. Workload Identityは、KubernetesサービスアカウントをIAMサービスアカウントとして機能させる。これにより、アプリケーションはクレデンシャルを直接扱うことなくGoogle Cloudサービスに認証することができ、ベストプラクティスに合致し、きめ細かなアクセス制御を提供できる。
リンク
https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity#what_is
</div></details>

## Q. 2-26
あなたは複数のマイクロサービスで構成されるアプリケーションを設計しています。各マイクロサービスには独自のRESTful APIがあり、個別のKubernetesサービスとしてデプロイされます。あなたは、APIに変更があったときにこれらのAPIのコンシューマが影響を受けないようにし、またAPIの新しいバージョンがリリースされたときにサードパーティのシステムが中断されないようにしたい。

Googleが推奨するベストプラクティスに従って、アプリケーションへの接続をどのように設定すべきでしょうか？
1. APIのURLを使って適切なバックエンドにリクエストをルーティングするIngressを使う。
2. サービスディスカバリーシステムを活用し、リクエストで指定されたバックエンドに接続します。
3. 複数のクラスタを使用し、DNSエントリを利用してリクエストを別々のバージョンのバックエンドにルーティングする。
4. 複数のバージョンを同じサービスにまとめ、POSTリクエストでAPIバージョンを指定する。
<details><div>
    答え：1
説明
不正解
B. サービスディスカバリーはクラスタ内でのみ機能するため、外部クライアントは使用できません。
C. 複数のクラスタを使用するのはやりすぎです。同じサービスの複数のバージョンを1つのクラスタ内にデプロイできます。
D. リクエストボディでAPIバージョンを渡すことは、RESTのベストプラクティスではありません。
正解
A. ベストプラクティスは、/v1/foo、/v2/fooのように、URLパスでAPIのバージョンを渡すことです。このアプローチを使用すると、Ingressリソースを使用して、GKEクラスタ内の適切なバックエンドサービスにリクエストをルーティングできます。
リンク
https://cloud.google.com/kubernetes-engine/docs/concepts/ingress#deprecated_annotation
https://cloud.google.com/kubernetes-engine/docs/concepts/ingress#features_of_https_load_balancing
</div></details>

## Q. 2-27
MySQLデータベースをGoogle CloudのマネージドCloud SQLデータベースに移行する予定です。このCloud SQLインスタンスに接続するCompute Engine仮想マシンインスタンスがあります。Compute EngineインスタンスがCloud SQLにアクセスするためのIPをホワイトリストに登録したくありません。

どうすればいいでしょうか？
1. Cloud SQLインスタンスのプライベートIPを有効にします。
2. Cloud SQLにアクセスするプロジェクトをホワイトリストに登録し、Compute Engineインスタンスをホワイトリストに登録されたプロジェクトに追加します。
3. Cloud SQLで、外部インスタンスからデータベースへのアクセスを許可するロールを作成し、そのロールをCompute Engineインスタンスに割り当てます。
4. あるプロジェクトにCloud SQLインスタンスを作成します。別のプロジェクトにCompute Engineインスタンスを作成します。これら2つのプロジェクト間でVPNを確立し、Cloud SQLへの内部アクセスを許可する。
<details><div>
    答え：1
説明
不正解です：
B. このオプションはホワイトリストに言及しているため無効です。
C. Cloud SQLは、この方法で外部インスタンスからのアクセスを制御するカスタムロールを作成する機能を提供していないため、このオプションは無効です。
D. このオプションは、理論的にはIPホワイトリストなしでCloud SQLとCompute Engineインスタンス間のセキュアな接続を提供できますが、プロジェクト間のVPN接続の管理など、不必要な複雑さをもたらします。プライベートIP（オプションA）を有効にすることは、よりシンプルで直接的なソリューションです。
正解
A. このページによると、Compute Engineからの接続には、'プライベートIP'、'パブリックIP'、'Cloud SQL Proxy'の3つの方法があります。Cloud SQL Proxy'オプションは回答に含まれていません。また、'Public IP'オプションはIPホワイトリストが必要です（質問によるとこれは受け入れられません）ので、唯一の有効な回答は'Private IP'です。
リンク
https://cloud.google.com/sql/docs/mysql/connect-compute-engine
https://cloud.google.com/sql/docs/mysql/connect-overview
</div></details>

## Q. 2-28
あなたはサーバーアプリケーションの負荷テストを行っています。最初の30秒の間に、以前はアクティブでなかったCloud Storageバケットが、1秒あたり2,000の書き込みリクエストと1秒あたり7,500の読み取りリクエストに対応していることを確認しました。アプリケーションは、要求が増加するにつれて、Cloud Storage JSON APIから断続的に5xxと429のHTTPレスポンスを受信するようになりました。Cloud Storage APIからの失敗した応答を減らしたい。

何をすべきでしょうか？
1. アップロードを多数の個別のストレージバケットに分散します。
2. クラウドストレージとのインターフェースにJSON APIではなくXML APIを使用する。
3. アプリケーションからアップロードを呼び出しているクライアントにHTTPレスポンスコードを戻します。
4. アプリケーションのクライアントからのアップロード速度を制限して、休止状態のバケツのピーク要求速度に徐々に到達するようにします。
<details><div>
    答え：4
説明
不正解
A. アップロードを多数の個別のストレージバケットに分散させると、失敗した応答が必ずしも減らない可能性があり、システムの複雑さが増す可能性があります。
B. JSON API の代わりに XML API を使用しても、パフォーマンスが向上するとは限らず、アプリケーションに大幅な変更が必要になる可能性がある。
C. HTTP応答コードをクライアントに戻すと、問題の根本原因に対処できない可能性があり、さらにエラーが発生する可能性があります。
正答
D. アップロードレートを制限することで、リクエストのレートを制御し、Cloud Storage APIが圧倒されるのを防ぎます。ピーク・リクエスト・レートに徐々に到達することで、システムがスケールして応答する時間を与え、応答が失敗する可能性を減らすことができる。したがって、このアプローチは観察された問題に直接対処し、与えられた選択肢の中で最良の選択である。
リンク
https://cloud.google.com/storage/docs/request-rate#ramp-up
</div></details>

## Q. 2-29
あなたの開発チームは、既存のモノリシックなアプリケーションをコンポーザブルなマイクロサービス群にリファクタリングするよう求められています。新しいアプリケーションには、どのような設計面を実装すべきでしょうか？(2つの選択肢を選んでください)
1. マイクロサービスの呼び出し元が使用するのと同じプログラミング言語でマイクロサービスのコードを開発する。
2. マイクロサービス実装とマイクロサービス呼び出し元との間でAPI契約書を作成する。
3. すべてのマイクロサービス実装とマイクロサービス呼び出し元との間で非同期通信を要求する。
4. パフォーマンス要件に対応するために、マイクロサービスの十分なインスタンスが実行されていることを確認する。
5. 現在のインターフェイスと互換性がない可能性のある将来の変更を許可するために、バージョニングスキームを実装する。
<details><div>
    答え：2,5
説明
不正解
A. 柔軟性を制限します。マイクロサービスは異なる言語で開発できます。
C. 通信は、一律の要件ではなく、特定のニーズに基づいて選択されるべきである。
D. これは基本的な設計の側面ではなく、運用上の懸念事項です。
正解
B. マイクロサービスがどのように相互作用するかを定義し、明確性を確保し、統合の問題を減らします。
E. 既存のクライアントを壊すことなく、マイクロサービスが独立して進化することを可能にする。
リンク
https://cloud.google.com/appengine/docs/standard/java/designing-microservice-api#using_strong_contracts
</div></details>

## Q. 2-30
目下の課題は、Google Kubernetes Engineクラスタ内の様々なチームのアプリケーション間でリソースを共有するためのポリシーを作成することだ。目的は、すべてのアプリケーションが円滑な運用のために必要なリソースにアクセスできることを保証することです。

この目標を達成するために、2つの具体的な対策を講じる必要があります。
1. オブジェクトの仕様でリソースの制限と要求を指定する。
2. チームごとにネームスペースを作成し、各ネームスペースにリソースのクォータを割り当てます。
3. LimitRangeを作成して、各ネームスペースのデフォルトの計算リソース要件を指定します。
4. アプリケーションごとにKubernetesサービスアカウント（KSA）を作成し、各KSAをネームスペースに割り当てます。
5. Anthosポリシーコントローラーを使用して、すべてのネームスペースにラベルアノテーションを強制します。テイントとトレレーションを使用して、ネームスペースのリソース共有を許可します。
<details><div>
    答え：2,3
説明
不正解
A. D. E. 
選択肢（A、D、E）は、説明されたコンテキストで異なるチームのアプリケーション間でリソースを共有するためのポリシーを作成するタスクに直接対応していません。
正解
B. こうすることで、チームが消費できるリソースに制限を設けることができ、1つのチームがクラスタのすべてのリソースを消費することがなくなり、すべてのチーム間でリソースが公平に共有されます。
C. LimitRangeを使用すると、特定のネームスペース内のすべてのPodに対してデフォルトの制限と要求を設定できます。また、そのネームスペース内のPodが、定義されたLimitRangeを超えるリソースを決して消費できないようにします。
リンク
https://cloud.google.com/blog/products/containers-kubernetes/kubernetes-best-practices-resource-requests-and-limits
https://kubernetes.io/docs/concepts/policy/resource-quotas/
https://kubernetes.io/docs/concepts/policy/limit-range/
</div></details>

## Q. 2-31
継承した App Engine 上でアプリケーションを実行しており、そのアプリケーションが安全でないバイナリを使用しているかどうか、または XSS 攻撃に対して脆弱であるかどうかを調べたいとします。

どのサービスを使うべきですか？
1. クラウド・アーマー
2. スタックドライバー・デバッガー
3. クラウドセキュリティスキャナ
4. スタックドライバエラーレポート
<details><div>
    答え：3
説明
不正解
A. クラウドアーマーは、分散型サービス拒否（DDoS）保護とアプリケーションレベルの保護を提供するWebアプリケーションファイアウォール（WAF）であり、特に安全でないバイナリやXSS攻撃などの脆弱性をスキャンするようには設計されていません。
B. Stackdriver Debugger は、Google Cloud で実行されているアプリケーションのデバッグに使用され、コードの動作に関する詳細な洞察を提供しますが、特にセキュリティ・スキャン用に設計されていません。
D. Stackdriver Error Reporting は、Google Cloud 内のアプリケーションに対してリアルタイムのエラー追跡と分析を提供し、開発者がセキュリティ脆弱性ではなく、アプリケーションのエラーを特定して理解できるようにします。
正解
C. Cloud Security Scannerは、XSSを含む一般的な脆弱性について、App Engine、Compute Engine、Google Kubernetes Engineアプリケーションをスキャンするように設計されているため、このタスクの正しい選択肢です。
リンク
https://cloud.google.com/security-scanner
https://cloud.google.com/appengine/docs/standard/python/application-security
</div></details>

## Q. 2-32
AndroidアプリとiOSアプリで使用するAPIを開発中です。

HTTPSをサポートし、帯域幅コストを最小限に抑え、モバイルアプリと簡単に統合する必要がある場合、どのようなアーキテクチャが適しているでしょうか？
1. RESTful API
2. API向けMQTT
3. gRPCベースのAPI
4. SOAPベースのAPI
<details><div>
    答え：3
説明
不正解
A. HTTPS は広く使用されサポートされていますが、RESTful API は通常 JSON を使用します。
B. MQTTは、IoTアプリケーションでよく使用される軽量メッセージングプ ロトコルである。低帯域幅、高遅延のネットワーク向けに設計されているが、一般的なモバイルアプリのAPI開発には通常使用されない。
D. SOAPベースのAPI： SOAPは、構造化された情報を交換するためのプロトコルである。HTTPSをサポートできますが、他のオプションよりも冗長な傾向があり、帯域幅コストが高くなります。
正解です：
C. gRPCは、構造化データをシリアライズする手法であるプロトコル・バッファ（protobufs）を使用し、軽量かつ高速に設計されています。HTTPSをサポートし、帯域幅の面で非常に効率的であるため、モバイル・アプリケーションに適しています。
リンク
https://cloud.google.com/blog/products/api-management/understanding-grpc-openapi-and-rest-and-when-to-use-them
https://grpc.io/blog/mobile-benchmarks/
</div></details>

## Q. 2-33
Cloud Buildを使用して、Cloud Source Repositoriesリポジトリへのソースコードのコミットごとに新しいDockerイメージを作成しています。アプリケーションはmasterブランチへのコミットごとにビルドされますが、自動化された方法でmasterブランチへの特定のコミットをリリースしたいとします。

どうすればいいでしょうか？
1. 新しいリリースのビルドを手動でトリガーする。
2. Gitタグパターンに基づいてビルドトリガーを作成し、新しいリリースにはGitタグ規約を使用する。
3. Gitブランチの名前パターンに基づいてビルド・トリガーを作成し、新しいリリースにはGitブランチの命名規則を使う。
4. ソースコードを別の Cloud Build トリガーで 2 つ目の Cloud Source Repositories リポジトリにコミットし、このリポジトリを新規リリースのみに使用します。
<details><div>
    答え：2
説明
不正解
A. 手動で新しいリリースのビルドをトリガーしても、必要な自動化された方法は提供されません。
C. Gitブランチ名のパターンに基づいてビルド・トリガーを作成し、新しいリリースのためにGitブランチの命名規則を使用すると、より複雑なブランチ構造になる可能性がある。これは、タグを使って特定のリリースをマークするほど明確でも簡潔でもないかもしれません。
D. 別の Cloud Build トリガーを使用してソース コードを 2 つ目の Cloud Source Repositories リポジトリにコミットすることは、より面倒なアプローチであり、リポジトリ間の重複や同期の問題につながる可能性があります。
正解
B. Git タグパターンに基づいてビルドトリガーを作成し、新規リリース用の Git タグ規約を使うことで、どのコミットをリリースするのかを指定することができます。この方法は、タグ付けされたリリースのビルドプロセスを自動化し、ベストプラクティスに沿ったものになります。
リンク
https://cloud.google.com/source-repositories/docs/integrating-with-cloud-build#create_a_build_trigger
https://docs.docker.com/docker-hub/builds/
</div></details>

## Q. 2-34
あなたは Cloud Spanner 顧客データベースのスキーマを設計しています。顧客テーブルに電話番号配列フィールドを格納し、ユーザーが電話番号で顧客を検索できるようにしたいとします。

このスキーマをどのように設計しますか？
1. Customersという名前のテーブルを作成し、顧客の電話番号を格納するArrayフィールドをテーブルに追加します。
2. Customersという名前のテーブルとPhonesという名前のテーブルを作成する。
3. Customersという名前のテーブルを作成し、顧客の電話番号を保持するArrayフィールドをテーブルに追加します。
4. Customers という名前のテーブルを親テーブルとして作成します。
<details><div>
    答え：4
説明
不正解
A. 配列フィールドに電話番号を格納すると、電話番号による検索を簡単にサポートできません。
B. 電話番号からCustomerIdを検索するために、PhonesテーブルにCustomerIdフィールドを追加します。
CustomersテーブルとPhonesテーブルを別々に作成すると、電話番号による検索が可能になりますが、顧客と電話番号のリレーションシップが強い場合、ローカリティを最適化できない可能性があります。
C. Arrayフィールドにセカンダリインデックスを作成します。
Cloud SpannerはArrayフィールドのセカンダリインデックスをサポートしていないため、このオプションは実行できません。https://cloud.google.com/spanner/docs/data-types
正解
D. Phonesという名前のテーブルを作成し、このテーブルをCustomersテーブルにインターリーブします。
Phonesテーブルの電話番号フィールドにインデックスを作成します。
インターリーブ・テーブル構造を作成することで、CustomersとPhonesの間に親子関係が確立され、一緒にアクセスされることが多いデータのローカリティが維持されます。Phonesテーブルの電話番号フィールドにインデックスを作成することで、電話番号による効率的な検索が可能になります。
したがって、オプションDは与えられた要件に最適な設計です。
リンク
https://cloud.google.com/spanner/docs/schema-design#creating-indexes
https://cloud.google.com/spanner/docs/data-types
</div></details>

## Q. 2-35
Google Kubernetes Engineでホストされているウェブサイトの新しいヨーロッパバージョンをデプロイする必要があります。現在のウェブサイトと新しいウェブサイトは、同じHTTP(S)ロードバランサーの外部IPアドレス経由でアクセスする必要がありますが、ドメイン名は異なります。

あなたは何をすべきでしょうか？
1. 新しいドメインにマッチするホストルールで新しいIngressリソースを定義します。
2. 新しいドメインにマッチするホストルールで、既存のIngressリソースを修正する。
3. 既存のIPアドレスをloadBalancerIPとして指定して、LoadBalancerタイプの新しいサービスを作成する。
4. 新しいIngressリソースを生成し、既存のIPアドレスをkubernetes.io/ingress.global-static-ip-nameとして指定する。
<details><div>
    答え：2
説明
不正解
A. 既存のIPアドレスを指定せずに新しいIngressリソースを定義すると、通常、新しいIPアドレスを持つ新しいロードバランサーが作成されます。
C. LoadBalancerタイプの新しいサービスを作成すると、異なるドメイン名のホストルールを指定することができません。
D. 新しいIngressリソースを生成し、既存のIPアドレスを指定することは解決策のように見えるかもしれませんが、選択肢Bで説明したように、新しいIngressを作成するよりも、既存のIngressを変更する方が適しています。
正解
B. 新しいホストルールを含むように既存のIngressリソースを変更すると、同じロードバランサーとIPアドレスを使用して新しいドメイン名のトラフィックを処理できるようになります。したがって、オプションBが正しい選択です。
リンク
https://kubernetes.io/docs/concepts/services-networking/ingress/#name-based-virtual-hosting
https://cloud.google.com/kubernetes-engine/docs/tutorials/configuring-domain-name-static-ip
</div></details>

## Q. 2-36
あなたは、1つのPub/Subトピックからメッセージをサブスクライブして受信し、対応する行をデータベースに挿入するアプリケーションを設計しています。アプリケーションはLinux上で実行され、プリエンプト可能な仮想マシンを活用してコストを削減します。あなたは、グレースフル・シャットダウンを開始するシャットダウン・スクリプトを作成する必要があります。

あなたは何をすべきですか?
1. プロセス間シグナルを使用して、アプリケーション・プロセスにデータベースからの切断を通知するシャットダウン・スクリプトを記述します。
2. サインインしているすべてのユーザーに、Compute Engineインスタンスがダウンする旨のメッセージをブロードキャストし、現在の作業を保存してサインアウトするように指示するシャットダウンスクリプトを作成します。
3. アプリケーションがポーリングしている場所に、5分ごとにファイルを書き込むシャットダウンスクリプトを記述する。ファイルが読み込まれた後、アプリケーションはデータベースから切断する。
4. シャットダウンが進行中であることを知らせるメッセージをPub/Subトピックに発行するシャットダウンスクリプトを記述します。アプリケーションがメッセージを読み取ったら、データベースから切断します。
<details><div>
    答え：1
説明
不正解
B. サインインしているすべてのユーザーにメッセージをブロードキャストすることは、アプリケーションを優雅にシャットダウンし、データベースから切断するという目的とは関係ありません。
C. アプリケーションが5分ごとにポーリングするファイルを書き込むのは、特に即時のシャットダウンが必要な場合、間接的で効率が悪い方法です。
D. Pub/Subトピックへのメッセージの発行も間接的な方法であり、特に他のサブスクライバが同じトピックをリッスンしている場合は、さらに複雑な問題が発生する可能性があります。
正解
A. プロセス間シグナルを使用してアプリケーションプロセスに通知することは、グレースフル・シャットダウンを開始する一般的な方法です。これにより、アプリケーションは、開いている接続をすべて閉じ、必要なクリーンアップタスクを実行することで、シグナルに応答することができます。つまり、これはグレースフル・シャットダウンを実現する最も簡単で効果的な方法なのです。
リンク
https://cloud.google.com/compute/docs/instances/preemptible#preemption
</div></details>

## Q. 2-37
Google Kubernetes Engine（GKE）に、Pub/Subメッセージを読み込んで処理するアプリケーションをデプロイしている。各Podは1分間に固定数のメッセージを処理します。メッセージがPub/Subトピックにパブリッシュされる速度は、1日や1週間を通してかなり変化します。

タイムリーにメッセージを処理できるように、GKE デプロイメントを拡張したいとします。ワークロードを自動的に適応させるために、どの GKE 機能を使うべきですか?
1. 自動モードでの垂直ポッドオートスケーラー
2. 推奨モードのVertical Pod Autoscaler
3. 外部メトリックに基づく水平ポッドオートスケーラー
4. リソース使用率に基づく水平ポッドオートスケーラー
<details><div>
    答え：3
説明
不正解
A. AutoモードのVertical Pod Autoscalerは、既存のPodのCPUとメモリを調整しますが、外部メトリクスに基づいてPodを追加または削除することはありません。
B. 推奨モードのVertical Pod Autoscalerは、CPUとメモリの推奨設定を提供しますが、自動調整は行いません。
D. リソース使用率に基づく水平Pod Autoscalerは、CPUまたはメモリ使用率に基づいてPodをスケーリングします。
正解
C. Horizontal Pod Autoscaler（HPA）は、観察されたメトリックに応じてデプロイメント内のポッド数を自動的にスケールできるため、この作業に適したツールです。具体的には、外部メトリクス（Pub/Subキュー内の未処理メッセージ数など）を使用してスケーリングを実行します。
リンク
https://cloud.google.com/kubernetes-engine/docs/tutorials/autoscaling-metrics#pubsub
https://cloud.google.com/kubernetes-engine/docs/concepts/custom-and-external-metrics
</div></details>

## Q. 2-38
目的は、App Engineにウェブサイトをデプロイし、URL http://www.altostrat.com/ からアクセスできるようにすることです。

どのようなアクションが必要だと思いますか？
1. ウェブマスターセントラルでドメインの所有権を確認する。App Engineの正規名ghs.googlehosted.comを指すDNS CNAMEレコードを作成します。
2. Webmaster Centralでドメインの所有権を確認します。単一のグローバルApp Engine IPアドレスを指すようにAレコードを定義します。
3. dispatch.yamlでマッピングを定義して、ドメインwww.altostrat.com をApp Engineサービスに指定します。App Engineの正規名ghs.googlehosted.comを指すDNS CNAMEレコードを作成します。
4. dispatch.yamlでマッピングを定義し、ドメインwww.altostrat.com をApp Engineサービスに向けます。単一のグローバルApp Engine IPアドレスを指すように、Aレコードを定義します。
<details><div>
    答え：1
説明
不正解
B. このオプションにはドメインの所有権の確認が含まれますが、単一のグローバルIPアドレスにAレコードを定義することは、IPアドレスが変更される可能性があるため、App Engineでは推奨されません。
C. dispatch.yamlでマッピングを定義することは関連性があるように見えるかもしれませんが、単にカスタムドメインをApp Engineにマッピングする場合には必須のステップではありません。DNS CNAMEレコードの作成は正しいですが、ドメインの所有権の確認ができないため、このオプションは不完全です。
D. オプションBと同様に、これには単一のIPアドレスを指すAレコードの定義が含まれますが、これは推奨されません。また、dispatch.yamlでマッピングを定義することは、この目的には必要な手順ではありません。ドメイン所有権の確認がないため、この選択肢は正しくありません。
正解
A. このオプションは、カスタムドメインをApp Engineにマッピングする標準的な手順の概要です：
Webmaster Centralでドメインの所有権を確認します。App Engineの正式名称ghs.googlehosted.comを指すDNS CNAMEレコードを作成し、カスタムドメインの解決先をApp Engineアプリケーションにします。
リンク
https://cloud.google.com/appengine/docs/flexible/mapping-custom-domains
</div></details>

## Q. 2-39
アプリケーションはユーザーから入力を受け取り、それをユーザーの連絡先に公開します。この入力はCloud Spannerのテーブルに保存されます。あなたのアプリケーションはレイテンシに敏感で、一貫性にはあまり敏感ではありません。

このアプリケーションでは、Cloud Spannerからの読み取りをどのように実行すべきですか？
1. 読み取り専用トランザクションを実行します。
2. シングルリード方式でステールリードを実行する。
3. シングルリード方式でストロングリードを実行する。
4. 読み書きトランザクションを使用してステイルリードを実行する。
<details><div>
    答え：2
説明
不正解
A. 読み取り専用トランザクションは、特定のタイムスタンプにおけるデータベースの一貫したビューを提供します。ただし、一貫性よりも待ち時間を優先することはありません。
C. 強力な読み取りは、最新のコミット値を確実に読み取るため、一貫性は確保されるが、必ずしも低レイテンシを優先するわけではない。
D. 読み書きトランザクションは一般的に、読み取りと書き込みの両方を必要とする操作に使用されます。
正解：
B. ステイル・リードでは、古い可能性のある値を読み取ることができます。これにより、同時実行中の書き込みの完了を待たずに読み取りを進めることができるため、レイテンシが改善される可能性があります。これは、一貫性よりもレイテンシを優先するアプリケーションに沿った選択肢です。
リンク
https://cloud.google.com/spanner/docs/best-practices-gaming-database

</div></details>

## Q. 2-40
あなたはGoogle Cloud上で動作するウェブアプリケーションを開発しています。トラフィックがない日もあれば、急増する日もあります。アプリケーションを自動的にスケールアップ/スケールダウンする必要があり、アプリケーションの実行に関連するコストを最小限に抑える必要があります。

あなたは何をすべきでしょうか？
1. Firestoreをデータベースとしてアプリケーションを構築します。アプリケーションをCloud Runにデプロイします。
2. データベースとしてFirestoreを使用してアプリケーションを構築します。アプリケーションをGoogle Kubernetes Engine Standardクラスタにデプロイします。
3. データベースとしてCloud SQLを使用してアプリケーションを構築する。アプリケーションをGoogle Kubernetes Engine Autopilotクラスタにデプロイする。
4. Firestore をデータベースとしてアプリケーションを構築する。アプリケーションをオートスケーリング機能付きのCompute Engineマネージド・インスタンス・グループにデプロイする。
<details><div>
    答え：1
説明
不正解
B. GKEはゼロまでスケールしないため、Bは不正解です。
C. GKEはゼロまでスケールしないので、Cは正しくない）。また、Cloud SQLの実行にはコストがかかります。
D. Compute Engineは、ゼロスケールしないインスタンスを管理する。最低1つのインスタンスを実行する必要があります。
正解
A. Cloud Runはゼロへのスケーリングをサポートします。また、Firestoreのコストはストレージのみです。つまり、トラフィックがない場合、運用コストはゼロだ。
リンク
https://cloud.google.com/serverless-options
https://cloud.google.com/appengine/docs/the-appengine-environments
https://cloud.google.com/run
</div></details>

## Q. 2-41
開発中の Cloud Run サービスのロギングを設定しています。コンテナインスタンスは構造化されたログを標準出力（stdout）と標準エラー（stderr）ストリームに書き込みます。あなたは、自動的に作成されたリクエストログとコンテナログを関連付けたいと考えています。

どうすればよいでしょうか？
1. Cloud Traceにトレースを送信するようにアプリケーションをインスツルメンテーションします。
2. スナップショット・デバッガを使用して、各リクエストに対してランダムに生成された一意の識別子でログポイントを追加します。
3. X-Cloud-Trace-Contextヘッダー値を持つログ文にlogging.googleapis.com/traceフィールドを追加します。
4. ログ文に logging.googleapis.com/labels フィールドを追加し、各リクエストに対してランダムに生成された一意の識別子を付けます。
<details><div>
    答え：3
説明
不正解
A. このオプションはリクエストをトレースするのに役立ちますが、ログを関連付ける方法については直接言及していません。
B. このオプションは Cloud Run でのログの関連付けと直接は一致せず、特定のコード ポイントのデバッグにより関連する可能性があります。
D. このオプションは、自動的に作成される要求ログと特に相関しません。また、ランダムに生成された識別子は、望ましい相関を提供しない可能性があります。
正解
C. logging.googleapis.com/trace フィールドをログ文に追加し、X-Cloud-Trace-Context ヘッダーの値に設定することで、リクエストログとコンテナログの相関を有効にします。これにより、リクエストログとコンテナログをリンクしてトレースできるようになり、デバッグやパフォーマンス解析が容易になります。
リンク
https://cloud.google.com/run/docs/logging#correlate-logs
https://cloud.google.com/logging/docs/structured-logging
</div></details>

## Q. 2-42
トラフィックの大幅な増加に対応できるように、認証サービスからの監査イベントの取り込みを再設計する必要があります。現在、監査サービスと認証サービスは同じCompute Engine仮想マシンで実行されています。それぞれのサービスをCompute Engine VMインスタンスのプールに分割し、Pub/Subを使用して認証サービスから監査サービスにイベントを送信する予定です。

システムが大量のメッセージを処理し、効率的に拡張できるようにするには、Pub/Subトピックとサブスクリプションをどのように設定すればよいですか?
1. Pub/Subトピックを1つ作成します。プル・サブスクリプションを1つ作成します。
2. Pub/Sub トピックを 1 つ作成します。監査サービス・インスタンスごとに 1 つのプル・サブスクリプションを作成します。
3. 1つのPub/Subトピックを作成する。プッシュサブスクリプションを1つ作成する。
4. 認証サービスインスタンスごとに1つのPub/Subトピックを作成する。トピックごとに1つのプル・サブスクリプションを作成する。
5. 認証サービスインスタンスごとに1つのPub/Subトピックを作成する。トピックごとに1つのプッシュサブスクリプションを作成する。
<details><div>
    答え：1
説明
不正解
B. インスタンスごとにプル・サブスクリプションを作成すると、各サブスクリプションでメッセージが重複し、同じメッセージが複数回処理されることになります。
C. プッシュサブスクリプションを使用することもできますが、プルサブスクリプションほど大量のメッセージを処理するのに適していないかもしれません。プッシュエンドポイントの管理と再試行の処理には、さらなる複雑さとオーバーヘッドがあるかもしれません。
D. 認証インスタンスごとにトピックを作成すると、不必要に複雑になり、メッセージが監査サービスインスタンスに均等に分散されない可能性があります。これは、不均一なスケーリングと追加の管理オーバーヘッドにつながる可能性がある。
E. このオプションも、インスタンスごとにトピックとプッシュサブスクリプションを持つことによる複雑さをもたらす。さらに、プッシュサブスクリプションは大量のメッセージの処理に最適ではないため、スケーリングの問題が発生する可能性があります。
正解
A. このセットアップにより、重複することなくスケーラブルにメッセージを取り込み、処理することができます。これは柔軟で、負荷に応じて拡張でき、監査サービスが必要に応じてメッセージをプルできるようにします。
リンク
https://cloud.google.com/pubsub/docs/subscriber#push-subscription
</div></details>

## Q. 2-43
ソーシャルメディア・アプリケーションに画像アップロード機能を組み込み、ユーザーが2MBから1GBまでの画像をアップロードできるようにすることである。目的は、この機能に関連するインフラ運用のオーバーヘッドを削減することである。
1. 画像を直接受け付けるようにアプリケーションを変更し、他のユーザー情報を保存するデータベースに保存します。
2. アプリケーションを変更して、クラウド・ストレージ用の署名付きURLを作成する。これらの署名付きURLをクライアントアプリケーションに転送し、画像をクラウドストレージにアップロードする。
3. GCP上に、ユーザー画像を受け入れるためのWebサーバーをセットアップし、アップロードされたファイルを保存するためのファイルストアを作成する。ファイルストアから画像を取得するようにアプリケーションを変更する。
4. クラウドストレージにユーザーごとに個別のバケットを作成する。それぞれのバケットに書き込みアクセスを許可する別のサービスアカウントを割り当てる。ユーザー情報に基づいて、サービス・アカウントの認証情報をクライアント・アプリケーションに転送する。アプリケーションはこのサービスアカウントを使って画像をクラウドストレージにアップロードする。
<details><div>
    答え：2
説明
不正解
A. データベースに大きなファイルを保存すると、パフォーマンスと管理に重大な問題が発生する可能性があります。この方法で1GBまでのファイルを扱うと、運用が複雑になる可能性があり、通常は推奨されません。
C. このオプションでは、Webサーバーとファイルストレージを管理する必要があり、運用のオーバーヘッドが増加します。
D. このオプションは、各ユーザーに個別のバケットとサービスアカウントで不必要な複雑さを生み出し、高い運用オーバーヘッドにつながる可能性があります。
正解
B. クラウド・ストレージの強みを活かして大容量ファイルを扱い、署名付きURLを使用してクライアントが画像を直接アップロードできるようにすることで、アプリケーションのインフラストラクチャの負荷と複雑さを軽減します。
リンク
https://cloud.google.com/blog/products/storage-data-transfer/uploading-images-directly-to-cloud-storage-by-using-signed-url
</div></details>

## Q. 2-44
あなたは、モノリシックなアプリケーションをマイクロサービスモデルに従うように再構築したい。この変更がビジネスに与える影響を最小限に抑えながら、これを効率的に達成したい。

どのアプローチを取るべきでしょうか？
1. アプリケーションをCompute Engineにデプロイし、オートスケールをオンにします。
2. アプリケーションの機能を適切なマイクロサービスに段階的に置き換える。
3. モノリシックなアプリケーションを適切なマイクロサービスで一気にリファクタリングし、デプロイする。
4. モノリスとは別に適切なマイクロサービスで新しいアプリケーションを構築し、新しいアプリケーションが完成したらモノリスを置き換える。
<details><div>
    答え：2
説明
不正解
A. このオプションは、実際にはマイクロサービスアーキテクチャへの移行には対応していません。単に既存のモノリスを別のホスティングソリューションに移行し、オートスケールを有効にするだけです。
C. このオプションはマイクロサービスへの移行を目的としているが、すべてを一度に行うことは非常にリスクが高い。何か問題が発生した場合、ビジネスへの影響は相当なものになる可能性がある。
D. このアプローチは有効かもしれないが、並行開発に多額の投資が必要になるかもしれない。また、オプションCと同じリスクを伴うビッグバンリリースにつながるかもしれません。
正解
B. このアプローチは、モノリスからマイクロサービスへの段階的な変換を可能にします。段階的に行うことで、ビジネスの中断を最小限に抑えて運用を継続することができ、問題が発生したときに監視して対処することができます。
リンク
https://cloud.google.com/architecture/migrating-a-monolithic-app-to-microservices-gke
</div></details>

## Q. 2-45
Knativeで動作するオンプレミスのコンテナをGoogle Cloudに移行したい。移行がアプリケーションのデプロイ戦略に影響しないことを確認する必要があり、フルマネージドサービスを利用したいと考えています。

コンテナのデプロイには、どのGoogle Cloudサービスを使うべきでしょうか？
1. Cloud Run
2. コンピュートエンジン
3. Google Kubernetes Engine
4. App Engineの柔軟な環境
<details><div>
    答え：1
説明
不正解
B. これはIaaS（Infrastructure as a Service）サービスであり、コンテナやサーバーレスプラットフォームではありません。Knativeが提供するサーバーレス機能は提供しない。
C. GKEはマネージドKubernetesサービスであり、Knativeによって管理されたコンテナを実行することができるが、Cloud Runのようなフルマネージドのサーバーレスエクスペリエンスは提供しない。
D. これはコンテナをサポートするPlatform as a Service (PaaS)ですが、Cloud RunほどKnativeのサーバーレスモデルと密接に連携していません。
正解
A. Cloud RunはKnativeと互換性があり、Knativeベースのアプリケーションをスムーズに移行できるように設計されています。完全に管理されたサーバーレスプラットフォームを提供するので、要件に最適です。
リンク
https://cloud.google.com/blog/products/serverless/knative-based-cloud-run-services-are-ga
</div></details>

## Q. 2-46
CI/CD パイプラインに Cloud Build を使用して、Compute Engine 仮想マシンへの特定のファイルのコピーなど、いくつかのタスクを完了しています。パイプラインでは、パイプライン内のあるビルダーで生成されたフラットファイルに、同じパイプライン内の後続のビルダーがアクセスできる必要があります。

パイプライン内のすべてのビルダーがアクセスできるようにするには、ファイルをどのように保存すればよいですか？
1. Compute Engineインスタンスのメタデータを使用して、ファイルの内容を保存および取得します。
2. ファイルの内容を/workspace内のファイルに出力し、後続のビルドステップで同じ/workspaceファイルから読み取ります。
3. gsutilを使ってファイルの内容をCloud Storageオブジェクトに出力し、次のビルドステップで同じオブジェクトから読み込みます。
4. ビルド引数を追加して、別のウェブサーバに curl 経由で HTTP POST を実行し、1 つのビルダで値を永続化し、後続のビルドステップから curl 経由で HTTP GET を使用して値を読み取ります。
<details><div>
    答え：2
説明
不正解です：
A. Compute Engineインスタンスに関連するメタデータを保存するためのものであり、Cloud Buildステップ間でデータを共有するためのものではありません。
C. うまくいくかもしれませんが、/workspaceディレクトリを使用するのに比べて不必要に複雑です。
D. もまた、共有ディレクトリへの書き込みと共有ディレクトリからの読み込みだけで達成できるタスクに対して、複雑すぎるソリューションです。
正解です：
B. Cloud Buildでは、/workspaceディレクトリを使用することで、ビルドステップ間でデータを共有できます。すべてのビルド ステップは /workspace ディレクトリから読み取り、/workspace ディレクトリに書き込むことができるため、/workspace ディレクトリを使用してビルド ステップ間でデータを渡すことができます。
リンク
https://cloud.google.com/build/docs/configuring-builds/pass-data-between-steps#passing_data_using_workspaces
</div></details>

## Q. 2-47
あなたは、自社のアプリケーションをオンプレミスからGoogle Cloudへ移行する計画を任されました。御社のモノリシックなアプリケーションはeコマースのウェブサイトです。このアプリケーションは、段階的にGoogle Cloud上にデプロイされるマイクロサービスに移行されます。御社の収益の大部分はオンライン販売によるものであるため、移行中のリスクを最小限に抑えることが重要です。機能に優先順位をつけ、最初に移行する機能を選択する必要があります。

何をすべきでしょうか？
1. 商品カタログを移行します。これはフロントエンドと商品データベースへの統合があります。
2. フロントエンド、注文データベース、サードパーティの決済ベンダーとの統合がある決済処理を移行します。
3. 注文データベース、在庫システム、サードパーティ出荷ベンダーとの統合がある。
4. ショッピングカートの移行。フロントエンド、カートデータベース、在庫システム、支払い処理システムとの統合がある。
<details><div>
    答え：1
説明
不正解
B. 注文データベースや第三者支払ベンダーのような重要なコンポーネントと統合しているため、高いリスクを伴う可能性があります。
C. 受注データベース、在庫システム、第三者出荷ベンダーとの統合もあり、複雑になる可能性がある。
D. フロントエンド、カートデータベース、在庫システム、支払処理システムへの接続があり、最も多くの統合があるようです。
正解
A. 最初に移行する部分としては、最も複雑でリスクが少ないと思われるため、最も論理的な最初のステップと思われます。これにより、チームは、より複雑なコンポーネントに取り組む前に、移行プロセスの経験と自信を得ることができます。
リンク
https://cloud.google.com/architecture/migrating-a-monolithic-app-to-microservices-gke#choosing_an_initial_migration_effort
</div></details>

## Q. 2-48
あなたはGoogle Kubernetes Engine上でコンテナ化されたアプリケーションを実行しています。コンテナイメージはContainer Registryに保存されています。あなたのチームはCI/CDプラクティスを使用しています。既知の重大な脆弱性を持つコンテナのデプロイを防止する必要があります。
あなたは何をすべきですか？
1. 
- Web Security Scannerを使用して、アプリケーションを自動的にクロールします。
- アプリケーションのログを確認してスキャン結果を確認し、コンテナに既知の重要な脆弱性がないことを証明します。
- バイナリ認証を使用して、コンテナをデプロイする前に証明書を提供するよう強制するポリシーを実装する。
2. 
- Web Security Scanner を使用して、アプリケーションを自動的にクロールする。
- Cloud Console のスキャン詳細ページでスキャン結果を確認し、コンテナに既知の重要な脆弱性がないことを証明する。
- バイナリ認証を使用して、コンテナをデプロイする前に証明書を提供するよう強制するポリシーを実装する。
3. 
- Container Scanning API を有効にして脆弱性スキャンを実行する。
- クラウドコンソールのコンテナレジストリで脆弱性レポートを確認し、コンテナに既知の重要な脆弱性がないことを証明する。
- バイナリ認証を使用して、コンテナがデプロイされる前に証明書を提供するよう強制するポリシーを実装する。
4. 
- コンテナスキャンAPIを有効にして脆弱性スキャンを実行する
- Container Scanning API を通じて脆弱性レポートをプログラムでレビューし、コンテナに既知の重要な脆弱性がないことを証明する。
- バイナリ認証を使用して、コンテナがデプロイされる前に証明書を提供するよう強制するポリシーを実装する。
<details><div>
    答え：4
説明
不正解
A.B.C.
オプション A と B では、Web Security Scanner を使用しますが、これはコンテナイメージの脆弱性スキャンには関係ありません。むしろ、XSSやSQLインジェクションのような一般的な脆弱性について、Webアプリケーションをスキャンするのに適しています。
オプションCはほぼ正しいですが、Cloud Consoleの脆弱性レポートを手動で確認する必要があります。これは可能ですが、自動化されたCI/CDプラクティスとうまく整合しない可能性があります。
正解
D.
正しいアプローチである。これは、Container Scanning APIを活用して脆弱性スキャンを実行し、脆弱性レポートのプログラムによるレビュー（CI/CDパイプラインの一部として自動化できる）を可能にし、Binary Authorizationを使用して、既知の重要な脆弱性を持つコンテナがデプロイされないようにします。

リンク
https://cloud.google.com/container-analysis/docs/automated-scanning-howto#view-code
https://cloud.google.com/binary-authorization/docs
</div></details>

## Q. 2-49
Pub/Subにメッセージを発行するWebアプリケーションがあります。このアプリケーションの新しいバージョンをローカルでビルドする予定ですが、新しいビルドごとに Pub/Sub の統合を迅速にテストしたいと考えています。

ローカルテストはどのように構成すればよいですか？
1. 統合開発環境（IDE）にCloud Codeをインストールします。Cloud API に移動し、有効な Google プロジェクト ID に対して Pub/Sub を有効にします。ローカルで開発する場合は、pubsub.googleapis.com を呼び出すようにアプリケーションを構成します。
2. gcloudを使用してPub/Subエミュレータをインストールし、有効なGoogleプロジェクトIDでエミュレータを起動します。ローカルで開発する場合は、${gcloud beta emulators pubsub env-init}でローカルのエミュレータを使用するようにアプリケーションを設定します。
3. Google Cloudコンソールで、APIライブラリに移動し、Pub/Sub APIを有効にします。ローカルで開発する場合は、pubsub.googleapis.com を呼び出すようにアプリケーションを構成します。
4. gcloudを使用してPub/Subエミュレータをインストールし、有効なGoogleプロジェクトIDでエミュレータを起動します。ローカルで開発する場合は、PUBSUB_EMULATOR_HOST変数をエクスポートして、ローカルのエミュレータを使用するようにアプリケーションを設定します。
<details><div>
    答え：4
説明
不正解
A. このオプションはローカルでテストする方法を提供しません。代わりに、Google Cloudの実際のPub/Subサービスを呼び出すようにアプリケーションに指示します。これは、本番環境で望ましくない副作用を引き起こし、コストが発生する可能性があります。
B. このオプションは正解に近いですが、エミュレータを使うようにアプリケーションを設定する具体的な方法が間違っています。エミュレータを使用するようにアプリケーションを設定する正しい方法は、PUBSUB_EMULATOR_HOST環境変数をエクスポートすることです。
C. オプション A と同様に、このオプションはアプリケーションに Google Cloud 内の実際の Pub/Sub サービスとのやり取りを指示します。これは、本番環境に影響を与えずにローカルでテストする手段を提供しません。
正解
D. ローカルで開発し、Pub/Subの統合をテストする場合、Google Cloudの実際のPub/Subサービスを呼び出すのではなく、Pub/Subエミュレータを使用することをお勧めします。これにより、コストを発生させることなく、また本番のPub/Subシステムに影響を与えることなく、アプリケーションの開発とテストを行うことができます。

このオプションDは、アプリケーションが実際のPub/Subサービスと同様にやり取りできるローカルPub/Sub環境をセットアップする方法を提供します。
リンク

</div></details>

## Q. 2-50
あなたの e コマース・アプリケーションは外部からのリクエストを受け取り、図のようにクレジットカード処理、配送、在庫管理のためのサードパーティ API サービスに転送します。


顧客から、アプリケーションの動作が予測不可能な時間帯に遅くなるという報告を受けています。アプリケーションはメトリクスを報告しません。一貫性のないパフォーマンスの原因を特定する必要があります。

あなたは何をすべきでしょうか？
1. 各言語用の OpenTelemetry ライブラリをインストールし、アプリケーションを計測してください。
2. コンテナ内にOps Agentをインストールし、アプリケーション・メトリクスを収集するように構成します。
3. ダウンストリーム・サービスを呼び出すときに、X-Cloud-Trace-Context ヘッダーを読み取り、転送するようにアプリケーションを修正する。
4. アプリケーションメトリクスを収集するために、Google Kubernetes EngineクラスタでPrometheusのマネージドサービスを有効にする。
<details><div>
    答え：1
説明
不正解
B. このオプションは、システムとコンテナからメトリクスを収集するのに役立ちますが、サードパーティ・サービスとの相互作用を理解するのに必要な詳細なトレース情報が得られるとは限りません。
C. このオプションは Google Cloud トレースに特有であり、相互作用している外部のサードパーティ サービスには適用されない場合があります。スローダウンが発生している場所の全体像を把握できない可能性があります。
D. Managed Service for Prometheusは、GKEクラスタ上のメトリクスを収集するのに便利ですが、サードパーティのサービスを通じて要求がどのように処理されているかの詳細なトレースを提供するとは限りません。
正解
A. OpenTelemetry は、分散トレースやメトリクス収集を含む、観測可能性のための API とインスツルメンテーションを提供する複合ライブラリです。アプリケーションにOpenTelemetryを追加することで、様々なコンポーネントやサービスを流れるリクエストをトレースすることができ、どこでスローダウンが発生しているのかをピンポイントで特定することができます。

リンク
https://cloud.google.com/trace/docs/trace-app-latency
</div></details>

## Q. 3-1
あなたはNode.jsでクラウド関数を書いており、ソースコードはGitリポジトリに保存されています。ソースコードにコミットされた変更が自動的にテストされるようにしたい。ソースコードを一意に命名された Cloud Function にプッシュし、その関数をテストとして呼び出し、クリーンアップとして Cloud Function を削除する Cloud Build 構成を記述します。テストが失敗すると、クラウド関数が削除されないことがわかりました。

どうすればよいでしょうか？
1. ステップの順序を変更して、テストを実行する前にクラウド関数を削除します。
2. クラウド構築ステップに、クラウド機能テスト ステップを削除するwaitFor オプションを必須先行ステップとして含めます。
3. クラウド構築ステップでクラウド関数の結果をファイルに書き込み、0 を返すようにします。クラウド関数の削除後に、ファイルに期待された結果が含まれているかどうかをチェックし、含まれていない場合は失敗するステップを追加します。
4. クラウド ビルド テスト ステップで、result という環境変数に結果を設定し、0 を返すようにします。クラウド関数削除の後に、環境変数に期待した結果が含まれているかどうかをチェックする最終ステップを追加します。
<details><div>
    答え：3
説明
不正解：
A. テストを実行する前にクラウド関数を削除すると、関数が存在しなくなるため、テストが不可能になります。
B. この方法で waitFor オプションを使用すると、テストが失敗した場合にビルド全体が失敗し、クラウド関数は削除されません。テストが失敗した場合に関数をクリーンアップするという問題は解決しません。
D. 環境変数はステップが実行されるコンテナに対してローカルなので、ビルドプロセスの異なるステップ間で情報を渡すために使用することはできません。
正解
C. クラウド関数をデプロイし、結果を（成功または失敗に関係なく）ファイルに保存し、クラウド関数を削除し、ファイルの内容をテストすることで、適切なクリーンアップとテスト結果の正確なレポートが保証されます。
リンク
https://cloud.google.com/build/docs/configuring-builds/configure-build-step-order
https://cloud.google.com/build/docs/configuring-builds/create-basic-configuration
https://cloud.google.com/build/docs/build-config
</div></details>

## Q. 3-2
Google Kubernetes Engine（GKE）クラスタにWebアプリケーションをデプロイしました。Cloud Monitoringのメトリクスを確認していると、クラスタのCPU負荷が1日中変動していることがわかります。コストを最小限に抑えながらパフォーマンスを最大化するために、ポッドとノートの数を自動的に調整したいとします。

あなたは何をすべきですか？
1. マネージドインスタンスグループ（MIG）を修正してオートスケーリングを有効にし、CPU負荷に基づいてノードの最大量と最小量を設定します。
2. GKEクラスタでCluster Autoscalerを有効にし、CPU負荷に基づいてワークロードを自動スケールするようにHorizontal Pod Autoscaler（HPA）を構成します。
3. GKEクラスタ上でCluster Autoscalerを有効にし、カスタムメトリックに基づいてワークロードをオートスケールするようにHPAを構成します。
4. MIGを修正して、CPU負荷に基づいてノードの最大量と最小量を構成するオートスケーリングを有効にし、CPU負荷に基づいてワークロードをスケールするようにVertical Pod Autoscaler（VPA）を構成します。
<details><div>
    答え：2
説明
不正解
A. GKE には固有のオートスケーリング機能があるため、GKE によって作成されたインスタンスグループで Compute Engine のオートスケーリング機能を使用しないでください。
C. CPUメトリクスは標準であり、説明するシナリオではカスタムメトリクスを使用する必要はありません。
D. 繰り返しになるが、Compute Engineのオートスケーリング機能は、GKEで作成したインスタンスグループには使用しないこと。この問題はCPU負荷に基づくスケーリングに重点を置いているため、VPA（Vertical Pod Autoscaler）はここでは必要ありません。
正解
B. GKEクラスタでCluster Autoscalerを有効にすると、クラスタ内のノード数がワークロードの要求に基づいて自動的に調整されます。CPU負荷に基づいてワークロードを自動スケールするようにHPA（Horizontal Pod Autoscaler）を設定することは、CPU負荷の変動に応じてポッド数を調整する要件と一致します。
リンク
https://cloud.google.com/kubernetes-engine/docs/concepts/cluster-autoscaler
https://cloud.google.com/kubernetes-engine/docs/how-to/cluster-autoscaler
https://cloud.google.com/kubernetes-engine/docs/how-to/scaling-apps
</div></details>

## Q. 3-3
Cloud Run 上で Java アプリケーションを実行しています。アプリケーションのエラーメッセージがエラーレポートコンソールに表示されません。どうすればよいですか？
1. Cloud Monitoringクライアント・ライブラリがJavaアプリケーションにバンドルされていることを確認します。
2. アプリケーションログが正しい地域のストレージバケットに書き込まれていることを確認します。
3. アプリケーションエラーが標準エラー出力に書き込まれていることを確認します。
4. System.out.printlnを使用して例外をログに記録する。
<details><div>
    答え：3
説明
不正解
A. サービスが内部的にログ収集プロセスを処理するため、Cloud MonitoringクライアントライブラリはCloud Runのエラーレポートには必要ありません。
B. エラーレポートは地域のログバケットに保存されたログを分析しないため、これを検証しても問題は解決しません。
D. System.out.printlnを使用すると、標準エラー・ストリームではなく標準出力ストリーム（標準出力）に出力されるため、エラー・レポート・コンソールにエラー・メッセージが表示されません。
正解です：
C. Cloud Runでは、エラーメッセージはエラー報告で認識されるために標準エラーストリーム（stderr）に書き込まれる必要があります。アプリケーションエラーが stderr に書き込まれていることを確認することで、問題は解決します。
リンク
https://cloud.google.com/error-reporting/docs/troubleshooting
https://cloud.google.com/run/docs/error-reporting
</div></details>

## Q. 3-4
アプリケーションのパフォーマンスを分析しています。クラスタ内の特定のCloud Bigtableテーブルが他のテーブルよりも多く使用され、エンドユーザーに対するアプリケーションのパフォーマンスに一貫性がないことを確認しました。

あるタブレットでは、同じような名前の行キーのセクションが大きく使用されていますが、他のタブレットではアイドル状態です。ユーザーの郵便番号が行キーの最初のコンポーネントであり、その郵便番号から発信されたプロファイルによってアプリケーションが大量に使用されていることがわかりました。

行キーの生成方法を変更して、人間が読めるようにし、Cloud Bigtableの需要がクラスタ内でより均等になるようにします。

どうすればよいでしょうか？
1. 連続的に生成された整数値を使用します。
2. 行内容のMD5ハッシュのサブセットを使用する。
3. 複数の人間が読める属性を連結して使用する。
4. ミリ秒単位のUNIXエポックスタイルのタイムスタンプを使用する。
<details><div>
    答え：3
説明
不正解
A. 連続的に生成された整数値を使用すると、ホットスポットが発生する可能性があります。この場合、クラスタ全体でリクエストが不均等に分散されることになり、現在直面している問題と同じになります。
B. ハッシュを使用することで、行のキーをタブレット間でより均一に分散させることができますが、行の内容のMD5ハッシュを使用すると、問題のトラブルシューティングが難しくなります。また、要求事項の一つである人間が読めるものでもない。
D. UNIXのエポックスタイルのタイムスタンプを使用すると、同じミリ秒の間に複数の更新が発生した場合、衝突が発生する可能性があります。タイムスタンプをBigtableの行キーとして使用することは、一般的に推奨されません。
正解
C. 複数の人間が読み取り可能な属性を連結して行キーとすることで、属性の選択によっては、タブレット間でキーをより均等に分散させることができます。この方法は、行キーが人間が読めるという要件も満たす。
リンク
https://cloud.google.com/bigtable/docs/schema-design#types_of_row_keys
https://cloud.google.com/bigtable/docs/schema-design-time-series#ensure_that_your_row_key_avoids_hotspotting
</div></details>

## Q. 3-5
御社は、米国で人気を博したマルチプレイヤーゲームで成功を収めている。現在、同社は他の地域に拡大したいと考えています。ユーザーがポイントを交換できる新機能を開始します。この機能は世界中のユーザが利用できます。御社の現在のMySQLバックエンドは、ゲームをホストするCompute Engineインスタンスの限界に達しています。貴社は、地域間でグローバルな一貫性と高可用性を提供する別のデータベースに移行したいと考えています。どのデータベースを選択すべきでしょうか？
1. BigQuery
2. クラウドSQL
3. クラウド・スパナー
4. クラウドBigtable
<details><div>
    答え：3
説明
不正解
A. BigQueryは主に分析データベースであり、トランザクションワークロード、特にマルチリージョンでグローバルに一貫性のあるトランザクションを含むワークロードには適していません。
B. Cloud SQLは、リージョン内の高可用性は提供するが、複数のリージョンにまたがってその機能を拡張することはできない。これはグローバルな一貫性と可用性の要件を満たさない。
D. Cloud Bigtableは高いスループットとスケーラビリティを提供するが、このケースで必要とされるグローバルな可用性は提供しない。大規模な分析および運用ワークロードには適していますが、グローバルに分散されたトランザクションシステムには適していません。
正解
C. これは正しい選択です。Cloud Spannerは、地域間の高可用性と強力な一貫性の両方を提供するグローバル分散データベースとして設計されています。世界的に人気のあるマルチプレイヤーゲームの要求を処理できるため、説明したシナリオに最適です。
リンク
Cloud Spannerドキュメント
</div></details>

## Q. 3-6
貴社はアナリティクスのユースケースの拡大を計画しています。新しいユースケースの1つでは、データアナリストがSQLを使用してイベントをほぼリアルタイムで分析する必要があります。急成長が予想されるため、できるだけマネージド・サービスを利用したいと考えています。

どうすればよいでしょうか？
1. Pub/Subトピックとサブスクリプションを作成します。ソースからPub/Subトピックにイベントをストリームします。Dataflowを活用して、これらのイベントをBigQueryに取り込みます。
2. Pub/Subトピックとサブスクリプションを作成します。ソースからPub/Subトピックにイベントをストリームします。Dataflowを活用して、これらのイベントをCloud Storageに取り込みます。
3. Pub/Sub トピックとサブスクリプションを作成する。ソースからイベントをPub/Subトピックにストリームします。データフローを活用して、これらのイベントをデータストアモードのFirestoreに取り込みます。
4. 大規模なCompute Engineインスタンス上にKafkaインスタンスを作成します。ソースからKafkaパイプラインにイベントをストリーミングする。Dataflowを活用して、これらのイベントをCloud Storageに取り込む。
<details><div>
    答え：1
説明
不正解
B. クラウド・ストレージはSQL分析用に構造化されていないため、これは個々のイベントを挿入してSQLで分析するには適していません。
C. データストア・モードのFirestoreはSQL分析用に最適化されていないため、この要件には最適ではありません。
D. このソリューションは完全に管理されたソリューションを提供しません。また、クラウド・ストレージはSQL分析に適していないため、ほぼリアルタイムでSQLを使ってデータを分析する機能も欠けています。
正解
A. これは、フルマネージドサービスを活用し、BigQueryを使用してほぼリアルタイムのSQL分析を可能にするため、正しいアプローチです。Pub/Subはストリーミングデータを処理し、Dataflowはデータを処理して変換し、BigQueryはSQLでデータを分析するのに適しています。
リンク
https://cloud.google.com/dataflow/docs/tutorials/dataflow-stream-to-bigquery
https://cloud.google.com/architecture/reference-patterns/overview#general_analytics
</div></details>

## Q. 3-7
Cloud Run上にデプロイされたアプリケーションは大量のトラフィックを受け取ります。アプリケーションへの変更をデプロイすると、すべてのユーザーに悪影響が及ぶことを懸念しています。コストの問題から本格的な負荷テストは避けたいと考えていますが、それでも新機能をできるだけ早くデプロイしたいと考えています。

どのアプローチを取るべきでしょうか？
1. 本番アプリケーションに対する負荷テストを毎週スケジュールします。
2. ローカルの開発環境を使用して、Google Cloud 外で負荷テストを実行する。
3. ユーザーに新機能へのアクセスを許可する前に、新バージョンとしてデプロイし、スモークテストを実施する。その後、すべてのユーザーが新機能にアクセスできるようにする。
4. トラフィック分割を使用して、一部のユーザーに新機能をテストしてもらい、すべてのユーザーが新機能を利用できるようになるまで、トラフィック分割を徐々に調整します。
<details><div>
    答え：4
説明
不正解
A. 負荷テストを定期的に実行することは、特に頻繁に実行する場合、コストがかかり、本番環境を混乱させる可能性があります。
B. ローカルのテスト環境は本番環境を正確に表していない可能性があり、このアプローチでは実際のユーザーに徐々に変更をロールアウトする方法を提供できない。
C. これはある程度のテストを提供しますが、すべてのユーザーがアクセスできるようにする前に、新機能を徐々にロールアウトしたり、実際のユーザーテストを行ったりすることはできません。
正解
D. このアプローチでは、ユーザーの一部に徐々に新機能を導入し、その行動を分析し、必要に応じてトラフィック配分を調整することができます。費用対効果の高いテストと安全な配備のバランスが取れます。
リンク
https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#split-traffic
</div></details>

## Q. 3-8
あなたのチームはCloud Runを使用して、すべてのPub/SubメッセージをCloud StorageオブジェクトとBigQueryテーブルの両方に書き込んでいます。運用上のオーバーヘッドを最小限に抑えたい。どのアーキテクチャを実装すべきですか？
1. One topic, 1 subscription, 2 Cloud Run Services
2. One topic, 2 subscriptions, 2 Cloud Run Services
3. One topic, 1 push subscription, 1 Cloud Run Service
4. Two topic, 2 subscriptions, 2 Cloud Run Services
<details><div>
    答え：2
説明
不正解：
これはメッセージの半分をBigQueryに、半分をクラウドストレージに書き込むことになり、ニーズを満たさないため、オプションAは正しくありません。
1つのシステムへのメッセージ処理に失敗すると、BigQueryまたはGoogle Cloud Storageへの書き込みが重複する可能性があるため、オプションCは正しくありません。
オプションDは、メッセージ送信料が重複し、メッセージを2つの異なるトピックに2回送信する必要があるため、コストが増加し、追加のトピックを管理する必要があり、クライアントが複雑になるため、正しくありません。
正解
各App Engineサービスは、書き込む独自のメッセージを取得し、独立して再試行/失敗できるため、オプションBは正しい。
リンク
https://cloud.google.com/run/docs/triggering/pubsub-push
https://cloud.google.com/pubsub/docs/admin
</div></details>

## Q. 3-9
Webアプリケーションからの注文を処理し、データをFirestoreのDatastoreモードのコレクションに保存するAPIエンドポイントを作成しています。アプリケーションのテスト中に、アプリケーションが Datastore API から HTTP 5xx サーバー エラーに遭遇すると、このエラーをキャッチしてクライアントに HTTP 200 OK 応答コードを返しますが、Datastore 内にはデータが保存されないことに気付きました。APIエンドポイントのコンシューマに、書き込み要求が失敗したことを知らせたい。

どうすればよいでしょうか？
1. HTTP 204 No Contentレスポンスを返す。
2. HTTP 406 Not Acceptableレスポンスを返す。
3. HTTP 500 Internal Server Error レスポンスを返す。
4. Firestore が HTTP 2xx レスポンスを返すまで、指数関数バックオフを使用して Datastore API を再試行します。
<details><div>
    答え：3
説明
不正解
A. このステータスコードはリクエストが正常に処理されたことを示しますが、送り返す情報はありません。これは成功を誤って意味するので、ここでは適さない。
B. このステータスコードは、クライアントが定義した受け入れ可能な値のリストに一致する応答をサーバが生成できないことを意味し、Datastoreで発生したエラーとは無関係です。
D. 指数関数的バックオフによる再試行を実装することは、一過性のエラーに対処する際に良いプラクティスであることが多いのですが、エラーの性質を理解せず、再試行制限を課すことなくやみくもに再試行すると、無限ループやその他の望ましくない動作につながる可能性があります。また、エラーが続く場合、クライアントはまだ何も知らされないままかもしれません。
正解
C. この応答コードは、サーバーが予期しない状況に遭遇し、リクエストを処理できなかったことを示します。このレスポンスコードは、サーバー側で障害が発生し、クライアントのリクエストが正しかったことをクライアントに知らせます。
リンク
https://www.restapitutorial.com/httpstatuscodes.html
</div></details>

## Q. 3-10
NFS共有に設定を保存するレガシーアプリケーションをコンテナ化しました。このアプリケーションをGoogle Kubernetes Engine (GKE)にデプロイする必要があり、コンフィギュレーションが取得されるまでアプリケーションにトラフィックを提供させたくありません。

あなたは何をすべきでしょうか？
1. gsutilユーティリティを使用して、起動時にDockerコンテナ内からファイルをコピーし、ENTRYPOINTスクリプトを使用してサービスを開始します。
2. GKEクラスタ上にPersistentVolumeClaimを作成します。ボリュームから設定ファイルにアクセスし、ENTRYPOINTスクリプトを使用してサービスを開始します。
3. Dockerfile の COPY ステートメントを使用して、構成をコンテナイメージにロードします。構成が利用可能であることを確認し、ENTRYPOINTスクリプトを使用してサービスを開始します。
4. GKEインスタンスグループに起動スクリプトを追加し、ノード起動時にNFS共有をマウントする。構成ファイルをコンテナにコピーし、ENTRYPOINTスクリプトを使用してサービスを開始する。
<details><div>
    答え：2
説明
不正解
A. gsutilはGoogle Cloud Storageと対話するためのコマンドラインツールであり、コンテナ化されたアプリケーションやNFS共有を管理するためのものではないため、不正解です。
C. 構成データをDockerイメージに格納することは、Kubernetesのベストプラクティスではないため、間違っています。なぜなら、Dockerイメージに設定データを保存することは、Kubernetesのベストプラクティスではないからです。これはコンテナの移植性を低下させ、アプリケーションの外部に設定と秘密を保持するというクラウドネイティブモデルに適合しません。
D. GKEは、起動スクリプトを含め、基礎となるノードインフラストラクチャを管理するため、正しくありません。また、GKEは、個々のノードの動作を直接スクリプト化することが実用的でない、あるいは可能でさえないという点で、個々のノードへのアクセスを抽象化しています。
正解です：
B. このオプションは、NFSのサポートを含む、ストレージリソースを管理するためのKubernetesのネイティブ機能を活用します。アプリケーションは、コンテナのローカルであるかのように、NFS共有から構成にアクセスできます。ENTRYPOINTスクリプトがサービスを開始するまで、コンテナはトラフィックを提供しません。
リンク
https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes
https://cloud.google.com/filestore/docs/accessing-fileshares
https://cloud.google.com/storage/docs/gcs-fuse
</div></details>

## Q. 3-11
Cloud Runを使用して新しいWebアプリケーションを開発し、Cloud Source Repositoriesにコードをコミットしています。可能な限り最も効率的な方法で新しいコードをデプロイしたい。すでにコンテナをビルドするCloud Build YAMLファイルを作成し、次のコマンドを実行しています：gcloud run deploy。

次に何をすべきでしょうか？
1. コードがリポジトリにプッシュされたときに通知されるPub/Subトピックを作成します。イベントがトピックにパブリッシュされたときにビルドファイルを実行する Pub/Sub トリガーを作成します。
2. リポジトリコードが開発ブランチにプッシュされたことに応答してビルドファイルを実行するビルドトリガーを作成する。
3. Webhook URL への HTTP POST 呼び出しに応答してビルドファイルを実行する Webhook ビルドトリガーを作成します。
4. 24 時間ごとに次のコマンドを実行する Cron ジョブを作成します。
<details><div>
    答え：2
説明
不正解
A. Pub/Sub通知は通常、イベント駆動型の非同期ワークロードに使用され、特にビルドのトリガーには使用されません。
C. Webhook を使用してビルドをトリガすることはできますが、Cloud Build のネイティブ トリガ機構を使用するよりも効率が悪く、安全性も低いため、C. は正しくありません。また、コードがリポジトリにプッシュされるたびに HTTP POST 呼び出しを送信するには、手作業や追加のサービス設定が必要になります。
D. gcloud builds submit. コードのプッシュに反応するのではなく、定期的（毎日）にビルドに依存します。これは、コード変更が発生していない場合に不要なビルドが発生したり、重要なコード変更のデプロイが遅れたりする可能性があるため、効率的ではありません。
正解
B. Cloud Buildはビルドトリガーを提供し、新しいコードがソースコードリポジトリの指定されたブランチにプッシュされたときにビルドプロセスを実行するように構成できます。この戦略はしばしば継続的デプロイメントまたは継続的デリバリーと呼ばれます。オプションBを使用すると、デプロイプロセスを効率的に自動化できます。新しいコードが開発ブランチにプッシュされるたびに、ビルドが自動的にトリガーされ、変更が必要なときにだけ迅速にデプロイされるようになります。
リンク
https://cloud.google.com/build/docs/automating-builds/create-manage-triggers#connect_repo
</div></details>

## Q. 3-12
あなたの会社では、Google Cloudに保存されるすべてのデータを顧客が管理する暗号化キーで暗号化することを要求する新しいセキュリティイニシアチブを取っています。クラウド鍵管理サービス（KMS）を使用して鍵へのアクセスを設定する予定です。職務分掌」の原則とGoogleが推奨するベストプラクティスに従う必要があります。

あなたは何をすべきでしょうか？(選択肢を2つ選んでください。）
1. 独自のプロジェクトでクラウドKMSをプロビジョニングする。
2. Cloud KMSプロジェクトにオーナーを割り当てないでください。
3. 鍵を使用するプロジェクトにCloud KMSをプロビジョニングする。
4. クラウドKMSの鍵を使用するプロジェクトのオーナーにroles/cloudkms.adminロールを付与する。
<details><div>
    答え：1
説明
不正解
B. プロジェクトに所有者を割り当てないことは、Googleが推奨するベストプラクティスに反するため、正しくありません。すべてのプロジェクトは、管理と説明責任のために、少なくとも1人の指定された所有者を持つ必要があります。
C. 鍵が使用されるプロジェクトにCloud KMSを併設することは、鍵の管理ミスや意図しない鍵アクセスにつながる可能性があるため、正しくない。これらの懸念は切り離して考えるのが最善である。
D. 鍵を使用するプロジェクトの所有者にcloudkms.adminロールを付与することは、職務分掌の原則に反する。これは一人のユーザーに鍵の管理と使用の両方の権限を与えることになり、不正なアクセスや変更につながる可能性があります。
正解
A. クラウド鍵管理サービス（KMS）を独自のプロジェクトに作成することで、責任の境界が明確になり、鍵の偶発的な削除や変更のリスクを低減できる。
E. クラウドKMSプロジェクトの所有者ロールを、クラウドKMSの鍵を使用するプロジェクトの所有者とは異なるユーザーに付与する。
Cloud KMSプロジェクトに、鍵を使用するプロジェクトとは異なるオーナーを割り当てることで、暗号化鍵の管理を、鍵を使用するユーザーやアプリケーションから切り離すことができます。これにより、鍵の不正使用や削除のリスクを低減できます。
リンク
https://cloud.google.com/kms/docs/separation-of-duties#using_separate_project
</div></details>

## Q. 3-13
あなたのチームは、本番プロジェクトの Cloud Run 上で実行されているアプリケーションでエラーの急増を検出しました。アプリケーションは、Pub/Sub トピック A からメッセージを読み取り、メッセージを処理し、トピック B にメッセージを書き込むように構成されています。テストには一連のモック・メッセージを使用できます。

あなたは何をすべきですか?
1. ローカルマシンにPub/SubおよびCloud Runエミュレータをデプロイします。アプリケーションをローカルにデプロイし、アプリケーションのロギング・レベルを DEBUG または INFO に変更します。トピックAにモック・メッセージを書き込み、ログを分析します。
2. アプリケーションのロギングレベルをDEBUGまたはINFOに変更し、ログを分析します。
3. ローカル・マシンにPub/Subエミュレータをデプロイします。本番アプリケーションをローカルの Pub/Sub トピックに指定します。トピック A にモック・メッセージを書き込み、ログを分析します。
4. アプリケーションのログ レベルを DEBUG または INFO に変更し、ログを分析します。
<details><div>
    答え：1
説明
不正解：
B. 
C. 本番アプリケーションのトピック A に直接モック・メッセージを書き込むと、本番アプリケーションに影響を与え、問題が悪化する可能性があるため、オプション B と D は正しくありません。テストは、予期しない副作用を避けるために、実稼働環境では実行しないでください。
D. 実運用アプリケーションをローカルの Pub/Sub トピックに向けることは、ネットワーク構成によっては現実的でないか、不可能である可能性が高く、実運用ワークロードの中断につながる可能性があるため、オプション C は正しくありません。さらに、テスト環境と本番環境を分離するという原則にも違反することになります。
正解
A. 実際の本番アプリケーションやデータに影響を与えることなく、本番環境をローカル・マシンで再現できます。Pub/SubおよびCloud Runエミュレータとともにアプリケーションをローカルにデプロイすることで、本番環境を模倣した隔離された環境でテストを実施し、ログを分析することができます。これにより、テストが本番のワークロードに干渉することはありません。
リンク
https://cloud.google.com/pubsub/docs/emulator
</div></details>

## Q. 3-14
Compute Engineインスタンスで実行され、任意のユーザーのGoogle Driveにファイルを書き込むWebアプリケーションを作成しています。Google Drive APIを認証するようにアプリケーションを設定する必要があります。

どうすればよいですか？
1. https://www.googleapis.com/auth/drive.file スコープを使用する OAuth クライアント ID を使用して、各ユーザーのアクセストークンを取得します。
2. ドメイン全体の権限を委譲されたOAuthクライアントIDを使用します。
3. App Engineサービスアカウントとhttps://www.googleapis.com/auth/drive.file スコープを使用して、署名付きJSON Webトークン（JWT）を生成します。
4. ドメイン全体の権限を委譲されたApp Engineサービスアカウントを使用します。
<details><div>
    答え：1
説明
不正解
B. ドメイン全体の権限は、通常、G Suiteドメイン管理者がサードパーティのアプリケーションにドメイン内のすべてのユーザーのデータへのアクセスを許可するために使用されます。このシナリオでは必要ありません。
C. D. 
App Engineではなく、Compute Engineインスタンスが使用されているため、オプションCは正しくありません。また、サービスアカウントはユーザーではなくアプリケーションを表すため、サービスアカウントを使用すると、アプリからユーザーのGoogle Driveにファイルを書き込むことができません。
オプションDも同じ理由で間違っています。さらに、ドメイン全体の権限は、このシナリオでは不要であり、要件に適合しません。
正解
A. ユーザーのドライブにファイルを書き込むために、ウェブアプリケーションが各ユーザーの代理として Google Drive API を認証する必要があります。これは通常 OAuth 2.0 を使って行われ、 ユーザのパスワードを共有することなく、 アプリケーションがユーザの代わりにアクションを実行する許可を与えることができます。
https://www.googleapis.com/auth/drive.file スコープでは、アプリが作成したGoogle Driveファイルを閲覧・管理することができます。
リンク
https://developers.google.com/drive/api/guides/api-specific-auth
https://developers.google.com/drive/api/guides/about-auth
</div></details>

## Q. 3-15
あなたのアプリケーションはGoogle Kubernetes Engine (GKE)クラスタにデプロイされています。あなたはこのアプリケーションをCloud Load Balancing HTTP(S)ロードバランサーの後ろに公開したい。

どうすればいいでしょうか？
1. GKE Ingressリソースを設定する。
2. GKEサービスリソースを構成します。
3. タイプを持つ GKE Ingress リソースを設定する： ロードバランサー
4. タイプ: LoadBalancer で GKE Service リソースを構成する： ロードバランサー。
<details><div>
    答え：1
説明
不正解
B. Serviceリソースだけでは、アプリケーションを公開することはできますが、HTTP(S)ロードバランサーのようなレベルのトラフィック管理はできません。ロードバランサーはSSL/TLS終端、ホスト、パスベースのルーティングを扱うことができ、特定のノードに限定されません。
C. D. 
オプション C と D は正しくありません： LoadBalancerは、HTTP(S)ロードバランサーではなく、ネットワークロードバランサーを作成するために、Ingressではなく、Serviceリソースで使用されます。ネットワークロードバランサーはネットワークスタックの低いレベル(トランスポートレイヤー - レイヤー4)で動作し、HTTP(S)ロードバランサーのようなHTTP(S)パスベースのルーティングルールをサポートしません。HTTP(S)ロードバランサーはネットワークスタックの上位レベル（アプリケーションレイヤー - レイヤー7）で動作し、HTTP(S)リクエストに基づくより複雑なルーティングルールを可能にします。これはGKEのIngressを介して行われます。
正解
A. Google Kubernetes Engine (GKE)では、HTTP(S)ロードバランサーの背後にあるパブリックインターネットトラフィックにアプリケーションを公開したい場合、Ingressリソースを使用する必要があります。Ingressリソースは、クラスタ内で動作するアプリケーションにHTTP(S)トラフィックをルーティングするためのルールを定義します。
リンク
https://cloud.google.com/kubernetes-engine/docs/concepts/ingress
</div></details>

## Q. 3-16
セキュリティチームは、Google Kubernetes Engine で実行されているすべてのデプロイ済みアプリケーションを監査しています。監査が完了した後、チームは一部のアプリケーションがクラスタ内でトラフィックを平文で送信していることを発見しました。アプリケーションへの変更を最小限に抑え、Googleからのサポートを維持しながら、すべてのアプリケーションのトラフィックをできるだけ早く暗号化する必要があります。

どうすればいいでしょうか？
1. ネットワークポリシーを使用して、アプリケーション間のトラフィックをブロックします。
2. Istioをインストールし、アプリケーション・ネームスペースでプロキシ・インジェクションを有効にしてから、mTLSを有効にします。
3. アプリケーション内で信頼済みネットワーク範囲を定義し、それらのネットワークからのトラフィックのみを許可するようにアプリケーションを構成します。
4. 自動化プロセスを使用して、Let's Encrypt にアプリケーション用の SSL 証明書を要求し、アプリケーションに追加する。
<details><div>
    答え：2
説明
不正解
A. ネットワークポリシーはポッド間のトラフィックを制御するための貴重なツールですが、ネットワークトラフィックの暗号化はできません。
C. 信頼済みネットワークの範囲は、IP アドレスに基づいてアクセスを制御するだけで、トラフィックを暗号化しません。
D. SSL/TLS証明書はネットワークトラフィックを暗号化するための重要なコンポーネントですが、すべてのアプリケーションに手動で実装するのは大変な作業となり、アプリケーションへの変更を最小限に抑えるという要件を満たせません。さらに、これらの証明書の管理と更新が負担になる可能性があります。
正解
B. Istioは、アプリケーション（またはサービス）間のトラフィックを管理できるサービス・メッシュです。相互TLS（mTLS）と呼ばれる機能が含まれており、サービス間を行き来するすべてのトラフィックを自動的に暗号化します。つまり、アプリケーションが平文でトラフィックを送信していても、Kubernetesクラスタ内の通信はすべて暗号化される。
Istioでプロキシ・インジェクションを有効にすると、Kubernetesの各アプリケーション・ポッドに小さなヘルパー（または「サイドカー・プロキシ」）が自動的に挿入される。このサイドカー・プロキシがトラフィックの暗号化と復号化をすべて行うので、アプリケーションを暗号化対応に変更する必要はない。このため、Istioは迅速かつ効果的なソリューションとなる。
リンク
https://cloud.google.com/istio/docs/istio-on-gke/overview
</div></details>

## Q. 3-17
あなたは、クラウドストレージのバケットに保存されたプライベートな画像や動画を含むウェブアプリケーションを開発しています。ユーザは匿名で、Google アカウントを持っていません。アプリケーション固有のロジックを使用して、画像や動画へのアクセスを制御したいとします。どのようにアクセスを設定すればよいでしょうか？
1. 各WebアプリケーションユーザのIPアドレスをキャッシュし、Google Cloud Armorを使用して名前付きIPテーブルを作成します。ユーザがバックエンドバケットにアクセスすることを許可するGoogle Cloud Armorセキュリティポリシーを作成します。
2. AllUsers に Storage Object Viewer IAM ロールを付与する。Webアプリケーションで認証後、ユーザがバケットにアクセスできるようにする。
3. Identity-Aware Proxy (IAP) を設定し、Web アプリケーションでユーザを認証する。IAP による認証後、ユーザが Bucket にアクセスできるようにする。
4. バケットへの読み取りアクセスを許可する署名付きURLを生成します。Webアプリケーションで認証した後、ユーザがそのURLにアクセスできるようにする。
<details><div>
    答え：4
説明
不正解
A. Google Cloud Armorは、分散サービス拒否（DDoS）攻撃から保護するものであり、クラウドストレージ内のオブジェクトへのアクセスを提供するものではありません。
B. この場合、インターネット上のすべての人にバケットへのアクセスを許可することになり、アプリケーション固有のロジックでアクセスを制御することはできません。
C. IAP（Identity-Aware Proxy）は、Google Cloud上で動作するアプリケーションへのアクセスを制御するために使用されるものであり、Cloud Storageバケットへのアクセスを制御するために使用されるものではない。さらに、IAPはユーザーがGoogleアカウントを持っていることを要求しますが、シナリオではユーザーが匿名でGoogleアカウントを持っていないことが指定されています。
正解
D. このシナリオでは、Googleアカウントを持たないユーザーのCloud Storageオブジェクトへのアクセスを制御する必要があります。署名付きURLはこのための良いソリューションです。これらのURLは、特定のオブジェクトへの一時的なアクセスを提供し、必要なすべての認証情報を含んでいます。ウェブアプリのロジックでユーザーを認証した後、必要なリソースにアクセスするための署名付きURLを生成して提供することができます。
リンク
https://cloud.google.com/storage/docs/access-control/signed-urls#should-you-use
</div></details>

## Q. 3-18
あなたは最近、モノリシックなアプリケーションをマイクロサービスに分解してGoogle Cloudに移行しました。マイクロサービスの1つはCloud
ファンクションを使用してデプロイされます。アプリケーションを最新化する際、サービスのAPIに後方互換性のない変更を加えました。元のAPIを使用する既存の呼び出し元と、新しいAPIを使用する新しい呼び出し元の両方をサポートする必要があります。どうすればよいのでしょうか？
1. 元のクラウド関数はそのままにして、新しいAPIを持つ2番目のクラウド関数をデプロイします。ロードバランサーを使用して、バージョン間の呼び出しを分散します。
2. 元のCloud Functionはそのままにして、変更されたAPIだけを含む2番目のCloud Functionをデプロイする。呼び出しは自動的に正しい関数にルーティングされます。
3. 元のクラウド機能はそのままにして、新しいAPIを持つ2番目のクラウド機能をデプロイします。Cloud Endpointsを使用して、バージョン管理されたAPIを公開するAPIゲートウェイを提供する。
4. 新しいAPIをサポートするようにコードを変更した後、Cloud Functionを再デプロイします。APIの両方のバージョンに対するリクエストは、呼び出しに含まれるバージョン識別子に基づいて処理されます。
<details><div>
    答え：3
説明
不正解
A. ロードバランサーはAPIバージョンに基づいてトラフィックをルーティングするようには設計されていません。
B. クラウド・ファンクションは、APIの変更に基づいて正しいファンクションにコールを自動的にルーティングしない。
D. Cloud FunctionはAPIの両方のバージョンに対するリクエストを処理することができますが、特にAPIへの変更が大きい場合はそうならない可能性があります。また、これはより複雑で保守しにくいコードベースにつながる可能性があります。
正解
C. Cloud Endpointsは、異なるバージョンのAPIを公開する方法を提供することで、それを支援することができます。異なるCloud Functionsを指す複数のAPIパス（例えばv1とv2）を定義できる。このアプローチにより、既存のクライアントは古いバージョンのAPIを使い続けることができ、新しいクライアントは新しいバージョンのAPIを使い始めることができる。
リンク
https://cloud.google.com/endpoints/docs/openapi/get-started-cloud-functions
</div></details>

## Q. 3-19
アプリケーションでは、ホストとなるCompute Engine仮想マシンインスタンスに保存された認証情報を使用して、サービスアカウントをGCP製品に認証する必要があります。これらの認証情報をできるだけ安全にホストインスタンスに配布したいとします。
どうすればよいでしょうか。
1. HTTP署名付きURLを使用して、必要なリソースへのアクセスを安全に提供します。
2. インスタンスのサービスアカウントのアプリケーションデフォルト認証情報を使用して、必要なリソースを認証します。
3. インスタンスのデプロイ後にGCPコンソールからP12ファイルを生成し、アプリケーションを開始する前に認証情報をホストインスタンスにコピーします。
4. クレデンシャル JSON ファイルをアプリケーションのソースリポジトリにコミットし、CI/CD プロセスに、インスタンスにデプロイされるソフトウェアと一緒にパッケージ化させます。
<details><div>
    答え：2
説明
不正解
A. 署名付きURLは、リソース（Googleクラウドストレージのファイルなど）への一時的なアクセスに使用され、サービスアカウントの認証には使用されません。
C. インスタンスのデプロイ後に GCP コンソールから P12 ファイルを生成し、アプリケーションを起動する前にホスト・インスタンスに資格情報をコピーする。また、P12 ファイルは安全性が低く、Google Cloud のサービス・アカウント管理では非推奨とされています。
D. ソースコードリポジトリにクレデンシャルをコミットすることは、セキュリティ上悪い習慣です。リポジトリにアクセスできる人なら誰でも認証情報にアクセスできるので、セキュリティリスクにつながる可能性があります。
正しい答え
B. Compute EngineインスタンスがGoogle Cloudサービスとやり取りする必要がある場合、作成時にインスタンスにサービスアカウントを割り当てるのがベストプラクティスです。Googleが提供するApplication Default Credentials (ADC)ライブラリは、インスタンスに関連付けられたサービスアカウントの認証情報を自動的に取得し、Google Cloudサービスへの認証されたリクエストを可能にします。このアプローチは安全であり、手動でのクレデンシャル管理を必要としない。
リンク
https://cloud.google.com/compute/docs/api/how-tos/authorization
</div></details>

## Q. 3-20
本番環境のGoogle Kubernetes Engine（GKE）クラスタでアプリケーションを実行しています。Cloud Deployを使用して、アプリケーションを本番GKEクラスタに自動的にデプロイします。開発プロセスの一環として、アプリケーションのソースコードに頻繁に変更を加える予定であり、リモートソースコードリポジトリにプッシュする前に変更をテストするツールを選択する必要があります。

ツールセットは以下の要件を満たす必要があります：

- ローカルの頻繁な変更を自動的にテストする。

- ローカルへのデプロイは、本番環境へのデプロイをエミュレートします。

最小限のリソースを使用して、ラップトップ上でコンテナの構築と実行をテストするには、どのツールを使用すべきですか？
1. Docker Composeとdockerd
2. Terraformとkubeadm
3. MinikubeとSkaffold
4. kanikoとTekton
<details><div>
    答え：3
説明
不正解
A. ローカルのDockerコンテナオーケストレーションに焦点を当てていますが、真のKubernetes環境を提供していません。
B. 軽量なローカル開発環境ではなく、Infrastructure-as-CodeとKubernetesクラスタのブートストラップに関わる。
D. コンテナイメージの構築とKubernetesネイティブのCI/CDに関係するが、MinikubeやSkaffoldと同じようにKubernetesのローカル開発と自動テストには関係しない。
正解
C. 頻繁なローカルの変更を自動的にテストし、本番デプロイをエミュレートするローカルデプロイを持つという要件を考えると、ローカルのKubernetes開発と継続的な開発ワークフローを提供するツールが必要です。
Minikube： ラップトップ上でシングルノードのKubernetesクラスタをローカルに実行でき、本格的な環境のオーバーヘッドなしに、実際のKubernetesクラスタに対してテストと開発を行うシンプルな方法を提供します。これは、ローカルマシン上で本番デプロイをエミュレートするのに役立つ。
Skaffold： Skaffoldは、Kubernetesアプリケーションの継続的開発を容易にするコマンドラインツールだ。開発中にアプリケーションを自動的にビルド、プッシュ、デプロイし、開発から本番環境へのシームレスな移行を可能にする。
これら2つのツールを組み合わせることで、指定された要件を満たすことができる。
リンク
Minikubeドキュメント
Skaffoldドキュメント
</div></details>

## Q. 3-21
Google Kubernetes Engine (GKE) クラスタにアプリケーションをデプロイすることを計画しています。あなたのアプリケーションは水平にスケールすることができ、アプリケーションの各インスタンスは安定したネットワークIDと独自の永続ディスクを持つ必要があります。

どのGKEオブジェクトを使うべきですか？
1. デプロイメント
2. ステートフルセット
3. レプリカセット
4. レプリケーションコントローラー
<details><div>
    答え：
説明
不正解
A. C. D. 
オプションA（Deployment）、C（ReplicaSet）、およびD（ReplicationController）は、この特定のシナリオに必要な安定したネットワークIDおよび個々の永続ディスクアタッチメントを本質的に提供しません。
正解
B. StatefulSetは、Podのセットのデプロイとスケーリングを管理し、これらのPodの順序と一意性を保証するKubernetesワークロードオブジェクトです。Podが交換可能なデプロイメントとは異なり、StatefulSet内の各Podは、StatefulSetの名前とPodの序数（web-0、web-1など）からホスト名を導出します。つまり、ネットワークのアイデンティティは安定したままです。さらに、StatefulSetは一般的に永続ボリュームと共に使用されるため、各インスタンスは独自の永続ディスクを持つことができます。
リンク
- ステートフルセット｜Google Kubernetes Engine（GKE） | Googleクラウド
- 第10章. StatefulSets: レプリケートされたステートフル・アプリケーションのデプロイ - Kubernetes in Action
</div></details>

## Q. 3-22
HTTP クラウド関数を使用して、デスクトップ ブラウザとモバイル アプリケーションの両方のクライアントからのユーザー アクティビティを処理するアプリケーションがあります。この関数は、HTTP POST を使用するすべてのメトリック送信のエンドポイントとして機能します。
レガシーの制限により、この関数は、Web またはモバイル セッションでユーザーが要求するドメインとは別のドメインにマッピングする必要があります。クラウド機能のドメインは https://fn.example.com です。デスクトップクライアントとモバイルクライアントはドメインhttps://www.example.com。関数のHTTPレスポンスにヘッダーを追加する必要があります。
HTTP レスポンスにヘッダーを追加して、ブラウザとモバイルのセッションだけがメトリクスをクラウド関数に送信できるようにする必要があります。

どのレスポンス・ヘッダを追加しますか？
1. Access-Control-Allow-Origin： *
2. Access-Control-Allow-Origin：https://*.example.com。
3. Access-Control-Allow-Origin: https://fn.example.com
4. アクセス制御-許可-オリジン: https://www.example.com
<details><div>
    答え：4
説明
不正解
A. オプションA（*）は、どのドメインでもリソースにアクセスできるようにするもので、必要な特定のドメインへのアクセスを制限するものではありません。
B. オプションB(https://*.example.com)は、Access-Control-Allow-Originヘッダーの 有効な値ではない。この文脈では、ワイルドカードは単一の*文字以外 サポートされないからである。
C. オプションC（https://fn.example.com）は、クラウド機能自身のドメインからのアクセスのみを許可することになり、デスクトップおよびモバイルクライアントのドメインからのアクセスを許可する要件と一致しません。
正解
D. このオプションは、指定されたドメイン（https://www.example.com）のみがリソースにアクセスすることを明示的に許可します。これは、記載されている要件を満たしています。
リンク
https://cloud.google.com/functions/docs/samples/functions-http-cors
</div></details>

## Q. 3-23
Compute EngineアプリケーションをGoogle Kubernetes Engineに移行することにしました。Cloud Buildを使用してコンテナイメージをビルドし、それをArtifact Registryにプッシュする必要があります。

あなたは何をすべきですか？(2つの選択肢を選んでください）
1. gcloud builds submitコマンド
2. 
3. 
4. cloudbuild.yaml
5. 
<details><div>
    答え：
説明
不正解です：
選択肢Bは、Cloud Runへのコンテナのデプロイに関するものであり、Cloud Buildを使用してイメージをビルドしてプッシュすることではありません。
選択肢 C は、既存のイメージへのタグの追加に関するものであり、Cloud Build を使用したイメージの構築とプッシュに関するものではありません。
選択肢Eは、gcloudビルダーを使用したアプリのデプロイについて説明しており、ArtifactレジストリへのDockerイメージのビルドとプッシュについて説明していません。
正解です：
選択肢Aは、gcloud builds submitコマンドを使用してCloud Buildプロセスを開始するので正しいです。
選択肢Dは、Dockerイメージをビルドし、それをレジストリにプッシュする手順の概要を示しているため、正解です。指定されたスニペットにタイプミスがあるので（steps構文のハイフンが抜けている）、上記のように修正してください。
リンク
https://cloud.google.com/artifact-registry/docs/configure-cloud-build
https://cloud.google.com/sdk/gcloud/reference/builds/submit
</div></details>

## Q. 3-24
運用中のアプリケーションがあります。これは、管理されたインスタンスグループによって制御されるCompute Engine仮想マシンインスタンス上にデプロイされています。トラフィックは、HTTP(S) ロードバランサーを介してインスタンスにルーティングされます。ユーザーはアプリケーションにアクセスできません。あなたは、アプリケーションが利用できないときに警告を発する監視技術を実装したいと考えています。どのテクニックを選択すべきですか？
1. スモークテスト
2. スタックドライバ・アップタイム・チェック
3. クラウド負荷分散-ヘルスチェック
4. マネージド・インスタンス・グループ - ヘルス・チェック
<details><div>
    答え：2
説明
不正解
A. スモークテストは、しばしば手動で、あるいは継続的インテグレーションプロセスの一部として実行されるテストの一種です。通常、本番アプリケーションの継続的な監視には使用されません。
C. クラウドロードバランシング-ヘルスチェックは、どのバックエンドインスタンスが健全でトラフィックを受け取ることができるかを判断するためにロードバランサーによって使われる。重要ではあるが、アプリケーション自体がダウンした場合のアラート機能は直接提供しない。
D. マネージド・インスタンス・グループ-ヘルス・チェックは、マネージド・インスタンス・グループ内のインスタンスの健全性を判断するために使用されます。オプションCと同様に、アプリケーションがエンドユーザーから利用できない場合に直接アラートすることはありません。
正解
B. Stackdriver uptime checks（現在はGoogle Cloud Monitoring uptime checksと呼ばれています）は、HTTPまたはHTTPSエンドポイント上でチェックを構成することができます。エンドポイントに定期的にリクエストを送信し、利用できない場合に警告を発します。このため、アプリケーションを外部から利用できない場合にアラートを出すのに適している。
リンク
https://cloud.google.com/monitoring/uptime-checks
Stackdriver Monitoring Automation Part 3: Uptime Checks｜by Charles｜Google Cloud - Community｜Medium
</div></details>

## Q. 3-25
あなたのチームメイトから、以下のコードを確認するように頼まれました。このコードの目的は、多数の小さな行をBigQueryテーブルに効率的に追加することです。

BigQuery service = BigQueryOptions.newBuilder().build().getService()；
public void writeToBigQuery (Collection<Map<String, String>> rows){ 以下のようにします。
    for (Map<String, String> rows: rows) { { { { { { { (Map<String, String> rows: rows)
        InsertAllRequest insertRequest = InsertAllRequest.newBuilder(
            "datasetId", "tableId"、
            InsertAllRequest.RowToInsert.of(row)).build()；
        service.insertAll (insertRequest)；
    }
}
チームメイトにどの改善を提案しますか？
1. 各リクエストに複数の行を含める。
2. 複数のスレッドを作成して並列に挿入を実行する。
3. 各行をクラウドストレージオブジェクトに書き込み、BigQueryにロードする。
4. 各行を並列にクラウドストレージオブジェクトに書き込み、その後BigQueryにロードする。
<details><div>
    答え：1
説明
不正解
B. 
選択肢Bの「複数のスレッドを作成して並列に挿入を実行する」は、パフォーマンスを向上させるかもしれませんが、各行に対する個別のリクエストのため、依然として高いネットワーク・オーバーヘッドが発生します。
C. D. 
オプションCとDは、別のサービス（クラウドストレージ）が関与するため、さらなる複雑さと潜在的な待ち時間が発生します。これらのオプションは、挿入操作の制限を超える非常に大きなデータセットを処理する場合に適しています。
正解
A. 
1回のリクエストで複数の行をバッチ処理することで、APIコールの回数を減らし、ネットワークのオーバーヘッドを減らし、全体的なパフォーマンスを向上させることができます。(InsertAllRequest)
リンク
BigQueryへのデータストリーミング
</div></details>

## Q. 3-26
あなたの会社の開発チームは、それぞれのローカル環境からリソースを管理したいと考えています。

あなたは、各チームの Google Cloud プロジェクトへの開発者アクセスを有効にするよう依頼されました。Google が推奨するベストプラクティスに従いつつ、効率を最大化したいと考えています。

どうすればよいでしょうか？
1. ユーザーをプロジェクトに追加し、関連するロールをユーザーに割り当て、関連する各プロジェクトIDをユーザーに提供します。
2. ユーザーをプロジェクトに追加し、関連するロールをユーザーに割り当て、関連する各プロジェクト番号をユーザーに提供する。
3. グループを作成し、グループにユーザーを追加し、関連するロールをグループに割り当て、関連する各プロジェクトIDをユーザーに提供します。
4. グループを作成し、グループにユーザーを追加し、関連するロールをグループに割り当て、関連する各プロジェクト番号をユーザーに提供する。
<details><div>
    答え：3
説明
不正解
A. 個々のユーザーの権限を管理することは、特にチームが大きくなったり変更されたりすると、扱いにくくなります。効率的でなく、ヒューマンエラーにつながる可能性があります。
B. さらに、プロジェクト番号は一般的にプロジェクトIDよりも人間にとって使いにくいものであるため、番号を提供するのは現実的ではないかもしれません。
D. グループを使用するのはベストプラクティスですが、プロジェクトIDの代わりにプロジェクト番号を提供するのは現実的ではありません。プロジェクトIDの方が人間が読みやすく、通常プロジェクトを参照するために使用されるため、ユーザーに提供するのに適しています。
正解
C. 選択肢Cは、グループベースのアクセス制御の利点を活用し、プロジェクトIDを提供して使い勝手を向上させるため、Googleが推奨するベストプラクティスに最も合致しています。
リンク
Google Cloud IAM アクセスの管理
</div></details>

## Q. 3-27
運用チームから、プロジェクト内で実行されているクラウドBigtable、Memorystore、およびクラウドSQLデータベースを一覧表示するスクリプトの作成を依頼されました。スクリプトでは、ユーザーがフィルタ式を送信して、表示される結果を制限できるようにする必要があります。

どのようにデータを取得する必要がありますか？
1. HBase API、Redis API、MySQL接続を使用してデータベースのリストを取得します。結果を結合し、フィルタを適用して結果を表示する。
2. HBase API、Redis API、MySQL接続を使ってデータベースのリストを取得する。結果を個別にフィルタリングし、それらを組み合わせて結果を表示する。
3. gcloud bigtable instances list、gcloud redis instances list、gcloud sql databases listを実行する。アプリケーション内でフィルタを使用し、結果を表示する。
4. gcloud bigtableインスタンスリスト、gcloud redisインスタンスリスト、およびgcloud sqlデータベースリストを実行します。各コマンドで-filterフラグを使用し、結果を表示します。
<details><div>
    答え：4
説明
不正解
A. この場合、サービスごとにカスタム接続と追加ロジックが必要になり、不必要に複雑になります。gcloudコマンドラインツールは、この情報にアクセスするための、より効率的で標準的な方法を提供します。
B. 繰り返しになるが、個別のAPIと接続を使うと複雑さが増す。このアプローチでは、このようなタスクを単純化するために設計された、利用可能なgcloudコマンドも利用できない。
C. このオプションは、インスタンスを一覧表示するためにgcloudコマンドラインツールを正しく使用しますが、コマンドラインレベルでフィルタを適用できる組み込みの-filterフラグを利用しません。アプリケーション内でフィルタを適用するには、追加のロジックが必要です。
正しい答え
D. このオプションは、gcloudコマンドライン・ツールと-filterフラグを利用して、Cloud Bigtable、Memorystore、およびCloud SQLのインスタンスを効率的にリストし、フィルタリングします。このアプローチは、ベスト・プラクティスに沿い、組み込み機能を活用して複雑さを軽減します。
リンク
https://cloud.google.com/sdk/gcloud/reference/topic/filters
</div></details>

## Q. 3-28
あなたは、階層的なデータ構造をデータベースに保存するモバイルアプリケーションを構築しています。このアプリケーションは、オフラインで作業しているユーザーがオンラインに戻ったときに変更を同期できるようにします。バックエンドサービスは、サービスアカウントを使用してデータベース内のデータをリッチ化します。このアプリケーションは非常に人気があると予想され、シームレスかつ安全に拡張する必要がある。

どのデータベースとIAMロールを使うべきか？
1. Cloud SQLを使用し、roles/cloudsql.editorロールをサービスアカウントに割り当てます。
2. Bigtableを使用し、roles/bigtable.viewerロールをサービスアカウントに割り当てます。
3. ネイティブ・モードのFirestoreを使用し、roles/datastore.userロールをサービス・アカウントに割り当てます。
4. データストアモードのFirestoreを使用し、roles/datastore.viewerロールをサービスアカウントに割り当てます。
<details><div>
    答え：3
説明
不正解
A. Cloud SQLはリレーショナルデータベースであり、階層的なデータ構造には最適な選択ではないかもしれません。
editorロールは編集と管理へのフルアクセスを許可しますが、単にデータをリッチ化するには必要以上の権限かもしれません。
B. Bigtableは大規模用に設計されていますが、階層構造ではなく、高スループットでスケーラブルなNoSQLデータによく使用されます。
ビューアロールは読み取りアクセスしか許可しないため、データをエンリッチ（書き込み）する必要のあるサービスアカウントには適していません。
D. データストアモードのFirestoreも階層データをサポートしますが、サーバサイドのアプリケーションにより重点を置いています。
ビューアロールは読み取りアクセスしか許可しないため、データのエンリッチ化には適していません。
正解
C. ネイティブ・モードのFirestoreはモバイル・アプリケーション向けに設計されており、階層的なデータ構造とオフライン同期をサポートしています。
roles/datastore.userロールは、エンティティの読み取り、書き込み、および削除の権限を提供し、データをエンリッチするサービスアカウントに適しています。
このオプションは、シナリオで述べられている要件と一致しています。
リンク
https://cloud.google.com/architecture/building-scalable-apps-with-cloud-firestore
https://firebase.google.com/docs/firestore/manage-data/enable-offline
</div></details>

## Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

## Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

## Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

## Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

## Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>
