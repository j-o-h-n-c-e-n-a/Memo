# クラウド コンピューティングの概要
最近では誰もがクラウドに関心があります クラウドとは何か わかりやすい定義を紹介します アメリカ国立標準技術研究所の定義ですが どこでも当てはまります クラウドコンピューティングとは ITの利用手段であり 重要な５つの特性があります まず 必要に応じて自分で リソースを取得できます 単純なインターフェースを使うだけで 必要な処理能力、ストレージ、 ネットワークを取得できます 人間の介入は不要です 第二に ネットワーク経由で 場所を問わずリソースにアクセスできます 第三に リソースのプロバイダは 巨大なプールから顧客にリソースを割り当てます プロバイダは一括購入による スケールメリットを活かし 顧客に割引を提供できます 顧客はリソースの物理的な場所を 気にする必要はありません 第四に リソースは増減できます 必要に応じて迅速に追加できます 必要なければ減らせます 最後に 発生する料金は リソースを使用または予約した分だけです 使用を停止すると課金も停止します 以上がクラウドの定義です

# GCP コンピューティング アーキテクチャ
仮想データセンターによって IaaSとPaaSのサービスが可能になりました IaaSの未加工のコンピューティング、 ストレージ、ネットワークは データセンターと同様に編成されます 一方 PaaSでは 作成するアプリコードが ライブラリにバインドされるため 必要なインフラにアクセスできます そのため アプリのロジックのみに集中できます IaaSモデルでは 割り当てた分の料金を支払います PaaSモデルでは使用した分を支払います いずれも リスクの高い予測に基づいて 事前購入する以前の方法より経済的です クラウドコンピューティングの進化に伴い マネージドインフラとマネージドサービスの 勢いが増しています GCPの多くのサービスでは リソースのプロビジョニングが不要です 詳しくはこのコースで説明します 簡単にアプリに組み込めて 料金は使用した分だけです PaaSとIaaSを取り上げましたが SaaSについてはどうでしょうか Google検索、Gmail、ドキュメント、 ドライブなどの人気アプリはSaaSアプリです エンドユーザーが インターネットで直接利用するからです G Suiteはこのコースの対象外ですが 是非利用してみてください

# Google ネットワーク
一部の推定データによると Googleネットワークは世界のインターネット トラフィックの40%を伝送しています Googleネットワークは世界最大規模であり 長年にわたり数十億ドルを投資して構築しました 可能な限りスループットを高くし レイテンシを低くするように設計されています 世界各地の90を超える インターネット相互接続点と 100を超えるPoPで相互接続しています Googleリソースに トラフィックが送信されると Googleはレイテンシが最も低い エッジネットワークロケーションから応答します エッジキャッシングネットワークにより コンテンツはユーザーの近くに置かれます

# GCP のリージョンとゾーン
GCPの編成について説明します 最小の編成単位は 右側に示されているゾーンです ゾーンは GCPリソースのデプロイ領域です たとえば Compute Engineを使って GCPでVMを起動すると VMは指定したゾーンで稼働します ゾーンはGCPデータセンターのように 思われていますが正確にはそうではありません ゾーンは１つの建物と 対応するわけではないからです ただしそのように見てもかまいません ゾーンはリージョンという 個々の地域にグループ化されています GCPリソースを配置する リージョンを選択できます リージョン内のゾーン間では 高速ネットワーク接続を使用できます リージョン内のロケーションのラウンドトリップ ネットワークレイテンシは５ミリ秒未満です ゾーンはリージョン内の 単一障害点ドメインだと思ってください フォールトトレラントなアプリの構築では リソースをリージョン内の 複数のゾーンに分散できます こうするとアプリを 予期せぬ障害から保護できます リソースは複数リージョンで実行できます 多くのお客様がそうしています アプリを世界中のユーザーの 近くに配置するためです さらに 自然災害などによる リージョン全体の機能停止からも保護できます 一部のGCPサービスでは リソースをマルチリージョンに配置できます たとえば Cloud Storageでは データを欧州のマルチリージョンに配置できます つまり データの冗長性を確保するために 欧州内の160km以上離れた ２つ以上の場所にデータを保管できます 現時点でGCPには15のリージョンがあります 最新のリージョン数については cloud.google.comをご覧ください

# 環境に対する責任
仮想世界でもベースとなるのは 物理的なインフラです こうした一連のサーバーは 大量のエネルギーを消費します 既存のデータセンター全体の 電力消費量は世界全体の消費量の約２％です Googleはデータセンターの運用を 効率化する取り組みをしています 初めてISO 14001認証を取得したのは Googleのデータセンターです これは資源効率を高め 無駄を減らすための フレームワークを規定している標準規格です これはフィンランドのハミナにある Googleデータセンターです Googleで最も高度かつ効率的な データセンターの１つです エネルギー消費量を減らすために 冷却システムには海水を使用しています こうした取り組みは世界初です Googleは風力と太陽光エネルギーを 最も多く購入している企業の１つです 2007年以来 Googleは100％カーボンニュートラルです 近いうちにデータセンターの電力は 100％再生可能エネルギーになります お客様と同様に Googleは 地球環境の保護に努めています GCPのお客様には それぞれ環境目標があります GCPでワークロードを実行することも その達成の一助となるはずです

# お客様のための料金設定
Googleは他のクラウドプロバイダに先駆けて IaaSサービスのCompute Engineで 秒単位の課金を導入しました バースト性の高いワークロードの場合 きめ細かい課金は大幅なコスト削減になります 多くのGCPサービスが秒単位で課金されます Compute Engineや Kubernetes Engine などです このコースではこれらも取り上げます Compute Engineでは 自動的に継続利用割引が適用されます 請求月のVMインスタンスの実行時間が 特定の割合を超えると適用される割引です 具体的にはインスタンスの 実行時間が月の25%を超えると 以降はそのインスタンスの１分ごとの 使用料金に自動的に割引が適用されます カスタムVMタイプでは VMをアプリに合わせて微調整できます つまりワークロードに応じて料金を調整できます オンライン料金計算ツールを使えば 費用を見積もることができます

# オープン API
ワークロードをクラウドに移行するのを 不安に思う人もいます ベンダーロックインを危惧しているからです Googleはアプリを他の場所で実行できる さまざまな方法を提供しています Googleが最適なプロバイダで なくなった場合も安心です Googleがベンダーロックインの回避を どのように支援しているのか紹介します GCPサービスは オープンソースプロダクトと互換性があります Cloud Bigtableという データべースを見てみましょう Bigtableはオープンソースデータベースの Apache HBaseを使用しています そのためコードを移植しやすくなっています 他にもCloud Dataprocでは オープンソースビッグデータ環境のHadoopを マネージドサービスとして提供しています Googleはテクノロジーの主な要素を オープンソースライセンスで公開しています Google以外のオプションも選べる エコシステムを作るためです たとえば TensorFlow Googleが開発した機械学習用の オープンソースソフトウェアライブラリは 強力なオープンソースエコシステムの 中心となっています 多くのGCPテクノロジーには 相互運用性があります Kubernetesでは異なるクラウドで稼働する マイクロサービスを組み合わせることができます Stackdriverでは複数のクラウドプロバイダ間で ワークロードを監視できます

# Google Cloud Platform を選択する理由
GCPではコンピューティング、ストレージ、 ビッグデータ、機械学習、 アプリサービスを選んで ウェブ、モバイル、分析、バックエンド ソリューションに使用できます GCPはグローバルで費用対効果が高く オープンソース対応です セキュリティも考慮されています まとめましょう GCPのプロダクトとサービスには大きく分けて コンピューティング、ストレージ、 ビッグデータ、機械学習、 ネットワーキングと運用、ツールがあります このコースでは 各コンピューティングサービスを取り上げ それを選択する理由を説明します 各ストレージサービスも取り上げ その仕組みとユースケースを説明します Google Cloudデータアナリスト学習トラックの コースで各サービスを詳しく学習できます ビッグデータと機械学習サービスの 機能と目的も説明します これらのサービスの詳細についても データアナリスト学習トラックの コースで学習できます

# 多層セキュリティのアプローチ
Googleにはユーザー数が10億を超える サービスが７つもあるため Google社員はセキュリティを 常に気に掛けています セキュリティを考慮した設計は GCPと各サービスを実行する インフラの隅々に行き渡っています Googleがお客様のデータを保護するために 行っている取り組みを紹介します Googleデータセンターのサーバーボードと ネットワーク機器はカスタム設計です カスタムチップも設計しています Titanというハードウェア セキュリティチップは 現在サーバーと周辺機器の両方に デプロイされています サーバーマシンは暗号方式の署名を使用して 正しいソフトウェアを起動します 自社で設計して構築したデータセンターは 複数層の物理セキュリティで保護されています データセンターへのアクセスは ごく一部の社員に制限されています 私はアクセスできません Googleのインフラはリモートプロシージャ コールで取得されたデータを暗号化して プライバシーと整合性を確保します Googleサービスはこのように相互通信します このインフラはデータセンター間で転送される PCトラフィックを自動的に暗号化します 中央のアイデンティティサービスは一般に Googleログインページとして提示されますが ユーザー名とパスワードを要求するだけでなく リスク要因に基づいて 自動的に追加情報を要求します 過去に同じデバイスまたは同様の場所から ログインしたかどうかなどのリスク要因です ユーザーはログイン時に ２つ目の要素も使用できます これにはU2Fオープンスタンダードに基づく デバイスも含まれます 私のもそうです Googleでは大半のアプリが物理ストレージに ストレージサービスを介してアクセスします これらのサービスには 暗号化が組み込まれています ハードドライブとSSDでの ハードウェア暗号化も有効にしています そのためお客様のデータは 保存時に暗号化されます Googleサービスをインターネット上で 利用可能にするには Google Front End（GFE）という インフラサービスに登録します このサービスは着信ネットワーク接続が 正しい証明書を使用していることを確認します GFEはさらにサービス拒否攻撃に対する 防御策も講じています インフラの規模が大きいため Google では 多くのサービス拒否攻撃を単純に吸収できます これはGFEの背後でも同じです Googleはマルチティアでマルチレイヤの サービス拒否攻撃防御によって サービス拒否の影響のリスクを さらに低減しています Googleのインフラ内部では マシンインテリジェンスとルールにより インシデントの可能性が警告されます Googleはレッドチーム演習を実施して 攻撃をシミュレートし より有効に対処できるよう取り組んでいます Googleはインフラの管理権限を 付与する社員を絞り込み その活動を積極的に監視しています フィッシング攻撃から社員を保護するために 社員アカウントではU2F対応の セキュリティキーの使用を必須にしています おかげでキーを忘れなくなりました コードの安全性を最大限確保するため ソースコードは一元管理されます 新しいコードは ２名で確認してから保管されます デベロッパーにはセキュリティバグを 取り込まないようライブラリが提供されます 社外では 脆弱性報奨金プログラムも実施しています Googleのインフラやアプリで バグを発見した方に報奨金を提供しています

# 予算と請求
想定外に多額のGCP請求を 回避する方法はあるでしょうか GCPにはそのためのツールが４つあります 予算とアラート、課金データエクスポート、 レポート、割り当てです まず 予算とアラートを見ていきましょう 予算は請求先アカウントごと またはGCPプロジェクトごとに定義できます 予算には上限を設けることも 別の指標を関連付けることもできます たとえば 前月の利用額の割合などです アラートを作成すれば 費用が予算上限に近づいたときに通知が届きます たとえば 予算上限を20,000ドルに設定し アラートを90％に設定すると 利用額が18,000ドルに達した時点で 通知アラートが届きます 通常 アラートは 50％、90％、100％に設定しますが カスタマイズも可能です 課金データエクスポートでは 詳細な課金情報を 分析用に取得しやすい場所に保管できます たとえばBigQueryデータセットや Cloud Storageバケットなどです

レポートはGCP Console内の ビジュアルツールです 利用額を監視できます 割り当ても実装しています これはアカウント所有者と GCPコミュニティ全体を保護する手段です エラーや悪意のある攻撃による リソースの過剰消費を防ぐことができます 割り当てには２種類あります 頻度に基づく割り当てと 数量に基づく割り当てです どちらもGCPプロジェクト単位で 適用されます 頻度に基づく割り当ては 一定期間後にリセットされます たとえば Kubernetes Engineの デフォルトの割り当ては GCPプロジェクトごとに 100秒あたり1,000回のAPI呼び出しです 100秒が経過すると制限がリセットされます 一方 数量に基づく割り当ては プロジェクトで使用できる リソースの数を制御します たとえばデフォルトでは 各GCPプロジェクトで使用できる VPCネットワークの最大数は５です すべてのプロジェクトには 同じ割り当てが設定されますが Google Cloudサポートに 割り当ての増加をリクエストできます

# Getting Started with GCP
GCPで実行するワークロードは プロジェクトを使って整理します Google Cloud Identity and Access Management（IAM）を使用して 誰が何をできるかをコントロールします 接続するインターフェースには 複数の選択肢があります このモジュールは こうした基礎知識を基に進めます プロジェクトはGCPで使用する リソースを整理する主な手段です これを使って共通のビジネス目標を 持つリソースをグループ化します 最小権限の原則はコンピューティング インフラを管理するうえで非常に重要です クラウドでもオンプレミスでも同じです これは 各ユーザーに 必要な権限だけを付与するという原則です 最小権限の環境では あらゆるエラーからユーザーを保護できます 私の同僚が実行中の本番環境データベースを 誤って削除したことがありました なぜなら本来は必要のない rootユーザーの権限を持っていたからです 彼は今でも申し訳なさを感じています GCPのお客様はIAMを使用して最小権限を実装し こうした誤りを防ぐことができます GCPの管理レイヤを操作するには ４つの方法があります ウェブベースのConsole、 SDKとコマンドラインツール、 API、モバイルアプリです このクラスでは主にConsoleと コマンドラインツールを使用します オンプレミスのインフラでアプリを構築する場合 スタック全体のセキュリティ管理が必要です ハードウェアとそれらを収容する場所の 物理的セキュリティから ディスク上のデータの暗号化 ネットワークの健全性 アプリに収めるコンテンツの セキュリティに至るまでの責任が生じます アプリをGCPに移行すると 下位層のセキュリティはGoogleが管理します Googleはその規模を活かして お客様が自社で運用するよりも 高度なセキュリティを提供することができます セキュリティスタックの上位層は 引き続きお客様の管理になります GoogleはIAMなどのツールを提供して お客様が上位層で任意のポリシーを 実装できるようにしています

# Google Cloud Platform リソース階層
GCPのリソース階層は下位層から見ていったほうが容易に理解できます。 
使用するリソースは VM、Cloud Storageバケット、 テーブル、BigQueryなど
すべてが プロジェクトに整理されます 加えてプロジェクトをフォルダに まとめることもできます。 
フォルダには他のフォルダも格納できます。
組織が使用する全フォルダとプロジェクトは 組織ノードの下にまとめられます。 
プロジェクト、フォルダ、組織ノードには まとめてポリシーを定義できます。
一部のGCPリソースでは 個別にポリシーを定義できます。
たとえばCloud Storageバケットです そちらについては後ほど詳しく見ていきます。
それまでは ポリシーは階層の下位に 継承されることを覚えておいてください。

すべてのGCPリソースは、１つのプロジェクトに属します。プロジェクトはGCPサービスを使用する際の基本単位です。
APIの管理、課金の有効化、 共同編集者の追加と削除などを行います。 
各プロジェクトは独立した区画であり、各リソースは 1 つの区画にのみ属します。
プロジェクトごとに異なるオーナーとユーザーを作成して個別に管理できます。
各GCPプロジェクトに名前とプロジェクトIDを割り当てます。プロジェクトIDは永続的かつ不変で、GCP全体で一意である必要があります。このIDをさまざまなコンテキストで使用して、GCPに作業対象のプロジェクトを指示します。一方、プロジェクトには 好きな名前を付けられます。 
各プロジェクトには固有のプロジェクト番号も割り当てられ、さまざまなコンテキストで表示されます。ただしこのコースではあまり使用しません。
プロジェクトIDは人が読める文字列にします。このIDはプロジェクトを示すために頻繁に使用することになります。 
プロジェクトはフォルダにまとめることができます。フォルダは作業を楽にするためのツールです。たとえばフォルダを使用して 組織内の各部門、チーム、アプリ、 環境を表すことができます。フォルダを使ってチームの管理権限を委任すれば、各チームが独立して対応できるようになります。
フォルダ内のリソースは、そのフォルダのIAMポリシーを継承します。たとえばプロジェクト３と４が同じチームによって管理される場合、フォルダBにIAMポリシーを適用します。その結果、プロジェクト３と４のそれぞれに同じポリシーを適用する手間もエラーの発生も抑えられます。
注意点があります。フォルダを使用するには階層の最上位に組織ノードが必要です。詳細はこれから説明します。 
社内の全プロジェクトは１つの構造にまとめることができます。ほとんどの企業では、リソースの使用状況の確認とポリシーの適用を一元的に行う必要があります。それを可能にするのが組織ノードです。 
組織ノードは階層の最上位階層であり、特別な役割を持っています。たとえば、組織ポリシー管理者を指定して、管理者だけがポリシーを変更できるようにします。プロジェクト作成者の役割も割り当てられます。 購入を行えるユーザを管理する効果的な方法です。
組織ノードはどのように作成するのでしょうか。会社がG Suiteを 利用しているかどうかによって異なります。 G Suiteドメインがある場合、GCPプロジェクトは自動的に組織ノードに属します。 そうでない場合は Google Cloud Identityを 使用して作成できます。新しい組織ノードを作成した時点では、ドメイン内の全員が引き続きプロジェクトと請求先アカウントを作成できます。これは混乱を避けるためです。 新しい組織ノードを作成したら、まずこれらの操作を許可するチームメンバーを決定しましょう。組織ノードを作成すれば、その下にフォルダを作成して、そこにプロジェクトを配置できます。
リソース整理の例を紹介します。３つのプロジェクトがあり、それぞれが複数のGCPサービスのリソースを使用するとします。この例ではフォルダを使用していませんが、プロジェクトはいつでもフォルダに移せます。リソースは親リソースからポリシーを継承します。たとえば組織レベルで設定したポリシーは、自動的にすべての子プロジェクトに継承されます。継承が遷移するということです。つまり、プロジェクト内のすべてのリソースがポリシーを継承します。
重要なルールが１つあります。階層の上位で実装されたポリシーが、それより下位で付与されたアクセス権限を削除することはできません。たとえばbookshelfプロジェクトのポリシーによって、ユーザーPatにCloud Storageバケットの変更権限が付与されているとします。しかし、組織レベルのポリシーでPatに許可されているのは、バケットの変更ではなく表示です。この場合、より制限の緩いポリシーが適用されます。ポリシーの設計ではこの点に注意してください。

# Identity and Access Management（IAM）
IAMを使えば特定のリソースへの操作権限をユーザーに付与できます。
IAMポリシーは「誰が」「何を」 「どのリソースに」対して行えるかを定義します。
[誰が]では対象とする １人以上のユーザーを指定します。その定義に使用できるのは Googleアカウント、Googleグループ サービスアカウント、G Suite全体 、 Cloud Identityドメインです。
[何を]はIAM役割で定義します。IAM役割とは権限の集合です。意味のある操作を行うには通常、複数の権限が必要です。 たとえばプロジェクト内のインスタンスを管理するには、インスタンスを作成、削除、 起動、停止、変更する必要があります。こうした権限を１つの役割にまとめれば、権限を管理しやすくなります。
[誰が]は Googleアカウント、Googleグループ サービスアカウント、G Suite全体、 Cloud Identityドメインのいずれかになります。
IAM役割には３種類あります。順に見ていきましょう。基本の役割は広範です。GCPプロジェクトに適用すると、そのプロジェクトの全リソースに適用されます。基本の役割には オーナー、編集者、閲覧者があります。
[閲覧者]はリソースを確認できますが、状態の変更はできません。
[編集者]は閲覧者の権限に加えて、リソースの状態を変更できます。
[オーナー]は編集者の権限に加えて、リソースの役割と権限を管理できます。プロジェクトのオーナーにはもう１つの権限があります。支払い / 請求の設定です。通常、請求管理の担当者には プロジェクトリソースの変更権限は与えません。そのために課金管理者の役割を付与できます。
機密データが含まれるプロジェクトに複数のメンバーが取り組む場合は注意が必要です。基本の役割では広範すぎるかもしれません。GCP IAMにはよりきめ細かい役割もあります。
各GCPサービスには 独自の[定義済みの役割]があり、役割を適用できる対象が定義されています。たとえば、後ほど取り上げる Compute Engineでは 仮想マシンをサービスとして提供しており、複数の定義済み役割が用意されています。それらは特定のプロジェクト、特定のフォルダ、 組織全体のCompute Engineリソースに適用できます。マネージドデータベースサービスの Cloud Bigtableも見てみましょう。Cloud Bigtableが提供する役割は、組織全体、特定プロジェクト、さらに個々のBigtableデータベース インスタンスにも適用できます。

# IAM 役割
Compute Engineの InstanceAdmin役割を持つユーザーは、VMに対して特定の操作を行うことができます。たとえば、VMの一覧表示、 構成の読み取りと変更、VMの起動と停止です。操作対象のVMは役割の適用先によって決まります。ここでは特定のGoogleグループのユーザー全員がこの役割を持っています。この役割はproject_aの全VMに適用されます。さらにきめ細かい役割が必要な場合は、カスタムの役割があります。多くの会社では最小権限のモデルを使って各メンバーに必要最小限の権限のみを付与しています。たとえば、InstanceOperator役割を定義して、特定のユーザーにCompute EngineとVMの起動と停止を許可し、再構成は許可しないとします。カスタムの役割を使えばこれを実現できます。ただし注意点があります。
第一に、[カスタムの役割]を使うことを明確に決める必要があります。権限の管理が必要になるからです。会社によっては 事前定義済みの役割を選択しています。
第二に、カスタムの役割を使用できるのは[プロジェクトまたは組織レベル]のみです。フォルダレベルでは使用できません。 権限を付与する対象がユーザーではなく、Compute Engine VMだとしたら？ その場合はサービスアカウントを使用します。たとえばVMで実行しているアプリのデータを Google Cloud Storageに保管するとします。そのデータへのアクセスは、インターネット上の全員に許可するのではなくVMだけに許可します。そこで、Cloud Storageに対してVMを認証するためのサービスアカウントを作成します。サービスアカウントの名前はメールアドレスにします。ただし、パスワードではなく暗号鍵でリソースにアクセスします。こちらの例では、サービスアカウントにCompute EngineのInstanceAdmin役割が付与されています。VMで実行中のアプリはこのアカウントを使って他のVMを作成、変更、削除できます。また、サービスアカウントの管理も必要です。たとえば Aliceが特定のサービスアカウントで実行可能な操作を管理するとします。一方、Bobは表示さえできれば十分です。サービスアカウントはIDであると同時にリソースでもあるため。IAMポリシーをそれ自体に適用できます。サービスアカウントでAliceには編集者の役割を、Bobには閲覧者の役割を付与できます。他のGCPリソースの役割を付与する場合と同じです。プロジェクト内のVMのグループごとに異なるIDを付与できます。その結果、グループごとに異なる権限を管理しやすくなります。また、VMを再作成しなくてもサービスアカウントの権限を変更できます。さらに複雑な例を紹介します。Compute Engineの複数のVMにまたがって、実装されたアプリがあるとします。あるアプリコンポーネントには、別のプロジェクトでの編集者役割が必要ですが、他のコンポーネントには不要です。そこで２つのサービスアカウントを作成します。VMのサブグループごとに１つ作成します。最初のサービスアカウントにだけ、別のプロジェクトでの権限を与えます。これでアプリのコードが誤っていたり、VMが感染したりしたとしてもその影響を軽減できます。

# GCPの操作
GCPの４つの操作方法を 順に説明していきます GCP Console、SDKとCloud Shelll、 モバイルアプリ、APIの4つです Consoleはウェブベースの 管理インターフェースです GCPでアプリを作成するときに使用します アプリのエンドユーザーは使用しません Consoleではすべてのプロジェクトと 使用するリソースを確認、管理できます GCPサービスのAPIの 有効化、無効化、確認も可能です Cloud Shellにもアクセスできます Cloud ShellはGCPの コマンドラインインターフェースで ブラウザで簡単に使用できます Cloud Shellでは Google Cloudソフトウェア開発キット（SDK） に含まれるツールを使用できます インストールは不要です ソフトウェア開発キットについて説明します Google Cloud SDKは GCPでリソースとアプリを 管理するためのツールの一式です SDKに含まれるgcloudツールは GCPのプロダクトとサービスのメインの コマンドラインインターフェースです Cloud Storage用のgsutilと BigQuery用のbq（BigQuery）も含まれています SDKコマンドにアクセスするには ConsoleのCloud Shellボタンを クリックするのが簡単です SDKコマンドがすでにインストールされた VM上のウェブブラウザに コマンドラインが表示されます SDKを自分のマシンに インストールすることもできます ノートパソコンでもオンプレミスサーバーでも 他のクラウドのVMでもかまいません SDKはDockerイメージとしても提供されており システムを非常に簡単に扱うことができます GCPを構成するサービスには APIが用意されています コードでAPIをコントロールできます こうしたAPIは RESTfulと呼ばれます つまり Representational State Transfer パラダイムに従っています 詳細はここでは説明しませんが ウェブブラウザがウェブサーバーと 通信するのと同様の方法で Googleサービスをコードで使用できます APIではリソースとGCPをURLで指名します コードでAPIに情報を渡すには JSONを使用します テキスト形式の情報をウェブで 渡すためによく使われる形式です ユーザーログインとアクセスコントロール のためのオープンシステムも存在します GCP Consoleでは APIを有効または無効にできます 多くはデフォルトで無効にされています 割り当てと制限も適用されます こうした制限によって リソースの誤使用を防ぐことができます 必要なAPIだけを有効にして リソースが追加で必要になったら 割り当ての増加をリクエストできます たとえば GCPリソースをコントロール する必要があるアプリを作成するには APIを適切に使用する必要があります そこでAPI Explorerを利用します GCP Consoleに含まれる API Explorerというツールでは APIについてインタラクティブに 調べることができます 使用可能なAPIとバージョンを確認できます APIが要求するパラメータに関する ドキュメントも組み込まれています インタラクティブにAPIを試すことができ ユーザー認証も使えます たとえば APIを調べて そのAPIを使用する アプリの作成を始めるとします ゼロからコードを作成する必要はありません Googleのクライアントライブラリを使えば コードからGCPを呼び出す 面倒な作業を大幅に軽減できます ライブラリには２種類あります Cloudクライアントライブラリは Google CloudのAPIに推奨される 最新のライブラリです 各言語のネイティブスタイルと イディオムを採用しています ただし 最新のサービスと機能を サポートしていない場合もあります その場合は 使用する言語に対応する Google APIクライアントライブラリを使用します こうしたライブラリは普遍性と完全性を 重視して設計されています 最後に 開発者だけでなくすべてのユーザーに 役に立つツールがもう１つあります GCPで使用しているリソースを調べて管理できる AndroidとiOS向けのモバイルアプリです ダッシュボードを構築して 必要な情報をひと目で確認できます


# Compute Engineについて
クラウドでワークロードを実行する方法としては VMがよく知られています Compute EngineではVMを Googleのグローバルインフラで実行できます このモジュールでは Compute Engineの仕組みについて 仮想ネットワーキングを中心に説明します VMの利点の１つは 本格的なOSの処理能力と普遍性を 備えていることです VMは物理サーバーと同じように構成できます CPU処理能力、メモリ量、 ストレージの容量とタイプ、OSを指定できます VMは柔軟に再構成できます さらにGoogle Cloudで稼働するVMには 比類ないネットワーク接続性があります

# Virtual Private Cloud（VPC）ネットワーク
多くのユーザーはGCPを使い始める際に、最初のプロジェクトに独自の Virtual Private Cloud（VPC）を定義するか、デフォルトのVPCを選んで使い始めます。いずれにしてもVPCネットワークがGCPリソースの相互接続と、インターネットとの接続を可能にします。
ネットワークをセグメント化し、ファイアウォールルールでインスタンスへのアクセスを制限できます。 
静的ルートを作成すればトラフィックを特定の宛先に転送できます。
GCPを初めて使う多くの方が驚くことは、定義するVPCネットワークが[グローバルスコープ]を持つということです。世界中のどのGCPリージョンにもサブネットを持てます。サブネットはリージョン内の複数ゾーンをまたぐことも可能です。 
このアーキテクチャにより、グローバルスコープのネットワークレイアウトを簡単に定義できます。同じサブネットで複数ゾーンにリソースを配置することもできます。カスタムネットワーク内のサブネットのサイズは動的に拡大できます。割り当てるIP範囲を拡大するだけです。構成済みのVMに影響はありません。この例のVPCには１つのネットワークがあります。１つのサブネットが GCP us-east1リージョンに定義されています。接続されている Compute Engine VMは２つです。これらは同じサブネットで隣り合っていますが、異なるゾーン内にあります。この機能を使用すれば、単純なネットワークレイアウトながらも、復元性の高いソリューションを作成できます。

# Compute Engine
Compute EngineではVMを作成してGoogleのインフラで実行できます。先行投資は要りません。高速で一貫したパフォーマンスのシステムで数千もの仮想CPUを実行できます。
VMインスタンスを作成するには GCP Console、または gcloudコマンドラインツールを使います。VMで実行できるLinuxまたは Windows Serverイメージには Google提供のものと カスタマイズバージョンがあります。物理サーバーからイメージを インポートすることも可能です。
VMを作成するときにマシンタイプを選びます。タイプによってメモリ量と仮想CPUの数が決まります。タイプにはごく小さなものから非常に大きなものまであります。
事前定義済みのタイプで要件を満たせない場合は、[カスタムVM]を作成できます。処理能力については機械学習やデータ処理など、GPUを利用できるワークロード向けにGCPの多くのゾーンでは GPUを利用できます。
物理的なマシンと同じように VMにもディスクが必要です。永続ストレージは２種類から選択できます。[標準とSSD]です。 アプリに高パフォーマンスの一時的領域が必要な場合は、[ローカルSSD]を接続できます。ただし永続的な価値のあるデータは、別の場所に保管してください。ローカルSSDのコンテンツは[VMが終了すると消去される]からです。したがって、もう１種類は永続ディスクです。ほとんどのユーザーは初めはデフォルトの標準永続ディスクを使用します。ブートイメージも選べます。さまざまなバージョンの LinuxとWindowsが用意されています。独自のイメージもインポートできます。VMが常に特定の構成で起動すると便利です。起動時にソフトウェアパッケージをインストールするなどです。これを行うには GCP VM[起動スクリプト]を渡すのが一般的です。他の種類のメタデータを渡すこともできます。
VMが稼動したら、簡単にディスクのスナップショットを取れます。バックアップとして保管したり、別のリージョンへのVMの移行時に使用したりできます。完了するまで人が介入しないワークロードがあるとします。大規模なデータセットを分析するバッチジョブなどです。
[プリエンブティブルVM]でジョブを実行すると、費用を節約できます。プリエンプティブルVMには通常の Compute Engine VMと異なる点が１つあります。他でリソースが必要になった場合に Compute Engineがそれを[終了できる]という点です。 プリエンプティブルVMでは 費用を大幅に節約できますが 停止と再開が可能なジョブに使用してください。
インスタンスに応じた適切なマシンは、仮想CPUの数やメモリ量を基に選択できます。事前定義済みマシンタイプを使用することも、カスタムマシンタイプを作成することもできます。前述のとおり、Compute EngineではVMをかなり大きなサイズにできます。この動画を録画している時点では VMの仮想CPUの最大数は96です。ベータ版での最大メモリサイズは624GBです。最新情報は、GCPウェブサイトでご確認ください。大規模なVMはインメモリデータベースや 分析などのワークロードに役立ちます。しかし、GCPの大半のお客様は最初にスケールアップではなく、スケールアウトを行います。Compute Engineの自動スケーリング機能を使用すると、負荷の指標に基づいてアプリのVM数を増減できます。この仕組みの一環として、着信トラフィックの負荷がVM間で分散されます。Google VPCは何種類かの負荷分散をサポートしています。負荷分散については次のセクションで説明します。

# VPC の重要な機能
物理ネットワークと同じく VPCでもルーティングテーブルを使用します 同じネットワーク内のインスタンス間で トラフィックを転送するためです サブネット間やGCPゾーン間でも 外部IPアドレスを使用せずに転送できます VPCルーティングテーブルは 組み込まれているので プロビジョニングや管理は不要です ファイアウォールインスタンスの プロビジョニングと管理も不要です VPCのグローバルな 分散型ファイアウォールを使用して インスタンスへの 送受信トラフィックを制限できます ファイアウォールル―ルの定義では インスタンスのメタデータタグを使用できます これは非常に便利です たとえばすべてのウェブサーバーに 「web」というタグを付けるとします ファイアウォールルールで ポート80または443での受信トラフィックを 「web」タグが付いたVMに許可します IPアドレスは何であろうと関係ありません 前に説明したように VPCはGCPプロジェクトに属します 複数のGCPプロジェクトがあり VPC間の通信が必要な場合はどうなるでしょう 心配いりません このような通信も可能です 単に２つのVPC間にピアリング関係を確立して トラフィックを交換可能にする場合 VPCピアリングを使用できます 一方 IAMを機能を最大限に利用して 別のプロジェクトのVPCに対して 誰が何の操作を行えるか制御するには 共有VPCを使用できます いくつか前のスライドで 負荷の変化に応じてVMが 自動スケーリングする仕組みを説明しました その時々でアプリを提供する VMの数が変わる場合 ユーザーはどのようにアプリに アクセスするのでしょうか その答えはCloud Load Balancingです これはソフトウェアで定義された 完全分散型のマネージドサービスです ロードバランサは 管理対象のVM内で実行されないため スケーリングも管理も不要です Cloud Load Balancingはすべての トラフィックに対応しています これにはHTTPとHTTPS、 その他のTCPとSSLトラフィック、 UDPトラフィックも含まれます Cloud Load Balancingでは １つのエニーキャストIPが 世界中のリージョンのバックエンド インスタンスのフロントエンドとなります 負荷はリージョン間で分散されます さらに自動マルチリージョン フェイルオーバーにより バックエンドの不調時には トラフィックを分割して移動します Cloud Load Balancingは ユーザー、トラフィック、バックエンドの状態、 ネットワーク条件などの変化に瞬時に対応します たとえばオンラインゲームが大ヒットするなど 需要の急増が見込まれるとします サポートチケットでGoogleに 負荷の急増を予告する必要があるでしょうか いいえ いわゆる事前警告は不要です ウェブアプリの負荷を リージョン間で分散する場合は HTTPS負荷分散を使用します HTTP以外のSSLトラフィックには グローバルSSLプロキシロードバランサを 使用します SSLを使用しないTCPトラフィックであれば グローバルTCPプロキシロードバランサを 使用します この２種類のプロキシサービスは 特定のポート番号とTCPでのみ機能します UDPトラフィックや任意のポート番号の トラフィックを負荷分散する場合は リージョンロードバランサで リージョン全体に負荷を分散できます これらすべてのサービスの共通点は インターネットから送信されるトラフィックを 対象としていることです プロジェクト内での トラフィックの負荷分散はどうでしょう アプリのプレゼンテーション層と ビジネスロジック層の間での負荷分散などです その場合は内部ロードバランサを使用します GCP内部IPアドレスでの受信トラフィックの 負荷をCompute Engine VM間に分散します よく知られている Googleの無料サービスの１つに 公開ドメインネームサービスを 世界に提供する8.8.8.8があります DNSはインターネットホスト名を アドレスに変換します お察しのとおり Googleには高度なDNSインフラがあります これにより8.8.8.8を 誰もが利用できるようになっています GCPで作成するアプリのインターネット ホスト名とアドレスについてはどうでしょう 世界中でアプリが見つかるように GCPではCloud DNSを提供しています これはGoogleと同じインフラで 実行されるマネージドDNSサービスです 低レイテンシと高可用性を実現し 費用効率の高い方法で アプリとサービスをユーザーに提供できます DNS情報を公開すると その情報は 全世界のあらゆる場所から配信されます Cloud DNSはプログラムも可能です 数百万ものDNSゾーンとレコードを 公開して管理するには GCP Console、コマンドライン インターフェース、APIを使用できます Googleにはグローバルな エッジキャッシュシステムがあります このシステムを使ってアプリの コンテンツ配信を加速化するには Google Cloud CDNを使用します ユーザーは低レイテンシを実感するでしょう コンテンツの発信元の負荷が減り 費用も節約できまます HTTPS負荷分散を設定した後に チェックボックスをオンにするだけで Cloud CDNを有効にできます 当然 CDNは他にもたくさん存在します すでにCDNを使用している場合 GCPのCDN Interconnectパートナー プログラムの対象である可能性があります その場合はそのまま使用できます GCPのお客様の多くはGoogle VPCと 他のネットワークの相互接続を必要とします オンプレミスネットワークや他の クラウド内のネットワークなどです 選択肢はたくさんあります 多くのお客様は 仮想プライベートネットワークを IPSECプロトコルを使用して インターネットで接続します さらに 動的な接続にするために Cloud RouterというGCP機能を使用します この機能を使用すると 他のネットワークとGoogle VPCの間で BGPを使って VPN経由でルート情報を交換できます たとえば 新しいサブネットを Google VPCに追加すると オンプレミスネットワークが自動的に そのルートを取得します インターネットを使用したくないお客様もいます セキュリティの懸念がある場合や 信頼性の高い帯域幅が必要な場合などです その場合はGoogleとの ダイレクトピアリングを検討できます ピアリングとはルーターを Google POPと同じデータセンターに配置して トラフィックを交換することです Googleは世界中に 100を超えるPOPを設けています POPでまだ接続を確立していない場合は キャリアピアリングプログラムの パートナーに接続を依頼できます ピアリングには欠点が１つあります それはGoogleのSLAの対象ではないことです Googleとの相互接続で 高い稼働率が必要な場合は Dedicated Interconnectを使用してください Googleとの１つ以上の 直接プライベート接続を確立できます 接続形態がGoogleの仕様を満たす場合 その接続は最大で 稼働率99.99％のSLAの対象になります VPNで接続をバックアップすれば 信頼性はさらに高くなります

# Google Cloud Platform のストレージ オプションの概要
すべてのアプリには データ ストレージが必要です ストリーミング メディアや センサーデータ、口座の残高、 私のポケモンの 2,600強のCPデータなどの保管場所です アプリとワークロードによって 必要なストレージデータベース ソリューションは異なります ご存知のとおり データはVMの永続ディスクに保管できます GCPには他のストレージオプションもあり 構造化、非構造化、トランザクション、 リレーショナルデータに応じて選べます このモジュールで取り上げる ストレージオプションは Cloud Storage、Cloud SQL、 Cloud Spanner、Cloud Data Store、 Google Bigtableです アプリに応じて １つまたは複数の ストレージサービスを使用します

# Cloud Storage
まずCloud Storageについて説明しましょう。
オブジェクトストレージとは何でしょう。フォルダの階層としてデータを管理するファイルストレージとは異なります。OSがデータをディスクの塊として、管理するブロックストレージとも異なります。オブジェクトストレージとは、データを保管するとその一連のバイトが[オブジェクト]として扱われ、固有のキーでデータをアドレス指定できるストレージを意味します。それだけです。通常、これらの固有のキーは[URL形式]です。つまり、ウェブテクノロジーとの相性が良いストレージです。Cloud Storageの仕組みもまったく同じですが、さらに利点があります。これはスケーラブルなフルマネージドサービスです。つまり、容量の事前プロビジョニングは不要です。オブジェクトを作成するだけで、耐久性と可用性に優れたデータ保存が可能になります。
Cloud Storageはさまざまな目的で使用できます。ウェブサイトコンテンツの配信やアーカイブ・復旧用データの保管、ユーザーの直接ダウンロードによる大容量データの配布などです。Cloud Storageはファイルシステムではありません。格納されているオブジェクトごとにURLがあるからです。各オブジェクトは多くの点で、ファイルのようなものなのでオブジェクトを「ファイル」という言葉で説明しても構いませんが、正確にはファイルシステムとは違います。Linuxマシンのルートファイルシステムとして、Cloud Storageを使うことはありません。
Cloud Storageはバケットで構成されます。ユーザーがバケットを作成して構成し、そこにオブジェクトを格納します。ストレージオブジェクトは不変です。つまり、インプレースで編集するのではなく[新しいバージョン]を作成します。
Cloud Storageは必ずサーバー側で[データを暗号化]してからディスクに書き込みます。暗号化の追加料金はありません。また、デフォルトでは[転送中のデータがHTTPSで暗号化]されます。
データ転送については、大量のデータをCloud Storageに保存できる便利なサービスもあります。この後のモジュールで改めて説明します。Cloud Storageに格納されたデータは、他のGCPストレージサービスに移動できます。すでに述べたとおり、Cloud Storageのファイルはバケットに整理されます。バケットの作成時に[グローバルに一意の名前]を付けます。バケットとそのコンテンツを保管する地理的ロケーションを指定し、デフォルトのストレージクラスを選択します。ユーザーにとってレイテンシが最小になる ロケーションを選んでください。大半のユーザーがヨーロッパにいる場合は、ヨーロッパのロケーションを選択します。
オブジェクトとバケットへのユーザーアクセスを制御する方法はいくつかあります 通常はCloud IAMで十分です。役割はプロジェクトから バケット、オブジェクトへと継承されます。よりきめ細かい制御が必要な場合は アクセス制御リスト（ACL）を作成します。[ACL]で定義するのはバケットとオブジェクトにアクセスできるユーザーとユーザーのアクセスレベルです。各ACLは２つの情報で構成されます。１つは指定の操作を実行できるユーザーを定義する「スコープ」で、たとえば特定のユーザーやユーザーグループを定義します。もう１つは実行できる操作を定義する「権限」です。読み取り権限や書き込み権限などです。先ほど述べたように Cloud Storageオブジェクトは不変です。必要であればバケットでオブジェクトの[バージョニングを有効]にできます。その場合、 Cloud Storageは 変更履歴を保持します。つまり、バケット内の全オブジェクトを上書きまたは削除します。オブジェクトのアーカイブバージョンを一覧表示して、オブジェクトを前の状態に復元したり、完全にバージョンを削除したりできます。オブジェクトバージョニングを有効にしていない場合は、新しいオブジェクトが常に古いオブジェクトを上書きします。バージョニングは便利ですが、ゴミが溜まるのが心配であれば、Cloud Storageの ライフサイクル管理ポリシーを使用するといいでしょう。たとえば Cloud Storageに365日を経過したオブジェクトを削除するように指示できます。2013年１月１日より前に作成されたものを削除するという形でも指示できます。バージョニングが有効なバケットでは、直近の３つのバージョンだけを残すことも可能です。

# Cloud Storage の操作
Cloud Storageではストレージクラスを ４つの中から選択できます Regional、Multi-Regional、 Nearline、Coldlineです Multi-RegionalとRegionalは 高パフォーマンスのオブジェクトストレージです 一方 NearlineとColdlineは バックアップとアーカイブ用のストレージです よって２つのグループの間に 太い境界線を引きました いずれのストレージクラスにも Cloud Storage APIで同じようにアクセスでき すべてミリ秒単位でアクセス時間が計測されます では違いを見ていきましょう Regionalでは 特定のGCPリージョンにデータを保管できます us-central1、europe-west1、 asia-east1のいずれかです Multi-Regionalより安価ですが 冗長性は低くなります 一方 Multi-Regionalでは 料金は高くなりますが 地理的冗長性が確保されます 米国、EU、アジアなどの大まかな 地理的ロケーションを選ぶと Cloud Storageが160km以上離れた２か所の 地理的ロケーションにデータを保管します Multi-Regionalが適しているのは 頻繁にアクセスするデータです たとえば ウェブサイトのコンテンツや インタラクティブなワークロード モバイルアプリやゲームアプリの データなどです Regionalが適しているのは Compute Engine、VM、Kubernetes Engine クラスタの近くにデータを保管する場合です データ集約型の計算パフォーマンスが 向上するためです Nearlineは安価で 耐久性に優れたサービスです アクセス頻度が低い データの保管に適しています このストレージクラスが Multi-RegionalやRegionalよりも適しているのは データの読み取りや変更を行うのが 平均で月に１回以下の場合です たとえばCloud Storageに 継続的にファイルを追加して 月に１度の分析に使用する場合は Nearlineが最適です Coldlineは非常に安価な 耐久性に優れたサービスで データアーカイブ、オンラインバックアップ、 障害復旧に適しています Coldlineは年に１度程度しか アクセスしないデータの保管に最適です なぜなら可用性が若干低く 90日の最小保存期間があるからです データアクセスに費用がかかり １オペレーションあたりの費用も高めです たとえば データのアーカイブや 障害復旧での使用に適しています 可用性はストレージクラスによって異なります 最も高いのは可用性99.95％の Multi-Regionalです 次は可用性99.9％のRegionalです NearlineとColdlineの可用性は99％です 料金については すべてのクラスで１か月あたりの データ保存量に対しGB単位で料金が発生します 料金が最も高いのは Multi-Regionalで 最も低いのはColdlineです 下りトラフィックと データ転送の料金がかかることもあります これらの料金に加えて Nearlineではデータ読み取りにも GB単位の料金が発生します ColdlineではGB単位の データ読み取り料金はさらに高くなります どのストレージクラスでも 複数の方法でデータを Cloud Storageに取り込めます 多くのお客様は gsutil を使用しています これはCloud SDKに含まれる Cloud Storageコマンドです Chromeブラウザを使用していれば GCP Consoleでドラッグ＆ドロップでの データ移動も可能です テラバイトからペタバイト規模の データをアップロードする場合は GCPのオンラインStorage Transfer Serviceと オフラインTransfer Applianceを利用できます Storage Transfer Serviceでは 別のクラウドプロバイダ、別のリージョン、 HTTPSエンドポイントから Cloud Storageへの一括転送を スケジュールして管理できます Transfer Applianceはラックマウント型の 大容量ストレージ サーバーで Google Cloudからリースできます ネットワークに接続してデータを読み込んでから アップロード施設に配送するだけで データがCloud Storageにアップロードされます このサービスを使えば１台の機器で 最大１ペタバイトのデータを安全に転送できます 現時点ではまだベータ版で 使用できる場所は限られていますので 詳細についてはウェブサイトをご覧ください Cloud Storageに データを格納する方法は他にもあります このストレージはGCPの多数のプロダクトと サービスと密接に統合されているためです たとえば BigQueryとCloud SQLとの間で テーブルをインポート、エクスポートできます App Engineのログや Cloud Datastoreのバックアップ App Engineで使用するイメージなどの オブジェクトも保管できます 他にもインスタンスの起動スクリプトや Compute Engineイメージ Compute Engineアプリの オブジェクトなども保管できます つまりCloud Storageはクラウドへの データ取り込みポイントになり データを長期間保存する場所としても 頻繁に使用されています

# Google Cloud Bigtable
Cloud Bigtableはビッグデータ用の NoSQLデータベースサービスです [NoSQL]とは何でしょう もちろんデータベースではありません 簡単に概要を説明します まずリレーショナルデータベースは 各行に一連の同じ列があるテーブルの 集合だと考えてください このルールと各テーブルに指定したルールを データベースエンジンが適用します これはデータベーススキーマと呼ばれます スキーマが大きな助けになるアプリもあれば 大きな障害になるアプリもあります 一部のアプリではもっと柔軟な手法が必要です たとえば NoSQLスキーマです こうしたアプリでは すべての行に同じ列がある必要はありません データベースによってはこれを活かすために データを低密度で行に取り込みます これはNoSQLデータベースの特徴の１つです Bigtableにもこの特徴があります Bigtableは低密度に格納されるテーブルで 数十億行、数千列にスケールして 数ペタバイトのデータを保管できます GCPのフルマネージドサービスなので 構成や調整は不要です Bigtableが適しているのは 単一の参照キーを持つデータです 一部のアプリ開発者はBigtableを 永続ハッチテーブルとみなしています Bigtableは極めて低いレイテンシで 大容量データを格納するのに最適です 高スループットの読み書きに対応するため 運用アプリと分析アプリの両方に理想的です たとえば IoT、ユーザー分析、 財務データ分析などです Cloud Bigtableは HBaseと同じ オープンソースAPIを介して提供されます HBaseはApache Hadoopプロジェクトの ネイティブデータベースです [Hadoop]については 別途説明します 同じAPIを使用するということは HBaseとBigtableの間で アプリを移植できるということです 独自のApache HBaseインストール環境を 管理している場合 なぜBigtableを選択するのか 疑問に思うかもしれません その理由をいくつか説明します まず スケーラビリティです 独自のHbaseインストール環境では ある時点で１秒あたりのクエリ数を スケールするのが難しくなります Bigtableではマシンの数を 増やすだけでスケールできます ダウンタイムも必要ありません また Bigtableはアップグレードや 再起動などの管理タスクを透過的に処理します Bigtable内のデータはすべて 処理中にも保存時にも暗号化されます IAM権限を使用してBigtableデータに アクセスできるユーザーも制御できます 最後にもう１点お伝えします Bigtableは Googleの多くのコアサービスを 支えるデータベースです Google検索、アナリティクス、 マップ、Gmailなどのサービスです Cloud Bigtableは GCPエコシステムの一部であるため 他のGCPサービスや サードパーティクライアントと連携できます アプリのAPIの観点から見ると Cloud Bigtableでのデータの読み書きは データサービス層で行えます つまりマネージドVMや HBase RESTサーバー HBaseクライアントを使用する Javaサーバーなどで行えます 通常は ここでアプリ、ダッシュボード、 データサービスにデータが提供されます 各種のストリーム処理フレームワークで データをストリーミングすることも可能です Cloud Dataflow Streaming、 Spark Streaming、Stormなどを使えます ストリーミングできない場合は Hadoop Map/Reduce、Dataflow、Sparkで データの読み書きを一括処理できます 通常は 集約データおよび 新しく計算されたデータが Cloud Bigtableまたは 下流のデータベースに書き込まれます

