# クラウド コンピューティングの概要
最近では誰もがクラウドに関心があります クラウドとは何か わかりやすい定義を紹介します アメリカ国立標準技術研究所の定義ですが どこでも当てはまります クラウドコンピューティングとは ITの利用手段であり 重要な５つの特性があります まず 必要に応じて自分で リソースを取得できます 単純なインターフェースを使うだけで 必要な処理能力、ストレージ、 ネットワークを取得できます 人間の介入は不要です 第二に ネットワーク経由で 場所を問わずリソースにアクセスできます 第三に リソースのプロバイダは 巨大なプールから顧客にリソースを割り当てます プロバイダは一括購入による スケールメリットを活かし 顧客に割引を提供できます 顧客はリソースの物理的な場所を 気にする必要はありません 第四に リソースは増減できます 必要に応じて迅速に追加できます 必要なければ減らせます 最後に 発生する料金は リソースを使用または予約した分だけです 使用を停止すると課金も停止します 以上がクラウドの定義です

# GCP コンピューティング アーキテクチャ
仮想データセンターによって IaaSとPaaSのサービスが可能になりました IaaSの未加工のコンピューティング、 ストレージ、ネットワークは データセンターと同様に編成されます 一方 PaaSでは 作成するアプリコードが ライブラリにバインドされるため 必要なインフラにアクセスできます そのため アプリのロジックのみに集中できます IaaSモデルでは 割り当てた分の料金を支払います PaaSモデルでは使用した分を支払います いずれも リスクの高い予測に基づいて 事前購入する以前の方法より経済的です クラウドコンピューティングの進化に伴い マネージドインフラとマネージドサービスの 勢いが増しています GCPの多くのサービスでは リソースのプロビジョニングが不要です 詳しくはこのコースで説明します 簡単にアプリに組み込めて 料金は使用した分だけです PaaSとIaaSを取り上げましたが SaaSについてはどうでしょうか Google検索、Gmail、ドキュメント、 ドライブなどの人気アプリはSaaSアプリです エンドユーザーが インターネットで直接利用するからです G Suiteはこのコースの対象外ですが 是非利用してみてください

# Google ネットワーク
一部の推定データによると Googleネットワークは世界のインターネット トラフィックの40%を伝送しています Googleネットワークは世界最大規模であり 長年にわたり数十億ドルを投資して構築しました 可能な限りスループットを高くし レイテンシを低くするように設計されています 世界各地の90を超える インターネット相互接続点と 100を超えるPoPで相互接続しています Googleリソースに トラフィックが送信されると Googleはレイテンシが最も低い エッジネットワークロケーションから応答します エッジキャッシングネットワークにより コンテンツはユーザーの近くに置かれます

# GCP のリージョンとゾーン
GCPの編成について説明します 最小の編成単位は 右側に示されているゾーンです ゾーンは GCPリソースのデプロイ領域です たとえば Compute Engineを使って GCPでVMを起動すると VMは指定したゾーンで稼働します ゾーンはGCPデータセンターのように 思われていますが正確にはそうではありません ゾーンは１つの建物と 対応するわけではないからです ただしそのように見てもかまいません ゾーンはリージョンという 個々の地域にグループ化されています GCPリソースを配置する リージョンを選択できます リージョン内のゾーン間では 高速ネットワーク接続を使用できます リージョン内のロケーションのラウンドトリップ ネットワークレイテンシは５ミリ秒未満です ゾーンはリージョン内の 単一障害点ドメインだと思ってください フォールトトレラントなアプリの構築では リソースをリージョン内の 複数のゾーンに分散できます こうするとアプリを 予期せぬ障害から保護できます リソースは複数リージョンで実行できます 多くのお客様がそうしています アプリを世界中のユーザーの 近くに配置するためです さらに 自然災害などによる リージョン全体の機能停止からも保護できます 一部のGCPサービスでは リソースをマルチリージョンに配置できます たとえば Cloud Storageでは データを欧州のマルチリージョンに配置できます つまり データの冗長性を確保するために 欧州内の160km以上離れた ２つ以上の場所にデータを保管できます 現時点でGCPには15のリージョンがあります 最新のリージョン数については cloud.google.comをご覧ください

# 環境に対する責任
仮想世界でもベースとなるのは 物理的なインフラです こうした一連のサーバーは 大量のエネルギーを消費します 既存のデータセンター全体の 電力消費量は世界全体の消費量の約２％です Googleはデータセンターの運用を 効率化する取り組みをしています 初めてISO 14001認証を取得したのは Googleのデータセンターです これは資源効率を高め 無駄を減らすための フレームワークを規定している標準規格です これはフィンランドのハミナにある Googleデータセンターです Googleで最も高度かつ効率的な データセンターの１つです エネルギー消費量を減らすために 冷却システムには海水を使用しています こうした取り組みは世界初です Googleは風力と太陽光エネルギーを 最も多く購入している企業の１つです 2007年以来 Googleは100％カーボンニュートラルです 近いうちにデータセンターの電力は 100％再生可能エネルギーになります お客様と同様に Googleは 地球環境の保護に努めています GCPのお客様には それぞれ環境目標があります GCPでワークロードを実行することも その達成の一助となるはずです

# お客様のための料金設定
Googleは他のクラウドプロバイダに先駆けて IaaSサービスのCompute Engineで 秒単位の課金を導入しました バースト性の高いワークロードの場合 きめ細かい課金は大幅なコスト削減になります 多くのGCPサービスが秒単位で課金されます Compute Engineや Kubernetes Engine などです このコースではこれらも取り上げます Compute Engineでは 自動的に継続利用割引が適用されます 請求月のVMインスタンスの実行時間が 特定の割合を超えると適用される割引です 具体的にはインスタンスの 実行時間が月の25%を超えると 以降はそのインスタンスの１分ごとの 使用料金に自動的に割引が適用されます カスタムVMタイプでは VMをアプリに合わせて微調整できます つまりワークロードに応じて料金を調整できます オンライン料金計算ツールを使えば 費用を見積もることができます

# オープン API
ワークロードをクラウドに移行するのを 不安に思う人もいます ベンダーロックインを危惧しているからです Googleはアプリを他の場所で実行できる さまざまな方法を提供しています Googleが最適なプロバイダで なくなった場合も安心です Googleがベンダーロックインの回避を どのように支援しているのか紹介します GCPサービスは オープンソースプロダクトと互換性があります Cloud Bigtableという データべースを見てみましょう Bigtableはオープンソースデータベースの Apache HBaseを使用しています そのためコードを移植しやすくなっています 他にもCloud Dataprocでは オープンソースビッグデータ環境のHadoopを マネージドサービスとして提供しています Googleはテクノロジーの主な要素を オープンソースライセンスで公開しています Google以外のオプションも選べる エコシステムを作るためです たとえば TensorFlow Googleが開発した機械学習用の オープンソースソフトウェアライブラリは 強力なオープンソースエコシステムの 中心となっています 多くのGCPテクノロジーには 相互運用性があります Kubernetesでは異なるクラウドで稼働する マイクロサービスを組み合わせることができます Stackdriverでは複数のクラウドプロバイダ間で ワークロードを監視できます

# Google Cloud Platform を選択する理由
GCPではコンピューティング、ストレージ、 ビッグデータ、機械学習、 アプリサービスを選んで ウェブ、モバイル、分析、バックエンド ソリューションに使用できます GCPはグローバルで費用対効果が高く オープンソース対応です セキュリティも考慮されています まとめましょう GCPのプロダクトとサービスには大きく分けて コンピューティング、ストレージ、 ビッグデータ、機械学習、 ネットワーキングと運用、ツールがあります このコースでは 各コンピューティングサービスを取り上げ それを選択する理由を説明します 各ストレージサービスも取り上げ その仕組みとユースケースを説明します Google Cloudデータアナリスト学習トラックの コースで各サービスを詳しく学習できます ビッグデータと機械学習サービスの 機能と目的も説明します これらのサービスの詳細についても データアナリスト学習トラックの コースで学習できます

# 多層セキュリティのアプローチ
Googleにはユーザー数が10億を超える サービスが７つもあるため Google社員はセキュリティを 常に気に掛けています セキュリティを考慮した設計は GCPと各サービスを実行する インフラの隅々に行き渡っています Googleがお客様のデータを保護するために 行っている取り組みを紹介します Googleデータセンターのサーバーボードと ネットワーク機器はカスタム設計です カスタムチップも設計しています Titanというハードウェア セキュリティチップは 現在サーバーと周辺機器の両方に デプロイされています サーバーマシンは暗号方式の署名を使用して 正しいソフトウェアを起動します 自社で設計して構築したデータセンターは 複数層の物理セキュリティで保護されています データセンターへのアクセスは ごく一部の社員に制限されています 私はアクセスできません Googleのインフラはリモートプロシージャ コールで取得されたデータを暗号化して プライバシーと整合性を確保します Googleサービスはこのように相互通信します このインフラはデータセンター間で転送される PCトラフィックを自動的に暗号化します 中央のアイデンティティサービスは一般に Googleログインページとして提示されますが ユーザー名とパスワードを要求するだけでなく リスク要因に基づいて 自動的に追加情報を要求します 過去に同じデバイスまたは同様の場所から ログインしたかどうかなどのリスク要因です ユーザーはログイン時に ２つ目の要素も使用できます これにはU2Fオープンスタンダードに基づく デバイスも含まれます 私のもそうです Googleでは大半のアプリが物理ストレージに ストレージサービスを介してアクセスします これらのサービスには 暗号化が組み込まれています ハードドライブとSSDでの ハードウェア暗号化も有効にしています そのためお客様のデータは 保存時に暗号化されます Googleサービスをインターネット上で 利用可能にするには Google Front End（GFE）という インフラサービスに登録します このサービスは着信ネットワーク接続が 正しい証明書を使用していることを確認します GFEはさらにサービス拒否攻撃に対する 防御策も講じています インフラの規模が大きいため Google では 多くのサービス拒否攻撃を単純に吸収できます これはGFEの背後でも同じです Googleはマルチティアでマルチレイヤの サービス拒否攻撃防御によって サービス拒否の影響のリスクを さらに低減しています Googleのインフラ内部では マシンインテリジェンスとルールにより インシデントの可能性が警告されます Googleはレッドチーム演習を実施して 攻撃をシミュレートし より有効に対処できるよう取り組んでいます Googleはインフラの管理権限を 付与する社員を絞り込み その活動を積極的に監視しています フィッシング攻撃から社員を保護するために 社員アカウントではU2F対応の セキュリティキーの使用を必須にしています おかげでキーを忘れなくなりました コードの安全性を最大限確保するため ソースコードは一元管理されます 新しいコードは ２名で確認してから保管されます デベロッパーにはセキュリティバグを 取り込まないようライブラリが提供されます 社外では 脆弱性報奨金プログラムも実施しています Googleのインフラやアプリで バグを発見した方に報奨金を提供しています

# 予算と請求
想定外に多額のGCP請求を 回避する方法はあるでしょうか GCPにはそのためのツールが４つあります 予算とアラート、課金データエクスポート、 レポート、割り当てです まず 予算とアラートを見ていきましょう 予算は請求先アカウントごと またはGCPプロジェクトごとに定義できます 予算には上限を設けることも 別の指標を関連付けることもできます たとえば 前月の利用額の割合などです アラートを作成すれば 費用が予算上限に近づいたときに通知が届きます たとえば 予算上限を20,000ドルに設定し アラートを90％に設定すると 利用額が18,000ドルに達した時点で 通知アラートが届きます 通常 アラートは 50％、90％、100％に設定しますが カスタマイズも可能です 課金データエクスポートでは 詳細な課金情報を 分析用に取得しやすい場所に保管できます たとえばBigQueryデータセットや Cloud Storageバケットなどです

レポートはGCP Console内の ビジュアルツールです 利用額を監視できます 割り当ても実装しています これはアカウント所有者と GCPコミュニティ全体を保護する手段です エラーや悪意のある攻撃による リソースの過剰消費を防ぐことができます 割り当てには２種類あります 頻度に基づく割り当てと 数量に基づく割り当てです どちらもGCPプロジェクト単位で 適用されます 頻度に基づく割り当ては 一定期間後にリセットされます たとえば Kubernetes Engineの デフォルトの割り当ては GCPプロジェクトごとに 100秒あたり1,000回のAPI呼び出しです 100秒が経過すると制限がリセットされます 一方 数量に基づく割り当ては プロジェクトで使用できる リソースの数を制御します たとえばデフォルトでは 各GCPプロジェクトで使用できる VPCネットワークの最大数は５です すべてのプロジェクトには 同じ割り当てが設定されますが Google Cloudサポートに 割り当ての増加をリクエストできます

# Getting Started with GCP
GCPで実行するワークロードは プロジェクトを使って整理します Google Cloud Identity and Access Management（IAM）を使用して 誰が何をできるかをコントロールします 接続するインターフェースには 複数の選択肢があります このモジュールは こうした基礎知識を基に進めます プロジェクトはGCPで使用する リソースを整理する主な手段です これを使って共通のビジネス目標を 持つリソースをグループ化します 最小権限の原則はコンピューティング インフラを管理するうえで非常に重要です クラウドでもオンプレミスでも同じです これは 各ユーザーに 必要な権限だけを付与するという原則です 最小権限の環境では あらゆるエラーからユーザーを保護できます 私の同僚が実行中の本番環境データベースを 誤って削除したことがありました なぜなら本来は必要のない rootユーザーの権限を持っていたからです 彼は今でも申し訳なさを感じています GCPのお客様はIAMを使用して最小権限を実装し こうした誤りを防ぐことができます GCPの管理レイヤを操作するには ４つの方法があります ウェブベースのConsole、 SDKとコマンドラインツール、 API、モバイルアプリです このクラスでは主にConsoleと コマンドラインツールを使用します オンプレミスのインフラでアプリを構築する場合 スタック全体のセキュリティ管理が必要です ハードウェアとそれらを収容する場所の 物理的セキュリティから ディスク上のデータの暗号化 ネットワークの健全性 アプリに収めるコンテンツの セキュリティに至るまでの責任が生じます アプリをGCPに移行すると 下位層のセキュリティはGoogleが管理します Googleはその規模を活かして お客様が自社で運用するよりも 高度なセキュリティを提供することができます セキュリティスタックの上位層は 引き続きお客様の管理になります GoogleはIAMなどのツールを提供して お客様が上位層で任意のポリシーを 実装できるようにしています

# Google Cloud Platform リソース階層
GCPのリソース階層は下位層から見ていったほうが容易に理解できます。 
使用するリソースは VM、Cloud Storageバケット、 テーブル、BigQueryなど
すべてが プロジェクトに整理されます 加えてプロジェクトをフォルダに まとめることもできます。 
フォルダには他のフォルダも格納できます。
組織が使用する全フォルダとプロジェクトは 組織ノードの下にまとめられます。 
プロジェクト、フォルダ、組織ノードには まとめてポリシーを定義できます。
一部のGCPリソースでは 個別にポリシーを定義できます。
たとえばCloud Storageバケットです そちらについては後ほど詳しく見ていきます。
それまでは ポリシーは階層の下位に 継承されることを覚えておいてください。

すべてのGCPリソースは、１つのプロジェクトに属します。プロジェクトはGCPサービスを使用する際の基本単位です。
APIの管理、課金の有効化、 共同編集者の追加と削除などを行います。 
各プロジェクトは独立した区画であり、各リソースは 1 つの区画にのみ属します。
プロジェクトごとに異なるオーナーとユーザーを作成して個別に管理できます。
各GCPプロジェクトに名前とプロジェクトIDを割り当てます。プロジェクトIDは永続的かつ不変で、GCP全体で一意である必要があります。このIDをさまざまなコンテキストで使用して、GCPに作業対象のプロジェクトを指示します。一方、プロジェクトには 好きな名前を付けられます。 
各プロジェクトには固有のプロジェクト番号も割り当てられ、さまざまなコンテキストで表示されます。ただしこのコースではあまり使用しません。
プロジェクトIDは人が読める文字列にします。このIDはプロジェクトを示すために頻繁に使用することになります。 
プロジェクトはフォルダにまとめることができます。フォルダは作業を楽にするためのツールです。たとえばフォルダを使用して 組織内の各部門、チーム、アプリ、 環境を表すことができます。フォルダを使ってチームの管理権限を委任すれば、各チームが独立して対応できるようになります。
フォルダ内のリソースは、そのフォルダのIAMポリシーを継承します。たとえばプロジェクト３と４が同じチームによって管理される場合、フォルダBにIAMポリシーを適用します。その結果、プロジェクト３と４のそれぞれに同じポリシーを適用する手間もエラーの発生も抑えられます。
注意点があります。フォルダを使用するには階層の最上位に組織ノードが必要です。詳細はこれから説明します。 
社内の全プロジェクトは１つの構造にまとめることができます。ほとんどの企業では、リソースの使用状況の確認とポリシーの適用を一元的に行う必要があります。それを可能にするのが組織ノードです。 
組織ノードは階層の最上位階層であり、特別な役割を持っています。たとえば、組織ポリシー管理者を指定して、管理者だけがポリシーを変更できるようにします。プロジェクト作成者の役割も割り当てられます。 購入を行えるユーザを管理する効果的な方法です。
組織ノードはどのように作成するのでしょうか。会社がG Suiteを 利用しているかどうかによって異なります。 G Suiteドメインがある場合、GCPプロジェクトは自動的に組織ノードに属します。 そうでない場合は Google Cloud Identityを 使用して作成できます。新しい組織ノードを作成した時点では、ドメイン内の全員が引き続きプロジェクトと請求先アカウントを作成できます。これは混乱を避けるためです。 新しい組織ノードを作成したら、まずこれらの操作を許可するチームメンバーを決定しましょう。組織ノードを作成すれば、その下にフォルダを作成して、そこにプロジェクトを配置できます。
リソース整理の例を紹介します。３つのプロジェクトがあり、それぞれが複数のGCPサービスのリソースを使用するとします。この例ではフォルダを使用していませんが、プロジェクトはいつでもフォルダに移せます。リソースは親リソースからポリシーを継承します。たとえば組織レベルで設定したポリシーは、自動的にすべての子プロジェクトに継承されます。継承が遷移するということです。つまり、プロジェクト内のすべてのリソースがポリシーを継承します。
重要なルールが１つあります。階層の上位で実装されたポリシーが、それより下位で付与されたアクセス権限を削除することはできません。たとえばbookshelfプロジェクトのポリシーによって、ユーザーPatにCloud Storageバケットの変更権限が付与されているとします。しかし、組織レベルのポリシーでPatに許可されているのは、バケットの変更ではなく表示です。この場合、より制限の緩いポリシーが適用されます。ポリシーの設計ではこの点に注意してください。

# Identity and Access Management（IAM）
IAMを使えば特定のリソースへの操作権限をユーザーに付与できます。
IAMポリシーは「誰が」「何を」 「どのリソースに」対して行えるかを定義します。
[誰が]では対象とする １人以上のユーザーを指定します。その定義に使用できるのは Googleアカウント、Googleグループ サービスアカウント、G Suite全体 、 Cloud Identityドメインです。
[何を]はIAM役割で定義します。IAM役割とは権限の集合です。意味のある操作を行うには通常、複数の権限が必要です。 たとえばプロジェクト内のインスタンスを管理するには、インスタンスを作成、削除、 起動、停止、変更する必要があります。こうした権限を１つの役割にまとめれば、権限を管理しやすくなります。
[誰が]は Googleアカウント、Googleグループ サービスアカウント、G Suite全体、 Cloud Identityドメインのいずれかになります。
IAM役割には３種類あります。順に見ていきましょう。基本の役割は広範です。GCPプロジェクトに適用すると、そのプロジェクトの全リソースに適用されます。基本の役割には オーナー、編集者、閲覧者があります。
[閲覧者]はリソースを確認できますが、状態の変更はできません。
[編集者]は閲覧者の権限に加えて、リソースの状態を変更できます。
[オーナー]は編集者の権限に加えて、リソースの役割と権限を管理できます。プロジェクトのオーナーにはもう１つの権限があります。支払い / 請求の設定です。通常、請求管理の担当者には プロジェクトリソースの変更権限は与えません。そのために課金管理者の役割を付与できます。
機密データが含まれるプロジェクトに複数のメンバーが取り組む場合は注意が必要です。基本の役割では広範すぎるかもしれません。GCP IAMにはよりきめ細かい役割もあります。
各GCPサービスには 独自の[定義済みの役割]があり、役割を適用できる対象が定義されています。たとえば、後ほど取り上げる Compute Engineでは 仮想マシンをサービスとして提供しており、複数の定義済み役割が用意されています。それらは特定のプロジェクト、特定のフォルダ、 組織全体のCompute Engineリソースに適用できます。マネージドデータベースサービスの Cloud Bigtableも見てみましょう。Cloud Bigtableが提供する役割は、組織全体、特定プロジェクト、さらに個々のBigtableデータベース インスタンスにも適用できます。

# IAM 役割
Compute Engineの InstanceAdmin役割を持つユーザーは、VMに対して特定の操作を行うことができます。たとえば、VMの一覧表示、 構成の読み取りと変更、VMの起動と停止です。操作対象のVMは役割の適用先によって決まります。ここでは特定のGoogleグループのユーザー全員がこの役割を持っています。この役割はproject_aの全VMに適用されます。さらにきめ細かい役割が必要な場合は、カスタムの役割があります。多くの会社では最小権限のモデルを使って各メンバーに必要最小限の権限のみを付与しています。たとえば、InstanceOperator役割を定義して、特定のユーザーにCompute EngineとVMの起動と停止を許可し、再構成は許可しないとします。カスタムの役割を使えばこれを実現できます。ただし注意点があります。
第一に、[カスタムの役割]を使うことを明確に決める必要があります。権限の管理が必要になるからです。会社によっては 事前定義済みの役割を選択しています。
第二に、カスタムの役割を使用できるのは[プロジェクトまたは組織レベル]のみです。フォルダレベルでは使用できません。 権限を付与する対象がユーザーではなく、Compute Engine VMだとしたら？ その場合はサービスアカウントを使用します。たとえばVMで実行しているアプリのデータを Google Cloud Storageに保管するとします。そのデータへのアクセスは、インターネット上の全員に許可するのではなくVMだけに許可します。そこで、Cloud Storageに対してVMを認証するためのサービスアカウントを作成します。サービスアカウントの名前はメールアドレスにします。ただし、パスワードではなく暗号鍵でリソースにアクセスします。こちらの例では、サービスアカウントにCompute EngineのInstanceAdmin役割が付与されています。VMで実行中のアプリはこのアカウントを使って他のVMを作成、変更、削除できます。また、サービスアカウントの管理も必要です。たとえば Aliceが特定のサービスアカウントで実行可能な操作を管理するとします。一方、Bobは表示さえできれば十分です。サービスアカウントはIDであると同時にリソースでもあるため。IAMポリシーをそれ自体に適用できます。サービスアカウントでAliceには編集者の役割を、Bobには閲覧者の役割を付与できます。他のGCPリソースの役割を付与する場合と同じです。プロジェクト内のVMのグループごとに異なるIDを付与できます。その結果、グループごとに異なる権限を管理しやすくなります。また、VMを再作成しなくてもサービスアカウントの権限を変更できます。さらに複雑な例を紹介します。Compute Engineの複数のVMにまたがって、実装されたアプリがあるとします。あるアプリコンポーネントには、別のプロジェクトでの編集者役割が必要ですが、他のコンポーネントには不要です。そこで２つのサービスアカウントを作成します。VMのサブグループごとに１つ作成します。最初のサービスアカウントにだけ、別のプロジェクトでの権限を与えます。これでアプリのコードが誤っていたり、VMが感染したりしたとしてもその影響を軽減できます。

# GCPの操作
GCPの４つの操作方法を 順に説明していきます GCP Console、SDKとCloud Shelll、 モバイルアプリ、APIの4つです Consoleはウェブベースの 管理インターフェースです GCPでアプリを作成するときに使用します アプリのエンドユーザーは使用しません Consoleではすべてのプロジェクトと 使用するリソースを確認、管理できます GCPサービスのAPIの 有効化、無効化、確認も可能です Cloud Shellにもアクセスできます Cloud ShellはGCPの コマンドラインインターフェースで ブラウザで簡単に使用できます Cloud Shellでは Google Cloudソフトウェア開発キット（SDK） に含まれるツールを使用できます インストールは不要です ソフトウェア開発キットについて説明します Google Cloud SDKは GCPでリソースとアプリを 管理するためのツールの一式です SDKに含まれるgcloudツールは GCPのプロダクトとサービスのメインの コマンドラインインターフェースです Cloud Storage用のgsutilと BigQuery用のbq（BigQuery）も含まれています SDKコマンドにアクセスするには ConsoleのCloud Shellボタンを クリックするのが簡単です SDKコマンドがすでにインストールされた VM上のウェブブラウザに コマンドラインが表示されます SDKを自分のマシンに インストールすることもできます ノートパソコンでもオンプレミスサーバーでも 他のクラウドのVMでもかまいません SDKはDockerイメージとしても提供されており システムを非常に簡単に扱うことができます GCPを構成するサービスには APIが用意されています コードでAPIをコントロールできます こうしたAPIは RESTfulと呼ばれます つまり Representational State Transfer パラダイムに従っています 詳細はここでは説明しませんが ウェブブラウザがウェブサーバーと 通信するのと同様の方法で Googleサービスをコードで使用できます APIではリソースとGCPをURLで指名します コードでAPIに情報を渡すには JSONを使用します テキスト形式の情報をウェブで 渡すためによく使われる形式です ユーザーログインとアクセスコントロール のためのオープンシステムも存在します GCP Consoleでは APIを有効または無効にできます 多くはデフォルトで無効にされています 割り当てと制限も適用されます こうした制限によって リソースの誤使用を防ぐことができます 必要なAPIだけを有効にして リソースが追加で必要になったら 割り当ての増加をリクエストできます たとえば GCPリソースをコントロール する必要があるアプリを作成するには APIを適切に使用する必要があります そこでAPI Explorerを利用します GCP Consoleに含まれる API Explorerというツールでは APIについてインタラクティブに 調べることができます 使用可能なAPIとバージョンを確認できます APIが要求するパラメータに関する ドキュメントも組み込まれています インタラクティブにAPIを試すことができ ユーザー認証も使えます たとえば APIを調べて そのAPIを使用する アプリの作成を始めるとします ゼロからコードを作成する必要はありません Googleのクライアントライブラリを使えば コードからGCPを呼び出す 面倒な作業を大幅に軽減できます ライブラリには２種類あります Cloudクライアントライブラリは Google CloudのAPIに推奨される 最新のライブラリです 各言語のネイティブスタイルと イディオムを採用しています ただし 最新のサービスと機能を サポートしていない場合もあります その場合は 使用する言語に対応する Google APIクライアントライブラリを使用します こうしたライブラリは普遍性と完全性を 重視して設計されています 最後に 開発者だけでなくすべてのユーザーに 役に立つツールがもう１つあります GCPで使用しているリソースを調べて管理できる AndroidとiOS向けのモバイルアプリです ダッシュボードを構築して 必要な情報をひと目で確認できます


# Compute Engineについて
クラウドでワークロードを実行する方法としては VMがよく知られています Compute EngineではVMを Googleのグローバルインフラで実行できます このモジュールでは Compute Engineの仕組みについて 仮想ネットワーキングを中心に説明します VMの利点の１つは 本格的なOSの処理能力と普遍性を 備えていることです VMは物理サーバーと同じように構成できます CPU処理能力、メモリ量、 ストレージの容量とタイプ、OSを指定できます VMは柔軟に再構成できます さらにGoogle Cloudで稼働するVMには 比類ないネットワーク接続性があります

# Virtual Private Cloud（VPC）ネットワーク
多くのユーザーはGCPを使い始める際に、最初のプロジェクトに独自の Virtual Private Cloud（VPC）を定義するか、デフォルトのVPCを選んで使い始めます。いずれにしてもVPCネットワークがGCPリソースの相互接続と、インターネットとの接続を可能にします。
ネットワークをセグメント化し、ファイアウォールルールでインスタンスへのアクセスを制限できます。 
静的ルートを作成すればトラフィックを特定の宛先に転送できます。
GCPを初めて使う多くの方が驚くことは、定義するVPCネットワークが[グローバルスコープ]を持つということです。世界中のどのGCPリージョンにもサブネットを持てます。サブネットはリージョン内の複数ゾーンをまたぐことも可能です。 
このアーキテクチャにより、グローバルスコープのネットワークレイアウトを簡単に定義できます。同じサブネットで複数ゾーンにリソースを配置することもできます。カスタムネットワーク内のサブネットのサイズは動的に拡大できます。割り当てるIP範囲を拡大するだけです。構成済みのVMに影響はありません。この例のVPCには１つのネットワークがあります。１つのサブネットが GCP us-east1リージョンに定義されています。接続されている Compute Engine VMは２つです。これらは同じサブネットで隣り合っていますが、異なるゾーン内にあります。この機能を使用すれば、単純なネットワークレイアウトながらも、復元性の高いソリューションを作成できます。

# Compute Engine
Compute EngineではVMを作成してGoogleのインフラで実行できます。先行投資は要りません。高速で一貫したパフォーマンスのシステムで数千もの仮想CPUを実行できます。
VMインスタンスを作成するには GCP Console、または gcloudコマンドラインツールを使います。VMで実行できるLinuxまたは Windows Serverイメージには Google提供のものと カスタマイズバージョンがあります。物理サーバーからイメージを インポートすることも可能です。
VMを作成するときにマシンタイプを選びます。タイプによってメモリ量と仮想CPUの数が決まります。タイプにはごく小さなものから非常に大きなものまであります。
事前定義済みのタイプで要件を満たせない場合は、[カスタムVM]を作成できます。処理能力については機械学習やデータ処理など、GPUを利用できるワークロード向けにGCPの多くのゾーンでは GPUを利用できます。
物理的なマシンと同じように VMにもディスクが必要です。永続ストレージは２種類から選択できます。[標準とSSD]です。 アプリに高パフォーマンスの一時的領域が必要な場合は、[ローカルSSD]を接続できます。ただし永続的な価値のあるデータは、別の場所に保管してください。ローカルSSDのコンテンツは[VMが終了すると消去される]からです。したがって、もう１種類は永続ディスクです。ほとんどのユーザーは初めはデフォルトの標準永続ディスクを使用します。ブートイメージも選べます。さまざまなバージョンの LinuxとWindowsが用意されています。独自のイメージもインポートできます。VMが常に特定の構成で起動すると便利です。起動時にソフトウェアパッケージをインストールするなどです。これを行うには GCP VM[起動スクリプト]を渡すのが一般的です。他の種類のメタデータを渡すこともできます。
VMが稼動したら、簡単にディスクのスナップショットを取れます。バックアップとして保管したり、別のリージョンへのVMの移行時に使用したりできます。完了するまで人が介入しないワークロードがあるとします。大規模なデータセットを分析するバッチジョブなどです。
[プリエンブティブルVM]でジョブを実行すると、費用を節約できます。プリエンプティブルVMには通常の Compute Engine VMと異なる点が１つあります。他でリソースが必要になった場合に Compute Engineがそれを[終了できる]という点です。 プリエンプティブルVMでは 費用を大幅に節約できますが 停止と再開が可能なジョブに使用してください。
インスタンスに応じた適切なマシンは、仮想CPUの数やメモリ量を基に選択できます。事前定義済みマシンタイプを使用することも、カスタムマシンタイプを作成することもできます。前述のとおり、Compute EngineではVMをかなり大きなサイズにできます。この動画を録画している時点では VMの仮想CPUの最大数は96です。ベータ版での最大メモリサイズは624GBです。最新情報は、GCPウェブサイトでご確認ください。大規模なVMはインメモリデータベースや 分析などのワークロードに役立ちます。しかし、GCPの大半のお客様は最初にスケールアップではなく、スケールアウトを行います。Compute Engineの自動スケーリング機能を使用すると、負荷の指標に基づいてアプリのVM数を増減できます。この仕組みの一環として、着信トラフィックの負荷がVM間で分散されます。Google VPCは何種類かの負荷分散をサポートしています。負荷分散については次のセクションで説明します。

# VPC の重要な機能
物理ネットワークと同じく VPCでもルーティングテーブルを使用します 同じネットワーク内のインスタンス間で トラフィックを転送するためです サブネット間やGCPゾーン間でも 外部IPアドレスを使用せずに転送できます VPCルーティングテーブルは 組み込まれているので プロビジョニングや管理は不要です ファイアウォールインスタンスの プロビジョニングと管理も不要です VPCのグローバルな 分散型ファイアウォールを使用して インスタンスへの 送受信トラフィックを制限できます ファイアウォールル―ルの定義では インスタンスのメタデータタグを使用できます これは非常に便利です たとえばすべてのウェブサーバーに 「web」というタグを付けるとします ファイアウォールルールで ポート80または443での受信トラフィックを 「web」タグが付いたVMに許可します IPアドレスは何であろうと関係ありません 前に説明したように VPCはGCPプロジェクトに属します 複数のGCPプロジェクトがあり VPC間の通信が必要な場合はどうなるでしょう 心配いりません このような通信も可能です 単に２つのVPC間にピアリング関係を確立して トラフィックを交換可能にする場合 VPCピアリングを使用できます 一方 IAMを機能を最大限に利用して 別のプロジェクトのVPCに対して 誰が何の操作を行えるか制御するには 共有VPCを使用できます いくつか前のスライドで 負荷の変化に応じてVMが 自動スケーリングする仕組みを説明しました その時々でアプリを提供する VMの数が変わる場合 ユーザーはどのようにアプリに アクセスするのでしょうか その答えはCloud Load Balancingです これはソフトウェアで定義された 完全分散型のマネージドサービスです ロードバランサは 管理対象のVM内で実行されないため スケーリングも管理も不要です Cloud Load Balancingはすべての トラフィックに対応しています これにはHTTPとHTTPS、 その他のTCPとSSLトラフィック、 UDPトラフィックも含まれます Cloud Load Balancingでは １つのエニーキャストIPが 世界中のリージョンのバックエンド インスタンスのフロントエンドとなります 負荷はリージョン間で分散されます さらに自動マルチリージョン フェイルオーバーにより バックエンドの不調時には トラフィックを分割して移動します Cloud Load Balancingは ユーザー、トラフィック、バックエンドの状態、 ネットワーク条件などの変化に瞬時に対応します たとえばオンラインゲームが大ヒットするなど 需要の急増が見込まれるとします サポートチケットでGoogleに 負荷の急増を予告する必要があるでしょうか いいえ いわゆる事前警告は不要です ウェブアプリの負荷を リージョン間で分散する場合は HTTPS負荷分散を使用します HTTP以外のSSLトラフィックには グローバルSSLプロキシロードバランサを 使用します SSLを使用しないTCPトラフィックであれば グローバルTCPプロキシロードバランサを 使用します この２種類のプロキシサービスは 特定のポート番号とTCPでのみ機能します UDPトラフィックや任意のポート番号の トラフィックを負荷分散する場合は リージョンロードバランサで リージョン全体に負荷を分散できます これらすべてのサービスの共通点は インターネットから送信されるトラフィックを 対象としていることです プロジェクト内での トラフィックの負荷分散はどうでしょう アプリのプレゼンテーション層と ビジネスロジック層の間での負荷分散などです その場合は内部ロードバランサを使用します GCP内部IPアドレスでの受信トラフィックの 負荷をCompute Engine VM間に分散します よく知られている Googleの無料サービスの１つに 公開ドメインネームサービスを 世界に提供する8.8.8.8があります DNSはインターネットホスト名を アドレスに変換します お察しのとおり Googleには高度なDNSインフラがあります これにより8.8.8.8を 誰もが利用できるようになっています GCPで作成するアプリのインターネット ホスト名とアドレスについてはどうでしょう 世界中でアプリが見つかるように GCPではCloud DNSを提供しています これはGoogleと同じインフラで 実行されるマネージドDNSサービスです 低レイテンシと高可用性を実現し 費用効率の高い方法で アプリとサービスをユーザーに提供できます DNS情報を公開すると その情報は 全世界のあらゆる場所から配信されます Cloud DNSはプログラムも可能です 数百万ものDNSゾーンとレコードを 公開して管理するには GCP Console、コマンドライン インターフェース、APIを使用できます Googleにはグローバルな エッジキャッシュシステムがあります このシステムを使ってアプリの コンテンツ配信を加速化するには Google Cloud CDNを使用します ユーザーは低レイテンシを実感するでしょう コンテンツの発信元の負荷が減り 費用も節約できまます HTTPS負荷分散を設定した後に チェックボックスをオンにするだけで Cloud CDNを有効にできます 当然 CDNは他にもたくさん存在します すでにCDNを使用している場合 GCPのCDN Interconnectパートナー プログラムの対象である可能性があります その場合はそのまま使用できます GCPのお客様の多くはGoogle VPCと 他のネットワークの相互接続を必要とします オンプレミスネットワークや他の クラウド内のネットワークなどです 選択肢はたくさんあります 多くのお客様は 仮想プライベートネットワークを IPSECプロトコルを使用して インターネットで接続します さらに 動的な接続にするために Cloud RouterというGCP機能を使用します この機能を使用すると 他のネットワークとGoogle VPCの間で BGPを使って VPN経由でルート情報を交換できます たとえば 新しいサブネットを Google VPCに追加すると オンプレミスネットワークが自動的に そのルートを取得します インターネットを使用したくないお客様もいます セキュリティの懸念がある場合や 信頼性の高い帯域幅が必要な場合などです その場合はGoogleとの ダイレクトピアリングを検討できます ピアリングとはルーターを Google POPと同じデータセンターに配置して トラフィックを交換することです Googleは世界中に 100を超えるPOPを設けています POPでまだ接続を確立していない場合は キャリアピアリングプログラムの パートナーに接続を依頼できます ピアリングには欠点が１つあります それはGoogleのSLAの対象ではないことです Googleとの相互接続で 高い稼働率が必要な場合は Dedicated Interconnectを使用してください Googleとの１つ以上の 直接プライベート接続を確立できます 接続形態がGoogleの仕様を満たす場合 その接続は最大で 稼働率99.99％のSLAの対象になります VPNで接続をバックアップすれば 信頼性はさらに高くなります

# Google Cloud Platform のストレージ オプションの概要
すべてのアプリには データ ストレージが必要です ストリーミング メディアや センサーデータ、口座の残高、 私のポケモンの 2,600強のCPデータなどの保管場所です アプリとワークロードによって 必要なストレージデータベース ソリューションは異なります ご存知のとおり データはVMの永続ディスクに保管できます GCPには他のストレージオプションもあり 構造化、非構造化、トランザクション、 リレーショナルデータに応じて選べます このモジュールで取り上げる ストレージオプションは Cloud Storage、Cloud SQL、 Cloud Spanner、Cloud Data Store、 Google Bigtableです アプリに応じて １つまたは複数の ストレージサービスを使用します

# Cloud Storage
まずCloud Storageについて説明しましょう。
オブジェクトストレージとは何でしょう。フォルダの階層としてデータを管理するファイルストレージとは異なります。OSがデータをディスクの塊として、管理するブロックストレージとも異なります。オブジェクトストレージとは、データを保管するとその一連のバイトが[オブジェクト]として扱われ、固有のキーでデータをアドレス指定できるストレージを意味します。それだけです。通常、これらの固有のキーは[URL形式]です。つまり、ウェブテクノロジーとの相性が良いストレージです。Cloud Storageの仕組みもまったく同じですが、さらに利点があります。これはスケーラブルなフルマネージドサービスです。つまり、容量の事前プロビジョニングは不要です。オブジェクトを作成するだけで、耐久性と可用性に優れたデータ保存が可能になります。
Cloud Storageはさまざまな目的で使用できます。ウェブサイトコンテンツの配信やアーカイブ・復旧用データの保管、ユーザーの直接ダウンロードによる大容量データの配布などです。Cloud Storageはファイルシステムではありません。格納されているオブジェクトごとにURLがあるからです。各オブジェクトは多くの点で、ファイルのようなものなのでオブジェクトを「ファイル」という言葉で説明しても構いませんが、正確にはファイルシステムとは違います。Linuxマシンのルートファイルシステムとして、Cloud Storageを使うことはありません。
Cloud Storageはバケットで構成されます。ユーザーがバケットを作成して構成し、そこにオブジェクトを格納します。ストレージオブジェクトは不変です。つまり、インプレースで編集するのではなく[新しいバージョン]を作成します。
Cloud Storageは必ずサーバー側で[データを暗号化]してからディスクに書き込みます。暗号化の追加料金はありません。また、デフォルトでは[転送中のデータがHTTPSで暗号化]されます。
データ転送については、大量のデータをCloud Storageに保存できる便利なサービスもあります。この後のモジュールで改めて説明します。Cloud Storageに格納されたデータは、他のGCPストレージサービスに移動できます。すでに述べたとおり、Cloud Storageのファイルはバケットに整理されます。バケットの作成時に[グローバルに一意の名前]を付けます。バケットとそのコンテンツを保管する地理的ロケーションを指定し、デフォルトのストレージクラスを選択します。ユーザーにとってレイテンシが最小になる ロケーションを選んでください。大半のユーザーがヨーロッパにいる場合は、ヨーロッパのロケーションを選択します。
オブジェクトとバケットへのユーザーアクセスを制御する方法はいくつかあります 通常はCloud IAMで十分です。役割はプロジェクトから バケット、オブジェクトへと継承されます。よりきめ細かい制御が必要な場合は アクセス制御リスト（ACL）を作成します。[ACL]で定義するのはバケットとオブジェクトにアクセスできるユーザーとユーザーのアクセスレベルです。各ACLは２つの情報で構成されます。１つは指定の操作を実行できるユーザーを定義する「スコープ」で、たとえば特定のユーザーやユーザーグループを定義します。もう１つは実行できる操作を定義する「権限」です。読み取り権限や書き込み権限などです。先ほど述べたように Cloud Storageオブジェクトは不変です。必要であればバケットでオブジェクトの[バージョニングを有効]にできます。その場合、 Cloud Storageは 変更履歴を保持します。つまり、バケット内の全オブジェクトを上書きまたは削除します。オブジェクトのアーカイブバージョンを一覧表示して、オブジェクトを前の状態に復元したり、完全にバージョンを削除したりできます。オブジェクトバージョニングを有効にしていない場合は、新しいオブジェクトが常に古いオブジェクトを上書きします。バージョニングは便利ですが、ゴミが溜まるのが心配であれば、Cloud Storageの ライフサイクル管理ポリシーを使用するといいでしょう。たとえば Cloud Storageに365日を経過したオブジェクトを削除するように指示できます。2013年１月１日より前に作成されたものを削除するという形でも指示できます。バージョニングが有効なバケットでは、直近の３つのバージョンだけを残すことも可能です。

# Cloud Storage の操作
Cloud Storageではストレージクラスを ４つの中から選択できます Regional、Multi-Regional、 Nearline、Coldlineです Multi-RegionalとRegionalは 高パフォーマンスのオブジェクトストレージです 一方 NearlineとColdlineは バックアップとアーカイブ用のストレージです よって２つのグループの間に 太い境界線を引きました いずれのストレージクラスにも Cloud Storage APIで同じようにアクセスでき すべてミリ秒単位でアクセス時間が計測されます では違いを見ていきましょう Regionalでは 特定のGCPリージョンにデータを保管できます us-central1、europe-west1、 asia-east1のいずれかです Multi-Regionalより安価ですが 冗長性は低くなります 一方 Multi-Regionalでは 料金は高くなりますが 地理的冗長性が確保されます 米国、EU、アジアなどの大まかな 地理的ロケーションを選ぶと Cloud Storageが160km以上離れた２か所の 地理的ロケーションにデータを保管します Multi-Regionalが適しているのは 頻繁にアクセスするデータです たとえば ウェブサイトのコンテンツや インタラクティブなワークロード モバイルアプリやゲームアプリの データなどです Regionalが適しているのは Compute Engine、VM、Kubernetes Engine クラスタの近くにデータを保管する場合です データ集約型の計算パフォーマンスが 向上するためです Nearlineは安価で 耐久性に優れたサービスです アクセス頻度が低い データの保管に適しています このストレージクラスが Multi-RegionalやRegionalよりも適しているのは データの読み取りや変更を行うのが 平均で月に１回以下の場合です たとえばCloud Storageに 継続的にファイルを追加して 月に１度の分析に使用する場合は Nearlineが最適です Coldlineは非常に安価な 耐久性に優れたサービスで データアーカイブ、オンラインバックアップ、 障害復旧に適しています Coldlineは年に１度程度しか アクセスしないデータの保管に最適です なぜなら可用性が若干低く 90日の最小保存期間があるからです データアクセスに費用がかかり １オペレーションあたりの費用も高めです たとえば データのアーカイブや 障害復旧での使用に適しています 可用性はストレージクラスによって異なります 最も高いのは可用性99.95％の Multi-Regionalです 次は可用性99.9％のRegionalです NearlineとColdlineの可用性は99％です 料金については すべてのクラスで１か月あたりの データ保存量に対しGB単位で料金が発生します 料金が最も高いのは Multi-Regionalで 最も低いのはColdlineです 下りトラフィックと データ転送の料金がかかることもあります これらの料金に加えて Nearlineではデータ読み取りにも GB単位の料金が発生します ColdlineではGB単位の データ読み取り料金はさらに高くなります どのストレージクラスでも 複数の方法でデータを Cloud Storageに取り込めます 多くのお客様は gsutil を使用しています これはCloud SDKに含まれる Cloud Storageコマンドです Chromeブラウザを使用していれば GCP Consoleでドラッグ＆ドロップでの データ移動も可能です テラバイトからペタバイト規模の データをアップロードする場合は GCPのオンラインStorage Transfer Serviceと オフラインTransfer Applianceを利用できます Storage Transfer Serviceでは 別のクラウドプロバイダ、別のリージョン、 HTTPSエンドポイントから Cloud Storageへの一括転送を スケジュールして管理できます Transfer Applianceはラックマウント型の 大容量ストレージ サーバーで Google Cloudからリースできます ネットワークに接続してデータを読み込んでから アップロード施設に配送するだけで データがCloud Storageにアップロードされます このサービスを使えば１台の機器で 最大１ペタバイトのデータを安全に転送できます 現時点ではまだベータ版で 使用できる場所は限られていますので 詳細についてはウェブサイトをご覧ください Cloud Storageに データを格納する方法は他にもあります このストレージはGCPの多数のプロダクトと サービスと密接に統合されているためです たとえば BigQueryとCloud SQLとの間で テーブルをインポート、エクスポートできます App Engineのログや Cloud Datastoreのバックアップ App Engineで使用するイメージなどの オブジェクトも保管できます 他にもインスタンスの起動スクリプトや Compute Engineイメージ Compute Engineアプリの オブジェクトなども保管できます つまりCloud Storageはクラウドへの データ取り込みポイントになり データを長期間保存する場所としても 頻繁に使用されています

# Google Cloud Bigtable
Cloud Bigtableはビッグデータ用の NoSQLデータベースサービスです [NoSQL]とは何でしょう もちろんデータベースではありません 簡単に概要を説明します まずリレーショナルデータベースは 各行に一連の同じ列があるテーブルの 集合だと考えてください このルールと各テーブルに指定したルールを データベースエンジンが適用します これはデータベーススキーマと呼ばれます スキーマが大きな助けになるアプリもあれば 大きな障害になるアプリもあります 一部のアプリではもっと柔軟な手法が必要です たとえば NoSQLスキーマです こうしたアプリでは すべての行に同じ列がある必要はありません データベースによってはこれを活かすために データを低密度で行に取り込みます これはNoSQLデータベースの特徴の１つです Bigtableにもこの特徴があります Bigtableは低密度に格納されるテーブルで 数十億行、数千列にスケールして 数ペタバイトのデータを保管できます GCPのフルマネージドサービスなので 構成や調整は不要です Bigtableが適しているのは 単一の参照キーを持つデータです 一部のアプリ開発者はBigtableを 永続ハッチテーブルとみなしています Bigtableは極めて低いレイテンシで 大容量データを格納するのに最適です 高スループットの読み書きに対応するため 運用アプリと分析アプリの両方に理想的です たとえば IoT、ユーザー分析、 財務データ分析などです Cloud Bigtableは HBaseと同じ オープンソースAPIを介して提供されます HBaseはApache Hadoopプロジェクトの ネイティブデータベースです [Hadoop]については 別途説明します 同じAPIを使用するということは HBaseとBigtableの間で アプリを移植できるということです 独自のApache HBaseインストール環境を 管理している場合 なぜBigtableを選択するのか 疑問に思うかもしれません その理由をいくつか説明します まず スケーラビリティです 独自のHbaseインストール環境では ある時点で１秒あたりのクエリ数を スケールするのが難しくなります Bigtableではマシンの数を 増やすだけでスケールできます ダウンタイムも必要ありません また Bigtableはアップグレードや 再起動などの管理タスクを透過的に処理します Bigtable内のデータはすべて 処理中にも保存時にも暗号化されます IAM権限を使用してBigtableデータに アクセスできるユーザーも制御できます 最後にもう１点お伝えします Bigtableは Googleの多くのコアサービスを 支えるデータベースです Google検索、アナリティクス、 マップ、Gmailなどのサービスです Cloud Bigtableは GCPエコシステムの一部であるため 他のGCPサービスや サードパーティクライアントと連携できます アプリのAPIの観点から見ると Cloud Bigtableでのデータの読み書きは データサービス層で行えます つまりマネージドVMや HBase RESTサーバー HBaseクライアントを使用する Javaサーバーなどで行えます 通常は ここでアプリ、ダッシュボード、 データサービスにデータが提供されます 各種のストリーム処理フレームワークで データをストリーミングすることも可能です Cloud Dataflow Streaming、 Spark Streaming、Stormなどを使えます ストリーミングできない場合は Hadoop Map/Reduce、Dataflow、Sparkで データの読み書きを一括処理できます 通常は 集約データおよび 新しく計算されたデータが Cloud Bigtableまたは 下流のデータベースに書き込まれます

# Google Cloud SQL と Google Cloud Spanner
NoSQLデータベースについて説明しました。次はリレーショナルデータベース サービスに目を向けましょう。
これらのサービスは、データベーススキーマを使用してアプリのデータの一貫性と正確性を保ちます。これらのサービスのもう１つの特徴は、トランザクションに役立つことです。
データベースの一連の変更をアプリで、オールオアナッシングとして指定できます。変更はすべて成功かすべて失敗のどちらかです。
データベーストランザクションがなければ、オンラインバンクで預金を口座間で移動できません。たとえば、ある口座から １万ドルを引き出したのに、なんらかの不具合で振替先口座に預金が移動できなかったとしましょう。銀行が１万ドルを誤って移動したからかもしれません。
リレーショナルデータベースの設定、保守、管理には手間がかかります。これらの作業に時間を取られたくないが、リレーショナルデータベースによる保護は必要という場合は[CloudSQL]を検討してください。 このフルマネージドサービスでは、MySQLまたはPostgreSQLの データベースエンジンを選択できます。
Cloud SQLのMySQLと PostgreSQLのデータベースはどちらも テラバイト規模のデータを処理できます。現時点では、Cloud SQL for PostgreSQLはベータ版ですのでウェブサイトで最新の状況をご確認ください。もちろん Compute Engine VM内で 独自のデータベースサーバーを実行できます。GCPの多くのお客様がそうしています。一方でCloud SQLマネージドサービスにはいくつかの利点があります。 
まず、Cloud SQLは [複数のレプリカサービス]を提供します リード、フェイルオーバー、 外部レプリカなどです。
あるゾーンが停止状態になっても Cloud SQLの自動フェイルオーバーによって ゾーン間でデータをレプリケートできます。 オンデマンドまたはスケジュール設定した、バックアップでデータをバックアップできます。マシンタイプの変更による垂直スケーリングとリードレプリカによる水平スケーリングも可能です。
セキュリティについては、Cloud SQLインスタンスにはネットワークファイアウォールがあり、顧客データは Googleの内部ネットワーク上でも データベーステーブル、一時ファイル、 バックアップ内でも暗号化されます。
Cloud SQLインスタンスのもう１つの利点は、他のGCPサービスや外部サービスからアクセスできることです。
Compute Engineインスタンスに Cloud SQLインスタンスへのアクセスを許可して、VMと同じゾーン内で Cloud SQLインスタンスを構成できます。 Cloud SQLはSQL WorkBenchや Toadなどのアプリやツールに加え、標準のMySQLドライバを使った 外部アプリにも対応しています。水平スケーリングが必要なため、Cloud SQLで対応できない場合は[CloudSpanner]を検討してください。 [グローバル規模]のトランザクション整合性、 スキーマ、SQLを提供し、自動同期レプリケーションで 高可用性を実現します。[ペタバイト規模]の容量も提供できます。 Cloud Spannerを検討するのは、リレーショナルデータベースの 容量を超えた場合、高スループットを得るために シャーディングする場合、トランザクションの整合性、 グローバルデータ、強整合性が必要な場合、データベースを強化する場合などです。金融アプリや在庫管理アプリなどのユースケースに適しています。

# Google Cloud Datastore
GCP NoSQLデータベースの１つ Cloud Bigtableについて説明しましたが スケーラビリティの高い NoSQLデータベースは他にもあります Cloud Datastoreです これは主に App Engineアプリの 構造化データの格納に使用されます また App EngineとCompute Engineをまたぐ ソリューションを構築する際に Cloud Datastoreを統合ポイントにできます フルマネージドサービスなので シャーディングと レプリケーションは自動処理されます 高可用性と耐久性を兼ね備えているため 自動でスケールして負荷に対処します Cloud Bigtableとは異なり 複数のデータベース行を対象とした トランザクションも実行できます SQLのようなクエリも可能です Cloud Datastoreには １日の無料割り当てがあるので 保存、読み取り、書き込み、削除などの 小規模オペレーションを無料で行えます

# ストレージ オプションの比較
GCPの主な ストレージオプションを説明したので アプリやワークフローに適切なものを 選択できるように比較してみましょう この表は各サービスの 技術的な違いを示しています 各行が技術仕様、各列がサービスです 左から順に各サービスを説明します Cloud Datastoreを検討するのは 非構造化オブジェクトを格納する場合 またはトランザクションとSQLに似た クエリのサポートが必要な場合です このサービスは テラバイト規模の容量を提供します 最大ユニットサイズは エンティティあたり１MBです Cloud Bigtableを検討するのは 大量の構造化オブジェクトを格納する場合です Cloud BigtableはSQLクエリも 複数行のトランザクションもサポートしません このサービスは ペタバイト規模の容量を提供します 最大ユニットサイズは セルあたり10MB、行あたり100MBです Cloud Storageを検討するのは 大きな画像や映画などの 10MGを超える不変blobを格納する場合です このサービスは ペタバイト規模の容量を提供します 最大ユニットサイズは オブジェクトあたり５TBです Cloud SQLまたはCloud Spannerを 検討するのは オンライントランザクション処理システムで 完全SQLサポートが必要な場合です 容量については Cloud SQLはテラバイト規模 Cloud Spannerはペタバイト規模です Cloud SQLのリードレプリカで対応できない 水平スケーリングが必要な場合は Cloud Spannerの使用を検討してください BigQueryを取り上げていないのは データストレージとデータ処理の 境界にあるためですが 「Big Data and Machine Learning in the Cloud」モジュールで詳細を学べます 通常 BigQueryにデータを格納する目的は ビッグデータ分析とインタラクティブな クエリや機能を使用するためです BigQueryは オンラインアプリの バックアップ保存先などには適しません

各ストレージサービスの 技術的な違いを確認すると どのサービスを選択すべきか 判断するのに役立ちます ユースケースも判断材料になります 各サービスをもう一度見ていきましょう Cloud Datastoreは 半構造化データの格納に最適です つまり App Engineアプリで 使用するデータです Bigtableは 読み書きの多い 分析データの格納に最適です AdTech、金融、IoTのデータなどです Cloud Storageは構造化、非構造化、 バイナリ、オブジェクトデータに最適です 画像、大きなメディアファイル、 バックアップなどです SQLはウェブフレームワークと 既存アプリでの使用に最適です ユーザー認証情報や顧客の注文を 格納する場合などです Cloud Spannerは２TBを超える 大規模なデータベースアプリに最適です 金融取引やeコマースの ユースケースなどに適しています このモジュールの冒頭で述べたように これらのサービスは アプリに応じて複数使用できます

# コンテナ、Kubernetes、Kubernetes Engine
このモジュールでは、ソフトウェアコンテナの概要と Google Kubernetes Engineで 実行する方法を学習します。
Compute Engineについては すでに説明しました GCPのIaaSサービスです。クラウドでVMを実行して、永続ストレージとネットワーキングを使用します。App EngineはGCPのPaaSサービスです。
ここで紹介するのは [KubernetesEngine]というサービスです。インフラの面倒な作業を省けるという点では、IaaSサービスと似ています。PaaSサービスにも似ています。デベロッパーのニーズを念頭に構築されているからです。
最初に、コンテナというソフトウェアをパッケージ化する方法を説明します。コンテナが便利な理由と Kubernetes Engineで コンテナを管理する方法を説明します。
まず思い出してほしいのは、IaaSサービスはコンピューティングリソースを共有可能にするために、ハードウェアを仮想化するということです。各VMでは任意のOSインスタンスを使用できます。VM上でアプリをビルドして実行し メモリ、ファイルシステム、 ネットワーキングインターフェースなどの物理マシンと同じものにアクセスできます。しかし柔軟性には犠牲が必要です。
このような環境での 最小コンピューティング単位は、VMとそれに関連付けられたアプリ そしてゲストOSですが、このOSはサイズが大きく、数ギガバイトに及ぶことがあります。起動に数分かかる場合もあります。その価値はありますが、VMは高度に構成可能です。
任意のツールをインストールして実行できます。ディスクやネットワーキングなどの基となるシステムリソースを構成し、独自のウェブサーバーデータベースやミドルウェアをインストールできるのです。
一方、アプリが大成功したとして需要の増加に対応するには、ゲストOSを含むVM全体の単位でスケールアウトする必要があります。そのため、リソース使用量が思いのほか急増する可能性があります。
これと対照的なのが、App EngineのようなPaaS環境です。App Engineにデプロイする場合、方法はかなり異なります。空のVMを得るのではなく、アプリに必要なサービスファミリーにアクセスします。必要な作業は、該当するサービスを使用したコードと自己完結型ワークロードを作成して、独立したライブラリを組み込むことだけです。アプリの需要が増加するとプラットフォームがアプリをシームレスにスケールします。ワークロードとインフラとは別に行われます。スケールは迅速に行われますが、基のサーバーアーキテクチャーはコントロールできません。そこで登場するのが[コンテナ]です。コンテナとは PaaSのようなワークロードの独立した 環境によるスケーラビリティと IaaS環境のようなOSとハードウェアの抽象化層を提供するものです。

コンテナはコードとその依存関係が存在する見えないボックスであり、ファイルシステムとハードウェアの独自のパーティションにのみアクセスできます。Windows、Linux、その他のOSではプロセスとは実行中プログラムのインスタンスのことです。コンテナは新しいプロセスとして迅速に起動します。完全に新しいOSインスタンスの 起動にかかる時間とは比較になりません。
各ホストで必要なのは、コンテナをサポートするOSとコンテナランタイムだけです。基本的にはハードウェアではなく、OSを仮想化していることになります。この環境はPaaSのようにスケールする一方、IaaSと同等の柔軟性を備えています。
コンテナによる抽象化は、コードの移植性を高めます。OSとハードウェアをブラックボックスとして扱えるからです。コードを開発環境からステージ環境、 本番環境に移行する際も、ノートパソコンからクラウドに移行する際も変更したり再構築したりする必要はありません。たとえばウェブサーバーは、ほんの数秒でスケールできます。
単一ホスト上のワークロードのサイズによっては 何十台、何百台もデプロイできます。これは単純な例ですので より複雑な例を考えてみましょう。 多数のコンテナを使用して、アプリをビルドするとします。たとえばマイクロサービスパターンに従って、各コンテナが独自の機能を実行します。各コンテナ内のコードは、ネットワークファブリックで互いに通信できます。このような仕組みにする場合、アプリをモジュール化できます。
モジュールは簡単にデプロイでき、複数のホストで独立してスケールします。ホストはアプリの需要に応じてスケールアップ、スケールダウンでき、コンテナの起動と停止を行います。ホストで障害が発生して、置換する場合も同様です。 
ここで役立つのが[Kubernetes]です。Kubernetesを使用すると、多数のホスト上の[多数のコンテナのオーケストレーション]、スケール、新しいバージョンのロールアウト、以前のバージョンへのロールバックを簡単に行えます。 
まず、コンテナをビルドして実行する方法を説明していきます。コンテナイメージの一般的な形式は オープンソースツールのDockerで 定義されているものです。この例ではDockerを使用して、アプリとその依存関係をコンテナにバンドルします。
別のツールも使用できます、たとえば Google Cloudが提供する Cloud Buildは コンテナをビルドするためのマネージドサービスです。コードの例をお見せします。Pyhonウェブアプリです。一般的な Flaskフレームワークを使用しています。ウェブブラウザがこのコードと対話して、最上位のドキュメントを求めるたびに、アプリは「hello world」で応答します。ブラウザがリクエストに 「/version」を追加した場合は、アプリがそのバージョンを返します。このアプリをデプロイするにはどうすればよいでしょうか？ 特定のバージョンのPyshonが必要です。さらに特定のバージョンのFlaskも必要です。Pythonのrequirements.txtファイルでコントロールします。他の依存関係もここで制御します。Dockerfileを使用してコードをコンテナにパッケージ化する方法を指定します。たとえば、Ubuntuは一般的な Linuxディストリビューションです。こちらから始めましょう。Pythonのインストール方法は開発環境の場合と同様です。このファイルに指定されているため再現できます。前に作成したrequirements.txtファイルをコピーしましょう。そちらを使ってアプリの依存関係をインストールします。アプリを構成するファイルもコピーします。

コンテナを起動する環境にコンテナの実行方法を指示します。「docker build」コマンドで コンテナをビルドします。その結果コンテナがビルドされて実行可能イメージとしてローカルシステムに保管されます。次に「docker run」コマンドでイメージを実行します。実際は、コンテナレジストリサービスにイメージをアップロードします。たとえばGoogle Container Registryです。ここでイメージの共有やダウンロードを行います。アプリをパッケージしましたが、信頼できるスケーラブルな分散型システムを構築するまでには至っていません。アプリの構成、サービスディスカバリ、 更新の管理、モニタリングも必要です。次のレッスンでは、KubernetesとKubernetes Engineを 利用する方法を説明します。

# Kubernetes と GKE の概要
ここまでコンテナとアプリのコンテナ化の基礎を学習しました。次はKubernetesの役割について説明します。
Kubernetesはオープンソースのコンテナオーケストレーターです。アプリの管理とスケーリングに役立ちます。Kubernetesが提供するAPIでは、許可されたユーザーのみが複数のユーティリティを使って、そのオペレーションを制御できます。後ほどユーティリティの１つ、kubectlコマンドを紹介します。
Kubernetesでは[クラスタという、一連のノード]にコンテナをデプロイできます。クラスタとは、マスターコンポーネントのセットでシステム全体とコンテナを実行する一連のノードをコントロールするものです。Kubernetesでは、[ノードとはコンピューティングインスタンス]あり。Google Cloudでは、ノードとは[ComputeEngine内で実行されるVM]です。
Kubernetesを使用する際は、一連のアプリとアプリ間の対話方法を記述すれば、それらの実行方法がKubernetesで自動的に識別されます。Kubernetesを使用すると、前のレッスンで作成したようなコンテナ化アプリを簡単に実行できますが、Kubernetesクラスタはどのように取得するのでしょうか？ 
いつでもハードウェア上で自分で作成できます、あるいはVMを提供する環境でも可能です。自分で作成した場合は保守が必要になります。これは大変な作業です。保守作業に追われるのは有意義な時間の使い方ではないため、Google Cloudでは Kubernetes Engineを提供しています。クラウド内のマネージドサービスとしてのKubernetesです。これを使えばGCP Consoleで、Kubernetesクラスタを作成できます。Cloud SDKに含まれる gcloudコマンドでも作成できます。GKEクラスタはカスタマイズできます。各種マシンタイプ、多数のノード、 ネットワーク設定がサポートされています。 
GKEを使用してKubernetesクラスタを 作成するコマンドの一例を紹介しましょう。「gcloud container clusters create k1」です。 このコマンドでは、「K1」というクラスタが作成されます。すぐに使える構成済みのクラスタです。進捗状況はConsoleで確認できます。
Kubernetesがコンテナや一連の関連コンテナをデプロイするときは、常に[ポッドという抽象化層]の中にデプロイします。ポッドはKubernetesの最小デプロイ単位であり、クラスタで実行中のプロセスのようなものです。アプリの一部であることもアプリ全体であることもあります。通常は各ポッドに１つのコンテナをデプロイしますが、強い依存関係を持つコンテナが複数ある場合は単一のポッドにパッケージ化できます。これらは自動的にネットワークを共有し、共通のディスクストレージ ボリュームを使用できます。
Kubernetesの各ポッドにはコンテナ用に固有のIPアドレスとポートが割り当てられます。ポッド内のコンテナ同士はローカルホスト ネットワークインターフェースで通信するため、デプロイされているノードは認識されません。Kubernetesでポッド内のコンテナを実行する１つの方法は、「kubectl run」コマンドです。もっと良い方法を後ほど説明しますが、このコマンドを使えばすぐに開始できます。
kubectl runコマンドを実行すると、ポッド内の実行中コンテナで[Deployment]が起動されます。この例のポッド内で実行されるコンテナは nginxオープンソース ウェブサーバーのイメージです。kubectlコマンドによって、リクエストしたバージョンのnginxイメージが Container Registryから取得されます。Deploymentとは何でしょう？
Deploymentは、同じポッドのレプリカのグループを表します。ノードのいずれかで障害が発生しても、ポッドの実行状態を保つことができます。Deploymentにはアプリの一部、またはアプリ全体を含めることができます。この例では、nginxウェブサーバーが含まれています。実行中のnginxポッドを表示するには、「kubectl get pods」コマンドを実行します。デフォルトではDeployment内のポッドには、クラスタ内からしかアクセスできません。では nginxウェブサーバーのコンテンツへのアクセスをインターネット上の全員に許可するには？ 
Deployment内のポッドを一般公開するには、ロードバランサを接続します。「kubectl expose」コマンドで接続します。KubernetesでServiceを作成し、そこにポッドの固定IPアドレスを設定します。Serviceとは Kubernetesで 負荷分散を表す基本手法です。つまり Kubernetesに対して、パブリックIPアドレスで外部ロードバランサをServiceに接続するように指定し、クラスタの外部からアクセスできるようにしています。
GKEではこうしたロードバランサは、ネットワークロードバランサとして作成されます。これはCompute EngineがVMに提供する、マネージド負荷分散サービスの１つです。GKEではコンテナでこの負荷分散を簡単に使用できます。このIPアドレスにアクセスするクライアントは、サービス背後のポッドにルーティングされます。この例ではポッドは１つしかありません。シンプルなnginxポッドです。ではServiceとは厳密には何でしょう？
Serviceは一連のポッドをグループ化して、安定したエンドポイントを提供するものです。この例では、ネットワークロードバランサが管理するパブリックIPアドレスです。ただし、他の選択肢もあります。ではなぜServiceが必要なのでしょう？ポッドのIPアドレスを直接使用できないのでしょうか？
たとえばアプリがフロントエンドとバックエンドで構成されているとします。フロントエンドからバックエンドには、ポッドの内部IPアドレスでアクセスできるので、Serviceは不要なはずです。しかし管理の問題があります。Deploymentがポッドを作成して破棄すると、ポッドに固有のIPアドレスが割り当てられますが。このアドレスは変わります。Serviceは安定したエンドポイントを提供します。
Kubernetesについて学習を進めれば、内部のアプリバックエンドに適する、他のServiceタイプがわかってくるでしょう。 「kubectl get services」コマンドで ServiceのパブリックIPアドレスを確認できます。クライアントはこのアドレスで リモートからnginxコンテナにアクセスできます。追加の処理能力が必要になったら、「kubectl scale」コマンドで Deploymentをスケールできます。この例のDeploymentには、３つのnginxウェブサーバーがあります。いずれもServiceの背後にあり、１つの固定IPアドレスでアクセスできます。自動スケーリングでも便利なパラメータを設定できます。たとえば、CPU使用率に応じて Deploymentを自動スケールするとします。このコマンドでは、最小ポッド数を10に指定しています。[最大ポッド数は15]です。スケールアップの基準として、CPU使用率が処理能力の80％に達した時点でポッド数をスケールアップします。
ここまでは命令型コマンドの実行方法を説明しました。exposeやscaleなどです。命令型は、Kubernetesの段階的な学習やテストには役立ちますが、Kubernetesの真の強みは宣言型です。コマンドを実行する代わりに構成ファイルを渡します。このファイルで目的の状態を指定すれば、Kubernetesがその方法を判断します。こうした構成ファイルは管理ツールになります。変更を加えるには、構成ファイルを編集し、変更後のバージョンをKubernetesに提示します。スライドのコマンドは、これまでの作業に基づく構成ファイルの操作の開始点として使用できます。コマンドの出力はこのようになります。構成ファイルの操作は一見すると難しそうです。何行ものコードが見慣れない構文で記述されているためです。しかし慣れてくると簡単に処理できます。
バージョン管理システムに保存して、インフラの変更を追跡することもできます。この例のDeployment構成ファイルは、nginxポッドのレプリカ数を３として宣言しています。selectorフィールドを定義して、特定のポッドをレプリカとしてグループ化する方法を指示しています。ポッドを特定できるのはラベルが共有されているためです。該当するポッドのアプリには 「nginx」のラベルが付いています。３つではなく５つのレプリカを実行する場合、Deployment構成ファイルを編集して３を５に変更するだけです。非常に柔軟です。そして「kubectl apply」コマンドを実行して、更新後のファイルが使用されるようにします。「kubectl get replicasets」コマンドで レプリカを表示して更新後の状態を確認します。さらに「kubectl get pods」コマンドでポッドがオンラインになるのを観察します。この出力例では５つのポッドがすべて実行状態になっています。最後にDeploymentを調べて実行中のレプリカ数が正しいかを確認します。そのためには、「kubectl get deployments」を使用します。この例では５つレプリカがすべて使用可能になっています。クライアントは引き続きエンドポイントにアクセスできます。「kubectl get services」コマンドで Serviceの外部IPへの 影響がないことを確認できます。現時点でGKEでは nginxポッドの５つのコピーが実行されていて、１つのServiceで５つのポッドへのトラフィックをプロキシしています。Kubernetesではこの手法により、負荷を分散してServiceをスケールします。前のレッスンでは、 Pythonアプリをコンテナ化しました。それをnginxに置き換えて同じツールを使って、デプロイとスケールを行えます。
最後にアプリのバージョンを 更新する方法を説明します。コンテナを更新して新しいコードをできるだけ早く適用する必要があります。しかし、すべての変更を一度にロールアウトするのはリスクが伴います。アプリの再ビルドと再デプロイの間、ユーザーがダウンタイムを経験するのは避けたいはずです。そのため、Deploymentには更新戦略という属性があります。これはローリングアップデートの例です。Deploymentのローリングアップデートを選択して管理対象ソフトウェアの新しいバージョンを指定すると、Kubernetesが新しいバージョンのポッドを１つずつ作成し、各ポッドが使用可能になるのを待ってから古いバージョンのポッドを破棄します。ローリングアップデートを使用すれば、ダウンタイムを生じさせることなく アプリのバージョンを迅速に更新できます。

# Hybrid and Multi-Cloud Computing (Anthos)  の概要
コンテナについての理解を深めるために、最新のハイブリッド/マルチクラウド アーキテクチャでの使用方法について説明します。
その前に典型的なオンプレミスの分散システムアーキテクチャを見てみましょう。クラウドが登場するまで、企業はこの方法でコンピューティングニーズに対応していました。ほとんどの企業向けアプリケーションは、分散システムとして設計されます。つまり、サービス提供に必要なワークロードが複数のネットワークサーバーに分散されます。
ワークロードをマイクロサービスに分割し、管理と拡張を容易にする方法として、ここ数年でコンテナの人気が高まっています。従来、企業向けシステムとそのワークロードは コンテナ化の有無にかかわらず、オンプレミスに格納されてきました。つまり自社のネットワークやデータセンター内の一連の大容量サーバー上に格納されていました。この場合、アプリのコンピューティングニーズに利用可能なリソースで対応しきれなくなるとより高性能なサーバーが必要になります。サーバーをインストールするには、ネットワークの変更や拡張が必要です。新しいサーバーを構成して、
そこにアプリとその依存関係を読み込まなければ、リソースのボトルネックを解決できません。このような[オンプレミスのアップグレードを完了するには数か月から１年以上]かかることもあります。サーバーの平均耐用年数が３～５年であることを、考えるとかなりの費用がかかります。今すぐコンピューティング能力の増強が必要な場合はどうでしょう？または一部のワークロードをオンプレミスからクラウドに再配置して、コスト削減と高可用性を実現したい一方でオンプレミスネットワークからアプリを移行したくない場合はどうでしょう？クラウドでしか利用できないサービスが必要な場合はどうでしょう？
そこで役立つのが最新のハイブリッド/[マルチクラウドアーキテクチャ]です。この方法ではシステムインフラの一部をオンプレミスに維持したまま 他の部分をクラウドに移行できます。したがってニーズに応じた固有の環境を構築できます。ご自分のペースで特定のワークロードだけをクラウドに移行できます。なぜなら完全に移行する必要はないからです。クラウドの柔軟性、スケーラビリティ、コスト削減を実現しながら、移行を決めたワークロードを実行できます。機械学習、コンテンツキャッシュ、データ分析、長期保存、IoTなどの専門サービスも、リソースツールキットに追加できます。
ハイブリッドアーキテクチャによる分散システムとサービスの運用は、最近盛んに話題になっています。Googleが開発したAnthosについても耳にされたかもしれません。Anthosとは何でしょう？
AnthosはGoogleのハイブリッド/マルチクラウドソリューションで、分散システムとサービス管理ソフトウェアの最新技術が採用されています。 Anthosフレームワークの基盤となるのは、[オンプレミスのKubernetes]と Google Kubernetes Engine（[GKE]）です。これをアーキテクチャの基盤として、ポリシーベースのライフサイクルをサポートする。中央コントロールプレーンを介し、ハイブリッド/マルチクラウド環境を一元管理します。Anthosにはアプリの整合性をモニタリングし、維持するためのツールも揃っているので、オンプレミス、クラウド、複数のクラウドでもネットワーク全体で整合性を維持できます。

詳しく見てみましょう。Anthosで最新のハイブリッドインフラスタックを段階的に構築してみます。
まず、ハイブリッドネットワークのクラウド側のGKEを見てみましょう。GKEはコンテナ化アプリをデプロイするためのマネージド型の本番環境です。高可用性とSLAによりシームレスに動作します。Certified Kubernetesが実行されるため、クラウドとオンプレミス間を自由に移動できます。
自動ノード修復、自動アップグレード、 自動スケーリングも組み込まれています。リージョンクラスタを使用するため、複数のマスターで高可用性を維持します。複数のゾーン間でノードのストレージをレプリケートします。2019年10月時点でゾーンの数は３つです。ハイブリッドネットワークのオンプレミス側にもGKEがデプロイされます。オンプレミス側のGKEは本番環境レベルのターンキーKubernetesで、ベストプラクティスの構成が事前に読み込まれています。
Googleが検証、テストしたKubernetesの最新リリースに簡単にアップグレードできます。GCP上のコンテナサービスにもアクセスできます。たとえばCloud Build、Container Registry、 監査ロギングなどです。Istio、Knative、Marketplaceの 各ソリューションも統合されます。クラウド環境とオンプレミス環境でのKubernetesのバージョンと操作は一貫しています。
クラウドとオンプレミスのGKEはどちらも Marketplaceと統合するため、ネットワーク内のクラスタはオンプレミスでもクラウドでも、コンテナ化アプリの同じリポジトリにアクセスできます。これによりネットワークのどちら側でも同じ構成を使用できるため、アプリの開発時間が短縮されます。
正しい構成をどこにでもレプリケートして、クラスタ間の整合性を維持できます。アプリで何百ものマイクロサービスを使用して、ワークロードを処理することもあります。これだけの数のサービスを追跡して、正常性をモニタリングするのは至難の業です。
AnthosはIstioオープンソース サービスメッシュとして、勘に頼った判断をマイクロサービスの管理とセキュリティから完全に排除します。
サービスメッシュのレイヤはハイブリッド ネットワークと通信する際に、Cloud Interconnectでデータを同期して渡します。
StackdriverはGogle Cloudに組み込まれた ロギングとモニタリングのソリューションです。完全に管理されたロギング、指標の収集、 モニタリング、ダッシュボード、アラートによりハイブリッド/マルチクラウドネットワークのあらゆる側面を監視します。簡単に構成できて高性能なクラウドベース 可観測性ソリューションをお求めの場合、Stackdriverが最適です。１つのダッシュボードで すべての環境をモニタリングすることも可能です。
最後に、Anthos Configuration Managementはクラスタ構成の信頼できる唯一の情報源を提供します。この情報源が保持されるポリシーリポジトリは、実際にはGitリポジトリです。この図のリポジトリはオンプレミス側にありますが、クラウドでホストすることもできます。Anthos Configuration Managementエージェントは、ポリシーリポジトリを使って各環境でローカルに構成を適用することで、複数の環境でクラスタを所有する際の複雑さを省きます。Anthos Configuration Managementでは、管理者とデベロッパー向けに単一のリポジトリコミットでコード変更をデプロイする機能も提供しています。名前空間による構成の継承も実装できます。Anthosの詳細については、こちらのリソースをご覧ください。

# モジュールの概要、App Engine の紹介
アプリのコンピューティングインフラを提供する ２つのGCPプロダクトについて説明しました Compute EngineとKubernetes Engineです この２つの共通点はアプリを実行する インフラを選択できることです Compute EngineではVM、Kubernetes Engineでは コンテナを基に選択します しかし インフラを 気にしたくない場合もあります コードのみに集中したい場合です そのためにあるのがApp Engineです このモジュールで詳しく説明します PaaSから見ていきましょう PaaSは 「サービスとしてのプラットフォーム」です App Engineプラットフォームが コードの実行に必要なハードウェアと ネットワークインフラを管理します App Engineにアプリをデプロイするには コードを提供するだけです 残りの処理はApp Engineが行います App Engineには多くのウェブアプリに必要な サービスが組み込まれています NoSQLデータベース、インメモリキャッシュ、 負荷分散、ヘルスチェック、ロギング ユーザー認証機能などです これらのサービスを利用する アプリコードを作成すれば App Engineがサービスを提供します App Engineは受信トラフィック量に応じて アプリを自動的にスケールします 料金は使用したリソースの分だけです サービスのプロビジョニングや保守も不要です したがってApp Engineは ワークロードが変動しやすいか予測できない ウェブアプリやモバイルバックエンドに 特に適しています App Engineにはスタンダード環境と フレシキブル環境の２つがあります それぞれの概要と選び方を説明していきます

# Google App Engine スタンダード環境
２つのApp Engine環境のうち シンプルなのはスタンダード環境です フレキシブル環境よりもデプロイが簡単で [きめ細かい自動スケーリング]が可能です どちらの環境でも 一部のサービスに [１日の無料割り当て使用量]が設定されています しかしスタンダード環境の特徴は 使用量の少ないアプリは 無料で実行できる場合があることです GoogleではApp Engineソフトウェア開発 キットを複数言語で提供しているため アプリをローカルでテストしてから App Engineサービスにアップロードできます SDKには単純な デプロイコマンドも含まれています コードは実際にどこで実行されるのでしょうか 実行可能バイナリとは 何を意味するのでしょうか App Engineでは このバイナリを「ランタイム」と呼びます スタンダード環境では Google提供のランタイムを使用します 選択肢について説明します App Engineスタンダード環境で 使用できるランタイムは 特定のバージョンの Java、Python、PHP、Goです ランタイムにはApp Engine API対応の ライブラリも組み込まれています 多くのアプリでは スタンダード環境のランタイムと ライブラリだけで十分です 他の言語でコードを作成する場合 スタンダード環境は適しません フレキシブル環境をご検討ください スタンダード環境ではコードの制限があり 「サンドボックス」でコードが実行されます これはハードウェア、OS、物理的なサーバーの 場所に依存しないソフトウェア構成概念です このサンドボックスこそが スタンダード環境でアプリをきめ細かく スケールして管理できる理由の１つです 通常 サンドボックスには いくつかの制約があります たとえば アプリは ローカルファイルシステムに書き込めません データを存続させるには データベースサービスに書き込む必要があります また アプリが受信するすべてのリクエストは 60秒でタイムアウトします 任意のサードパーティソフトウェアは インストールできません 以上の制約が問題になる場合は フレキシブル環境を選択してください これはApp Engineスタンダード環境の 使用方法を示す図です App Engine SDKを使ってアプリを開発し テストバージョンをローカルで実行します 準備ができたら SDKを使用して アプリをデプロイします 各App Engineアプリは GCPプロジェクト内で実行されます App Engineが自動的にサーバーインスタンスを プロビジョン、スケール、負荷分散します 一方 アプリは専用のAPIを使って 各種サービスを呼び出すことができます たとえば データを保持するNoSQLデータストア そのデータをキャッシュするMemcache 検索、ロギング、ユーザーログイン ユーザーリクエスト以外によって アクションを開始できる タスクキューやタスクスケジューラなどです

# Google App Engine フレキシブル環境
    SSHで接続できる
スタンダード環境のサンドボックスモデルの 制約がネックになっているとします それでもApp Engineを利用したい場合 App Engineフレキシブル環境があります App Engineフレキシブル環境では サンドボックスではなく App Engineを実行するコンテナを指定します アプリは[ComputeEngineのVM上]の Dockerコンテナ内で実行されます App Engineが Compute Engine VMを管理します ヘルスチェックを行い 必要に応じて修復します VMを実行する地理的リージョンは ユーザーが選択します さらに下位互換性を維持するための 重要なOS更新も自動的に適用されます その結果ユーザーはコードに集中できます App Engineフレキシブル環境のアプリは 標準ランタイムを使用し App Engineのデータストア、Memchach、 タスクキューなどのサービスにアクセスできます こちらはスタンダード環境とフレキシブル環境の 比較表です スタンダード環境のほうがアプリの インスタンスを短時間で起動できます ただしアプリを実行するインフラへの アクセスは制限されます たとえば フレキシブル環境では アプリを実行するVMにSSHで接続できます ローカルディスクへの書き込みが可能です サードパーティソフトウェアも インストールできます アプリがApp Engineを介さずに ネットワークを呼び出すことも可能です 一方 スタンダード環境では アプリが完全にアイドル状態であれば 請求料金はゼロになります 前述のようにApp Engineは Dockerコンテナを使用するため App EngineとKubernetes Engineの 違いも気になると思います こちらはApp EngineとKubernetes Engineの 比較表です App Engineスタンダード環境は アプリのデプロイとスケーリングを 最大限コントロールしたい場合に適しています Kubernetes Engineではアプリオーナーは Kubernetesの柔軟性を活用できます App Engineフレキシブル環境は これらの中間に位置するものです App Engine環境ではコンテナを 目的を達成する手段として扱いますが Kubernetes Engineでは コンテナは構築の基盤になります

# Google Cloud Endpoints と Apigee Edge
アプリケーションプログラミング インターフェース（API）については このコースで何度か取り上げましたが ここで正確に理解しておきましょう ソフトウェアサービスの実装は 複雑で変わりやすいものです たとえば 他のソフトウェアが そのサービスを利用するたびに その動作を詳細に知る 必要があるとしたら非常に面倒です そのためアプリデベロッパーは ソフトウェアを構造化して 簡潔で明快なインターフェースで 不要な詳細を抽象化し その情報をドキュメント化します これがAPIです APIが変更されない限り 基盤となる実装はいくらでも変更できます APIを利用している他のソフトウェアが その変更を知る必要はありません 機能の追加や廃止のために APIの変更が必要になることもあります こうしたAPIの変更を適切に行うため デベロッパーはAPIのバージョン管理を行います バージョン２のAPIにバージョン１にはない 呼び出しが含まれるとします このAPIを利用するプログラムでは 呼び出しの際にAPIバージョンを指定できます APIへの対応は非常に重要です GCPには２つのAPI管理ツールが 用意されています 問題に対してのアプローチが異なり それぞれの長所があります ソフトウェアサービスと GCPのバックエンドを開発しているとします APIを簡単に公開して 信頼できるデベロッパーのみに 使用してもらいたいと考えています 使用状況を監視して記録する 簡単な方法も必要です APIが呼び出し側のエンドユーザーを 把握するための統一的な方法も必要です そこで役立つのがCloud Endpointsです Cloud Endpointsでは簡単にデプロイできる プロキシを使用して必要な機能を実装できます さらにAPIコンソールの使いやすい インターフェースで機能を管理できます Cloud EndpointsはGCPで実行される アプリをサポートします アプリで使用している言語や クライアントテクノロジーは問いません Apigee EdgeもAPIプロキシを 開発、管理するためのプラットフォームです ただし位置付けが異なります レート制限、割り当て、分析などの ビジネス的な問題に重点を置いています Apigee Edgeの多くのユーザーは 他社にソフトウェアサービスを提供しているため こうした機能が重要になります [ApigeeEdge]はGCP外部の バックエンドサービスにも対応するため エンジニアが[レガシーアプリ]を 「分解」するときによく使われます モノリシックアプリを 一度に移行することはリスクがありますが Apigee Edgeを使用すれば サービスを１つずつ分離し レガシーアプリが完全に使用されなくなるまで マイクロサービスに分解して 順番に実装することができます

# クラウドでの開発
Google Cloudではユーザーによって 各種アプリが作成されています 開発、デプロイ、モニタリング用の 一般的なツールはGCPでも機能します GCPに密接に統合されている ツールも使用できます ここではこうしたツールについて説明します まずは開発についてお話ししましょう GCPの多くのお客様はGitを使用して ソースコードツリーを保管、管理しています つまり 独自のGitインスタンスを実行するか ホスト型Gitプロバイダを使用しています 独自のインスタンスの利点は 完全な制御です ホスト型Gitプロバイダの利点は 作業負担の軽減です ３つ目の手段として コードの公開をGCPプロジェクトに限定して IAM権限で保護しながら Gitインスタンスの 保守を省けるとしたらどうでしょう その手段がまさに [CloudSourceRepositories]です Gitバージョン管理によってチームによる アプリやサービスの開発をサポートします App Engine、Compute Engine、 Kubernetes Engineで実行するアプリなどです Cloud Source Repositoriesでは プライベートGitリポジトリを いくつでも使用できるので クラウドプロジェクトの関連コードを 任意の方法で整理できます Cloud Source Repositoriesには ソースビューアもあります GCP Console内からリポジトリの ファイルを参照して表示できます 多くのアプリにはイベントで 駆動される部分があります たとえば ユーザーが画像を アップロードできるアプリでは アップロードのたびに 画像を複数の方法で処理する必要があります 標準の画像形式に変換し 複数のサムネイルを作成してサイズ別に リポジトリに保管するなどです このような関数はアプリに統合できますが それを処理する コンピューティングリソースが必要です １日１回の処理でも ミリ秒ごとの処理でも必要です このプロビジョニング問題を 解決できるとしたら？ 必要な画像処理を行う 単一目的の関数を作成するだけで 画像がアップロードされるたびに 自動的に実行されると便利です それを可能にするのがCloud Functionsです サーバーやランタイムバイナリを 気にする必要はありません GCPのNode.js環境対応のコードを JavaScriptで作成して 起動の条件を構成するだけです サーバーの使用料金は不要です 関数の実行時間分の料金を 100ミリ秒単位で支払うだけです Cloud Functionsのトリガーの基準は Cloud Sotrage、Cloud Pub/Sub、 HTTP呼び出しのイベントです Cloud Functionを設定するには まず対象のイベントを選択します Cloud Functionsに 各イベントタイプを指示します この宣言は「トリガー」と呼ばれます 次に JavaScript関数をトリガーに関連付けます 以降は該当するイベントが発生するたびに 関数が応答します マイクロサービスアーキテクチャを 使用するアプリなどは Cloud Functions内で完全に実装できます Cloud Functionsは既存のアプリを 拡張するためにも使用されています スケーリングの心配がなくなります

# デプロイメント: コードとしてのインフラストラクチャ
GCPでの環境設定には多くの手順があります コンピューティング、ネットワーク、 ストレージの各リソースを設定して 構成を常に把握する必要があります 命令型アプローチでは これらを手動で行います つまり 意図した環境を設定するための コマンドを見つける必要があります 環境に変更を加える場合は 新しい状態に変更するための コマンドを見つけます 環境のクローンを作成するには すべてのコマンドを再び実行します これは大変な作業です テンプレートを使用したほうが効率的です テンプレートとは目的とする環境の仕様です 命令型に対して宣言型の方法です GCPのDeployment Managerでは これが可能です このインフラ管理サービスは GCPリソースの作成と管理を自動化します これを使用するには テンプレートファイルを作成し YAMLマークアップ言語またはPythonを使用して 環境に必要なコンポーネントを記述します そのテンプレートを Deployment Managerに渡すと 記述された環境の作成に必要な アクションが判断され実行されます 環境を変更する場合は テンプレートを編集し 環境を更新するよう Deployment Managerに指示します テンプレートを保管して バージョン管理するには Cloud Source Repositoriesを利用します

# モニタリング: プロアクティブなインストゥルメンテーション
アプリの安定した実行には モニタリングが不可欠です モニタリングにより アプリに加えた変更の 有効性を判断できます アプリがダウンしたと苦情が来ても 情報をもとに落ち着いて対処できます Stackdriverはモニタリング、 ロギング、診断用のGCPツールです Stackdriverでは 各種シグナルにアクセスできます インフラプラットフォーム、 VM、コンテナ、ミドルウェア アプリ層、ログ、指標、 トレースなどのシグナルです アプリの正常性、パフォーマンス、 可用性の分析情報を取得できます 問題が発生しても迅速に修正できます

Stackdriverのコアコンポーネントは Monitoring、Logging、Trace、 Error Reporting、Debuggingです Stackdriver Monitoringがチェックするのは クラウド環境内のウェブアプリや インターネットでアクセスできる その他のサービスのエンドポイントです 稼働時間チェックを構成して URL、グループのほか インスタンスや ロードバランサなどのリソースを関連付けます 基準に基づくアラートも設定できます アクションが必要なヘルスチェック結果や 稼働時間の減少などの基準です Monitoringは多数の通知ツールと 組み合わせて使用できます アプリの状態を可視化する ダッシュボードも作成できます Loggingではアプリのログを 表示、フィルタ、検索できます ログの内容に基づく指標を定義して ダッシュボードとアラートに 統合することもできます ログはBigQuery、Cloud Storage、 Cloud Pub/Subにエクスポートできます Error Reportingは アプリのエラーを追跡、グループ化し 新しいエラーが検出されると通知します TraceではApp Engineアプリの レイテンシを抜き出して URLごとの統計レポートを作成できます デバッグについてはどうでしょう アプリに多数のログステートメントを 追加してデバッグするのは大変な作業です Debuggerでは別の方法を使用できます アプリの本番環境データを ソースコードに関連付けて 本番環境の任意のコード位置で アプリの状態を調べられるようにします したがってログステートメントを 追加しなくてもアプリの状態を確認できます Debuggerが本領を発揮するのは アプリのソースコードが使用できる場合です したがって Cloud Source Repositoriesなどの リポジトリにコードを保管すると役立ちます

# ビッグデータと機械学習の概要
Googleは将来的にはすべての会社が データ企業になると確信しています 競争上優位性を得るには迅速かつ有効に データを使用することが不可欠だからです Google Cloudでは誰でも Googleが提供するインフラとデータ処理の 最新テクノロジーを利用できます Google Cloudは データ分析システムを 構築・維持する際の複雑さを 自動で取り除きます このモジュールでは データを迅速かつ最大限に活用するための Googleのテクノロジーについて説明します リアルタイム分析と機械学習もカバーします これらのツールは アプリに簡単に 統合できるよう実用的に設計されています そのため自社のドメイン専門家を介して データからすばやく分析情報を入手できます

# Google Cloud ビッグデータ プラットフォーム
Google Cloudの ビッグデータソリューションは、有用なデータ分析情報によってビジネスとユーザーエクスペリエンスを変革します。Googleではこれを「統合サーバーレス プラットフォーム」と呼んでいます。つまり「サーバーレス」とは、ジョブを実行するインスタンスのプロビジョニングが不要ということです。フルマネージドサービスでかかるのはリソース使用分の料金だけです。プラットフォームは統合型です。さまざまなGCPサービスを使って、カスタムソリューションを作成できます。
Apache [Hadoop]はビッグデータ対応のオープンソースフレームワークです。ベースとなるのはGoogleが開発した、MapReduceプログラミングモデルです。MapReduceモデルの最もシンプルな形では、「map関数」と呼ばれる関数が並行して膨大なデータセットを処理し、それぞれに中間結果を生成します。そして別の「reduce関数」という関数が、すべての中間結果に基づいて最終的な結果セットを生成します。「Hadoop」という用語は Apache Hadoop自体と関連プロジェクトの総称としてよく使用されます。Apache Spark、Apache Pig、 Apache Hiveなどのプロジェクトです。
Cloud Dataprocという高速で使いやすいマネージドサービスを使用すると、Hadoop、Spark、Hive、Pigを GCP上で実行できます。Hadoopクラスタをリクエストするだけで、90秒以内にクラスタが自動作成されます。クラスタを構成するCompute Engine VMの 数とタイプは指定でき、クラスタの実行中に処理能力を増減する必要がある場合は、スケールアップまたはダウンできます。クラスタではHadoopソフトウェアのデフォルト構成を使用することも、構成をカスタマイズすることもできます。さらにStackdriverで、クラスタをモニタリングできます。
Hadoopジョブをオンプレミスで実行する場合は、ハードウェアへの資本投資が必要です。Cloud Dataprocで実行すれば、クラスタの存続中に使用した、ハードウェアリソースの料金を支払うだけです。料金設定は時間単位ですが、Cloud Dataprocの課金は秒単位です。すべてのCloud Dataprocクラスタは、１秒単位で課金されます。最小課金時間は１分です。クラスタを使い終わって削除すれば、課金は停止されます。オンプレミスのハードウェア資産よりも俊敏にリソースを使用できます。費用を節約するために、Cloud Dataprocでの一括処理に[プリエンプティブル]Compute Engine インスタンスを使用することもできます。終了されても正常に再起動できるジョブであれば、この方法でインスタンスの費用を大幅に削減できます。この動画を収録した時点では、プリエンプティブルインスタンスだと 約80％の費用を削減できます。Dataprocクラスタの費用に含まれるのは、インスタンスの費用だけではありませんが、かなりの部分を占めます。データがクラスタに取り込まれたら、SparkとSpark SQLを使用して、データマイニングを行えます。MLibというApache Sparkの 機械学習ライブラリを使用して、機械学習でパターンを検出することもできます。

# Cloud Dataflow
Cloud Dataprocが役立つのは、データセットの[サイズが明らか]な場合やクラスタサイズを[自分で管理する]場合です。
一方、リアルタイムのデータやデータのサイズとレートが[予測できない場合は、CloudDataflowが最適]です。この統合プログラミングモデル （マネージドサービス）を使えば、広範なデータ処理パターンを開発して実行できます。抽出、変換、読み取り（ETL）から、バッチ計算、連続計算にまで対応します。
Dataflowで作成するデータパイプラインは、バッチデータとストリーミングデータの両方に適用できます。クラスタの起動もインスタンスのサイズ変更も不要です。処理に必要なリソースが何であれ、Cloud Dataflowがリソース管理を完全に自動化します。Cloud Dataflowを使用すれば、リソース管理やパフォーマンス最適化などの作業から解放されます。この例のDataflowパイプラインでは「ソース」で、BigQueryテーブルからデータを読み込み、「変換」で各種の方法でデータを処理し、「シンク」で出力をCloud Storageに書き込んでいます。変換にはMapオペレーションと Reduceオペレーションがあり、非常に高機能なパイプラインを構築できます。パイプラインの各ステップは、柔軟にスケールされます。クラスタの起動や管理は不要です。このサービスがすべてのリソースを オンデマンドで提供します。
最適化された組み込みの自動パーティショニング機能により、遅れている作業が動的に再調整されるため、ホットキーに関する懸念が減ります。過度に大きい入力チャンクが同じクラスタにマップされるといった懸念です。Dataflowはさまざまなユースケースで使用されます。前述のとおり、これは汎用のETLツールです。さらにデータ分析エンジンとして使用すると、さまざまな分野で役立ちます。たとえば[不正検出]、 [金融サービス]、[IoT分析]、[製造]、[ヘルスケア]、[ロジスティクス]、[クリックストリーム]、[小売業のPoS]や[セグメンテーション分析]などです。パイプラインは外部サービスを含む、複数のサービスをオーケストレートできるため、パーソナライズされたゲーム体験などを提供するリアルタイムアプリに使用できます。

# BigQuery
たとえば動的パイプラインではなく、膨大なデータを探索して、データを実行したいとします。膨大なデータセットに対する、[アドホックSQLクエリ]が必要です。これを可能にするのがBigQueryです。ペタバイト規模で低料金の[フルマネージド分析データウェアハウス]です。インフラの管理は不要なので、有用な情報を見つけるためのデータ分析に専念できます。使い慣れたSQLを使えるだけでなく、従量課金制モデルを利用できます。
BigQueryにデータを取り込むのは簡単です。Cloud StorageやCloud Datastoreから読み込んだり、BigQueryに1秒あたり最大10万行をストリーミングしたりできます。BigQuery内の数テラバイトのデータに対して、わずか数秒でSQLクエリを実行できます。Googleインフラの処理能力を利用するからです。さらにCloud Dataflow、Hadoop、Sparkを使って、BigQuery内のデータを簡単に読み書きできます。
BigQueryはスタートアップ企業から Fortune 500企業まで あらゆる組織で使用されています。小さな組織では 毎月の無料割り当てが、大きな組織では シームレスなスケーリングと 可用性99.9％のSLAが好評です。
Googleのインフラと同じく、BigQueryもグローバルです。BigQueryではデータを保持するリージョンを指定できます。たとえばデータをヨーロッパで保持する場合、ヨーロッパにクラスタを設定する必要はありません。データセットを作成するEUロケーションを指定するだけです。USとアジアのロケーションも選択できます。
BigQueryではストレージと計算処理が分離されるため、クエリとデータストレージの料金は別々に支払います。つまり、クエリの料金を支払うのは [実際に実行しているときだけ]です。BigQuery内のデータへのユーザーアクセスを完全に制御でき、プロジェクト間でのデータセットの共有も制御できます。料金やパフォーマンスに影響しないデータセットを共有した場合、共有相手が実行したクエリの料金は共有相手が支払います。BigQueryに長期間保存されているデータには、長期保存割引料金が[自動的に適用]されます。データの保存期間が[90日]に達すると自動的にストレージ料金が引き下げられます。

# Cloud Pub/Sub と Cloud Datalab
リアルタイムのイベントを扱うときは、メッセージングサービスが役立ちます。Cloud Pub/Subです。
ストリーム分析のためのシンプルで信頼性の高いスケーラブルな基盤です。これを使えば、構築した個別のアプリ間でメッセージを送受信できます。アプリが分割されるため、独立してスケールできます。Pub/Subの「Pub」はパブリッシャーの略、 「Sub」はサブスクライバーの略です。
アプリがメッセージをパブリッシュすると、１つ以上のサブスクライバーが受信します。メッセージの受信は必ずしも同期する必要はありません。そのためPub/Subは、システムを分離するのに便利です。「at least once」（最低 １ 回）の 配信を低レイテンシで行う設計になっています。 「at-least-once配信」とは[メッセージが複数回配信される可能性がわずかにある]ことを意味します。アプリの作成時は、この点に注意してください。

Cloud Pub/Subはオンデマンドでスケールし、１秒あたり100 万件以上のメッセージを処理できます。割り当ては必要に応じて選べます。基盤となるテクノロジーは、Google社内で使用しているものと同じです。高頻度で予測不可能な量のデータが、到着するアプリでは重要な構成部分になります。たとえばIoTシステムなどです。
ストリーミングデータを分析する場合、Cloud DataflowとPub/Subを組み合わせて使用できます。GCPのコンピューティングプラットフォームで、構築されたアプリにも使用できます。サブスクライバーを構成してpushまたはpullベースでメッセージを受信します。つまり、サブスクライバーが新着メッセージの通知を受けるようにするか、定期的に新着メッセージを確認するように構成できます。
科学者たちは長いことラボノードブックを使って考えをまとめ、データを探索してきました。データサイエンスでもこのラボノートブックが鍵となります。データ分析のあちこちに結果に関するコメントを書き込むのは自然なことだからです。ノートブックのホスト環境として、一般的なのはProject Jupyterです。Pythonコードを含むウェブベースのノードブックを作成して保守できるので、インタラクティブにコードを実行して、結果を確認できます。Cloud Datalabはこの自然な手法から管理作業を取り除きます。Compute Engine VM内で稼働するからです。
Cloud Datalabを使うには、VMのタイプとVMを実行するGCPリージョンを指定します。Datalabを起動すると、すぐに使えるインタラクティブなPython環境が提供されます。複数のGCPサービスが、自動的にオーケストレートされるので、データの探索に専念できます。料金は使用したリソースの分だけです。Datalab自体の追加料金はありません。BigQuery、Compute Engine、 Cloud Storageと統合されているため。データにアクセスする際の認証の煩わしさはありません。稼動中はGoogle Chartsでデータを可視化したり、線グラフを描画したりできます。活発なPythonコミュニティの公開ノートブックで学習することもできます。統計や機械学習などに対応する、多数のパッケージもあります。

# Google Cloud 機械学習プラットフォーム
機械学習（ML）は人工知能分野の１部門です。問題を解決するために明示的にソリューションをコード化するのではなく、時間とともに自ら改善するシステムを人間のコード作成者が構築し、トレーニングデータというサンプルデータを繰り返し処理させます。MLを使用している主要なGoogleアプリにはYouTube、フォト、Googleモバイルアプリ、 Google翻訳などがあります。Google MLプラットフォームが、クラウドサービスとして提供されているので、革新的な機能を独自のアプリに追加できます。Cloud Machine Learning Platformは最新のMLサービスを提供します。事前トレーニング済みモデルを備え、カスタムモデルも生成できます。他のGCPサービスと同様にサービスの幅は広く汎用サービスからカスタマイズ済みのサービスまであります。TensorFlowという、オープンソースのソフトウェアライブラリはニューラルネットワークなどのMLアプリで並外れた効果を発揮します。 これはGoogle Brainが社内用に開発し、世界に役立つようオープンソース化したものです。TensorFlowはどこでも実行できますが、理想的な場所はGCPです。MLモデルには大量のオンデマンドリソースとトレーニングデータが必要だからです。TensorFlowでは、Tensor Processing Unit（TPU）も利用できます。これはTesorFlowでのMLワークロードを加速化できるハードウェアデバイスです。GCPではCompute Engine VMを使ってクラウドでTPUを利用できます。Cloud TPU１個あたりのパフォーマンスは 最大180 TFLOPSです。料金は使用した分だけなので、先行資本投資は不要です。より高レベルなマネージドサービスが必要な場合は、Google Cloud Machine Learning Engineを使用すれば、サイズを問わずあらゆるデータの MLモデルを簡単に構築できます。任意のTensorFlowモデルを使用して、大規模なトレーニングを マネージドクラスタ上で行えます。アプリにさまざまなML機能を追加したいが、機能の細々とした仕組みについては気にしたくない場合は、Google Cloudの特定の目的用の一連のML APIを利用することができます。これについては後ほど説明します。Cloud Machine Learning Platformは さまざまなアプリに使用されています。用途には主に２つのカテゴリがあります。構造化データの処理と非構造化データの処理です。構造化データを処理する場合 MLを使用して各種の分類タスクと 回帰タスクを行うことができます。顧客離れ分析、 製品の診断、予測などです レコメンデーションエンジンの中心として コンテンツのパーソナライズ、 クロスセル、アップセルに対応できます。MLを使って不正検出、センサー診断、 ログ指標で異常を検出することも可能です。非構造化データを処理する場合、MLを画像分析に使用して配送品の損傷やスタイルの識別、 コンテンツの報告などを行えます。テキスト分析にも使用できます。コールセンター、ブログ分析、言語の識別、トピックの分類、感情分析などです。とりわけ革新的なMLアプリの多くは、こうした複数のアプリを組み合わせたものです。ある顧客が SNS で あなたの商品に好意的な投稿をした際に、アプリが自動的にその顧客に連絡して顧客が好みそうな別の商品の割引を提示したとしたらどうでしょう。Google Cloud Machine Learning Platformでは、こうした双方向性を簡単に実現できます。

# 機械学習 API
Cloud Vision APIを使用して 画像の内容を理解することができます このAPIは 画像を何千ものカテゴリに 高速で分類します ヨット、ライオン、エッフェル塔などに分類して 画像内の個々の物体を検出したり 画像内の印刷文字を 見つけて読み上げたりできます ここで取り上げる他のAPIと同じように 使いやすいAPIの背後には 高度なMLモデルが組み込まれています このAPIを使用して 画像カタログのメタデータの作成 不適切なコンテンツの管理 画像の感情分析を行えます

Cloud Speech APIで 音声をテキストに変換できます グローバルなユーザーベースに対応するため このAPIは80を超える言語と方言を認識します アプリのマイクで入力された 音声の文字起こしや 音声コマンドコントロールの有効化、 音声ファイルの文字起こしが可能です Cloud Natural Language APIは 自然言語を理解するための さまざまなテクノロジーを提供します このAPIは構文を解析でき ユーザーが入力した文を トークンに分割し 各トークンで名詞、動詞、形容詞などの 品詞を識別して単語間の関係を把握します エンティティ認識も可能です テキストを解析して 人、組織、場所、イベント、商品、 メディアの言及にフラグを立てます テキストブロックで表現されている 感情を総合的に読み取ることもできます これらの機能は英語、スペイン語、日本語など 複数の言語で使用できます

Cloud Translation APIを使って シンプルでプログラム可能なインターフェースで 任意の文字列を サポートされている言語に翻訳できます 原文の言語が不明でもAPIが特定できます Cloud Video Intelligence APIは 各種形式の動画にアノテーションを付け 動画内の主要エンティティ（名詞）を識別し それらが出現するタイミングを特定できます このAPIを使用すれば動画コンテンツの 検索と検出が可能になります この動画の収録時点では Cloud Video Intelligenceサービスは ベータ版です GCPウェブサイトで最新情報を確認してください

# 復習
このモジュールでは、このコースの内容を振り返ります。コースの冒頭で、インフラの各段階について説明しました。マネージドインフラから、動的インフラまでの段階です。GCPのコンピューティングサービスは、この段階に沿って用意されています。
Googleのインフラで実行されるVMにアプリをデプロイする場合は、Compute Engineを選びます。
Googleのインフラで実行されるコンテナにアプリをデプロイする場合は、Kubernetes Engineを選びます。定義したKubernetesクラスタが管理されます。
コードに集中したい場合は、App Engineを選びます。インフラとプロビジョニングの大部分をGoogleに任せられます。App Engineフレキシブル環境では、[任意のランタイム]を使えます。アプリを実行する環境を完全に制御できます。App Engineスタンダード環境では、いずれかの[標準ランタイム]を選択します。[きめ細かくスケールでき、ゼロにもスケールできます]。
インフラをまったく管理したくない場合は、Cloud Functionsを使用してアプリを構築または拡張します。ビジネスロジックのコードを渡せば、コードはイベントに応じてオンデマンドで起動されます。

GCPでは、さまざまな方法で受信トラフィックの負荷を分散できます。
グローバルHTTP(S)負荷分散では、１つのエニーキャストIPの背後にウェブアプリを配置できます。世界中のリージョンのバックエンド インスタンス間で負荷が分散されます。GCPのコンテンツ配信ネットワークとも統合されています。トラフィックがHTTPでもHTTPSでもない場合、グローバルTCPまたはSSLプロキシを使用できます。[他のポートを使う場合やUDPトラフィックの場合は、リージョンロードバランサ]を使用します。多層アプリの内部層の負荷分散には内部ロードバランサを使用します。

GCPでは、さまざまな方法でオンプレミスや他のクラウドネットワークとGoogle VPCを相互接続できます。
VPNの設定は簡単で、Cloud Routerによって動的にルーティングできます。Googleとのピアリングも可能です。世界中のPOPで直接接続するか、キャリアパートナーを介して接続できます。SLAが必要で、ネットワークトポロジ要件を満たせる場合は Dedicated Interconnectを使用できます。

Cloud Datastoreが適しているのは、構造化データを格納する場合やトランザクションやSQLに似たクエリのサポートが必要な場合です。
Cloud Bigtableが適しているのは、構造化オブジェクトなどの単一キーのデータを大量に格納する場合です。
Cloud Storageが適しているのは、不変のバイナリオブジェクトの格納です。
Cloud SQLまたはCloud Spannerは、OLTPシステムに完全なSQLサポートが必要な場合に使用します。Cloud SQLはテラバイト規模の容量を提供し、 Cloud Spannerはペタバイト規模の容量と水平スケーラビリティを提供します。
BigQueryが適しているのは、OLAPシステムで対話式クエリとペタバイト規模の容量が必要な場合です。

今取り上げたサービスのうち、Cloud Storageには４つのストレージクラスがあります。Multi-RegionalとRegionalは、アクセス頻度が高いデータ用のクラスです。世界中のウェブユーザーに配信するコンテンツにはMulti-regionalを使用します。計算処理に使用するデータの格納には、Regionalを使用します。NearlineとColdlineは アクセス頻度が低いデータ用のクラスです。バックアップや頻繁にアクセスしないコンテンツ用にはNearlineをアーカイブや災害復旧用にはColdlineを使用します。

