# コース概要
AWSプロフェッショナルのためのGoogle Cloud Fundamentalsトレーニングコースへようこそ。このコースの目的は、既存のAWSの知識を活用し、Google Cloudの概要を知っていただくことです。Google Cloudの提供するサービスは、大きく分けて、コンピュート、ストレージ、ビッグデータ、機械学習、Web、モバイル、分析、バックエンドソリューションのためのアプリケーションサービスに分類されます。ビデオ、クイズ、ハンズオンラボを組み合わせることで、Google Cloudの価値と、クラウドソリューションがどのようにビジネス戦略に組み込まれるかを学ぶことができます。このコースの対象者は、Google Cloud上にアプリケーションを展開し、アプリケーション環境を構築することを計画しているソリューション、開発者、システム、運用担当者、ソリューションアーキテクトを想定しています。このコースは、Google Cloudを評価するビジネス意思決定者にとっても有益です。そう言っていただけると嬉しいのですが、このコースではGoogle Cloudに特化したサービスや概念について知ることができます。基礎レベルのコースであるため、クラウド技術を全く知らない学習者向けの内容もあることを念頭に置いてください。このコースに前提条件はありませんが、アプリケーション開発、Linux OS、システム運用、データ分析、機械学習などに精通していることが、このコースで扱う技術を最もよく理解するために役に立ちます。このコースでは、5つの主要な学習目標を達成することを目的としています。このコースを終了するまでに、次のことができるようになります。 Google クラウド製品およびサービスの目的と価値を確認することができる。アプリエンジン、Google Cooper 90s エンジン、コンピュートエンジンのような Google Cloud 上のアプリケーション デプロイメント環境を選択し、使用することができる。Cloud Storage、Cloud sequel、Cloud Big Table、Fire Store などの Google Cloud ストレージオプションを選択して使用できる Google Cloud サービスに触れ、顧客が Google Cloud を使用した方法を説明できる さて、準備万端、始めましょう。

# Cloud computing overview
まずは、クラウドコンピューティングの概要からご紹介します。

クラウドは最近話題になっていますが、そもそもクラウドとは何でしょうか？

クラウドコンピューティングという言葉は、アメリカの国立標準技術研究所（National Institute of Standards and Technology）が作ったものです。米国に特化したものではありませんが。クラウドコンピューティングとは、情報技術（IT）の利用方法の一つで、次の5つの特徴を等しく持っています。

第一に、顧客はウェブインターフェースを通じて、オンデマンドかつセルフサービスであるコンピューティングリソースを手に入れることができます。ユーザーは、人間の介入を必要とせずに、必要な処理能力、ストレージ、ネットワークを手に入れることができるのです。

第二に、顧客はインターネットを通じて、接続できる場所であればどこからでもこれらのリソースにアクセスできるようになります。

第三に、クラウドプロバイダーはこれらのリソースの大きなプールを持ち、そのプールからユーザーにリソースを割り当てる。これにより、プロバイダーは大量に購入し、その節約分を顧客に還元することができるのです。

顧客は、それらのリソースの正確な物理的位置を知る必要も、気にする必要もない。

第4に、リソースは弾力的である。つまり、柔軟性があり、顧客はそうすることができる。より多くのリソースが必要な場合は、より多くのリソースを迅速に入手できますし、必要なリソースが少ない場合は、規模を縮小することができます。そして最後に、お客様は使用した分だけの支払い、または使用した分だけの予約をすることができます。リソースの使用を止めれば、支払いも止まります。

それが、クラウドの定義です。

しかし、なぜ今、クラウドモデルがこれほどまでに説得力を持つのでしょうか？その理由を理解するためには、いくつかの歴史を見てみる必要がある。

クラウドコンピューティングへの流れは、コロケーションと呼ばれる最初の波から始まりました。コロケーションは、データセンターの不動産に投資する代わりに、物理的なスペースをレンタルすることで経済的な効率をユーザーに提供するものでした。

今日の仮想化データセンターは、第二の波であり、過去数十年のプライベートデータセンターやコロケーション施設と類似している。
2:そこから始まる動画再生、トランスクリプトに従ってください。
仮想化データセンターの構成要素は、ホストコンピューティングサーバーの物理的なビルディングブロックと一致しています。CPU、ディスク、ロードバランスなどですが、現在は仮想化されたデバイスになっています。仮想化によって、企業はインフラを維持しながらも、ユーザーが制御し、設定する環境を維持することができます。

数年前、Googleは、仮想化モデルの枠内ではビジネスが十分に速く進めないことに気づきました。

自動化されたサービスとスケーラブルなデータサービスの組み合わせで構成され、アプリケーションの実行に使用されるインフラを自動的にプロビジョニングし設定する、完全自動の弾性サードウェーブクラウドです。

今日、Google Cloudは、彼のサードウェーブクラウドをgoogleの顧客が利用できるようにしています。

Googleは、将来的には規模や業種に関係なく、すべての企業がテクノロジーによって競合他社と差別化されるようになると考えています。

そのテクノロジーは、ますますソフトウェアの形になっていくでしょう。優れたソフトウェアは、高品質のデータに基づいています。

これは、すべての企業がデータ企業である、あるいはいずれデータ企業になるということを意味している。

# IaaS and PaaS
データセンターの仮想化により、お客様には2つの新しいタイプのサービスが提供されるようになりました。一般にIaaSと呼ばれるInfrastructure as a Serviceと、PaaSと呼ばれるPlatform as a Serviceです。IaaSは、生の計算、ストレージ、およびネットワーク機能を、物理データセンターと同様のリソースに仮想的に編成して提供するものです。これに対し、PaaSは、アプリケーションに必要なインフラへのアクセスを提供するライブラリにコードをバインドします。これにより、より多くのリソースをアプリケーションロジックに集中させることができます。IaaSモデルでは、顧客は事前に割り当てたリソースに対して料金を支払います。PaaSモデルでは、顧客は実際に使用するリソースに対して料金を支払います。クラウドコンピューティングの進化に伴い、マネージドインフラストラクチャとマネージドサービスに勢いが移っています。マネージド・リソースとサービスを活用することで、企業はビジネス目標により集中することができ、技術インフラの構築と維持に費やす時間と費用を削減することができます。また、顧客に対してより迅速かつ信頼性の高い製品やサービスを提供することができます。サーバーレスは、クラウドコンピューティングの進化における新たなステップです。サーバーレスでは、インフラ管理の必要性がなくなるため、開発者はサーバーの設定よりもコードに集中することができます。Googleが提供するサーバーレス技術には、イベント駆動型のコードを従量制サービスとして管理するCloud Functionsや、コンテナ化したマイクロサービスベースのアプリケーションを完全管理環境でデプロイできるCloud Runがあります。このコースの範囲外ですが、Software as a Service（SaaS）について聞いたことがあり、それが何であり、クラウドの生態系にどのように適合するのか不思議に思ったことがあるかもしれません。SaaSとは、Software as a Serviceの略で、ローカルコンピュータにインストールされるのではなく、クラウド上で動作するアプリケーションです。その代わり、サービスとしてクラウド上で実行され、エンドユーザーがインターネット上で直接利用することになる。Googleワークスペースの一部であるGmail、Docs、Driveなどの人気のあるGoogleアプリケーションは、すべてSaaSの例です。

# Google CloudとAWSのリージョンとゾーンの比較
GoogleとAWSは共に、顧客にクラウドサービスを提供する方法としてリージョンを使用している。1つ違うのは、Googleもデータセンターサービスを提供するためにゾーンを使用しており、すべてのリージョンに少なくとも3つのゾーンがあることだ。AWSは、高可用性を提供する方法として、アベイラビリティゾーンと呼ばれるデータセンターのクラスターを使用している。各リージョンには、少なくとも2つのアベイラビリティゾーンがある。Google CloudとAWSの両方は、世界中のより多くの場所にあるPOP（Point of Presence）を持っています。これらのポイント・オブ・プレゼンス・ロケーションは、エンドユーザーのより近くでコンテンツをキャッシュするのに役立ちます。しかし、それぞれのプラットフォームは、異なる方法でそれぞれのPOSを使用しています。Google Cloudは、Cloud CDNを提供し、App EngineやCloud Storageなどのサービスにビルトインされたエッジキャッシュを提供するために、Point of Presenceを使用しています。AWSは、コンテンツ配信ネットワークサービスであるAmazon Cloud Frontや、Lambda at the Edgeなどのエッジキャッシングサービスを提供するために、Point of Presenceを使用しています。Google CloudのPOSは、Googleが所有する光ファイバーでデータセンターを結んでいます。この障害物のない接続により、Google Cloudベースのアプリケーションは、Google Cloud上のすべてのサービスに高速かつ確実にアクセスできることになる。要約すると、リージョンとゾーンに関連する用語について見てみよう。Google CloudとAWSの両製品は、互いに比較的近いデータセンターとサービスのクラスターを定義するためにリージョンという用語を使用している。データセンターのサービスと可用性は、Google Cloudではゾーンに抽象化することができ、これはAWSのアベイラビリティゾーンに相当するものである。Google Cloudはpopsを利用して、App EngineやCloud Storageなどの複数のサービスにビルトインのエッジキャッシングを提供している。AWSも同様の方法でエッジキャッシングを提供している。

# Google Cloudのネットワーク
Google Cloudは、Google独自のグローバルネットワーク上で動作しています。Googleのネットワークは、この種のものとしては最大です。Googleはその構築のために、何年もかけて何十億ドルも投資してきました。このネットワークは、世界中にある100以上のコンテンツ・キャッシング・ノードを活用し、お客様のアプリケーションに可能な限り高いスループットと低いレイテンシーを提供するよう設計されています。これらは、需要の高いコンテンツがより速くアクセスできるようにキャッシュされる場所で、アプリケーションは最も速い応答時間を提供する場所からユーザーのリクエストに応答できるようになります。Google Cloudのインフラは、北米、南米、ヨーロッパ、アジア、オーストラリアの5つの主要な地域に拠点を置いています。なぜなら、アプリケーションの設置場所を選ぶことは、可用性、耐久性、レイテンシーといった品質に影響を与えるからです。これらのロケーションはそれぞれ、いくつかの異なる地域やゾーンに分けられます。リージョンは、ゾーンで構成される独立した地理的なエリアを表します。例えば、ロンドン、またはヨーロッパ西2地域は、現在3つの異なるゾーンから構成されている地域です。ゾーンは、Google Cloud のリソースが配置される領域である。例えば、コンピュートエンジンを使って仮想マシンを起動すると、リソースの冗長性を確保するために、指定したゾーンで実行される。また、異なる地域でリソースを実行することもできる。これは、世界中のユーザーにアプリケーションを近づけるため、また自然災害など地域全体に問題が発生した場合の保護に有効です。Google Cloudのサービスの中には、マルチリージョンと呼ばれるようなリソースの配置をサポートしているものがある。例えば、クラウドストレージでは、ヨーロッパのマルチリージョンにデータを置くことができます。これは、ロンドンとベルギーのように、ヨーロッパ内で160km以上離れた、少なくとも2つの地理的な場所に冗長的に保存されることを意味します。Google Cloudは現在、29地域、88ゾーンをサポートしている。この数は常に増加しているが。最新の数字はcloud.google.com/about/locationsで見ることができます。

# 環境負荷
Google Cloudのネットワークを含む仮想世界は、物理的なインフラの上に構築されており、鼻歌を歌うサーバーのラックはすべて、膨大な量のエネルギーを消費しています。既存のデータセンターを合わせると、世界の電力のおよそ2％を消費していることになります。このことを念頭に置き、Googleはデータセンターを可能な限り効率的に稼働させるよう取り組んでいます。お客様と同じように、Googleも地球のために正しいことをしようとしています。Google Cloudをご利用のお客様は、それぞれ環境に関する目標をお持ちだと思いますが、Google Cloud上で作業着を稼働させることは、その目標を達成するための一部となり得ると考えています。そのため、GoogleのデータセンターがISO 14001認証を最初に取得したことは有益なことです。ISO14001は、資源効率の向上と廃棄物の削減を通じて、組織が環境パフォーマンスを強化するための枠組みを示した規格です。

その一例として、フィンランドのハミナにあるグーグルのデータセンターをご紹介します。この施設は、Googleのデータセンターの中でも最も先進的で効率的なものの1つです。フィンランド湾の海水を利用した冷却システムは、エネルギー使用量を削減し、この種のものとしては世界初となります。創業の10年間で、グーグルは大手企業として初めてカーボンニュートラルを達成しました。2年目には、再生可能エネルギー100％を達成した最初の企業になりました。2030年までには、完全にカーボンフリーな運営を行う最初の大企業になることを目指しています。

# セキュリティ
Googleの9つのサービスにはそれぞれ10億人以上のユーザーがいるため、Googleの社員が常にセキュリティを意識していることは間違いないでしょう。GoogleクラウドとGoogleサービスが稼働するインフラ全体に、セキュリティのための設計が行き届いているのです。

Googleが顧客のデータを安全に保つために行っているいくつかの方法についてお話します。

セキュリティインフラは、データセンターの物理的なセキュリティから始まり、インフラの基盤となるハードウェアとソフトウェアのセキュリティ、そして最後に運用セキュリティを支えるための技術的な制約とプロセスまで、段階的に説明することができます。

まず、3つの主要なセキュリティ機能で構成されるハードウェア基盤層から始めます。

1つ目は、ハードウェアの設計と出所です。Googleのデータセンターでは、サーバーボードもネットワーク機器も、Googleがカスタム設計しています。

Googleはまた、現在サーバーと周辺機器の両方に配備されているハードウェアセキュリティチップを含むカスタムチップを設計しています。

次の機能は、セキュアブートスタックです。

Googleのサーバーマシンは、バイオ、ブートローダ、カーネル、基本オペレーティングシステムイメージに対する暗号署名など、正しいソフトウェアスタックを起動するためのさまざまな技術を使用しています。このレイヤーの最後の特徴は、構内セキュリティです。Googleは、何重もの物理的なセキュリティ保護を組み込んだ独自のデータセンターを設計・構築しています。

これらのデータセンターへのアクセスは、ごく少数のグーグル社員だけに制限されている。

Googleはさらに、一部のサーバーをサードパーティのデータセンターでホストしており、データセンター事業者が提供するセキュリティ層に加えて、Googleが管理する物理的なセキュリティ対策が施されていることを保証しています。

次にサービス展開レイヤですが、ここではサービス間通信の暗号化が大きな特徴となっています。

Googleのインフラは、ネットワーク上のリモートプロシージャコールRPCデータに対して、暗号によるプライバシーと完全性を提供します。

Googleのサービスは、RPCコールを使って相互に通信します。インフラストラクチャは、データセンター間を行き来するすべてのインフラストラクチャのRPCトラフィックを自動的に暗号化します。

Googleは、このデフォルトの暗号化をGoogleデータセンター内のすべてのインフラストラクチャーRPCトラフィックに拡張できるハードウェア暗号アクセラレーターの配備を開始しました。

次に、ユーザーIDレイヤーがあります。

Google Central Identityサービスは、通常エンドユーザーにGoogleのログインページとして表示され、単純なユーザー名とパスワードの入力を求めるだけではありません。

また、過去に同じ端末や同じような場所からログインしたことがあるかなどのリスク要因に基づいて、追加情報を求めるインテリジェントなサービスも提供しています。

ユーザーは、ユニバーサルセカンドファクターU2Fオープンスタンダードに基づくデバイスを含め、サインイン時にセカンダリーファクターを使用することもできます。ストレージサービス層では、encryption at restセキュリティ機能を見つけることができます。

Googleのほとんどのアプリケーションは、ストレージサービスを介して間接的に物理ストレージ、つまりファイルストレージにアクセスし、これらのストレージサービスのレイヤーで、一元管理された鍵を使った暗号化が適用されます。

Googleはまた、ハードディスクとSSDでハードウェア暗号化のサポートを可能にします。

次のレイヤーは、インターネット通信レイヤーです。そしてこれは2つのセキュリティ機能で構成されている。

インターネット上で公開されているGoogleのサービスは、Googleフロントエンドと呼ばれるインフラサービスに登録されており、すべてのTLS接続が公開秘密鍵ペアと認証局CAのX0.509証明書を使用して終了することを保証し、完全前方秘匿のサポートなどのベストプラクティスに従います。

GFEはさらに、サービス妨害（DoS）攻撃からの保護も適用しています。

また、サービス妨害（DoS）対策も提供されています。Googleは、そのインフラ規模の大きさにより、多くのDoS攻撃を単純に吸収することができます。また、Google は多層的な DoS 防御を備えており、GFE の背後で動作するサービスに対する DoS 攻撃のリスクをさらに低減しています。

最後のレイヤーは、Googleの運用セキュリティレイヤーで、4つの主要な機能を提供します。

1つ目は、侵入検知です。ルールとマシン・インテリジェンスが、Googleの運用セキュリティ・チームにインシデントの可能性を警告する。

Googleは、検知・対応メカニズムの有効性を測定・改善するためにレッドチーム演習を実施しています。

次に、リスク内部の低減です。Googleは、インフラへの管理アクセスを許可された従業員の活動を積極的に制限し、積極的に監視しています。

Googleの従業員に対するフィッシング攻撃を防ぐため、従業員アカウントではU2F互換のセキュリティキーの使用が義務付けられています。

最後に、厳格なソフトウェア開発の実践があります。Googleの社員は厳密なソース管理を行い、新しいコードには二者間レビューを要求しています。また、Googleは開発者に、ある種のセキュリティバグの発生を防ぐためのライブラリを提供しています。

さらに、Google は、インフラストラクチャやアプリケーションのバグを発見して知らせてくれた人に報酬を支払う、脆弱性報奨プログラムを実施しています。

Googleの技術的なインフラセキュリティについては、cloud.google.com/security/security-designで詳しく知ることができます。

# Open source ecosystems
特定のベンダーに縛られることを恐れて、ワークロードをクラウドに移行することを躊躇する企業もあるようです。しかし、何らかの理由でGoogleが自分たちのニーズに最適なプロバイダーでなくなったと判断した場合、アプリケーションを別の場所で実行する能力をお客様に提供するのです。Googleは、技術の重要な要素をオープンソースライセンスで公開し、顧客にGoogle以外の選択肢を提供するエコシステムを構築しています。例えば、Google社内で開発された機械学習のためのオープンソースソフトウェアライブラリであるTensorFlowは、強力なオープンソースエコシステムの中核を成しています。Googleが提供する相互運用性それはスタックの複数のレイヤーです。KubernetesとGoogle Kubernetes Engineは、異なるクラウドで動作するマイクロサービスを混在させる機能を提供し、Google Clouds Operations Suiteは、複数のクラウドプロバイダでワークロードを監視することを可能にします。

# Pricing and billing
この講座の締めくくりとして Google cCoudsの料金体系を簡単に見てみましょう。Googleは、主要なクラウドプロバイダーとして初めて、Infrastructure as a Service Computeの提供であるCompute Engineに秒単位の課金を実現しました。さらに、コンテナインフラストラクチャAs a ServiceであるGoogle Kubernetes Engineの利用に対しても、秒単位の課金が提供されるようになった。ビッグデータシステム「Hadoop」に相当する「Data」もサービスとして稼働しています。そして、プラットフォーム・アズ・ア・サービスであるApp Engineの柔軟な環境VMS、これらの製品・サービスについては、後ほど講座でご紹介します。Compute Engineは、課金月のかなりの期間、仮想マシンインスタンスを実行すると自動的に割引が適用される、持続的利用割引を提供しています。具体的には、1ヶ月のうち25%以上インスタンスを実行すると、そのインスタンスで使用した分単位で自動的に割引が適用されます。カスタム仮想マシンタイプにより、コンピュートエンジンの仮想マシンを、アプリケーションに最適なVCPUとメモリの量で微調整できるため、ワークロードに合わせて価格を調整することができます。オンライン価格計算ツールは、cloud.google.com/products/calculatorで試算することができます。Google Cloud の利用料金が高額にならないようにするには、どうすればよいのでしょうか。課金アカウントレベルまたはプロジェクトレベルで予算を定義することができます。予算は、固定された限度額とすることも、前月の支出額に対する割合など、他の指標に関連付けることもできます。コストが予算の上限に近づいたときに通知を受けるには、例えば、予算の上限を2万ドル、アラートを90%に設定してアラートを作成することができます。経費が18,000ドルに達すると通知アラートが届きます。アラートは一般的に50%、100%に設定されていますが、カスタマイズすることも可能です。レポートは、Google Cloudコンソールのビジュアルツールで、プロジェクトやサービスに基づいて支出を監視することができる。最後に、Google Cloudは、エラーや悪意ある攻撃によるリソースの過剰消費を防ぐためのクォータも実装している。アカウント所有者とGoogle Cloudコミュニティ全体の両方を保護する。クォータにはレートクォータとアロケーションクォータの2種類があります。どちらもプロジェクトレベルのレートクォータで返信され、特定の時間が経過するとリセットされます。例えば、デフォルトでは、GKサービスは各Google CloudプロジェクトからのAPIへの呼び出しを100秒に1000回というクォータを実装している。その100秒後に制限はリセットされる割り当てクォータは、プロジェクトで持つことができるリソースの数を管理する。例えば、デフォルトでは、各Google Cloudプロジェクトは、5つ以下の仮想プライベートクラウドネットワークを許可するクォータを持っている。プロジェクトはすべて同じクォータで開始されるが、Google Cloudのサポートに増加のリクエストをすることで、その一部を変更することができる。

# 3
# Google Cloudのリソース階層
このセクションでは、Google Cloudの機能構造について見ていきます。Google Cloudのリソース階層は、4つのレベルを含んでいます。下から順に、リソース、プロジェクト、フォルダー、組織ノードがあります。最初のレベルでは、リソースがある。これらは仮想マシン、Cloud Storageバケット、BigQueryのテーブル、その他Google Cloudにあるあらゆるものを表している。リソースはプロジェクトに整理され、第二階層に位置する。プロジェクトはフォルダーやサブフォルダーにまとめることができる。これらは第3階層に位置する。そしてトップレベルには、組織内のすべてのプロジェクト、フォルダー、リソースを包含する組織ノードがある。このリソース階層を理解することは、Google Cloud を使用する際にポリシーがどのように管理され適用されるかに直接関係するため、重要である。ポリシーは、プロジェクト、フォルダー、組織ノードの各レベルで定義することができる。Google Cloudのサービスによっては、個々のリソースにポリシーを適用することもできる。ポリシーは下方に継承される。つまり、あるフォルダにポリシーを適用すると、そのフォルダ内のすべてのプロジェクトにも適用される。リソース階層の2番目のレベルであるプロジェクトについて、もう少し詳しく見てみましょう。プロジェクトは、Google Cloud Servicesを有効にして使用するための基礎となるものである。例えば、APIの管理、課金の有効化、共同作業者の追加と削除、その他のGoogleサービスの有効化などである。各プロジェクトは、組織ノードの下にある独立したエンティティであり、各リソースは正確に1つのプロジェクトに属している。プロジェクトは別々に構築、管理されるため、異なるオーナーやユーザーを持つことができる。各Google Cloudプロジェクトは、3つの識別属性を持つ。プロジェクトID、プロジェクト名、そしてプロジェクト番号だ。プロジェクトIDはGoogleによって割り当てられたグローバルにユニークな識別子で、作成後に変更することはできない。これを私たちはイミュータブル（immutable）と呼んでいる。プロジェクトIDは、Google Cloudに作業する正確なプロジェクトを知らせるために、さまざまな文脈で使用される。しかし、プロジェクト名はユーザーが作成するものである。プロジェクト名はユニークである必要はなく、いつでも変更可能であるため、不変ではありません。また、Google Cloudは各プロジェクトに一意のプロジェクト番号を割り当てている。これらのGoogleが生成した番号が存在することを知っておくと便利ですが、このコースではあまり調べません。この番号は主にGoogle Cloudがリソースを追跡するために内部的に使用されています。Google CloudのResource Managerツールは、プロジェクト管理をプログラム的に支援するために設計されています。これはAPIで、アカウントに関連するすべてのプロジェクトのリストを収集し、新しいプロジェクトを作成し、既存のプロジェクトを更新し、プロジェクトを削除することができます。以前に削除されたプロジェクトを復元することも可能で、RPC APIとREST APIでアクセスすることができる。Google Cloudのリソース階層の第3階層はフォルダーである。フォルダーでは、選択した粒度のリソースにポリシーを割り当てることができる。フォルダー内のリソースは、そのフォルダーに割り当てられたポリシーとパーミッションを継承する。フォルダは、プロジェクト、他のフォルダ、またはその両方の組み合わせを含むことができます。フォルダを使用すると、階層構造で組織の下にプロジェクトをグループ化できます。たとえば、組織には複数の部門があり、それぞれが独自の Google Cloud リソースのセットを持っている場合があります。フォルダを使用すると、部門ごとにこれらのリソースをグループ化することができます。また、フォルダを利用することで、各チームが独立して作業できるように管理権限を委譲することができる。先に述べたように、フォルダ内のリソースは、そのフォルダのポリシーとパーミッションを継承する。例えば、同じチームが管理する2つの異なるプロジェクトがある場合、ポリシーを共通のフォルダに入れることで、同じパーミッションを持たせることができます。他の方法で行う。両方のプロジェクトにそれらのポリシーの重複したコピーを置くことは、面倒でミスを犯しやすいものです。両方のリソースのパーミッションを変更する必要がある場合、1か所だけでなく、2か所でそれを行う必要があります。フォルダを使用するには、Google Cloudの階層構造で最上位のリソースである組織ノードを持つ必要がある。そのアカウントに付属する他のすべては、フォルダ、プロジェクト、および他のリソースを含む、このノードの下に行く。この最上位の組織ノードには、いくつかの特別なルールが関連付けられています。たとえば、組織ポリシー管理者を指定して、適切な権限を持つ人だけがポリシーを変更できるようにすることができます。また、プロジェクト作成者の役割を割り当てることができます。これは、誰がプロジェクトを作成することができますので、誰がお金を使うことができるかを制御するための素晴らしい方法です。新しい組織ノードの作成方法は、あなたの会社がGoogleワークスペースの顧客でもあるかどうかによって異なります。ワークスペース・ドメインを持っている場合、Google Cloudプロジェクトは自動的に組織ノードに所属することになる。そうでない場合は、Google の Identity Access アプリケーションと Endpoint Management Platform である Cloud Identity を使用して生成することができます。
新しい組織ノードを作成すると、ドメイン内の誰でも、以前と同じようにプロジェクトや課金アカウントを作成できるようになります。また、その下にフォルダーを作成し、プロジェクトをその中に入れることもできます。フォルダとプロジェクトの両方は、組織ノードの子とみなされます。

# Google CloudとAWSのリソース階層を比較する
Google CloudとAWSでは、リソース階層が異なるため、課金にも違いがあります。Google Cloudの場合、すべてのリソースとサービスはプロジェクトで活用されなければならず、プロジェクトで構築されたものはすべてそのプロジェクトにビルドされる。Google Cloudでは、柔軟な課金モードが用意されている。各プロジェクトは独自の課金アカウントを持つことができる。1つの課金アカウントを組織全体で使用することも、必要に応じて任意の組み合わせで構成することも可能だ。この図では、課金はボトムアップ、リソース、ビルドプロジェクトから始まっているが、課金はフォルダや組織レベルでも適用することができる。デフォルトでは、各AWSアカウントは独自の課金アカウントを持っています。複数のアカウントを1つの課金アカウントにまとめるには、連結課金を設定する必要があり、下位のメンバーアカウント群にリンクする1つの管理アカウントを作成する。各アカウントには、そのアカウントを制御するためのルートユーザーまたはスーパーユーザーが存在します。ルートユーザーは、そのアカウント内のすべてのリソースにアクセスできますが、それ以外にはアクセスできません。アカウント数が増えると、リンク構造が複雑になることがある。また、複数のアカウントを、自分で作成した一つの組織に統合し、一元管理することも可能です。アカウントをグループ化して統合請求したり、アカウント内のユーザーやロールのサービスへのアクセスをブロックするポリシーを添付したり、これらのポリシーがアカウントポリシーを上書きしたりすることができます。Google Cloudリソースの主な差別化ポイントは、複数の課金アカウント、プロジェクトごとの課金グループ、そしてよりシンプルな階層管理です。AWSでは1つのアカウントに1つの課金アカウントが必要だが、Google CloudではGoogle Cloudのアカウントごとに多くの課金アカウントを柔軟に持つことができる。AWSではサブアカウント単位で課金するのに対し、Google Cloudではプロジェクト単位で課金することができる。Google Cloudはアカウント、組織、フォルダ、プロジェクトレベルでポリシーを適用できるが、AWSはアカウントと組織レベルでのみポリシーを適用できる。アカウント管理者は、Google CloudではGoogleユーザーまたはグループ、AWSではアカウント管理者用のグループとロールを持つIAMユーザーを使用することができます。Google Cloudのアカウントは、GmailユーザーやGoogleワークスペースのスーパーユーザーを管理者として持つことができます。AWSでは、アカウントを管理するために独自のRootユーザが必要です。

# Identity and Access Management (IAM)
組織ノードに多くのフォルダ、プロジェクト、リソースが含まれる場合、誰が何にアクセスできるかを制限する必要がある場合があります。このタスクを支援するために、管理者はアイデンティティとアクセス管理またはIAMを使用することができます。IAMを使用すると、管理者は、誰がどのリソースで何を行うことができるかを定義するポリシーを適用することができます。IAMのポリシーは、Googleアカウント、Googleグループ、サービスアカウント、クラウドアイデンティティドメインのいずれかを指定することができます。

鉄のポリシーのどの部分を実行できるかはロールによって定義され、IAMロールは権限の集合体である。例えば、プロジェクトで仮想マシンインスタンスを管理するには、仮想マシンを作成、削除、開始、停止、変更できる必要があります。そこで、これらの権限をわかりやすく、管理しやすくするためにロールにまとめています。ユーザー、グループ、またはサービスアカウントに、リソース階層の特定の要素に関するロールが与えられると、そのロールは、ユーザー、グループ、またはサービスアカウントに適用されます。その結果、選択された要素と、階層内のその下のすべての要素の両方にポリシーが適用されます。IAMのロールには、基本、事前定義、カスタムの3種類があります。最初のルールタイプは基本で、基本ロールはGoogle Cloudプロジェクトに適用されるとかなり範囲が広くなり、そのプロジェクト内のすべてのリソースに影響します。

基本的な役割には、オーナー、エディター、ビューアー、課金管理者などがあります。これらの基本的な役割について、もう少し詳しく見てみましょう。プロジェクトの閲覧者は、リソースにアクセスすることはできますが、変更を加えることはできません。

プロジェクトエディターはリソースにアクセスし、変更を加えることができ、プロジェクトオーナーもリソースにアクセスし、変更を加えることができます。さらに、プロジェクトオーナーは、関連するロールとパーミッションを管理し、ビルドを設定することができます。

多くの場合、企業は誰かがプロジェクトのビルドを制御したいが、プロジェクトのリソースを変更できないようにしたい。これは、課金管理者の役割によって可能になります。

注意点があります。もし複数の人が機密データを含むプロジェクトで一緒に作業している場合、基本的なルールはおそらく広すぎるでしょう。幸いなことに、私は典型的な職務のニーズを満たすために、より具体的に調整されたパーミッションを割り当てる他の方法を提供しています。

ここで、2つ目のタイプの役割について説明します。Googleのクラウドサービスには、あらかじめ定義されたロールのセットがあり、それらのロールを適用できる場所まで定義されています。

例えば、コンピュートエンジンを使って仮想マシンをサービスとして提供するグーグルクラブの製品を見てみましょう。特定のプロジェクト、特定のフォルダ、または組織全体において、コンピュートエンジンのリソースにインスタンスや管理者など、あらかじめ定義されたロールを適用することが可能です。

これにより、これらのロールを持つ人は、定義された特定のアクションを実行できるようになります。

しかし、さらに特定の権限を持つロールを割り当てる必要がある場合はどうでしょうか。それは、カスタムロールを使用する場合です。多くの企業では最小権限モデルを採用しており、組織内の各人に、業務を遂行するために必要な最小限の権限を与えています。例えば、インスタンスオペレータのロールを見つけて、一部のユーザにコンピュートエンジンの仮想マシンの停止と起動を許可したいが、再構成は許可しないようにしたいとします。カスタム・ロールを使用すると、これらの権限を正確に定義することができます。 カスタム・ロールの作成を始める前に、2つの重要な点に注意してください。まず、作成したカスタム・ロールを定義する権限を管理する必要があります。このため、一部の組織では、定義済みのロールを使用することにしています。第二に、カスタムルールは、プロジェクトレベルまたは組織レベルのいずれかにのみ適用できます。フォルダレベルに適用することはできません。


# Service accounts
もし、個人ではなく、Compute Engine Virtual Machineに権限を与えたい場合はどうすればいいでしょうか？そのためのサービスアカウントです。例えば、クラウドストレージにデータを保存する必要のある仮想マシンでアプリケーションを実行するとします。しかし、インターネット上の誰でもそのデータにアクセスできるようにするのではなく、その特定の仮想マシンのみにアクセスできるようにします。その仮想マシンをクラウドストレージに認証するために、サービスアカウントを作成することができます。

サービスアカウントはメールアドレスで命名されるが、パスワードの代わりに暗号鍵を用いてリソースにアクセスする。つまり、あるサービスアカウントにCompute Engineのインスタンス管理者ロールが付与されている場合、そのサービスアカウントを持つVMで動作するアプリケーションは、他のVMの作成、変更、削除ができるようになります。

サービスアカウントは管理される必要があります。例えば、アリスはどのGoogleアカウントがサービスアカウントとして動作するかを管理する必要があり、一方ボブはサービスアカウントのリストを見ることができればいいのです。幸運なことに、アイデンティティであることに加えて、サービスアカウントはリソースでもあるので、それ自身のIAMポリシーをそれに付加することができます。

これは、アリスがサービスアカウントのエディターロールを持ち、ボブがビューアーロールを持つことができることを意味します。これは他の Google Cloud リソースに対するロール付与と同じです。

# AWS IAMとGoogle Cloud IAMの比較
Google CloudとAWSのIAMは同じ機能を持ち、クラウドのユーザー認証とパーミッションを保護するメカニズムを提供する。IAMはアプリケーションやOSを保護するのではなく、クラウド上で誰が何をできるかを制御するために使用される。GoogleとAWSのIAMは同じ機能を果たすが、その方法は全く異なる。Googleはサービスアカウントを使用して、サービス間の認証を制御する。AWSはIAMのロールとプロファイルを使用してこの制御を行う。Google Cloudの場合、ユーザーIDはGoogle Cloudの外部で管理される。例えば、ワークスペースやGmailアカウントを使ってIDを管理することができる。すでに組織でActive Directoryベースのソリューションを持っているならば、朗報がある。Google Cloudは、Google IDアカウントを追加で作成することなく、ユーザーの統合アクセス管理を提供することができる。これにより、DNSドメイン内の既存のActive Directoryテナントを維持したまま、Google Cloudにプロジェクトを移行することができる。AWSの場合、ユーザーとグループのIDはAWSを使用して作成されます。EC2の場合は、インスタンスプロファイルを使用することもできる。Google Cloudの場合、ポリシーは適用されるロールによってユーザーのパーミッションを設定するバインディングのリストである。ポリシードキュメントは、AWSがユーザーにパーミッションを適用するために使用される。ドキュメントはJSONを使用して構築され、リソース上で適用される。Google Cloudでは、リソース上のユーザーロールペアリングがユーザーの権限を決定する。AWSでは、マネージドポリシーを使用して定義済みのパーミッションを適用することができる。これは、デフォルトのパーミッションを適用するために使用される事前構築されたJSONドキュメントである。最後に、Googleでは、職務上の役割に一致するように構築された事前定義されたロールを使用します。AWSには、マネージドポリシーと呼ばれる同様の機能がある。マネージドポリシーは、ジョブロールによってパーミッションをグループ化するJSONドキュメントである。

# Cloud Identity
Google Cloud の新規顧客がこのプラットフォームを使い始めるとき、Gmail アカウントで Google Cloud コンソールにログインするのが一般的です。そして、Google グループを使用して、同じような役割のチームメイトと共同作業を行います。この方法は簡単に始められますが、チームのアイデンティティが一元管理されていないため、例えば誰かが組織を離れた場合に問題が発生する可能性があり、後々課題となることがあります。この設定では、チームのクラウドリソースへのユーザーのアクセスを即座に削除する簡単な方法がないのです。Cloud Identityは、Google Admin Consoleを使ってポリシーを定義し、ユーザーとグループを管理することができる。管理者は、既存の Active Directory や LDAP システムで使用しているのと同じユーザー名とパスワードを使って Google Cloud リソースにログインし、管理することができる。Cloud Identityを使用すると、誰かが組織を離れる際に管理者がGoogle Admin Consoleを使用してアカウントを無効化し、グループから削除することができる。Cloud Identity は無料版と、モバイルデバイスを管理する機能を備えたプレミアム版がある。Google Cloudの顧客でgoogle workspaceの顧客であれば、この機能はすでにGoogle Admin Consoleで利用可能である。

# Google Cloudとの連動
Google Cloudにアクセスし、対話する方法は4つあります。Cloud Console、Cloud SDK、Cloud Shell。APIとCloudコンソールのモバイルアプリ。では、それぞれを探ってみましょう。Google Cloudコンソールは、Google Cloudのグラフィカル・ユーザー・インターフェース（GUI）であり、シンプルなWebベースのインターフェースでスケールのデプロイや本番環境の問題を診断することができる。クラウドコンソールでは、リソースの検索、健全性の確認、リソースの完全な管理、リソースの使用量を制御するための予算設定などを簡単に行うことができます。また、クラウドコンソールには、リソースを素早く見つけるための検索機能があり、ブラウザからSSH経由でインスタンスに接続することができます。2は、Cloud ShellのクラウドSDKを利用します。Cloud SDKは、googleクラウド上でホストされているリソースやアプリケーションを管理するために使用できるツールのセットです。gcloudツールは、googleクラウドの製品・サービス用のメインコマンドラインインターフェースを提供するものです。コマンドラインからクラウドストレージにアクセスできるGsutilや、BigQuery用のコマンドラインツールであるBQなどがあります。インストールすると、クラウドSDK内のすべてのツールはbinディレクトリの下に配置されます。Cloud Shellは，ブラウザから直接クラウドのリソースにコマンドラインでアクセスできるツールです．Cloud ShellはDebianベースの仮想マシンで、5ギガバイトのホームディレクトリを持つため、googleクラウドのプロジェクトやリソースを容易に管理することができます。Cloud Shellを使えば、Cloud SDK gcloudコマンドやその他のユーティリティが常にインストールされ、完全に認証された状態で利用可能な最新の状態になります。googleクラウドにアクセスする3つ目の方法は、アプリケーション・プログラミング・インターフェース（API）を通じてアクセスする方法です。googleクラウドを構成するサービスは、APIを提供しており、あなたが書いたコードでそれらを制御することができます。クラウドコンソールには、Google APIs Explorerというツールがあり、どのAPIがどのバージョンで利用できるかが表示されます。これらのAPIは、ユーザー認証が必要なものでも対話的に試すことができます。では、APIを探索し、それを使用するアプリケーションを構築する準備ができたとすると、ゼロからコーディングを始める必要があるのだろうか？GoogleはクラウドクライアントライブラリとGoogle APIクライアントライブラリを多くの一般的な言語で提供しており、あなたのコードからGoogle Cloudを呼び出すタスクから多くの労力を取り除いてくれる。現在、Java、Python、PHP、Cスラッシュ、Go、Nodo.js、Ruby、C++といった言語がライブラリに含まれています。このアプリを使うと、コンピュートエンジンのインスタンスを起動、停止したり、SSHで接続したり、各インスタンスのログを見たりすることができます。また、クラウドのSQLインスタンスを停止したり、起動したりすることもできます。さらに、アプリケーションエンジン上に配置されたアプリケーションの管理も可能で、エラーの表示、配置のロールバック、トラフィックの分割の変更などを行うことができます。クラウドコンソールのモバイルアプリでは、プロジェクトの最新の課金情報と、予算オーバーのプロジェクトに対する課金アラートを提供します。カスタマイズ可能なグラフを設定し、CPU使用率、ネットワーク使用率、1秒あたりのリクエスト数、サーバーエラーなどの主要な指標を表示することができます。モバイルアプリでは、アラートとインシデント管理も可能です。クラウドコンソールのモバイルアプリは、cloud dot google dot com forward slash council dash appからダウンロードすることができます。

# Virtual Private Cloud networking
このセクションでは、仮想ネットワーキングに焦点を当てながら、Google compute engineの仕組みを探っていきます。多くのユーザーは、最初のグーグルクラウドプロジェクト内で独自の仮想プライベートクラウドを定義することから、グーグルクラウドを使い始めます。あるいは、デフォルトの仮想プライベートクラウドから始めることもあります。仮想プライベートクラウドとは何だろうか？仮想プライベートクラウド（VPC）は、Google Cloudのようなパブリッククラウド内でホストされる安全な個々のプライベートクラウドコンピューティングモデルです。VPC上では、コードの実行、データの保存、Webサイトのホスティングなど、通常のプライベートクラウドで可能なことは何でも行えます。しかし、このプライベートクラウドは、パブリッククラウドプロバイダーによって遠隔地からホストされています。つまり、VPCは、パブリッククラウドコンピューティングの拡張性と利便性と、プライベートクラウドコンピューティングのデータ分離を兼ね備えているのです。VPCネットワークは、Googleクラウドのリソースを相互に接続し、インターネットに接続する。これには、ネットワークのセグメント化、ファイアウォールルールによるインスタンスへのアクセス制限、特定の宛先にトラフィックを転送するための静的ルートの作成などが含まれる。Google VPCネットワークは、グローバルなネットワークです。また、サブネットを持つこともできます。サブネットは、世界中のどの Google Cloud リージョンにおいても、より大きなネットワークの一部をセグメント化したものです。サブネットはリージョンを構成するゾーンにまたがることができる。このアーキテクチャにより、グローバルな範囲を持つネットワークレイアウトを簡単に定義することができる。リソースは、同じサブネット上の異なるゾーンに存在することもできる。サブネットのサイズは、割り当てられたIPアドレスの範囲を拡張することで増やすことができ、すでに設定されている仮想マシンには影響を与えません。例えば、現在Google Clouds us east one regionで定義された1つのサブネットを持つ1つのネットワークを持つVPCを例に挙げてみましょう。このVPCにコンピュートエンジンVMが接続されている場合、異なるゾーンにあるにもかかわらず、同じサブネット上にある彼らの隣人を意味します。この機能を利用することで、障害に強く、かつシンプルなネットワークレイアウトを維持したソリューションを構築することができます。

# Amazon VPCとGoogle VPCの比較
VPCは、地域内のアベイラビリティゾーン上に構築されるサブネットで構成されます。

サブネットにはパブリックとプライベートがあり、パブリックサブネットはインターネットにトラフィックをルーティングでき、プライベートサブネットはVPCからトラフィックが出ることがありません。

VPCは、RFC1918に準拠したプライベートIPアドレスのCIDRまたはクラスレスドメイン間ルーティング範囲で構築する必要があります。VPC内のすべてのサブネットは、VPCのCIDR範囲の一部であるプライベートIP範囲を持っている必要があり、ルートテーブルは、トラフィックの経路を把握できる各VPC用に構築されています。仮想マシンやネットワークに適用できるファイアウォールであるセキュリティグループなしでは、トラフィックはネットワーク外に流れません。ネットワークアクセス制御リストは、サブネットへのトラフィックの許可と拒否を設定することができますが、それは状態フェルではありません。googleとamazonが提供するネットワークサービスは、その範囲に違いがありますが、その主な違いを見てみましょう。

Google VPCのネットワークはグローバルで、サブネットはリージョンにまたがるということが重要なポイントになります。AWSはVPCのスコープを地域レベルで維持し、サブネットはアベイラビリティゾーンにまたがっている。

Google Cloud では、複数のプライベート ネットワークを接続し、それらのスペースを個別に管理することなく、グローバルな単一のプライベート ネットワークを作成することができます。

また、プロジェクトごとに複数のネットワークを定義して、柔軟性を高めることもできます。詳しくは後ほど説明します。

Googleのルーティングはグローバルに広がっており、AWS VPCはリージョナルなので、ファイアウォールルールもグローバルであることが必要です。また、ルーティングテーブルやネットワークアクセス制御リスト、セキュリティ境界もグローバルである。

# Compute Engine
このコースの前半では、インフラストラクチャー・アズ・ア・サービス（IS）について説明しました。今回は、GoogleクラウドのIaaSソリューションであるコンピュート・エンジンについて説明します。コンピュート・エンジンを使うと、ユーザーはGoogleのインフラストラクチャ上で仮想マシンを作成し、実行することができる。先行投資は不要で、高速で安定したパフォーマンスを発揮するように設計されたシステム上で何千もの仮想CPUを実行することができる。各仮想マシンには、本格的なオペレーティングシステムのパワーと機能が含まれています。つまり、仮想マシンは物理サーバと同様に、必要なCPUパワーとメモリ、ストレージの量と種類、オペレーティングシステムを指定して構成することができるのです。仮想マシン・インスタンスは、Google Cloudのプロジェクトやリソースを管理するウェブベースのツールであるGoogle Cloudコンソール、またはgcloudコマンドラインツールで作成することができる。インスタンスでは、Googleが提供するLinuxやWindows Serverのイメージ、またはこれらのイメージをカスタマイズしたものを実行することができます。また、他のOSのイメージを構築して実行したり、仮想マシンを柔軟に再構成したりすることも可能です。

Google Cloud を使い始めるには、Google とサードパーティベンダーの両方のソリューションを提供するクラウドマーケットプレイスを利用するのが手っ取り早い。これらのソリューションでは、ソフトウェア仮想マシンインスタンス、ストレージ、またはネットワーク設定を手動で構成する必要はありません。ただし、必要であれば、起動前にそれらの多くを変更することができます。

クラウドマーケットプレイスにあるほとんどのソフトウェアパッケージは、Google Cloud リソースの通常の使用料を超える追加料金なしで利用できます。クラウドマーケットプレイスの画像には、特に商用ライセンスされたソフトウェアを持つサードパーティによって公開されているものなど、使用料がかかるものもあります。しかし、これらはすべて、起動前に月額料金の見積もりが表示されます。この時点で、コンピュート・エンジンの価格と請求の仕組みが気になるところだろう。仮想マシンの利用については、1分単位から秒単位で課金され、仮想マシンの実行時間が長くなると自動的に持続利用割引が適用されるようになっています。そのため、1ヶ月のうち25%以上稼働した仮想マシンには、1分ごとに自動的に割引が適用されます。また、コミットメントユース割引も提供されています。これは、安定した予測可能なワークロードに対して、特定の量のVCPUとメモリを、1年または3年の使用期間を約束する代わりに、通常価格から最大57%割引で購入できることを意味します。そして、プリエンプティブVMです。例えば、大規模なデータセットを分析するバッチジョブのように、人が座って終了を待つ必要のないワークロードがあるとします。ジョブの実行にプリエンプト可能なVMを選択することで、場合によっては90%ものコスト削減が可能になります。プリエンプティブVMが通常のコンピュータ・エンジンVMと異なる点はただ1つです。コンピュータ・エンジンは、そのリソースが他の場所で必要とされる場合、ジョブを終了させる権限を持っています。プリエンプティブVMを使えば節約できますが、ジョブの停止と再開が可能であることを確認する必要があります。ストレージに関しては、compute engineは、処理と永続ディスクの間で高いスループットを得るために、特定のオプションやマシンタイプは必要ではありません。これはデフォルトで、追加コストなしで提供されます。そして最後に、カスタム・マシン・タイプでは、必要なものだけに料金を支払います。

Compute Engineでは、事前に定義されたマシンタイプや、独自のカスタムマシンタイプを使用して、仮想CPUの数やメモリ量など、インスタンスのマシンプロパティを選択できます。

# Comparing Amazon EC2 and Compute Engine
AWSとGoogleのVirtual Machinesには多くの共通点があります。Compute EngineもAmazon Elastic Compute Cloud、EC2も、RAM、CPU、GPUを選択し、設定することができる。どちらも幅広いオペレーティングシステムを提供している。両方の仮想マシンに仮想ディスクを追加でき、両方のインスタンスにエフェメラルおよびスタティックなパブリックおよびプライベートIPアドレスを使用でき、両方のインスタンスタイプでブートストラップ用のメタデータとスクリプトを使用できる。また、Compute EngineとAmazon EC2には、いくつかの重要な違いがあります。Compute Engineインスタンスは通常30秒程度で起動するが、Amazon EC2インスタンスは数分かかることがある。Google CloudとAWSは、コンピュート・サービスの一部としてブロック・ストレージ・オプションを提供している。Compute Engineは永続ディスクを、Amazon EC2はElastic Block Store（EBS）を提供する。それぞれのサービスには、価格や性能の異なる複数のブロック・ストレージ・タイプがある。リージョナルパーシステントディスクは、同じリージョンにある2つのゾーン間でデータの耐久性のあるストレージとレプリケーションを提供します。Compute Engine上で堅牢なシステムを設計する場合、複数のゾーンにまたがるリソースの高可用性を維持するために、地域永続ディスクの利用を検討してみてください。AWSは、リージョナルパーシステントディスクのオプションを提供していない。Amazon EC2はSpot Instancesと呼ばれる一時的なインスタンスを提供し、Compute EngineはPreemptible VMsと呼ばれる同様のインスタンスを提供します。どちらも似たような機能を提供するが、価格モデルは異なる。Compute Engineの場合、Preemptible VMsの価格は固定されている。マシンの種類によっては、Preemptible VMの価格はオンデマンド料金の80%近くまで割り引かれることもあります。プリエンプト可能なVMは、Compute Engineによって再生されない場合、最大24時間実行され、その後自動的に終了する。また、ライセンス料のかかるプレミアムOSを使用している場合、そのPreemptible VMを使用している間はライセンス料の全額が請求される。Compute EngineとAmazon EC2には、実行中のインスタンスから同様のオンデマンド価格モデルがあり、どちらも最低1分から秒単位で課金される。Amazon EC2では、1年間または3年間のリザーブド・インスタンスのプロビジョニングを約束することで、割引価格を得ることができる。前払いするほど、条件付きで割引率が高くなります。Compute Engineインスタンスでは、持続的な使用によって割引価格が得られ、自動的に割引が適用されます。その月にインスタンスを長く使えば使うほど割引率が上がり、標準的なオンデマンド料金の30%も節約できる可能性がある。AWSには、Amazon Machine Image（AMI）オプションが豊富に用意されていますが、使用するインスタンスは事前に定義されたものを選択する必要があります。Google Cloudでは、お客様の仕様に合わせたカスタムマシンを構築することができます。Compute EngineとAmazon EC2の主な違いを整理してみよう。Compute EngineとAmazon EC2は、どちらも特定の量の仮想CPU、RAM、ネットワーク機能を持つ様々な定義済みインスタンス構成を提供している。Compute Engineはマシンタイプ、Amazon EC2はインスタンスタイプと呼ばれます。Compute EngineとAmazon EC2の両方は、新しいインスタンスを作成するためにマシンイメージを使用します。AmazonはこれらのイメージをAmazon Machine Images、AMIと呼び、Compute Engineは単にイメージと呼んでいます。どちらも、コンピュート・サービスの一部としてブロック・ストレージ・オプションを提供しています。Compute Engineは永続ディスクを提供し、Amazon EC2はElastic Block Store (EBS)を提供します。Compute Engineでは、ローカルディスクはローカルSSDと呼ばれ、ほぼすべてのマシンタイプに装着することができる。1つのインスタンスに最大24台まで接続できる。Amazon EC2では、ローカルディスクは、インスタンスストアまたはエフェメラルストアと呼ばれます。これらのディスクは、インスタンスタイプのファミリに応じて、HDDまたはSSDのいずれかになります。これらのディスクの数とサイズは、特定のインスタンスタイプに依存し、調整することはできません。Compute EngineとAmazon EC2では、割引価格に対する考え方が大きく異なっています。Compute Engineは、Preemptible VM、Sustained Use Instances、およびCommitted Use Contractに対して割引を提供しています。Amazon EC2は、一時的なスポットインスタンスと予約インスタンスのプロビジョニングによる割引を提供している。貯蓄プランでは、1年または3年間の一定量の使用を約束する代わりに、大幅な節約が可能だが、リザーブドインスタンスよりも柔軟性がある。

# Scaling virtual machines
先ほどCompute Engineで見たように、定義済みのマシンタイプのセットを使ったり、カスタムマシンタイプを作成することで、仮想CPUの数やメモリの量など、インスタンスに最も適したマシンプロパティを選択することができます。そのために、コンピュートエンジンにはオートスケーリングという機能があり、ロードメトリクスに基づいてアプリケーションにVMを追加したり減算したりすることができるようになっています。この機能を実現するための他のパーツは、VM間で受信トラフィックをバランスさせることです。GoogleのVirtual Private Cloud（VPC）は、いくつかの異なる種類のロードバランシングをサポートしているため、これから詳しく説明する。Compute Engineでは、非常に大きなVMを構成することができ、インメモリデータベースやCPUを多用する分析などのワークロードには最適です。しかし、Google Cloudの顧客の多くは、スケールアップではなく、スケールアウトから始める。VMあたりの最大CPU数はマシンファミリに関連付けられ、ユーザが利用できるクォータにも制約される（これはゾーンに依存する）。現在利用可能なVMマシンタイプの仕様は、cloud.google.com/compute/docs/machine-typesで見ることができる。

# Important VPC compatibilities
それでは、Virtual Private Cloudの最も重要な互換性機能をいくつかご紹介します。物理ネットワークと同様に、VPCにもルーティングテーブルがあります。VPCのルーティングテーブルはビルトインされているので、ルーターのプロビジョニングや管理は必要ありません。ルーティング・テーブルは、同じネットワーク内、サブネットワーク間、あるいはGoogle Cloudゾーン間でトラフィックを転送するために使用され、外部IPアドレスは必要ない。Google Cloudでプロビジョニングや管理が必要ないもう一つのものは、ファイアウォールである。VPCはグローバルな分散ファイアウォールを提供し、受信と送信の両方のトラフィックを通じてインスタンスへのアクセスを制限するように制御することができる。ファイアウォールのルールは、コンピュートエンジンインスタンスのメタデータタグで定義できるので、実に便利です。例えば、全てのウェブサーバにwebというタグを付けて、ポート80や443のトラフィックはIPアドレスに関係なくwebタグの付いた全てのVMSに許可されるというファイアウォールルールを書くことができます。VPCはGoogle Cloudプロジェクトに属していることは覚えているはずです。しかし、あなたの会社が複数のGoogle Cloudプロジェクトを持っていて、VPCがお互いに話す必要がある場合はどうしたらよいでしょうか。VPCピアリングを使えば、2つのVPCの間にトラフィックを交換する関係を構築できる。あるいは、アイデンティティ・アクセス管理IAMの機能をフルに活用し、あるプロジェクトの誰と何をVPCとやり取りできるかを制御するために、共有VPCを設定することも可能です。

# Cloud Load Balancing
前回は、変化する負荷に対応するために、仮想マシンがどのようにオートスケールを行うかを探りました。しかし、ある時は4台の仮想マシンで提供され、別の時は40台の仮想マシンで提供される場合、顧客はどのようにアプリケーションを入手するのでしょうか？それは、クラウドのロードバランシングによって実現されます。ロードバランサーの仕事は、ユーザーのトラフィックをアプリケーションの複数のインスタンスに分散させることです。負荷を分散させることで、アプリケーションのパフォーマンスに問題が発生するリスクを低減させます。クラウドロードバランサーは、すべてのトラフィックを完全に分散し、ソフトウェアで定義し、管理するサービスです。ロードバランサーはVMで動作しないため、スケーリングや管理について心配する必要はありません。HTTPやHTTPS、その他のTCPやSSLトラフィック、UDPトラフィックなど、すべてのトラフィックをクラウド・ロード・バランシングに任せることができます。クラウドロードバランシングは、自動的なマルチリージョンフェイルオーバーを含むクロスリージョンロードバランシングを提供し、バックエンドが不健全になった場合はトラフィック違反を穏やかに移動させます。クラウド・ロード・バランシングは、ユーザー、トラフィック、ネットワーク、バックエンドの健全性、その他の関連条件の変化に素早く反応することができます。需要の急増が予想される場合はどうでしょうか？例えば、あなたのオンラインゲームがすでにヒットしているとします。Googleに負荷がかかっていることを警告するために、サポートチケットを提出する必要がありますか？いいえ、いわゆる事前のウォーミングアップは必要ありません。VPCには負荷分散のためのオプションが用意されています。Webアプリケーションのために地域をまたいだ負荷分散が必要な場合は、グローバルHTTP負荷分散を使用します。HTTP以外のSecure Sockets Layerトラフィックには、グローバルなSSLプロキシロードバランサーを使用します。SSLを使わないその他のTCPトラフィックであれば、グローバルTCPプロキシロードバランサーを使います。最後の2つのプロキシサービスは、特定のポート番号に対してのみ動作し、TCPに対してのみ動作します。UDPトラフィックや任意のポート番号のトラフィックをロードバランスしたい場合は、リージョナルロードバランサーを使えば、Google Cloudリージョン全体でロードバランスすることができる。最後に、これらのサービスに共通しているのは、インターネットからGoogleネットワークに流入するトラフィックを対象としていることだ。しかし、プロジェクト内部でトラフィックの負荷分散を行いたい場合はどうすればいいのだろうか？例えば、アプリケーションのプレゼンテーション層とビジネス層の間で負荷分散を行いたい場合です。その場合は、地域の内部ロードバランサーを使用する。Google Cloud の内部 IP アドレスでトラフィックを受け取り、compute Engine VM 間でロードバランシングを行います。

# Comparing load balancing in Google Cloud and AWS
GoogleとAmazonのロードバランシングを比較すると、いくつかの共通点があります。リクエストはHTTP、TCP、YDPで、リクエストはインターネットから来るか、内部リソースから来るかです。

ロードバランサーは、クライアントからのアクセスを制限するためにファイアウォールの背後に配置することができ、どちらもヘルスチェックとセッションアフィニティをサポートしています。また、GoogleのHTTPロードバランサーとAmazonのアプリケーションロードバランサーは、マイクロサービスに対するパスベースのルーティングをサポートしています。

AWSのロードバランサーはインスタンスベースのマネージドサービスであり、ロードバランサーのスケーリングには数分かかることがある。AWSのロードバランサーはインスタンスベースのマネージドサービスです。ロードバランサーを事前に温めてトラフィックを処理するには Elasticロードバランサーは、HTTPとHTTPS、TCP、アプリケーションのトラフィックを処理することができます。Google CloudとAWSのロードバランシングに対するアプローチの主な違いをまとめてみましょう。

Google Cloudのロードバランスはソフトウェアベースであるのに対し、AWSのロードバランスはEC2インスタンス上で動作する。Google Cloudのロードバランスは仮想マシンを使用しないため、サービスの起動が速く、EC2インスタンスは起動に数分かかる。そのため、AWSで短時間に大量のトラフィックが予想される場合、サポートチケットを開いて手動で仮想マシンのロードバランスをさらに開始しなければならないことがある。Google Cloudのロードバランサーはグローバルに管理されたサービスです、ロードバランサーはリージョンでサービスが構築されているわけではなく、ネットワークエッジでサービスが構築されているため、リージョンの停止にも耐えることができます。AWSのロードバランサーはリージョンで構築されているため、リージョンがダウンするとロードバランサーも一緒にダウンしてしまう可能性がある。Google Cloudのロードバランサーは、HTTPのみURLに基づいてトラフィックをルーティングすることができ、URLは特定のバックエンドサービスにトラフィックを誘導することができる。AWSは、HTTPとTCPのリスナーとリスナールールに基づきトラフィックをルーティングできる。Google CloudもAWSもヘルスチェックを活用して、健全なインスタンスにのみトラフィックが送られるようにし、新しいインスタンスで仮想マシンを破壊するオプションであるオートヒールも可能です。しかし、Google Cloudのヘルスチェックはバックエンドサービス経由のロードバランサーとインスタンスグループの両方で利用でき、AWSは対象グループにのみヘルスチェックが適用されます。Google Cloudはグローバルとリージョン内の両方にトラフィックを分散できるロードバランサーを提供しているが、AWSのロードバランサーはリージョン内のみにトラフィックを分散できる。AWSでグローバル規模のロードバランシングを実現するには、リージョンのロードバランシングとAWSのグローバルアクセラレーターを組み合わせる必要がある。

# Cloud DNS and Cloud CDN
Googleの無料サービスの中で最も有名なものの一つが、パブリックドメイン名サービスを世界に提供する8.8.8.8である。

DNSは、インターネットのホスト名をアドレスに変換するものです。ご想像の通り、Googleは高度に発達したDNSインフラを持っています。8.8.8.8を利用できるようにして、誰もがそれを利用できるようにしているのです。

しかし、Google Cloudで構築されたアプリケーションのインターネットホスト名やアドレスはどうなるのでしょうか。Google CloudはCloud DNSを提供し、世界中がそれらを見つけるのを助けてくれます。

Googleと同じインフラで動作するマネージドDNSサービスです。低レイテンシーで高可用性を持ち、アプリケーションやサービスをユーザーに提供するための費用対効果の高い方法です。公開するDNS情報は、世界中の冗長化された拠点から提供されます。また、クラウドDNSはプログラマブルです。Cloud Console、コマンドラインインターフェース、またはAPIを使用して、数百万のDNSゾーンとレコードを公開し、管理することができます。Googleは、グローバルなエッジキャッシュのシステムも持っています。エッジキャッシュとは、エンドユーザーに近い場所にコンテンツを保存するために、キャッシュサービスを利用することである。

Cloud CDNコンテンツデリバリーネットワークを利用することで、アプリケーションでのコンテンツ配信を高速化することができます。

これは、お客様の顧客がより低いネットワーク遅延を経験することを意味します。また、httpロードバランシングの設定後は、コンテンツのオリジンへの負荷が軽減され、コスト削減も可能です。クラウドCDNは、1つのチェックボックスで有効にすることができます。

他にも様々なCDNがあります。もちろん、すでに利用している場合は、Google Cloud CDN インターコネクトパートナープログラムの一部である可能性があり、継続して利用することが可能です。

# Connecting networks to Google VPC
Google Cloud の顧客の多くは、Google Virtual Private Clouds を、オンプレミスのネットワークや他のクラウドにあるネットワークなど、システム内の他のネットワークに接続したいと考えています。これを実現するには、いくつかの効果的な方法がある。1つは、インターネット上の仮想プライベート・ネットワーク接続から始めて、IPSec VPN プロトコルを使用してトンネル接続を作成する方法である。接続をダイナミックにするために、Cloud Routerと呼ばれるGoogle Cloudの機能を使用することができる。Cloud Routerは、Border Gateway Protocolを使用して、他のネットワークとGoogle VPCがVPN上で経路情報を交換できるようにする。この方法を使うと、Google VPCに新しいサブネットを追加した場合、オンプレミスのネットワークは自動的にそのサブネットへのルートを取得することになる。しかし、インターネットを使用してネットワークを接続することは、セキュリティ上の懸念や帯域幅の信頼性の問題から、必ずしもすべての人にとって最適な選択肢とは限りません。もうひとつの選択肢は、ダイレクト・ピアリングを利用してGoogleとピアリングすることを検討することです。ピアリングとは、GoogleのPoEと同じ公共データセンターにルーターを設置し、それを使ってネットワーク間でトラフィックを交換することです。Googleは世界中に100以上のPoE（Point of Presence）を持っています。まだ接続拠点にいないお客様は、Carrier Peeringプログラムのパートナーと連携して接続することができます。Carrier Peeringを利用すると、オンプレミスネットワークやサービスプロバイダーのネットワークからGoogleワークスペースや、1つ以上のパブリックIPアドレスを通して公開できるGoogleクラウド製品に直接アクセスできるようになります。しかし、ピアリングの欠点は、Googleのサービスレベル契約の対象外であることだ。相互接続のために最高のアップタイムを得ることが重要な場合、Dedicated Interconnectを使用することが良い解決策となる。このオプションでは、Googleへの1つまたは複数の直接のプライベート接続が可能になります。これらの接続がGoogleの仕様を満たすトポロジーを持つ場合、最大99.99パーセントのSLAでカバーすることも可能です。また、これらの接続はVPNによってバックアップされ、より高い信頼性を得ることができる。最後に紹介するのは、オンプレミスネットワークとVPCネットワーク間の接続をサポートするサービスプロバイダを経由して提供する「Partner Interconnect」です。パートナー・インターコネクトは、データセンターが専用インターコネクトのコロケーション施設に到達できない物理的な場所にある場合や、データのニーズが10ギガバイト/秒の接続全体を保証できない場合に有効です。可用性のニーズに応じて、Partner Interconnectはミッションクリティカルなサービスやダウンタイムを許容するアプリケーションをサポートするように構成することができます。専用インターコネクトと同様に、これらの接続がGoogleの仕様を満たすトポロジーであれば、最大99.99パーセントのSLAでカバーすることができます。ただし、サードパーティのサービスプロバイダが提供する Partner Interconnect のいかなる側面にも、また Google のネットワーク外で発生した問題にも、Google は責任を負わないことに注意してください。

# Google Cloud storage options
すべてのアプリケーションは、ストリーミングするメディアや、おそらくデバイスからの検閲されたデータのようなデータを保存する必要があり、異なるアプリケーションやワークロードは、異なるストレージ・データベース・ソリューションを必要とします。Google Cloudには、構造化データ、非構造化データ、トランザクションデータ、リレーショナルデータ用のストレージオプションがあります。このセクションでは、Google Cloudの5つのストレージ製品について説明します。Cloud Storage、Cloud Sequel、Cloud Spanner、Firestore、そしてCloud Bigtableです。アプリケーションによっては、これらのサービスのうち1つまたは複数を使用して作業を行うことがあります。

# Cloud Storage
まずはクラウドストレージから。クラウドストレージは、開発者やI.T.オーガニゼーションに耐久性と可用性の高いオブジェクトストレージを提供するサービスである。しかし、オブジェクトストレージとは何でしょうか？オブジェクトストレージとは、データをオブジェクトとして管理するコンピュータのデータストレージのアーキテクチャで、ファイルストレージのようなファイルやフォルダーの階層構造やブロックストレージのようなディスクのチャンクとしてではなく、オブジェクトとしてデータを管理します。オブジェクトは、実際のデータ自体のバイナリ形式と、作成日、作成者のリソースタイプ、権限などの関連するメタデータ、およびグローバルに一意の識別子を含むパッケージ形式で保存されます。これらの一意なキーはURの他の形式であり、オブジェクトストレージはWeb技術とうまく相互作用することを意味する。一般的にオブジェクトとして保存されるデータには、ビデオ、写真、オーディオ録音などがある。クラウドストレージは、グーグルのオブジェクトストレージ製品です。この製品は、顧客が任意の量のデータを保存し、必要なときに何度でも取り出すことができるようにします。フルマネージドでスケーラブルなサービスであり、さまざまな用途に利用できる。例えば、Webサイトのコンテンツ配信、アーカイブや災害復旧のためのデータ保存、エンドユーザーへの直接ダウンロードによる大容量データオブジェクトの配信などです。クラウドストレージは、ビデオや写真などのオンラインコンテンツのバックアップやアーカイブデータ、ワークフロー処理の中間結果の保存など、BLOBとして知られるバイナリラージオブジェクトストレージが必要な場合に主に使用されます。クラウドストレージのファイルは、バケットに整理される。バケットには、グローバルに一意な識別子と、保存する場所を特定する必要があり、バケットの理想的な場所は、レイテンシーが最小になる場所です。例えば、ユーザーの多くがヨーロッパにいる場合、ヨーロッパの特定のGoogle Cloudリージョンか、EUのマルチリージョンを選びたいところです。クラウドストレージが提供するストレージオブジェクトは、イミュータブル（不変）であり、編集することはできない。管理者は、新しいバージョンが古いものを完全に上書きするか、バケット内のバージョニングを有効にして特定のオブジェクトに加えられた変更を追跡するかを選択することができます。バージョニングを選択した場合、クラウドストレージは、そのバケットに含まれるすべてのオブジェクトの上書きまたは削除された変更の詳細な履歴を保持するようになります。もし、デフォルトでオブジェクトのバージョニングをオンにしない場合。オブジェクトのバージョニングを有効にすると、常に新しいバージョンが古いバージョンを上書きします。必要に応じて、オブジェクトのアーカイブバージョンをリストアップしたり、オブジェクトを古い状態に復元したり、オブジェクトのバージョンを永久に削除したりすることができます。多くの場合、個人を特定できる情報がデータオブジェクトに含まれている可能性があります。そのため、保存されたデータへのアクセスを制御することは、I am ロールと必要に応じてアクセス制御リストを使用して、セキュリティとプライバシーを維持するために不可欠です。組織は、各ユーザーが業務に必要なリソースのみにアクセスし、それ以上のアクセス権を持たないようにするセキュリティのベストプラクティスに準拠することができます。オブジェクトやバケットに対するユーザーのアクセスを制御するには、いくつかの方法があります。ほとんどの場合、プロジェクト、バケット、オブジェクトの間で十分なロールが継承されるようになっていますが、より細かい制御が必要な場合は、アクセス制御リストを作成します。各アクセスコントロールリストは、2つの情報から構成されています。ひとつはスコープで、これは誰がアクセスしてアクションを実行できるかを定義するものです。これは、特定のユーザーまたはユーザーのグループとなります。2つ目は、読み取りや書き込みなど、どのようなアクションを実行できるかを定義する「許可」です。なぜなら、大量のオブジェクトデータの保存と取得には、すぐにコストがかかるからです。クラウド Georgeは、ライフサイクル管理ポリシーも提供しています。例えば、365日以上前のオブジェクトを削除したり、2013年1月1日以前に作成されたオブジェクトを削除したり、バージョニングを有効にしたバケットに各オブジェクトの最新3バージョンだけを保持するようにクラウドストレージに指示することができる。このように管理することで、実際に必要なもの以上にお金を払うことがなくなります。

# クラウドストレージ ストレージクラスとデータ転送
クラウドストレージには、主に4つのストレージクラスがあります。1つ目はStandard Storageです。スタンダード・ストレージは、頻繁にアクセスするデータやホットなデータに最適とされている。また、短期間だけ保存するデータにも最適だ。2つ目のストレージクラスは、ニアラインストレージです。これは、平均して月に1回以下しかデータを読み取ったり変更したりしないような、アクセス頻度の低いデータを保存するのに適している。例えば、データのバックアップ、ロングテールのマルチメディアコンテンツ、データアーカイブなどが挙げられる。3番目のストレージクラスは、コールドラインストレージである。これもまた、アクセス頻度の低いデータを保存するための低コストなオプションである。ただし、ニアラインストレージと比較すると、コールドラインストレージは、最大でも90日に1回程度のデータの読み取りや変更を行うためのものである。4番目のストレージクラスは、アーカイブストレージです。これは、データアーカイブ、オンラインバックアップ、ディザスタリカバリに理想的に使用される最も低コストなオプションです。データへのアクセスや運用にかかるコストが高く、最低保存期間が365日であるため、1年に1回以下しかアクセスしない予定のデータに最適な選択肢です。これら4つのクラスにはそれぞれ違いがありますが、これらのストレージクラスすべてに共通する特徴がいくつかあることは特筆に値します。例えば、最小オブジェクトサイズの要件がない無制限のストレージ、世界中からのアクセスとロケーション、低遅延と高耐久性、セキュリティツールやAPIにまで及ぶ統一されたエクスペリエンス、データがマルチリージョンまたはデュアルリージョンで保存されている場合のジオリダンダンシーなどが挙げられます。これは、地理的に多様なデータセンターに物理サーバーを配置し、壊滅的なイベントや自然災害から保護し、最適なパフォーマンスを得るためにトラフィックを負荷分散させることを意味します。クラウドストレージは、使用した分だけ支払うため最低料金がなく、容量の事前プロビジョニングも必要ありません。セキュリティの面では、クラウドストレージはディスクに書き込む前に必ずサーバー側でデータを暗号化するため、追加料金はかかりません。お客様の端末と Google の間でやり取りされるデータは、デフォルトで HTTPS/TLS（Transport Layer Security）を使用して暗号化されています。どのストレージクラスを選んでも、データをクラウド・ストレージに取り込む方法はいくつかある。多くのお客様は、Cloud SDKのCloud Storageコマンドであるgsutilを使用して、オンライン転送を行っています。また、Google Chromeウェブブラウザを使えば、Cloud Councilのドラッグ＆ドロップでデータを移動させることもできる。しかし、テラバイトやペタバイトのデータをアップロードする必要がある場合はどうすればよいのでしょうか？ストレージ転送サービスを使えば、大量のオンラインデータを迅速かつ低コストでクラウドストレージにインポートすることができます。Storage Transfer Serviceでは、他のクラウドプロバイダーから、別のクラウドストレージ地域から、あるいはHTTPSエンドポイントから、クラウドストレージへのバッチ転送をスケジュールし管理することができます。そして、Transfer ApplianceはGoogle Cloudから購入したラケットボールのような大容量ストレージサーバーである。ネットワークに接続し、データをロードした後、アップロード施設に送り、そこでデータをCloud Storageにアップロードする。1台のアプライアンスで最大1ペタバイトのデータを転送することができます。クラウド・ストレージは、他のGoogle Cloud製品やサービスと密接に統合されているため、データをサービスに移動する方法が他にもたくさんあります。例えば、BigQueryとCloud SQLの両方とテーブルをインポートしたりエクスポートしたりすることができます。また、App EngineのログやFirestoreのバックアップ、画像などApp Engineのアプリケーションで使用するオブジェクトを保存することもできる。クラウドストレージは、インスタンスの起動スクリプト、Compute Engineのイメージ、Compute Engineのアプリケーションで使用されるオブジェクトも起動することができます。

# Comparing Amazon S3 and Amazon Glacier to Cloud Storage
それぞれのストレージサービス、クラウドストレージ、amazon simple storage service S 3を比較すると、多くの類似点があります。どちらのサービスでも、オブジェクトはバケットに格納されます。バケットは入れ子にすることができず、グローバルにユニークな名前を付ける必要があり、バージョン保護もできません。Object は Bucket 内の個々のファイルであり、どんなファイルタイプでも構いません。しかし、5テラバイトを超えることはできません。ただし、ストレージの容量は事実上無制限。オブジェクトには、サイズ、最終更新日、メディアタイプなどのメタデータを付与することができる。

クラウドストレージとAWSが提供するストレージオプションの主な違いをいくつか挙げてみましょう。

標準的な分散オブジェクトストレージの要件では、クラウドストレージ標準とamazon S three標準の主な違いは、デプロイメントのローカリティにある。S three標準がリージョナルであるのに対して、Clouds George標準はマルチリージョナル、デュアルリージョナル、リージョナルです。クラウドストレージとAmazon S3はそれぞれ、標準的なストレージ層の可用性を必要としないデータ向けに、コストを抑えたストレージクラスを提供しています。

クラウドストレージは、クラウドストレージニアラインとクラウドジョージコールドラインを提供しています。amazon S3は、標準的な不定期アクセスと1ゾーンの不定期アクセスを提供する一方。ここでも、重要な違いは、デプロイの局所性にある。ニアラインとコールドラインは、マルチリージョン、デュアルリージョン、リージョナルですが。S three standard I A はリージョナル、S 31 zone I A はゾーナルです。コールドラインは、30日ではなく90日の最低期間を条件として、より低いストレージコストのオプションを提供します。Googleとamazonはそれぞれ、定期的なアクセスや迅速な取得を必要としないデータのためのコールドストレージオプションを提供しています。クラウドストレージはクラウドストレージアーカイブという追加クラスを提供し、amazonはamazon Glacierを提供しています。クラウドストレージには、クラウドストレージアーカイブというクラスがあり、amazonにはamazon Glacierというクラスがあります。クラウドストレージスタンダードと同じです。amazon Glacierのレイテンシは、数分から数時間にも及びます。アーカイブストレージのストレージコストの低さは、Amazon Glacierの90日に対し、360日の5日です。

# Cloud SQL
Google Cloudの2つ目のコア・ストレージ・オプションは、Cloud SQLである。Cloud SQLは、MySQL、PostgreSQL、SQL Serverなどのリレーショナルデータベースをフルマネージドでサービスとして提供する。パッチやアップデートの適用、バックアップの管理、レプリケーションの設定など、日常的だが必要で、しばしば時間のかかる作業をGoogleに任せることで、ユーザーは優れたアプリケーションの構築に集中できるように設計されている。Cloud SQLは、ソフトウェアのインストールやメンテナンスを必要としません。最大で64プロセッサコア、400GB以上のRAM、30テラバイトのストレージまで拡張することができます。Cloud SQLのプライマリーインスタンス、外部プライマリーインスタンス、外部MySQLインスタンスからの自動レプリケーションシナリオをサポートします。Cloud SQLは、マネージドバックアップをサポートしており、バックアップされたデータは安全に保存され、復元が必要な場合はアクセス可能です。Cloud SQLは、Googleの内部ネットワーク上やデータベースのテーブル、一時ファイル、バックアップに保存される顧客データを暗号化し、各データベースインスタンスへのネットワークアクセスを制御するネットワークファイアウォールを搭載しているため、インスタンスの費用で7回のバックアップが可能です。Cloud SQLインスタンスの利点は、他のGoogle Cloudサービスや、外部サービスからもアクセスできることだ。Cloud SQLは、Java用のコネクタJやPython用のMySQL DBなどの標準的なドライバを使って、App Engineで利用することができる。Compute Engineインスタンスは、Cloud SQLインスタンスへのアクセスを許可され、Cloud SQLインスタンスが仮想マシンと同じゾーンにあるように設定できる。Cloud SQLは、SQL WorkbenchやToadなど、標準的なMySQLドライバを使用した外部アプリケーションやツールもサポートしています。

# Amazon RDSとCloud SQLの比較
Amazon Relational Data ServiceまたはCloud SQLのamazon RDSは、多くの点で似ています。どちらも商用リレーショナルデータベース管理システムを使用するマネージド・リレーショナルデータベースサービスである。AWSとGoogleクラウドは、インスタンス、バックアップ、アップデート、フェイルオーバーを含むデータベースのインフラを管理する。データ管理、スキーマ構築、ユーザー管理はこれまで通りユーザーが行う。読み出しと書き込みは、適切なデータベースに対して異なるスケーリングが可能です。インスタンスは垂直方向にしかスケールできません、単一の書き込みデータベースを大きくすることができます。

読み取りレプリカを使用して読み取りを水平にスケールし、それらを異なるゾーンまたはアベイラビリティゾーンに配置することができます。

フェイルオーバーレプリカは、別のゾーンまたはアベイラビリティゾーンに構築することができます。フェイルオーバーの処理は、クラウド事業者が責任をもって行います。

Cloud SQLは、MySQL、PostgresSQL、SQLサーバーのためのフルマネージドリレーショナルデータベースサービスです。Amazon RDSは、Amazon Aurora、MySQL、PostgreSQL、MariaDB、Oracle、Microsoft SQL serverをサポートしています。クラウドSQLとアマゾンRDSを比較してみましょう。アマゾンRDSでは、VPCセキュリティグループを使用して接続を許可するか、RDSセキュリティグループを使用してDBユーザーとグループにテーブル、ビュー、クエリへのアクセスを許可します。Cloud SQLでは、VPSのファイアウォールやCloud SQLのプロキシ、またはIPアドレスを許可リストに追加して許可したネットワークを使用します。

amazon RDSとCloud SQLの両方が、暗号化された外部接続のためのSSLの使用をサポートしています。

また、Amazon RDSプロキシとCloud SQLプロキシを使用して、それぞれのデータベースへの接続を暗号化することができます。Amazon RDSでは、静止状態のデータの暗号化を有効にすることができます。Cloud SQLでは、Googleの内部ネットワークにあるときと、データベースのテーブル、一時ファイル、バックアップに保存されている顧客データはデフォルトで暗号化されます。

Amazon RDSでリードレプリカを作成することができます。Cloud SQL for MySQLでは、Cloud SQLインスタンスのリードレプリカを作成することができます。また、Cloud SQLのプライマリーからレプリケーションを行う外部インスタンスを作成し、外部プライマリーインスタンスからレプリカとCloud SQLを作成することも可能です。Amazon RDSでは、バックアップはデフォルトで有効になっています。Cloud SQLでは、オプションで自動バックアップを有効にすることができます。

# Cloud Spanner
Google Cloudが提供する3つ目のコアストレージは、Cloud Spannerである。Cloud Spannerは、水平方向に拡張可能で、強い一貫性を持ち、SQLを話す、完全に管理されたリレーショナルデータベースサービスである。Googleのミッションクリティカルなアプリケーションとサービスによってバトルテストされています。Spannerは、Googleの800億ドル規模のビジネスを支えるサービスです。Cloud Spannerは、セカンダリインデックスでの結合、高可用性、強力なグローバル一貫性、2TBを超えるデータベースサイズ、1秒間に大量の入出力処理を必要とするSQLリレーショナルデータベース管理システムに特に適しています。1秒間に数万回以上の読み取りと書き込みが必要です。

# Firestore
Google Cloudの4つ目のコアストレージオプションはFirestoreです。Firestoreは、モバイル、ウェブ、サーバー開発向けの、柔軟で水平方向に拡張可能なNoSQLクラウドデータベースです。Firestoreでは、データはドキュメントに保存され、その後コレクションに整理される。ドキュメントには、サブコレクションに加え、複雑なネスト化されたオブジェクトを含めることができます。FirestoreのNoSQLクエリを使用すると、特定のドキュメントを個別に取得したり、クエリパラメータに一致するコレクション内のすべてのドキュメントを取得したりすることができます。クエリには複数のチェインフィルタを含めることができ、フィルタリングとソートオプションを組み合わせることができます。また、デフォルトでインデックスが設定されているため、クエリのパフォーマンスはデータセットではなく、結果セットのサイズに比例します。Firestoreはデータ同期を利用して、接続されているすべてのデバイスのデータを更新します。しかし、単純な1回限りのフェッチクエリを効率的に行うこともできるように設計されています。アプリがアクティブに使用している以外のデータをキャッシュするため、デバイスがオフラインの場合でも、アプリはデータの書き込み、読み取り、リスニング、およびクエリを実行できます。デバイスがオンラインに戻ると、Firestoreはローカルでの変更をFirestoreに同期します。FirestoreはGoogle Cloudの強力なインフラを活用し、自動的なマルチリージョンデータレプリケーション、強力な一貫性保証、アトミックバッチ操作、リアルトランザクションをサポートしています。価格面では、Firestoreで実行するドキュメントの読み取り、書き込み、削除のそれぞれに対して課金されます。また、クエリーは、クエリーがデータを返すかどうかにかかわらず、1回のクエリーにつき1ドキュメントの読み取りが課金されます。また、データの保存容量や、データへのアクセスに使用するネットワーク帯域幅も課金対象となります。イングレスは現在無料で、多くの場合イグレスも無料です。詳細はFirestoreの価格ページをご覧ください。また、Googleの課金計算機を使って、特定のユースケースでの価格を見積もることもできます。Firestoreは、米国地域間のネットワーク・イグレスが月10ギガバイト無料であることに加え、1日あたり5万件の文書読み取り、2万件の文書書き込み、2万件の文書削除、1ギガバイトの保存データという無料クォータが設定されています。1日あたりの無料利用枠を超えた場合のみ課金されます。このため、わずかな費用で、あるいは無料でFirestoreを使った開発を始めることができます。

# Cloud Bigtable
Google Cloudのコアストレージの最後に紹介するのは、Cloud Bigtableである。Cloud Bigtableは、GoogleのNoSQLビッグデータデータベースサービスである。検索、分析、地図、Gmailなど、Googleのコアサービスの多くを支えているデータベースと同じものです。Bigtableは、大規模なワークロードを一貫して低レイテンシかつ高スループットで処理できるように設計されています。Internet of Things、ユーザー分析、財務データ分析など、運用と分析の両方のアプリケーションに最適な選択肢です。どのストレージが最適かを判断する際、お客様は1テラバイト以上の半構造化データまたは構造化データを扱う場合、Bigtableを選択することが多いようです。データが高速でスループットが高い、あるいは変化が激しい。NoSQLデータを扱う場合。これは通常、強力なリレーショナル・セマンティクスが必要とされないトランザクションを意味します。データが時系列である、または自然な意味での順序付けがなされている。データに対して非同期、バッチ、同期のリアルタイム処理を行うビッグデータ、またはデータに対して機械学習アルゴリズムを実行する。Cloud Bigtableは他のGoogle Cloudサービスやサードパーティークライアントと連携することができます。APIを使って、Managed VM、HBase RESTサーバ、HBaseクライアントを使ったJavaサーバなどのデータサービス層を通して、Cloud Bigtableからデータを読み書きすることができます。一般的には、アプリケーション、ダッシュボード、データサービスなどにデータを提供するために利用されます。データは、dataflow streaming、spark streaming、stormなどの一般的なストリーム処理フレームワークを用いてストリーミングすることもできる。ストリーミングができない場合は、Hadoop MapReduce、Dataflow、Sparkなどのバッチ処理でCloud Bigtableからデータを読み出し、書き込むこともできる。多くの場合、要約されたデータや新たに計算されたデータは、Cloud Bigtableや下流のデータベースに書き戻される。

# ストレージオプションの比較
Google Cloud の主要なストレージ オプションについて説明しましたが、特定のアプリケーションやワークフローに最も適したサービスを比較するのに役立てましょう。大きな画像や動画など、10メガバイトを超える不変のブロブを保存する必要がある場合は、クラウド ストレージの使用を検討してください。このストレージは、ペタバイト単位の容量を提供し、1オブジェクトあたりの最大ユニットサイズは5テラバイトです。オンライントランザクション処理システムでSQLをフルサポートする必要がある場合は、Cloud SQLまたはCloud Spannerの利用を検討してください。Cloud SQLはマシンの種類によって最大30,720ギガバイト、Cloud Spannerはペタバイトの容量を提供します。Cloud SQLは、ウェブフレームワークや既存のアプリケーション（ユーザー認証や顧客注文の保存など）に最適です。読み取りレプリカだけでなく、水平方向のスケーラビリティが必要で、Cloud SQLが要件に合わない場合は、Cloud Spannerの利用を検討してください。Cloud Spannerは、2テラバイトを超えるような大規模なデータベースアプリケーションに最適です。例えば、Eコマースのユースケースで金融取引を計画する場合などです。リアルタイムのクエリ結果やオフラインのクエリサポートとともに、大規模なスケーリングと予測可能性が必要な場合は、Firestoreを検討してください。このストレージサービスは、1エンティティあたり最大1メガバイトの単位で、テラバイトの容量を提供します。Firestoreは、モバイルおよびWebアプリケーションのデータの保存、同期、クエリに最適です。最後に、大量の構造化オブジェクトを保存する必要がある場合は、Cloud Bigtableの利用を検討してください。Cloud BigtableはSQLクエリをサポートせず、複数行のトランザクションもサポートしない。このストレージサービスは、1セルあたり10メガバイト、1行あたり100メガバイトの最大ユニットサイズで、ペタバイトの容量を提供します。Bigtableは、アドテクノロジー、金融、IoTデータなど、読み書きの多いイベントを伴う分析データに最適です。アプリケーションによっては、これらのサービスのうちの1つまたは複数を使用して作業を行う可能性があります。このコースのこのセクションでBigQueryが言及されていないことにお気づきかもしれません。これは、BigQueryがデータストレージとデータ処理の間に位置し、他のコースでより深くカバーされるからです。BigQueryにデータを保存する通常の理由は、そのビッグデータ解析とインタラクティブなクエリ機能を使用するためです。しかし、BigQueryは純粋なデータストレージ製品ではありません。

# Introduction to containers
Google Cloud の Infrastructure as a Service で、サーバ、ファイルシステム、ネットワークへのアクセスを提供する Compute Engine と、Google Cloud の Platform as a Service である App Engine については、すでに説明したとおりです。このセクションでは、コンテナについて説明し、コンテナがどのように使用されているかを理解できるようにします。Infrastructure as a Service（IaaS）では、仮想マシンを使ってハードウェアを仮想化することで、他の開発者とコンピューティングリソースを共有することができます。これにより、各開発者は自分のOSをデプロイしてハードウェアにアクセスし、RAM、ファイルシステム、ネットワーク・インターフェイスなどにアクセスできる自己完結型の環境でアプリケーションを構築することができます。そこで登場するのがコンテナです。コンテナのアイデアは、PaaSではワークロードの独立したスケーラビリティを提供し、IaaSではOSとハードウェアの抽象化レイヤーを提供することです。設定可能なシステムであれば、好きなランタイムのWebサーバーやデータベース、ミドルウェアをインストールし、ディスク容量やディスクI/O、ネットワークなどの基盤となるシステムリソースを設定し、好きなように構築することができます。しかし、柔軟性には代償が伴います。コンピュートの最小単位は、アプリケーションとそのVMです。ゲスト OS のサイズは大きく、ギガバイトに及ぶこともあり、起動に数分かかることもあります。アプリケーションの需要が増加すると、VM全体をコピーし、アプリケーションのインスタンスごとにゲストOSを起動しなければならず、時間がかかり、コストも高くつきます。しかし App Engine では、プログラミング サービスにアクセスすることができます。これらのサービスを使用する自己完結型のワークロードでコードを記述し、依存するライブラリを含めるだけでよいのです。つまり、アプリケーションの需要が増加すると、プラットフォームは、ワークロードやインフラストラクチャに依存することなく、アプリケーションをシームレスに拡張することができるのです。このため、アプリケーションの規模は急速に拡大しますが、コスト削減のために基礎となるアーキテクチャを微調整することはできません。コンテナは、コードとその依存関係を囲む目に見えない箱であり、ファイルシステムの独自のパーティションとハードウェアへのアクセスは制限されています。作成に必要なのはわずかなシステムコールだけで、プロセスと同じように素早く起動することができます。各ホストで必要なのは、OSカーネル、サポートするコンテナ、そしてコンテナランタイムだけです。要するに、OSが仮想化されているのです。PaaSのようにスケールしますが、IaaSとほぼ同じ柔軟性が得られます。これにより、コードが超ポータブルになり、OSやハードウェアをブラックボックスとして扱うことができます。開発環境からステージング環境、本番環境、あるいはラップトップ環境からクラウド環境まで、何も変更したり再構築したりすることなく移行することができます。例えば、ウェブサーバーを拡張する場合、コンテナを使えば数秒でできますし、ワークロードの規模に応じて数十から数百のコンテナを1台のホストにデプロイすることも可能です。これは、1つのホスト上でアプリケーション全体を実行する1つのコンテナをスケーリングする簡単な例に過ぎません。しかし、おそらく多くのコンテナを使用してアプリケーションを構築し、それぞれがマイクロサービスのように独自の機能を実行したいと思うことでしょう。このように構築し、ネットワーク接続でつなげば、モジュール化し、簡単にデプロイし、ホスト群にまたがって独立してスケールさせることができるようになります。アプリの需要の変化やホストの障害に応じて、ホストのスケールアップやスケールダウン、コンテナの起動や停止を行うことができます。

# Kubernetes
コンテナ化されたアプリケーションの管理とスケーリングを支援する製品にKubernetesがあります。アプリケーションやワークロードをスケーリングする際の手間を省くために、KubernetesはGoogle Kubernetes Engine、GKEを使ってブートストラップすることができるようになっています。Kubernetesとは？Kubernetesは、コンテナ化されたワークロードとサービスを管理するためのオープンソースプラットフォームです。多くのホスト上で多くのコンテナをオーケストレーションし、マイクロサービスとしてスケールさせ、ロールアウトとロールバックを簡単に展開することができます。最も高いレベルでは、Kubernetesは、クラスターと呼ばれるノードの集合にコンテナをデプロイするために使用できるAPIのセットです。システムは、コントロールプレーンとして動作する主要コンポーネントのセットと、コンテナを実行するノードのセットに分かれています。Kubernetesでは、ノードはマシンのようなコンピューティングインスタンスを表します。Compute Engineで動作する仮想マシンであるGoogle Cloud上のノードとは異なることに注意してください。アプリケーションのセットと、それらがどのように相互作用すべきかを記述し、Kubernetesがそれを実現する方法を決定します。1つまたは複数のコンテナの周りにラッパーを使用してコンテナをノードにデプロイすることが、ポッドを定義するものです。Podは、Kubernetesで作成またはデプロイできる最小の単位です。これは、レプリケーションのコンポーネントまたはアプリ全体のいずれかとして、クラスタ上で実行中のプロセスを表します。一般に、1つのポッドには1つのコンテナしかありません。しかし、依存関係が高い複数のコンテナがある場合は、それらを1つのポッドにパッケージ化し、それらの間でネットワークやストレージのリソースを共有することができます。ポッドは、コンテナ用の一意のネットワークIPとポートのセット、およびコンテナの実行方法を制御する設定可能なオプションを提供します。Kubernetesでポッド内のコンテナを実行する方法の1つは、kubectl runコマンドを使用することで、ポッド内でコンテナが実行されている状態でデプロイメントを開始することです。デプロイは、同じPodのレプリカのグループを表し、それらが実行されるノードに障害が発生した場合でも、Podを実行し続けることができます。デプロイは、アプリケーションのコンポーネントや、アプリケーション全体を表すこともできます。プロジェクトで実行中のPodのリストを表示するには、kubectl get podsコマンドを実行します。Kubernetesは、Podのために固定IPアドレスを持つサービスを作成します。コントローラによると、そのサービスにパブリックIPアドレスを持つ外部のロードバランサーをアタッチして、クラスタ外の他者がアクセスできるようにする必要があるそうです。GKEでは、ロードバランサーはネットワークロードバランサーとして作成されます。そのIPアドレスに到達したクライアントは、そのサービスの背後にあるポッドにルーティングされます。サービスとは、ポッドの論理的な集合と、それらにアクセスするためのポリシーを定義する抽象化である。デプロイメントがポッドを作成および破棄すると、ポッドには独自のIPアドレスが割り当てられますが、これらのアドレスは長期間にわたって安定したものではありません。サービスグループはポッドのセットであり、ポッドに安定したエンドポイントまたは固定 IP アドレスを提供します。たとえば、フロントエンドとバックエンドという2つのポッドセットを作成し、それらを独自のサービスの背後に置いた場合、バックエンドポッドは変わるかもしれませんが、フロントエンドポッドはそのことに気づきません。フロントエンドポッドはこのことを意識せず、単にバックエンドサービスを参照します。デプロイメントをスケールするには、kubectl scaleコマンドを実行します。この例では、3つのPodがデプロイメントに作成され、それらはサービスの後ろに配置され、1つの固定IPアドレスを共有します。また、他のパラメータを使用して自動スケーリングを使用することもできます。たとえば、CPU 使用率が一定の限界に達したときに Pod の数を増やすように指定することができます。ここまでで、exposeやscaleといった命令的なコマンドの実行方法について見てきました。これは、Kubernetesを段階的に学習し、テストするには効果的です。しかし、Kubernetesの本当の強さは、宣言的な方法で作業するときに発揮されます。コマンドを発行する代わりに、Kubernetesに望む状態を伝える設定ファイルを提供し、Kubernetesがそれをどのように行うかを決定します。これを実現するには、デプロイメント設定ファイルを使用します。このファイルを取得するには、kubectl get podsコマンドを実行すると、次のようなデプロイメント設定ファイルを取得できます。kubectl get deploymentsまたはkubectl describe deploymentsを使用して、適切な数のレプリカが実行されていることを確認することができます。3つのレプリカではなく5つのレプリカを実行するには、デプロイメント設定ファイルを更新し、kubectl applyコマンドを実行して更新された設定ファイルを使用します。kubectl get servicesでサービスの外部IPを取得し、クライアントからパブリックIPアドレスに到達することで、これまで通りエンドポイントに到達することができます。最後の質問は、アプリの新バージョンをアップデートしたいときはどうするのか、ということです。新しいコードをユーザーに提供するためにコンテナを更新したいのですが、一度にそれらの変更をロールアウトするのは危険です。この場合、kubectl rolloutを使うか、デプロイメント設定ファイルを変更してからkubectl applyで変更を適用することになります。すると、新しいアップデート戦略に従って新しいPodが作成されます。以下は、新しいバージョンのPodを個別に作成し、新しいPodが利用可能になるのを待ってから古いPodの一つを破棄する設定例です。

# Google Kubernetes Engine
コンテナとKubernetesの基本を理解したところで、Google Kubernetes EngineまたはGKEについて説明しましょう。GKEは、Googleがホスティングするクラウド上のマネージドKubernetesサービスです。GKE環境は、複数のマシン、具体的にはコンピュートエンジンインスタンスをグループ化してクラスターを形成しています。Kubernetes EngineでKubernetesクラスタを作成するには、Google Cloud Consoleまたはクラウドソフトウェア開発キットで提供されているGCloudコマンドを使用します。GKEクラスタはカスタマイズ可能で、さまざまなマシンタイプ、ノード数、ネットワーク設定に対応しています。Kubernetesは、クラスターと対話するためのメカニズムを提供します。Kubernetesのコマンドとリソースは、アプリケーションのデプロイと管理、管理タスクの実行、ポリシーの設定、およびデプロイされたワークロードの健全性の監視に使用されます。GKEクラスターを実行すると、Google Cloudが提供する高度なクラスター管理機能の恩恵を受けることができます。これには、Google CloudのCompute Engineインスタンスのロードバランシング、クラスタ内のノードのサブセットを指定して柔軟性を高めるノードプール、クラスタのノードインスタンス数の自動スケーリング、クラスタのノードソフトウェアの自動アップグレード、ノードの健全性と可用性を維持するノード自動修復、クラスタを可視化するGoogle Cloudのオペレーションスイートのログと監視が含まれる。また、オンプレミスとクラウドのリソースを橋渡しする必要がある場合、GKEクラスタでレプリケーションを実行することは良い基盤となります。GKEのクラスタ上でKubernetesを起動するには、次のコマンドを実行するだけです。GCloud container clusters create K1.

# Hybrid and multi-cloud
コンテナがどのように機能するかはお分かりいただけたと思いますが、ここではその情報をさらに一歩進めて、最新のハイブリッドクラウドやマルチクラウドのアーキテクチャでコンテナをどのように使用できるかを探ってみたいと思います。まず、典型的なオンプレミス分散システム・アーキテクチャを見ることから始めましょう。ほとんどの企業規模のアプリケーションは、サービスを提供するために必要なコンピューティングワークロードを2つ以上のネットワークサーバーに分散させる分散システムとして設計されています。近年では、これらのワークロードをマイクロサービスに分解し、より簡単に保守・拡張できるようにするコンテナが一般的になってきています。従来、こうした企業システムとそのワークロードは、コンテナ化されているかどうかにかかわらず、オンプレミスに置かれていました。つまり、企業のネットワーク内や自社のデータセンター内のどこかで稼働する大容量サーバー群に格納されていたのです。アプリケーションのコンピューティングニーズが利用可能なコンピューティングリソースを上回り始めると、オンプレミスシステムを使用している企業は、リソースのボトルネックを解決する前に、より強力なサーバーを調達し、必要なネットワークの変更または拡張後に会社のネットワークにインストールし、新しいサーバーを構成し、最後にアプリケーションとその依存関係を新しいサーバーにロードする必要がありました。このようなオンプレミス型のアップグレードに要する時間は、数カ月から1年以上にも及ぶ可能性があります。特に、平均的なサーバーの耐用年数が3～5年であることを考えると、かなりのコストがかかる可能性があります。しかし、今すぐにより多くのコンピューティングパワーを必要とする場合はどうでしょうか。数カ月後ではなく、今すぐ必要だとしたら？低コストと高可用性のために、一部のワークロードをオンプレミスからクラウドに移行したいが、エンタープライズ・アプリケーション全体をオンプレミスのネットワークから移行するのは気が進まない、あるいはできない場合はどうでしょう。クラウドでしか利用できない特殊な製品やサービスを利用したい場合はどうすればよいでしょうか。このような場合、最新のハイブリッドまたはマルチクラウドアーキテクチャが役立ちます。システムインフラの一部をオンプレミスに残し、他の部分をクラウドに移行することで、企業のニーズに合った環境を構築することができるのです。本格的な移行は必要ないため、特定のワークロードだけを自分のペースでクラウドに移行することができます。機械学習、コンテンツ・キャッシング、データ分析、長期保存、IoTショー・コンピューティング・リソース・ツールキットなど、移行を決めたワークロードの実行には、クラウド・サービスが提供する柔軟性、拡張性、および計算コストの削減を活用することができる。次のビデオでは、最新のハイブリッドおよびマルチクラウドの分散システムおよびサービス管理に対する Google Cloud の回答について学びます。

# Anthos
最近、分散システムやサービスを強化するためのハイブリッドアーキテクチャの採用について、よく耳にするようになりました。Google が開発した Anthos というハイブリッド、マルチクラウド分散システム、分散サービス管理システムについても耳にしたことがあるかもしれません。しかし、Anthosとは一体何なのでしょうか？Anthosは、Googleの分散システムとサービス管理ソフトウェアの最新の技術革新によって実現されたハイブリッドとマルチクラウドのソリューションです。Anthosのフレームワークは、オンプレミスのKubernetesとGKEを基盤としています。これは、ハイブリッドや複数のクラウド環境にわたってポリシーベースのアプリケーションライフサイクル配信をサポートする中央制御プレーンのために、完全に統合され、集中管理されたアーキテクチャの基盤を提供します。Anthos はまた、オンプレミス、クラウド、または複数のクラウドに関わらず、ネットワーク全体でアプリケーションの一貫性を監視・維持するための豊富なツールセットを提供します。Anthos を使って最新のハイブリッドインフラスタックを順を追って構築しながら、このフレームワークをより深く見ていきましょう。まず、ハイブリッドネットワークのクラウド側にある Google Kubernetes Engine を見てみましょう。Google Kubernetes Engine は、コンテナ化されたアプリケーションをデプロイするためのマネージドな本番環境であり、高可用性と SLA でシームレスに動作し、認定 Kubernetes を実行するためクラウドとオンプレミス間で移植性があり、自動ノード修復、自動アップグレード、自動スケーリングを含み、複数のコントロールプレーンとゾーン間のノードストレージレプリケーションによる高可用性のために地域クラスタが使用されています。ハイブリッドネットワークのオンプレミス側で対応するのはGKE on-premです。GKE on-premは、ベストプラクティス設定がプリロードされたKubernetesのターンキープロダクショングレード適合バージョンで、Googleによって検証・テストされた最新のKubernetesリリースへの容易なアップグレード経路を提供し、Cloud Build Container RegistryやCloud監査ログなどGoogle Cloud上のコンテナサービスへのアクセス、Istio KnativeやCloud Marketplaceソリューションとの連携、およびクラウドとオンプレミス環境間でのKubernetesバージョンと体験の一貫性を保証しているのだそうです。Google Kubernetes EngineとGKEオンプレミスはどちらも、オンプレミスかクラウドかにかかわらず、ネットワーク内のすべてのクラスタがコンテナ化されたアプリケーションの同じリポジトリにアクセスできるように、マーケットプレイスと統合されています。これにより、ネットワークの両側で同じ設定を使用できるようになり、クラスタ間の適合性を維持するために費やす時間を短縮できます。また、write-once-replicate-anywhereアプローチにより、アプリケーションの開発に費やす時間も短縮されます。エンタープライズ・アプリケーションでは、コンピューティングのワークロードを処理するために何百ものマイクロサービスを使用する場合があります。これらのサービスをすべて追跡し、その健全性を監視することは、すぐに困難な課題となります。Anthos Service MeshとIstio Open Source service meshは、マイクロサービスの管理とセキュリティのための当て推量をすべて取り除きます。これらのサービスメッシュ層は、Cloud Interconnectを使用してハイブリッドネットワーク上で通信し、データの同期と受け渡しを行います。Cloud LoggingとCloud Monitoringは、Google Cloudに組み込まれたロギングとモニタリングのソリューションである。Google CloudのOperationsスイートは、ハイブリッドまたはマルチクラウドネットワークのあらゆる側面を監視する、完全に管理されたロギング、メトリクス収集、監視、ダッシュボード作成、および警告のソリューションを提供します。ハイブリッドやマルチクラウドネットワークの全側面を監視し、単一のガラス張りのダッシュボードで全ての環境を監視できる、設定が簡単で強力なクラウドベースの監視ソリューションをお求めのお客様に最適なソリューションです。最後に、Anthos Configuration Management は、クラスタの構成に関する単一の権威ある真実のソースを提供します。これはポリシーリポジトリに保存され、実際は Git リポジトリです。このリポジトリは、オンプレミスまたはクラウドに配置することができます。Anthos Configuration Managementエージェントは、ポリシーリポジトリを使用して、各環境でローカルに設定を実施し、環境間でクラスタを所有する複雑さを管理します。Anthos Configuration Management はまた、管理者と開発者が単一のリポジトリコミットでコード変更を展開する機能を提供し、アプリケーション内の名前と権限の衝突を防ぐ方法である名前空間を使用した構成継承を実装するオプションがあります。Anthos の詳細については cloud.google.com/anthos を参照してください。

# Amazon Elastic Container ServiceとGoogle Kubernetes Engineを比較する。
Google Kubernetes EngineとAmazon Elastic Container Serviceは、同じ目的を果たすものですが、その方法は異なっています。特定の機能がどのように異なるのかを見てみましょう。どちらもコンテナの実行と管理には仮想マシンのクラスタを使用します。GKEはCompute Engineインスタンスを使用し、Amazon EKSとAmazon ECSはEC2インスタンスを使用します。Amazon ECSはDockerをサポートしていますが、GKEとAmazon EKSはDockerとRocket形式のコンテナの両方をサポートしています。GKEとAmazon EKSのノードエージェントは、Kubernetesで使用されるオープンソースのエージェントであるKubeletsを使用しています。Amazon ECSは、独自のAmazon ECSエージェントを使用します。GKEとAmazon EKSは、Kubernetesがアプリケーションを実行する方法であるPodsによってコンテナをグループ化します。Amazon ECSはタスクと呼ばれる特定のグループを使用します。GKEではレプリケーションコントローラーを使用してサイジングを行うことができます。Amazon EKSとAmazon ECSがサービスを使うのに対して、GKEはサービスを使います。GKEでのコマンド実行は、オープンソースのCube CTLコマンドラインとGクラウドの組み合わせで可能です。Amazon EKSは、独自のコマンドラインインタフェースまたはCube CTLを使用できます。Amazon ECSは、Amazon ECSのコマンドラインインターフェイスを使用します。最後に、GKEの最大の利点の1つは、移植性です。Kubernetesは、物理的なハードウェアや仮想マシンだけでなく、さまざまなクラウド上で動作させることができます。Amazon EKSとAmazon ECSはAWS上でのみ実行可能です。

# App Engine
このコースではこれまで、Google Cloud の紹介と、クラウドでの仮想マシン、ネットワーク、ストレージ、コンテナの使用に関するオプションと利点を探ってきました。このセクションでは、クラウドでのアプリケーション開発に目を向けます。App Engine は、Web アプリケーションを大規模に開発およびホストするための、完全に管理されたサーバーレスプラットフォームです。どのように機能するのでしょうか。App Engine では、一般的なコーディング言語、ライブラリ、およびフレームワークから選択して、使い慣れたツールを使用してアプリケーションを開発し、需要に応じてスケール アプリケーション インスタンスのサーバーを自動的にプロビジョニングできます。つまり、コードをアップロードするだけで、Google がアプリの可用性を管理します。コーディングには、Eclipse、IntelliJ、Maven、Git、Jenkins、PyCharmなどのオプションがあります。App Engine では、プロビジョニングやメンテナンスのためのサーバーは必要ありません。App Engineは、NoSQLデータストア、memcache、ロードバランシング、ヘルスチェック、アプリケーションログ、およびほとんどのアプリケーションに共通するユーザー認証APIなどの組み込みサービスやAPIを提供します。また、App Engine は、ローカル マシンでのアプリケーションの開発、デプロイ、および管理を支援するソフトウェア開発キット (SDK) を提供しています。各SDKには、App Engineで利用可能なすべてのAPIとライブラリ、ローカル コンピュータ上でApp Engineのすべてのサービスをエミュレートする同化したセキュアなサンドボックス環境、アプリケーションをCloudにアップロードして異なるバージョンを管理するためのデプロイツールが含まれています。SDKはローカルでアプリケーションを管理し、Google Cloud Consoleは本番でアプリケーションを管理します。Cloud Consoleのウェブベースのインターフェースを使って、新しいアプリケーションの作成、ドメイン名の設定、アプリケーションの稼働バージョンの変更、アクセスログやエラーログの確認などを行うことができます。セキュリティの観点からは、Google Cloud のセキュリティおよびリスク管理プラットフォームである Security Command Center がウェブアプリケーションを安全に保ちます。Cloud Consoleを通じて、Security Command Centerを使用して、一般的なWebアプリケーションの脆弱性を自動的にスキャンして検出することができます。

# App Engine environments
App Engineの環境には、標準環境と柔軟環境の2種類があります。App Engine Standard Environmentは、Googleのインフラストラクチャ上で動作するContainer Instancesをベースにしている。コンテナには、サポートされている言語とバージョンの標準化されたリストからランタイムがあらかじめ設定されており、App Engineの標準APIをサポートするライブラリが含まれています。多くのアプリケーションでは、標準環境のランタイムとライブラリだけで十分な場合があります。標準環境の機能には、クエリ、ソート、トランザクションを備えた永続ストレージ、自動スケーリングと負荷分散、リクエストの範囲外の作業を行うための非同期タスクキュー、指定時刻または一定間隔でイベントをトリガーするスケジュールタスク、他のGoogle CloudサービスやAPIとの連携などがある。標準環境を利用するには、いくつかの要件がある。Java、Python、PHP、Go、Node.js、Ruby の指定されたバージョンを使用する必要があります。アプリケーションは、ランタイムに依存するサンドボックスの制約に準拠する必要があります。アプリケーションは安全なサンドボックス環境で実行されます。これにより、App Engine Standard Environment は、複数のサーバーにリクエストを分散し、トラフィック需要に応じてサーバーを拡張することができます。つまり、アプリケーションは、サーバーのハードウェア、オペレーティング システム、または物理的な場所に依存しない、独自の安全で信頼できる環境内で実行されます。標準的な環境のワークフローは、通常、次の3つのステップを踏みます。まず、ウェブアプリケーションをローカルで開発し、テストします。2つ目は、SDKを使用してアプリケーションをApp Engineにデプロイする。3 番目に、App Engine がアプリケーションをスケーリングし、サービスを提供する。App Engineは柔軟な環境も提供する。標準環境のサンドボックスモデルでは制限が多すぎる場合、柔軟な環境では、Web アプリケーションを実行するコンテナの種類を指定することができます。このオプションでは、Google CloudのCompute Engine Virtual Machines上のDockerコンテナ内でアプリケーションを実行できる。この場合、App EngineがCompute Engine Machinesを管理する。つまり、インスタンスは健全性をチェックされ、必要に応じてヒールされ、プロジェクト内の他のモジュールインスタンスと同位置に配置されます。重要な後方互換性のあるアップデートは、基盤となるオペレーティング システムに自動的に適用されます。VMインスタンスは、プロジェクトの設定に従って、自動的に地域ごとに配置されます。Google の管理サービスにより、すべてのプロジェクトの VM インスタンスが最適なパフォーマンスのために同位置に配置されます。VMインスタンスは週単位で再起動されます。再起動の際、Googleの管理サービスは、必要なオペレーティングシステムとセキュリティのアップデートを適用します。この柔軟な環境は、マイクロサービス、認証、SQLおよびNoSQLデータベース、トラフィック分割、ロギング、検索、バージョニング、セキュリティスキャン、Memcache、およびコンテンツ配信ネットワークに対応しています。App Engine Flexibleでは、ユーザーが最も得意とするコード記述に主な焦点を置いたまま、ライブラリでのカスタム設定の恩恵を受けることもできます。また、App Engine Flexible環境では、Dockerファイルを使用して仮想マシンのランタイムとOSをカスタマイズすることができます。App Engine Standardとして、サポートされるランタイムはPython、Java、Go、Node.js、PHP、Rubyなどです。しかし、App Engine Flexible では、これらのランタイムの異なるバージョンを使用したり、カスタム Docker イメージの提供やオープンソース コミュニティの Dockerfile を使用して独自のカスタム ランタイムを提供することもできます。この2つの環境は、それぞれどのように違うのでしょうか。まず、標準環境から見てみましょう。アプリケーションのインスタンスを数秒で立ち上げることができますが、アプリケーションを実行するインフラへのアクセスは少なくなります。標準環境では、アプリケーションが動作している仮想マシンにSSHで接続したり、ローカルディスクに書き込んだりすることができないのです。標準環境では、特定の言語のサードパーティバイナリをサポートしていますし、App Engineを使ってネットワークへの呼び出しを行うことも可能です。最後に価格ですが、無料ティアの利用後は、自動シャットダウンを伴うインスタンスクラス単位での支払いとなります。柔軟性のある環境は、起動に数秒ではなく数分かかります。しかし、アプリケーションを実行する仮想マシンにSSHで接続することができます。また、スクラッチベースにローカルディスクを使用したり、サードパーティーのソフトウェアをインストールしたり、App Engineを介さずにネットワークに接続することも可能です。価格面では、フレキシブルな環境の場合、自動シャットダウンはなく、1時間ごとのリソース割り当てで支払います。App EngineはDockerコンテナを利用するため、Google Kubernetes Engineと比較してどうなのか気になる方も多いかと思います。App Engineの標準環境は、Webやモバイルアプリケーションのデプロイとスケーリングを最大限にコントロールするサービスを求める人向けです。一方、Google Kubernetes Engineは、アプリケーションの所有者にKubernetesの柔軟性をフルに提供する。App Engineの柔軟な環境は、この2つの中間のようなものです。

# App EngineとAmazon Elastic Beanstalkの比較
App Engine Standard、App Engine Flexible、AWS Elastic Beanstalkは、同様のパス機能を提供しています。3つとも、必要に応じてリソースを活用する方法として、オートスケールを使用することができます。また、3つともIAMロールを使ってセキュリティを確保することができ、米国、欧州、中東、アフリカ、アジア太平洋地域で利用可能である。2つのApp Engine環境とElastic Beanstalkの間で、特定の機能がどのように異なるかを見てみましょう。App EngineとElastic Beanstalkは、どちらもさまざまなランタイムをサポートしています。App Engine標準環境は、標準環境がサポートするロックダウン環境のため、サポートするランタイムが少なくなっています。App Engine flexible environmentとElastic Beanstalkは、どちらもカスタムランタイムをサポートしています。App Engine標準環境には無料ティアがあり、Elastic Beanstalkには最初の1年間は無料ティアがあります。最初の1年を過ぎると、無料ティアは利用できなくなります。App Engine標準環境は、ネットワーク制御をサポートしていません。IPエンドポイントのみインターネットに公開されます。App Engine flexible environmentとElastic Beanstalkは、ともにVPCの利用をサポートしています。アプリケーションの認証については、Elastic Beanstalkではプラットフォーム上で動作するアプリケーションに認証を書き込む必要があります。App Engineについては、GoogleがFirebaseを利用した様々なIDプロバイダを提供しています。3つのオプションはすべて、タスクとメッセージのキューの使用をサポートしている。Google Cloudサービスの場合、App EngineはCloud Task APIやPub Sub（プッシュ＆プル管理型メッセージキュー）を使うことができる。Elastic Beanstalkは、プルキューであるamazon Simple Queue Serviceのみをサポートしている。App Engine標準環境の価格は、1時間あたりのインスタンス数に基づいており、無料ティアがあります。App Engine フレキシブル環境の価格は、VCPU/コア時間、メモリ/ギガバイト時間、永続ディスク/ギガバイト/月がベースとなります。Elastic Beanstalkの価格は、使用するAWSのサービスに基づいています。

# Google Cloud API management tools
さて、ここまででApp Engineの概要がわかったと思います。クラウドエンドポイントであるApigee Edgeに話を移そう。これらはGoogle Cloudのアプリケーションプログラミングインターフェース（API）の管理ツールです。では、APIとは一体何かというと、ソフトウェア・サービスの実装は複雑で変更しやすい。もし、そのサービスを利用するために他のソフトウェア・サービスを詳細に明示的にコーディングしなければならないとしたら、結果はもろく、エラーが起こりやすいものになってしまうだろう。そのため、アプリケーション開発者は、不要な細部を隠蔽したクリーンで明確に定義されたインターフェースを提供するように、ソフトウェアを構成します。そして、そのインターフェイスを文書化したものが、アプリケーション・プログラミング・インターフェイスです。インターフェイスが変更されない限り、基本的な実装は変更可能であり、APIを使用する他のソフトウェアはそれを知る必要も、気にする必要もありません。時には、APIを変更しなければならないこともあります。例えば、あるAPIのバージョン2には、バージョン1にはないコールが含まれているかもしれない。つまり、APIを利用するプログラムは、その呼び出しで使いたいAPIのバージョンを指定することができる。APIをサポートすることは非常に重要なタスクである。そしてGoogle Cloudは、cloud endpointsとApigee Edgeという2つのAPI管理ツールを提供している。

Cloud endpointsは、独自のDockerコンテナで動作するサービスプロキシである分散型拡張可能サービスプロキシを利用した分散型API管理システムです。その目的は、最も要求の厳しいAPIであっても、低レイテンシーかつ高いパフォーマンスで作成・維持できるようにすることです。クラウドエンドポイントは、API協議会のホスティング、ロギング、モニタリングなどの機能を提供し、APIの作成、共有、メンテナンス、セキュリティ確保を支援します。クラウドエンドポイントは、オープンAPI仕様をサポートするあらゆるAPIで使用できます。クラウドエンドポイントは、App Engine、Google Kubernetesエンジン、およびAndroid.、iOS、JavaScriptなどのコンピュートエンジンクライアントを実行するアプリケーションをサポートしています。APIプロキシの開発・管理に利用できるGoogle Cloudプラットフォームには、Apigee Edgeがある。クラウドエンドポイントとは異なり、Apigee Edgeは、レート制限、クォータ、分析などのビジネス上の問題に特化している。実際、多くのApigee Edgeユーザは、他社にソフトウェアサービスを提供しています。Apigee Edgeのバックインサービスは、Google Cloudである必要はないのです。また、その結果、エンジニアはレガシーアプリケーションを分解するために利用することも多い。つまり、大規模で重要なアプリケーションを一度に置き換えるのではなく、Apigee Edgeを使ってそのサービスを個別に切り離すことができるのです。これにより、レガシーアプリケーションが最終的に廃棄されるまで、マイクロサービスを立ち上げ、それぞれを順番に実装することができます。

# Cloud Run
コースのセクションで探求する最後のアプリケーションプラットフォームは、Cloud Runです。WebリクエストやPub/Subイベントを介してステートレスコンテナを実行することができるマネージドコンピュートプラットフォームです。

Cloud Runはサーバーレスです。つまり、インフラストラクチャの管理タスクをすべて取り除き、アプリケーションの開発に集中することができます。

KnativeはKubernetes上に構築されたオープンなAPIと実行環境であり、異なる環境やプラットフォーム間でワークロードを移動する自由を与えてくれます。Google Cloudでも、Google Kubernetes Engineでも、Knativeが動作する場所ならどこでも、完全に管理することができるのです。

Cloud Runは高速です。ほぼ瞬時にゼロから自動でスケールアップ、スケールダウンができ、使った分だけ課金されます。100ミリ秒単位で計算されるため、過剰にプロビジョニングされたリソースの代金を支払う必要はありません。

Cloud Run の開発者ワークフローは、簡単な 3 段階のプロセスです。まず、好きなプログラミング言語を使ってアプリケーションを作成します。このアプリケーションは、Web リクエストをリッスンするサーバーを起動する必要があります。

第二に、アプリケーションをビルドしてコンテナイメージにパッケージ化し、第三に、コンテナイメージをアーティファクトレジストリにプッシュし、Cloud Runがそれをデプロイする。

Cloud Runは、アーティファクトレジストリに保存されているイメージのみをデプロイできることに注意してください。

必要な権限があれば、ローカルソースから独自のコードをビルド、プッシュ、デプロイすることができます。また、アーティファクトレジストリに既に存在するイメージをデプロイすることもできます。

コンテナイメージをデプロイすると、固有の HTTPS URL が返ってきます。

その後、Cloud Runはリクエストを処理するためにオンデマンドでコンテナを起動し、コンテナを動的に追加・削除することですべての受信リクエストが処理されるようにします。

クラウドランはサーバーレスなので、開発者はアプリケーションの構築に専念でき、それを支えるインフラの構築やメンテナンスに煩わされないということです。

ある種のユースケースでは、コンテナベースのワークフローは、透明性と柔軟性に優れているため、素晴らしいものです。

コンテナイメージを構築すれば、どのファイルがどのようにコンテナイメージに入るのかを正確に決定する力を持つことができます。しかし、アプリケーションを構築することは、コンテナ化とそれに伴う責任について考えなければならないのは言うまでもなく、すでに十分に難しいことなのです。

ソースコードをHTTPSエンドポイントに変換する方法を探しているだけで、ベンダーにコンテナイメージが安全で、よく構成され、一貫した方法で構築されていることを確認してほしい場合もあります。クラウドランを使えば、その両方が可能になります。ソースベースのワークフローと同様に、コンテナベースのワークフローを使用することができます。

ソースベースのアプローチを使用する場合、コンテナイメージの代わりにソースコードをデプロイすることになります。

Cloud Runは、ソースをビルドし、アプリケーションをコンテナイメージにパッケージ化します。

Cloud Runは、オープンソースのプロジェクトであるbuildpacksを使っています。

クラウドランはHTTPSの配信を代行します。つまり、ウェブ要求の処理についてだけ心配すればよく、暗号化の追加はCloud Runに任せることができます。デフォルトでは、アプリケーションはグローバルドメインrun.appのユニークなサブドメインで公開されます。また、独自のカスタムドメインを使用することもできます。

Cloud Runが他のすべてを管理します。有効なSSL証明書の生成、セキュアな設定による正しいSSL終了の構成、受信リクエストの処理、リクエストの復号化、アプリケーションへの転送などです。

クラウドランの価格モデルはユニークで、コンテナが100ミリ秒の粒度でWebリクエストを処理している間と、起動時やシャットダウン時に使用したシステムリソースに対してのみ支払いが発生します。コンテナがリクエストを処理しない場合は、何も支払う必要はありません。

さらに、100万件のリクエストを処理するごとに、少額の手数料が発生しました。

コンテナ時間の価格は、CPUとメモリによって上昇します。vCPUとメモリが多いコンテナはより高価になります。現在、クラウドは最大4つのvCPUと8ギガバイトのメモリを割り当てることができます。

コンピュートエンジンのような他のコンピュート製品のほとんどは、サーバーが稼働している限り、たとえ使っていなくても課金されます。つまり、アイドル状態のサーバーの容量に対して料金を支払っていることが多いのです。

Linux 64ビット用にコンパイルされたバイナリであれば、Cloud Runを使って実行することができます。つまり、Java、Python、Node.js、PHP、Go、C++などの一般的な言語を使って書かれたウェブアプリケーションを実行するために、Cloud Runを使用することができるのです。

また、Cobol、Haskell、Perlといったあまり一般的ではない言語で書かれたコードも実行できます。

アプリがWebリクエストを処理する限り、問題ありません。

# 8
# クラウドでの開発
多くのユーザーがGoogle Cloudの製品やサービスを使って印象的なアプリケーションを開発しています。アプリが完成したら、Google Cloud を使ってデプロイすることもできます。このセクションでは、Cloud Source Repositories、Cloud Functions、Terraformを含む、クラウドでの開発のためのGoogle Cloudのメソッドを探求していきます。その後、infrastructure as a codeを使ったデプロイメントについて見ていきます。まず、クラウドでの開発について見ていきましょう。Google Cloud の顧客の多くは、ソースコードツリーの保存、バージョン管理、管理に Git リポジトリを使用しています。つまり、彼らは独自のGetインスタンスを実行します。これは、完全な制御が必要な場合には素晴らしいオプションです。あるいは、ホストされたGitプロバイダーを使っています。これは、完全な制御が必要でない場合には、より少ない作業で済みます。しかし、Google Cloud プロジェクトでコードを非公開にし、IAM パーミッションで保護しながらも、Git インスタンスを自分で管理する必要がないという第三の選択肢があるとしたらどうでしょう。その第三の選択肢は、Cloud Source Repositories で利用できる。Cloud Source Repositories は、Google Cloud 上でホストされるフル機能の Git リポジトリを提供し、App Engine や Compute Engine 上で動作するものを含む、あらゆるアプリケーションやサービスの共同開発をサポートします。Cloud Source Repositories では、任意の数のプライベート Git リポジトリを持つことができます。これにより、クラウド・プロジェクトに関連するコードを、あなたが選んだ方法で整理することができます。また、デバッガーやエラー報告などの Google Cloud 診断ツールは、Git リポジトリのコードを使用して、デプロイされたコードの特定の領域の問題を、ユーザーの速度を落とすことなく追跡できるようになる。もしあなたのコードが既に GitHub や Bitbucket リポジトリにあれば、Cloud Project に移行して他のリポジトリと同様に使用でき、ブラウジングや診断も可能です。多くのアプリケーションにはイベントドリブンな部分があります。例えば、ユーザーに画像をアップロードさせるアプリケーションがあるとします。そのイベントが発生したとき、画像はいくつかの異なる方法で処理される必要があるかもしれません。例えば、画像を標準的なフォーマットに変換したり、サムネイルを異なるサイズに変換したり、それぞれの新しいファイルをリポジトリに保存したりといった具合です。この機能をアプリケーションに統合することもできますが、その場合、そのための計算資源を提供しなければなりません。それが1ミリ秒に1回起ころうが、1日に1回起ころうが。Cloud Functionsを使えば、不要な画像操作を完了する単一目的の関数を書き、新しい画像がアップロードされるたびに自動的に実行されるように手配することができる。Cloud Functionsは、イベントベースの軽量な非同期計算ソリューションであり、サーバーや実行環境を管理することなく、クラウドのイベントに対応する小さな単一目的の関数を作成することができる。これらの関数は、個々のビジネスロジック・タスクからアプリケーション・ワークフローを構築するために使用することができます。また、クラウドファンクションを使って、クラウドサービスを接続・拡張することも可能です。100ミリ秒単位で課金されます。ただし、コードが実行されている間だけです。個々のクラウド・ファンクションは、JavaScript、Node.js、Python、またはGoで記述され、Google Cloud上のマネージドNode.js環境で実行される。Cloud StorageやPub Subからのイベントは、Cloud Functionsを非同期でトリガーすることができます。また、HTTP呼び出しで同期的に実行することもできる。

# デプロイメント Infrastructure as Code（インフラストラクチャー・アズ・コード
Google Cloud で環境を作成することは、コンピュータネットワークやストレージリソースを設定し、それらの設定を追跡するなど、多くの作業を意味します。この作業は、環境を思い通りにセットアップするために必要なコマンドを書くことで、手動で行うことができる。しかし、環境を変更する場合はコマンドを更新し、環境を複製する場合は新しいコマンドを手動で記述する必要があり、手間がかかる。それよりも、テンプレートを使った方が効率的です。テンプレートを使えば、設定ファイルを書くのと同じように、アプリケーション環境の仕様を書くことができる。そして、そのテンプレートをスカウト環境にデプロイすることで、同じアプリケーション環境を必要な数だけ素早く作成することができます。これはTerraformで実現できます。Terraformを使うには、HashiCorpの設定言語であるHClを使って、環境の構成要素をどのようなものにするかを記述したテンプレートファイルを作成します。Terraformはそのテンプレートを使って、テンプレートに記述された環境を作るために必要なアクションを決定します。環境を変更する必要がある場合は、テンプレートを編集し、Terraformを使用して変更内容に合わせて環境を更新することができます。Terraformのテンプレートは、Cloudのソースリポジトリにバージョン管理で保存することができます。

# 9
# モニタリングの重要性
このセクションでは、クラウドでの開発とデプロイメントから、ロギングとモニタリングに焦点を移します。まず、モニタリングから始めましょう。モニタリングは、製品の信頼性の基礎となるものです。モニタリングは、トレンドやアプリケーションの使用パターンを示すことで、緊急に対応する必要があるものを明らかにし、より良いキャパシティプランニングを可能にします。Google Site Reliability Engineeringの書籍はlanding.google.com/sre/booksで読むことができます。

モニタリングとは、クエリの数や種類、エラーの数や種類、処理時間、サーバの寿命など、システムに関する定量的なデータをリアルタイムに収集、処理、集計、表示することと定義されています。モニタリングによって、システムの継続的な運用を保証し、長期的な傾向分析を明らかにし、ダッシュボードを構築し、システムが事前に定義されたサービスレベル目標に違反した場合に担当者に警告し、システムとシステムの変化を比較し、インシデント対応を改善するためのデータを提供することができるようになるのです。いくつかのタスクを挙げるだけです。アプリケーションのクライアントは通常、製品のパブリックサイドしか見ないため、開発者とビジネス関係者の両方が、クライアントを満足させる最も重要な方法は、製品のその部分の開発に最も多くの時間と労力を費やすことであると考えがちです。しかし、本当に信頼できる製品であるためには、どんなに優れた製品でも、想定されるクライアントの負荷を処理するのに十分な容量を持つ環境に配備する必要があります。また、優れた製品には徹底的なテストが必要です。できれば、洗練された継続的インテグレーションと継続的開発によるリリースパイプラインで自動化されたテストが必要です。事後分析と根本原因分析は、DevOpsチームがクライアントにインシデントの発生理由と再発防止策を知らせるための方法です。この文脈では、システムやソフトウェアの障害について議論していますが、インシデントという用語はセキュリティの侵害を表す場合にも使われることがあります。ここでは、信頼を築くために透明性が重要です。私たちは、製品を継続的に改善する必要があり、そのためにモニタリングから得られるデータが必要です。ビジネスインテリジェンスを提供するダッシュボードが必要で、DevOps担当者が仕事に必要なデータを入手できるようにします。さらに良い方法は、できるだけ多くのアラートを処理する自動化システムを構築することで、人間は最も重要な問題にしか目を向ける必要がなくなります。最後に、アプリケーションの機能やパフォーマンスの問題をデバッグするために重要なデータを提供するモニタリング・ツールが必要です。このモジュールの後半で、Googleの統合監視ツールについてもう少し詳しく見ていきます。

# 性能と信頼性の測定
システムの性能と信頼性を測る4つのゴールデンシグナルがあります。それは、レイテンシー、トラフィック、飽和、エラーです。レイテンシーは、システムの特定の部分が結果を返すまでにかかる時間を測定します。レイテンシーが重要なのは、ユーザー・エクスペリエンスに直接影響すること、レイテンシーの変化が新たな問題を示唆していること、その値が容量需要と結びついていること、そしてシステムの改善度を測定するために使用できることです。しかし、具体的にどのように測定するのでしょうか？レイテンシーの測定基準の例としては、ページロードのレイテンシー、スレッド待ちのリクエスト数、クエリー時間、サービス応答時間、トランザクション時間、最初の応答までの時間、データ復帰完了までの時間、などが挙げられます。次のシグナルはトラフィックで、システムに到達したリクエストの数を測定します。トラフィックは、現在のシステム需要の指標となるため、重要です。トラフィックの過去のトレンドはキャパシティプランニングに使用され、インフラストラクチャの支出を計算する際の中核となる指標です。トラフィックの測定基準の例としては、1秒あたりのHTTPリクエスト数、静的コンテンツと動的コンテンツのリクエスト数、ネットワークI/O、同時セッション数、1秒あたりのトランザクション数、1秒あたりの検索数、アクティブリクエスト数、書き込み操作数、読み取り操作数、アクティブ接続数などが挙げられます。3つ目のシグナルは飽和で、システムがどれだけ容量に近いかを測定します。ただし、容量は、基盤となるサービスやアプリケーションに依存する主観的な尺度であることが多いので、注意が必要です。飽和が重要なのは、サービスがどれだけ充実しているかを示す指標であり、最も制約の多いリソースに焦点を当て、容量に達したときにパフォーマンスの劣化につながることが多いからです。キャパシティ・メトリクスの例としては、メモリ使用率、スレッド・プール使用率、キャッシュ使用率、ディスク使用率、CPU使用率、ディスク容量、メモリ容量、接続可能数、システム上のユーザ数などがあります。4つ目のシグナルはエラーで、システム障害やその他の問題を測定するイベントである。エラーは、コンピュータ・プログラムやシステムの欠陥、故障、誤動作によって、不正確な結果や予期せぬ動作をする場合に発生することが多い。エラーは、何かが故障していることを示す場合もあれば、構成や容量の問題を示す場合もあり、サービスレベルの目標違反を示す場合もあり、また、エラーはアラートを送信する時期であることを意味する場合もあるので重要である。エラーメトリクスの例：不正解は不正なコンテンツ、400および500のHTTPコードの数、失敗したリクエストの数、例外の数、スタックトレースの数、有効性チェックに失敗したサーバー、およびドロップされた接続の数など。

# SLI、SLO、およびSLAを理解する
ここで、SLSSLOSとSLASに焦点を移そう。これらはすべて、金シグナルメトリクスのシステムに対して設定される目標の一種である。サービス・レベル・インジケータまたは SLIS は、サービスの信頼性の一面を測定する、慎重に選択されたモニタリング・メトリクスです。理想的には、SLIはユーザーが経験するその信頼性と密接な線形関係を持つべきで、2つの数値の比率、つまり有効なイベントの数で割った良いイベントの数として表現することをお勧めします。サービスレベル目標（SLO）は、サービスレベル指標と目標信頼性を組み合わせたものです。一般に推奨されているようにSLSを表現した場合、SLOSは一般に100%にわずかに及ばないところになります。例えば、99.9 や 3 ナインなどです。すべてを測定することはできないので、可能な限り、スマートなSLOSを選択する必要があります。SLOは具体的であるべきです。このサイトはあなたにとって十分速いですか？それは具体的ではありません。95パーセントの結果が100ミリ秒以下で返されるというような文は具体的です。SLOSは、測定可能な指標に基づく必要があります。多くのモニタリングは、時間をかけてグループ化された数字に数学を適用したものです。SLIは、数値またはデルタでなければならない 何か私たちは数学的な方程式で測定することができます。SLOの目標は達成可能なものでなければならない。100％の可用性というと聞こえはいいが、長期間にわたって維持することはおろか、取得することも不可能である。SLOは関連性のあるものでなければならない。ユーザーにとって重要か？アプリケーション関連の目標を達成するのに役立つか？もしそうでなければ、それは悪い指標です。そして、SLOは時間的制約があるべきです。あなたは、サービスが99％利用可能であることを望みます。それは結構なことです。それは年単位ですか？月単位、日単位ですか？計算は、例えば日曜日から日曜日までの設定された時間の特定のウィンドウを見るのでしょうか？それとも、過去7日間の連続した期間なのでしょうか。このような質問に対する答えがわからなければ、正確に測定することはできません。そして、サービス・レベル・アグリーメント（SLA）とは、システムやアプリケーションのダウンタイムが一定量にとどまることを顧客に約束するものです。SLAは、あなたが顧客に提供すると約束したサービスの最低レベルを記述したもので、その約束を破った場合はどうなるのでしょうか。もしあなたのサービスが有料であれば、SLAには、そのサービスがこの契約よりも長い時間停止した場合に、返金やクレジットで補償する方法が含まれているかもしれません。問題を発見し、評判が落ちる前に改善策を講じる機会を提供することです。警告のしきい値は、SLAに記載されているサービスの最低レベルよりもかなり高いことが多い。SLOSSLIS と SLAS がサービスの信頼性を向上させるためには、ビジネスのすべての部分が、それらがユーザー体験の正確な尺度であることに同意し、さらにそれらを意思決定のための主要なドライバーとして使用することに同意する必要があります。SLO を逸脱した場合は、SLS を逸脱した場合と同様に、具体的な結果を文書化する必要があります。たとえば、変化の速度を遅くし、リスクを排除して信頼性を向上させるためにエンジニアリングの努力を傾けることは、製品を SLOS に迅速に適合させるために取るべき行動です。運用チームは、これらの結果を強制し、開発手法に変化をもたらすために、経営陣の強力なサポートを必要としています。

# 統合された観測可能なツール
このセクションの最後に、Google Cloudの統合されたモニタリング、ロギング、エラーレポート、およびデバッグツールについて見てみましょう。オンプレミス環境で仕事をしたことがあるなら、サーバーに物理的に触れることができることをご存じでしょう。アプリケーションが応答しなくなった場合、その原因を物理的に特定することができます。しかし、クラウドでは、サーバーは自分のものではなく、Googleのものであり、物理的に検査することはできません。では、サーバーやデータベース、アプリケーションに何が起きているのか、どうやって知ることができるのでしょうか？その答えは、Googleの統合された観測可能なツールを使うことです。観測可能性はシグナルから始まる。シグナルとは、ハードウェア層から上のGoogle製品に取り込まれ、統合されたメトリック、ロギング、トレースデータだ。これらの製品から、シグナル・データはGoogle Cloudのオペレーション・ツールに流れ込み、ダッシュボードやメトリクス・エクスプローラで可視化することができる。自動化されたログやカスタムログは、ログエクスプローラーで解析することができる。サービスは、サービスレベル目標への準拠を監視し、エラーバジェットを追跡することができます。ヘルスチェックを使用して、外部向けサイトやサービスのアップタイムとレイテンシーをチェックし、実行中のアプリケーションをデバッグおよびプロファイリングすることができます。インシデントが発生した場合、シグナルデータからコードに自動アラートを生成したり、さまざまな情報チャネルを通じて主要な担当者にアラートを送信したりすることができます。エラー報告は、運用と開発チームがクラウドベースのサービスにおけるクラッシュを発見、カウント、分析するのに役立ち、サービスレベル目標を遵守する必要があり、可視化および分析ツールは、Google Cloudで何が起こっているかのトラブルシューティングを支援することができます。最終的には、Google がオンプレミスよりも正確な洞察をクラウド インストレーションに提供するので、サーバーに簡単にアクセスできることを見逃すことはないでしょう。次のビデオでは、監視、ログ記録、エラー報告、およびデバッグを行う運用担当者に最も適した、Google Cloud が提供する製品とツールを探ります。

# モニタリングツール
DevOps担当者がGoogle Cloud Projectsの内部で何が起こっているかを正確に追跡したいと思ったとき、多くの場合、まずモニタリングを思い浮かべます。前述したように、モニタリングはシグナルデータから始まります。メトリクスは計測を行い、その計測値を時系列に並べるために数学を使用します。例えば、生のCPU使用率の測定値を取り、それを平均して1分ごとに1つの値を生成するようなものである。Google Cloudはデフォルトで1,000種類以上のメトリクスデータを収集し、ダッシュボード、アラート、その他いくつかの重要なツールに組み込むことができます。データサイエンティストがBigQueryで大規模なスケーラブルクエリを実行する場合、現在実行中のクエリの数、スキャンされて請求書に追加されたバイト数、データスロット使用パターンを知ることは重要である。また、コンテナ化されたアプリケーションやCloud Runを実行しているDevOpsチームにとっても、CPUやメモリの使用状況やアプリの構築時間を知ることは重要なことかもしれません。同じDevOpsチームが、カスタムアプリケーションが実行されているときはいつでも、そのアプリケーションからのシグナルメトリクスを補強したい場合は、オープンソースのOpenTelemetryを使用して、独自のメトリクスを作成し、Compute Engine上のワークロードは、稼働時間、ディスクスループット、その他の多くのメトリクスとともに、CPUとメモリの使用率データの恩恵を受けることができる。クラウドモニタリングは、クラウドを利用したアプリケーションのパフォーマンス、稼働率、および全体的な健全性を可視化するものです。プロジェクト、ログ、サービス、システム、エージェント、カスタム・コード、およびCassandra、Nginx、Apache Web Server、Elasticsearchなどのさまざまな共通アプリケーション・コンポーネントから、メトリクス、イベント、およびメタデータを収集します。クラウド・モニタリングはデータを取り込み、ダッシュボード、メトリクス・エクスプローラ・チャート、自動化されたアラートによって洞察を生成します。

# ロギングツール
このビデオでは、Googleクラウドに統合されたロギングツールを見ていきます。

クラウドロギングにより、ユーザーはログエントリやイベントの収集、保存、検索、分析、監視、警告を行うことができます。自動ログ収集は、アプリエンジン、クラウドラン、ログエージェントを実行するコンピュートエンジンVMSやGKEなどのGoogleクラウド製品に統合されています。

ログ解析のほとんどは、Googleクラウドの統合ログエクスプローラーで始まります。また、ログを複数の場所にエクスポートして、別の分析やさらなる分析を行うことも可能です。

Pub-subメッセージは、カスタムコードやデータフローのようなストリーム処理技術を使って、ほぼリアルタイムで分析することができます。

このような場合、「ビッグクエリ」を利用することで、解析者はシーケンシャルクエリを通じてログデータを調査し、アーカイブログファイルやクラウドストレージをいくつかのツールや技術で解析することができる。

ログデータは、クラウドストレージにファイルとして、パブサブを通じてメッセージとして、または大きなクエリテーブルにエクスポートすることができます。ログベースのメトリクスを作成し、クラウド監視、ダッシュボード、アラート、サービスのSLOSに統合することができます。データアクセスログのデフォルトの保存期間は30日間ですが、最大3650日まで設定可能です。管理者ログはデフォルトで100日間保存され、ログをクラウドストレージやビッグクエリにエクスポートして保存期間を延長することができます。

このような場合、「クラウドを利用する」「クラウドを利用する」「クラウドを利用する」「クラウドを利用する」という3つの選択肢があります。

クラウド監査ログは、「誰が、いつ、どこで、何をしたのか」という問いに答えるのに役立ちます。

管理者の活動記録、設定の変更。

データアクセスは、リソースの構成またはメタデータを読み取る呼び出しと、ユーザーが提供するリソースデータの作成、変更、読み取りを行うユーザー主導の呼び出しを追跡します。システムイベントは、リソースの構成を変更する非人間的な Google Cloud 管理アクションです。また、アクセスの透明性では、コンテンツにアクセスする際にグーグルの担当者が取った行動をログに記録します。エージェントログは、AWSやGoogle CloudのVMにインストールできる、Googleがカスタマイズしパッケージ化したfluentdエージェントを使用し、Google Cloudインスタンスからログデータを取り込みます。例えば、コンピュートエンジン、マネージドVMSやコンテナ、AWS EC2インスタンスなどです。ネットワークログは、ネットワークとセキュリティの両方のオペレーションに、詳細なネットワークセキュリティの遠隔測定を提供します。VPCフローログは、VPCネットワークフローのサンプルを記録し、ネットワーク監視、フォレンジック、リアルタイムのセキュリティ分析、費用の最適化に使用することができます。

ファイアウォールルールのロギングにより、ファイアウォールルールの効果を監査、検証、分析することができます。

Natゲートウェイのログは、Natネットワーク接続とエラーに関する情報を取得します。

Service logs は、Google cloud にコードをデプロイしている開発者が作成したログにアクセスすることができます。例えば、node dot js を使ってコンテナを構築し、クラウドにデプロイした場合、standard out や standard air に記録されたログは自動的にクラウドログに送られ、簡単に一元的に見ることができるようになります。

# エラー報告・デバッグツール
このセクションの最後に、エラー報告とデバッグのために Google Cloud が提供するツールについて見てみましょう。エラー報告は、実行中のクラウド サービスにおけるクラッシュをカウント、分析、集計します。ほとんどのモダンな言語でのクラッシュは、コード自体で捕捉・処理されない例外です。その管理インターフェースは、ソートやフィルタリングの機能とともに結果を表示します。専用のビューには、エラーの詳細、タイムチャート、発生状況、影響を受けたユーザーアカウント、最初と最後に見た日付、クリーンな例外スタックトレースが表示されます。また、アラートを作成し、新しいエラーの通知を受け取ることも可能です。Cloud Debugger では、アプリケーションを停止したり速度を落としたりすることなく、本番環境下でデバッグを行うことができるため、コード、機能、パフォーマンスを実際の本番環境下で検証することができます。コンソールのURLを送信するだけでデバッグセッションを共有できるので、他のチームメンバーとのコラボレーションも簡単です。スナップショットにより、特定の行の位置でアプリケーションとプロダクションの状態をキャプチャすることができます。ログポイントを使用して、特定の行位置でオンデマンドに新しいログステートメントを注入することができます。また、アプリケーションの言語で書かれた簡単な条件式を使って、必要な時にスナップショットをキャプチャしたり、ログポイントメッセージを書き込んだりすることができます。Cloud Debugger は、既存の開発者ワークフローに簡単に統合できます。クラウドのロギング、エラーレポート、ダッシュボード、IDE、GCloudコマンドラインインターフェースから直接デバッガーを起動し、スナップショットを取得することが可能です。Debugger は、Cloud Source Repositories、GitHub、Bitbucket、GitLab などのバージョン管理システムと容易に統合できるため、ソースコードの正しいバージョンを表示する方法を知っています。Cloud Traceは、Googleがプロダクションサービスで使用しているツールをベースにしたトレースシステムで、分散アプリケーションからレイテンシーデータを収集し、Google Cloud Consoleに表示するものである。Traceは、App Engine、Compute Engine VM、Kubernetes Engineコンテナ上にデプロイされたアプリケーションからトレースを取得することができます。パフォーマンスに関する考察は、ほぼリアルタイムで提供されます。Traceは、アプリケーションのすべてのトレースを自動的に解析し、詳細なレイテンシレポートを生成して、パフォーマンスの低下を表面化します。Traceは、トレースデータを継続的に収集、分析し、アプリケーションのパフォーマンスに対する最近の変化を自動的に特定します。パフォーマンスの低いコードは、誰にも知られず、誰も何もしないまま、アプリケーションやWebサービスのレイテンシとコストを毎日増加させています。Cloud Profilerは、統計的手法と極めて低負荷のインスツルメンテーションを使用してこれを変更し、すべての本番アプリケーションインスタンスで実行することで、アプリケーションのCPUとヒープに関する全体像を、速度を落とすことなく提供します。Compute Engine VM、App Engine、Kubernetesなど幅広いプラットフォームに対応しているため、開発者はGoogle Cloud、その他のクラウドプラットフォーム、Javaをサポートするオンプレミスなど、あらゆる場所で稼働するアプリケーションを分析することができます。Go、Python、Node.jsをサポートしています。Cloud Profilerは、関連する関数のコール階層とリソース消費をインタラクティブなフレームグラフィックで表示し、開発者がどのパスが最もリソースを消費しているか、コードが実際にコールされるさまざまな方法を理解するのに役立ちます。

# クラウドモニタリングとAmazon CloudWatchの比較
AWSとGoogle Cloudは、それぞれのプラットフォームに対して統合されたモニタリング・サービスを提供している。Amazon CloudWatchはAWSのロギングとモニタリングの両方を提供し、Cloud loggingとCloud monitoringはGoogle Cloudのロギングとモニタリングのサービスをそれぞれ提供する。この2つの技術がお互いにどのようにマッピングされるかを見てみよう。Amazon CloudWatchは、AWSアカウントで使用されているサービスのメトリクスを収集する。Cloud monitoringでは、Google Cloudプロジェクトをワークスペースに追加することができ、そのGoogle Cloudプロジェクトのメトリクスを収集する。追加されたすべてのGoogle Cloudプロジェクトのメトリクスは、そのワークスペース下のCloud Monitoringで利用可能である。Amazon CloudWatchは、AWSクラウド・サービスを自動的に監視する。In Cloud Monitoringは、Google Cloudサービスを自動的に監視する。どちらのサービスも、エージェントを通じて追加のメトリクスを収集し、カスタムメトリクスを書き込む機能を提供しています。Amazon CloudWatchエージェントとクラウド・モニタリング・エージェントの両方で、サードパーティ・ソースからメトリクスを取り込むように設定することができます。Amazon CloudWatchは、AWSアカウントでメトリクスを分離し、次にリージョンで分離する。メトリクスは、AWSアカウントとAWSリージョンの組み合わせの中で集約される。クラウドモニタリングは、ワークスペースに追加されたすべてのGoogle Cloudプロジェクトからのメトリクスを含む。メトリクスは、ワークスペースとGoogle Cloudプロジェクトの組み合わせで区切られている。クラウドモニタリングのアカウント内でメトリクスを集計することができます。クラウドモニタリングとAmazon CloudWatchの両方が、そのクラウドサービスから自動的にメトリクスを収集する。CloudWatchエージェントは、EC2インスタンスやオンプレミスサーバーから、より多くのシステムレベルのメトリクスを収集する機能を提供する。クラウドモニタリングエージェントは、仮想マシンインスタンスからシステムやアプリケーションのメトリクスを収集することができる。さらに、クラウドモニタリングのPrometheusエージェントは、ロギングサービスであるPrometheusを通じて公開されるメトリクスを収集する。どちらの技術でも、カスタムメトリクスを公開することができます。Amazon CloudWatchとCloud monitoringのメトリクスデータタイプは、似たような構造になっています。メトリクス構造の最大の違いは、クラウド監視メトリクスが複数のメトリクスと値のタイプを提供することです。一方、Amazon CloudWatchは、統計セットを除く。Amazon CloudWatch APIは、値型がdoubleのメトリクスを除いています。また、APIは集約されたメトリクスである統計セットも受け入れる。クラウドモニタリングは、3つのタイプのメトリクスを受け入れる。Gauge、delta、cumulativeの3種類です。クラウドモニタリングは6週間、Amazon CloudWatchはメトリクスのデータ型に基づいてメトリクスの情報を保持します。amazon CloudWatchとクラウドモニタリングの両方が、メトリクス値に基づいてアクションを起こす機能を提供します。Amazon CloudWatchでは、これらの閾値はアラームと呼ばれています。また、クラウドモニタリングでは、アラートポリシーと呼ばれています。AWSとクラウドモニタリングは、どちらも世界中の拠点からアクセスしてサービスの可用性を検証するツールを提供しています。AWSはRoute 53のヘルスチェック、クラウドモニタリングはアップタイムチェックを利用する。どちらもアラーム、アラート、ダッシュボードで使用できるサーフェスメトリクスをチェックする。最後に、どちらの技術も、クラウド・コンソール、SDK、API、クライアント・ライブラリを介したサービス・アクセスをサポートしている。

# コース概要
Google Cloud Fundamentals Core Infrastructure Training Course を修了された皆様、おめでとうございます！出発前に、モジュール 1 で学んだことを復習しましょう。Googleクラウドとクラウドコンピューティングについて紹介し、Infrastures of ServiceとPass Platform as a Serviceを通じて、マネージドインフラとマネージドサービスの概念を学びました。Google Cloud のネットワーク、Google Cloud がインフラストラクチャ全体のセキュリティに重点を置いていること。Google がオープン ソース ライセンスと Google クラウドを使用してテクノロジーの主要要素を公開する方法、価格、構造、および課金ツール。モジュール 2 では、4 つのレベルのリソース プロジェクト、フォルダー、組織負荷で構成される Google Cloud のリソース階層について学びました。また、クラウドのアイデンティティとアクセス管理、またはクラウドI amを使用する際のポリシーの定義とその下位継承について学びました。モジュール 3 では、仮想マシンと仮想ネットワーキングを中心に、コンピュート・エンジンの仕組みについて学びました。VPC（仮想プライベートクラウド）コンピュート・エンジンのスケーリング機能や、ルーティング・テーブル、ファイアウォール、VPc、ピアリング、共有 VPC など Google Virtual Private Cloud と互換性のある重要な機能も紹介され、ネットワーク管理の必要性が低くなることが分かりました。また、クラウドのロードバランシングについても検討した。すべてのトラフィックに対応する完全分散型のソフトウェア定義マネージド・サービスです。最後に、当社のオンプレミスまたは他のクラウドネットワークをgoogle VPcで相互接続できることを比較しました。 モジュール4では、Google Cloudの5つのコアストレージのオプションについて検討しました。クラウド・ストレージ クラウドビッグテーブル また、クラウド・ストレージを構成する4つのストレージ・クラスについては、アクセス頻度の高いホット・データに使用されるスタンダード・ストレージと、アクセス頻度の低いクール・データおよびアーカイブ・ストレージに使用されるコールド・ライン・ストレージについて検討しました。モジュール 5 では、コードとその依存関係を囲む目に見えない箱であるコンテナについて学びました。コンテナベースの3つの製品を紹介しました。 kubernetesは、コンテナ化されたワークロードとサービスを管理するためのオープンソースプラットフォームです。Google kubernetes engine、クラウド上でGoogleがホストするマネージドkubernetesサービス、そしてethos。モジュール6では、最新のハイブリッドおよびマルチクラウド分散システムおよびサービス管理に対するGoogleの回答です。このモジュールでは、クラウドでのアプリケーション開発に焦点が当てられています。このモジュールでは、Webアプリケーションを大規模に開発し、ホストするためのapp engineフルマネージドサーバーレスプラットフォームと、Google Cloudが提供するapi管理ツールへの標準的かつ柔軟なapp engine環境、cloud endpointsとapogee edge in cloud run、Webリクエストやpub subイベント経由でステートレスコンテナを実行できるマネージド計算用プラットフォームについて探りました。Mulele 7からは、クラウドでの開発とデプロイに焦点を当てました。クラウドソースリポジトリとは、google.co.jpにホストされているフル機能のGitリポジトリです。クラウド。クラウド機能。軽量なイベントベースの非同期計算ソリューションで、単一目的の関数や、テンプレートを使ってアプリケーション環境の仕様を書くことができるテラフォームを作成することができます。設定ファイルを書くのと同じように、最後のモジュールでは、google cloud上のログとモニタリングに焦点を当て、システムのパフォーマンスと信頼性を測定する4つのゴールデンシグナル、レイテンシ、トラフィックの飽和とエラー、サービスレベル指標、サービスレベル目標、サービスレベル合意など、ゴールデンシグナル指標に対してシステムに設定する目標のタイプを探りましたね。そして最後に、googleの統合観測能力ツールである、クラウドモニタリング、クラウドロギング、エラー、レポート、D bugger、クラウドトレース、クラウドプロファイラを紹介します。このコースは、google cloudの旅のほんの始まりにすぎません。さらなるトレーニングや実践的な練習をしたい方は、cloud dot google dot com forward slash trainingでさまざまな学習パスを調べてみてください。また、自分の専門知識を確認し、googleクラウド技術でビジネスを変革する能力を示したい場合は、googleクラウド認定資格の取得を検討することもできます。googleクラウド認定資格の詳細については、cloud dot google dot com forward slash certificationsをご覧ください。このコースを修了していただきありがとうございました。

