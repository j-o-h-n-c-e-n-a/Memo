# 1
## 1
### Q. 問題4: 回答
あなたはGoogle CloudリソースのTerraformデプロイを実行するCI/CDパイプラインを作成しています。CI/CDツーリングはGoogle Kubernetes Engine（GKE）で実行され、各パイプラインの実行にエフェメラルなポッドを使用します。ポッド内で実行されるパイプラインが、Terraformデプロイを実行するための適切なIAM（Identity and Access Management）権限を持っていることを確認する必要があります。ID管理についてはGoogleが推奨するプラクティスに従う必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. 新しいKubernetesサービスアカウントを作成し、そのサービスアカウントをポッドに割り当てます。Workload Identityを使用して、Googleサービスアカウントとして認証します
2. 新しいGoogleサービスアカウントを作成し、適切なIAM権限を割り当てます
3. Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、そのキーをKubernetesシークレットとして保存し、そのキーをポッドに注入し、GOOGLE_APPLICATION_CREDENTIALS環境変数を設定します
4. Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、CI/CDツールのシークレット管理ストアにキーを保存し、認証にこのキーを使用するようにTerraformを設定します
5. ポッドを実行するCompute Engine VMインスタンスに関連付けられたGoogleサービスアカウントに、適切なIAMパーミッションを割り当てます
<details><div>
    答え：1,2
説明
この問題では、CI/CDパイプラインでGoogle CloudリソースのTerraformデプロイを実行するためのIAM権限管理について質問がされています。特に、Google Kubernetes Engineで実行されるエフェメラルなポッドが適切な権限を持っていることが必要で、Googleの推奨するID管理のプラクティスに従うことが求められています。ここで、ロールを持つインスタンスとそのアクセス管理を安全に管理する方法として、Kubernetesサービスアカウントの作成とその割り当て、Workload Identityの使用、Googleサービスアカウントの作成とIAM権限の管理などが試験対策となります。選択肢を読み解く際には、GoogleのID管理のベストプラクティスと、セキュリティや運用面でのコンソールからの各種設定の違いに注目することが必要です。
基本的な概念や原則：
Terraform：Infrastructure as Codeツールで、クラウドリソースのデプロイを自動化します。Google CloudのリソースやIAMポリシーなど、多くのGoogle Cloudサービスがサポートされています。
Google Kubernetes Engine（GKE）：Kubernetesのマネージド環境を提供するGoogle Cloudサービスです。クラスター管理やオートスケーリングなどの機能があります。
エフェメラルポッド：一時的に作成され、タスク完了後にすぐに削除されるKubernetesのポッドです。CI/CDパイプラインなど短期間のタスクに適しています。
IAM権限：Google Cloudサービスのリソースに対するアクセスを制御する機能です。サービスアカウントに対して適切な権限を割り当てることで、適切なアクセス制御が可能になります。
Kubernetesサービスアカウント：Kubernetes内での身元証明とアクセス制御を行うアカウントです。特定のポッドに割り当てることができます。
Workload Identity：GKE上のサービスアカウントをGoogle Cloudのサービスアカウントにマッピングする機能です。これにより、GKEの各ポッドは適切なIAM権限を持つことになります。
Googleサービスアカウント：Google Cloudリソースに対するアクセスを認証・認可するための特殊なアカウントです。適切なIAM権限を持つことで、リソースへの安全なアクセスが可能になります。
正解についての説明：
（選択肢）
・新しいKubernetesサービスアカウントを作成し、そのサービスアカウントをポッドに割り当てます。Workload Identityを使用して、Googleサービスアカウントとして認証します
・新しいGoogleサービスアカウントを作成し、適切なIAM権限を割り当てます
この選択肢が正解の理由は以下の通りです。
まず、問題文の最初の要件である"ポッド内で実行されるパイプラインが、Terraformデプロイを実行するための適切なIAM権限を持っていること"を満たすために、新しいGoogleサービスアカウントを作成し、適切なIAM権限を割り当てることが必要です。このようにすることで、CI/CDツールが実行されるGKE環境を、実際にリソースのデプロイメントや更新を行うためのIAM権限を持つアカウントとして扱うことができます。
次に、Googleの推奨するプラクティスに従うために、新しいKubernetesサービスアカウントを作成し、そのサービスアカウントをポッドに割り当てます。
そして、Workload Identityを使用してGoogleサービスアカウントとして認証します。Workload IdentityはGKEのサービスアカウントとGoogle Cloudのサービスアカウントを関連付けるシステムで、これによってCI/CDパイプラインが実行されるポッドが適切なアイデンティティと権限を持つようになります。これにより、エフェメラルなポッドがTerraformデプロイを実行するための十分な権限を持つように、安全かつ効率的に許可とアイデンティティの管理が可能になります。
不正解についての説明：
選択肢：Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、そのキーをKubernetesシークレットとして保存し、そのキーをポッドに注入し、GOOGLE_APPLICATION_CREDENTIALS環境変数を設定します
この選択肢が正しくない理由は以下の通りです。
JSONサービスアカウントキーの使用は、キーのライフサイクル管理や機密性保持が難しく、Googleの推奨するプラクティスではありません。
代わりに、Workload Identityを使用してサービスアカウントを認証する方法が推奨されています。
選択肢：Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、CI/CDツールのシークレット管理ストアにキーを保存し、認証にこのキーを使用するようにTerraformを設定します
この選択肢が正しくない理由は以下の通りです。
JSONサービスアカウントキーの使用はセキュリティ上のリスクを引き起こし、Googleが推奨するプラクティスを満たしません。
これに対して、適切なIAM権限を持たせてWorkload Identityを使用することで、セキュリティが強化され、Terraformデプロイの認証も確実に行えます。
選択肢：ポッドを実行するCompute Engine VMインスタンスに関連付けられたGoogleサービスアカウントに、適切なIAMパーミッションを割り当てます
この選択肢が正しくない理由は以下の通りです。
ポッドのIAM権限はCompute Engine VMインスタンスのサービスアカウントからではなく、Kubernetesサービスアカウントから派生すべきです。これはGoogleの推奨するプラクティスに従っていません。GKE上でのID管理にはWorkload Identityを使用すべきです。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://www.terraform.io/docs/providers/google/guides/provider_reference.html
</div></details>

### Q. 問題9: 未回答
あなたのチームは、Google Cloudの内外にデプロイする新しいアプリケーションを設計しています。システムリソースの使用率などの詳細なメトリクスを収集する必要があります。この収集システムのセットアップに必要な作業量を最小限に抑えながら、一元化されたGoogle Cloudサービスを使用したいと考えています。
この要件を満たすために、どうすればよいですか？

1. Google Cloud Operation Suite Debuggerパッケージをインポートし、タイミング情報を含むデバッグメッセージを出力するようにアプリケーションを設定します
2. 両方のロケーションにアプリケーションパフォーマンスモニタリング（APM）ツールをインストールし、分析のために中央データストレージロケーションへのエクスポートを構成します
3. Google Cloud Operation Suite Profilerパッケージをインポートし、さらなる解析のためにGoogle Cloud Operation Suiteに関数のタイミングデータをリレーするように設定します
4. タイミングライブラリを使ってコードを計測し、Google Cloud Operation Suiteによってスクレイピングされるヘルスチェックエンドポイント経由でメトリクスを公開します
<details><div>
    答え：3
説明
この問題では、Google Cloudと他のプラットフォームにデプロイする新しいアプリケーションで詳細なメトリクスを収集し、それらメトリクスの設定に必要な作業量を最小限に抑えるための戦略が求められています。システムのメトリクスの収集のためのツールやサービスを選択する際のポイントとしては、その手軽さ、一元化への対応力、そしてGoogle Cloudとの互換性が考慮すべき特徴となります。またGoogle Cloud内外両方の環境で使用できることも求められています。そこで選択肢は、適切なGoogle Cloud Operation Suiteのパッケージかツール選択に関するものとなります。
基本的な概念や原則：
Google Cloud Operation Suite：Google Cloudの監視、トラブルシューティング、アプリケーションのパフォーマンス分析を行うための統合されたツールセットです。このツールを使用すると、システムに関する詳細な情報を容易に収集できます。
Profilerパッケージ：Google Cloud Operation Suiteの一部で、実行中のアプリケーションからのパフォーマンス情報を収集します。詳細なプロファイリングデータを提供し、ボトルネックの解析などに使用できます。
Debuggerパッケージ：Google Cloud Operation Suiteの一部のデバッグツールです。アプリケーションの動作を詳細に追跡し、エラーや不具合の原因を特定します。
タイミングライブラリ：コードの実行時間を計測するためのツールやライブラリです。これを使って特定の処理のパフォーマンスを測定することが可能です。
ヘルスチェック：システムの健全性をモニタリングするためのテストです。Google Cloud Operation Suiteはヘルスチェックの結果を監視し、問題があればアラートを出します。
アプリケーションパフォーマンスモニタリング（APM）ツール：アプリケーションのパフォーマンスを継続的に監視し、問題を検出するためのツールです。実行時間、エラーレートなどのパフォーマンス指標を収集します。
正解についての説明：
（選択肢）
・Google Cloud Operation Suite Profilerパッケージをインポートし、さらなる解析のためにGoogle Cloud Operation Suiteに関数のタイミングデータをリレーするように設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Operation Suite（旧Google Cloud Operation Suite）は、Google Cloudの内外で動作するアプリケーションの監視、トラブルシューティング、アラートのためのパワフルな監視ツールです。ここで提案されているCloud Operations Profilerは、Operations Suiteの一部であり、実行中のアプリケーションをプロファイリングし、関数のタイミングやシステムリソースの利用状況などの詳細なメトリクスを収集し分析します。この情報をCloud Operation Suiteにリレーすることで、すべての情報を一元化し、パフォーマンス分析や問題解決を容易にします。
また、Profilerパッケージをインポートするだけで、アプリケーションにプロファイリング機能を追加できるため、セットアップに必要な作業量を最小限に抑えることができます。これらの理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：Google Cloud Operation Suite Debuggerパッケージをインポートし、タイミング情報を含むデバッグメッセージを出力するようにアプリケーションを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite Debuggerパッケージは、主にアプリケーションの不具合を解析する仕組みで、詳細なメトリクスやリソース使用状況の収集を主な目的としていません。設問の要件は詳細なメトリクスの収集と一元化された管理を求めているため、Cloud Operation Suite Profilerパッケージの使用が適切です。
選択肢：タイミングライブラリを使ってコードを計測し、Google Cloud Operation Suiteによってスクレイピングされるヘルスチェックエンドポイント経由でメトリクスを公開します
この選択肢が正しくない理由は以下の通りです。
タイミングライブラリを使用してコードを計測すると、セットアップに必要な作業量が増えます。
一方、Google Cloud Operation Suite Profilerパッケージをインポートする方が作業量を最小限に抑えながら詳細なメトリクスを取得できます。
選択肢：両方のロケーションにアプリケーションパフォーマンスモニタリング（APM）ツールをインストールし、分析のために中央データストレージロケーションへのエクスポートを構成します
この選択肢が正しくない理由は以下の通りです。
APMツールを両方のロケーションにインストールする方法は、セットアップに必要な作業量を増大させます。
そして、中央データストレージロケーションへのエクスポートを構成しなければならない点も面倒な作業となります。
それに対し、Google Cloud Operation Suite Profilerパッケージを利用することで作業量が大幅に削減できます。
参考リンク：
https://cloud.google.com/profiler/docs/profiling-external
https://cloud.google.com/profiler/docs
https://cloud.google.com/monitoring/docs
</div></details>

## 2

## 3
### Q. 問題7: 未回答
セキュリティのシフトレフトを目指すあなたの会社のイニシアチブの一環として、InfoSecチームは全チームに対し、すべてのGoogle Kubernetes Engine（GKE）クラスターにガードレールを実装し、信頼され承認されたイメージのデプロイのみを許可するよう求めています。あなたは、セキュリティのシフトレフトというInfoSecチームの目標を満たす方法を決定する必要があります。
この要件を満たすために、どうすればよいですか？
1. Artifact Registryでコンテナ分析を有効にし、コンテナイメージの一般的な脆弱性と暴露（CVE）をチェックします
2. 実行中のポッドの脆弱性を監視するために、FalcoまたはTwistlockをGKEにデプロイします
3. IAM（Identity and Access Management）ポリシーを構成して、GKEクラスターに最小権限モデルを作成します
4. バイナリ認証を使用して、CI/CDパイプラインでイメージを認証します
<details><div>
    答え：4
説明
この問題では、セキュリティのシフトレフトという概念とその具現化を理解することがキーとなります。シフトレフトは開発プロセスの早い段階でセキュリティを取り入れることを意味し、すべてのGKEクラスターにおいて信頼できるイメージのみデプロイするという要求が出されています。選択肢を見るときには、この目指すべき状態を満たす手段に焦点を当て、GKEのクラスターレベルで操作するよりも早い段階、つまりCI/CDパイプラインのステージでセキュリティを担保する選択肢を探すべきです。
基本的な概念や原則：
バイナリ認証：Google Kubernetes Engine（GKE）環境でのコンテナイメージの実行を制御するための運用時間のセキュリティ機能です。信頼されたソースからのイメージのみがデプロイできるようにします。
セキュリティのシフトレフト：セキュリティの考慮をプロジェクトの初期段階に持ち込むアプローチです。開発プロセスの初期段階でセキュリティ問題を検出し、修正します。
Artifact Registry：Google Cloudのパッケージ管理サービスで、Dockerコンテナイメージや言語ベースのパッケージを保存、管理します。ワークロードのセキュリティと信頼性を向上させるために使用します。
IAM（Identity and Access Management）：Google Cloudリソースへの認証と認可を管理するサービスです。IAMポリシーを使って、特定のユーザーが特定のリソースに対して何をすることができるかをコントロールします。
Falco、Twistlock：Kubernetesセキュリティのツールです。実行中のポッドの脆弱性を監視し、不正な行為を検出します。
CI/CDパイプライン：継続的インテグレーション（CI）と継続的デリバリー（CD）を組み合わせた開発プロセスです。コードの変更を自動的にビルド、テスト、デプロイします。
正解についての説明：
（選択肢）
・バイナリ認証を使用して、CI/CDパイプラインでイメージを認証します
この選択肢が正解の理由は以下の通りです。
まず、バイナリ認証はGoogle Cloudのサービスで、信頼できるイメージのみがデプロイされることを保証します。これは、環境に対する全てのイメージデプロイを制御し、未承認や不明なソースからのデプロイを防ぎます。そのため、InfoSecチームが求めている"信頼され承認されたイメージのデプロイのみを許可する"という要件を満たすことができます。
次に、バイナリ認証はCI/CDパイプライン（継続的インテグレーション/継続的デリバリー）と統合され、デプロイプロセス中にイメージが信頼できるかどうかを自動的に検証します。これにより、セキュリティのシフトレフトを進めることができます。セキュリティのシフトレフトとは、開発の初期段階からセキュリティを考慮に入れるアプローチのことで、この早期に問題を特定することでリスクを軽減し、修正費用を削減することができます。
不正解についての説明：
選択肢：Artifact Registryでコンテナ分析を有効にし、コンテナイメージの一般的な脆弱性と暴露（CVE）をチェックします
この選択肢が正しくない理由は以下の通りです。
Artifact Registryでのコンテナ分析はイメージの脆弱性をチェックする機能ですが、特定のイメージのデプロイを制限するガードレールを実装する機能はありません。
一方、バイナリ認証を使用すれば、信頼され承認されたイメージのみのデプロイを実現できます。
選択肢：IAM（Identity and Access Management）ポリシーを構成して、GKEクラスターに最小権限モデルを作成します
この選択肢が正しくない理由は以下の通りです。
IAMポリシーを配置してGKEクラスターに最小権限モデルを作成するという手法は、認証やアクセス制御には効果的ですが、特定の信頼され承認されたイメージのデプロイのみを許可するという具体的な要件を実現するには対応していません。
一方、バイナリ認証はCI/CDパイプライン内で特定のイメージが期待するように署名され証明されたものであるかを確認し、その結果次第でGKE上へのデプロイを控えることが可能です。これにより、問題の要件を概念的にも技術的にも満たすことができます。
選択肢：実行中のポッドの脆弱性を監視するために、FalcoまたはTwistlockをGKEにデプロイします
この選択肢が正しくない理由は以下の通りです。
FalcoやTwistlockは、既にデプロイされたポッドの脆弱性を監視するツールですが、この問題はあらかじめ承認されたイメージのみデプロイできるようにする点に重点が置かれています。
したがって、正解のバイナリ認証を用いてCI/CDパイプラインでイメージが認証されるべきです。
参考リンク：
https://cloud.google.com/binary-authorization/docs
https://cloud.google.com/kubernetes-engine/docs/concepts/binary-authorization
https://cloud.google.com/artifact-registry/docs/container-analysis
</details></div>

### Q. 問題13: 未回答
あなたの会社では、CI/CDのためにGoogle Cloud VMインスタンス上で動作するJenkinsを使っています。あなたは、Terraformを使用することで、Infrastructure as Code Automationを使用するように機能を拡張する必要があります。Terraform JenkinsインスタンスがGoogle Cloudリソースを作成する権限があることを確認する必要があります。あなたは、Googleが推奨するプラクティスに従いたいと考えています。
この要件を満たすために、どうすればよいですか？
1. Jenkins VMインスタンスに、適切なIAM（Identity and Access Management）権限を持つサービスアカウントがアタッチされていることを確認します
2. Terraformインスタンス専用のサービスアカウントを作成します。シークレットキーの値をダウンロードし、JenkinsサーバのGOOGLE_CREDENTIALS環境変数にコピーします
3. Terraformコマンドを実行する前に、Jenkinsのステップとしてgcloud auth application-default loginコマンドを追加します
4. Secret Managerが認証情報を取得できるように、Terraformモジュールを使用します
<details><div>
    答え：1
説明
この問題では、Google Cloudの仮想マシンインスタンス上で稼働するJenkinsがTerraformを介してGoogle Cloudリソースの作成を可能にすることが求められています。その際にはGoogleが推奨するプラクティスに従うことが求められています。その要点としては、サービスアカウントの適切な使用やIAM権限の管理が挙げられます。また、認証情報やシークレットキーの管理も重要な要素となります。これらの要素を考慮に入れつつ、最適な解答選択肢を選びます。
基本的な概念や原則：
サービスアカウント：Google Cloudでアプリケーションやサービスが他のGoogleサービスと認証され、通信できるようにするための特殊なアカウントです。IAMポリシーによって権限を与えられます。
IAM（Identity and Access Management）：Google Cloudにおける認証と権限管理のフレームワークです。ユーザー、グループ、サービスアカウントへのリソースへのアクセスを制御できます。
Terraform：Infrastructure as Code（IaC）を実現するためのオープンソースのツールです。クラウドリソースの作成、変更、バージョン管理を自動化できます。
Secret Manager：Google Cloudのセキュアなストレージサービスで、APIキーやパスワードなどの機密情報を保存、管理できます。
Jenkins：オープンソースのCI/CDツールです。ビルド、テスト、デプロイなどの自動化をサポートします。
gcloud auth application-default loginコマンド：Google Cloud SDKのコマンドで、アプリケーションデフォルトの認証情報を取得します。ただし、プロダクション環境ではこの方法は推奨されていません。
正解についての説明：
（選択肢）
・Jenkins VMインスタンスに、適切なIAM（Identity and Access Management）権限を持つサービスアカウントがアタッチされていることを確認します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、Googleが推奨するプラクティスとして、インスタンスに操作権限を与えるべき相手（この場合はTerraform Jenkinsインスタンス）に対してサービスアカウントを用いることが推奨されています。サービスアカウントはアプリケーションやサービスがGoogle Cloudリソースに安全にアクセスするための特別な種類のアカウントです。
また、これらのサービスアカウントに対しては、必要な操作のみを許可する最小権限の原則に基づきIAM権限を付与することが推奨されています。
したがって、Jenkins VMインスタンスに適切なIAM権限を持つサービスアカウントをアタッチすることで、Terraform JenkinsインスタンスがGoogle Cloudリソースを作成する権限を確保することができます。以上から、この選択肢が要件を満たす最適な方法となります。
不正解についての説明：
選択肢：Secret Managerが認証情報を取得できるように、Terraformモジュールを使用します
この選択肢が正しくない理由は以下の通りです。
要件は、Terraform Jenkinsインスタンスが適切な権限を有していること確認することで、Secret Managerを使用すると認証情報の取得が可能になりますが、その使用が要件を満たすわけではありません。プラクティスとしては、サービスアカウントを通じて適切なIAM権限をアタッチするのが推奨されています。
選択肢：Terraformインスタンス専用のサービスアカウントを作成します。シークレットキーの値をダウンロードし、JenkinsサーバのGOOGLE_CREDENTIALS環境変数にコピーします
この選択肢が正しくない理由は以下の通りです。
Googleの推奨するプラクティスでは、シークレットキーをダウンロードし直接環境変数にコピーするのではなく、サービスアカウントを用いて認証を行います。これは、シークレットキーの取り扱いはリスクが高く、セキュリティの観点から推奨されないからです。正解の選択肢であるIAM権限を持つサービスアカウントを利用する方が、セキュリティが確保されます。
選択肢：Terraformコマンドを実行する前に、Jenkinsのステップとしてgcloud auth application-default loginコマンドを追加します
この選択肢が正しくない理由は以下の通りです。
gcloud auth application-default loginコマンドを使用すると、ユーザーアカウントを使ってGoogle Cloudサービスに対する認証を行いますが、これは本番環境では適切な方法ではありません。セキュリティ上の理由から、サービスアカウントを介した認証が推奨されます。そのため、Jenkins VMインスタンスに適切なIAM権限を持つサービスアカウントをアタッチする方法が必要です。
参考リンク：
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/docs/terraform
https://www.terraform.io/docs/providers/google/guides/getting_started.html
</details></div>

## 4
### Q. 問題10: 未回答
あなたの会社では、GitOps手法に従ってデプロイされたGoogle Kubernetes Engine（GKE）でアプリケーションを実行しています。アプリケーション開発者は、アプリケーションをサポートするためにクラウドリソースを頻繁に作成します。あなたは、Googleが推奨するプラクティスに確実に従いながら、開発者がインフラストラクチャをコードとして管理できるようにしたいと考えています。コンフィギュレーションのドリフトを避けるために、インフラストラクチャをコードとして定期的に調整する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. Terraform builderでCloud Buildを構成し、terraform planとterraform applyコマンドを実行します
2. Terraform planとterraform applyコマンドを実行するためのTerraform dockerイメージでポッドリソースを作成します
3. Google Kubernetes Engine（GKE）にConfig Connectorをインストールして設定します
4. terraform planコマンドとterraform applyコマンドを実行するためのTerraform dockerイメージでJobリソースを作成します
<details><div>
    答え：3
説明
この問題では、Google Kubernetes Engine（GKE）でアプリケーションを実行している状況下で、開発者がインフラストラクチャをコードとして管理するための最善の手法を選ぶことが求められています。ここで重要な点は、Googleが推奨するプラクティスを守りつつ、コンフィギュレーションのドリフトを避けることです。選択肢には、GKEに対する設定手段やTerraformを使用したインフラストラクチャのコード化を行う手法等があるので、これらの選択肢を用いて、Googleの推奨プラクティスに沿いつつ、開発者が容易にインフラストラクチャ管理ができる解答を選ぶべきです。
基本的な概念や原則：
GitOps：インフラストラクチャ管理のためのオペレーションプラクティスです。Gitを単一のソースとして使用し、デプロイメントやアップデートを自動化することで、迅速で信頼性の高いシステム変更を可能にします。
Google Kubernetes Engine（GKE）：Google CloudのマネージドKubernetesサービスです。アプリケーションをコンテナ化し、スケーリングと自動更新などの操作を行うことができます。
Config Connector：Google Cloudのサービスで、Google CloudリソースをKubernetesオブジェクトとして管理します。これにより、Kubernetesを使用してGoogle Cloudリソースとインフラを管理することができます。
インフラストラクチャ管理：インフラリソース（サーバ、ストレージ、ネットワークなど）をプロビジョニング、設定、運用するプロセスです。
Cloud Build：Google Cloudのサービスで、ソースコードからコンテナイメージやアプリケーションをビルドします。
Terraform：インフラストラクチャをコード化し、クラウドサービス、オンプレミスのリソースなどを安全かつ効率的にプロビジョニングするためのオープンソースのツールです。
コンフィギュレーションドリフト：運用環境の設定が、基準となる設定から時間とともに変わっていく現象です。これにより予期しない問題やエラーが発生する可能性があります。
正解についての説明：
（選択肢）
・Google Kubernetes Engine（GKE）にConfig Connectorをインストールして設定します
この選択肢が正解の理由は以下の通りです。
Google Kubernetes Engine（GKE）のConfig Connectorは、KubernetesリソースのようにGoogle Cloudリソースを管理するためのツールであり、これを用いることで開発者はインフラストラクチャをコードとして管理できます。GitOpsの手法は、ソースコードリポジトリを単一のソースとし、その変更が自動的に本番環境へデプロイされる方法論であり、Config Connectorをインストールすることで、そのアプローチをリソースとコンフィグの管理にも適用することが可能となります。
さらに、Config Connectorを使用すると、各リソースの望ましい状態がコードで定義されているため、定期的に適用することでコンフィギュレーションドリフトを防ぐことが可能となります。
このように、Config ConnectorはGitOps手法と相性が良く、Googleの推奨するプラクティスに従う結果となります。
不正解についての説明：
選択肢：Terraform builderでCloud Buildを構成し、terraform planとterraform applyコマンドを実行します
この選択肢が正しくない理由は以下の通りです。
Terraformを使用すると、インフラストラクチャの定義をコードとして管理できますが、GitOpsの原則に基づく自動同期機能は持っていません。そのため、手動での適用が必要となり、設定のドリフトの可能性が高まります。
一方、Config Connectorを使用すれば、GKE上でインフラストラクチャを直接管理でき、GitOpsの手法に自然に合致します。
選択肢：Terraform planとterraform applyコマンドを実行するためのTerraform dockerイメージでポッドリソースを作成します
この選択肢が正しくない理由は以下の通りです。
Terraformを用いたポッドリソースの作成はGitOpsメソッドに沿っていません。GitOpsはリポジトリを単一情報源とし、変更はプルリクエストによるレビューを通じて承認されます。明示的なTerraformコマンドに頼るアプローチは、この原則に反します。GKEにConfig Connectorを設定することは、Kubernetesリソースとしてクラウドリソースを直接管理するように設計されているため、GitOpsのスタイルに適合します。
選択肢：terraform planコマンドとterraform applyコマンドを実行するためのTerraform dockerイメージでJobリソースを作成します
この選択肢が正しくない理由は以下の通りです。
Terraform dockerイメージでJobリソースを作る方法は調整のために手動でコマンドを実行する必要があり、コンフィギュレーションドリフトの自動対策にはなりません。
一方、Config Connectorは自動化に適しており、Googleが推奨しているプラクティスも満たせます。
参考リンク：
https://cloud.google.com/config-connector/docs/overview
https://cloud.google.com/kubernetes-engine/docs/tutorials/config-connector
https://cloud.google.com/anthos-config-management/docs/tutorials/gitops-cloud-build
</details></div>

# 2
## 1
### Question 1
 
単一ゾーンにある自動スケーリングされたマネージド インスタンス グループで、アプリケーションを実行しています。これは優先度の高いワークロードであり、マネージド インスタンス グループに対するすべての変更を確定する前にテストする必要があります。変更のテスト中に、どのようなリクエストにも対処できるように十分な容量を確保する必要があります。どうすればよいですか。
1. 変更中に、スケールアウトのみを行うように自動スケーリングを構成する。
2. 変更中に、自動スケーリングを一時的に無効にする。
3. マネージド インスタンス グループを複数のゾーンで実行するように変更する。
4. 予測自動スケーリングを有効にする。
<details><div>
フィードバック
A: 正解です。スケールアウトのみを行うように自動スケーリングを構成すると、容量が低下することはありません。リクエストの数が増えると、マネージド インスタンス グループがスケールアウトします。

B: 不正解です。自動スケーリングを無効にした場合、サポートされるのは現在の容量だけなので、変更中に容量が不足する可能性があります。

C: 不正解です。複数のゾーンで実行するようにマネージド インスタンス グループを変更しても、テスト中の変更が容量に影響しないとは限りません。

D: 不正解です。予測自動スケーリングを有効にしても、アプリケーションに十分な容量が確保されるとは限りません。既存の構成の変更中に、実際のリクエスト数が急増したり、行った変更が予測自動スケーリングに影響したりして、容量不足になる可能性があります。
 
https://cloud.google.com/compute/docs/autoscaler/managing-autoscalers
</details></div>

### Question 2
 
会社のチームに属するすべての従業員は、一般的な統合開発環境（IDE）も含め、整合性のあるテンプレート化された開発環境を使用することが求められます。開発環境にセキュリティ パッチと更新を継続して適用する必要があります。また、各チームのすべての開発者が整合性のある開発環境を使用できるように、信頼性の高い、Google が推奨する手法を特定する必要があります。どうすればよいですか。

1. すべてのセキュリティ パッチが適用された、基準となる Compute Engine マシンの日次スナップショットを作成し、開発者がそのスナップショットを使用して各自のマシンを更新する。
2. 更新スクリプトを使用して、すべてのソフトウェア更新のチェックリストを作成し、開発者が各自のマシンを更新する。
3. 最新の依存関係を含むイメージを作成して、開発者が利用するノートパソコンにそのイメージをインストールする。
4. 各チームに特化した Cloud Workstations 構成を作成する。
<details><div>
正解
各チームに特化した Cloud Workstations 構成を作成する。

フィードバック
A: 不正解です。開発者が各自で更新を行うと不整合が生じる可能性があります。

B: 不正解です。開発者が各自で更新を行うと不整合が生じる可能性があります。

C: 不正解です。重要なパッチや更新をすべての開発者のノートパソコンに確実にロールアウトすることはできません。

D: 正解です。Cloud Workstations 構成は、複数の開発者が一貫したワークステーションを作成できるテンプレートを提供し、マシンタイプ、ディスクサイズ、ツール、プリインストールされるライブラリなどの構成設定を指定します。マシンタイプやコンテナ イメージの変更など、ワークステーション構成に対して行われた操作は、ワークステーションが次に起動したときに各ワークステーションに反映されます。
 
https://cloud.google.com/workstations/docs/overview
 
https://cloud.google.com/workstations/docs/create-configuration
 
https://cloud.google.com/workstations/docs/create-workstation
 
https://www.youtube.com/watch?v=E1cblFqb8nk
 
https://www.youtube.com/watch?v=C6Dpmujxp9Q
</details></div> 

### Question 3
 
重大な脆弱性に対処するセキュリティ パッチに関する情報があなたのチームに届きました。このパッチは、世界中の数百万ものお客様にサービスを提供する Compute Engine インスタンスに適用する必要があります。エンドユーザーに対する影響と費用を最小限に抑えながら、セキュリティ パッチを迅速にロールアウトする必要があります。どうすればよいですか。

1. 24 時間のローリング アップデートを行い、各リージョンで夜間にロールアウトする。
2. A/B ロールアウトを行い、Compute Engine のすべてのインスタンスのコピーを作成する。セキュリティ パッチを適用してからユーザーを切り替える。
3. 世界中のすべての Compute Engine インスタンスを同時に更新する。
4. セキュリティ パッチのカナリア ロールアウトを短期間で行う。
<details><div>
正解
セキュリティ パッチのカナリア ロールアウトを短期間で行う。

フィードバック
A: 不正解です。これは効果的な戦略ではありません。現在、お客様に日中にサービスを提供しているリージョン内の重要なシステムが攻撃ベクトルとなる可能性があるからです。

B: 不正解です。この方法は費用対効果が低く、すべてのサービスおよびマシンのコピーを作成するのにも時間がかかります。

C: 不正解です。セキュリティ パッチになんらかの悪影響や予期しない影響がある場合、すべてのユーザーが同時に影響を受ける可能性があります。

D: 正解です。カナリア ロールアウトを短期間で行うと、ロールアウトの展開前に、セキュリティ パッチのあらゆる副作用を、迅速かつ費用対効果の高い方法で特定できます。
 
https://sre.google/workbook/canarying-releases/
 
https://cloud.google.com/blog/products/gcp/how-release-canaries-can-save-your-bacon-cre-life-lessons
</details></div>

### Question 4
 
Cloud Run で世界中のユーザーに対してデプロイされるアプリケーションがあります。Cloud Run を構成し、リクエストに対するレスポンスが低レイテンシになるように、すべてのユーザーを最も近いリージョンにルーティングする必要があります。どうすればよいですか。

1. アプリケーションを 1 つのリージョンにデプロイし、グローバル外部 HTTP(S) ロードバランサの背後でグローバル エニーキャスト IP アドレスを使ってアプリケーションを提供する。
2. アプリケーションを各リージョンにデプロイし、グローバル外部 HTTP(S) ロードバランサの背後でグローバル エニーキャスト IP アドレスを使ってアプリケーションを提供する。
3. アプリケーションを各大陸の 1 つのリージョンにデプロイし、それぞれのリージョンでリージョン外部 HTTP(S) ロードバランサを使ってアプリケーションを提供して、同じグローバル IP アドレスをすべてのリージョン ロードバランサに割り当てる。
4. アプリケーションを 1 つのリージョンにデプロイし、フロントエンドに Google Cloud Armor を構成してすべての IP アドレスからのトラフィックを許可する。
<details><div>
正解
アプリケーションを各リージョンにデプロイし、グローバル外部 HTTP(S) ロードバランサの背後でグローバル エニーキャスト IP アドレスを使ってアプリケーションを提供する。

フィードバック
A: 不正解です。すべてのリクエストが Cloud Run の 1 つのインスタンスにルーティングされることになり、レイテンシや輻輳が発生します。

B: 正解です。Cloud Run インスタンスはユーザーのロケーションに最も近いリージョンで利用可能にする必要があります。グローバル外部 HTTP(S) ロードバランサはエニーキャスト IP アドレスのエンドポイントに設定でき、Cloud Run インスタンスが実行されている最も近いリージョンにリクエストがルーティングされます。

C: 不正解です。これは最も効率的なソリューションではありません。構成が複雑なロードバランサを複数構成する必要があり、お客様に対して一元的ではありません。

D: 不正解です。Google Cloud Armor の許可ルールにより全世界からのトラフィックが許可されますが、1 つのリージョンから提供される場合、レスポンスのレイテンシは高くなります。
 
https://cloud.google.com/run/docs/multiple-regions
 
https://cloud.google.com/run/docs/container-contract
</details></div>

### Question 5
 
会社では、Pod のエビクションとスケジュール変更に正しく反応しないレガシー データベースが Google Kubernetes Engine（GKE）で実行されています。実行中のデータベースを停止するわけにはいきません。使用する GKE メンテナンス戦略を選択する必要があります。どうすればよいですか。

1. GKE メンテナンスを「Stable」チャンネルで構成する。
2. ノードプールのアップグレード戦略の max-surge-upgrade を 0 に設定して構成する。
3. 「PodDisruptionBudget」オブジェクトを作成し、maxUnavailable を 100% に指定する。
4. メンテナンスの除外時間枠を「マイナー アップグレードまたはノード アップグレードなし」スコープで構成する。
<details><div>
正解
メンテナンスの除外時間枠を「マイナー アップグレードまたはノード アップグレードなし」スコープで構成する。

フィードバック
A: 不正解です。Stable リリース チャンネルのみを選択すると、すべての更新が Stable のリリース スケジュールで実行され、Pod エビクションが発生する可能性があります。

B: 不正解です。サージ アップグレード戦略ではメンテナンス更新を制限できず、Pod エビクションが発生する可能性があります。

C: 不正解です。100% の「PodDisruptionBudget」ではメンテナンス アップグレードは停止されないため、Pod エビクションが発生する可能性があります。

D: 正解です。「マイナー アップグレードまたはノード アップグレードなし」設定により、ノードプールの中断は回避され、ノードのアップグレードによるワークロードのエビクションとスケジュール変更を避けることができます。
 
https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions
 
https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions#scope_of_maintenance_to_exclude
 
https://cloud.google.com/kubernetes-engine/docs/concepts/release-channels
 
https://cloud.google.com/kubernetes-engine/docs/best-practices/upgrading-clusters
 
https://www.youtube.com/watch?v=eqJQTANI_RI
</details></div>

### Question 6
 
組織で Cloud Run を使用して、コンテナ化されたアプリケーションをデプロイしています。アプリケーションの新しいバージョンが内部テストに合格したので、本番環境でのテストが必要になりました。アプリケーションをエンドユーザー向けにリリースする前に、ベータ版テスターがそのアプリケーションをテストできる構成を実装する必要があります。どうすればよいですか。

1. Cloud Run アプリケーションを本番環境にデプロイし、トラフィックの 1% をアプリケーションに転送する。
2. Google Cloud Armor を構成し、テストチーム以外の IP アドレスから送信されたリクエストを拒否する。
3. Compute Engine でプライベート VM インスタンスにコンテナをデプロイし、テストチームのアクセスのみを有効にする。
4. Cloud Run アプリケーションを「--no-traffic」オプションのタグ付きリビジョンで本番環境にデプロイし、テストチームと URL を共有する。
<details><div>
正解
Cloud Run アプリケーションを「--no-traffic」オプションのタグ付きリビジョンで本番環境にデプロイし、テストチームと URL を共有する。

フィードバック
A: 不正解です。エンドユーザーが 1% のうちに含まれ、アプリケーションにアクセスする可能性があります。

B: 不正解です。テストチームが使用する IP アドレスのリストを管理することは煩雑で、信頼性に欠けます。

C: 不正解です。このデプロイ環境は本番環境とは異なり、アプリケーションを確実にエンドユーザーにリリースするには、さらにテストする必要があります。

D: 正解です。タグを割り当てると、トラフィックを処理せずに特定の URL のリビジョンにアクセスできます。
 
https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#deploy-with-tags
 
https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#tags
 
https://www.youtube.com/watch?v=pi0Ss24bqL4
</details></div>

### Question 7
 
あなたが勤める小さな会社では、Cloud Build で CI / CD パイプラインの一部としてオープンソースの Java パッケージを使用しています。セキュリティ チームは、オープンソース パッケージの脆弱性が悪用されることを懸念しています。本番環境の依存関係の安全性を確保するために、費用対効果の高いソリューションを実装する必要があります。どうすればよいですか。

1. Assured Open Source Software（Assured OSS）パッケージを Cloud Build に pull する。
2. Cloud Source Repositories にパッケージを pull し、セキュリティ チームでオープンソース パッケージの検証を行う。
3. オープンソース パッケージをローカルに pull し、Cloud Build を使用してすべてのパッケージをスキャンして、フラグが付けられたパッケージを削除する。
4. 最新バージョンの GitHub パッケージのみを Cloud Build パイプラインに pull する。
<details><div>
正解
Assured Open Source Software（Assured OSS）パッケージを Cloud Build に pull する。

フィードバック
A: 正解です。Assured OSS パッケージは Google Cloud 独自のセキュアなパイプライン内に構築され、脆弱性のスキャン、分析、ファズテストが定期的に実施されます。

B: 不正解です。これは最も費用対効果の高いソリューションとはいえません。Google Cloud では、厳選された検証済みのオープンソース パッケージがすでに提供されているからです。

C: 不正解です。各ビルドに含まれるすべてのパッケージをスキャンすることは、費用対効果が高いとはいえません。また、不可欠なパッケージを削除すると、ビルドは失敗します。

D: 不正解です。最新のオープンソース バージョンを pull すると、未検出のバグや脆弱性が含まれている可能性があります。
 
https://cloud.google.com/assured-open-source-software/docs/remoterepositoryaccess
 
https://cloud.google.com/assured-open-source-software/docs/javaaccess
 
https://cloud.google.com/software-supply-chain-security/docs/practices
</details></div>

### Question 8
 
いくつかの Compute Engine インスタンス上で実行するカスタム アプリケーションがあります。サーバーの利用率が 90% まで上昇することがありますが、すぐに 50% 程度に戻ります。サーバーの利用率が 80% を超えた場合は、それに対処するよう通知するアラートが設定されていますが、届く通知が非常に多いため、利用率の高い状態が少なくとも 5 分続いた場合にのみ通知するようにアラートを変更する必要があります。どうすればよいですか。

1. ログベースの指標からアラートを作成する。ローリング ウィンドウは 5 分、しきい値は 90% とする。
2. ログベースの指標からアラートを作成する。ローリング ウィンドウは 5 分、しきい値は 80% とする。
3. 80% を超える利用率が 5 分間続いたことを示す通知を Cloud Run アプリケーションに送信する。
4. ログベースの指標からアラートを作成する。ローリング ウィンドウは 5 分とし、条件に指標は指定しない。
<details><div>
正解
ログベースの指標からアラートを作成する。ローリング ウィンドウは 5 分、しきい値は 80% とする。

フィードバック
A: 不正解です。90% を基準とした通知の場合、通知件数は減りますが、80～90% の高い利用率ではトリガーされません。

B: 正解です。利用率の高い状態が 5 分間続いた場合にのみ通知を受ける必要があります。

C: 不正解です。アラートをフィルタおよび分析するカスタム ソリューションの構築には多大な労力が必要になります。

D: 不正解です。指標がないことは、利用率が高いことを示すものではありません。
 
https://cloud.google.com/logging/docs/logs-based-metrics
 
https://cloud.google.com/logging/docs/logs-based-metrics/charts-and-alerts
 
https://cloud.google.com/monitoring/alerts/types-of-conditions#metric-threshold
 
https://www.youtube.com/watch?v=D0YKWvuJgwg
 
https://www.youtube.com/watch?v=4RgJjx4IxMs
 
https://www.cloudskillsboost.google/focuses/619?parent=catalog
</details></div>

### Question 9
 
組織には本番環境のプロジェクトが多数あり、それらを Google Cloud に移行する必要があります。組織のポリシーを一元管理しています。Google が推奨する方法に沿って、リソース階層のポリシー変更をロールアウトしようと考えています。どうすればよいですか。

1. ポリシー変更をテストするための組織とそれとは別の組織を本番環境に作成する。
2. 本番環境の組織を作成し、この組織に階層の上位から下位に向けてポリシー変更を段階的に適用する。
3. 本番環境の組織とリリース前のチェック用にステージング環境を作成し、ステージング環境ですべてのテストを実行する。
4. 本番環境の組織を作成し、この組織の本番環境のプロジェクトから順に階層の下位から上位に向けてポリシー変更を段階的に適用する。
<details><div>
正解
ポリシー変更をテストするための組織とそれとは別の組織を本番環境に作成する。

フィードバック
A: 正解です。ポリシーが適用されるリソース階層が変更されると、広範囲にわたり意図しない結果が生じる可能性があります。こうしたリスクを回避するため、メインの組織に適用する前に、別の組織でポリシーの変更をテストすることをおすすめします。

B:不正解です。多くのポリシーは組織全体に適用されます。既存の本番環境の組織にポリシー変更が適用されると、広範囲にわたり意図しない結果が生じる可能性があります。

C:不正解です。ステージング環境は本番環境の構成が反映される必要があります。構成の変更や、テストのためにセキュリティ構成を簡易化することはおすすめしません。

D: 不正解です。既存の本番環境の組織にポリシー変更が適用されると、意図しない結果が生じる可能性があります。
 
https://cloud.google.com/architecture/identity/best-practices-for-planning#use_a_separate_organization_for_experimenting
</details></div>

### Question 10
 
大量のデータを処理するフォールト トレラントなバッチ処理アプリケーションが組織で実行されています。コンピューティングは数百の VM に分散され、並列処理されています。大規模なデータ処理を実行するために費用対効果の高いソリューションを実装する必要があります。どうすればよいですか。

1. Spot VM を割り当ててデータを処理する。
2. 単一テナントのマシンを割り当ててデータを処理する。
3. 自動修復が有効であるマネージド インスタンス グループを作成する。
4. アクセラレータ最適化 VM と自動スケーリングが有効であるマネージド インスタンス グループを作成する。
 <details><div>
正解
Spot VM を割り当ててデータを処理する。

フィードバック
A: 正解です。Spot VM は、Compute Engine でのフォールト トレラントな処理において、通常の VM と比べて費用対効果の高いソリューションです。

B: 不正解です。単一テナント VM は最も費用対効果の高いソリューションではありません。

C: 不正解です。自動修復によって異常な VM は修復されますが、通常の VM 構成においては、最も費用対効果の高いソリューションではありません。

D: 不正解です。自動スケーリングにより必要に応じて VM が割り当てられますが、アクセラレータ最適化 VM 構成においては、最も費用対効果の高いソリューションではありません。
 
https://cloud.google.com/compute/docs/instances/spot
 
https://cloud.google.com/compute/docs/instances/create-use-spot
</details></div>

### Question 11
 
システム侵害の疑いが生じた場合に備えて本番環境のレプリカをテスト用に作成するよう、セキュリティ チームに求められています。Google が推奨する方法に沿って、セキュリティ チームに迅速にレプリカを提供する必要があります。どうすればよいですか。

1. Cloud Asset Inventory を実行し、本番環境内のリソースを一覧表示し、Google Cloud コンソールを使用してリソースを再作成する。
2. 本番環境を再作成する Terraform スクリプトを作成し、必要に応じてスクリプトを再実行する。
3. Security Command Center を使用してスキャンを実行し、本番環境内のリソースを一覧表示し、gcloud CLI を使用してリソースを再作成する。
4. 本番環境を再作成する Bash シェル スクリプトを作成し、必要に応じてスクリプトを再実行する。
<details><div>
フィードバック
A: 不正解です。コンソールを使用して技術環境全体を手動で繰り返し再作成することは、Google が推奨する方法ではありません。

B: 正解です。技術環境の再現性を管理するための方法として、Infrastructure as Code を推奨します。Google が推奨する Infrastructure as Code のツールは Terraform です。

C: 不正解です。Security Command Center で一覧表示したリソースでは、それらを再作成するための情報として不十分です。また、gcloud コマンドライン ツールを使用して技術環境全体を手動で繰り返し再作成することは、Google が推奨する方法ではありません。

D: 不正解です。Bash スクリプト ツールを使用して技術環境全体を手動で繰り返し再作成することは、Google が推奨する方法ではありません。
 
https://cloud.google.com/blog/products/devops-sre/want-repeatable-scale-adopt-infrastructure-as-code-on-gcp
 
https://cloud.google.com/docs/terraform
 
https://cloud.google.com/docs/terraform/best-practices-for-terraform
</details></div>

### Question 12
 
Google Cloud VPC 内の VM へのネットワーク トラフィックを調査する必要があります。VPC フローログが有効にされています。トラフィックの情報をフィルタすると、そのネットワーク トラフィックは利用不可になっています。問題を特定する必要があります。どうすればよいですか。

1. TCP プロトコルでフィルタするかどうかを判断する。
2. サンプルレートを下げるかどうかを判断する。
3. フィルタしているトラフィック量が非常に少ないかどうかを判断する。
4. VPC 外部の VM から VPC 内部の VM にトラフィックが流れているかどうかを判断する。
 
<details><div>
正解
フィルタしているトラフィック量が非常に少ないかどうかを判断する。

フィードバック
A: 不正解です。これは問題ではありません。TCP は VPC フローログでサポートされており、データのキャプチャで使用できます。

B: 不正解です。サンプルレートを下げるとキャプチャされるログは減少します。サンプルレート 1.0（100%）はすべてのエントリが保持されることを意味します

C: 正解です。トラフィック量が非常に少ないことが問題だと考えられます。ログはサンプリングされるので、少量のフローでは一部のパケットが失われる場合があります。

D: 不正解です。これは問題ではありません。VPC フローログでは外部サーバーから Google Cloud VPC 内の VM へのトラフィックをキャプチャできます。
 
https://cloud.google.com/vpc/docs/using-flow-logs#some_flows_are_missing
 
https://cloud.google.com/vpc/docs/using-flow-logs
</details></div>

### Question 13
 
あなたの同僚が夜間の待機中に、プロジェクトの Virtual Private Cloud（VPC）に侵入する不審なトラフィックの増加に気づきました。そこで同僚は、特定の IP アドレスから発信されるトラフィックを停止するように、Cloud Armor の構成を更新しました。この変更によりネットワーク トラフィックは減少しましたが、影響を受けたお客様からエスカレーションがあり、その結果、会社にペナルティが課されました。チームは Google が推奨する方法に沿って再発を防止したいと考えています。どうすればよいですか。

1. 同僚向けにインシデント レポートを作成し、シニア マネジメントにエスカレーションする。
2. この同僚によるすべての変更について、第 2 レベルの確認を求めるプロセスを作成する。
3. すべての変更が、変更の確認を行う追加の人員がいる日中に行われるよう求めるポリシーを作成する。
4. 主な技術的問題を特定し、チーム全体が利用できるように内容を文書化する。
 
<details><div>
フィードバック
A: 不正解です。これは推奨される方法に沿ったアプローチではありません。プロセスの改善よりも、個人の責任の追及に重点が置かれているからです。

B: 不正解です。これは推奨される方法に沿ったアプローチではありません。全員のプロセスではなく、特定の個人のプロセスの改善に重点が置かれているからです。

C: 不正解です。これは現実的なポリシーではありません。構成はいつでも変更できるようにする必要があるからです。ここでは、潜在的なサイバー攻撃は夜間に発生しました。チームが求めているのは、いつでも適用できるプロセスです。

D: 正解です。このソリューションは DevOps / SRE のアプローチを利用したもので、個人の責任を追及せずに、技術的問題を客観的に特定します。
 
https://sre.google/workbook/postmortem-culture/
 
https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons
</details></div>

### Question 14
 
会社のためにソフトウェア デリバリー パイプラインを作成するとします。開発チームによって提供されるアプリケーションの新機能を、Cloud Deploy を使用してテスト環境、ステージング環境、本番環境に順にデプロイする必要があります。対応するデプロイ ターゲットはすでに定義されています。あなたはリリースを作成してデリバリー パイプラインをインスタンス化しました。Google が推奨する方法に沿ってデプロイを実施する必要があります。どうすればよいですか。

1. 各ステージの前にデプロイを承認するように Binary Authorization を構成する。
2. Artifact Registry で各ステージ用のイメージを作成し、各イメージを対応するステージに適用する。
3. ステージングと本番の各ステージで初回リリースをプロモートする。
4. デリバリーの各ステージ向けに別々のデリバリー パイプラインを作成する。
<details><div>
正解
ステージングと本番の各ステージで初回リリースをプロモートする。

フィードバック
A: 不正解です。Binary Authorization はデプロイ前にセキュリティ チェックを行います。ただし、それはデプロイそのもののためのソリューションではありません。

B: 不正解です。デプロイごとに別のイメージを作成するアプローチはおすすめしません。

C: 正解です。リリースをインスタンス化すると、最初のターゲットにデプロイされます。その後、ステージングと本番環境に順にプロモートします。

D: 不正解です。このユースケースでは、Cloud Deploy で別々のデリバリー パイプラインを作成することはおすすめしません。デプロイを次のステージにプロモートするのがおすすめのアプローチです。
 
https://cloud.google.com/deploy/docs/deploy-app-run
 
https://cloud.google.com/deploy/docs/promote-release
</details></div>

### Question 15
 
組織では Google Cloud で毎日多くのビルドを実行しています。VM がパブリック IP アドレスを持たないようにし、データの引き出しからビルドマシンを保護する必要があります。Google が推奨する方法に沿って、カスタマイズ可能で簡単に管理できる、ビルドに関するソリューションを作成し、組織の需要に対応しようと考えています。どうすればよいですか。

1. VPC Service Controls を使用して Cloud Build でプライベート プールを実装する。
2. 要求されるプライバシーのために Cloud Build のデフォルト プールでビルドを実行、構成する。
3. Compute Engine VM を使用してカスタム VPC にビルド環境を作成し、Jenkins を使ってビルドを実行する。
4. Compute Engine Spot VM インスタンスを使用してカスタム VPC にビルド環境を作成し、Jenkins を使ってビルドを実行する。

<details><div>
正解
VPC Service Controls を使用して Cloud Build でプライベート プールを実装する。

フィードバック
A: 正解です。VPC Service Controls を利用してプライベート プールでビルドを実行すると、セキュリティが強化され、デフォルト プールでは実施できない複数のカスタマイズを行うことができます。

B: 不正解です。デフォルト プールでは、パブリック IP アドレスなどの VM 構成を制限するカスタマイズは実施できません。

C: 不正解です。このカスタム アプローチは多大な労力を必要とするため、Google Cloud で推奨されるアプローチではありません。

D: 不正解です。このカスタム アプローチは多大な労力を必要とするため、Google Cloud で推奨されるアプローチではありません。
 
https://cloud.google.com/build/docs/private-pools/private-pools-overview
 
https://cloud.google.com/build/docs/private-pools/using-vpc-service-controls
 
https://cloud.google.com/build/docs/private-pools/set-up-private-pool-to-use-in-vpc-network
</details></div>

### Question 16
 
あなたの会社では、9 月に大きな販売イベントを計画しています。販売イベントの期間中に運用をサポートする従業員グループを特定しました。Google が推奨する方法に沿って、それらの従業員に Google Cloud リソースへのアクセス権を 9 月にのみ付与するとします。どうすればよいですか。

1. 特定した従業員を含むグループを作成する。グループにリソースへのアクセス権を割り当て、Identity and Access Management（IAM）の条件として日時表現を 9 月に設定する。
2. 特定した従業員を含むグループを作成し、リソースへのアクセス権がある Identity and Access Management（IAM）のカスタムロールをグループに割り当てる。9 月末にカスタムロールを削除する。
3. 特定した従業員のマシンからリソースへのトラフィックを許可するファイアウォール ルールを追加する。9 月末にトラフィックを拒否するようにファイアウォール ルールを変更する。
4. リソースへのアクセス権がある Identity and Access Management（IAM）のカスタムロールを、特定した各従業員に割り当てる。9 月末にカスタムロールを削除するように Cloud Scheduler タスクを作成する。

<details><div>
フィードバック
A: 正解です。IAM の条件により、指定した期間中にのみ、必要な権限が自動的に割り当てられます。

B: 不正解です。必ず 9 月末にロールを削除する必要があるので、この方法はおすすめしません。また、権限が直ちに適用されますが、これは不要です。

C: 不正解です。ファイアウォール ルールを使用するとネットワーク トラフィックを許可できますが、リソースを操作できる IAM 権限がユーザーに割り当てられることにはなりません。

D: 不正解です。個々のユーザーにロールを割り当てることはおすすめしません。また、Cloud Scheduler を使用して後からロールを削除するのも推奨される方法ではありません。
 
https://cloud.google.com/iam/docs/conditions-overview
</details></div>

### Question 17
 
会社では、ヨーロッパのユーザーにサービスを提供するアプリケーションを実行しています。業界の規制によって、リソースのインスタンス化は特定のリージョンでのみ許可されています。Google Cloud 組織のすべてのプロジェクトでこの要件を満たす必要があります。どうすればよいですか。

1. ログベースのアラートを作成して、許可リストのリージョン外で作成されたリソースを特定し、非遵守のリソースを削除する。
2. Asset Inventory で毎時スキャンを実行して全リソースのカタログを作成し、許可リストのリージョン外のインスタンスを削除する。
3. 新しいインスタンスを作成する権限を持つ限定ユーザー グループを作成し、コンプライアンスを検証するプロセスを作成する。
4. 組織ポリシーを構成し、許可されるリージョンを「in: allowed_values」リストで指定する。

<details><div>
正解
組織ポリシーを構成し、許可されるリージョンを「in: allowed_values」リストで指定する。

フィードバック
A: 不正解です。このオプションではリソースが作成されてしまい、業界規制に違反します。

B: 不正解です。このオプションではリソースが作成されてしまい、業界規制に違反します。

C: 不正解です。このチームが誤ってまたは不正に、リソースを不適切なリージョンに作成する可能性があるため、信頼性に欠けます。

D: 正解です。組織ポリシー制約によって、許可されたリージョン外でのリソースの作成をプリエンプトします。
 
https://cloud.google.com/resource-manager/docs/organization-policy/defining-locations#gcloud
 
https://cloud.google.com/resource-manager/docs/organization-policy/overview
</details></div>

### Question 18
 
コンピューティング集約的なタスクを行うモジュールがアプリケーションに含まれています。開発チームは、さまざまなアルゴリズムでテストして、このモジュールを最適化したいと考えています。あなたはチームメンバーとしてステージング環境と本番環境の両方でアルゴリズムをテストし、各アルゴリズムのパフォーマンスに関する詳細なデータを収集するとします。どうすればよいですか。

1. プロファイリング ライブラリを使用してコードを計測する。Cloud Profiler でフレームグラフとしてデータを可視化する。
2. アルゴリズムのさまざまな部分でログ ステートメントを使用してコードを計測する。ログベースの通知を送信して、アルゴリズムの実行に関するデータを収集する。
3. アルゴリズムのさまざまな部分でログ ステートメントを使用してコードを計測する。同じ制御構造が複数回呼び出されたときに、ログ指標に基づく通知を送信する。
4. コードを計測して、リクエストとレスポンスのフローをキャプチャする。Cloud Trace でリクエストのレイテンシを確認する。

<details><div>
フィードバック
A: 正解です。Cloud Profiler のフレームグラフを使用すると、プログラム内のコールスタックを可視化できます。これによってボトルネックを特定し、コードとアルゴリズムの最適化に関するガイドとして活用できます。

B: 不正解です。ログ ステートメントはアルゴリズムのタイミングに影響します。この方法で収集したデータは可視化するには不便であり、ボトルネックに関するガイダンスを提供するには詳細が不十分です。

C: 不正解です。ログ ステートメントはアルゴリズムのタイミングに影響します。この方法で収集したデータは可視化するには不便であり、ボトルネックに関するガイダンスを提供するには詳細が不十分です。

D: 不正解です。Cloud Trace では、コードのベンチマークに関する十分な情報が提供されません。この方法は、複数回呼び出しが行われるアプリケーションの分散トレースにより適しています。
 
https://cloud.google.com/profiler/docs/concepts-profiling
 
https://cloud.google.com/profiler/docs/measure-app-performance
 
https://cloud.google.com/profiler/docs/concepts-flame
 
https://codelabs.developers.google.com/cloud-profiler-go#0
 
https://codelabs.developers.google.com/codelabs/otel-cloudtrace-go#0
</details></div>

### Question 19
 
コードは手動と Webhook によって、GitHub に保存され、Cloud Build でビルドされます。コードをビルドするには、機密情報にアクセスする必要があります。Google が推奨する方法に沿って、機密情報のセキュリティを確保したいと考えています。どうすればよいですか。

1. ビルドを毎回コマンドラインからトリガーし、必要な機密情報をパラメータとして指定する。
2. 機密情報のみを含む暗号化されたファイルを GitHub リポジトリに作成し、Cloud Build ファイルでその暗号化ファイルを参照する。
3. Secret Manager のエントリを作成し、Cloud Build ファイルに機密情報シークレットの URI を指定して、ビルドステップでパラメータとしてシークレットを参照する。
4. コードを GitHub に保持し、機密情報専用の新しいリポジトリを Cloud Source Repositories に作成して、Cloud Build ファイルで新しいリポジトリを参照する。

<details><div>
フィードバック
A: 不正解です。このソリューションは、ビルドが Webhook によってトリガーされる場合に機能しません。

B: 不正解です。原則として、機密情報、シークレット、認証情報は、ソース リポジトリに保存すべきではありません。GitHub リポジトリへのアクセス権を持つ他のユーザーが認証情報にアクセスする可能性があり、最小権限の原則に違反します。

C: 正解です。Secret Manager は Identity and Access Management（IAM）を使用して構成できるため、最小権限の原則に従っています。Cloud Build から Secret Manager を参照でき、パラメータ置換によってビルドステップにシークレットを含めることができます。

D: 不正解です。原則として、機密情報、シークレット、認証情報は、ソース リポジトリに保存すべきではありません。機密情報を別個のリポジトリに保存することも認められません。Cloud Source Repositories リポジトリへのアクセス権を持つ他のユーザーが機密情報にアクセスする可能性があり、最小権限の原則に違反します。
 
https://cloud.google.com/build/docs/securing-builds/use-secrets
 
https://cloud.google.com/build/docs/configuring-builds/substitute-variable-values
</details></div>

### Question 20
 
あなたの会社では、Compute Engine 仮想マシン（VM）にデプロイされたアプリケーションを使用してお客様にサービスを提供しています。サービスレベル契約（SLA）を設けて、月に 99% の可用性を提供しています。月の最初の 22 日間のテレメトリー データによると、処理したリクエスト数は 10,000,000 件、可用性は 99.28% となっています。開発チームはアプリケーションに追加した新機能をデプロイしたいと考えています。あなたはサイト信頼性エンジニアリング（SRE）手法に沿いつつ、デプロイ アプローチを決定するとします。どうすればよいですか。

1. Confidential VMs に直ちに新機能をデプロイする。
2. 新機能のデプロイを翌月に延期する。
3. SLA を 98.5% に変更し、新機能を直ちにデプロイするようお客様に依頼する。
4. SLO を変更し、新機能を直ちにデプロイするようお客様に依頼する。

<details><div>
フィードバック
A: 不正解です。Confidential VMs では、エンドユーザーのリクエストに対する高可用性は保証されません。

B: 正解です。エラー バジェットが非常に少なくなります。また、安定性と機能の更新のバランスを取る必要があります。

C: 不正解です。残りのエラー バジェットが少ない場合に SLA を変更することは、アプリケーションを配信するためのアプローチとしておすすめしません。

D: 不正解です。SLO は内部の尺度であり、お客様とのサービス契約を反映したものではありません。
</details></div>

# 3
## 1
### Q. 問題11: 回答
Cloud Run と Cloud Functions でクライアント アプリケーションを構築して実行している。クライアントでは、ログをログサービスにインポートできるように、すべてのログを 1 年間使用できる必要があります。必要なコード変更は最小限に抑える必要があります。
あなたは何をするべきか?
1. Cloud Run のすべてのイメージと Cloud Functions のすべての関数を更新して、Cloud Logging とクライアントのロギング サービスの両方にログを送信します。ログの送信に必要なすべてのポートが VPC ファイアウォールで開いていることを確認します。
2. Pub/Sub トピック、サブスクリプション、ログ シンクを作成します。すべてのログをトピックに送信するようにログ シンクを構成します。ログを取得するためのトピックへのアクセス権をクライアントに付与します。
3. ストレージ バケットと適切な VPC ファイアウォール ルールを作成します。Cloud Run のすべてのイメージと Cloud Functions のすべての関数を更新して、ストレージ バケット内のファイルにログを送信します。
4. ログ バケットとログ シンクを作成します。ログバケットの保持期間を 365 日に設定します。バケットにログを送信するようにログシンクを設定します。ログを取得するためのバケットへのアクセス権をクライアントに付与します。
<details><div>
    答え：4

不正解:
A. Cloud Run のすべてのイメージと Cloud Functions のすべての関数を更新して、Cloud Logging とクライアントのロギング サービスの両方にログを送信します。ログの送信に必要なすべてのポートが VPC ファイアウォールで開いていることを確認します。
このアプローチでは、各アプリケーションと関数にデュアル ログ機能を実装するために、大幅なコード変更が必要です。
VPC ファイアウォールで開いているポートを管理してログ送信を有効にすると、複雑さが増し、セキュリティ上の懸念が生じる可能性があります。
保持要件を満たすことはできますが、かなりの運用オーバーヘッドが伴い、コードの変更を最小限に抑えるという目標から逸脱します。
B. Pub/Sub トピック、サブスクリプション、ログ シンクを作成します。すべてのログをトピックに送信するようにログ シンクを構成します。ログを取得するためのトピックへのアクセス権をクライアントに付与します。
Pub/Sub トピックとサブスクリプションをログ シンクで設定すると、アプリケーション コードを変更することなくログがキャプチャされます。
Pub/Sub はリアルタイムのログ ストリーミングには効率的ですが、本質的に長期保存や直接的な保持管理は提供されません。
クライアントは、Pub/Sub からログを積極的に取得し、独自のストレージと保持を管理する必要があるため、クライアント側で複雑さが生じる可能性があります。
C. ストレージ バケットと適切な VPC ファイアウォール ルールを作成します。Cloud Run のすべてのイメージと Cloud Functions のすべての関数を更新して、ストレージ バケット内のファイルにログを送信します。
これには、Cloud Storage バケットにログを送信するためにすべての画像と関数を更新することが含まれますが、これには大幅なコード変更が必要です。
ログ送信のファイアウォール規則を管理すると、セキュリティ上のリスクと追加の管理オーバーヘッドが発生する可能性があります。
このアプローチは、コードの変更を最小限に抑えるという目的から逸脱し、ログ管理の複雑さを増します。
正解：
D. ログ バケットとログ シンクを作成します。ログバケットの保持期間を 365 日に設定します。バケットにログを送信するようにログシンクを設定します。ログを取得するためのバケットへのアクセス権をクライアントに付与します。
このオプションでは、Cloud Logging を利用してログをキャプチャし、ログシンクを利用して Cloud Storage バケットに自動的に送信します。
バケットに 365 日間の保持ポリシーを設定すると、必要な期間ログが保存されます。
ログのキャプチャとエクスポートは、アプリケーション コード内ではなくインフラストラクチャ レベルで処理されるため、コードの変更が最小限に抑えられます。
ログ取得のためにバケットへのクライアントアクセスを提供することは、簡単で安全であり、運用上のオーバーヘッドを最小限に抑えるという要件に合致しています。
要約すると、オプション A と C は目的を達成できますが、大幅なコード変更が必要であり、運用が複雑になります。オプションBは、リアルタイムのログストリーミングソリューションを提供しますが、固有の長期ストレージと保持管理に欠けています。オプションDは、クラウドネイティブなログ管理のベストプラクティスと連携し、コードの変更を最小限に抑え、必要なログ保持を確保する、最も効率的で簡単なアプローチとして際立っています。
リンクス：
https://cloud.google.com/logging/docs/routing/overview#:~:text=URL%3A%20https%3A%2F%2Fcloud
</div></details>

### Q. 問題20: 未回答
ロードバランサーを使用せずにHTTPエンドポイントを提供するアプリケーションを監視する責任があります。HTTP応答のレイテンシーは、ポジティブなユーザーエクスペリエンスを確保する上で重要な役割を果たします。すべてのユーザーが経験する HTTP レイテンシに関する分析情報を取得し、この目的のために Cloud Monitoring を利用することを目指しています。
どのような手順を踏む必要がありますか?
1. 積み上げ棒グラフ
2. 累積メトリクス
3. 分布
4. METRIC_KIND_UNSPECIFIED の使用
<details><div>
    答え：3

不正解:
オプションA: 積み上げ棒グラフは特定の指標を視覚化できますが、応答時間の範囲と分散に関する洞察を提供するため、遅延は分布を使用するとより効果的に表されます。
オプションB:累積メトリクスでは、グラフが増加し続けるため、個々のレイテンシーインスタンスの追跡には適していません。HTTP 応答時間の動作を正確に反映することはできません。
オプションD:METRIC_KIND_UNSPECIFIED の使用は、待機時間などの特定の測定には適していません。レイテンシーメトリクスを効果的に監視および分析するために必要な精度が不足しています。
正解：
オプションC:レイテンシーは通常、分布として測定され、過去の 99 パーセンタイルよりも遅いリクエスト数を特定するなど、さまざまなパーセンタイルを分析できます。このアプローチにより、レイテンシのパフォーマンスを包括的に把握できます。
リンクス：
https://cloud.google.com/monitoring/api/v3/kinds-and-types
https://sre.google/workbook/implementing-slos/
https://cloud.google.com/architecture/adopting-slos/
</div></details>

## 2
### Q. 問題24: 未回答
グローバルな組織で働いており、99%の可用性目標でサービスを管理していますが、エンジニアリングリソースは限られています。現在の暦月には、サービスの可用性が 99.5% に達していることを確認しました。目的は、サービスが定義された可用性の目標を一貫して満たし、新機能のリリースなどのビジネスの変化に適応できるようにすると同時に、運用コストを最小限に抑えながら技術的負債を削減することです。Google が推奨する方法に従うことを目標としている。
あなたは何をするべきか?
1. サービスにコンピューティング リソースを追加することで、サービスに N+1 の冗長性を追加します。
2. 反復的なタスクを自動化することで、労力を特定、測定、排除します。
3. サービス レベルの可用性のエラー バジェットを定義し、残りのエラー バジェットを最小限に抑えます。
4. 対応可能なエンジニアを機能バックログに割り当て、サービスが可用性目標内にとどまるようにします。
<details><div>
    答え：2

不正解:
A. サービスにコンピューティング リソースを追加することで、サービスに N+1 の冗長性を追加します。
冗長性を追加すると可用性が向上しますが、特にサービスが既に可用性の目標を満たしている場合は、最も費用対効果の高いアプローチではない可能性があります。不必要なリソース使用率とコストの増加につながる可能性があります。
C. サービス レベルの可用性のエラー バジェットを定義し、残りのエラー バジェットを最小限に抑えます。
エラーバジェットを定義することは、イノベーションのペースと信頼性のバランスを取るための良い方法ですが、信頼性の低いリスクを管理することが大切です。このアプローチは、技術的負債や運用コストを削減するという目標に直接対処するものではありません。
D. 対応可能なエンジニアを機能バックログに割り当て、サービスが可用性目標内にとどまるようにします。
運用効率を考慮せずに機能開発のみに集中すると、技術的負債と運用上の課題が増加する可能性があります。このアプローチでは、サービスの保守と信頼性の重要な側面が無視される可能性があります。
正解：
B. 反復的なタスクを自動化することで、労力を特定、測定、排除します。
労力の削減:労苦とは、サービスにあまり価値を付加しないが、その運用に必要な反復的で平凡なタスクを指します。これらのタスクを自動化することで、エンジニアリングチームの作業負荷を大幅に軽減し、より影響力のあるアクティビティに集中できるようになります。
可用性の目標達成における一貫性:手間が省けることで、チームは、監視、パフォーマンスチューニング、ベストプラクティスの実装など、サービスの可用性を確保するためのプロアクティブな対策により多くの時間を費やすことができます。
ビジネスの変化への適応:労力が減ったことで、チームは新機能のリリースなど、ビジネスの変化に適応するためにより多くのリソースを割り当てることができます。自動化は、新しい変更が導入されても、安定した運用環境を維持するのに役立ちます。
運用コストの最小化: 反復的なタスクを自動化することで、運用コストの削減にもつながります。手動による介入の必要性が最小限に抑えられるため、人為的ミスのリスクとそれに関連するコストが削減されます。
要約すると、反復的なタスクの自動化に重点を置くことで、現在のレベルのサービス可用性を維持できるだけでなく、運用コストを抑えながら、ビジネスの変化への適応や技術的負債の削減など、より戦略的なタスクに貴重なエンジニアリングリソースを解放することができます。
リンクス：
https://sre.google
</div></details>

## 3
### Q.  問題4: 未回答
Compute Engine でアプリケーション サーバーのグループを管理しており、デベロッパーがデバッグのためにアプリケーションログに簡単にアクセスできるように、構成の労力を最小限に抑えた安全な方法を探しています。
このソリューションをGoogle Cloud Platform(GCP)に実装するには、どのようなアプローチを使用しますか?
1. Cloud Logging Agent をアプリケーション サーバーにデプロイ
2. Cloud Logging Agent と Logs Private Viewer ロール
3. Monitoring Viewer ロールを持つ Cloud Monitoring Agent
4. Cloud Storage にログをアップロードするための gsutil
<details><div>
    答え：

不正解:
B. Cloud Logging Agent と Logs Private Viewer ロール:このオプションにはログ エージェントのデプロイも含まれますが、"ログ プライベート ビューアー" ロールはより制限が厳しく、機密データを含むログへのアクセスを必要とするシナリオに適しています。
C. Monitoring Viewer ロールを持つ Cloud Monitoring Agent:このセットアップは、ログではなくメトリックに重点を置いているため、デバッグ目的で詳細なアプリケーション ログにアクセスする必要がある開発者にはあまり適していません。
D. Cloud Storage にログをアップロードするための gsutil: この方法では、追加のスクリプトと手動設定が必要です。Google Cloud のオペレーション スイート(Stackdriver)を使用する場合に比べて効率が悪く、効果的なデバッグに不可欠なリアルタイムのログ アクセスも提供されません。
正解：
ある。
Cloud Logging エージェントをアプリケーション サーバーにデプロイします。
開発者に、ログにアクセスして表示するためのIAMログ閲覧者ロールを付与します。
この方法では、ログを一元管理するためのログエージェントのデプロイと適切な IAM ロールを組み合わせて、ログへの安全なロールベースのアクセスを確保します。効率的で、セキュリティを維持しながら構成の労力を最小限に抑えます。
リンクス：
ログエクスプローラーを使用してログを表示するView logs by using the Logs Explorer
IAMによるアクセス制御
</div></details>

チームは、世界中の何百万人もの顧客にサービスを提供している Compute Engine インスタンスに重要なセキュリティ パッチを適用する必要があります。
パッチを迅速に展開し、コストと顧客への影響を最小限に抑えるには、どのような戦略を採用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. 世界中のすべての Compute Engine インスタンスを同時に更新する。
すべてのインスタンスを同時に更新するのは危険です。パッチによって問題が発生すると、すべてのユーザーに一度に影響を与え、サービスの大幅な中断につながる可能性があります。
C. 各リージョンの夜間にスケジュールされた 24 時間のローリング更新を実行します。
24 時間のローリング アップデートは、オフピーク時に更新を実行することで顧客への影響を最小限に抑えますが、重要なパッチには適していません。どのリージョンでも更新を遅らせると、システムが特定されたセキュリティの脅威に対して脆弱なままになる可能性があります。
D. A/B ロールアウトを実装し、Compute Engine ですべてのインスタンスのコピーを作成し、パッチを適用してから、ユーザーを切り替えます。
重複インスタンスの完全なセットの作成を伴う A/B ロールアウトは、費用対効果が高くなく、タイムリーでもありません。この方法では、かなりのリソースと時間を必要とするため、迅速なセキュリティパッチの展開は現実的ではありません。
正解：
A. セキュリティ パッチのカナリア ロールアウトを短期間で実行します。
Canary ロールアウトでは、最初に少数のインスタンスにパッチを適用できます。このアプローチにより、より広範なロールアウトの前にパッチの影響を監視し、問題を早期に特定して対処することで、リスクとコストを最小限に抑えることができます。
リンクス：
カナリアリリース
カナリアを放つことでベーコンを救う方法—CREの人生の教訓
</div></details>


