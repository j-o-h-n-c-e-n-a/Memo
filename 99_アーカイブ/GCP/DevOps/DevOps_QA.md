# 1
## 1
### Q. 問題4: 回答
あなたはGoogle CloudリソースのTerraformデプロイを実行するCI/CDパイプラインを作成しています。CI/CDツーリングはGoogle Kubernetes Engine（GKE）で実行され、各パイプラインの実行にエフェメラルなポッドを使用します。ポッド内で実行されるパイプラインが、Terraformデプロイを実行するための適切なIAM（Identity and Access Management）権限を持っていることを確認する必要があります。ID管理についてはGoogleが推奨するプラクティスに従う必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. 新しいKubernetesサービスアカウントを作成し、そのサービスアカウントをポッドに割り当てます。Workload Identityを使用して、Googleサービスアカウントとして認証します
2. 新しいGoogleサービスアカウントを作成し、適切なIAM権限を割り当てます
3. Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、そのキーをKubernetesシークレットとして保存し、そのキーをポッドに注入し、GOOGLE_APPLICATION_CREDENTIALS環境変数を設定します
4. Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、CI/CDツールのシークレット管理ストアにキーを保存し、認証にこのキーを使用するようにTerraformを設定します
5. ポッドを実行するCompute Engine VMインスタンスに関連付けられたGoogleサービスアカウントに、適切なIAMパーミッションを割り当てます
<details><div>
    答え：1,2
説明
この問題では、CI/CDパイプラインでGoogle CloudリソースのTerraformデプロイを実行するためのIAM権限管理について質問がされています。特に、Google Kubernetes Engineで実行されるエフェメラルなポッドが適切な権限を持っていることが必要で、Googleの推奨するID管理のプラクティスに従うことが求められています。ここで、ロールを持つインスタンスとそのアクセス管理を安全に管理する方法として、Kubernetesサービスアカウントの作成とその割り当て、Workload Identityの使用、Googleサービスアカウントの作成とIAM権限の管理などが試験対策となります。選択肢を読み解く際には、GoogleのID管理のベストプラクティスと、セキュリティや運用面でのコンソールからの各種設定の違いに注目することが必要です。
基本的な概念や原則：
Terraform：Infrastructure as Codeツールで、クラウドリソースのデプロイを自動化します。Google CloudのリソースやIAMポリシーなど、多くのGoogle Cloudサービスがサポートされています。
Google Kubernetes Engine（GKE）：Kubernetesのマネージド環境を提供するGoogle Cloudサービスです。クラスター管理やオートスケーリングなどの機能があります。
エフェメラルポッド：一時的に作成され、タスク完了後にすぐに削除されるKubernetesのポッドです。CI/CDパイプラインなど短期間のタスクに適しています。
IAM権限：Google Cloudサービスのリソースに対するアクセスを制御する機能です。サービスアカウントに対して適切な権限を割り当てることで、適切なアクセス制御が可能になります。
Kubernetesサービスアカウント：Kubernetes内での身元証明とアクセス制御を行うアカウントです。特定のポッドに割り当てることができます。
Workload Identity：GKE上のサービスアカウントをGoogle Cloudのサービスアカウントにマッピングする機能です。これにより、GKEの各ポッドは適切なIAM権限を持つことになります。
Googleサービスアカウント：Google Cloudリソースに対するアクセスを認証・認可するための特殊なアカウントです。適切なIAM権限を持つことで、リソースへの安全なアクセスが可能になります。
正解についての説明：
（選択肢）
・新しいKubernetesサービスアカウントを作成し、そのサービスアカウントをポッドに割り当てます。Workload Identityを使用して、Googleサービスアカウントとして認証します
・新しいGoogleサービスアカウントを作成し、適切なIAM権限を割り当てます
この選択肢が正解の理由は以下の通りです。
まず、問題文の最初の要件である"ポッド内で実行されるパイプラインが、Terraformデプロイを実行するための適切なIAM権限を持っていること"を満たすために、新しいGoogleサービスアカウントを作成し、適切なIAM権限を割り当てることが必要です。このようにすることで、CI/CDツールが実行されるGKE環境を、実際にリソースのデプロイメントや更新を行うためのIAM権限を持つアカウントとして扱うことができます。
次に、Googleの推奨するプラクティスに従うために、新しいKubernetesサービスアカウントを作成し、そのサービスアカウントをポッドに割り当てます。
そして、Workload Identityを使用してGoogleサービスアカウントとして認証します。Workload IdentityはGKEのサービスアカウントとGoogle Cloudのサービスアカウントを関連付けるシステムで、これによってCI/CDパイプラインが実行されるポッドが適切なアイデンティティと権限を持つようになります。これにより、エフェメラルなポッドがTerraformデプロイを実行するための十分な権限を持つように、安全かつ効率的に許可とアイデンティティの管理が可能になります。
不正解についての説明：
選択肢：Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、そのキーをKubernetesシークレットとして保存し、そのキーをポッドに注入し、GOOGLE_APPLICATION_CREDENTIALS環境変数を設定します
この選択肢が正しくない理由は以下の通りです。
JSONサービスアカウントキーの使用は、キーのライフサイクル管理や機密性保持が難しく、Googleの推奨するプラクティスではありません。
代わりに、Workload Identityを使用してサービスアカウントを認証する方法が推奨されています。
選択肢：Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、CI/CDツールのシークレット管理ストアにキーを保存し、認証にこのキーを使用するようにTerraformを設定します
この選択肢が正しくない理由は以下の通りです。
JSONサービスアカウントキーの使用はセキュリティ上のリスクを引き起こし、Googleが推奨するプラクティスを満たしません。
これに対して、適切なIAM権限を持たせてWorkload Identityを使用することで、セキュリティが強化され、Terraformデプロイの認証も確実に行えます。
選択肢：ポッドを実行するCompute Engine VMインスタンスに関連付けられたGoogleサービスアカウントに、適切なIAMパーミッションを割り当てます
この選択肢が正しくない理由は以下の通りです。
ポッドのIAM権限はCompute Engine VMインスタンスのサービスアカウントからではなく、Kubernetesサービスアカウントから派生すべきです。これはGoogleの推奨するプラクティスに従っていません。GKE上でのID管理にはWorkload Identityを使用すべきです。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://www.terraform.io/docs/providers/google/guides/provider_reference.html
</div></details>

### Q. 問題9: 未回答
あなたのチームは、Google Cloudの内外にデプロイする新しいアプリケーションを設計しています。システムリソースの使用率などの詳細なメトリクスを収集する必要があります。この収集システムのセットアップに必要な作業量を最小限に抑えながら、一元化されたGoogle Cloudサービスを使用したいと考えています。
この要件を満たすために、どうすればよいですか？

1. Google Cloud Operation Suite Debuggerパッケージをインポートし、タイミング情報を含むデバッグメッセージを出力するようにアプリケーションを設定します
2. 両方のロケーションにアプリケーションパフォーマンスモニタリング（APM）ツールをインストールし、分析のために中央データストレージロケーションへのエクスポートを構成します
3. Google Cloud Operation Suite Profilerパッケージをインポートし、さらなる解析のためにGoogle Cloud Operation Suiteに関数のタイミングデータをリレーするように設定します
4. タイミングライブラリを使ってコードを計測し、Google Cloud Operation Suiteによってスクレイピングされるヘルスチェックエンドポイント経由でメトリクスを公開します
<details><div>
    答え：3
説明
この問題では、Google Cloudと他のプラットフォームにデプロイする新しいアプリケーションで詳細なメトリクスを収集し、それらメトリクスの設定に必要な作業量を最小限に抑えるための戦略が求められています。システムのメトリクスの収集のためのツールやサービスを選択する際のポイントとしては、その手軽さ、一元化への対応力、そしてGoogle Cloudとの互換性が考慮すべき特徴となります。またGoogle Cloud内外両方の環境で使用できることも求められています。そこで選択肢は、適切なGoogle Cloud Operation Suiteのパッケージかツール選択に関するものとなります。
基本的な概念や原則：
Google Cloud Operation Suite：Google Cloudの監視、トラブルシューティング、アプリケーションのパフォーマンス分析を行うための統合されたツールセットです。このツールを使用すると、システムに関する詳細な情報を容易に収集できます。
Profilerパッケージ：Google Cloud Operation Suiteの一部で、実行中のアプリケーションからのパフォーマンス情報を収集します。詳細なプロファイリングデータを提供し、ボトルネックの解析などに使用できます。
Debuggerパッケージ：Google Cloud Operation Suiteの一部のデバッグツールです。アプリケーションの動作を詳細に追跡し、エラーや不具合の原因を特定します。
タイミングライブラリ：コードの実行時間を計測するためのツールやライブラリです。これを使って特定の処理のパフォーマンスを測定することが可能です。
ヘルスチェック：システムの健全性をモニタリングするためのテストです。Google Cloud Operation Suiteはヘルスチェックの結果を監視し、問題があればアラートを出します。
アプリケーションパフォーマンスモニタリング（APM）ツール：アプリケーションのパフォーマンスを継続的に監視し、問題を検出するためのツールです。実行時間、エラーレートなどのパフォーマンス指標を収集します。
正解についての説明：
（選択肢）
・Google Cloud Operation Suite Profilerパッケージをインポートし、さらなる解析のためにGoogle Cloud Operation Suiteに関数のタイミングデータをリレーするように設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Operation Suite（旧Google Cloud Operation Suite）は、Google Cloudの内外で動作するアプリケーションの監視、トラブルシューティング、アラートのためのパワフルな監視ツールです。ここで提案されているCloud Operations Profilerは、Operations Suiteの一部であり、実行中のアプリケーションをプロファイリングし、関数のタイミングやシステムリソースの利用状況などの詳細なメトリクスを収集し分析します。この情報をCloud Operation Suiteにリレーすることで、すべての情報を一元化し、パフォーマンス分析や問題解決を容易にします。
また、Profilerパッケージをインポートするだけで、アプリケーションにプロファイリング機能を追加できるため、セットアップに必要な作業量を最小限に抑えることができます。これらの理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：Google Cloud Operation Suite Debuggerパッケージをインポートし、タイミング情報を含むデバッグメッセージを出力するようにアプリケーションを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite Debuggerパッケージは、主にアプリケーションの不具合を解析する仕組みで、詳細なメトリクスやリソース使用状況の収集を主な目的としていません。設問の要件は詳細なメトリクスの収集と一元化された管理を求めているため、Cloud Operation Suite Profilerパッケージの使用が適切です。
選択肢：タイミングライブラリを使ってコードを計測し、Google Cloud Operation Suiteによってスクレイピングされるヘルスチェックエンドポイント経由でメトリクスを公開します
この選択肢が正しくない理由は以下の通りです。
タイミングライブラリを使用してコードを計測すると、セットアップに必要な作業量が増えます。
一方、Google Cloud Operation Suite Profilerパッケージをインポートする方が作業量を最小限に抑えながら詳細なメトリクスを取得できます。
選択肢：両方のロケーションにアプリケーションパフォーマンスモニタリング（APM）ツールをインストールし、分析のために中央データストレージロケーションへのエクスポートを構成します
この選択肢が正しくない理由は以下の通りです。
APMツールを両方のロケーションにインストールする方法は、セットアップに必要な作業量を増大させます。
そして、中央データストレージロケーションへのエクスポートを構成しなければならない点も面倒な作業となります。
それに対し、Google Cloud Operation Suite Profilerパッケージを利用することで作業量が大幅に削減できます。
参考リンク：
https://cloud.google.com/profiler/docs/profiling-external
https://cloud.google.com/profiler/docs
https://cloud.google.com/monitoring/docs
</div></details>

### Q. 問題12: 未回答
アプリケーションコンテナイメージをビルドするために、Cloud BuildでCI/CDパイプラインを作成しています。アプリケーションコードはGitHubに保存されています。あなたの会社では、本番イメージビルドはメインブランチに対してのみ実行され、変更管理チームはメインブランチへのすべてのプッシュを承認する必要があります。イメージのビルドはできるだけ自動化したいと考えています。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. リポジトリ上のメインブランチにブランチ保護ルールを設定します
2. トリガーのIncluded filesフィルターにOWNERSファイルを追加します
3. Cloud Buildジョブにトリガーを作成します。リポジトリイベントの設定を"ブランチにプッシュ"に設定します
4. トリガーの承認オプションを有効にします
5. Cloud Buildジョブにトリガーを作成します。リポジトリイベント設定を"Pull request"に設定します
<details><div>
    答え：1,3
説明
この問題では、ユーザーがCI/CDパイプラインを設定し、特定のルールに従ってイメージのビルドを制御したいという要件を明らかにしています。具体的には、本番イメージビルドをメインブランチに限定し、メインブランチへの全てのプッシュが変更管理チームによって承認される必要があるという条件が述べられています。これらの要件を満たすために適切な選択肢が2つ求められています。選択肢を評価するときには、これらの特定の要件を満たす選択肢を適切に識別することが試験のポイントとなります。
基本的な概念や原則：
Cloud Build：ソースコードからソフトウェアアーティファクトをビルドするためのGoogle Cloudのサービスです。CI/CDパイプラインの自動化に利用します。
トリガー：Cloud Buildを特定のイベント（例えば、リポジトリ上のブランチへのプッシュ）に対して自動的に反応させるための設定です。
リポジトリ：ソースコードやその他のデータを保存し、履歴管理や共有を行うためのシステムです。GitHubはその一例です。
ブランチ保護ルール：Gitリポジトリへの変更を制限するための設定です。例えば、あるブランチへのプッシュを特定のユーザーやチームだけに制限することができます。
GitHub：ソフトウェア開発プロジェクトのためのホスティングプラットフォームです。Gitを用いてソースコードのバージョン管理を行います。
正解についての説明：
（選択肢）
・Cloud Buildジョブにトリガーを作成します。リポジトリイベントの設定を"ブランチにプッシュ"に設定します
・リポジトリ上のメインブランチにブランチ保護ルールを設定します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Buildジョブにトリガーを作成し、リポジトリイベントの設定を"ブランチにプッシュ"に設定することで、メインブランチに対する変更があるたびに自動的にビルドがトリガーされます。これによりイメージのビルドを効率的に自動化し、メインブランチに対してのみ本番イメージビルドを実行するという要件を満たします。
また、リポジトリ上のメインブランチにブランチ保護ルールを設定することで、変更管理チームがメインブランチへの全てのプッシュを承認する必要がなくなります。具体的には、ブランチ保護ルールを使用すれば、特定のブランチに対する直接のコミットやプッシュを制限したり、プルリクエストの承認やステータスチェックの成功などの条件を満たさなければマージができないように設定できます。これにより、不適切な変更がメインブランチに適用されることを防ぐことができます。この2つの手段を組み合わせることで、上記の要件を満たすことができます。
不正解についての説明：
選択肢：Cloud Buildジョブにトリガーを作成します。リポジトリイベント設定を"Pull request"に設定します
この選択肢が正しくない理由は以下の通りです。
"Pull request"に設定されたトリガーはプルリクエストの作成時にイメージのビルドが開始しますが、要件はメインブランチへのプッシュ時のみビルドを行うことです。そのため、リポジトリイベントの設定を"ブランチにプッシュ"に設定するのが正しいです。
選択肢：トリガーのIncluded filesフィルターにOWNERSファイルを追加します
この選択肢が正しくない理由は以下の通りです。
OWNERSファイルをIncluded filesフィルターに追加することで、特定のファイルの変更にトリガーを絞ることができます。しかし、変更管理チームがメインブランチへの全てのプッシュを承認するという要件には関連性がありません。
また、この方法ではビルドの自動化という目的にも寄与しません。正解の選択肢では、特定のブランチへのプッシュをトリガーに設定し、保護ルールで承認制を加えます。
選択肢：トリガーの承認オプションを有効にします
この選択肢が正しくない理由は以下の通りです。
Cloud Buildには"トリガーの承認オプション"を有効にする機能が存在しません。代わりにブランチ保護ルールを設定することで、メインブランチへのプッシュが変更管理チームによる承認を経てから行われるように制御することが可能です。
参考リンク：
https://cloud.google.com/build/docs/automating-builds/create-manage-triggers
https://cloud.google.com/build/docs/securing-builds/configure-access-control
https://docs.github.com/en/github/administering-a-repository/managing-branch-protection-rules
</div></details>

### Q. 問題20: 未回答
あなたは、キャッシュメモリに製品情報を保存するアプリケーションをサポートしています。キャッシュミスが発生するたびに、Cloud Loggingにエントリが記録されます。あなたは、キャッシュミスが発生する頻度を時系列で可視化したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. Google Cloud Operation Suite Profilerを設定し、ログに基づいてキャッシュミスが発生したタイミングを特定し、視覚化します
2. Cloud LoggingをGoogle Data Studioのソースとしてリンクします。キャッシュミスのログにフィルタをかける
3. BigQueryをGoogle Cloud Operation Suiteログのシンクとして設定します。キャッシュミスログをフィルタリングし、別のテーブルに書き込むスケジュールクエリを作成します
4. Cloud Loggingでログベースのメトリックを作成し、Google Cloud Operation Suite Monitoringでそのメトリックのダッシュボードを作成します
<details><div>
    答え：4
説明
この問題では、Cloud Loggingに記録されたキャッシュミスの頻度を時系列で可視化する方法が求められています。ここでは、リアルタイムでの監視と分析、メトリクスの視覚化、Cloud Loggingと他のGoogle Cloudサービスとの連携などが重要な要素となります。主にはログからメトリクスを生成し、それを視覚化するサービスを選択すれば解決策となります。Google Cloud Operation Suite MonitoringやGoogle Data Studio、Profiler、BigQueryなどが選択肢となるため、特定の要件に最適なサービスを選ぶことが適切な解答に繋がります。
基本的な概念や原則：
Cloud Logging：Google Cloudのロギングサービスです。システムやアプリケーションのログデータを管理し、リアルタイムで分析可能なツールを提供します。
ログベースのメトリック：Cloud Loggingに記録されたログエントリに基づいて生成されるカスタムメトリックです。これを使用すると、ログエントリの特定のデータを継続的に監視し、分析することが可能となります。
Google Cloud Operation Suite（旧オペレーションスイート）：Google Cloud上でのシステムのモニタリング、トラブルシューティング、アプリケーションのパフォーマンス向上などを支援するツール群です。
Google Cloud Operation Suite Monitoring：時系列データを表示、分析、アラート設定を行えるMonitoringサービスを提供します。これを使用すると特定のメトリックの振る舞いを時間軸で視覚化することが可能です。
Google Data Studio：Googleのビジュアル分析ツールです。データの吸上げをしダッシュボードの作成、共有が行えますが、直接的にCloud Loggingのデータを時系列で視覚化することはできません。
Google Cloud Operation Suite Profiler：アプリケーションのパフォーマンスボトルネックを視覚化するツールですがログの可視化には向いていません。
BigQuery：Google Cloudのビッグデータ分析ツールです。大量のデータに対してSQLクエリを実行できますが、リアルタイムの視覚化やログの直接的なハンドリングには適していません。
正解についての説明：
（選択肢）
・Cloud Loggingでログベースのメトリックを作成し、Google Cloud Operation Suite Monitoringでそのメトリックのダッシュボードを作成します
この選択肢が正解の理由は以下の通りです。
まず、Cloud LoggingはGoogle Cloudのログ管理サービスで、アプリケーションのさまざまなアクティビティのログを記録します。キャッシュミスの時系列データを取得するためには、このログ情報をメトリクスとして抽出する必要があります。そのためにログベースのメトリックを作成します。このメトリックは、ログデータの特定のパターンを数値化し、それを時間とともに追跡する機能を提供します。つまり、定義したパターンがログに登場するたびにそのカウントがインクリメントされ、これによりキャッシュミスの頻度を追跡することができます。
その後、Google Cloud Operation Suite Monitoringを使用してこれらのメトリクスを時系列で視覚化します。MonitoringはCloud上の資源とアプリケーションのパフォーマンスを時間経過に沿って監視したり可視化したりするためのサービスです。ここで作成されたダッシュボードを利用すれば、キャッシュミスの発生頻度を時系列で視覚的に理解することが可能となります。
不正解についての説明：
選択肢：Cloud LoggingをGoogle Data Studioのソースとしてリンクします。キャッシュミスのログにフィルタをかける
この選択肢が正しくない理由は以下の通りです。
Cloud Loggingは直接Google Data Studioにリンクすることができません。キャッシュミスの頻度を時系列で可視化するためには、Cloud Loggingでログベースのメトリックを作成し、それをGoogle Cloud Operation Suite Monitoringで視覚化するのが適切です。
選択肢：Google Cloud Operation Suite Profilerを設定し、ログに基づいてキャッシュミスが発生したタイミングを特定し、視覚化します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite Profilerはアプリケーションの性能問題を診断するためのツールであり、ログデータから時系列での可視化を作成するのには適しません。それに対してCloud LoggingとMonitoringはログデータを基にメトリックを作成、視覚化するのに最適なツールです。
選択肢：BigQueryをGoogle Cloud Operation Suiteログのシンクとして設定します。キャッシュミスログをフィルタリングし、別のテーブルに書き込むスケジュールクエリを作成します
この選択肢が正しくない理由は以下の通りです。
BigQueryを使用してログのフィルタリングを行うと確かに情報を取得できますが、これでは時系列での可視化を直接行うことはできません。問題の要件は時間経過と共にキャッシュミスの発生頻度を可視化することであり、これはGoogle Cloud Operation Suite Monitoringが提供する機能で可能です。
参考リンク：
https://cloud.google.com/logging/docs/logs-based-metrics
https://cloud.google.com/monitoring/api/metrics#Google Cloud-logging
https://cloud.google.com/logging/docs/view/overview
</div></details>

### Q. 問題26: 未回答
Cloud Runアプリケーションは、構造化されていないログをテキスト文字列としてCloud Loggingに書き込みます。非構造化ログをJSONベースの構造化ログに変換したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. Cloud Runコンテナイメージにログエージェントをインストールし、ログエージェントを使用してログをCloud Loggingに転送します
2. Cloud Loggingソフトウェア開発キット（SDK）を使用するようにアプリケーションを修正し、jsonPayloadフィールドを持つログエントリを送信します
3. Fluent Bitサイドカーコンテナをインストールし、JSONパーサーを使います
4. ログのテキストペイロードをJSONペイロードに変換するようにログエージェントを設定します
<details><div>
    答え：2
説明
この問題では、Cloud Runアプリケーションが現在テキスト文字列としてCloud Loggingに書き込んでいる非構造化ログを、JSONベースの構造化ログにどう変換するかを問われています。アプリケーションが現在使用しているログ出力方法と、目指すログ形式の違いを理解することが重要です。選択肢を検討する際には、適切なツールや手法を通じてテキスト文字列をJSON形式に変換する解決策を選ぶ必要があります。
基本的な概念や原則：
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションとシステムからのログデータを集め、分析、エクスポートすることができます。
非構造化ログ：特定のデータ構造を持たないログデータのことです。分析や管理が難しい場合があります。
Cloud Logging SDK：Cloud Loggingにログエントリを送信するためのソフトウェア開発キットです。jsonPayloadフィールドを使用して、非構造化ログを構造化ログに変換することが可能です。
構造化ログ：特定の構造（例えばJSON）を持つログデータのことです。データ分析や管理が容易になります。
jsonPayloadフィールド：Cloud Loggingで使用されるフィールドで、ログエントリの本文をJSON形式で格納します。構造化ログの作成に使用されます。
正解についての説明：
（選択肢）
・Cloud Loggingソフトウェア開発キット（SDK）を使用するようにアプリケーションを修正し、jsonPayloadフィールドを持つログエントリを送信します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Loggingソフトウェア開発キット（SDK）は、アプリケーションログの作成と管理をGoogle Cloudで直接実行できるようにするためのツールキットです。その主な機能は通常のテキストベースのログだけでなく、構造化されたJSONベースのログを含んでいます。
したがって、Cloud Logging SDKを使用すると、アプリケーションから直接構造化ログをCloud Loggingに送信できます。
具体的には、SDKを使用してアプリケーションを修正し、jsonPayloadフィールドを持つログエントリを送信すれば、サーバーレス環境のCloud Runアプリケーションから生成された非構造化ログをJSONベースの構造化ログに変換することができます。これにより、ログデータの分析と管理が大幅に容易になります。この選択肢は正確で効率的な解決策を提供します。
不正解についての説明：
選択肢：Fluent Bitサイドカーコンテナをインストールし、JSONパーサーを使います
この選択肢が正しくない理由は以下の通りです。
Fluent BitサイドカーコンテナとJSONパーサーを使用する方法は、すでに存在するログデータの形式を変換する為によく使用されますが、それは既存のログを解析してJSON形式に変換するものであり、アプリケーションが直接構造化ログを出力する方法とは違います。正解の選択肢のCloud Logging SDKを使うことで、アプリケーション自身がJSONベースの構造化ログを出力、Cloud Loggingへと送信することが可能になります。
選択肢：Cloud Runコンテナイメージにログエージェントをインストールし、ログエージェントを使用してログをCloud Loggingに転送します
この選択肢が正しくない理由は以下の通りです。
Cloud Runの環境ではログエージェントをインストールすることができません。Cloud Runのログ取得は自動的に行われ、特別なログエージェントをインストールする必要はありません。
一方、Cloud Logging SDKを使用すればアプリケーションレベルでログの形式を制御し、jsonPayloadフィールドを持つログエントリを送信することが可能です。
選択肢：ログのテキストペイロードをJSONペイロードに変換するようにログエージェントを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのログエージェントはログの収集と転送を担いますが、ログの形式をテキストからJSONに変換する機能はありません。
一方、Cloud Logging SDKを使用すれば、アプリケーションが直接JSON形式のログを生成できるため、この問題の要件を満たします。
参考リンク：
https://cloud.google.com/logging/docs/structured-logging
https://cloud.google.com/logging/docs/reference/libraries
https://cloud.google.com/run/docs/logging
</div></details>

### Q. 問題31: 未回答
あなたはCloud Loggingにログを書き込むアプリケーションを管理しています。あなたは一部のチームメンバーにログをエクスポートする機能を与える必要があります。
この要件を満たすために、どうすればよいですか？

1. logging.sinks.listとlogging.sink.getパーミッションを持つカスタムIAMロールを作成し、付与します
2. チームメンバーにCloud IAMのlogging.configWriterのIAMロールを付与します
3. これらのメンバーにのみログのエクスポートを許可するように、Access Context Managerを構成します
4. Cloud IAMで組織ポリシーを作成し、これらのメンバーにのみログエクスポートの作成を許可します
<details><div>
    答え：2
説明
この問題では、Cloud Loggingからログをエクスポートする能力を特定のチームメンバーに付与する方法を探しています。それを行うためには、特定のIAMロールやポリシーの付与、リソースに対するパーミッションの設定といった操作が考えられます。選択肢を検討するにあたっては、それぞれのメソッドの特性とCloud Loggingのエクスポート操作に必要な権限について理解を深めることが必要です。
基本的な概念や原則：
Cloud IAM（Identity and Access Management）：Google Cloudのリソースへのアクセスを制御するためのツールです。特定のユーザーに特定のリソースへの許可を与えたり、その許可を取り消したりすることが可能です。
IAMロール：IAMポリシーに付与できる許可の集合です。例えば、logging.configWriterロールは、Cloud Loggingの設定を作成および管理する権限を持つユーザーに付与されます。
ログのエクスポート：Cloud Loggingから外部のストレージやツールにログ数据を移動させる行為です。エクスポートは、ログの長期保存、コンプライアンス監査、または外部のログ分析ツールでの処理が必要な場合に使用されます。
Access Context Manager：Google Cloudのサービスで、組織全体のアクセスレベルを設定し管理することが可能です。しかし、特定の個々の操作（例えばログのエクスポート）を制御するためには、より細かい制御を提供するIAMが適しています。
組織ポリシー：Google Cloudの全てのリソースに適用されるルールで、特定の設定や制限を提供します。しかし、個々のユーザーの特定の操作に対する権限を制御するためには、よりパーソナライズされた権限を提供するIAMが適しています。
正解についての説明：
（選択肢）
・チームメンバーにCloud IAMのlogging.configWriterのIAMロールを付与します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud IAM（Identity and Access Management）は、Google Cloudの資源へのアクセスを制御する重要なツールであり、特定のロールを特定のユーザーまたはグループに付与することで精緻なアクセス制御が可能です。その中のlogging.configWriterロールは、Cloud Loggingの設定を操作するための許可を与えます。具体的には、Cloud Loggingのログビューやログベースのメトリクスを作成・更新し、ログエクスポート先に新しいシンクを作成する権限を持っています。
したがって、このロールをチームメンバーに付与することで、ログのエクスポートを可能にするという要件を満たすことができます。
不正解についての説明：
選択肢：これらのメンバーにのみログのエクスポートを許可するように、Access Context Managerを構成します
この選択肢が正しくない理由は以下の通りです。
Access Context Managerは、Google Cloudリソースへのアクセスを制御するために使用されますが、特定の操作（ログのエクスポートなど）へのアクセスを許可するロールを果たすものではありません。
これに対して、IAMのlogging.configWriterのロールはログのエクスポートを許可する権限を持っています。
選択肢：logging.sinks.listとlogging.sink.getパーミッションを持つカスタムIAMロールを作成し、付与します
この選択肢が正しくない理由は以下の通りです。
logging.sinks.listとlogging.sink.getパーミッションを持つカスタムIAMロールを作成し付与すると、ロールを付与されたユーザーはロギングシンクのリストを取得や特定のシンクデータの取得をすることができますが、エクスポートの設定を行う（書き込み）権限はありません。
それに対して、logging.configWriterのIAMロールはログエクスポートの設定に必要な全ての権限を持つため、正解の選択肢となります。
選択肢：Cloud IAMで組織ポリシーを作成し、これらのメンバーにのみログエクスポートの作成を許可します
この選択肢が正しくない理由は以下の通りです。
組織ポリシーは組織全体のリソースに対するアクセス制御を設定するもので、特定のメンバーにログエクスポートの操作権限を付与する趣旨とは異なります。
それに対して、IAMロールのlogging.configWriterを付与することでログのエクスポート許可を具体的なメンバーに与えることが可能です。
参考リンク：
https://cloud.google.com/logging/docs/access-control
https://cloud.google.com/iam/docs/understanding-roles#logging-roles
https://cloud.google.com/logging/docs/export/configure_export_v2
</div></details>

### Q. 問題34: 未回答
あなたの会社のCTOは、社内で使用するために、すべてのインシデントに関するポストモーテムポリシーを導入するようあなたに依頼しました。あなたは、そのポリシーがあなたの会社で成功するように、良いポストモーテムとは何かを定義したいと思います。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. すべてのポストモーテムに、インシデントの原因、インシデントを引き起こした責任者またはチームの特定、インシデントの今後の発生を防止する方法を含めるようにします
2. すべてのポストモーテムに、何が原因でインシデンとが発生したのか、インシデンとがどのように悪化した可能性があるのか、また、将来、インシデンとが発生するのを防ぐにはどうすればよいのかを含めるようにします
3. すべてのポストモーテムに、すべてのインシデント参加者が含まれるようにし、ポストモーテムをできるだけ広く共有します
4. すべてのポストモーテムに、インシデントの重大性、インシデントの今後の発生を防止する方法、および内部システムコンポーネントの名前を挙げずにインシデントの原因を含めるようにします
5. すべてのポストモーテムに、顧客情報を名指しすることなく、インシデントの解決方法とインシデントの原因を含めるようにします
<details><div>
    答え：2,3
説明
この問題では、それぞれの選択肢が提供するポストモーテムのベストプラクティスと効用、それに関連する社内のimpacted stakeholders（影響を受けるステークホルダー）の参照や彼らへの情報共有の有無、その情報の具体性と精度を試されています。ポストモーテムを成功させるためには、全体的な透明性と責任の免責が重要であり、それはインシデントの理解と改善に役立つ全体的な学習と知識を共有することを目指すべきです。情報を十分に提供しつつ、個別のチームまたは個人への非難を避ける選択肢を見つけるのが重要です。
基本的な概念や原則：
ポストモーテム分析：インシデンとやインシデント後に行われるレビューのことで、何がうまくいかなかったのか、何が原因であったのか、どのように改善可能だったのかを理解し、将来のインシデントを防止するためのプラクティスです。
レビューの公開：ポストモーテムレビューは、関与者全員が参加できるように共有するべきです。これにより、全員が問題の解決に参加し、学びを共有することができます。
インシデントの原因分析：インシデンとやインシデントが発生した原因を適切に識別し、分析することが重要です。この情報は、同様の問題が再発するのを防ぐために使用されます。
フェイルセーフの設計：システムが故障した場合に問題がさらに悪化する可能性を考慮し、それを防止するための方法を特定することが重要です。
適切な情報の共有：ポストモーテム分析には適切な情報が含まれていることが重要で、個々の人やチームを責めたり、顧客情報を不適切に公開したりするべきではありません。重要なのは問題の解決と将来の問題の予防です。
正解についての説明：
（選択肢）
・すべてのポストモーテムに、何が原因でインシデンとが発生したのか、インシデンとがどのように悪化した可能性があるのか、また、将来、インシデンとが発生するのを防ぐにはどうすればよいのかを含めるようにします
・すべてのポストモーテムに、すべてのインシデント参加者が含まれるようにし、ポストモーテムをできるだけ広く共有します
この選択肢が正解の理由は以下の通りです。
まず、インシデンとの原因、インシデンとが悪化した可能性のある要因、そしてそれを防ぐための予防策を明確にすることで、ポストモーテムが具体的な学習をもたらす価値ある過程となります。このような情報は、それぞれのインシデントから学び、同じ問題が再発するのを防ぎ、システムの改善に直接つながる情報であり、ポストモーテムの主要なロールを果たします。
次に、全てのインシデント参加者の意見を反映し、ポストモーテムを広く共有することもまた重要です。このアプローチにより、ポストモーテムは専門家だけでなく関連するすべてのステークホルダーにとっての学習の機会となります。
また、インシデンとが関連するすべての部分を正確に把握し、全体像を理解することができ、一部の人だけが情報を持つという状況を防ぎます。これらがポストモーテムポリシーが社内で成功するための重要な要素です。
不正解についての説明：
選択肢：すべてのポストモーテムに、インシデントの原因、インシデントを引き起こした責任者またはチームの特定、インシデントの今後の発生を防止する方法を含めるようにします
この選択肢が正しくない理由は以下の通りです。
ポストモーテム文化の目的は、非難せずにインシデンとから学ぶためです。
したがって、インシデントを引き起こした責任者またはチームを特定することは、ポストモーテムの目的に反します。適切なポストモーテムは、原因と予防策を特定することに焦点を当てつつ、非難から遠ざけます。
選択肢：すべてのポストモーテムに、インシデントの重大性、インシデントの今後の発生を防止する方法、および内部システムコンポーネントの名前を挙げずにインシデントの原因を含めるようにします
この選択肢が正しくない理由は以下の通りです。
インシデント原因の分析と改善策の提案において、内部システムコンポーネントの名前を伏せてしまうと、真の原因を特定しにくく、解決の道筋を立てるのが難しくなります。効率的な問題解決のため、具体的な情報が必要となるためです。
選択肢：すべてのポストモーテムに、顧客情報を名指しすることなく、インシデントの解決方法とインシデントの原因を含めるようにします
この選択肢が正しくない理由は以下の通りです。
ポストモーテムではインシデントの解決方法と原因だけでなく、インシデンとがどのように悪化した可能性があり、将来のインシデンとを防ぐための改善策も含める必要があります。つまり、ただ原因と解決策を記すだけでは、重要な部分が欠けてしまいます。
参考リンク：
https://cloud.google.com/incident-response
https://cloud.google.com/architecture/creating-a-culture-of-observability
https://landing.google.com/sre/sre-book/chapters/postmortem-culture/
</div></details>

### Q. 問題39: 回答
Cloud Runを使用してサーバーレスアプリケーションを構築し、そのアプリケーションを本番環境にデプロイしました。あなたはコスト最適化のためにアプリケーションのリソース使用率を特定したいと考えています。
この要件を満たすために、どうすればよいですか？

1. Cloud Opsを使用してログベースのメトリクスを作成し、アプリケーションのリソース使用率を監視します
2. 分散トレース機能付きのCloud Traceを使用して、アプリケーションのリソース使用率を監視します
3. Ops AgentとCloud Profilerを使用して、アプリケーションのCPUとメモリの使用率を監視します
4. Cloud Monitoringを使用して、アプリケーションのコンテナCPUとメモリ使用率を監視します
<details><div>
    答え：4
説明
この問題では、サーバーレスアプリケーションのリソース使用率を特定することが目的で、そのアプリケーションはCloud Runにデプロイされているという事実が重要です。そのため問題解決のためには、Cloud Run用の適切な監視ツールを選択することが重要です。選択肢の中からCloud Runのアプリケーションに適切な監視ツールを選ぶことが求められます。ここでは、リソース使用率を監視するために適切なツールの選択が問われているのでそれに注目することが求められています。
基本的な概念や原則：
Cloud Run：コンテナ化されたアプリケーションをフルマネージドで実行するサービスです。サーバーレス環境での実行を可能にします。
Cloud Monitoring：Google Cloudのアプリケーションやインフラストラクチャのパフォーマンスを追跡し、視覚化するための監視サービスです。リソース使用率などの重要なメトリクスを提供します。
Cloud Trace：アプリケーションのパフォーマンスボトルネックを特定するための分散トレーシングシステムです。しかし、リソース使用率の監視には使用できません。
Ops Agent：Google Cloudのロギング、メトリクス、トレーシングエージェントです。しかし、メモリやCPU使用率に特化した監視能力はなく、Cloud Monitoringと組み合わせて使用されることが一般的です。
Cloud Profiler：Google Cloudのアプリケーションパフォーマンス管理ツールです。アプリケーションの実行時間を視覚化し、パフォーマンス問題を特定します。しかし、リソース使用率の監視には使用できません。
Cloud Ops：Google Cloudのオペレーションスイートです。ログ管理、エラーレポーティング、トレーシング、モニタリングなどの機能を提供します。しかし、ログベースのメトリクス作成はリソース使用率の監視だけでなく、他の多くの目的にも使用されます。
正解についての説明：
（選択肢）
・Cloud Monitoringを使用して、アプリケーションのコンテナCPUとメモリ使用率を監視します
この選択肢が正解の理由は以下の通りです。
まず、Cloud MonitoringはGoogle Cloudの監視、警告、診断ツールであり、アプリケーションのパフォーマンス、稼働状況、リソース使用率を追跡および可視化する機能を提供します。これはコスト最適化のためにあなたが必要としている機能であり、リソース使用率の特定に役立ちます。
また、Cloud MonitoringではCloud Runの各アプリケーションが使用しているCPUとメモリの詳細データを取得することができます。これにより、過負荷や過剰なリソース配分を特定し、最適化することが可能です。
したがって、Cloud Runのアプリケーションのコスト最適化を追求する場合、Cloud Monitoringは有効なツールと言えます。特に、サーバーレスアプリケーションのリソース使用状況を監視し、パフォーマンスを最適化する上で欠かせないサービスです。
不正解についての説明：
選択肢：分散トレース機能付きのCloud Traceを使用して、アプリケーションのリソース使用率を監視します
この選択肢が正しくない理由は以下の通りです。
Cloud Traceの分散トレース機能はアプリケーションのパフォーマンス問題を診断するのに役立ちますが、リソースのCPUやメモリ利用率を監視するためのものではありません。
それに対して、Cloud Monitoringはリソース使用率を視覚的に監視し解析する機能を提供しています。
選択肢：Ops AgentとCloud Profilerを使用して、アプリケーションのCPUとメモリの使用率を監視します
この選択肢が正しくない理由は以下の通りです。
Ops AgentとCloud Profilerはインフラやアプリケーションのパフォーマンスの詳細監視やプロファイリングには役立つが、サーバーレス環境でのリソース使用率の監視は直接的には行えません。
一方、Cloud MonitoringはコンテナのCPUやメモリ使用率を直接監視可能なので、この問題の要件を満たします。
選択肢：Cloud Opsを使用してログベースのメトリクスを作成し、アプリケーションのリソース使用率を監視します
この選択肢が正しくない理由は以下の通りです。
Cloud Opsは、Cloud Operationsの略であり、その一部にCloud Monitoringが含まれます。しかし、リソースの使用率を監視するためには、Cloud Monitoringの機能が直接必要となるため、正解の選択肢の方が具体的に正しい操作を指しています。ログベースのメトリクスではリソース使用率の監視が十分に行われません。
参考リンク：
https://cloud.google.com/monitoring
https://cloud.google.com/run/docs/monitoring/metrics
https://cloud.google.com/trace/docs
</div></details>

### Q. 問題40: 未回答
あなたの組織には、オンプレミスで動作するコンテナ化されたWebアプリケーションがあります。Google Cloudへの移行計画の一環として、以下の受け入れ基準を満たすデプロイ戦略とプラットフォームを選択する必要があります：
1.プラットフォームは、AndroidデバイスからのトラフィックをAndroid固有のマイクロサービスに誘導できなければなりません。
2.プラットフォームは、任意のパーセンテージベースのトラフィック分割が可能である必要があります。
3.デプロイメント戦略により、あらゆるマイクロサービスの複数のバージョンを継続的にテストできなければなりません。
あなたはこの要件を満たすために、どうすればよいですか？

1. アプリケーションのカナリアリリースをApp Engineにデプロイします。トラフィックの分割を使用して、IPアドレスに基づいてユーザートラフィックのサブセットを新しいバージョンに誘導します
2. アプリケーションのカナリアリリースをCompute Engineにデプロイします。Compute EngineでAnthos Service Meshを使用し、仮想サービスを設定することで、ユーザートラフィックの10%をカナリアリリースに誘導します
3. アプリケーションのカナリアリリースをCloud Runにデプロイします。トラフィック分割を使用して、リビジョンタグに基づいて、ユーザートラフィックの10%をカナリアリリースに誘導します
4. Anthosサービスメッシュを使ってGoogle Kubernetes Engineにカナリアリリースをデプロイします。トラフィックの分割を使用して、仮想サービスに設定されたユーザーエージェントヘッダーに基づき、ユーザートラフィックの10%を新しいバージョンに誘導します
<details><div>
    答え：4
説明
この問題では、コンテナ化されたWebアプリケーションをGoogle Cloudに適切に移行し、特定の要件を満たす最適なデプロイ戦略とプラットフォームを選ぶ方法を問います。目標とする要件には、Androidデバイスのトラフィックを特定のマイクロサービスに誘導する能力、任意のパーセンテージベースでのトラフィック分割が可能であること、複数のマイクロサービスのバージョンを同時にテストできるデプロイ戦略の必要性が含まれています。Google Cloudのサービスの理解と、それがどのように上記の要件を満たすのかを評価することがキーとなります。選択肢を吟味する際には、それぞれが提供する機能と限界を考慮しながら選択肢の詳細を注意深く確認することが重要です。
基本的な概念や原則：
Anthos Service Mesh：Google Cloudのサービスで、マイクロサービス間の通信を統制し、セキュリティ、ロードバランシング、モニタリングおよび診断の機能を提供します。
Google Kubernetes Engine（GKE）：マネージドなKubernetesサービスで、エンタープライズレベルのコンテナ化されたアプリケーションを構築、デプロイ、スケーリングするためのプラットフォームです。
カナリアリリース：新バージョンのアプリケーションを一部のユーザーだけに配布するデプロイ戦略で、新機能の影響をリスクを最小限に留めながら確認することが可能です。
トラフィック分割：異なるバージョンのアプリケーションやサービス間でトラフィックを分割します。パーセンテージベースで調整可能で、段階的なロールアウトやABテストに使われます。
Cloud Run：フルマネージド型のサーバーレスプラットフォームで、コンテナ化されたアプリケーションをデプロイし、自動的にスケールアップダウンします。
App Engine：開発者がアプリケーションをビルド、デプロイ、スケールできるフルマネージド型のPaaSです。自動的なスケーリング、ロードバランシング、マネージドランタイムなどの機能を持ちます。
Compute Engine：Google CloudのIaaSプロダクトで、仮想マシンを作成、管理するためのサービスです。
正解についての説明：
（選択肢）
・Anthosサービスメッシュを使ってGoogle Kubernetes Engineにカナリアリリースをデプロイします。トラフィックの分割を使用して、仮想サービスに設定されたユーザーエージェントヘッダーに基づき、ユーザートラフィックの10%を新しいバージョンに誘導します
この選択肢が正解の理由は以下の通りです。
まず、Anthos Service Meshは、マイクロサービス間での通信の管理と制御を提供するサービスメッシュプラットフォームであり、Google Kubernetes Engine（GKE）と一緒に使用されます。この組み合わせは、ANDROIDデバイスからのトラフィックをAndroid固有のマイクロサービスに誘導する機能を持つエンヴォイベースのプロキシを提供します。これは、WebアプリケーションでUser-Agent HTTPヘッダーを使用してトラフィックルーティングを行う機能を意味します。
また、Anthos Service Meshは任意のパーセンテージのトラフィック分割もサポートしています。これにより、新旧バージョン間でトラフィックを効率的に分割し、新機能の影響を評価することが可能となります。
さらに、カナリアリリースとは新バージョンのサービスを限定的に展開し、問題がないことを確認しながら全体に展開していくデプロイ戦略のことを指し、これによって複数のバージョンを継続的にテストする要件にも対応します。この機能により、問題がある場合にはすぐにロールバックするなど、運用の柔軟性と安全性が高まります。
不正解についての説明：
選択肢：アプリケーションのカナリアリリースをCloud Runにデプロイします。トラフィック分割を使用して、リビジョンタグに基づいて、ユーザートラフィックの10%をカナリアリリースに誘導します
この選択肢が正しくない理由は以下の通りです。
Cloud Runはトラフィック分割機能を提供しますが、ユーザーエージェントヘッダーに基づいたトラフィックの誘導はサポートしておらず、特定のマイクロサービスにAndroidからのトラフィックを誘導するという要件を満たせません。これに対してAnthosサービスメッシュならこの機能をサポートしています。
選択肢：アプリケーションのカナリアリリースをApp Engineにデプロイします。トラフィックの分割を使用して、IPアドレスに基づいてユーザートラフィックのサブセットを新しいバージョンに誘導します
この選択肢が正しくない理由は以下の通りです。
App EngineのカナリアリリースはIPアドレスに基づいてユーザートラフィックを分割することが可能ですが、Androidデバイスからのトラフィックを特定のマイクロサービスに誘導することはできません。この要件を満たすためには、ユーザーエージェントヘッダーに基づくトラフィック誘導が可能なAnthosサービスメッシュのようなソリューションが必要です。
選択肢：アプリケーションのカナリアリリースをCompute Engineにデプロイします。Compute EngineでAnthos Service Meshを使用し、仮想サービスを設定することで、ユーザートラフィックの10%をカナリアリリースに誘導します
この選択肢が正しくない理由は以下の通りです。
Compute EngineはAnthos Service Meshのサポート対象外であるため、この設定を利用することはできません。
したがって、Compute Engineを使用したシナリオは提供要件を満たさない適切な解決策ではなく、Google Kubernetes Engineを使用するほうが適しています。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/concepts/traffic-management
https://cloud.google.com/anthos-service-mesh/docs
https://cloud.google.com/kubernetes-engine/docs/how-to/deploying-apps
</div></details>

### Q. 問題44: 未回答
あなたのチームは、データのバッチに対して計算負荷の高い処理を行うサービスを構築しています。データはマシンのCPUの速度と数に基づいて高速に処理されます。これらのデータバッチのサイズはさまざまで、複数のサードパーティソースから随時届く可能性があります。サードパーティがデータを安全にアップロードできるようにする必要があります。コストを最小限に抑えつつ、可能な限り迅速にデータを処理したいと考えています。
この要件を満たすために、どうすればよいですか？

1. サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。標準的なGoogle Kubernetes Engine（GKE）クラスターを使用し、2つのサービスを維持します。1つはデータのバッチを処理するサービス、もう1つは新しいデータのバッチがないかCloud Storageを監視するサービスです。処理するデータのバッチがないときは、処理サービスを停止します
2. 第三者がデータのバッチをアップロードできるように、Compute Engineインスタンス上に安全なファイル転送プロトコル（SFTP）サーバーを提供し、サーバーに適切な認証情報を提供します。google.storage.object.finalize Cloud Storageトリガーを使用してCloud Functionsを実装します。この関数がCompute Engineのオートスケーリングマネージドインスタンスグループをスケールアップできるようにコードを記述します。処理が完了するとインスタンスを終了するデータ処理ソフトウェアがあらかじめロードされたイメージを使用します
3. サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。Cloud Monitoringを使用して、バケット内の新しいデータバッチを検出し、データを処理するCloud Functionsをトリガーします。処理の実行時間を最小限に抑えるために、可能な限り最大のCPUを使用するようにCloud Functionsを設定します
4. サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。google.storage.object.finalize Cloud Storageトリガーを持つCloud Functionを作成します。処理が完了したらインスタンスを終了させるデータ処理ソフトウェアがあらかじめロードされたイメージを使用します
<details><div>
    答え：4
説明
この問題では、高負荷のバッチ処理を効率的かつコスト効果的に行うための最良の方法を選びます。異なるサードパーティソースからデータが任意のタイミングで送られてくるという条件に対応できる柔軟さ、データのアップロードのための安全な手段、そしてコスト効率の良さを考慮して適切な選択肢を選ぶことが求められています。Google Cloudの各サービスの特性とそれらを使ったコスト効率の高いデータ処理の方法について理解していなければなりません。
基本的な概念や原則：
Cloud Storage：Google Cloudのデータストレージサービスで、データのバッチを安全に保存し、アクセスし、共有することが可能です。
IAM（Identity and Access Management）：Google Cloudの認証と認可を管理するツールです。特定のユーザーやサービスに対してリソースへのアクセス権限を細かく制御することができます。
Cloud Functions：イベント駆動型のサーバーレス環境で、時間やリソースの管理をせずにコードを実行することができます。特定のイベントに対して自動的にスケーリングします。
Cloud Storageトリガー：Cloud Storageで特定のイベントが発生したときにCloud Functionsを自動的に呼び出す機能です。特定のバケットにデータが追加・変更された時点でトリガーされることが一般的です。
Compute Engine：仮想マシンを実行するGoogle Cloudのインフラストラクチャサービスです。必要な仕様と量を選び、デプロイ及びスケーリングが可能です。
オートスケーリング：負荷に基づいて自動的にリソースの数を増減させる機能です。Compute EngineではVMのインスタンス数を動的に調節します。
Google Kubernetes Engine（GKE）：Google CloudでKubernetes環境を簡単にセットアップ、運用できるサービスです。稼働中のアプリケーションのスケーリングと配信を管理します。
正解についての説明：
（選択肢）
・サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。google.storage.object.finalize Cloud Storageトリガーを持つCloud Functionを作成します。処理が完了したらインスタンスを終了させるデータ処理ソフトウェアがあらかじめロードされたイメージを使用します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Storageバケットをサードパーティに提供することで、データやバッチのアップロードが容易になるだけでなく、IAMを使用して適切なアクセス制限を設けることができます。これによりセキュリティが強化されます。
次に、google.storage.object.finalize Cloud Storageトリガーを持つCloud Functionを作成すると、オブジェクトがバケットに最終的にアップロードされたタイミングで自動的に関数が実行されます。これにより、新たなデータが追加されるたびに即座にデータの処理が開始されることになります。
最後に、処理が完了したらインスタンスを終了させるソフトウェアを使用すれば、必要な時間だけリソースを使うようになり、コストを最小限に抑えることができます。これらの理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：第三者がデータのバッチをアップロードできるように、Compute Engineインスタンス上に安全なファイル転送プロトコル（SFTP）サーバーを提供し、サーバーに適切な認証情報を提供します。google.storage.object.finalize Cloud Storageトリガーを使用してCloud Functionsを実装します。この関数がCompute Engineのオートスケーリングマネージドインスタンスグループをスケールアップできるようにコードを記述します。処理が完了するとインスタンスを終了するデータ処理ソフトウェアがあらかじめロードされたイメージを使用します
この選択肢が正しくない理由は以下の通りです。
SFTPサーバーの設定は管理が複雑であり、必要な認証単位の追加や削除を行うことに多くのオーバーヘッドが発生します。
これに対し、Cloud StorageバケットはIAMによりアクセス制御が可能で、より直接的で簡単な方法で第三者に安全なアップロードを可能にします。
また、コスト面でもCloud Storageの方が低コストで効率的です。
選択肢：サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。標準的なGoogle Kubernetes Engine（GKE）クラスターを使用し、2つのサービスを維持します。1つはデータのバッチを処理するサービス、もう1つは新しいデータのバッチがないかCloud Storageを監視するサービスです。処理するデータのバッチがないときは、処理サービスを停止します
この選択肢が正しくない理由は以下の通りです。
サービスを常に維持するための管理コストと、新たなバッチデータをチェックするために別のサービスを維持する手間が発生します。
また、処理サービスが停止している間もGKEクラスター自体は稼働し続けるためコスト効率が悪いです。正解の選択肢ではCloud Functionsがデータ処理のトリガーとして稼働し、必要に応じてインスタンスを起動・終了するため、コスト効率的です。
選択肢：サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。Cloud Monitoringを使用して、バケット内の新しいデータバッチを検出し、データを処理するCloud Functionsをトリガーします。処理の実行時間を最小限に抑えるために、可能な限り最大のCPUを使用するようにCloud Functionsを設定します
この選択肢が正しくない理由は以下の通りです。
まず、Cloud Monitoringはデータバッチの到着を直接検出するためのツールではありません。正解の選択肢では、google.storage.object.finalizeイベントをトリガーとして用いるCloud Functionが適切に使用されています。
また、Cloud FunctionsはCPUの選択肢に制限があるため、高度なCPU設定を求められる処理には不向きです。
参考リンク：
https://cloud.google.com/storage/docs/access-control/iam
https://cloud.google.com/functions/docs/calling/storage
https://cloud.google.com/compute/docs/autoscaler
</div></details>

### Q. 問題45: 未回答
あなたの組織は、Google CloudプロジェクトのCloud Operationsでダッシュボードを生成するために使用されるシステムログを収集したいと考えています。システムログを収集するために、現在および将来のすべてのCompute Engineインスタンスを設定する必要があります。
この要件を満たすために、どうすればよいですか？

1. スタートアップスクリプトを使用して、Compute EngineイメージにOps Agentをインストールします
2. gcloud CLIを使用してエージェントポリシーを作成します
3. gcloud CLIを使用して、Cloud Asset Inventoryにリストされている各VMにOps Agentをインストールします
4. Cloud Operations VMsダッシュボードのAgent StatusがNot detectedのVMをすべて選択します。次に、Install agentsを選択します
<details><div>
    答え：2
説明
この問題では、Google CloudプロジェクトのCloud Operationsでログを収集するための設定について問われています。特に現在および将来のすべてのCompute Engineインスタンスのシステムログを収集する方法について考える必要があります。選択肢を見る際には、現在だけでなく将来のインスタンスもカバーできる、効率的な自動化の方法を探し、その上でCloud Operationsのログ収集に適した策を選ぶべきです。この問題は、Google Cloudのログ管理に関する理解と、継続的かつ自動化されたログ収集の設定方法への理解を試すものとなります。
基本的な概念や原則：
gcloud CLI：Google Cloudコマンドラインインターフェースで、Google Cloudサービスを操作するためのツールです。各種設定やリソース管理などがコマンドラインから行えます。
エージェントポリシー：特定の操作を実行するためにシステムに導入されるソフトウェアルールのセットです。このポリシーを通じてログ収集などの行動を制御します。
Ops Agent：Google Cloudのオペレーションスイートのためのエージェントです。メトリクスの収集とログの送信を行います。
Compute Engineインスタンス：Google Cloud上で仮想マシンを実行するためのインスタンスです。特定の作業のために設定やリソースを割り当てることができます。
Cloud Operations：Google Cloudの監視、トラブルシューティング、および診断に役立つツールセットです。これにより、プロジェクトのパフォーマンスを評価し、障害の原因を特定できます。
正解についての説明：
（選択肢）
・gcloud CLIを使用してエージェントポリシーを作成します
この選択肢が正解の理由は以下の通りです。
まず、gcloud CLIを使ってエージェントポリシーを作成することは、システムログを収集するための最適な手段です。これは、Ops AgentやLogging AgentのようなエージェントはCompute Engineインスタンスでシステムメトリックやログを収集するためのツールだからです。gcloud CLIを使ってエージェントポリシーを作成することで、エージェントが必要とされるすべての現在または将来のインスタンスに自動的にインストールされます。
さらに、エージェントは収集した情報をCloud Operationsに送信し、ここで情報が統合されて分析・閲覧できます。
そして、これらの情報を基にダッシュボードを生成することが可能となります。
したがって、特定の要件を満たすためには、gcloud CLIを使用してエージェントポリシーを作成することが適切な選択肢となります。
不正解についての説明：
選択肢：gcloud CLIを使用して、Cloud Asset Inventoryにリストされている各VMにOps Agentをインストールします
この選択肢が正しくない理由は以下の通りです。
Ops AgentをCloud Asset Inventoryにリストされている各VMに個別にインストールする方法は、将来に作成されるVMに対してログ収集の設定が適用されないため、今後の全インスタンスに対応するという要件に適合しません。
代わりに、エージェントポリシーを作成することで現在及び将来作成される全VMに対する一元的なシステムログ収集を設定することができます。
選択肢：Cloud Operations VMsダッシュボードのAgent StatusがNot detectedのVMをすべて選択します。次に、Install agentsを選択します
この選択肢が正しくない理由は以下の通りです。
Cloud Operations VMsダッシュボードのAgent StatusがNot detectedのVMを選択し、Install agentsを選択する方法は、現在のCompute Engineインスタンスに対してのみエージェントをインストールします。しかし、要件は現在だけでなく将来のすべてのCompute Engineインスタンスにも適用することを求めています。
それに対して、gcloud CLIを使用してエージェントポリシーを作成すると、新たに生成されるCompute Engineインスタンスにも自動的に適用されます。
選択肢：スタートアップスクリプトを使用して、Compute EngineイメージにOps Agentをインストールします
この選択肢が正しくない理由は以下の通りです。
スタートアップスクリプトを用いてOps Agentをインストールする方法は、手動でVMを生成する度にスクリプトを実行する必要があり、将来的に追加されるすべてのCompute Engineインスタンスに対応しきれません。
一方、gcloud CLIを用いてエージェントポリシーを作成すれば、新規に作られるCompute Engineインスタンスにも自動的に適用されます。
参考リンク：
https://cloud.google.com/logging/docs/agent/ops-agent
https://cloud.google.com/compute/docs/instances/create-start-instance
https://cloud.google.com/sdk/gcloud/reference/compute/instances/add-metadata
</div></details>

### Q. 問題46: 未回答
Google Kubernetes Engine（GKE）にアプリケーションをビルドしてデプロイするために、複数ステップのCloud Buildパイプラインを使用します。ビルド情報をWebhookにHTTP POSTすることで、サードパーティの監視プラットフォームと統合したいと考えています。また、開発工数を最小限に抑えたいと考えています。
この要件を満たすために、どうすればよいですか？

1. Cloud Loggingを使用して、Cloud Buildログからログベースのメトリックを作成します。Webhook通知タイプでアラートを作成します
2. Cloud Buildのパイプラインの最後に、ビルド情報をWebhookにHTTP POSTする新しいステップを追加します
3. 各Cloud Buildステップに、ビルド情報をWebhookにHTTP POSTするロジックを追加します
4. Cloud Build cloud-builds PubSubトピックにCloud Pub/Subプッシュサブスクリプションを作成し、ビルド情報をWebhookにHTTP POSTします
<details><div>
    答え：4
説明
この問題では、Cloud Buildパイプラインを使用してアプリケーションを作成しデプロイするシナリオが提示されており、ビルド情報をサードパーティの監視プラットフォームに送信する必要があります。また、開発工数を最小限に抑えなければなりません。これは自動化と効率性が重要な要素であり、手動でのステップ追加や独自のロジック作成を避けることを示唆しています。解答選択肢を選ぶ際には、Google Cloudの既存サービスを活用し、よりシンプルで効率的な実装を重視することが求められます。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：Google Cloudで提供されている、Kubernetesをマネージド形式で使うことができるサービスです。Kubernetesは、コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を行うためのオープンソースのプラットフォームです。
Cloud Build：Google Cloudの継続的インテグレーションとデリバリーサービスで、ソースコードをビルド、テスト、デプロイします。
Webhook：HTTP POSTコールバックで、あるアクションが起きたときに通知を受ける方法です。
Cloud Pub/Sub：Google Cloudのリアルタイムメッセージングサービスで、独立したアプリケーション間でメッセージを送受信できます。
Cloud Logging：Google Cloudのログ管理サービスで、Google Cloudのリソースからのログを収集、分析、保存、エクスポートします。
パイプライン：連続するプロセスの一連のステップを指し、ここではソースコードのビルドからデプロイまでの一連の作業を指します。パイプラインにより、一貫性と効率性が確保されます。
正解についての説明：
（選択肢）
・Cloud Build cloud-builds PubSubトピックにCloud Pub/Subプッシュサブスクリプションを作成し、ビルド情報をWebhookにHTTP POSTします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Pub/SubはメッセージングとイベントドリブンシステムのためのGoogle Cloudのスケーラブルなサービスで、異なるサーバーアプリケーション間でメッセージを送受信します。Cloud Buildのビルド情報はcloud-buildsというPub/Subトピックに自動的に送信されます。そのため、このトピックにプッシュサブスクリプションを作成することで、ビルドが終了するたびに自動的に情報を取得できます。
次に、Pub/Subのプッシュサブスクリプションは、新しいメッセージがトピックに追加されるたびに、登録したエンドポイント（この場合Webhook）にHTTP POSTリクエストを送信します。これにより、手間をかけずにビルド情報をサードパーティの監視プラットフォームと統合できます。
したがって、Cloud Build cloud-builds PubSubトピックにPub/Subプッシュサブスクリプションを作成することで、開発工数を最小限に抑えつつ、問題の要件を満たすことができます。
不正解についての説明：
選択肢：各Cloud Buildステップに、ビルド情報をWebhookにHTTP POSTするロジックを追加します
この選択肢が正しくない理由は以下の通りです。
各Cloud Buildステップにロジックを追加すると、開発工数が増えてしまいます。
一方、Cloud Build cloud-builds PubSubトピックにCloud Pub/Subプッシュサブスクリプションを作成する方が、開発工数を最小限に抑えることが可能です。
また、これによりビルド情報をWebhookに一元的にHTTP POSTすることが可能となります。
選択肢：Cloud Buildのパイプラインの最後に、ビルド情報をWebhookにHTTP POSTする新しいステップを追加します
この選択肢が正しくない理由は以下の通りです。
新たにビルド情報をWebhookにHTTP POSTするステップを追加すると、開発工数が増加します。これは、工数を最小限に抑えるという要求に反しています。
一方で、Pub/Subサブスクリプションを作成すれば、独自のステップを追加せずにビルド情報をWebhookにPOSTすることが可能です。
選択肢：Cloud Loggingを使用して、Cloud Buildログからログベースのメトリックを作成します。Webhook通知タイプでアラートを作成します
この選択肢が正しくない理由は以下の通りです。
Cloud Loggingでログベースのメトリクスを作成し、Webhook通知タイプでアラートを作成すると、必要な開発工数が増えます。正解の選択肢であるCloud Pub/Subプッシュサブスクリプションを使用する方が直接的な統合が可能で、開発工数を最小限に抑えることができます。
参考リンク：
https://cloud.google.com/build/docs/configuring-builds/subscribe-build-notifications
https://cloud.google.com/pubsub/docs/overview
https://cloud.google.com/monitoring/support/notification-options#webhooks
</div></details>

### Q. 問題47: 不正解
あなたはPythonで書かれ、App Engineフレキシブル環境でホストされているトレーディングアプリケーションをサポートしています。Google Cloud Operation Suite Error Reportingに送信されるエラー情報をカスタマイズしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、App Engineフレキシブル環境でコードを実行します
2. Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、Google Kubernetes Engine上でコードを実行します
3. Google Cloud Operation Suite Error Reporting APIを使用して、アプリケーションからReportedErrorEventにエラーを書き込み、Cloud Loggingに適切な書式のエラーメッセージを含むログエントリを生成します
4. Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、Compute Engine VM上でコードを実行します
<details><div>
    答え：1
説明
この問題では、Pythonで作成されたトレーディングアプリケーションがApp Engineフレキシブル環境でホストされ、そのエラー情報のカスタマイズ方法が求められています。Google Cloud Operation Suite Error Reportingに関連するAPIやライブラリ、またその属する環境（Compute Engine VMやGoogle Kubernetes Engine等）について理解している必要があります。また、エラー情報のカスタマイズとはどういう動作を指すのか、Cloud Loggingにおけるログエントリとは何かといった要素への理解も必要です。これらを踏まえた上で、問題の正解選択肢を読み解くべきです。
基本的な概念や原則：
App Engineフレキシブル環境：App Engineの一部で、コンテナベースのランタイムを使用してアプリケーションを実行します。Pythonなど様々な言語がサポートされており、自由なカスタマイズが可能です。
Google Cloud Operation Suite Error Reporting：Google Cloudのサービスで、アプリケーションが発生するエラーを自動的に検出、分析、通知してくれます。
ReportedErrorEvent：Cloud Operation Suite Error Reporting APIで使用するエンティティでエラー情報を表現します。
Cloud Logging：Google Cloudのサービスで、アプリケーションやGoogle Cloudのサービスからのログを一元管理できます。ログのエクスポートやリアルタイム分析も可能です。
Google Cloud Operation Suite Error Reportingライブラリ：Google Cloudが提供するライブラリで、Pythonなどの言語でCloud Operation Suite Error Reportingの機能を利用するために使用します。
Compute Engine：Google Cloud Serviceの一つで、仮想マシンを提供します。比較的自由度が高いサービスですが、全ての環境設定をユーザーが行わなければならない場合があります。
Google Kubernetes Engine：Google Cloud Serviceの一つで、Kubernetesの管理環境を提供します。Dockerコンテナを管理するためのプラットフォームであり、アプリケーションをデプロイ、保守、スケーリングするために使用します。
正解についての説明：
（選択肢）
・Google Cloud Operation Suite Error Reporting APIを使用して、アプリケーションからReportedErrorEventにエラーを書き込み、Cloud Loggingに適切な書式のエラーメッセージを含むログエントリを生成します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Operation Suite Error Reporting APIを使用することで、エラー情報のカスタマイズが可能になります。これにより、エラー情報を手動で操作し、アプリケーション固有のエラー内容を追加したり、エラーメッセージのフォーマットを変更したりすることができます。
そして、ReportedErrorEventはAPIが提供するデータ構造で、エラー情報をGoogle Cloud Operation Suite Error Reportingに送信するために使用します。
そして、Cloud Loggingに生成されるログエントリは、Google Cloud Operation Suite Error Reporting APIを使用して送信されたエラー情報を格納します。よって、この選択肢はApp Engineフレキシブル環境でホストされるPythonアプリケーションからのエラー情報のカスタマイズと送信を実現します。
不正解についての説明：
選択肢：Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、Compute Engine VM上でコードを実行します
この選択肢が正しくない理由は以下の通りです。
要件はApp Engineフレキシブル環境でもエラー情報をカスタマイズしたいとする一方で、不正解の選択肢はCompute Engine VM上でエラーライブラリを実行するという点で乖離しています。これにより、必要でないリソースを使用し、期待されている結果が得られなかったという問題が発生する可能性があります。
選択肢：Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、Google Kubernetes Engine上でコードを実行します
この選択肢が正しくない理由は以下の通りです。
要件はApp Engineフレキシブル環境でのエラー情報のカスタマイズであり、Google Kubernetes Engine上での実行は関係していません。
また、ライブラリをインストールしてもカスタマイズは可能ではなく、APIを通じてエラーメッセージを生成・送信することが必要です。
選択肢：Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、App Engineフレキシブル環境でコードを実行します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite Error Reportingライブラリをインストールするだけでは、エラー情報のカスタマイズは実現できません。エラーメッセージの内容を制御するために、APIを用いてReportedErrorEventにエラーを書き込む必要があります。
参考リンク：
https://cloud.google.com/error-reporting/docs
https://cloud.google.com/error-reporting/docs/formatting-error-messages
https://cloud.google.com/logging/docs/
</div></details>

## 2
### Q. 問題2: 未回答
あなたは、オンプレミスとGoogle Cloud上にデプロイされた大規模なGoogle Kubernetes Engine（GKE）クラスター上で実行されるeコマースアプリケーションをサポートしています。アプリケーションは、コンテナで実行されるマイクロサービスで構成されています。あなたは、CPUとメモリを最も使用しているコンテナを特定したいと考えています。
この要件を満たすために、どうすればよいですか？
1. Prometheusを使ってコンテナごとにログを収集・集計し、その結果をGrafanaで分析します
2. Cloud Loggingを使用して、アプリケーションのログをBigQueryにエクスポートし、コンテナごとにログを集約して、CPUとメモリの消費量を分析します
3. Google Cloud Operation Suite Kubernetes Engine Monitoringを使用します
4. Google Cloud Operation Suite Monitoring APIを使ってカスタムメトリクスを作成し、グループを使ってコンテナを整理します
<details><div>
    答え：3
説明
この問題では、Google Kubernetes Engine（GKE）上で動作するeコマースアプリケーションのリソース使用状況を正確に追跡し、特にCPUとメモリ使用量が高いコンテナを特定することが求められています。問題文から、アプリケーションがマイクロサービスとして構成されており、各サービスがコンテナで独立して動作していることが分かります。解決策として選択するべきツールは、属性やリソース使用状況に基づいてコンテナの監視を容易にし、その情報を視覚的に提供するものです。そのため、選択肢の中から、一部のツールがこの目的に適していないか充分でない要素を理解するために、各ツールの機能と限界を比較検討する必要があります。
基本的な概念や原則：
Google Cloud Operation Suite Kubernetes Engine Monitoring：Google Cloudの監視ツールです。Kubernetes Engineのクラスターや、ワークロード、Pod、コンテナ、およびサービスのパフォーマンスを監視するものです。CPUやメモリの使用量に関する詳細な情報を提供します。
PrometheusとGrafana：オープンソースのモニタリングと視覚化ツールです。Prometheusはメトリクス情報の収集とストレージを行い、Grafanaはそれらのメトリクスを視覚化します。両者ともに、グラフ化やアラート通知などの豊富な機能を提供していますが、設定や管理が必要です。
Google Cloud Operation Suite Monitoring API：Google CloudのAPIです。このAPIを使用することで、カスタムメトリクスを作成したり、メトリクスデータを取得・書き込みしたりすることが可能です。特定のユースケースに対してカスタマイズした監視が可能となりますが、設計と実装が必要です。
Cloud LoggingとBigQuery：Google Cloudのサービスです。Cloud Loggingはログの収集・分析・エクスポートを行い、BigQueryは大規模なデータのクエリ実行や分析を行うためのサービスです。アプリケーションのログをBigQueryにエクスポートし、各コンテナのログを集約して分析することで、CPUやメモリの消費量を調査することが可能ですが、適切なクエリの設計と実行が必要です。
正解についての説明：
（選択肢）
・Google Cloud Operation Suite Kubernetes Engine Monitoringを使用します
この選択肢が正解の理由は以下の通りです。
Google Cloud Operation Suite Kubernetes Engine Monitoringは、クラスター内の全体的なパフォーマンスや各ノードおよびコンテナのリソース使用状況を追跡し、可視化する機能を提供しています。この機能は、リソースを最も消費しているコンテナを特定するための重要なツールです。
この機能はCPU、メモリ、ストレージ、ネットワークなどのリソースの使用率を監視します。これにより、リソースの過剰消費やリソース不足が発生しているコンテナを特定することが可能となります。
また、Google Cloud Operationsによってデータは自動的に集約され、分析やアラートの設定、パフォーマンスの障害を特定するための洞察の提供など、より深い洞察を得ることが可能です。
したがって、Google Cloud Operation Suite Kubernetes Engine Monitoringを使用することで、CPUとメモリ使用率が最も高いコンテナを特定する要件を満たすことができます。
不正解についての説明：
選択肢：Prometheusを使ってコンテナごとにログを収集・集計し、その結果をGrafanaで分析します
この選択肢が正しくない理由は以下の通りです。
PrometheusとGrafanaを使用する方法もCPUとメモリの使用状況を確認することは可能ですが、導入と設定が必要であり、手間がかかります。対してGoogle Cloud Operation Suite Kubernetes Engine Monitoringは、多大な設定なしにコンテナのリソース使用状況を監視でき、より簡単に要件を満たすことができます。
選択肢：Google Cloud Operation Suite Monitoring APIを使ってカスタムメトリクスを作成し、グループを使ってコンテナを整理します
この選択肢が正しくない理由は以下の通りです。
カスタムメトリクスを作成し、グループでコンテナを整理するというアプローチは、具体的なコンテナのCPUとメモリの使用状況を追跡するために必要なすべての情報を提供しない可能性があります。
また、この方法はGoogle Cloud Operation Suite Kubernetes Engine Monitoringを使用するよりも手間がかかり、より複雑な設定が必要になるため、効率的ではありません。
選択肢：Cloud Loggingを使用して、アプリケーションのログをBigQueryにエクスポートし、コンテナごとにログを集約して、CPUとメモリの消費量を分析します
この選択肢が正しくない理由は以下の通りです。
Cloud LoggingとBigQueryでは、実際のメモリやCPUの使用状況を直接解析することはできません。それらはログデータを保管、分析するためのツールで、メモリやCPUの使用量を直接的に監視、追跡する能力はありません。
それに対し、Cloud Operation Suite Kubernetes Engine Monitoringは実際のリソースの使用状況を監視し特定することが可能です。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/monitoring
https://cloud.google.com/stackdriver/docs
https://prometheus.io/docs/introduction/overview/
</div></details>

### Q. 問題24: 未回答
あなたの組織は最近、アプリケーション開発にコンテナベースのワークフローを採用しました。あなたのチームは、自動化されたビルドパイプラインを通じて、本番環境のKubernetesクラスターに継続的にデプロイされる多数のアプリケーションを開発しています。セキュリティ監査人は、開発者やオペレータが自動テストを回避して、承認なしにコード変更を本番環境にプッシュできることを懸念しています。
承認を強制するために何をすべきですか？
1. Kubernetesクラスター内でバイナリ認証を有効にし、ビルドパイプラインを認証者として設定します
2. プルリクエストの承認が必要な保護ブランチをビルドシステムに設定します
3. アドミッションコントローラを使用して、受信リクエストが承認されたソースから発信されたものであることを確認します
4. Kubernetesのロールベースのアクセス制御（RBAC）を活用して、承認されたユーザーのみにアクセスを制限します
<details><div>
    答え：1
説明
この問題では、開発者やオペレーターが承認なしに本番環境にコード変更をプッシュすることを防ぎ、セキュリティを確保する方策を尋ねています。コード変更を本番環境にプッシュするプロセスが自動化されているため、このプロセスにおいて適切な承認メカニズムを通じてセキュリティを強化する方法を考えるべきです。そのためには、自動化プロセスにおける承認システムとして、それぞれの選択肢の特性を正確に理解することが必要です。
基本的な概念や原則：
バイナリ認証：Google Cloud上のKubernetesクラスターで特定のコンテナイメージのデプロイを制御するためのサービスです。これにより、承認されたソースからの変更だけがデプロイされるよう保証します。
Kubernetesクラスター：Kubernetesは、コンテナ化されたアプリケーションのデプロイ、スケーリング、運用を自動化するオープンソースのオーケストレーションシステムで、Kubernetesクラスターはその基盤となるインフラストラクチャです。
保護ブランチ：ソースコード管理システムにおいて特定の変更を制限するための設定です。例えば、プルリクエストの承認が必要となるよう設定できます。
アドミッションコントローラ：KubernetesのAPIへのリクエストをチェックし、その挙動を制御するプラギンです。リソースの作成、変更、削除等の操作がパスするかどうかをチェックします。
ロールベースのアクセス制御（RBAC）：KubernetesのAPIへの各ユーザーのアクセス権限を制御する手法です。ロール（ロール）を定義し、そのロールに対して一連のアクセス権限を割り当てます。
正解についての説明：
（選択肢）
・Kubernetesクラスター内でバイナリ認証を有効にし、ビルドパイプラインを認証者として設定します
この選択肢が正解の理由は以下の通りです。
まず、バイナリ認証は、Google Cloudにおけるコンテナイメージのデプロイを制御するセキュリティ機能です。これを有効にすると、特定の条件を満たしたコンテナイメージのみがKubernetesクラスターにデプロイされます。これにより、信頼できるソースからのデプロイメントのみが許可され、不正や信頼できないコードのデプロイを未然に防ぐことができます。
また、バイナリ認証は開発者やオペレーターが自動テストを回避して、承認なしにコード変更を本番環境にプッシュできないようにします。
さらに、ビルドパイプラインを認証者として設定することで、CI/CDパイプライン内で生成または変更されたコンテナイメージが信頼できるという保証が得られます。
このように、バイナリ認証を有効にしてビルドパイプラインを認証者とすることで、セキュリティ監査人の懸念を解消し、本番環境でのコード変更に対するリスクを軽減できるため、この選択肢が最適な解答となります。
不正解についての説明：
選択肢：プルリクエストの承認が必要な保護ブランチをビルドシステムに設定します
この選択肢が正しくない理由は以下の通りです。
保護ブランチはコードリポジトリレベルの制御であり、原則として本番環境への直接的なコードプッシュを防ぐことは可能ですが、自動テストの回避に対する具体的な対策とはなりません。
一方、バイナリ認証を有効にすると、ビルドパイプラインを通過したコンテナイメージのみがデプロイされるため、承認の強制及び自動テストの回避の防止に適しています。
選択肢：アドミッションコントローラを使用して、受信リクエストが承認されたソースから発信されたものであることを確認します
この選択肢が正しくない理由は以下の通りです。
アドミッションコントローラは、Kubernetes APIへのリクエストを監視し、ポリシーに基づいてそのリクエストを許可あるいは拒否します。しかし、これでは自動テストを回避し、承認なしに本番環境に変更をPushされることを防ぐ効果は無く、ビルドパイプラインのコントロールには不十分です。
それに対して、バイナリ認証を用いると確実に承認を通すビルドのみをデプロイできます。
選択肢：Kubernetesのロールベースのアクセス制御（RBAC）を活用して、承認されたユーザーのみにアクセスを制限します
この選択肢が正しくない理由は以下の通りです。
Security Auditorの主な懸念は承認なしにコード変更がプッシュされることであり、それはRBACを使ってアクセス制限を設けるだけでは対処できません。
それに対して、バイナリ認証を有効にすると、信頼できるソースからビルドされた正しいバイナリであることを確認し、不正な変更を防ぐことが可能です。
参考リンク：
https://cloud.google.com/binary-authorization/docs
https://cloud.google.com/kubernetes-engine/docs/concepts/binary-authorization
https://kubernetes.io/docs/reference/access-authn-authz/admission-controllers/
</div></details>

### Q. 問題50: 未回答
Webベースのアプリケーションの新機能を本番環境にデプロイする準備が整いました。Google Kubernetes Engine（GKE）を使用して、Webサーバーポッドの半分に段階的なロールアウトを行いたいと考えています。
この要件を満たすために、どうすればよいですか？
1. NoExecuteでノードテイントを使用します
2. パーティショニングされたローリングアップデートを使用します
3. パラレルポッド管理ポリシーでステートフルセットを使用します
4. デプロイメント仕様でレプリカセットを使用します
<details><div>
    答え：2
説明
この問題では、次の新機能を段階的に本番環境にデプロイしたいと考えているWebベースのアプリケーションの状況を理解することが必要です。この目的を達成するための方法について問われています。選択肢を検討するときは、Google Kubernetes Engine（GKE）を使ってWebサーバーポッドの半分にどのように段階的な更新を行うのかという点に焦点を当てることが重要です。選択肢はすべてKubernetesやGKEの機能に関するものですが、それぞれの機能が適切なロールアウト方法を提供できるかどうかを考える必要があります。
基本的な概念や原則：
パーティショニングされたローリングアップデート：新しいバージョンのアプリケーションを段階的にデプロイする手法です。元のポッドの一部をダウンして新しいバージョンのポッドを起動し、問題がなければ全てのポッドを新しいバージョンに更新することで、効果的なロールアウトやロールバックを実行します。
Google Kubernetes Engine（GKE）：Kubernetesクラスターのデプロイと管理を行うGoogle Cloudのサービスです。アプリケーションのスケーリングとロールアウト機能を提供します。
ノードテイント：Kubernetesの機能で、特定のノードにスケジュールされるポッドの制御を可能にします。ただし、デプロイメントの更新とは直接関連しません。
レプリカセット：Kubernetesのオブジェクトで、指定された数のポッドレプリカが実行されていることを保証します。ただし、回答として不適切です。
ステートフルセット：Kubernetesのオブジェクトで、順序付けられた、安定したネットワーク識別子を持つ一連のポッドを管理します。多くの場合、パラレルポッド管理ポリシーと共に使用されますが、段階的なロールアウトの答えとしては不適切です。
正解についての説明：
（選択肢）
・パーティショニングされたローリングアップデートを使用します
この選択肢が正解の理由は以下の通りです。
Google Kubernetes Engine（GKE）のパーティショニングされたローリングアップデートは、一度にすべてのポッドを更新するのではなく、指定した割合または数のポッドを一度に更新することができます。これにより、新機能を段階的にロールアウトし、障害発生時には影響を最小限に抑えることができます。
さらに、段階的なロールアウトでは新機能のパフォーマンスやユーザーフィードバックを逐次監視しながら進めることが可能になり、問題が生じた場合は迅速にロールバックすることも可能です。これは、新機能を安全に投入することが求められる本番環境において、中断時間を最小限に抑えつつ、新しいバージョンへの移行をスムーズに進めるために不可欠な機能です。
したがって、GKEのパーティショニングされたローリングアップデートが、Webサーバーポッドの半分に対する段階的ロールアウトを行うための適切な方法となります。
不正解についての説明：
選択肢：NoExecuteでノードテイントを使用します
この選択肢が正しくない理由は以下の通りです。
NoExecuteでノードテイントを使用すると、該当ノードは指定のポッドを撃退しますが、これはWebサーバーポッドの半分に段階的なロールアウトを行う要件を満たしません。
一方、パーティショニングされたローリングアップデートを使用すれば、徐々に更新を適用することが可能で、要件に合致します。
選択肢：デプロイメント仕様でレプリカセットを使用します
この選択肢が正しくない理由は以下の通りです。
デプロイメント仕様のレプリカセットでは段階的なロールアウトはできません。レプリカセットを使用すると一度にすべてのポッドが更新されます。
それに対して、パーティショニングされたローリングアップデートを使用すると、指定した割合のポッドを一度に更新することができ、段階的なロールアウトに対応しています。
選択肢：パラレルポッド管理ポリシーでステートフルセットを使用します
この選択肢が正しくない理由は以下の通りです。
ステートフルセットは状態を保持する必要があるアプリケーションのデプロイに使用しますが、新機能の段階的なロールアウトには適していません。
一方、パーティショニングされたローリングアップデートは、Webサーバーポッドの半分で新機能のデプロイを行う要件を満たします。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/concepts/deployment#rolling_updates
https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps
https://kubernetes.io/docs/concepts/workloads/controllers/deployment/#updating-a-deployment
</div></details>

## 3
### Q. 問題3: 未回答
Compute Engine上でアプリケーションを実行し、Google Cloud Operation Suiteを通してログを収集しています。あなたは、個人を特定できる情報（PII）が特定のログエントリフィールドに漏洩していることを発見しました。すべてのPIIエントリはuserinfoというテキストで始まります。これらのログエントリを後で確認できるように安全な場所にキャプチャし、Cloud Loggingへの漏洩を防ぎたいとします。
あなたはこの要件を満たすために、どうすればよいですか？
1. Google Cloud Operation SuiteエージェントでFluentdフィルタープラグインを使い、userinfoを含むログエントリーを削除し、エントリーをCloud Storageバケットにコピーします
2. Google Cloud Operation SuiteエージェントでFluentdフィルタープラグインを使い、userinfoを含むログエントリーを削除し、userinfoにマッチする高度なログフィルターを作成し、Google Cloud Operation SuiteコンソールでCloud Storageをシンクとしてログエクスポートを設定します
3. userinfoにマッチする基本的なログフィルターを作成し、Google Cloud Operation SuiteコンソールでCloud Storageをシンクとしてログエクスポートを設定します
4. userinfoに一致する高度なログフィルターを作成し、Google Cloud Operation SuiteコンソールでCloud Storageをシンクとしてログエクスポートを構成し、userinfoをフィルターとしてログ除外を構成します
<details><div>
    答え：1
説明
この問題では、Compute Engine上で動作していて、Google Cloud Operation Suiteを通じてログを収集するアプリケーションを考慮しています。特定のログエントリーフィールドに個人を特定できる情報（PII）が漏洩してしまっており、対策が求められています。注意すべきは、これらのPIIエントリはすべて'userinfo'というテキストで始まるという情報です。問題は、どのようにこれらを安全にキャプチャし、Google Cloud Loggingへの漏洩を防ぐかという点です。この問題を解決するために、Google Cloud Operation Suiteのエージェントやフィルタリングプラグイン、ログエクスポートといった概念が重要となります。
基本的な概念や原則：
Google Cloud Operation Suite：Google Cloudの監視ツール群です。Cloud Logging, Cloud Monitoringなどが含まれ、アプリケーションのパフォーマンス、ログ、リアルタイム分析などを管理します。
Fluentd：オープンソースのデータコレクターで、ログを統一的に管理するためのツールです。フィルタープラグインなど多種多様なプラグインが提供され、ログの収集、フィルタリング、転送を柔軟に行うことができます。
個人を特定できる情報（PII）：個人の識別や連絡などの情報を表します。プライバシー法により、保護されている情報が含まれます。
Cloud Logging：Google Cloud Operation Suiteの一部で、アプリケーションとシステムのログデータを一元的に管理するサービスです。
Cloud Storage：容量を気にせず、データを蓄積できるGoogle Cloudのストレージサービスです。データの保管やバックアップ、アーカイブなど、さまざまな利用シナリオに対応しています。
ログエクスポート：操作のログ情報のエクスポートのことです。異なるストレージサービスにデータをエクスポートし、取り出しや分析を可能にします。
ログフィルタ：特定の検索条件に一致するログデータのみを取り出すためのツールです。エラーや特定の操作など、重要な情報を効率的に抽出することができます。
正解についての説明：
（選択肢）
・Google Cloud Operation SuiteエージェントでFluentdフィルタープラグインを使い、userinfoを含むログエントリーを削除し、エントリーをCloud Storageバケットにコピーします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Operation SuiteエージェントはCompute Engineインスタンスからログを収集しCloud Loggingへ送信します。Fluentdフィルタープラグインを使用すると、エージェントがログエントリーを処理して送信する前にログをハンドリングすることができます。Fluentdフィルタープラグインにより、特定のパターンを含むログエントリーを削除することが可能となり、これによりPII情報がCloud Loggingに送信されるのを防ぐことができます。
また、Fluentdはログを他のデータストレージ、この場合はCloud Storageにコピーする機能も持っています。そのため、削除前のログエントリーを保存し、後から確認できるようにすることが可能です。削除したログエントリーを保存するため、PII情報を保持しつつ、セキュリティ上の漏洩を防げます。これらの理由から、この選択肢が最適な解答となります。
不正解についての説明：
選択肢：userinfoにマッチする基本的なログフィルターを作成し、Google Cloud Operation SuiteコンソールでCloud Storageをシンクとしてログエクスポートを設定します
この選択肢が正しくない理由は以下の通りです。
基本的なログフィルターを使用しても、該当するログエントリーはCloud Loggingから削除されず、依然として漏洩リスクが存在します。Fluentdフィルタープラグインを使用することで、適切にログエントリーを削除し、安全にエントリーをCloud Storageバケットにコピーすることが可能です。
選択肢：userinfoに一致する高度なログフィルターを作成し、Google Cloud Operation SuiteコンソールでCloud Storageをシンクとしてログエクスポートを構成し、userinfoをフィルターとしてログ除外を構成します
この選択肢が正しくない理由は以下の通りです。
高度なログフィルターとログ除外の構成は、userinfoを含むログエントリをフィルタリングし除外しますが、これらがCloud Storageにコピーされる保証はありません。
一方、Fluentdフィルタープラグインでは、userinfoを含むエントリを削除し、同時にエントリをCloud Storageにコピーすることが可能です。
選択肢：Google Cloud Operation SuiteエージェントでFluentdフィルタープラグインを使い、userinfoを含むログエントリーを削除し、userinfoにマッチする高度なログフィルターを作成し、Google Cloud Operation SuiteコンソールでCloud Storageをシンクとしてログエクスポートを設定します
この選択肢が正しくない理由は以下の通りです。
フィルタープラグインでPIIデータを削除した後に、userinfoをマッチさせるフィルターを作成するのはピント外れです。PIIデータは既に削除されているため、このフィルターは結果に影響を与えません。そのため、マッチングフィルターの作成は不要なステップで、正解の解答と比べて効率的でもないです。
参考リンク：
https://cloud.google.com/logging/docs/agent/logging/configuration
https://cloud.google.com/logging/docs/exclusions
https://www.fluentd.org/guides/recipes/google-cloud-platform-logging
<details><div>

### Q. 問題7: 未回答
セキュリティのシフトレフトを目指すあなたの会社のイニシアチブの一環として、InfoSecチームは全チームに対し、すべてのGoogle Kubernetes Engine（GKE）クラスターにガードレールを実装し、信頼され承認されたイメージのデプロイのみを許可するよう求めています。あなたは、セキュリティのシフトレフトというInfoSecチームの目標を満たす方法を決定する必要があります。
この要件を満たすために、どうすればよいですか？
1. Artifact Registryでコンテナ分析を有効にし、コンテナイメージの一般的な脆弱性と暴露（CVE）をチェックします
2. 実行中のポッドの脆弱性を監視するために、FalcoまたはTwistlockをGKEにデプロイします
3. IAM（Identity and Access Management）ポリシーを構成して、GKEクラスターに最小権限モデルを作成します
4. バイナリ認証を使用して、CI/CDパイプラインでイメージを認証します
<details><div>
    答え：4
説明
この問題では、セキュリティのシフトレフトという概念とその具現化を理解することがキーとなります。シフトレフトは開発プロセスの早い段階でセキュリティを取り入れることを意味し、すべてのGKEクラスターにおいて信頼できるイメージのみデプロイするという要求が出されています。選択肢を見るときには、この目指すべき状態を満たす手段に焦点を当て、GKEのクラスターレベルで操作するよりも早い段階、つまりCI/CDパイプラインのステージでセキュリティを担保する選択肢を探すべきです。
基本的な概念や原則：
バイナリ認証：Google Kubernetes Engine（GKE）環境でのコンテナイメージの実行を制御するための運用時間のセキュリティ機能です。信頼されたソースからのイメージのみがデプロイできるようにします。
セキュリティのシフトレフト：セキュリティの考慮をプロジェクトの初期段階に持ち込むアプローチです。開発プロセスの初期段階でセキュリティ問題を検出し、修正します。
Artifact Registry：Google Cloudのパッケージ管理サービスで、Dockerコンテナイメージや言語ベースのパッケージを保存、管理します。ワークロードのセキュリティと信頼性を向上させるために使用します。
IAM（Identity and Access Management）：Google Cloudリソースへの認証と認可を管理するサービスです。IAMポリシーを使って、特定のユーザーが特定のリソースに対して何をすることができるかをコントロールします。
Falco、Twistlock：Kubernetesセキュリティのツールです。実行中のポッドの脆弱性を監視し、不正な行為を検出します。
CI/CDパイプライン：継続的インテグレーション（CI）と継続的デリバリー（CD）を組み合わせた開発プロセスです。コードの変更を自動的にビルド、テスト、デプロイします。
正解についての説明：
（選択肢）
・バイナリ認証を使用して、CI/CDパイプラインでイメージを認証します
この選択肢が正解の理由は以下の通りです。
まず、バイナリ認証はGoogle Cloudのサービスで、信頼できるイメージのみがデプロイされることを保証します。これは、環境に対する全てのイメージデプロイを制御し、未承認や不明なソースからのデプロイを防ぎます。そのため、InfoSecチームが求めている"信頼され承認されたイメージのデプロイのみを許可する"という要件を満たすことができます。
次に、バイナリ認証はCI/CDパイプライン（継続的インテグレーション/継続的デリバリー）と統合され、デプロイプロセス中にイメージが信頼できるかどうかを自動的に検証します。これにより、セキュリティのシフトレフトを進めることができます。セキュリティのシフトレフトとは、開発の初期段階からセキュリティを考慮に入れるアプローチのことで、この早期に問題を特定することでリスクを軽減し、修正費用を削減することができます。
不正解についての説明：
選択肢：Artifact Registryでコンテナ分析を有効にし、コンテナイメージの一般的な脆弱性と暴露（CVE）をチェックします
この選択肢が正しくない理由は以下の通りです。
Artifact Registryでのコンテナ分析はイメージの脆弱性をチェックする機能ですが、特定のイメージのデプロイを制限するガードレールを実装する機能はありません。
一方、バイナリ認証を使用すれば、信頼され承認されたイメージのみのデプロイを実現できます。
選択肢：IAM（Identity and Access Management）ポリシーを構成して、GKEクラスターに最小権限モデルを作成します
この選択肢が正しくない理由は以下の通りです。
IAMポリシーを配置してGKEクラスターに最小権限モデルを作成するという手法は、認証やアクセス制御には効果的ですが、特定の信頼され承認されたイメージのデプロイのみを許可するという具体的な要件を実現するには対応していません。
一方、バイナリ認証はCI/CDパイプライン内で特定のイメージが期待するように署名され証明されたものであるかを確認し、その結果次第でGKE上へのデプロイを控えることが可能です。これにより、問題の要件を概念的にも技術的にも満たすことができます。
選択肢：実行中のポッドの脆弱性を監視するために、FalcoまたはTwistlockをGKEにデプロイします
この選択肢が正しくない理由は以下の通りです。
FalcoやTwistlockは、既にデプロイされたポッドの脆弱性を監視するツールですが、この問題はあらかじめ承認されたイメージのみデプロイできるようにする点に重点が置かれています。
したがって、正解のバイナリ認証を用いてCI/CDパイプラインでイメージが認証されるべきです。
参考リンク：
https://cloud.google.com/binary-authorization/docs
https://cloud.google.com/kubernetes-engine/docs/concepts/binary-authorization
https://cloud.google.com/artifact-registry/docs/container-analysis
<details><div>

### Q. 問題13: 未回答
あなたの会社では、CI/CDのためにGoogle Cloud VMインスタンス上で動作するJenkinsを使っています。あなたは、Terraformを使用することで、Infrastructure as Code Automationを使用するように機能を拡張する必要があります。Terraform JenkinsインスタンスがGoogle Cloudリソースを作成する権限があることを確認する必要があります。あなたは、Googleが推奨するプラクティスに従いたいと考えています。
この要件を満たすために、どうすればよいですか？
1. Jenkins VMインスタンスに、適切なIAM（Identity and Access Management）権限を持つサービスアカウントがアタッチされていることを確認します
2. Terraformインスタンス専用のサービスアカウントを作成します。シークレットキーの値をダウンロードし、JenkinsサーバのGOOGLE_CREDENTIALS環境変数にコピーします
3. Terraformコマンドを実行する前に、Jenkinsのステップとしてgcloud auth application-default loginコマンドを追加します
4. Secret Managerが認証情報を取得できるように、Terraformモジュールを使用します
<details><div>
    答え：1
説明
この問題では、Google Cloudの仮想マシンインスタンス上で稼働するJenkinsがTerraformを介してGoogle Cloudリソースの作成を可能にすることが求められています。その際にはGoogleが推奨するプラクティスに従うことが求められています。その要点としては、サービスアカウントの適切な使用やIAM権限の管理が挙げられます。また、認証情報やシークレットキーの管理も重要な要素となります。これらの要素を考慮に入れつつ、最適な解答選択肢を選びます。
基本的な概念や原則：
サービスアカウント：Google Cloudでアプリケーションやサービスが他のGoogleサービスと認証され、通信できるようにするための特殊なアカウントです。IAMポリシーによって権限を与えられます。
IAM（Identity and Access Management）：Google Cloudにおける認証と権限管理のフレームワークです。ユーザー、グループ、サービスアカウントへのリソースへのアクセスを制御できます。
Terraform：Infrastructure as Code（IaC）を実現するためのオープンソースのツールです。クラウドリソースの作成、変更、バージョン管理を自動化できます。
Secret Manager：Google Cloudのセキュアなストレージサービスで、APIキーやパスワードなどの機密情報を保存、管理できます。
Jenkins：オープンソースのCI/CDツールです。ビルド、テスト、デプロイなどの自動化をサポートします。
gcloud auth application-default loginコマンド：Google Cloud SDKのコマンドで、アプリケーションデフォルトの認証情報を取得します。ただし、プロダクション環境ではこの方法は推奨されていません。
正解についての説明：
（選択肢）
・Jenkins VMインスタンスに、適切なIAM（Identity and Access Management）権限を持つサービスアカウントがアタッチされていることを確認します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、Googleが推奨するプラクティスとして、インスタンスに操作権限を与えるべき相手（この場合はTerraform Jenkinsインスタンス）に対してサービスアカウントを用いることが推奨されています。サービスアカウントはアプリケーションやサービスがGoogle Cloudリソースに安全にアクセスするための特別な種類のアカウントです。
また、これらのサービスアカウントに対しては、必要な操作のみを許可する最小権限の原則に基づきIAM権限を付与することが推奨されています。
したがって、Jenkins VMインスタンスに適切なIAM権限を持つサービスアカウントをアタッチすることで、Terraform JenkinsインスタンスがGoogle Cloudリソースを作成する権限を確保することができます。以上から、この選択肢が要件を満たす最適な方法となります。
不正解についての説明：
選択肢：Secret Managerが認証情報を取得できるように、Terraformモジュールを使用します
この選択肢が正しくない理由は以下の通りです。
要件は、Terraform Jenkinsインスタンスが適切な権限を有していること確認することで、Secret Managerを使用すると認証情報の取得が可能になりますが、その使用が要件を満たすわけではありません。プラクティスとしては、サービスアカウントを通じて適切なIAM権限をアタッチするのが推奨されています。
選択肢：Terraformインスタンス専用のサービスアカウントを作成します。シークレットキーの値をダウンロードし、JenkinsサーバのGOOGLE_CREDENTIALS環境変数にコピーします
この選択肢が正しくない理由は以下の通りです。
Googleの推奨するプラクティスでは、シークレットキーをダウンロードし直接環境変数にコピーするのではなく、サービスアカウントを用いて認証を行います。これは、シークレットキーの取り扱いはリスクが高く、セキュリティの観点から推奨されないからです。正解の選択肢であるIAM権限を持つサービスアカウントを利用する方が、セキュリティが確保されます。
選択肢：Terraformコマンドを実行する前に、Jenkinsのステップとしてgcloud auth application-default loginコマンドを追加します
この選択肢が正しくない理由は以下の通りです。
gcloud auth application-default loginコマンドを使用すると、ユーザーアカウントを使ってGoogle Cloudサービスに対する認証を行いますが、これは本番環境では適切な方法ではありません。セキュリティ上の理由から、サービスアカウントを介した認証が推奨されます。そのため、Jenkins VMインスタンスに適切なIAM権限を持つサービスアカウントをアタッチする方法が必要です。
参考リンク：
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/docs/terraform
https://www.terraform.io/docs/providers/google/guides/getting_started.html
<details><div>

### Q. 問題18: 未回答
あなたは、再利用可能なインフラストラクチャをコードモジュールとして開発しています。各モジュールには、テストプロジェクトでモジュールを起動する統合テストが含まれています。ソース管理にGitHubを使っています。機能ブランチを継続的にテストし、変更が受け入れられる前にすべてのコードがテストされるようにする必要があります。統合テストを自動化するソリューションを実装する必要があります。
この要件を満たすために、どうすればよいですか？
1. Cloud Buildを使用してテストを実行します。プルリクエストがマージされた後、すべてのテストをトリガーして実行します
2. Cloud Buildを使用して特定のフォルダでテストを実行します。GitHubプルリクエストごとにCloud Buildをトリガーします
3. CI/CDパイプラインにはJenkinsサーバーを使います。featureブランチのすべてのテストを定期的に実行します
4. プルリクエストのレビュアーに、コードを承認する前に統合テストを実行するよう依頼します
<details><div>
    答え：2
説明
この問題では、GitHubで管理されている再利用可能なインフラストラクチャのコードモジュールに対して、変更が受け入れられる前にテストを行い、それらのテストを自動化するソリューションを選択することが求められています。具体的には、コードモジュールの統合テストを自動化し、GitHubのプルリクエストごとにテストをトリガーする必要があります。そのために選択肢から最も合致するソリューションを選ぶ必要があります。この問題を解く上で、CI/CDパイプライン、特に統合テストの自動化とGitHubとの連携について理解していることが必要です。統合テストの自動化に関する選択肢とGitHubのプルリクエストを連携させる選択肢に焦点を当てることが重要です。
基本的な概念や原則：
Cloud Build：Google Cloudのコンテナ化されたアプリケーションのビルドとテストを行うフルマネージドサービスです。CI/CDパイプラインを設定し、自動化されたビルドとテストを実行できます。
統合テスト：ソフトウェアの異なる部分を組み合わせてテストする方法です。異なるコードモジュールが適切に連携して動作することを確認します。
GitHub：ソースコードを管理するためのプラットフォームです。ブランチの作成、プルリクエストの作成とマージ、コードのレビューなどの機能を提供します。
トリガー：あるアクションが発生したときに自動的に処理を開始するためのメカニズムです。例えば、Cloud Buildでは、特定のイベント（GitHubのプルリクエストの作成など）に応じてビルドをトリガーできます。
Jenkins：オープンソースの自動化ツールで、CI/CDパイプラインを構築するために使用されます。しかし、設定と管理が複雑であるため、非専門家には難しい可能性があります。
レビュアー：他者のコードを検討し問題を指摘する人です。手動テストは確認作業に時間がかかり、エラーを見逃す可能性があります。
マージ後のテスト：全てのテストをプルリクエストがマージされた後に実行する手法です。しかし、問題が発見された場合に修正が難しい場合があります。
正解についての説明：
（選択肢）
・Cloud Buildを使用して特定のフォルダでテストを実行します。GitHubプルリクエストごとにCloud Buildをトリガーします
この選択肢が正解の理由は以下の通りです。
Cloud BuildはGoogle Cloudが提供している継続的インテグレーションとデリバリー（CI/CD）プラットフォームで、アプリケーションのビルド、テスト、デプロイを自動化します。GitHubのリポジトリとCloud Buildは直接連携が可能であり、GitHubのプルリクエストやプッシュが行われるごとにCloud Buildをトリガーして自動テストを行うことができます。開発者はそれぞれの機能ブランチに対して修正を加えると、Cloud Buildが自動的に統合テストを行い、その結果がすぐに分かるようになります。
このようにCloud Buildを使用すれば、開発者が手動でテストを行う手間を省き、コードの品質管理が効率化し、再利用可能なインフラストラクチャを継続的にテストし、変更をより迅速に受け入れられるようにすることが可能となるため、最適な選択肢と言えます。
不正解についての説明：
選択肢：CI/CDパイプラインにはJenkinsサーバーを使います。featureブランチのすべてのテストを定期的に実行します
この選択肢が正しくない理由は以下の通りです。
Jenkinsを使用すると、サーバーの管理や設定が必要となり、それ自体が負担となります。
また、"定期的に実行"するための選択肢は、要求されている"継続的にテスト"するという要件を満たしていません。Cloud BuildのようにGitHubプルリクエストごとにテストを実行する方法が最適です。
選択肢：プルリクエストのレビュアーに、コードを承認する前に統合テストを実行するよう依頼します
この選択肢が正しくない理由は以下の通りです。
人為的なテスト実行依頼は自動化の要件を満たしません。これは、ミスや見落としを生む可能性があり、繰り返しの作業を必要とします。
一方、Cloud Buildを使用すると、テストは自動的に行われるため、効率的かつ安全性が高まります。
選択肢：Cloud Buildを使用してテストを実行します。プルリクエストがマージされた後、すべてのテストをトリガーして実行します
この選択肢が正しくない理由は以下の通りです。
すべての変更が受け入れられる前にコードがテストされるべきですが、この選択肢ではプルリクエストがマージされた後にテストが実行されるため、その要件を満たしていません。正解はプルリクエストごとにテストをトリガーすることで、この要件を満たします。
参考リンク：
https://cloud.google.com/build/docs/automating-builds/build-repos-from-github
https://cloud.google.com/build/docs/configuring-builds/run-builds-on-github
https://cloud.google.com/solutions/infrastructure-as-code
<details><div>

### Q. 問題22: 未回答
あなたはGitブランチが更新されたときにTerraformコードをデプロイするCloud Buildジョブをデプロイしています。テスト中に、あなたはジョブが失敗することに気づきました。ビルドログに次のようなエラーがあります：
Initializing the backend...
Error: Failed to get existing workspaces: querying Cloud Storage failed: googleapi: Error 403
Googleが推奨する方法に従って問題を解決する必要があります。
この要件を満たすために、どうすればよいですか？
1. Terraformの設定で指定した名前でストレージバケットを作成します
2. ローカルの状態を使用するようにTerraformのコードを変更します
3. ステートファイルバケットのCloud Buildサービスアカウントにroles/storage.objectAdminのIAM（Identity and Access Management）ロールを付与します
4. プロジェクトのCloud Buildサービスアカウントに、roles/ownerのIAM（Identity and Access Management）ロールを付与します
<details><div>
    答え：3
説明
この問題では、Terraformコードのデプロイ時に発生したCloud Buildジョブのエラーの解決方法を尋ねています。エラーメッセージを注意深く読むと、Cloud Storageへの問い合わせが403エラー、つまりアクセス権限が足りないことで失敗していることが分かります。ここで役立つのはGoogle CloudのIAMロールに関する知識と、Cloud Buildの仕組みに関する知識です。このエラーから、Cloud Buildジョブが実行されているサービスアカウントがCloud Storageバケット内のTerraformステートファイルに適切なアクセス権限を持っていない可能性があることを推測することができます。Googleが推奨する方法に従って問題を解決するために、既存のIAMロールを適切に調整することや適切なバケットを指定することが重要になります。
基本的な概念や原則：
Cloud Build：Google Cloudのサービスで、ソースコードからコンテナイメージやその他のビルドアーティファクトを高速にビルドして提供します。トリガーにより、ソースコードの変更に自動的に反応します。
Terraform：Infrastructure as Code（IaC）ツールで、バージョン管理や再利用可能なモジュールを扱うことができます。定義した状態に基づいて、リソースの作成、更新、削除を自動化します。
IAM（Identity and Access Management）ロール：Google Cloudにおいて特定のユーザーやサービスアカウントに特定の操作を許可するための概念です。ロールを持つユーザーまたはサービスは、そのロールに関連付けられた操作を実行できます。
サービスアカウント：アプリケーションやサービスがGoogle Cloud APIを呼び出すために使用する特殊なGoogleアカウントです。制限された範囲のリソースへのアクセスを付与できます。
ステートファイル：Terraformが現在のリソースの状態を捉えて保存するファイルです。リソースの作成や削除、更新における差分を確認するために使用されます。
Cloud Storage：Google Cloudが提供するスケーラブルなオブジェクトストレージです。バケットと呼ばれるコンテナ内にデータを保存できます。このバケットに対するアクセス権はIAMにより管理されます。
正解についての説明：
（選択肢）
・ステートファイルバケットのCloud Buildサービスアカウントにroles/storage.objectAdminのIAM（Identity and Access Management）ロールを付与します
この選択肢が正解の理由は以下の通りです。
エラーメッセージはCloud Storageに問題があることを示しています。具体的には、Cloud Buildがステートファイルをバケットに設定・取得するための適切な承認が得られていないことが問題となっています。Googleの推奨方法は、必要な権限を持たせるためにCloud BuildサービスアカウントにIAMロールを付与することです。ここで付与すべきロールは"roles/storage.objectAdmin"です。このロールを付与すると、Cloud Buildはオブジェクトを作成、読み取り、更新、削除するためのフルコントロール権限を与えられます。この権限があることで、Cloud BuildはTerraformを正常にデプロイし、エラーを解消できます。
不正解についての説明：
選択肢：ローカルの状態を使用するようにTerraformのコードを変更します
この選択肢が正しくない理由は以下の通りです。
ローカルの状態を使用するようにTerraformのコードを変更すると、Gitのブランチが更新されたときに毎回新規の状態が生成されるため、既存のリソースに対する一貫性を維持することが困難となります。そのため、この問題を解決する最善策はIAMロールを付与してアクセス権を与えることです。
選択肢：Terraformの設定で指定した名前でストレージバケットを作成します
この選択肢が正しくない理由は以下の通りです。
エラーメッセージは、Terraformがステートファイルを読み書きするための適切な権限を持っていないことを示しています。つまり、ストレージバケットが存在しない、という問題ではなく、Cloud Buildサービスアカウントに必要なアクセス権を付与していないことが問題です。
選択肢：プロジェクトのCloud Buildサービスアカウントに、roles/ownerのIAM（Identity and Access Management）ロールを付与します
この選択肢が正しくない理由は以下の通りです。
roles/ownerのIAMロールは、全てのリソースに対する全ての操作が可能となるという大幅な権限を持つため、セキュリティ上のリスクが高まります。
一方、正解の選択肢では、必要な操作のみが許可されるため、原則として最小限の権限を付与する事が推奨されているのです。
参考リンク：
https://cloud.google.com/build/docs/securing-builds/configure-access-for-cloud-build
https://cloud.google.com/storage/docs/access-control/iam-roles
https://www.terraform.io/docs/language/settings/backends/gcs.html
<details><div>

## 4
### Q. 問題10: 未回答
あなたの会社では、GitOps手法に従ってデプロイされたGoogle Kubernetes Engine（GKE）でアプリケーションを実行しています。アプリケーション開発者は、アプリケーションをサポートするためにクラウドリソースを頻繁に作成します。あなたは、Googleが推奨するプラクティスに確実に従いながら、開発者がインフラストラクチャをコードとして管理できるようにしたいと考えています。コンフィギュレーションのドリフトを避けるために、インフラストラクチャをコードとして定期的に調整する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. Terraform builderでCloud Buildを構成し、terraform planとterraform applyコマンドを実行します
2. Terraform planとterraform applyコマンドを実行するためのTerraform dockerイメージでポッドリソースを作成します
3. Google Kubernetes Engine（GKE）にConfig Connectorをインストールして設定します
4. terraform planコマンドとterraform applyコマンドを実行するためのTerraform dockerイメージでJobリソースを作成します
<details><div>
    答え：3
説明
この問題では、Google Kubernetes Engine（GKE）でアプリケーションを実行している状況下で、開発者がインフラストラクチャをコードとして管理するための最善の手法を選ぶことが求められています。ここで重要な点は、Googleが推奨するプラクティスを守りつつ、コンフィギュレーションのドリフトを避けることです。選択肢には、GKEに対する設定手段やTerraformを使用したインフラストラクチャのコード化を行う手法等があるので、これらの選択肢を用いて、Googleの推奨プラクティスに沿いつつ、開発者が容易にインフラストラクチャ管理ができる解答を選ぶべきです。
基本的な概念や原則：
GitOps：インフラストラクチャ管理のためのオペレーションプラクティスです。Gitを単一のソースとして使用し、デプロイメントやアップデートを自動化することで、迅速で信頼性の高いシステム変更を可能にします。
Google Kubernetes Engine（GKE）：Google CloudのマネージドKubernetesサービスです。アプリケーションをコンテナ化し、スケーリングと自動更新などの操作を行うことができます。
Config Connector：Google Cloudのサービスで、Google CloudリソースをKubernetesオブジェクトとして管理します。これにより、Kubernetesを使用してGoogle Cloudリソースとインフラを管理することができます。
インフラストラクチャ管理：インフラリソース（サーバ、ストレージ、ネットワークなど）をプロビジョニング、設定、運用するプロセスです。
Cloud Build：Google Cloudのサービスで、ソースコードからコンテナイメージやアプリケーションをビルドします。
Terraform：インフラストラクチャをコード化し、クラウドサービス、オンプレミスのリソースなどを安全かつ効率的にプロビジョニングするためのオープンソースのツールです。
コンフィギュレーションドリフト：運用環境の設定が、基準となる設定から時間とともに変わっていく現象です。これにより予期しない問題やエラーが発生する可能性があります。
正解についての説明：
（選択肢）
・Google Kubernetes Engine（GKE）にConfig Connectorをインストールして設定します
この選択肢が正解の理由は以下の通りです。
Google Kubernetes Engine（GKE）のConfig Connectorは、KubernetesリソースのようにGoogle Cloudリソースを管理するためのツールであり、これを用いることで開発者はインフラストラクチャをコードとして管理できます。GitOpsの手法は、ソースコードリポジトリを単一のソースとし、その変更が自動的に本番環境へデプロイされる方法論であり、Config Connectorをインストールすることで、そのアプローチをリソースとコンフィグの管理にも適用することが可能となります。
さらに、Config Connectorを使用すると、各リソースの望ましい状態がコードで定義されているため、定期的に適用することでコンフィギュレーションドリフトを防ぐことが可能となります。
このように、Config ConnectorはGitOps手法と相性が良く、Googleの推奨するプラクティスに従う結果となります。
不正解についての説明：
選択肢：Terraform builderでCloud Buildを構成し、terraform planとterraform applyコマンドを実行します
この選択肢が正しくない理由は以下の通りです。
Terraformを使用すると、インフラストラクチャの定義をコードとして管理できますが、GitOpsの原則に基づく自動同期機能は持っていません。そのため、手動での適用が必要となり、設定のドリフトの可能性が高まります。
一方、Config Connectorを使用すれば、GKE上でインフラストラクチャを直接管理でき、GitOpsの手法に自然に合致します。
選択肢：Terraform planとterraform applyコマンドを実行するためのTerraform dockerイメージでポッドリソースを作成します
この選択肢が正しくない理由は以下の通りです。
Terraformを用いたポッドリソースの作成はGitOpsメソッドに沿っていません。GitOpsはリポジトリを単一情報源とし、変更はプルリクエストによるレビューを通じて承認されます。明示的なTerraformコマンドに頼るアプローチは、この原則に反します。GKEにConfig Connectorを設定することは、Kubernetesリソースとしてクラウドリソースを直接管理するように設計されているため、GitOpsのスタイルに適合します。
選択肢：terraform planコマンドとterraform applyコマンドを実行するためのTerraform dockerイメージでJobリソースを作成します
この選択肢が正しくない理由は以下の通りです。
Terraform dockerイメージでJobリソースを作る方法は調整のために手動でコマンドを実行する必要があり、コンフィギュレーションドリフトの自動対策にはなりません。
一方、Config Connectorは自動化に適しており、Googleが推奨しているプラクティスも満たせます。
参考リンク：
https://cloud.google.com/config-connector/docs/overview
https://cloud.google.com/kubernetes-engine/docs/tutorials/config-connector
https://cloud.google.com/anthos-config-management/docs/tutorials/gitops-cloud-build
<details><div>

# 2
## 1
### Question 1
 
単一ゾーンにある自動スケーリングされたマネージド インスタンス グループで、アプリケーションを実行しています。これは優先度の高いワークロードであり、マネージド インスタンス グループに対するすべての変更を確定する前にテストする必要があります。変更のテスト中に、どのようなリクエストにも対処できるように十分な容量を確保する必要があります。どうすればよいですか。
1. 変更中に、スケールアウトのみを行うように自動スケーリングを構成する。
2. 変更中に、自動スケーリングを一時的に無効にする。
3. マネージド インスタンス グループを複数のゾーンで実行するように変更する。
4. 予測自動スケーリングを有効にする。
<details><div>
フィードバック
A: 正解です。スケールアウトのみを行うように自動スケーリングを構成すると、容量が低下することはありません。リクエストの数が増えると、マネージド インスタンス グループがスケールアウトします。

B: 不正解です。自動スケーリングを無効にした場合、サポートされるのは現在の容量だけなので、変更中に容量が不足する可能性があります。

C: 不正解です。複数のゾーンで実行するようにマネージド インスタンス グループを変更しても、テスト中の変更が容量に影響しないとは限りません。

D: 不正解です。予測自動スケーリングを有効にしても、アプリケーションに十分な容量が確保されるとは限りません。既存の構成の変更中に、実際のリクエスト数が急増したり、行った変更が予測自動スケーリングに影響したりして、容量不足になる可能性があります。
 
https://cloud.google.com/compute/docs/autoscaler/managing-autoscalers
</details></div>

### Question 2
 
会社のチームに属するすべての従業員は、一般的な統合開発環境（IDE）も含め、整合性のあるテンプレート化された開発環境を使用することが求められます。開発環境にセキュリティ パッチと更新を継続して適用する必要があります。また、各チームのすべての開発者が整合性のある開発環境を使用できるように、信頼性の高い、Google が推奨する手法を特定する必要があります。どうすればよいですか。

1. すべてのセキュリティ パッチが適用された、基準となる Compute Engine マシンの日次スナップショットを作成し、開発者がそのスナップショットを使用して各自のマシンを更新する。
2. 更新スクリプトを使用して、すべてのソフトウェア更新のチェックリストを作成し、開発者が各自のマシンを更新する。
3. 最新の依存関係を含むイメージを作成して、開発者が利用するノートパソコンにそのイメージをインストールする。
4. 各チームに特化した Cloud Workstations 構成を作成する。
<details><div>
正解
各チームに特化した Cloud Workstations 構成を作成する。

フィードバック
A: 不正解です。開発者が各自で更新を行うと不整合が生じる可能性があります。

B: 不正解です。開発者が各自で更新を行うと不整合が生じる可能性があります。

C: 不正解です。重要なパッチや更新をすべての開発者のノートパソコンに確実にロールアウトすることはできません。

D: 正解です。Cloud Workstations 構成は、複数の開発者が一貫したワークステーションを作成できるテンプレートを提供し、マシンタイプ、ディスクサイズ、ツール、プリインストールされるライブラリなどの構成設定を指定します。マシンタイプやコンテナ イメージの変更など、ワークステーション構成に対して行われた操作は、ワークステーションが次に起動したときに各ワークステーションに反映されます。
 
https://cloud.google.com/workstations/docs/overview
 
https://cloud.google.com/workstations/docs/create-configuration
 
https://cloud.google.com/workstations/docs/create-workstation
 
https://www.youtube.com/watch?v=E1cblFqb8nk
 
https://www.youtube.com/watch?v=C6Dpmujxp9Q
</details></div> 

### Question 3
 
重大な脆弱性に対処するセキュリティ パッチに関する情報があなたのチームに届きました。このパッチは、世界中の数百万ものお客様にサービスを提供する Compute Engine インスタンスに適用する必要があります。エンドユーザーに対する影響と費用を最小限に抑えながら、セキュリティ パッチを迅速にロールアウトする必要があります。どうすればよいですか。

1. 24 時間のローリング アップデートを行い、各リージョンで夜間にロールアウトする。
2. A/B ロールアウトを行い、Compute Engine のすべてのインスタンスのコピーを作成する。セキュリティ パッチを適用してからユーザーを切り替える。
3. 世界中のすべての Compute Engine インスタンスを同時に更新する。
4. セキュリティ パッチのカナリア ロールアウトを短期間で行う。
<details><div>
正解
セキュリティ パッチのカナリア ロールアウトを短期間で行う。

フィードバック
A: 不正解です。これは効果的な戦略ではありません。現在、お客様に日中にサービスを提供しているリージョン内の重要なシステムが攻撃ベクトルとなる可能性があるからです。

B: 不正解です。この方法は費用対効果が低く、すべてのサービスおよびマシンのコピーを作成するのにも時間がかかります。

C: 不正解です。セキュリティ パッチになんらかの悪影響や予期しない影響がある場合、すべてのユーザーが同時に影響を受ける可能性があります。

D: 正解です。カナリア ロールアウトを短期間で行うと、ロールアウトの展開前に、セキュリティ パッチのあらゆる副作用を、迅速かつ費用対効果の高い方法で特定できます。
 
https://sre.google/workbook/canarying-releases/
 
https://cloud.google.com/blog/products/gcp/how-release-canaries-can-save-your-bacon-cre-life-lessons
</details></div>

### Question 4
 
Cloud Run で世界中のユーザーに対してデプロイされるアプリケーションがあります。Cloud Run を構成し、リクエストに対するレスポンスが低レイテンシになるように、すべてのユーザーを最も近いリージョンにルーティングする必要があります。どうすればよいですか。

1. アプリケーションを 1 つのリージョンにデプロイし、グローバル外部 HTTP(S) ロードバランサの背後でグローバル エニーキャスト IP アドレスを使ってアプリケーションを提供する。
2. アプリケーションを各リージョンにデプロイし、グローバル外部 HTTP(S) ロードバランサの背後でグローバル エニーキャスト IP アドレスを使ってアプリケーションを提供する。
3. アプリケーションを各大陸の 1 つのリージョンにデプロイし、それぞれのリージョンでリージョン外部 HTTP(S) ロードバランサを使ってアプリケーションを提供して、同じグローバル IP アドレスをすべてのリージョン ロードバランサに割り当てる。
4. アプリケーションを 1 つのリージョンにデプロイし、フロントエンドに Google Cloud Armor を構成してすべての IP アドレスからのトラフィックを許可する。
<details><div>
正解
アプリケーションを各リージョンにデプロイし、グローバル外部 HTTP(S) ロードバランサの背後でグローバル エニーキャスト IP アドレスを使ってアプリケーションを提供する。

フィードバック
A: 不正解です。すべてのリクエストが Cloud Run の 1 つのインスタンスにルーティングされることになり、レイテンシや輻輳が発生します。

B: 正解です。Cloud Run インスタンスはユーザーのロケーションに最も近いリージョンで利用可能にする必要があります。グローバル外部 HTTP(S) ロードバランサはエニーキャスト IP アドレスのエンドポイントに設定でき、Cloud Run インスタンスが実行されている最も近いリージョンにリクエストがルーティングされます。

C: 不正解です。これは最も効率的なソリューションではありません。構成が複雑なロードバランサを複数構成する必要があり、お客様に対して一元的ではありません。

D: 不正解です。Google Cloud Armor の許可ルールにより全世界からのトラフィックが許可されますが、1 つのリージョンから提供される場合、レスポンスのレイテンシは高くなります。
 
https://cloud.google.com/run/docs/multiple-regions
 
https://cloud.google.com/run/docs/container-contract
</details></div>

### Question 5
 
会社では、Pod のエビクションとスケジュール変更に正しく反応しないレガシー データベースが Google Kubernetes Engine（GKE）で実行されています。実行中のデータベースを停止するわけにはいきません。使用する GKE メンテナンス戦略を選択する必要があります。どうすればよいですか。

1. GKE メンテナンスを「Stable」チャンネルで構成する。
2. ノードプールのアップグレード戦略の max-surge-upgrade を 0 に設定して構成する。
3. 「PodDisruptionBudget」オブジェクトを作成し、maxUnavailable を 100% に指定する。
4. メンテナンスの除外時間枠を「マイナー アップグレードまたはノード アップグレードなし」スコープで構成する。
<details><div>
正解
メンテナンスの除外時間枠を「マイナー アップグレードまたはノード アップグレードなし」スコープで構成する。

フィードバック
A: 不正解です。Stable リリース チャンネルのみを選択すると、すべての更新が Stable のリリース スケジュールで実行され、Pod エビクションが発生する可能性があります。

B: 不正解です。サージ アップグレード戦略ではメンテナンス更新を制限できず、Pod エビクションが発生する可能性があります。

C: 不正解です。100% の「PodDisruptionBudget」ではメンテナンス アップグレードは停止されないため、Pod エビクションが発生する可能性があります。

D: 正解です。「マイナー アップグレードまたはノード アップグレードなし」設定により、ノードプールの中断は回避され、ノードのアップグレードによるワークロードのエビクションとスケジュール変更を避けることができます。
 
https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions
 
https://cloud.google.com/kubernetes-engine/docs/concepts/maintenance-windows-and-exclusions#scope_of_maintenance_to_exclude
 
https://cloud.google.com/kubernetes-engine/docs/concepts/release-channels
 
https://cloud.google.com/kubernetes-engine/docs/best-practices/upgrading-clusters
 
https://www.youtube.com/watch?v=eqJQTANI_RI
</details></div>

### Question 6
 
組織で Cloud Run を使用して、コンテナ化されたアプリケーションをデプロイしています。アプリケーションの新しいバージョンが内部テストに合格したので、本番環境でのテストが必要になりました。アプリケーションをエンドユーザー向けにリリースする前に、ベータ版テスターがそのアプリケーションをテストできる構成を実装する必要があります。どうすればよいですか。

1. Cloud Run アプリケーションを本番環境にデプロイし、トラフィックの 1% をアプリケーションに転送する。
2. Google Cloud Armor を構成し、テストチーム以外の IP アドレスから送信されたリクエストを拒否する。
3. Compute Engine でプライベート VM インスタンスにコンテナをデプロイし、テストチームのアクセスのみを有効にする。
4. Cloud Run アプリケーションを「--no-traffic」オプションのタグ付きリビジョンで本番環境にデプロイし、テストチームと URL を共有する。
<details><div>
正解
Cloud Run アプリケーションを「--no-traffic」オプションのタグ付きリビジョンで本番環境にデプロイし、テストチームと URL を共有する。

フィードバック
A: 不正解です。エンドユーザーが 1% のうちに含まれ、アプリケーションにアクセスする可能性があります。

B: 不正解です。テストチームが使用する IP アドレスのリストを管理することは煩雑で、信頼性に欠けます。

C: 不正解です。このデプロイ環境は本番環境とは異なり、アプリケーションを確実にエンドユーザーにリリースするには、さらにテストする必要があります。

D: 正解です。タグを割り当てると、トラフィックを処理せずに特定の URL のリビジョンにアクセスできます。
 
https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#deploy-with-tags
 
https://cloud.google.com/run/docs/rollouts-rollbacks-traffic-migration#tags
 
https://www.youtube.com/watch?v=pi0Ss24bqL4
</details></div>

### Question 7
 
あなたが勤める小さな会社では、Cloud Build で CI / CD パイプラインの一部としてオープンソースの Java パッケージを使用しています。セキュリティ チームは、オープンソース パッケージの脆弱性が悪用されることを懸念しています。本番環境の依存関係の安全性を確保するために、費用対効果の高いソリューションを実装する必要があります。どうすればよいですか。

1. Assured Open Source Software（Assured OSS）パッケージを Cloud Build に pull する。
2. Cloud Source Repositories にパッケージを pull し、セキュリティ チームでオープンソース パッケージの検証を行う。
3. オープンソース パッケージをローカルに pull し、Cloud Build を使用してすべてのパッケージをスキャンして、フラグが付けられたパッケージを削除する。
4. 最新バージョンの GitHub パッケージのみを Cloud Build パイプラインに pull する。
<details><div>
正解
Assured Open Source Software（Assured OSS）パッケージを Cloud Build に pull する。

フィードバック
A: 正解です。Assured OSS パッケージは Google Cloud 独自のセキュアなパイプライン内に構築され、脆弱性のスキャン、分析、ファズテストが定期的に実施されます。

B: 不正解です。これは最も費用対効果の高いソリューションとはいえません。Google Cloud では、厳選された検証済みのオープンソース パッケージがすでに提供されているからです。

C: 不正解です。各ビルドに含まれるすべてのパッケージをスキャンすることは、費用対効果が高いとはいえません。また、不可欠なパッケージを削除すると、ビルドは失敗します。

D: 不正解です。最新のオープンソース バージョンを pull すると、未検出のバグや脆弱性が含まれている可能性があります。
 
https://cloud.google.com/assured-open-source-software/docs/remoterepositoryaccess
 
https://cloud.google.com/assured-open-source-software/docs/javaaccess
 
https://cloud.google.com/software-supply-chain-security/docs/practices
</details></div>

### Question 8
 
いくつかの Compute Engine インスタンス上で実行するカスタム アプリケーションがあります。サーバーの利用率が 90% まで上昇することがありますが、すぐに 50% 程度に戻ります。サーバーの利用率が 80% を超えた場合は、それに対処するよう通知するアラートが設定されていますが、届く通知が非常に多いため、利用率の高い状態が少なくとも 5 分続いた場合にのみ通知するようにアラートを変更する必要があります。どうすればよいですか。

1. ログベースの指標からアラートを作成する。ローリング ウィンドウは 5 分、しきい値は 90% とする。
2. ログベースの指標からアラートを作成する。ローリング ウィンドウは 5 分、しきい値は 80% とする。
3. 80% を超える利用率が 5 分間続いたことを示す通知を Cloud Run アプリケーションに送信する。
4. ログベースの指標からアラートを作成する。ローリング ウィンドウは 5 分とし、条件に指標は指定しない。
<details><div>
正解
ログベースの指標からアラートを作成する。ローリング ウィンドウは 5 分、しきい値は 80% とする。

フィードバック
A: 不正解です。90% を基準とした通知の場合、通知件数は減りますが、80～90% の高い利用率ではトリガーされません。

B: 正解です。利用率の高い状態が 5 分間続いた場合にのみ通知を受ける必要があります。

C: 不正解です。アラートをフィルタおよび分析するカスタム ソリューションの構築には多大な労力が必要になります。

D: 不正解です。指標がないことは、利用率が高いことを示すものではありません。
 
https://cloud.google.com/logging/docs/logs-based-metrics
 
https://cloud.google.com/logging/docs/logs-based-metrics/charts-and-alerts
 
https://cloud.google.com/monitoring/alerts/types-of-conditions#metric-threshold
 
https://www.youtube.com/watch?v=D0YKWvuJgwg
 
https://www.youtube.com/watch?v=4RgJjx4IxMs
 
https://www.cloudskillsboost.google/focuses/619?parent=catalog
</details></div>

### Question 9
 
組織には本番環境のプロジェクトが多数あり、それらを Google Cloud に移行する必要があります。組織のポリシーを一元管理しています。Google が推奨する方法に沿って、リソース階層のポリシー変更をロールアウトしようと考えています。どうすればよいですか。

1. ポリシー変更をテストするための組織とそれとは別の組織を本番環境に作成する。
2. 本番環境の組織を作成し、この組織に階層の上位から下位に向けてポリシー変更を段階的に適用する。
3. 本番環境の組織とリリース前のチェック用にステージング環境を作成し、ステージング環境ですべてのテストを実行する。
4. 本番環境の組織を作成し、この組織の本番環境のプロジェクトから順に階層の下位から上位に向けてポリシー変更を段階的に適用する。
<details><div>
正解
ポリシー変更をテストするための組織とそれとは別の組織を本番環境に作成する。

フィードバック
A: 正解です。ポリシーが適用されるリソース階層が変更されると、広範囲にわたり意図しない結果が生じる可能性があります。こうしたリスクを回避するため、メインの組織に適用する前に、別の組織でポリシーの変更をテストすることをおすすめします。

B:不正解です。多くのポリシーは組織全体に適用されます。既存の本番環境の組織にポリシー変更が適用されると、広範囲にわたり意図しない結果が生じる可能性があります。

C:不正解です。ステージング環境は本番環境の構成が反映される必要があります。構成の変更や、テストのためにセキュリティ構成を簡易化することはおすすめしません。

D: 不正解です。既存の本番環境の組織にポリシー変更が適用されると、意図しない結果が生じる可能性があります。
 
https://cloud.google.com/architecture/identity/best-practices-for-planning#use_a_separate_organization_for_experimenting
</details></div>

### Question 10
 
大量のデータを処理するフォールト トレラントなバッチ処理アプリケーションが組織で実行されています。コンピューティングは数百の VM に分散され、並列処理されています。大規模なデータ処理を実行するために費用対効果の高いソリューションを実装する必要があります。どうすればよいですか。

1. Spot VM を割り当ててデータを処理する。
2. 単一テナントのマシンを割り当ててデータを処理する。
3. 自動修復が有効であるマネージド インスタンス グループを作成する。
4. アクセラレータ最適化 VM と自動スケーリングが有効であるマネージド インスタンス グループを作成する。
 <details><div>
正解
Spot VM を割り当ててデータを処理する。

フィードバック
A: 正解です。Spot VM は、Compute Engine でのフォールト トレラントな処理において、通常の VM と比べて費用対効果の高いソリューションです。

B: 不正解です。単一テナント VM は最も費用対効果の高いソリューションではありません。

C: 不正解です。自動修復によって異常な VM は修復されますが、通常の VM 構成においては、最も費用対効果の高いソリューションではありません。

D: 不正解です。自動スケーリングにより必要に応じて VM が割り当てられますが、アクセラレータ最適化 VM 構成においては、最も費用対効果の高いソリューションではありません。
 
https://cloud.google.com/compute/docs/instances/spot
 
https://cloud.google.com/compute/docs/instances/create-use-spot
</details></div>

### Question 11
 
システム侵害の疑いが生じた場合に備えて本番環境のレプリカをテスト用に作成するよう、セキュリティ チームに求められています。Google が推奨する方法に沿って、セキュリティ チームに迅速にレプリカを提供する必要があります。どうすればよいですか。

1. Cloud Asset Inventory を実行し、本番環境内のリソースを一覧表示し、Google Cloud コンソールを使用してリソースを再作成する。
2. 本番環境を再作成する Terraform スクリプトを作成し、必要に応じてスクリプトを再実行する。
3. Security Command Center を使用してスキャンを実行し、本番環境内のリソースを一覧表示し、gcloud CLI を使用してリソースを再作成する。
4. 本番環境を再作成する Bash シェル スクリプトを作成し、必要に応じてスクリプトを再実行する。
<details><div>
フィードバック
A: 不正解です。コンソールを使用して技術環境全体を手動で繰り返し再作成することは、Google が推奨する方法ではありません。

B: 正解です。技術環境の再現性を管理するための方法として、Infrastructure as Code を推奨します。Google が推奨する Infrastructure as Code のツールは Terraform です。

C: 不正解です。Security Command Center で一覧表示したリソースでは、それらを再作成するための情報として不十分です。また、gcloud コマンドライン ツールを使用して技術環境全体を手動で繰り返し再作成することは、Google が推奨する方法ではありません。

D: 不正解です。Bash スクリプト ツールを使用して技術環境全体を手動で繰り返し再作成することは、Google が推奨する方法ではありません。
 
https://cloud.google.com/blog/products/devops-sre/want-repeatable-scale-adopt-infrastructure-as-code-on-gcp
 
https://cloud.google.com/docs/terraform
 
https://cloud.google.com/docs/terraform/best-practices-for-terraform
</details></div>

### Question 12
 
Google Cloud VPC 内の VM へのネットワーク トラフィックを調査する必要があります。VPC フローログが有効にされています。トラフィックの情報をフィルタすると、そのネットワーク トラフィックは利用不可になっています。問題を特定する必要があります。どうすればよいですか。

1. TCP プロトコルでフィルタするかどうかを判断する。
2. サンプルレートを下げるかどうかを判断する。
3. フィルタしているトラフィック量が非常に少ないかどうかを判断する。
4. VPC 外部の VM から VPC 内部の VM にトラフィックが流れているかどうかを判断する。
 
<details><div>
正解
フィルタしているトラフィック量が非常に少ないかどうかを判断する。

フィードバック
A: 不正解です。これは問題ではありません。TCP は VPC フローログでサポートされており、データのキャプチャで使用できます。

B: 不正解です。サンプルレートを下げるとキャプチャされるログは減少します。サンプルレート 1.0（100%）はすべてのエントリが保持されることを意味します

C: 正解です。トラフィック量が非常に少ないことが問題だと考えられます。ログはサンプリングされるので、少量のフローでは一部のパケットが失われる場合があります。

D: 不正解です。これは問題ではありません。VPC フローログでは外部サーバーから Google Cloud VPC 内の VM へのトラフィックをキャプチャできます。
 
https://cloud.google.com/vpc/docs/using-flow-logs#some_flows_are_missing
 
https://cloud.google.com/vpc/docs/using-flow-logs
</details></div>

### Question 13
 
あなたの同僚が夜間の待機中に、プロジェクトの Virtual Private Cloud（VPC）に侵入する不審なトラフィックの増加に気づきました。そこで同僚は、特定の IP アドレスから発信されるトラフィックを停止するように、Cloud Armor の構成を更新しました。この変更によりネットワーク トラフィックは減少しましたが、影響を受けたお客様からエスカレーションがあり、その結果、会社にペナルティが課されました。チームは Google が推奨する方法に沿って再発を防止したいと考えています。どうすればよいですか。

1. 同僚向けにインシデント レポートを作成し、シニア マネジメントにエスカレーションする。
2. この同僚によるすべての変更について、第 2 レベルの確認を求めるプロセスを作成する。
3. すべての変更が、変更の確認を行う追加の人員がいる日中に行われるよう求めるポリシーを作成する。
4. 主な技術的問題を特定し、チーム全体が利用できるように内容を文書化する。
 
<details><div>
フィードバック
A: 不正解です。これは推奨される方法に沿ったアプローチではありません。プロセスの改善よりも、個人の責任の追及に重点が置かれているからです。

B: 不正解です。これは推奨される方法に沿ったアプローチではありません。全員のプロセスではなく、特定の個人のプロセスの改善に重点が置かれているからです。

C: 不正解です。これは現実的なポリシーではありません。構成はいつでも変更できるようにする必要があるからです。ここでは、潜在的なサイバー攻撃は夜間に発生しました。チームが求めているのは、いつでも適用できるプロセスです。

D: 正解です。このソリューションは DevOps / SRE のアプローチを利用したもので、個人の責任を追及せずに、技術的問題を客観的に特定します。
 
https://sre.google/workbook/postmortem-culture/
 
https://cloud.google.com/blog/products/gcp/fearless-shared-postmortems-cre-life-lessons
</details></div>

### Question 14
 
会社のためにソフトウェア デリバリー パイプラインを作成するとします。開発チームによって提供されるアプリケーションの新機能を、Cloud Deploy を使用してテスト環境、ステージング環境、本番環境に順にデプロイする必要があります。対応するデプロイ ターゲットはすでに定義されています。あなたはリリースを作成してデリバリー パイプラインをインスタンス化しました。Google が推奨する方法に沿ってデプロイを実施する必要があります。どうすればよいですか。

1. 各ステージの前にデプロイを承認するように Binary Authorization を構成する。
2. Artifact Registry で各ステージ用のイメージを作成し、各イメージを対応するステージに適用する。
3. ステージングと本番の各ステージで初回リリースをプロモートする。
4. デリバリーの各ステージ向けに別々のデリバリー パイプラインを作成する。
<details><div>
正解
ステージングと本番の各ステージで初回リリースをプロモートする。

フィードバック
A: 不正解です。Binary Authorization はデプロイ前にセキュリティ チェックを行います。ただし、それはデプロイそのもののためのソリューションではありません。

B: 不正解です。デプロイごとに別のイメージを作成するアプローチはおすすめしません。

C: 正解です。リリースをインスタンス化すると、最初のターゲットにデプロイされます。その後、ステージングと本番環境に順にプロモートします。

D: 不正解です。このユースケースでは、Cloud Deploy で別々のデリバリー パイプラインを作成することはおすすめしません。デプロイを次のステージにプロモートするのがおすすめのアプローチです。
 
https://cloud.google.com/deploy/docs/deploy-app-run
 
https://cloud.google.com/deploy/docs/promote-release
</details></div>

### Question 15
 
組織では Google Cloud で毎日多くのビルドを実行しています。VM がパブリック IP アドレスを持たないようにし、データの引き出しからビルドマシンを保護する必要があります。Google が推奨する方法に沿って、カスタマイズ可能で簡単に管理できる、ビルドに関するソリューションを作成し、組織の需要に対応しようと考えています。どうすればよいですか。

1. VPC Service Controls を使用して Cloud Build でプライベート プールを実装する。
2. 要求されるプライバシーのために Cloud Build のデフォルト プールでビルドを実行、構成する。
3. Compute Engine VM を使用してカスタム VPC にビルド環境を作成し、Jenkins を使ってビルドを実行する。
4. Compute Engine Spot VM インスタンスを使用してカスタム VPC にビルド環境を作成し、Jenkins を使ってビルドを実行する。

<details><div>
正解
VPC Service Controls を使用して Cloud Build でプライベート プールを実装する。

フィードバック
A: 正解です。VPC Service Controls を利用してプライベート プールでビルドを実行すると、セキュリティが強化され、デフォルト プールでは実施できない複数のカスタマイズを行うことができます。

B: 不正解です。デフォルト プールでは、パブリック IP アドレスなどの VM 構成を制限するカスタマイズは実施できません。

C: 不正解です。このカスタム アプローチは多大な労力を必要とするため、Google Cloud で推奨されるアプローチではありません。

D: 不正解です。このカスタム アプローチは多大な労力を必要とするため、Google Cloud で推奨されるアプローチではありません。
 
https://cloud.google.com/build/docs/private-pools/private-pools-overview
 
https://cloud.google.com/build/docs/private-pools/using-vpc-service-controls
 
https://cloud.google.com/build/docs/private-pools/set-up-private-pool-to-use-in-vpc-network
</details></div>

### Question 16
 
あなたの会社では、9 月に大きな販売イベントを計画しています。販売イベントの期間中に運用をサポートする従業員グループを特定しました。Google が推奨する方法に沿って、それらの従業員に Google Cloud リソースへのアクセス権を 9 月にのみ付与するとします。どうすればよいですか。

1. 特定した従業員を含むグループを作成する。グループにリソースへのアクセス権を割り当て、Identity and Access Management（IAM）の条件として日時表現を 9 月に設定する。
2. 特定した従業員を含むグループを作成し、リソースへのアクセス権がある Identity and Access Management（IAM）のカスタムロールをグループに割り当てる。9 月末にカスタムロールを削除する。
3. 特定した従業員のマシンからリソースへのトラフィックを許可するファイアウォール ルールを追加する。9 月末にトラフィックを拒否するようにファイアウォール ルールを変更する。
4. リソースへのアクセス権がある Identity and Access Management（IAM）のカスタムロールを、特定した各従業員に割り当てる。9 月末にカスタムロールを削除するように Cloud Scheduler タスクを作成する。

<details><div>
フィードバック
A: 正解です。IAM の条件により、指定した期間中にのみ、必要な権限が自動的に割り当てられます。

B: 不正解です。必ず 9 月末にロールを削除する必要があるので、この方法はおすすめしません。また、権限が直ちに適用されますが、これは不要です。

C: 不正解です。ファイアウォール ルールを使用するとネットワーク トラフィックを許可できますが、リソースを操作できる IAM 権限がユーザーに割り当てられることにはなりません。

D: 不正解です。個々のユーザーにロールを割り当てることはおすすめしません。また、Cloud Scheduler を使用して後からロールを削除するのも推奨される方法ではありません。
 
https://cloud.google.com/iam/docs/conditions-overview
</details></div>

### Question 17
 
会社では、ヨーロッパのユーザーにサービスを提供するアプリケーションを実行しています。業界の規制によって、リソースのインスタンス化は特定のリージョンでのみ許可されています。Google Cloud 組織のすべてのプロジェクトでこの要件を満たす必要があります。どうすればよいですか。

1. ログベースのアラートを作成して、許可リストのリージョン外で作成されたリソースを特定し、非遵守のリソースを削除する。
2. Asset Inventory で毎時スキャンを実行して全リソースのカタログを作成し、許可リストのリージョン外のインスタンスを削除する。
3. 新しいインスタンスを作成する権限を持つ限定ユーザー グループを作成し、コンプライアンスを検証するプロセスを作成する。
4. 組織ポリシーを構成し、許可されるリージョンを「in: allowed_values」リストで指定する。

<details><div>
正解
組織ポリシーを構成し、許可されるリージョンを「in: allowed_values」リストで指定する。

フィードバック
A: 不正解です。このオプションではリソースが作成されてしまい、業界規制に違反します。

B: 不正解です。このオプションではリソースが作成されてしまい、業界規制に違反します。

C: 不正解です。このチームが誤ってまたは不正に、リソースを不適切なリージョンに作成する可能性があるため、信頼性に欠けます。

D: 正解です。組織ポリシー制約によって、許可されたリージョン外でのリソースの作成をプリエンプトします。
 
https://cloud.google.com/resource-manager/docs/organization-policy/defining-locations#gcloud
 
https://cloud.google.com/resource-manager/docs/organization-policy/overview
</details></div>

### Question 18
 
コンピューティング集約的なタスクを行うモジュールがアプリケーションに含まれています。開発チームは、さまざまなアルゴリズムでテストして、このモジュールを最適化したいと考えています。あなたはチームメンバーとしてステージング環境と本番環境の両方でアルゴリズムをテストし、各アルゴリズムのパフォーマンスに関する詳細なデータを収集するとします。どうすればよいですか。

1. プロファイリング ライブラリを使用してコードを計測する。Cloud Profiler でフレームグラフとしてデータを可視化する。
2. アルゴリズムのさまざまな部分でログ ステートメントを使用してコードを計測する。ログベースの通知を送信して、アルゴリズムの実行に関するデータを収集する。
3. アルゴリズムのさまざまな部分でログ ステートメントを使用してコードを計測する。同じ制御構造が複数回呼び出されたときに、ログ指標に基づく通知を送信する。
4. コードを計測して、リクエストとレスポンスのフローをキャプチャする。Cloud Trace でリクエストのレイテンシを確認する。

<details><div>
フィードバック
A: 正解です。Cloud Profiler のフレームグラフを使用すると、プログラム内のコールスタックを可視化できます。これによってボトルネックを特定し、コードとアルゴリズムの最適化に関するガイドとして活用できます。

B: 不正解です。ログ ステートメントはアルゴリズムのタイミングに影響します。この方法で収集したデータは可視化するには不便であり、ボトルネックに関するガイダンスを提供するには詳細が不十分です。

C: 不正解です。ログ ステートメントはアルゴリズムのタイミングに影響します。この方法で収集したデータは可視化するには不便であり、ボトルネックに関するガイダンスを提供するには詳細が不十分です。

D: 不正解です。Cloud Trace では、コードのベンチマークに関する十分な情報が提供されません。この方法は、複数回呼び出しが行われるアプリケーションの分散トレースにより適しています。
 
https://cloud.google.com/profiler/docs/concepts-profiling
 
https://cloud.google.com/profiler/docs/measure-app-performance
 
https://cloud.google.com/profiler/docs/concepts-flame
 
https://codelabs.developers.google.com/cloud-profiler-go#0
 
https://codelabs.developers.google.com/codelabs/otel-cloudtrace-go#0
</details></div>

### Question 19
 
コードは手動と Webhook によって、GitHub に保存され、Cloud Build でビルドされます。コードをビルドするには、機密情報にアクセスする必要があります。Google が推奨する方法に沿って、機密情報のセキュリティを確保したいと考えています。どうすればよいですか。

1. ビルドを毎回コマンドラインからトリガーし、必要な機密情報をパラメータとして指定する。
2. 機密情報のみを含む暗号化されたファイルを GitHub リポジトリに作成し、Cloud Build ファイルでその暗号化ファイルを参照する。
3. Secret Manager のエントリを作成し、Cloud Build ファイルに機密情報シークレットの URI を指定して、ビルドステップでパラメータとしてシークレットを参照する。
4. コードを GitHub に保持し、機密情報専用の新しいリポジトリを Cloud Source Repositories に作成して、Cloud Build ファイルで新しいリポジトリを参照する。

<details><div>
フィードバック
A: 不正解です。このソリューションは、ビルドが Webhook によってトリガーされる場合に機能しません。

B: 不正解です。原則として、機密情報、シークレット、認証情報は、ソース リポジトリに保存すべきではありません。GitHub リポジトリへのアクセス権を持つ他のユーザーが認証情報にアクセスする可能性があり、最小権限の原則に違反します。

C: 正解です。Secret Manager は Identity and Access Management（IAM）を使用して構成できるため、最小権限の原則に従っています。Cloud Build から Secret Manager を参照でき、パラメータ置換によってビルドステップにシークレットを含めることができます。

D: 不正解です。原則として、機密情報、シークレット、認証情報は、ソース リポジトリに保存すべきではありません。機密情報を別個のリポジトリに保存することも認められません。Cloud Source Repositories リポジトリへのアクセス権を持つ他のユーザーが機密情報にアクセスする可能性があり、最小権限の原則に違反します。
 
https://cloud.google.com/build/docs/securing-builds/use-secrets
 
https://cloud.google.com/build/docs/configuring-builds/substitute-variable-values
</details></div>

### Question 20
 
あなたの会社では、Compute Engine 仮想マシン（VM）にデプロイされたアプリケーションを使用してお客様にサービスを提供しています。サービスレベル契約（SLA）を設けて、月に 99% の可用性を提供しています。月の最初の 22 日間のテレメトリー データによると、処理したリクエスト数は 10,000,000 件、可用性は 99.28% となっています。開発チームはアプリケーションに追加した新機能をデプロイしたいと考えています。あなたはサイト信頼性エンジニアリング（SRE）手法に沿いつつ、デプロイ アプローチを決定するとします。どうすればよいですか。

1. Confidential VMs に直ちに新機能をデプロイする。
2. 新機能のデプロイを翌月に延期する。
3. SLA を 98.5% に変更し、新機能を直ちにデプロイするようお客様に依頼する。
4. SLO を変更し、新機能を直ちにデプロイするようお客様に依頼する。

<details><div>
フィードバック
A: 不正解です。Confidential VMs では、エンドユーザーのリクエストに対する高可用性は保証されません。

B: 正解です。エラー バジェットが非常に少なくなります。また、安定性と機能の更新のバランスを取る必要があります。

C: 不正解です。残りのエラー バジェットが少ない場合に SLA を変更することは、アプリケーションを配信するためのアプローチとしておすすめしません。

D: 不正解です。SLO は内部の尺度であり、お客様とのサービス契約を反映したものではありません。
</details></div>

# 3
## 1
### Q. 問題6: 未回答
Cloud Run にデプロイされたアプリケーションがあり、グローバル ユーザーベースがあります。ユーザーが最も近いリージョンにルーティングされ、レスポンシが低くなるようにするには、Cloud Run をどのように構成すればよいのでしょうか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. アプリケーションを任意の 1 つのリージョンにデプロイし、グローバル外部 HTTP(S) ロード バランサーの背後にあるグローバル エニーキャスト IP アドレスでアプリケーションを提供します。
グローバル エニーキャスト IP を使用しても、アプリケーションを 1 つのリージョンにデプロイすると、すべての要求がその 1 つのインスタンスにルーティングされ、遠く離れたリージョンのユーザーに遅延や輻輳が生じる可能性があります。
C. 各リージョンのリージョンの外部 HTTP(S) ロードバランサーを使用して、大陸ごとに 1 つのリージョンにアプリケーションをデプロイし、すべてのリージョンのロードバランサーに同じグローバル IP アドレスをアタッチします。
大陸ごとに 1 つのリージョンにデプロイすると待機時間が短縮されますが、複数のリージョン ロード バランサーを使用すると複雑で効率が低下する可能性があります。また、ユーザーを最も近いインスタンスにルーティングするための統一されたアプローチも提供されません。
D. アプリケーションを任意の 1 つのリージョンにデプロイし、すべての IP アドレスからのトラフィックを許可するようにフロントエンドで Google Cloud Armor を構成します。
Google Cloud Armor の許可ルールでは、トラフィックをグローバルに許可できますが、1 つのリージョンからすべてのユーザーにサービスを提供すると、選択したリージョンから遠く離れたユーザーのレイテンシが長くなります。Google Cloud Armor は、グローバル トラフィックのレスポンス タイムの最適化ではなく、主にセキュリティに重点を置いています。
正解：
B. アプリケーションを各リージョンにデプロイし、グローバル外部 HTTP(S) ロード バランサーの背後にあるグローバル エニーキャスト IP アドレスでアプリケーションを提供します。
アプリケーションを複数のリージョンにデプロイし、エニーキャスト IP アドレスを持つグローバル外部 HTTP(S) ロードバランサーを使用すると、アプリケーションが実行されている最も近いリージョンにリクエストをルーティングできます。このアプローチにより、世界中のユーザーに低遅延の応答が保証されます。
リンクス：
複数のリージョンからのトラフィックを処理する
コンテナランタイムコントラクト
</div></details>

### Q. 問題11: 回答
Cloud Run と Cloud Functions でクライアント アプリケーションを構築して実行している。クライアントでは、ログをログサービスにインポートできるように、すべてのログを 1 年間使用できる必要があります。必要なコード変更は最小限に抑える必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. Cloud Run のすべてのイメージと Cloud Functions のすべての関数を更新して、Cloud Logging とクライアントのロギング サービスの両方にログを送信します。ログの送信に必要なすべてのポートが VPC ファイアウォールで開いていることを確認します。
このアプローチでは、各アプリケーションと関数にデュアル ログ機能を実装するために、大幅なコード変更が必要です。
VPC ファイアウォールで開いているポートを管理してログ送信を有効にすると、複雑さが増し、セキュリティ上の懸念が生じる可能性があります。
保持要件を満たすことはできますが、かなりの運用オーバーヘッドが伴い、コードの変更を最小限に抑えるという目標から逸脱します。
B. Pub/Sub トピック、サブスクリプション、ログ シンクを作成します。すべてのログをトピックに送信するようにログ シンクを構成します。ログを取得するためのトピックへのアクセス権をクライアントに付与します。
Pub/Sub トピックとサブスクリプションをログ シンクで設定すると、アプリケーション コードを変更することなくログがキャプチャされます。
Pub/Sub はリアルタイムのログ ストリーミングには効率的ですが、本質的に長期保存や直接的な保持管理は提供されません。
クライアントは、Pub/Sub からログを積極的に取得し、独自のストレージと保持を管理する必要があるため、クライアント側で複雑さが生じる可能性があります。
C. ストレージ バケットと適切な VPC ファイアウォール ルールを作成します。Cloud Run のすべてのイメージと Cloud Functions のすべての関数を更新して、ストレージ バケット内のファイルにログを送信します。
これには、Cloud Storage バケットにログを送信するためにすべての画像と関数を更新することが含まれますが、これには大幅なコード変更が必要です。
ログ送信のファイアウォール規則を管理すると、セキュリティ上のリスクと追加の管理オーバーヘッドが発生する可能性があります。
このアプローチは、コードの変更を最小限に抑えるという目的から逸脱し、ログ管理の複雑さを増します。
正解：
D. ログ バケットとログ シンクを作成します。ログバケットの保持期間を 365 日に設定します。バケットにログを送信するようにログシンクを設定します。ログを取得するためのバケットへのアクセス権をクライアントに付与します。
このオプションでは、Cloud Logging を利用してログをキャプチャし、ログシンクを利用して Cloud Storage バケットに自動的に送信します。
バケットに 365 日間の保持ポリシーを設定すると、必要な期間ログが保存されます。
ログのキャプチャとエクスポートは、アプリケーション コード内ではなくインフラストラクチャ レベルで処理されるため、コードの変更が最小限に抑えられます。
ログ取得のためにバケットへのクライアントアクセスを提供することは、簡単で安全であり、運用上のオーバーヘッドを最小限に抑えるという要件に合致しています。
要約すると、オプション A と C は目的を達成できますが、大幅なコード変更が必要であり、運用が複雑になります。オプションBは、リアルタイムのログストリーミングソリューションを提供しますが、固有の長期ストレージと保持管理に欠けています。オプションDは、クラウドネイティブなログ管理のベストプラクティスと連携し、コードの変更を最小限に抑え、必要なログ保持を確保する、最も効率的で簡単なアプローチとして際立っています。
リンクス：
https://cloud.google.com/logging/docs/routing/overview#:~:text=URL%3A%20https%3A%2F%2Fcloud
</div></details>

### Q. 問題20: 未回答
ロードバランサーを使用せずにHTTPエンドポイントを提供するアプリケーションを監視する責任があります。HTTP応答のレイテンシーは、ポジティブなユーザーエクスペリエンスを確保する上で重要な役割を果たします。すべてのユーザーが経験する HTTP レイテンシに関する分析情報を取得し、この目的のために Cloud Monitoring を利用することを目指しています。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
オプションA: 積み上げ棒グラフは特定の指標を視覚化できますが、応答時間の範囲と分散に関する洞察を提供するため、遅延は分布を使用するとより効果的に表されます。
オプションB:累積メトリクスでは、グラフが増加し続けるため、個々のレイテンシーインスタンスの追跡には適していません。HTTP 応答時間の動作を正確に反映することはできません。
オプションD:METRIC_KIND_UNSPECIFIED の使用は、待機時間などの特定の測定には適していません。レイテンシーメトリクスを効果的に監視および分析するために必要な精度が不足しています。
正解：
オプションC:レイテンシーは通常、分布として測定され、過去の 99 パーセンタイルよりも遅いリクエスト数を特定するなど、さまざまなパーセンタイルを分析できます。このアプローチにより、レイテンシのパフォーマンスを包括的に把握できます。
リンクス：
https://cloud.google.com/monitoring/api/v3/kinds-and-types
https://sre.google/workbook/implementing-slos/
https://cloud.google.com/architecture/adopting-slos/
</div></details>

### Q. 問題25: 未回答
組織では、大量のデータを処理するフォールト トレラントなバッチ処理アプリケーションを運用し、並列処理のために数百の VM に計算を分散しています。
このデータ処理を大規模に実行するための最も費用対効果の高いソリューションは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. データ処理には、テナントのマシンのみを使用します。
単一テナントの VM は、専用の物理サーバーを提供しますが、Standard VM やスポット VM に比べてコストが高いため、大規模なバッチ処理にはコスト効率が良くありません。
C. 自動修復を有効にしたマネージド・インスタンス・グループを確立します。
自動修復機能を備えたマネージド インスタンス グループでは、VM の正常性は確保されますが、特に標準 VM が使用されている場合は、本質的にコスト効率の高いソリューションは提供されません。
D. アクセラレータ最適化 VM と自動スケーリングを使用してマネージド インスタンス グループを設定します。
マネージド インスタンス グループでの自動スケーリングでは、需要に基づいてリソースが動的に調整されますが、これらの種類の VM は通常より高価であり、ハードウェア アクセラレータを必要とする特定のワークロード用に設計されているため、アクセラレータ最適化 VM の使用はバッチ処理に最もコスト効率の高い選択肢ではない可能性があります。
正解：
A. データ処理にはスポット VM を使用します。
スポット VM は、フォールト トレラントなバッチ処理タスクのための経済的な選択肢です。これらは標準の VM よりも安価であり、フォールト トレラントな環境でよく見られる中断を処理できるワークロードに適しています。
リンクス：
スポット VM
スポット VM の作成と使用
</div></details>

### Q. 問題33: 未回答
現在、仮想マシン(VM)の使用率を Cloud Logs に保存しており、インタラクティブな VM 使用率ダッシュボードを作成する必要があります。このダッシュボードは、共有が簡単で、リアルタイムの更新を提供し、四半期ごとに集約された情報を表示する必要があります。このタスクには、Google Cloud Platform ソリューションを利用することをお勧めします。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. VM 使用率を Cloud Pub/Sub にエクスポートし、次に SIEM システムにエクスポートします。
ログを Cloud Pub/Sub にエクスポートする: リアルタイムのデータ ストリーミングに適していますが、複雑さが増します。
ダッシュボードにSIEMを使用する:堅牢なセキュリティとイベント管理を提供しますが、外部ツールの統合が必要です。ダッシュボードの作成だけを行うための最も単純なソリューションではありません。
C. BigQuery にエクスポートし、次に Google スプレッドシート for Dashboard にエクスポートします。
BigQuery へのエクスポート: データの保存と分析に効果的です。
Google スプレッドシートへの転送: 手動の手順が導入されます。静的なレポートには適していますが、リアルタイムのデータ視覚化には適していません。
D. Cloud Storage へのエクスポート、カスタム アプリのビルド:
クラウドストレージへのエクスポート:データストレージに適していますが、直接分析ツールは提供していません。
カスタム視覚化アプリの構築: 最大限の柔軟性を提供しますが、かなりの開発リソースが必要です。迅速なセットアップやソフトウェア開発機能のない人には理想的ではありません。
正解：
A. BigQuery へのエクスポート、データポータルでの作成、ダッシュボードの共有:
1.VM 使用率データを Cloud Logs から BigQuery にエクスポートします。
2.BigQuery データを使用して、Google データポータルでインタラクティブなダッシュボードを作成します。
3. ダッシュボードを関係者と共有して、リアルタイムの更新や四半期ごとの集計情報を簡単に取得できます。
この方法では、Google Cloud の強力な分析ツールと可視化ツールを効率的に活用し、外部システムや複雑な手動プロセスを必要とせずに、VM 使用率データを効率的に分析して表示できます。
リンクス：
サポートされている宛先へのログのルーティング
</div></details>

### Q. 問題37: 未回答
組織では、Google Cloud で多数のビルドを頻繁に実行しています。セキュリティを強化するには、仮想マシン (VM) にパブリック IP アドレスがなく、データ流出から保護されていることを確認する必要があります。スケーラブルでカスタマイズ可能で管理しやすいビルドのソリューションを開発するために Google が推奨するベスト プラクティスは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. Cloud Build でビルドをデフォルトのプールを使用して構成し、プライバシーを強化します。
Cloud Build でデフォルト プールを使用するのは簡単に思えるかもしれませんが、パブリック IP アドレスの制限など、VM 設定をカスタマイズする柔軟性に欠けています。このオプションでは、複雑な組織のニーズに必要なレベルのセキュリティとカスタマイズを提供するには不十分です。
C. カスタム VPC で Compute Engine VM を使用し、ビルド環境には Jenkins を使用します。
Compute Engine VM と Jenkins を使用してビルド環境を作成すると、カスタマイズが可能になりますが、作業と管理が大幅に必要になります。このアプローチは、主にビルドのスケーリングと管理の複雑さが増し、非効率になる可能性があるため、Google Cloud の推奨プラクティスに沿っていません。
D. カスタム VPC の Compute Engine スポット VM インスタンスをビルド環境に Jenkins で利用します。
オプション C と同様に、ビルド環境にスポット VM インスタンスと Jenkins を使用する方が、より手間のかかるアプローチです。この方法はコスト面でのメリットもありますが、Google Cloud では推奨されません。これにより、一貫したスケーリングとビルド プロセスの効率的な管理が課題になる可能性があります。
正解：
A. VPC サービス コントロールを使用して Cloud Build にプライベート プールを実装します。
Cloud Build にプライベートプールを実装し、VPC サービス制御と組み合わせることで、セキュリティとカスタマイズのオプションを強化できます。このアプローチにより、VM にパブリック IP アドレスが割り当てられなくなるだけでなく、スケーラビリティと管理の容易さも提供され、Google の推奨プラクティスに合致します。プライベート プールでは、既定のプールで見られる制限とは異なり、よりカスタマイズされた構成が可能です。
リンクス：
プライベートプールの概要
VPC Service Controls の使用
VPC ネットワークでプライベートプールを使用するための環境を設定する
</div></details>

### Q. 問題41: 回答
組織では最近、アプリケーション開発用のコンテナーベースのワークフローを実装しました。チームは、自動ビルド パイプラインを介して運用環境の Kubernetes クラスターに継続的にデプロイされる複数のアプリケーションを作成します。セキュリティ監査人は、開発者やオペレーターが自動テストを迂回し、適切な承認なしにコード変更を本番環境に持ち込む可能性について懸念を表明しています。
承認を強制するには、どのような手順を実行する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. プル要求の承認を必要とする保護されたブランチを使用してビルド システムを構成します。
プル要求の承認を必要とする保護されたブランチは良い習慣ですが、シナリオにとって重要なパイプラインの使用の適用は保証されません。
B. アドミッション・コントローラーを使用して、受信要求が承認されたソースから発信されていることを確認します。
Kubernetesのアドミッションコントローラーは、セキュリティ上の目的でAPIサーバーへのリクエストをインターセプトすることに重点を置いていますが、コードデプロイの承認プロセスを直接強制するものではありません。
C. Kubernetes のロールベースのアクセス制御 (RBAC) を活用して、承認されたユーザーのみにアクセスを制限します。
Kubernetes RBAC はクラスター内のアクセスを制御しますが、特にオペレーターがこれをバイパスできるため、運用環境にプッシュされた変更の承認プロセスは適用されません。
正解：
D. Kubernetes クラスター内でバイナリ承認を有効にし、ビルド パイプラインを構成証明者として構成します。
ビルド パイプラインをアテスターとして使用する Kubernetes のバイナリ承認により、承認および署名されたコードのみが運用環境にデプロイされます。承認を強制する必要性に効果的に対処し、未承認のコードが本番環境にプッシュされるのを防ぎます。
リンクス：
https://cloud.google.com/binary-authorization
</div></details>

### Q. 問題45: 未回答
小規模な会社で、Cloud Build の CI / CD パイプラインでオープンソースの Java パッケージを利用しているとします。セキュリティチームは、これらのパッケージの潜在的な脆弱性について懸念を表明しています。
本番システムの依存関係のセキュリティを確保するために、どのような費用対効果の高いソリューションを実装する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. 常に最新バージョンの GitHub パッケージを Cloud Build パイプラインにプルしてください。
最新バージョンのパッケージをプルしても、これらのバージョンには未発見のバグや脆弱性が含まれている可能性があるため、セキュリティは保証されません。
C. セキュリティ チームによる検証のために、パッケージを Cloud Source Repositories にプルします。
Cloud Source Repositories でパッケージを手動で検証することは、特に Google Cloud が Assured OSS を通じてキュレーションおよび事前検証済みのオープンソース パッケージを提供している場合、費用対効果が高くありません。
D. オープンソース パッケージをローカルにダウンロードし、Cloud Build でスキャンして、フラグが立てられたパッケージを削除します。
各ビルドですべてのパッケージをローカルにスキャンすると、リソースを大量に消費し、費用対効果が高くありません。さらに、スキャン中にフラグが立てられた重要なパッケージを削除すると、ビルド プロセスが中断される可能性があり、非現実的なアプローチになります。
正解：
B. Cloud Build パイプラインで Assured Open Source Software(Assured OSS)パッケージを使用します。
Google Cloud の安全なパイプラインに構築され、脆弱性を定期的にスキャンする Assured OSS パッケージを利用することで、信頼性と費用対効果の高いソリューションが実現します。これらのパッケージは徹底的なセキュリティチェックを受け、パイプラインに脆弱性を持ち込むリスクを軽減します。
リンクス：
リモートリポジトリを使用した Assured OSS パッケージのダウンロード
リポジトリへの直接アクセスを使用したJavaパッケージのダウンロード
ソフトウェアサプライチェーンを保護
</div></details>

### Q. 問題47: 未回答
チームは、データ バッチに対して計算負荷の高い処理を実行するサービスを開発しています。処理速度と効率は、マシンのCPU速度と数量によって異なります。これらのデータバッチにはさまざまなサイズがあり、複数のサードパーティソースからいつでも到着できます。目的は、コストを最小限に抑え、データ処理速度を最適化しながら、サードパーティの安全なデータアップロードを可能にすることです。
これを達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. スケーリング用の Compute Engine + Cloud Function 上の SFTP サーバー:
SFTPサーバーを提供することで、安全なデータアップロードが可能になりますが、サーバーの資格情報を管理する必要があり、より効率的なクラウドネイティブソリューションを活用しません。
Cloud Functions の関数を使用して Compute Engine の自動スケーリング グループをスケーリングすることは、変動するワークロードを効率的に処理するための優れた方法です。
必要なソフトウェアをインスタンスを事前にロードし、完了時に終了するように設定することで、コストを最適化できます。
B. Cloud Storage + GKE クラスタと 2 つのサービス:
Cloud Storage は、サードパーティが適切な IAM 権限でデータをアップロードするための安全でスケーラブルな方法を提供します。
GKE クラスタは計算負荷の高いタスクを効率的に処理できますが、処理とモニタリングの両方にサービスを維持すると、特にデータがない期間にサービスが十分に活用されていない場合、コストが高くなる可能性があります。
コストを節約するために処理サービスを停止することは有益ですが、新しいデータが到着したときに起動に遅延が生じます。
D. Cloud Storage + Cloud Monitoring で Cloud Functions の関数をトリガーします。
アップロードに Cloud Storage を使用すると、IAM で効率的かつ安全になります。
Cloud Functions の関数のトリガーとしての Cloud Monitoring は革新的なアプローチですが、Cloud Storage のトリガーほど直接的でも効率的でもない場合があります。
最大の CPU を使用するように Cloud Functions を設定しても、コールド スタートの遅延が発生する可能性があるため、実行時間が常に最小化されるとは限らず、大規模な処理効率が考慮されません。
正解：
C. Cloud Storage + Cloud Functions の Compute Engine を自動スケーリングするための関数:
これはオプション A と似ていますが、よりスケーラブルで管理しやすい SFTP サーバーの代わりに Cloud Storage を使用します。
Compute Engine グループをスケーリングする Cloud Functions の関数トリガーは、変動するワークロードに対応する費用対効果と応答性に優れたソリューションです。
インスタンスの後処理と終了にプリロードされたイメージを使用すると、コストが最小限に抑えられ、リソース使用量が最適化されます。
これらの点を考慮すると、オプションCはニーズに対して最も費用対効果が高く効率的である可能性があります。Cloud Storage のスケーラビリティとセキュリティ、Cloud Functions のイベントドリブンな応答性、Compute Engine の動的なスケーリングを組み合わせて、さまざまなワークロードを処理します。このセットアップでは、クラウドネイティブ機能を活用し、処理が不要な場合はスケールダウンし、事前に読み込まれたイメージを使用してセットアップ時間を短縮することで、コストを最小限に抑えます。
リンクス：
カスタム Cloud Monitoring メトリクスを使用したインスタンスグループの自動スケーリング
</div></details>

### Q. 問題50: 回答
企業は、本番環境でのバグ、システム停止、パフォーマンスの遅れなどの問題に直面しています。開発者は現在、新機能の開発やバグの修正にこの環境を利用しています。さらに、運用環境で構成の変更や実験を行うと、ユーザーが停止します。テスト担当者は、同じ環境で負荷テストも実行するため、システムの速度が低下することがよくあります。環境を再設計して、運用環境でのバグや停止の発生を減らし、テスト担当者に新機能の負荷テスト機能を提供する必要があります。
どのような行動を取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. 本番環境で自動テスト スクリプトを作成して、障害が発生したらすぐに検出します。
障害を早期に検出することは有益ですが、本番環境で直接自動テストを実施すると、ユーザーが直面する停止のリスクが高まり、環境管理の誤りという根本的な問題に対処できません。
B. サーバー容量の小さい開発環境を作成し、開発者とテスト担当者のみにアクセス権を付与します。
これは、別の開発スペースを作成することで問題に部分的に対処しますが、包括的なテスト、特に運用環境と同様の環境を必要とするロード テストには十分ではない可能性があります。
C. 運用環境をセキュリティで保護して、開発者が変更できないようにし、1 年に 1 回の制御された更新プログラムを設定します。
これは制限が厳しすぎて、現代の開発状況では実用的ではありません。これにより、市場の変化に対応し、バグを修正し、機能をタイムリーに更新する能力が大幅に制限されます。
正解：
D. コードを記述するための開発環境と、構成、実験、およびロード テスト用のテスト環境を作成します。
このアプローチでは、環境を分離し、運用環境の安定性を確保します。独立した開発環境により、開発者は本番環境に影響を与えることなくコーディングとデバッグを行うことができますが、専用のテスト環境により、本番環境の安定性を損なうことなく、負荷テストを含む徹底的なテストが可能になります。このセットアップにより、より信頼性が高く効率的な開発およびテストプロセスが促進されます。
</div></details>

## 2
### Q. 問題2: 回答
開発、品質保証 (QA)、および運用の 3 つの異なる環境を含むシステムを設計している最中です。これらの各環境は Terraform を使用してデプロイされ、それぞれに Google Kubernetes Engine(GKE)クラスタが確立されます。これらの GKE クラスタは、アプリケーション チームがそれぞれのアプリケーションをデプロイするためのプラットフォームとして機能します。Anthos Config Management は、各 GKE クラスタ内にインフラストラクチャ レベルのリソースをデプロイするために利用され、テンプレート化されます。インフラストラクチャ オペレーターやアプリケーション所有者を含むすべてのユーザーは、GitOps アプローチを採用します。
このセットアップに最も適した状態にするには、コードとしてのインフラストラクチャ (IaC) とアプリケーション コードの両方のソース管理リポジトリをどのように整理する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B.
異なるディレクトリを持つ共有クラウド・インフラストラクチャ(Terraform)リポジトリ:A と似ていますが、GKE インフラストラクチャを異なるリポジトリに分離し、異なる環境用のブランチを使用します。これにより、複雑さが増し、Anthos Config Management の管理効率が低下する可能性があります。
機能のブランチを持つ個別のアプリケーション(アプリのソースコード)リポジトリ:これはオプションAと同じで、アプリケーションコードを独立して管理できます。
C.
クラウド・インフラストラクチャ(Terraform)とアプリケーション・コードの両方の共有リポジトリ:このアプローチでは、インフラストラクチャとアプリケーション開発の異なる側面を同じリポジトリ内で管理する際に複雑になる可能性があります。
アプリケーションリポジトリ内の機能の異なるディレクトリ:GitOps では一般的ではなく、通常は機能開発に異なるブランチが使用されます。
D.
環境ごとに個別のクラウドインフラストラクチャ(Terraform)リポジトリ:これにより、Terraform構成が重複し、環境間での一般的な変更の管理が複雑になる可能性があります。
個別の GKE インフラストラクチャ(Anthos Config Management Kustomize マニフェスト)リポジトリ:Terraform と同様に、これらを異なるリポジトリに分離すると、構成の管理と同期が困難になる可能性があります。
機能のブランチを持つ個別のアプリケーション(アプリのソースコード)リポジトリ:オプションAおよびBと一致しているため、独立したアプリケーション開発と機能の分岐が可能です。
正解：
ある。
クラウド・インフラストラクチャ(Terraform)リポジトリは、環境ごとに異なるディレクトリで共有されます。この構造は、異なるディレクトリが異なる環境を表すTerraform構成を管理する場合に論理的です。
GKE Infrastructure(Anthos Config Management Kustomize マニフェスト)リポジトリは、環境ごとに異なるオーバーレイ ディレクトリと共有されます。Kustomize と Anthos Config Management を使用するためのベスト プラクティスに準拠し、環境をディレクトリ別に表します。
アプリケーション (アプリのソース コード) リポジトリは、機能ごとに異なるブランチで区切られています。このセットアップにより、アプリケーション チームは、機能開発用のブランチを使用して、コードを個別に管理できます。
このアプローチは、さまざまな環境やアプリケーションのリポジトリを明確かつ効率的に編成し、GitOps の方法論とうまく連携させます。
リンクス：
ブランチの代わりにフォルダーを使用する
リポジトリのアーキテクチャ
</div></details>

### Q. 問題9: 未回答
Google Cloud VPC 内の VM へのネットワーク トラフィックを調査しており、VPC フローログを有効にしています。ただし、ログをフィルタリングしても、探している特定のネットワークトラフィック情報は表示されません。
問題を特定するために何をする必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. TCPプロトコルでフィルタリングしているかどうかを確認します。
VPC フローログは TCP プロトコルをサポートしており、TCP を使用するトラフィックはログにキャプチャする必要があります。この問題は、フィルタリングされているプロトコルの種類とは関係がない可能性があります。
C. [VPC Flow Logs] 設定でサンプルレートを下げることを検討してください。
VPC フローログのサンプルレートを下げると、キャプチャするログエントリは増えるどころか少なくなります。サンプルレートが高いほど、特に少量のトラフィックの場合、すべての関連データをキャプチャできる可能性が高くなります。
D. トラフィックが VPC 外の VM から VPC 内の VM に発信されているかどうかを調査します。
VPC フローログは、外部ソースから Google Cloud VPC 内の VM へのトラフィックをキャプチャできます。トラフィックの送信元は、VPC の外部か内部かにかかわらず、ログデータの可用性に影響を与えてはなりません。
正解：
B.フィルタリングしているトラフィックの量が非常に少ないかどうかを確認します。
VPC フローログはサンプリングされるため、すべてのパケットがログに記録されるわけではありません。トラフィック量が非常に少ない場合、一部のパケットがキャプチャされず、ログで使用できない可能性があります。これは、特定のトラフィックデータが欠落している理由を説明できる可能性があります。
リンクス：
https://cloud.google.com/vpc/docs/using-flow-logs#some_flows_are_missing
https://cloud.google.com/vpc/docs/using-flow-logs
</div></details>

### Q. 問題13: 回答
SRE のプラクティスと原則を順守する組織のメンバーとして、開発チームから新しいサービスの管理を引き受けます。運用準備レビュー (PRR) の結果、現在の状態ではサービスがサービス レベル目標 (SLO) を達成できないことがわかりました。目標は、サービスが運用環境で SLO を確実に達成することです。
次に何をすべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. SLO の目標をサービスで達成できるように調整して、運用環境に導入できるようにします。
このアプローチは誤解を招く可能性があります。準備ができていないサービスで SLO を調整して達成しやすくすると、ユーザーが期待する品質と信頼性が損なわれる可能性があります。SLO は、サービスの現在の機能だけでなく、ユーザーのニーズと期待を反映する必要があります。
B. 開発チームに、サービスの運用サポートを提供する必要があることを通知します。
開発チームと SRE チーム間のコラボレーションは重要ですが、特定された欠点に対処するための具体的なガイダンスや計画なしに、単に開発者にサービスを渡すだけでは、必要な改善につながらない可能性があります。運用環境に対するサービスの準備を強化するために、協力することが重要です。
D. SLO なしでサービスを運用環境に導入し、運用データを収集したら構築します。
SLO はサービスの信頼性とパフォーマンスを測定するためのベンチマークとなるため、明確な SLO なしでサービスをデプロイするとリスクが伴う可能性があります。SLO なしで開始すると、許容できるパフォーマンスの構成要素を明確に理解できないため、サービスの成功を測定し、改善が必要な領域を特定することが困難になります。
正解：
C. 引き渡し前に完了すべきサービスの信頼性向上の推奨項目を特定する。
このオプションは、サービスを運用する準備が整っており、責任を引き継ぐ前に SLO を満たせるようにするという SRE のプラクティスに沿ったものです。これには、開発チームと協力してサービスの信頼性を高めることが含まれます。
リンクス：
改善とリファクタリング
</div></details>

### Q. 問題19: 回答
カスタム Debian イメージを使用する仮想マシン (VM) で実行されているアプリケーションがあります。このイメージには Cloud Logging エージェントが含まれており、VM のスコープは cloud-platform です。アプリケーションは syslog を介して情報を記録しています。ただし、Google Cloud Platform Console のログ ビューアの [すべてのログ] プルダウン リストに syslog が表示されないという問題が発生しました。
この問題に対処するための最初のステップは何でしょうか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. ログビューアでエージェントのテストログエントリを探します。
これにより、エージェントがアクティブにログを送信しているかどうかが確認されます。ただし、ログが表示されない場合は、エージェントが最初に実行されているかどうかを確認するのがより基本的です。
B. 最新バージョンのクラウドエージェントをインストールします。
最新のエージェントを使用することは重要ですが、特に既にインストールされている場合は、エージェントが動作していることを確認することは二次的です。
C. VM サービス アカウントのアクセス スコープに monitoring.write スコープが含まれていることを確認します。
クラウドプラットフォームのスコープはログをカバーする必要がありますが、特に問題がエージェント自体にある可能性があるため、ログが表示されない場合の検証は最初のステップではありません。
正解：
D. VM に SSH 接続し、VM で次のコマンドを実行します。grep fluentdです。
このアプローチは、Google Cloud の Cloud Logging エージェントのトラブルシューティング ガイドで推奨される最初の手順と一致しています。エージェントは fluentd に基づいているため、ログを収集して Cloud Logging に転送するには、エージェントが実行されていることを確認することが重要です。コミュニティのインサイトでは、エージェントの動作ステータスを確認することが、ログの問題のトラブルシューティングの最初のステップである必要があることが強調されています。
リンクス：
https://cloud.google.com/logging/docs/agent/logging/troubleshooting#checklist
インスタンスへのサービスアカウントのアタッチ
</div></details>

### Q. 問題24: 未回答
グローバルな組織で働いており、99%の可用性目標でサービスを管理していますが、エンジニアリングリソースは限られています。現在の暦月には、サービスの可用性が 99.5% に達していることを確認しました。目的は、サービスが定義された可用性の目標を一貫して満たし、新機能のリリースなどのビジネスの変化に適応できるようにすると同時に、運用コストを最小限に抑えながら技術的負債を削減することです。Google が推奨する方法に従うことを目標としている。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. サービスにコンピューティング リソースを追加することで、サービスに N+1 の冗長性を追加します。
冗長性を追加すると可用性が向上しますが、特にサービスが既に可用性の目標を満たしている場合は、最も費用対効果の高いアプローチではない可能性があります。不必要なリソース使用率とコストの増加につながる可能性があります。
C. サービス レベルの可用性のエラー バジェットを定義し、残りのエラー バジェットを最小限に抑えます。
エラーバジェットを定義することは、イノベーションのペースと信頼性のバランスを取るための良い方法ですが、信頼性の低いリスクを管理することが大切です。このアプローチは、技術的負債や運用コストを削減するという目標に直接対処するものではありません。
D. 対応可能なエンジニアを機能バックログに割り当て、サービスが可用性目標内にとどまるようにします。
運用効率を考慮せずに機能開発のみに集中すると、技術的負債と運用上の課題が増加する可能性があります。このアプローチでは、サービスの保守と信頼性の重要な側面が無視される可能性があります。
正解：
B. 反復的なタスクを自動化することで、労力を特定、測定、排除します。
労力の削減:労苦とは、サービスにあまり価値を付加しないが、その運用に必要な反復的で平凡なタスクを指します。これらのタスクを自動化することで、エンジニアリングチームの作業負荷を大幅に軽減し、より影響力のあるアクティビティに集中できるようになります。
可用性の目標達成における一貫性:手間が省けることで、チームは、監視、パフォーマンスチューニング、ベストプラクティスの実装など、サービスの可用性を確保するためのプロアクティブな対策により多くの時間を費やすことができます。
ビジネスの変化への適応:労力が減ったことで、チームは新機能のリリースなど、ビジネスの変化に適応するためにより多くのリソースを割り当てることができます。自動化は、新しい変更が導入されても、安定した運用環境を維持するのに役立ちます。
運用コストの最小化: 反復的なタスクを自動化することで、運用コストの削減にもつながります。手動による介入の必要性が最小限に抑えられるため、人為的ミスのリスクとそれに関連するコストが削減されます。
要約すると、反復的なタスクの自動化に重点を置くことで、現在のレベルのサービス可用性を維持できるだけでなく、運用コストを抑えながら、ビジネスの変化への適応や技術的負債の削減など、より戦略的なタスクに貴重なエンジニアリングリソースを解放することができます。
リンクス：
https://sre.google
</div></details>

### Q. 問題25: 未回答
会社では、すべてのチーム メンバーに、一般的な統合開発環境 (IDE) を含む、一貫性のあるテンプレート化された開発環境を使用する必要があります。お客様は、これらの開発環境のセキュリティパッチとアップデートを維持する役割を担っています。さらに、各チームのすべてのデベロッパーが一貫した環境を使用できるように、信頼できる Google 推奨の方法を見つける必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. すべてのセキュリティ パッチを適用した「ゴールデン」マシンの Compute Engine スナップショットを毎日作成し、デベロッパーが自分のマシンを更新できるようにします。
スナップショットを使用してマシンを手動で更新する開発者に依存すると、すべての開発者が一様にプロセスに従うわけではないため、不整合が生じる可能性があります。
B. 更新スクリプトを使用してすべてのソフトウェア更新プログラムのチェックリストを作成し、開発者が自分のマシンを更新できるようにします。
チェックリストのアプローチは、更新を個々の開発者に大きく依存しているため、チーム全体で実装が多様で一貫性がなくなる可能性があります。
C. すべての最新の依存関係を持つイメージを作成し、開発者が使用できるようにラップトップにイメージをインストールします。
各開発者のラップトップで更新を直接管理することは、特に重要なパッチの場合、すべてのマシンが一貫して更新されるようにするには信頼できません。
正解：
D. 各チームに固有の Cloud Workstations 構成を作成します。
Cloud Workstations の構成は、一貫性のある開発環境を構築するためのテンプレートベースのアプローチを提供します。これらの構成では、マシン・タイプ、ディスク・サイズ、ツール、およびプリインストール・ライブラリーを指定できます。マシンタイプやコンテナイメージの更新など、ワークステーション構成に変更が加えられると、これらの変更は次回の起動時に各開発者のワークステーションに自動的に反映されます。これにより、統一性が確保され、開発環境の管理が簡素化されます。
リンクス：
https://cloud.google.com/workstations/docs/overview
https://cloud.google.com/workstations/docs/create-configuration
https://www.youtube.com/watch?v=E1cblFqb8nk
</div></details>

### Q. 問題32: 未回答
セキュリティチームは、システム侵害が疑われる場合にテストするために、本番インフラストラクチャのレプリカを作成する必要があります。
レプリカを迅速に配信するための Google 推奨のプラクティスに合わせるには、どのようなアプローチを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. Cloud Asset Inventory を利用して本番リソースを一覧表示し、Google Cloud コンソールを使用して手動で再作成します。
コンソールから技術環境全体を毎回手動で作り直すのは非効率的であり、Googleは推奨していません。この方法では、一貫性のある環境を維持するために不可欠なスケーラビリティと再現性が欠けています。
B. Security Command Center でスキャンを実行し、本番環境のリソースを一覧表示し、gcloud CLI を使用して手動で再作成します。
Security Command Center は貴重な分析情報を提供しますが、レプリケーションに必要な詳細なリソース構成は提供しません。また、gcloud CLI を使用した手動による再作成は時間がかかり、エラーが発生しやすいため、高速で信頼性の高い環境レプリケーションには適していません。
D. bash シェル スクリプトを記述して運用環境を複製し、必要に応じてスクリプトを実行します。
環境のレプリケーションに bash スクリプトを使用することは可能ですが、最も効率的で信頼性の高い方法ではありません。スクリプトは複雑で保守が困難になる可能性があり、状態管理やモジュール性など、Terraform などの IaC ツールに固有の利点が欠けています。
正解：
C. Terraformスクリプトを開発して本番環境を複製し、必要に応じてスクリプトを実行します。
コードとしてのインフラストラクチャ (IaC) は、技術環境を管理および複製するための推奨されるアプローチです。Terraformは、IaCツールとして、インフラストラクチャの自動化された反復可能な作成を可能にし、一貫性のあるエラーのない方法で環境を迅速に複製するための理想的なソリューションになります。
リンクス：
再現性のあるスケールが必要ですか?Infrastructure as Code を GCP に導入する
Terraformを使用するためのベスト・プラクティス
</div></details>

### Q. 問題37: 回答
アプリケーションのデプロイにSpinnakerを利用し、パイプライン内にカナリアデプロイメントステージを含めました。アプリケーションは、起動時にオブジェクトを読み込むメモリ内キャッシュに依存しています。
カナリアバージョンと本番バージョンの比較を自動化するには、カナリア分析をどのように設定する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. Canary を以前の製品バージョンの新しいデプロイと比較します。
Canaryを古いバージョンと比較し、本番環境の現在の状態を反映していないため、理想的ではありません。
C. Canary を現在の製品バージョンの既存のデプロイと比較します。
キャッシュのウォームアップ時間などの変数が発生し、比較の精度に影響を与える可能性があります。
D. カナリアを、以前の製品バージョンのスライディング ウィンドウの平均パフォーマンスと比較します。
より広範な比較を提供しますが、現在の運用環境のニュアンスを正確に反映していない可能性があり、分析を歪める可能性があります。
正解：
A. Canary を現在の製品バージョンの新しいデプロイと比較します。
カナリア テストでは、次の図に示すように、変更を部分的にロールアウトし、ベースライン デプロイに対してそのパフォーマンスを評価します。
この戦略は、カナリア テストのガイドラインに沿っており、カナリアは現在の運用環境を反映したベースライン デプロイと比較されます。このアプローチでは、バージョンと構成を制御し、カナリアに導入された変更のみに焦点を当てることで、その影響をより正確に分析できます。
リンクス：
自動デプロイのセットアップ
Canary を本番環境ではなくベースラインと比較する
カナリア テスト パターン
</div></details>

### Q. 問題40: 未回答
会社のソフトウェア配信パイプラインを作成しています。開発チームが提供する新しいアプリケーション機能は、テスト、ステージング、本番環境で Cloud Deploy を使用してデプロイする必要があります。対応するデプロイメント・ターゲットは既に定義されています。リリースを作成して配信パイプラインをインスタンス化しました。デプロイは、Google が推奨する方法に従って実行する必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. アーティファクト・レジストリで各ステージのイメージを作成し、対応するステージで各イメージを適用します。
デプロイごとに個別のイメージを作成することは、推奨される方法ではありません。
B. 各ステージの前に展開を承認するようにバイナリ承認を構成します。
バイナリ承認は、デプロイ前にセキュリティ チェックを提供します。ただし、デプロイ自体のソリューションではありません。
C. 配信ステージごとに独立した配信パイプラインを作成します。
このユースケースでは、Cloud Deploy で個別の配信パイプラインを作成することはおすすめしません。推奨されるアプローチは、デプロイを次のステージに昇格させることです。
正解：
D. ステージング段階と運用段階を通じて初期リリースをプロモートします。
リリースをインスタンス化すると、最初のターゲットにデプロイされます。ステージングに移行してから、再び本番環境に移行するようにプロモートできます。
リンクス：
https://cloud.google.com/deploy/docs/deploy-app-run
https://cloud.google.com/deploy/docs/promote-release
</div></details>

### Q. 問題42: 未回答
コードは GitHub に保存され、Cloud Build で手動と Webhook の両方でビルドされます。コードをビルドするには、機密情報にアクセスする必要があります。Google が推奨する方法に従って、機密情報のセキュリティを確保したい。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. 毎回コマンド ラインからビルドをトリガーし、必要な機密情報をパラメーターとして指定します。
この方法は、手動による介入が必要なため、Webhook によってトリガーされる自動ビルドには実行できません。さらに、コマンドラインパラメータを介して機密情報を公開しますが、これは安全ではありません。
B. GitHub リポジトリに機密情報のみを含む暗号化ファイルを作成し、Cloud Build ファイルで暗号化されたファイルを参照します。
機密情報を、たとえ暗号化された形式であっても、ソースコードリポジトリに保存することは、セキュリティのベストプラクティスに違反します。GitHub リポジトリにアクセスできる他のユーザーは、これらの暗号化された資格情報にアクセスする可能性があり、最小特権の原則に違反します。
D. コードを Github に保持します。機密情報専用の新しいリポジトリを Cloud Source リポジトリに作成し、Cloud Build ファイルで新しいリポジトリを参照します。
機密情報をソース リポジトリに格納することは、別のリポジトリに分離されている場合でも、お勧めしません。このクラウド ソース リポジトリ リポジトリにアクセスすると、機密情報への不正アクセスが発生し、最小権限の原則に違反する可能性があります。
正解：
C. Secret Manager でエントリを作成し、Cloud Build ファイルで機密シークレットの URI を指定して、ビルド ステップでシークレットをパラメータとして参照します。
Secret Manager の使用は、機密情報を安全に保存することで、ベスト プラクティスと一致します。Cloud Build はこれらのシークレットを安全に参照でき、IAM を使用すると、最小権限の原則に従うことができます。このアプローチにより、手動ビルドと Webhook トリガー ビルドの両方にシークレットを安全かつ便利に含めることができます。
リンクス：
シークレットマネージャーのシークレットを使用する
変数値の置換
</div></details>

### Q. 問題44: 未回答
会社は、ヨーロッパのユーザーにサービスを提供するアプリケーションを実行しています。業界の規制では、特定のリージョンでのみリソースをインスタンス化する必要があります。Google Cloud 組織内のすべてのプロジェクトがこの要件に従っていることを確認する必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. ログベースのアラートを作成して、リージョンの許可リスト外で作成されたリソースを特定します。非準拠のリソースをすべて削除します。
このアプローチは事後対応型であり、アラートがトリガーされる前に未承認のリージョンにリソースを作成できるようにすることで、規制に違反します。重要なのは、非準拠のリソースの作成を事前に防止することです。
B. 1 時間ごとに資産インベントリ スキャンを実行して、すべてのリソースをカタログ化します。リージョンの許可リストに含まれていないインスタンスをすべて削除します。
オプション A と同様に、この方法は事後対応型であり、規制要件に違反する非準拠のリソースの作成後にのみ識別されます。作成後の検出ではなく、予防に重点を置く必要があります。
C. 新しいインスタンスを作成する権限を持つ限定されたユーザーグループを作成します。コンプライアンスを検証するプロセスを作成します。
制御されたユーザー グループのみに依存しても、人為的エラーや意図的なアクションによって承認されていないリージョンにリソースが作成される可能性があるため、コンプライアンスは保証されません。この方法では、必要な自動適用メカニズムが不足しています。
正解：
D. "in: allowed_values" リスト内の許可されたリージョンを使用して組織ポリシーを構成します。
許可されたリージョンの一覧を含む組織ポリシーを構成すると、これらのリージョンの外部にリソースが作成されるのを効果的に防止できます。このプロアクティブなアプローチは、リソース作成の時点でコンプライアンスが確実に実施され、偶発的または意図的なコンプライアンス違反の可能性を排除することで、規制要件と一致します。
リンクス：
リソースの場所の制限
組織ポリシー サービスの概要
</div></details>

### Q. 問題48: 未回答
会社では、Compute Engine 仮想マシン(VM)にデプロイされたアプリケーションを使用して、顧客にサービスを提供しています。毎月 99% の可用性を提供するサービス レベル アグリーメント (SLA) があります。月の最初の 22 日間のテレメトリ データによると、99.28% の可用性で 10,000,000 件のリクエストを処理しました。開発チームは、アプリケーションに新しい機能を追加し、それらをデプロイしたいと考えています。サイト信頼性エンジニアリング (SRE) のプラクティスに従いながら、展開アプローチを決定する必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. 新機能をすぐにコンフィデンシャル VM にデプロイします。
コンフィデンシャル VM へのデプロイは、セキュリティの側面に重点を置き、エンド ユーザー要求の高可用性の確保には直接関係しません。このオプションでは、エラーバジェットの現在のステータスと、新機能のデプロイが可用性に及ぼす潜在的な影響は考慮されません。
C. SLO を変更し、新しい機能をすぐにデプロイするよう顧客に依頼します。
SLO は、SLA の達成を支援するために設定された内部目標であり、顧客と直接交渉されるものではありません。SLO を変更しても、SLA に基づく契約上の義務は変更されず、現在の可用性を危険にさらすことは正当化されません。
D. SLA を 98.5% に変更し、新機能をすぐにデプロイするように顧客に依頼します。
SLA の変更、特により低い標準への変更を提案することは、エラー バジェットが厳しい状況に対応するための一般的または推奨されるアプローチではありません。顧客の信頼と信頼性の認識に悪影響を与える可能性があります。焦点は、アプリケーションの更新を責任を持って管理しながら、合意されたSLAを維持することです。
正解：
B. 新機能の展開を翌月まで延期します。
既存の可用性が 99.28% で、残りのエラー バジェットが少ない場合、新機能を展開すると SLA に違反するリスクがあります。SRE のプラクティスでは、特にエラー バジェットが低い場合は、新機能の導入と安定性の維持のバランスを取ることが重要です。デプロイを延期すると、可用性がさらに低下するリスクが最小限に抑えられ、SLA の遵守に役立ちます。
リンクス：
エラー予算ポリシーの例
リスクの受け入れ
</div></details>

## 3
### Q.  問題3: 未回答
Compute Engine インスタンスでカスタム アプリケーションを管理すると、使用率が最大 90% まで急上昇することがありますが、通常は使用率は約 50% に戻ります。
現在、サーバーの使用率が 80% を超えた場合のアラートがありますが、受信する通知が多すぎます。
少なくとも 5 分間、一貫して高い使用率のみを通知するようにアラートを変更するにはどうすればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. 5 分間、使用率が 80% を超えることをフィルタリングする Cloud Run アプリケーションへの直接通知。
アラート分析用のカスタム Cloud Run アプリケーションを作成することは、この要件に対して不必要に複雑でリソースを大量に消費するソリューションです。
B. ログベースのメトリックからアラートを構成し、5 分間のローリング ウィンドウとメトリックの不在条件を設定します。
メトリックの不在に基づくアラートは、使用率が高いという問題には対処しません。むしろ、データがない期間や使用率が低い期間を示します。
D. 5 分のローリング ウィンドウと平均しきい値が 90% のログベースのメトリックからアラートを作成します。
しきい値を 90% に設定すると、通知の頻度は減りますが、80% から 90% の間で高い使用率が持続しているインスタンスは失われます。
正解：
C. 5 分間のローリング ウィンドウと平均しきい値が 80% のログベースのメトリックからアラートを設定します。
5 分間のローリング ウィンドウと平均しきい値を 80% に設定してアラートを構成すると、その期間にわたって使用率が一貫して高い場合にのみ通知されます。このアプローチは、頻繁で短命なスパイクの問題に効果的に対処し、持続的な高い使用率に焦点を当てています。
リンクス：
ログベースのメトリクスの概要
アラートポリシーの例の概要
Cloud Monitoring に関するアラートの作成 |ビデオ
</div></details>

### Q.  問題4: 未回答
Compute Engine でアプリケーション サーバーのグループを管理しており、デベロッパーがデバッグのためにアプリケーションログに簡単にアクセスできるように、構成の労力を最小限に抑えた安全な方法を探しています。
このソリューションをGoogle Cloud Platform(GCP)に実装するには、どのようなアプローチを使用しますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. Cloud Logging Agent と Logs Private Viewer ロール:このオプションにはログ エージェントのデプロイも含まれますが、"ログ プライベート ビューアー" ロールはより制限が厳しく、機密データを含むログへのアクセスを必要とするシナリオに適しています。
C. Monitoring Viewer ロールを持つ Cloud Monitoring Agent:このセットアップは、ログではなくメトリックに重点を置いているため、デバッグ目的で詳細なアプリケーション ログにアクセスする必要がある開発者にはあまり適していません。
D. Cloud Storage にログをアップロードするための gsutil: この方法では、追加のスクリプトと手動設定が必要です。Google Cloud のオペレーション スイート(Stackdriver)を使用する場合に比べて効率が悪く、効果的なデバッグに不可欠なリアルタイムのログ アクセスも提供されません。
正解：
ある。
Cloud Logging エージェントをアプリケーション サーバーにデプロイします。
開発者に、ログにアクセスして表示するためのIAMログ閲覧者ロールを付与します。
この方法では、ログを一元管理するためのログエージェントのデプロイと適切な IAM ロールを組み合わせて、ログへの安全なロールベースのアクセスを確保します。効率的で、セキュリティを維持しながら構成の労力を最小限に抑えます。
リンクス：
ログエクスプローラーを使用してログを表示するView logs by using the Logs Explorer
IAMによるアクセス制御
</div></details>

### Q.  問題14: 未回答
アプリケーションには、計算負荷の高いタスクを担当するモジュールが含まれています。開発チームは、さまざまなアルゴリズムをテストすることで、このモジュールを最適化することを目指しています。ステージング環境と本番環境の両方で各アルゴリズムのパフォーマンスを評価し、包括的なパフォーマンスデータを取得するには、どうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. コードをインストルメント化して、要求と応答のフローをキャプチャします。Cloud Trace でリクエストのレイテンシを確認します。
Cloud Trace は主に分散トレースに重点を置いており、複数のサービス間呼び出しがあるアプリケーションでのやり取りをモニタリングするのに適しています。アルゴリズムの最適化に必要な詳細なパフォーマンス指標を提供しないため、特定のコードセグメントやアルゴリズムの詳細なベンチマークには効果的ではありません。
C. アルゴリズムのさまざまな部分でログステートメントを使用してコードをインストルメント化します。ログベースの通知を送信して、アルゴリズムの実行に関するデータを収集します。
ログステートメントは実行フローに関する洞察を提供しますが、アルゴリズムのタイミングとパフォーマンスを変更し、結果に偏りが生じる可能性があります。さらに、ログステートメントによって収集されるデータは、通常、それほど詳細ではなく、視覚化の利便性が低いため、コード内の特定のパフォーマンスの問題やボトルネックを特定するのに効果的ではありません。
D. アルゴリズムのさまざまな部分でログステートメントを使用してコードをインストルメント化します。同じ制御構造が複数回呼び出されたときに、ログメトリックに基づいて通知を送信します。
オプション C と同様に、ログ ステートメントを使用すると、アルゴリズムの実際のパフォーマンスが妨げられる可能性があり、詳細または効率的な視覚化の手段は提供されません。ログメトリクスに基づいて通知を設定すると、繰り返しの呼び出しを特定するのに役立つ場合がありますが、効果的なアルゴリズムの最適化に必要な包括的なパフォーマンス分析は提供されません。
正解：
A. プロファイリングライブラリを使用してコードをインストルメント化します。Cloud Profiler でデータをフレームグラフとして視覚化します。
Cloud Profiler と統合されたプロファイリング ライブラリを利用すると、アプリケーションのパフォーマンスを詳細に把握できます。フレーム グラフは、呼び出し履歴を視覚的に表現し、パフォーマンスのボトルネックを特定して対処するのに役立ちます。この方法は、非効率なコードセグメントを視覚的にピンポイントで特定することにより、アルゴリズムを分析および最適化するのに効果的です。
リンクス：
プロファイリングの概念
アプリのパフォーマンスを測定する
Goでアプリのパフォーマンスを向上させるためのインストゥルメント(パート1:トレース)
Go でアプリのパフォーマンスを向上させるためのインストゥルメント (パート 2:プロファイラー)
</div></details>

### Q.  問題18: 未回答
会社では、Pod の削除や再スケジュールの影響を受けやすいレガシー データベースを Google Kubernetes Engine(GKE)で運用しています。データベースのオペレーションが中断されないようにするには、適切な GKE メンテナンス戦略を選択する必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. GKE メンテナンス チャネルを「Stable」に設定します。
GKE メンテナンス チャンネルを「Stable」に設定しても、更新は妨げられません。安定版のリリーススケジュールに基づいてスケジュールするだけです。これにより、更新中にPodが削除される可能性があります。
B. max-surge-upgrade を 0 に設定してノード プールのアップグレード戦略を構成します。
max-surge-upgrade が 0 に設定されたノード プールのアップグレード戦略では、メンテナンス更新は制限されません。メンテナンスは引き続き行われ、Podのエビクションにつながる可能性があります。
C. 「PodDisruptionBudget」オブジェクトを作成し、maxUnavailableを100%に指定します。
maxUnavailableを100%に設定した「PodDisruptionBudget」は、メンテナンスのアップグレードを妨げません。これは、自発的な中断中に利用できないPodの数を指定するだけで、メンテナンス中に立ち退きになる可能性があります。
正解：
D. 「マイナーまたはノードのアップグレードなし」のスコープでメンテナンス除外ウィンドウを設定します。
メンテナンス除外ウィンドウを "マイナーまたはノードのアップグレードなし" で構成すると、ノード プールの中断が効果的に防止されます。この設定により、ノードのアップグレードによるワークロードの削除や再スケジュールが回避され、GKE のレガシー データベースの安定性が確保されます。
リンクス：
メンテナンス期間と除外
リリース チャネルについて
GKE アップグレードのベスト プラクティス |ビデオ
クラスターのアップグレードに関するベスト・プラクティス
</div></details>

### Q.  問題24: 未回答
会社では 9 月に大規模な販売イベントを開催しており、この期間中の業務を支援する従業員のグループを選択しました。Google が推奨するプラクティスに合わせるために、これらの従業員に 9 月限定で Google Cloud リソースへのアクセス権を付与する最適なアプローチは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. 識別された従業員のマシンからリソースへのトラフィックを許可するファイアウォール規則を追加します。9 月末にトラフィックを拒否するようにファイアウォール ルールを変更します。
ファイアウォールルールはネットワークトラフィックを規制できますが、リソースとの対話に必要なIAMアクセス許可は付与されません。この方法では、ネットワーク アクセスは制御されますが、リソース固有のアクセス許可は効果的に管理されません。
C. 識別された従業員を含むグループを作成し、リソースにアクセスするためのアクセス許可を持つカスタム Identity and Access Management (IAM) ロールをグループに割り当てます。9月末にカスタムロールを削除します。
9月末にカスタムロールを手動で削除すると、人為的ミスや見落としのリスクが生じます。さらに、即時のアクセス許可を付与する必要がない場合があり、慎重に管理しないとセキュリティ上のリスクにつながる可能性があります。
D. 識別された各従業員に、リソースにアクセスするアクセス許可を持つカスタム Identity and Access Management (IAM) ロールを割り当てます。Cloud Scheduler タスクを作成して、9 月末にカスタムロールを削除します。
グループではなく個々のユーザーにロールを割り当てることは、一般に効率が悪く、管理が困難です。Cloud Scheduler を使用してロールを削除することは、IAM 権限を管理するための標準的な方法ではなく、不必要な複雑さと潜在的なセキュリティ監視につながる可能性があります。
正解：
B. 識別された従業員を含むグループを作成します。リソースにアクセスするためのグループ権限を割り当て、9 月の日付/時刻式を使用して Identity and Access Management (IAM) 条件を構成します。
IAM 条件を利用して、指定した期間の権限を付与することは、Google が推奨する方法です。この方法では、必要な権限を自動的に割り当てたり取り消したりできるため、9 月中にのみアクセスできるようになります。これにより、管理が簡素化され、アクセス許可を手動で変更する必要がなくなるため、セキュリティが強化されます。
リンクス：
IAM条件の概要
</div></details>

### Q.  問題29: 回答
組織内で事後分析を実装することを計画しており、プロセスが十分に受け入れられるようにすることを目指しています。
そのために取るべき2つのステップとは?(2つのオプションを選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. 新入社員に、練習を通じてチームへの事後分析を行うことを奨励します。
新入社員を巻き込むことはトレーニングには有益ですが、経験豊富なガイダンスによって補完されなければ、強力な事後分析文化を確立するのに効果的ではない可能性があります。
B. すべての事後分析の実施を担当する指定チームを作成します。
専任のチームを持つことで、プロセスを合理化できるだけでなく、インシデントに直接関与するチームから責任を切り離すことができ、学習への影響を軽減できる可能性があります。
E. 以前の事後分析を批評するためのフォーラムを組織に提供します。
過去の事後分析を振り返ることは改善に役立ちますが、批評だけに焦点を当てると、学習や成長ではなく、プロセスに対する否定的な認識につながる可能性があります。
正解：
C. 上級管理職に事後分析を認め、参加するよう促す。
リーダーシップの参加は、事後分析の重要性を示し、透明性と学習の文化を確立します。
D. 効果的な事後分析を書くことは、報われ、称賛される習慣であることを確認する。
効果的な事後分析を認めて称賛することで、参加が促進され、組織の学習プロセスにおけるその価値が強調されます。
リンクス：
Lowe's SRE が平均復旧時間 (MTTR) を 80% 以上短縮した方法
事後分析文化:失敗から学ぶ
</div></details>

### Q.  問題31: 回答
開発チームがサービスの API の新しいバージョンを作成しました。目標は、サードパーティの開発者とサードパーティがインストールしたアプリケーションのエンドユーザーへの影響を最小限に抑えて、新しい API バージョンをデプロイすることです。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. 新しいバージョンの API を導入し、古いバージョンの廃止を発表し、古い API の残りのユーザーに連絡し、古い API のユーザーにベスト エフォート サポートを提供し、古いバージョンを破棄します。
このアプローチでは、ユーザーの不意を突く可能性があります。古いバージョンの廃止を発表する前に新しいバージョンを導入すると、混乱を招き、ユーザーが適応するための十分な時間が与えられない可能性があります。
C. 古いバージョンの API の廃止を発表し、古い API の残りのユーザーに連絡し、新しいバージョンを導入し、古いバージョンを廃止し、古い API のユーザーにベストエフォート サポートを提供し、古いバージョンを廃止します。
このシーケンスは B と似ていますが、新しいバージョンを導入する前にユーザーに連絡するため、新しい API のロールアウトが遅れる可能性があります。
D. 新しいバージョンの API を導入し、古い API の残りのユーザーに連絡し、古いバージョンの廃止を発表し、古いバージョンを廃止し、古い API のユーザーにベストエフォート サポートを提供し、古いバージョンを廃止します。
このアプローチでは、廃止について通知される前に新しいバージョンでユーザーを驚かせるリスクがあり、混乱を伴う移行につながる可能性があります。
正解：
B. 古いバージョンの API の廃止を発表し、新しいバージョンを導入し、古い API の残りのユーザーに連絡し、古いバージョンを廃止し、古い API のユーザーにベストエフォート サポートを提供し、古いバージョンを廃止します。
このシーケンスにより、すべての利害関係者が今後の変更について事前に通知されます。新しいバージョンを導入する前に廃止を発表することで、ユーザーが準備と適応を行う時間を確保できます。個別のコミュニケーション、サポート、および古い API の体系的な段階的廃止をフォローアップすることで、中断を最小限に抑え、よりスムーズな移行を保証します。
リンクス：
古い API をオフにする正しい方法
</div></details>

### Q.  問題43: 未回答
同僚は、夜間のオンコール中にプロジェクトの仮想プライベートクラウド(VPC)に入る不審なトラフィックが増えていることに気付きました。同僚が Cloud Armor の設定を更新して、特定の IP アドレスから発信されるトラフィックを停止しました。この変更により、ネットワーク トラフィックは減少しましたが、影響を受けた顧客からのエスカレーションが発生し、会社にペナルティが課せられました。チームは、Google が推奨する方法を使用して再発を防止したいと考えています。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
A. すべての変更は、変更をレビューする追加の人がいる日中に行われることを要求するポリシーを確立します。
これは、構成をいつでも変更する必要があるため、実行可能なポリシーではありません。このケースでは、潜在的なサイバー攻撃が夜間に発生しました。チームには、いつでも適用できるプロセスが必要です。
B. この同僚に変更について第 2 レベルのレビューを要求するプロセスを作成します。
このアプローチは、すべての人のプロセスを改善するのではなく、個人に特化しているため、推奨されるプラクティスに従っていません。
D. 同僚のインシデント レポートを作成し、上級管理職にエスカレーションします。
このアプローチは、プロセスを改善するのではなく、個人を非難することに重点を置いているため、推奨されるプラクティスに従っていません。
正解：
C. 中核となる技術的問題を特定し、チーム全体で使用できるように学習内容を文書化します。
このソリューションは、個人を責めることなく、技術的な問題を客観的に特定するDevOps/SREアプローチを採用しています。
リンクス：
事後分析文化:失敗から学ぶ
大胆不敵な事後分析の共有 - CRE の人生の教訓
</div></details>

### Q.  問題48: 未回答
1 つのゾーン内の自動スケーリングされたマネージド インスタンス グループでアプリケーションを実行しています。これは優先度の高いワークロードであるため、変更を確定する前に、マネージド・インスタンス・グループへの変更をテストする必要があります。これらの変更をテストしながら、要求を処理するのに十分な容量を確保するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. 複数のゾーンで実行するようにマネージド インスタンス グループを変更します。
マネージド・インスタンス・グループを複数のゾーンで実行すると、可用性とフォールト・トレランスを強化できますが、テストの変更がリクエストを処理するグループのキャパシティに影響を与えないことが直接保証されるわけではありません。
C. 変更中は、自動スケールを一時的に無効にします。
自動スケーリングを無効にすると、グループは現在の容量で固定されますが、変更の実装中に予期しない需要の急増が発生した場合は、これでは不十分になる可能性があります。
D. 予測自動スケーリングを有効にします。
予測自動スケーリングは、予想される負荷の変化を予測して対応するのに役立ちますが、変更時に十分な容量を保証するものではありません。予測モデルに影響を与えるリアルタイム要求や変更の予期しないスパイクは、容量不足につながる可能性があります。
正解：
A. 変更を行うときは、自動スケールを "スケールアウトのみ" に構成します。
自動スケールを "スケールアウトのみ" に構成すると、容量が減らなくなります。要求が増加した場合、マネージド インスタンス グループは需要を満たすためにスケールアウトされ、テスト フェーズ中に十分な容量が維持されます。
リンクス：
オートスケーラーの管理
</div></details>

### Q.  問題50: 未回答
組織は、本番環境を含む複数のプロジェクトを Google Cloud に移行し、組織のポリシーを一元的に管理しています。
リソース階層のポリシー変更をロールアウトするために Google が推奨するプラクティスに合わせるには、どのようなアプローチを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. 運用環境用に 1 つの組織を作成し、階層全体にポリシーの変更を段階的に適用します。
ポリシーの変更を本番組織に直接実装すると、これらの変更が広範囲に及ぼし、意図しない影響が生じる可能性があるため、リスクが伴う可能性があります。最初に非運用環境でポリシーをテストすることが重要です。
C. 運用環境用の組織と、リリース前のチェック用に別のステージング環境を設定し、ステージング環境で実験を実行します。
ステージング環境はプレリリースチェックに不可欠ですが、本番環境の構成をミラーリングする必要があります。実験目的でステージング環境で構成を変更したり、セキュリティ設定を緩和したりすることはお勧めできません。
D. 運用環境の組織を形成し、運用プロジェクトの階層の下位から始めて、ポリシーの変更を段階的に導入します。
ポリシーの変更を本番組織に直接導入することは、たとえ段階的に行われたとしても、意図しない結果を招くリスクがあります。最初に、別の非運用環境でポリシーの変更を試すことをお勧めします。
正解：
A. ポリシーの変更を試すための組織を 1 つと、運用環境用に別の組織を設立します。
ポリシーの変更をテストするために別の組織を使用することは、賢明なアプローチです。これにより、本番環境に影響を与えるリスクを冒すことなく実験を行うことができます。この方法は、ポリシーがメイン組織に適用される前に、制御された設定で潜在的な問題と意図しない結果を特定するのに役立ちます。
リンクス：
https://cloud.google.com/architecture/identity/best-practices-for-planning#use_a_separate_organization_for_experimenting
</div></details>

## 4
### Q.  問題1: 未回答
チームは、世界中の何百万人もの顧客にサービスを提供している Compute Engine インスタンスに重要なセキュリティ パッチを適用する必要があります。
パッチを迅速に展開し、コストと顧客への影響を最小限に抑えるには、どのような戦略を採用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：

不正解:
B. 世界中のすべての Compute Engine インスタンスを同時に更新する。
すべてのインスタンスを同時に更新するのは危険です。パッチによって問題が発生すると、すべてのユーザーに一度に影響を与え、サービスの大幅な中断につながる可能性があります。
C. 各リージョンの夜間にスケジュールされた 24 時間のローリング更新を実行します。
24 時間のローリング アップデートは、オフピーク時に更新を実行することで顧客への影響を最小限に抑えますが、重要なパッチには適していません。どのリージョンでも更新を遅らせると、システムが特定されたセキュリティの脅威に対して脆弱なままになる可能性があります。
D. A/B ロールアウトを実装し、Compute Engine ですべてのインスタンスのコピーを作成し、パッチを適用してから、ユーザーを切り替えます。
重複インスタンスの完全なセットの作成を伴う A/B ロールアウトは、費用対効果が高くなく、タイムリーでもありません。この方法では、かなりのリソースと時間を必要とするため、迅速なセキュリティパッチの展開は現実的ではありません。
正解：
A. セキュリティ パッチのカナリア ロールアウトを短期間で実行します。
Canary ロールアウトでは、最初に少数のインスタンスにパッチを適用できます。このアプローチにより、より広範なロールアウトの前にパッチの影響を監視し、問題を早期に特定して対処することで、リスクとコストを最小限に抑えることができます。
リンクス：
カナリアリリース
カナリアを放つことでベーコンを救う方法—CREの人生の教訓
</div></details>


# 4
## 1

## 2

## 3

## 4
