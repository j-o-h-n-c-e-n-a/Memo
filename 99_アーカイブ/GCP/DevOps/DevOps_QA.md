## 1
### Q. 問題1: 未回答
あなたは現在、組織のGoogle CloudプロジェクトのCloud Monitoringメトリクスを表示する方法を計画しています。あなたの組織には以下の3つのフォルダと6つのプロジェクトがあります：
Developmentフォルダー
- cjp-one-dev
- cjp-two-dev
Stagingフォルダー
- cjp-one-staging
- cjp-two-staging
Productionフォルダー
- cjp-one-prod
- cjp-two-prod
Cloud Monitoringダッシュボードを構成して、1つのフォルダ内のプロジェクトのメトリクスのみを表示させたいとします。ダッシュボードが他のフォルダのプロジェクトのメトリクスを表示しないようにする必要があります。Googleが推奨するプラクティスに従います。
あなたはこの要件を満たすために、どうすればよいですか？
1. 新しいスコーププロジェクトを1つ作成します
2. フォルダごとに新しいスコーププロジェクトを作成します
3. 現在のcjp-one-dev、cjp-one-staging、cjp-one-prodプロジェクトを、各フォルダのスコーププロジェクトとして使用します
4. 現在のcjp-one-prodプロジェクトをスコーププロジェクトとして使用します
<details><div>
    答え：2
説明
この問題では、複数のGoogle CloudプロジェクトにわたるCloud Monitoringメトリクスを表示する方法を計画する必要があります。ここで重要なのは、各フォルダ内のプロジェクトのメトリクスだけを表示したいという要件です。そのため、各フォルダ単位でうまくスコープを分ける方法を考える必要があります。Googleの推奨するプラクティスを適用しつつ、適切なスコーププロジェクトの作成や使用方法を選択することが求められている状況です。
基本的な概念や原則：
Cloud Monitoring：Google Cloudのリソースとアプリケーションのパフォーマンスを監視、評価、保護するためのツールです。異常を迅速に特定し、通知を送ることが可能です。
Cloud Monitoringダッシュボード：Cloud Monitoringの情報を視覚的に表示するインターフェースです。パフォーマンスメトリクス、リソース利用率などをリアルタイムで把握することができます。
フォルダ：Google Cloudリソースの管理単位です。あるフォルダの中にあるプロジェクトとそのリソースは、そのフォルダの設定に基づいて制御されます。
Cloudプロジェクト：Google Cloud上でリソースを作成・管理するためのコンテナです。各プロジェクトは一意のIDを持ち、1つ以上のフォルダ内に配置されます。
スコーププロジェクト：特定の目的に合わせて設定・管理されるCloudプロジェクトです。特定のスコープ（例えば、特定のフォルダ内のプロジェクト）に対するリソース使用状況やメトリクスを把握するために使用されます。
Google Cloudの推奨プラクティス：Googleから公表されている、Cloudの効率的でセキュアな利用方法のガイドラインです。特定の要件を満たすための最良のソリューションを提供します。
正解についての説明：
（選択肢）
・フォルダごとに新しいスコーププロジェクトを作成します
この選択肢が正解の理由は以下の通りです。
Google Cloud Monitoringでは、ダッシュボードは一つのプロジェクトに対して設定されたものであり、他のプロジェクトのメトリックを表示することはできません。そのため、フォルダごとにスコーププロジェクトを作成することにより、フォルダ内の各プロジェクトのメトリクスを一元化することができます。そのスコーププロジェクトにダッシュボードを作成することで、特定のフォルダー内のプロジェクトのメトリクスのみを表示させることができます。これにより、他のフォルダのプロジェクトのメトリクスと混在することなく、1つのフォルダ内の各プロジェクトのメトリクスを効率よく管理・モニタリングすることが可能になります。これはGoogleが推奨するプラクティスにより適合しており、この要件を効果的に満たします。
不正解についての説明：
選択肢：新しいスコーププロジェクトを1つ作成します
この選択肢が正しくない理由は以下の通りです。
新しいスコーププロジェクトを1つだけ作成すると、全てのフォルダのメトリクスが混在して表示されてしまい、特定のフォルダのメトリクスだけを分離して表示することができません。
それに対して、フォルダごとに新しいスコーププロジェクトを作成すると、そのフォルダ内のプロジェクトのメトリクスのみを絞り込んで表示できます。
選択肢：現在のcjp-one-prodプロジェクトをスコーププロジェクトとして使用します
この選択肢が正しくない理由は以下の通りです。
cjp-one-prodプロジェクトをスコーププロジェクトとして使用した場合、他のフォルダのプロジェクトのメトリクスを表示できる範囲が制限されます。新しいスコーププロジェクトを作成することにより、各フォルダ内のプロジェクトのメトリクスのみを表示するダッシュボードを構成できます。
選択肢：現在のcjp-one-dev、cjp-one-staging、cjp-one-prodプロジェクトを、各フォルダのスコーププロジェクトとして使用します
この選択肢が正しくない理由は以下の通りです。
現在のプロジェクトを使用すると、フォルダ全体のメトリクスを正確に表示することが難しいです。そのため、新しいスコーププロジェクトを作成して、必要なメトリクスを的確に把握する方がベストプラクティスとされています。
参考リンク：
https://cloud.google.com/monitoring/dashboards
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://cloud.google.com/monitoring/api/v3/aggregation
</div></details>

### Q. 問題2: 未回答
あなたの会社は最近Google Cloudに移行しました。新しいプロジェクトと基本リソースをGoogle Cloudにプロビジョニングするために、高速で信頼性が高く、再現性のあるソリューションを設計する必要があります。
この要件を満たすために、どうすればよいですか？

1. Terraformモジュールを書いてソース管理リポジトリに保存します。terraform applyコマンドをコピーして実行し、新しいプロジェクトを作成します
2. リクエストから適切なパラメータを渡すgcloud CLIを使用してスクリプトを記述します。スクリプトをGitリポジトリに保存します
3. プロジェクトを作成するために、Google Cloudコンソールを使用します
4. Cloud Foundation ToolkitのTerraformリポジトリを使用します。適切なパラメータを指定してコードを適用し、Google Cloudプロジェクトと関連リソースを作成します
<details><div>
    答え：4
説明
この問題では、Google Cloudに移行した会社が新しいプロジェクトと基本リソースをプロビジョニングするための高速で信頼性が高く、再現性のあるソリューションを設計することが要求されています。ここで求められているのは、信頼性と再現性が高く、高速で新しいプロジェクトとリソースを作成する効率的な方法です。そのため、選択肢を見るときは、これらの要素を満たす各オプションを探すことが重要となります。この問題を解く上でのキーポイントはプロビジョニングの自動化と一貫性です。
基本的な概念や原則：
Cloud Foundation Toolkit：Google Cloudの環境を迅速にセットアップし、管理するためのモジュラーでスケーラブルなテンプレート群です。TerraformとDeployment Managerのモジュールが用意されています。
Terraform：HashiCorpが開発したオープンソースのインフラストラクチャアズコードツールです。異なるクラウドプロバイダやサービス間で標準的な操作と自動化を提供します。
Google Cloudプロジェクト：Google Cloudでリソースを作成して管理する基本的な組織単位です。
Google Cloud Console：Google Cloudの各種リソースやサービスを管理するためのWebベースのユーザインターフェースです。
gcloud CLI：Google Cloudのリソースやサービスをコマンドラインから操作するためのツールです。スクリプトでの利用にも適しています。
Git：分散型バージョン管理システムです。プロジェクトの全ての開発履歴を保管し、分散作業を効率的に行うことが可能です。
正解についての説明：
（選択肢）
・Cloud Foundation ToolkitのTerraformリポジトリを使用します。適切なパラメータを指定してコードを適用し、Google Cloudプロジェクトと関連リソースを作成します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Foundation Toolkit（CFT）のTerraformリポジトリは、Google Cloudのリソースを管理するための通常の慣行に基づいたさまざまなモジュールとテンプレートを提供します。これにより、新しいプロジェクトとその基本的なリソースを効率的にプロビジョニングするための強力なツールセットが利用可能になります。
また、TerraformはInfrastructure as Code（IaC）ツールの一つであり、コードを通じてインフラストラクチャを定義およびプロビジョニングすることを可能にします。これは、設定の再現性、バージョン管理、および多くの環境に対する一貫性の確保など、多くの利点を提供します。
したがって、CFTのTerraformリポジトリを使用してパラメータを指定し、コードを適用することで、高速で信頼性が高く、再現可能なソリューションを設計できます。これは新しいプロジェクトと関連リソースの作成に適しています。
不正解についての説明：
選択肢：プロジェクトを作成するために、Google Cloudコンソールを使用します
この選択肢が正しくない理由は以下の通りです。
Google Cloudコンソールを使用してプロジェクトを作成する方法は、高速で信頼性が高く、再現性のあるソリューションとは言えません。マニュアル操作で時間がかかるため、量が多いとミスも発生しやすくなります。
一方で、Cloud Foundation ToolkitのTerraformリポジトリを使用すると、コードによる管理が可能となり、高速、信頼性、再現性全ての要素を満たすが可能となります。
選択肢：リクエストから適切なパラメータを渡すgcloud CLIを使用してスクリプトを記述します。スクリプトをGitリポジトリに保存します
この選択肢が正しくない理由は以下の通りです。
gcloud CLIを使用してスクリプトを記述する方法でも基本的なリソースのプロビジョニングは実現できますが、再現性と信頼性の面で不十分です。
それに対して、Cloud Foundation ToolkitのTerraformリポジトリは高速で信頼性が高く再現性のあるソリューションを提供し、コード化されたインフラストラクチャ管理を実現します。
選択肢：Terraformモジュールを書いてソース管理リポジトリに保存します。terraform applyコマンドをコピーして実行し、新しいプロジェクトを作成します
この選択肢が正しくない理由は以下の通りです。
Terraformモジュールを書き、Terraform applyコマンドを使用する方法も新しいプロジェクトの作成に使用できますが、これだけでは再現性や信頼性が必ずしも保証されるわけではありません。
それに対して、Cloud Foundation ToolkitのTerraformリポジトリを利用すれば、既に信頼性が確認されたTerraformテンプレートを再利用できるため、要件をより確実に満たせます。
参考リンク：
https://cloud.google.com/resource-manager/docs/creating-managing-projects
https://cloud.google.com/foundation-toolkit
https://www.terraform.io/docs/providers/google/guides/getting_started.html
</div></details>

### Q. 問題3: 未回答
あなたは、アプリケーションのビルドにCloud Buildを使用しています。コストと開発工数を最小限に抑えながら、ビルド時間を短縮したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. 実行時間を最小化するために、複数の小さなビルドステップを使用します
2. Cloud Storageを使用して中間成果物をキャッシュします
3. ビルドを並列化するために複数のJenkinsエージェントを実行します
4. マシンタイプオプションを使用して、より大きなCloud Build仮想マシン（VM）を使用します
<details><div>
    答え：2
説明
この問題では、Cloud Buildを用いたアプリケーションのビルド工程において、ビルド時間を短縮することを目指し、かつコストと開発工数を最小限に抑える方策を選ぶことが求められています。選択肢を評価する際には、ビルド時間の短縮とコスト・工数の最小化のバランスを考慮する必要があります。選択肢の中には、時間短縮効果があるもののコストや開発工数が増大する可能性があるものも含まれているため、全体の最適解を見つけることがキーとなります。
基本的な概念や原則：
Cloud Build：Google CloudのCI/CDプラットフォームです。アプリケーションのビルドとテストをサーバレスで高速に行うことができます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。低遅延と高い伸縮性を提供します。
ビルドキャッシュ：ビルドプロセス中に生成される中間成果物を再利用してビルド時間を短縮するテクニックです。
Jenkinsエージェント：Jenkinsの仕事を実行するためのサーバです。並列化によりビルド時間を短縮できますが、管理が必要であり、余分なコストが発生する可能性があります。
ビルドステップ：ビルドプロセスの各フェーズを表す一連のタスクです。小さなステップに分割することは管理を容易にしますが、各ステップのオーバーヘッドによりビルド時間が長くなる可能性があります。
Cloud Build仮想マシン（VM）：ビルドプロセスを実行するための環境です。仮想マシンのサイズを大きくすることで、ビルド時間を短縮できますが、コストが増加する可能性があります。
正解についての説明：
（選択肢）
・Cloud Storageを使用して中間成果物をキャッシュします
この選択肢が正解の理由は以下の通りです。
まず、Cloud BuildはGoogle Cloudのフルマネージド型のビルドサービスであり、ソースコードからコンテナイメージやアプリケーションを効率的にビルドするために使用されます。ビルドプロセスの間に生成される一時的なファイルや中間成果物をCloud Storageにキャッシュすることで、それらを再利用し、同じビルドステップを繰り返すことなく、ビルド時間を大幅に短縮することができます。
加えて、Cloud Storageは高可用性と耐久性に優れ、大量のデータを安全に保存できるスケーラブルなストレージサービスです。
したがって、ビルドプロセスで生じる多数の中間成果物を保存、管理し、すぐにアクセスできることが可能となります。
さらに、中間成果物のキャッシュによるビルド時間の短縮は、ビルドに関連するコスト削減にも寄与します。これは、ビルドプロセスが時間をかけて同じ操作を繰り返すことを避けることで、計算リソースの使用を最適化するからです。これにより、開発工数も最小限に抑えることが可能となります。
従って、Cloud Storageを使用して中間成果物をキャッシュすることは、ビルド時間の短縮とコスト削減の両方を実現する効率的な手法と言えます。
不正解についての説明：
選択肢：ビルドを並列化するために複数のJenkinsエージェントを実行します
この選択肢が正しくない理由は以下の通りです。
ビルドを並列化するために複数のJenkinsエージェントを走らせると、確かにビルド時間を短縮できますが、それは追加の計算リソースを必要とします。これはコストと開発工数を増加させる可能性があります。
一方で、Cloud Storageを使用して中間成果物をキャッシュする方法は、再ビルド時間を削減し、コストと開発工数を抑えることができます。
選択肢：実行時間を最小化するために、複数の小さなビルドステップを使用します
この選択肢が正しくない理由は以下の通りです。
ビルドプロセスを複数の小さなステップに分割することは、ビルド時間を必ずしも短縮しません。それどころか、各ステップ間のオーバーヘッドによりビルド時間が延長する可能性があります。
一方、Cloud Storageを使用して中間成果物をキャッシュすることは、再利用可能なコンポーネントを保存し再ビルドを避けることで、ビルド時間の短縮に効果的です。
選択肢：マシンタイプオプションを使用して、より大きなCloud Build仮想マシン（VM）を使用します
この選択肢が正しくない理由は以下の通りです。
より大きなCloud Build仮想マシンを使用する方法はビルド時間を短縮する可能性がありますが、コストと開発工数を最小限に抑える目標には合わない可能性があります。
それに対して、Cloud Storageを使用して中間成果物をキャッシュする方法は、再利用可能な成果物を保存し次回のビルドで再利用することでビルド時間を短縮し、コストと開発工数も抑えることが可能です。
参考リンク：
https://cloud.google.com/build/docs/speeding-up-builds
https://cloud.google.com/build/docs/build-config-file-schema#options
https://cloud.google.com/storage/docs/uploading-objects
</div></details>

### Q. 問題4: 未回答
あなたはGoogle CloudリソースのTerraformデプロイを実行するCI/CDパイプラインを作成しています。CI/CDツーリングはGoogle Kubernetes Engine（GKE）で実行され、各パイプラインの実行にエフェメラルなポッドを使用します。ポッド内で実行されるパイプラインが、Terraformデプロイを実行するための適切なIAM（Identity and Access Management）権限を持っていることを確認する必要があります。ID管理についてはGoogleが推奨するプラクティスに従う必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. 新しいKubernetesサービスアカウントを作成し、そのサービスアカウントをポッドに割り当てます。Workload Identityを使用して、Googleサービスアカウントとして認証します
2. 新しいGoogleサービスアカウントを作成し、適切なIAM権限を割り当てます
3. Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、そのキーをKubernetesシークレットとして保存し、そのキーをポッドに注入し、GOOGLE_APPLICATION_CREDENTIALS環境変数を設定します
4. Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、CI/CDツールのシークレット管理ストアにキーを保存し、認証にこのキーを使用するようにTerraformを設定します
5. ポッドを実行するCompute Engine VMインスタンスに関連付けられたGoogleサービスアカウントに、適切なIAMパーミッションを割り当てます
<details><div>
    答え：1,2
説明
この問題では、CI/CDパイプラインでGoogle CloudリソースのTerraformデプロイを実行するためのIAM権限管理について質問がされています。特に、Google Kubernetes Engineで実行されるエフェメラルなポッドが適切な権限を持っていることが必要で、Googleの推奨するID管理のプラクティスに従うことが求められています。ここで、ロールを持つインスタンスとそのアクセス管理を安全に管理する方法として、Kubernetesサービスアカウントの作成とその割り当て、Workload Identityの使用、Googleサービスアカウントの作成とIAM権限の管理などが試験対策となります。選択肢を読み解く際には、GoogleのID管理のベストプラクティスと、セキュリティや運用面でのコンソールからの各種設定の違いに注目することが必要です。
基本的な概念や原則：
Terraform：Infrastructure as Codeツールで、クラウドリソースのデプロイを自動化します。Google CloudのリソースやIAMポリシーなど、多くのGoogle Cloudサービスがサポートされています。
Google Kubernetes Engine（GKE）：Kubernetesのマネージド環境を提供するGoogle Cloudサービスです。クラスター管理やオートスケーリングなどの機能があります。
エフェメラルポッド：一時的に作成され、タスク完了後にすぐに削除されるKubernetesのポッドです。CI/CDパイプラインなど短期間のタスクに適しています。
IAM権限：Google Cloudサービスのリソースに対するアクセスを制御する機能です。サービスアカウントに対して適切な権限を割り当てることで、適切なアクセス制御が可能になります。
Kubernetesサービスアカウント：Kubernetes内での身元証明とアクセス制御を行うアカウントです。特定のポッドに割り当てることができます。
Workload Identity：GKE上のサービスアカウントをGoogle Cloudのサービスアカウントにマッピングする機能です。これにより、GKEの各ポッドは適切なIAM権限を持つことになります。
Googleサービスアカウント：Google Cloudリソースに対するアクセスを認証・認可するための特殊なアカウントです。適切なIAM権限を持つことで、リソースへの安全なアクセスが可能になります。
正解についての説明：
（選択肢）
・新しいKubernetesサービスアカウントを作成し、そのサービスアカウントをポッドに割り当てます。Workload Identityを使用して、Googleサービスアカウントとして認証します
・新しいGoogleサービスアカウントを作成し、適切なIAM権限を割り当てます
この選択肢が正解の理由は以下の通りです。
まず、問題文の最初の要件である"ポッド内で実行されるパイプラインが、Terraformデプロイを実行するための適切なIAM権限を持っていること"を満たすために、新しいGoogleサービスアカウントを作成し、適切なIAM権限を割り当てることが必要です。このようにすることで、CI/CDツールが実行されるGKE環境を、実際にリソースのデプロイメントや更新を行うためのIAM権限を持つアカウントとして扱うことができます。
次に、Googleの推奨するプラクティスに従うために、新しいKubernetesサービスアカウントを作成し、そのサービスアカウントをポッドに割り当てます。
そして、Workload Identityを使用してGoogleサービスアカウントとして認証します。Workload IdentityはGKEのサービスアカウントとGoogle Cloudのサービスアカウントを関連付けるシステムで、これによってCI/CDパイプラインが実行されるポッドが適切なアイデンティティと権限を持つようになります。これにより、エフェメラルなポッドがTerraformデプロイを実行するための十分な権限を持つように、安全かつ効率的に許可とアイデンティティの管理が可能になります。
不正解についての説明：
選択肢：Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、そのキーをKubernetesシークレットとして保存し、そのキーをポッドに注入し、GOOGLE_APPLICATION_CREDENTIALS環境変数を設定します
この選択肢が正しくない理由は以下の通りです。
JSONサービスアカウントキーの使用は、キーのライフサイクル管理や機密性保持が難しく、Googleの推奨するプラクティスではありません。
代わりに、Workload Identityを使用してサービスアカウントを認証する方法が推奨されています。
選択肢：Googleサービスアカウント用の新しいJSONサービスアカウントキーを作成し、CI/CDツールのシークレット管理ストアにキーを保存し、認証にこのキーを使用するようにTerraformを設定します
この選択肢が正しくない理由は以下の通りです。
JSONサービスアカウントキーの使用はセキュリティ上のリスクを引き起こし、Googleが推奨するプラクティスを満たしません。
これに対して、適切なIAM権限を持たせてWorkload Identityを使用することで、セキュリティが強化され、Terraformデプロイの認証も確実に行えます。
選択肢：ポッドを実行するCompute Engine VMインスタンスに関連付けられたGoogleサービスアカウントに、適切なIAMパーミッションを割り当てます
この選択肢が正しくない理由は以下の通りです。
ポッドのIAM権限はCompute Engine VMインスタンスのサービスアカウントからではなく、Kubernetesサービスアカウントから派生すべきです。これはGoogleの推奨するプラクティスに従っていません。GKE上でのID管理にはWorkload Identityを使用すべきです。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/workload-identity
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://www.terraform.io/docs/providers/google/guides/provider_reference.html
</div></details>

### Q. 問題5: 未回答
あなたの会社では、Google Kubernetes Engine（GKE）を使用してサービスを実行しています。開発環境のGKEダスターは、冗長ロギングを有効にしてアプリケーションを実行します。開発者はkubectl logsコマンドを使用してログを表示し、Cloud Loggingは使用しません。アプリケーションには統一されたロギング構造が定義されていません。アプリケーションのロギングに関連するコストを最小限に抑えつつ、GKEの運用ログを収集する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. severity >= DEBUG resource.type = "k8s_container"の除外フィルタを、開発環境に関連するプロジェクトの_Defaultロギングシンクに追加します
2. 開発クラスターに対して、gcloud container clusters update --logging=SYSTEMコマンドを実行します
3. 開発環境に関連付けられたプロジェクトで、gcloud logging sinks update _Default --disabledコマンドを実行します
4. 開発クラスターに対して、gcloud container clusters update --logging=WORKLOADコマンドを実行します
<details><div>
    答え：1
説明
この問題では、Google Kubernetes Engine（GKE）上で動作するアプリケーションのロギングに関連するコストを抑えつつ、運用ログを適切に収集する方法が求められています。この要件を満たすためには、ロギングの範囲やレベルを適切に制御する方法を選ぶ必要があります。試験問題文からは、kubectlを用いたログ表示とともにCloud Loggingは使用せず、またアプリケーションには統一されたロギング構造がないことが明らかにされています。これらの条件を踏まえると、ログ収集の範囲や集約度を調整するオプションが適切です。そのため、適切なログフィルタを設定したり、gcloudコマンドを用いたクラスターの更新などが考えられますので、それぞれの選択肢の意味を理解しながら解答する必要があります。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：Google CloudのフルマネージドなKubernetesサービスです。大規模なワークロードの管理を簡素化し、ワークロードの運用・管理を自動化します。
kubectl logsコマンド：KubernetesのCLIであるkubectlを使用して、ポッド内のコンテナのログを表示するコマンドです。
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションとシステムのログを一元化して保存、分析、可視化することができます。
_Defaultロギングシンク：Google Cloud Loggingで提供されるデフォルトの投稿先です。ログエントリが最初に送信される先を指します。
冗長ロギング：一つのイベントに対して2つ以上のログが生成される状態です。これは、重複した情報を提供するため、ストレージの消費が増加し、コストが上昇する可能性があります。
severityフィルタリング：ログエントリの重要度（severity）に基づいてフィルタリングを行う機能です。重要度が低いログを除外することでロギングのコストを抑えることができます。
gcloudコマンド：Google Cloud SDKのコマンドラインツールです。これを使用して、Google Cloudのリソースとアプリケーションを管理・操作することができます。
正解についての説明：
（選択肢）
・severity >= DEBUG resource.type = "k8s_container"の除外フィルタを、開発環境に関連するプロジェクトの_Defaultロギングシンクに追加します
この選択肢が正解の理由は以下の通りです。
GKEでは、_Defaultロギングシンクが自動的に各種ログをCloud Loggingに送信します。この運用ログの収集は、システムの運用や監視に必要ですが、アプリケーションログの冗長な収集は大量のストレージとコストを必要とします。開発チームはkubectl logsコマンドを使用したアプリケーションログの表示が可能であり、Cloud Loggingを必要としていないため、ログの保存費用を最小限にすることができます。そのため、無駄なコストの増大を防ぐために、"severity >= DEBUG resource.type = "k8s_container"の除外フィルタを_Defaultロギングシンクに追加することで、DEBUGレベル以上のアプリケーションログのCloud Loggingへの保存を防ぐことが可能となるため、この設定が最も適しています。
不正解についての説明：
選択肢：開発クラスターに対して、gcloud container clusters update --logging=SYSTEMコマンドを実行します
この選択肢が正しくない理由は以下の通りです。
gcloud container clusters update --logging=SYSTEMコマンドは、ログをCloud Loggingに送信しないでローカルに保存しますが、それを行うと開発者はkubectl logsコマンドでログを参照できなくなります。
また、このコマンドを使用しても冗長なロギングの発生を防ぐことはできません。これは、要件の最小限のコストとkubectl logsコマンドの利用を満たさないため不適切です。
選択肢：開発クラスターに対して、gcloud container clusters update --logging=WORKLOADコマンドを実行します
この選択肢が正しくない理由は以下の通りです。
gcloud container clusters update --logging=WORKLOADコマンドは既存のクラスターの構成を変更し、作業ログの収集を有効にしますが、すでに冗長なロギングが有効にされていると述べられているので、これは不必要です。
加えて、この選択肢は開発者がkubectl logsコマンドを使ってログを見るためには役立たず、またアプリケーションのロギングに関連するコストを最小化することもできません。
選択肢：開発環境に関連付けられたプロジェクトで、gcloud logging sinks update _Default --disabledコマンドを実行します
この選択肢が正しくない理由は以下の通りです。
gcloud logging sinks update _Default --disabledコマンドが実行されると、すべてのログが無効化されてしまいます。その結果、GKEの運用ログが収集されなくなるため、問題の要件を満たすことができません。正解の選択肢は特定のフィルタを適用し、必要なログのみを収集するので、不必要なコストを抑えることが可能です。
参考リンク：
https://cloud.google.com/logging/docs/exclusions
https://cloud.google.com/kubernetes-engine/docs/how-to/logging
https://cloud.google.com/logging/docs/basic-concepts#log_entries
</div></details>

### Q. 問題6: 未回答
あなたの会社はGoogle Kubernetes Engine（GKE）でアプリケーションを実行しています。いくつかのアプリケーションはエフェメラルボリュームに依存しています。ワーカーノードのDiskPressureノード状態が原因で、いくつかのアプリケーションが不安定であることに気づきました。問題の原因となっているポッドを特定する必要がありますが、ワークロードとノードへの実行アクセスがありません。
この要件を満たすために、どうすればよいですか？

1. Metrics Explorerを使用して、container/ephemeral_storage/used_bytesメトリクスを確認します
2. emptyDirボリュームのあるポッドをすべて探します。df --hコマンドを使ってボリュームのディスク使用量を測定します
3. emptyDirボリュームのあるポッドをすべて探します。df --sh * コマンドを使用してボリュームのディスク使用量を測定します
4. Metrics Explorerを使用して、node/ephemeral_storage/used_bytesメトリックを確認します
<details><div>
    答え：1
説明
この問題では、Google Kubernetes Engine（GKE）においてディスク逼迫による不安定なアプリケーションの問題を診断する方法が求められています。まず問題文から、問題の原因となるポッドとそのエフェメラルボリュームの使用状況を特定する必要があることを理解する必要があります。ただし、アクセス制限により直接的な確認はできないため、間接的な手法を用いる必要があります。正解や不正解の選択肢からは、Metrics Explorerを使用して各種メトリクスを確認する方法や特定のコマンドを用いてディスク使用量を調査する方法が示されています。これらの情報を踏まえて解答を選ぶことが重要です。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：Google Cloudが提供するマネージドKubernetesサービスです。クラスターのセットアップ、スケーリング、アップグレードなどを自動化します。
エフェメラルボリューム：Kubernetesにおける一時的なストレージ領域です。ポッドがノードにバインドされている間だけ存在し、データは持続的ではありません。
DiskPressureノード状態：Kubernetesノードにおけるディスク使用状況を監視するパラメーターです。これが高いと、アプリケーションのパフォーマンスに影響を与えることがあります。
Metrics Explorer：Google Cloud Monitoringの機能で、Google Cloudのプロジェクトに関するメトリクスを視覚的に調査し、分析するためのツールです。
container/ephemeral_storage/used_bytesメトリクス：Kubernetesにおける各コンテナが使用しているエフェメラルストレージの量を示すメトリクスです。
emptyDirボリューム：Kubernetesのポッド内でデータを共有するためのテンポラリストレージです。ポッドがノードから削除されると、その内容も削除されます。
正解についての説明：
（選択肢）
・Metrics Explorerを使用して、container/ephemeral_storage/used_bytesメトリクスを確認します
この選択肢が正解の理由は以下の通りです。
Google Cloud MonitoringのMetrics Explorerは、Google Cloud環境上のメトリクスを視覚的に観察・分析するためのツールです。特に、次のような詳細な情報を抽出し、フィルタリングやグループ化が行えます。つまり、特定のメトリクス（ここではcontainer/ephemeral_storage/used_bytes）を確認するために使用できます。
これは、エフェメラルストレージの使用状況を示しており、各ポッドがどれだけのエフェメラルストレージを使用しているかを示すものです。この情報により、DiskPressureの問題を引き起こしている可能性のあるポッドを特定することができます。
ワークロードやノードへの実行アクセスがなくても、Metrics Explorerを使えばセンシティブな操作なしにこの情報を取得できるので、この場合の問題解決に適しています。
不正解についての説明：
選択肢：Metrics Explorerを使用して、node/ephemeral_storage/used_bytesメトリックを確認します
この選択肢が正しくない理由は以下の通りです。
問題の特定は、ノード全体のエフェメラルストレージ使用情報ではなく、各コンテナのエフェメラルストレージ使用情報に基づいて行う必要があります。不正解の選択肢は、ノード全体のエフェメラルストレージ使用量をチェックするものであるため、問題のある特定のポッドを特定するのには適していません。
選択肢：emptyDirボリュームのあるポッドをすべて探します。df --hコマンドを使ってボリュームのディスク使用量を測定します
この選択肢が正しくない理由は以下の通りです。
問題文にはワークロードとノードへの直接的な実行アクセスがないとありますが、df --hコマンドを使うにはそれらへの直接的な実行アクセスが必要です。そのため、この選択肢は要件を満たしません。対して正解のMetrics Explorerを使用すれば、ノードのアクセスなしにディスク使用量を確認することができます。
選択肢：emptyDirボリュームのあるポッドをすべて探します。df --sh * コマンドを使用してボリュームのディスク使用量を測定します
この選択肢が正しくない理由は以下の通りです。
問題文にはワークロードやノードへの実行アクセスがないと述べられており、それはdfコマンドを具体的なポッド上で実行することは不可能であることを意味します。
対照的に、Metrics Explorerを使用すれば、コマンドラインアクセスなしで容量情報を取得することが可能となるため、正解の選択が妥当です。
参考リンク：
https://cloud.google.com/monitoring/metrics-explorer
https://cloud.google.com/kubernetes-engine/docs/how-to/monitoring#monitoring_metrics_with_cloud_monitoring
</div></details>

### Q. 問題7: 未回答
あなたはクライアントのために新しいGoogle Cloudの組織を設計しています。クライアントは、Google Cloudで作成された長期間のクレデンシャルに関連するリスクを懸念しています。あなたは、運用上のオーバーヘッドを最小限に抑えながら、JSONサービスアカウントキーの使用に関連するリスクを完全に排除するソリューションを設計する必要があります。
この要件を満たすために、どうすればよいですか？

1. 組織管理者のみにroles/iam.serviceAccountKeyAdmin IAMロールを付与します
2. constraints/iam.disableServiceAccountKevCreation制約を組織に適用します
3. 定義済みロールのカスタムバージョンを使用して、すべてのiam.serviceAccountKeys.*サービスアカウントロールパーミッションを除外します
4. constraints/iam.disableServiceAccountKeyUpload制約を組織に適用します
<details><div>
    答え：2
説明
この問題では、新しいGoogle Cloudの組織を設計する中で、JSON形式のサービスアカウントキー使用をリスクと見なし、そのリスクを無くす方法を設計することが求められています。同時に、運用上のオーバーヘッドを最小限に抑える必要も要求されています。したがって、この問題を解くためには、これらの要件を満たすためのIAMポリシーや制約の適用について理解することが重要で、選択肢間で細かな違いに注目しながらその影響を評価することが求められます。
基本的な概念や原則：
Service Account：Google Cloudのサービスを利用するエンティティで、特定の権限が付与されまます。これを利用して、アプリケーションやユーザーがGoogle Cloudのリソースにアクセスします。
JSON Service Account Key：Service Accountを認証するための暗号化キーで、JSONフォーマットで提供されます。キーが漏洩するとService Accountによる不正アクセスのリスクが発生します。
組織ポリシー制約：Google Cloudのあるリソース(tree, folder, project)で適用可能な特定のポリシーです。これを設定することによって、そのリソースに対するアクションを制約します。
constraints/iam.disableServiceAccountKeyCreation：Service Accountのキー作成を禁止する制約です。これを設定することで、新規にService Accountのキーを作成することを防ぎます。
IAMロール：Google Cloudリソースへのアクセスの許可を集めたものです。仕事のロールに基づいてユーザーに権限を付与するために使用します。ロールは1つ以上のパーミッションで構成されます。
カスタムIAMロール：プロジェクトや組織で定義したIAMロールのことで、必要に応じて特定のパーミッションを組み合わせて作成します。ただし、管理に手間がかかったり落とし穴があるため注意が必要です。
正解についての説明：
（選択肢）
・constraints/iam.disableServiceAccountKevCreation制約を組織に適用します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudのプロジェクト設計でセキュリティを確保するためには、JSONサービスアカウントキーの利用リスクを制御することが重要です。JSONサービスアカウントキーはクレデンシャルとして使用され、不当に取得されるとシステムに大きなリスクをもたらす可能性があります。
ここで提案されている"constraints/iam.disableServiceAccountKeyCreation"という制約は、組織全体に新たなJSONサービスアカウントキーの作成を禁止するものであり、これによりリスクを排除することができます。この制約を適用することで、サービスアカウントキー作成が無効化され、長期間のクレデンシャルに関連するリスクを軽減することができます。
また、この制約を適用すれば、それぞれのプロジェクトやサービスで個別に設定を変更するという運用上のオーバーヘッドを大幅に減らすことが可能となり、効率的な運用が可能となります。
不正解についての説明：
選択肢：定義済みロールのカスタムバージョンを使用して、すべてのiam.serviceAccountKeys.*サービスアカウントロールパーミッションを除外します
この選択肢が正しくない理由は以下の通りです。
定義済みロールのカスタムバージョンを使用して特定のパーミッションを除外するだけでは、JSONサービスアカウントキーに関連するリスクを完全に排除することはできません。
また、制約を使用する方が操作のオーバーヘッドを最小限に抑えられます。
選択肢：constraints/iam.disableServiceAccountKeyUpload制約を組織に適用します
この選択肢が正しくない理由は以下の通りです。
まず、制約constraints/iam.disableServiceAccountKeyUploadは、既に作成されたキーのアップロードを制限しますが、新たなJSONサービスアカウントキーの作成を防ぐものではありません。これはクライアントが懸念しているリスクを排除するためには不適切です。対照的に正解の選択肢は、新規キー作成を無効化し、問題を根本的に解決します。
選択肢：組織管理者のみにroles/iam.serviceAccountKeyAdmin IAMロールを付与します
この選択肢が正しくない理由は以下の通りです。
組織管理者のみにroles/iam.serviceAccountKeyAdmin IAMロールを付与するだけでは、JSONサービスアカウントキーの作成を完全に防ぐことができません。新たな管理者が登場した場合や権限が変わった場合等、インシデンとを引き起こす可能性がまだ残ってしまいます。
逆に、制約を組織全体に適用することで、管理者のロールにかかわらずサービスアカウントキーの作成を無効にする事が出来ます。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/identity/docs/how-to/setup#auth
https://cloud.google.com/iam/docs/understanding-service-accounts
</div></details>

### Q. 問題8: 未回答
Compute Engine上でアプリケーションサーバーをプールしています。最小限の構成で済み、開発者がトラブルシューティングのためにアプリケーションログに簡単にアクセスできる、安全なソリューションを提供する必要があります。
Google Cloud上でどのようにソリューションを実装しますか？

1. アプリケーションサーバにGoogle Cloud Operation Suiteロギングエージェントをデプロイします。開発者に、Google Cloud Operation Suiteにアクセスしてログを表示するIAM Logs Viewerロールを付与します
2. アプリケーションサーバーにgsutilコマンドラインツールをインストールします。アプリケーションログをCloud Storageバケットにアップロードするスクリプトをgsutilを使って書き、cronで5分ごとに実行するようにスケジュールします。開発者にIAM Object Viewerのアクセス権を付与し、指定したバケット内のログを閲覧できるようにします
3. アプリケーションサーバにGoogle Cloud Operation Suiteモニタリングエージェントをデプロイします。開発者に、Google Cloud Operation Suiteにアクセスしてメトリクスを表示するIAM Monitoring Viewerロールを付与します
4. アプリケーションサーバにGoogle Cloud Operation Suiteロギングエージェントをデプロイします。開発者に、Google Cloud Operation Suiteにアクセスしてログを表示するためのIAM Logs Private Logs Viewerロールを付与します
<details><div>
    答え：1
説明
この問題では、Compute Engine上でプールされているアプリケーションサーバーのログを、可能な限りシンプルなセットアップで、開発者がトラブルシューティングのために安全にアクセスできる方法が求められています。設問の形状から、Google Cloud内の適切なツールやロールを置くことで問題に対する最適な解決策を選択することが重要となります。それぞれの選択肢のデプロイやロール付与について理解すると同時に、セキュリティ維持と最小限の構成を保つことの重要性を考慮することが求められています。
基本的な概念や原則：
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。あらかじめ定義された機械タイプから選択するか、カスタムマシンタイプを作成して、必要なリソースに合わせてインスタンスを設定できます。
Google Cloud Operation Suite：Google Cloudの監視、トラブルシューティング、診断、アラート作成などの機能を提供する統合型ツールスイートです。
ロギングエージェント：ログを収集し、指定されたストレージ先に転送するソフトウェアです。Google Cloud Operation Suiteの一部として、アプリケーションログを自動的にGoogle Cloudのロギングサービスに送信します。
IAM Logs Viewerロール：Google Cloud IAM（Identity and Access Management）のロールの一つで、ユーザーにログを表示する権限を与えます。
モニタリングエージェント：システムやアプリケーションの動作を監視し、異常を検出するソフトウェアです。Google Cloud Operation Suiteの一部として働きます。
gsutil：Google Cloud Storageをコマンドラインから操作するためのツールです。バケットの作成や削除、オブジェクトのアップロードやダウンロードなど、多くの操作をサポートしています。
IAM Object Viewerロール：Google Cloud IAM（Identity and Access Management）のロールの一つで、ユーザーにオブジェクトの閲覧権限を与えます。
正解についての説明：
（選択肢）
・アプリケーションサーバにGoogle Cloud Operation Suiteロギングエージェントをデプロイします。開発者に、Google Cloud Operation Suiteにアクセスしてログを表示するIAM Logs Viewerロールを付与します
この選択肢が正解の理由は以下の通りです。
Google Cloud Operation SuiteはGoogle Cloudの一部であり、アプリケーションログを一元的に管理し、追跡できるため、開発者はこのツールを使用してアプリケーションのログに簡単にアクセスできます。Google Cloud Operation Suiteにはロギングエージェントが含まれています。アプリケーションサーバにこのロギングエージェントをデプロイすれば、アプリケーションログは自動的にGoogle Cloud Operation Suiteに転送され、一元化された場所でアクセス可能となります。この選択肢がさらに優れている点は、アクセス制御をIAMロールを通じて制御することができることです。開発者にIAM Logs Viewerロールを付与することで、開発者はログを表示するためだけの最低限の権限を持つことになり、サーバーやその他のリソースへの不適切なアクセスリスクが軽減されます。以上の理由により、この選択肢は最小限の構成で開発者がログに簡単にアクセスできる、そして安全なソリューションを提供するために適しています。
不正解についての説明：
選択肢：アプリケーションサーバにGoogle Cloud Operation Suiteロギングエージェントをデプロイします。開発者に、Google Cloud Operation Suiteにアクセスしてログを表示するためのIAM Logs Private Logs Viewerロールを付与します
この選択肢が正しくない理由は以下の通りです。
Google Cloudには"IAM Logs Private Logs Viewer"ロールというものは存在しません。
したがって、この選択肢は誤りです。正解の選択肢は開発者に"IAM Logs Viewer"ロールを付与することで、これにより開発者はアプリケーションのログを閲覧することができます。
選択肢：アプリケーションサーバにGoogle Cloud Operation Suiteモニタリングエージェントをデプロイします。開発者に、Google Cloud Operation Suiteにアクセスしてメトリクスを表示するIAM Monitoring Viewerロールを付与します
この選択肢が正しくない理由は以下の通りです。
課題はアプリケーションログへのアクセスですが、モニタリングエージェントはメトリクスを収集します、ログを収集するものではありません。
また、イベントの記録及び問題解析のためには、IAM Logs Viewerロールを使ってCloud Operation Suiteのログを開発者が見ることが必要です。
選択肢：アプリケーションサーバーにgsutilコマンドラインツールをインストールします。アプリケーションログをCloud Storageバケットにアップロードするスクリプトをgsutilを使って書き、cronで5分ごとに実行するようにスケジュールします。開発者にIAM Object Viewerのアクセス権を付与し、指定したバケット内のログを閲覧できるようにします
この選択肢が正しくない理由は以下の通りです。
gsutilとcronを使用してログをCloud Storageに定期的に移動することは、冗長で効率的でなく、またトラブルシューティングのためにリアルタイムのログが必要な場合、適切でない可能性があります。
対照的に、Cloud Operation Suiteロギングエージェントはリアルタイムのログを提供し、管理が簡単であり、開発者のトラブルシューティングにより適しています。
参考リンク：
https://cloud.google.com/logging/docs/agent
https://cloud.google.com/iam/docs/understanding-roles#logging-roles
https://cloud.google.com/logging/docs/view/overview
</div></details>

### Q. 問題9: 未回答
あなたのチームは、Google Cloudの内外にデプロイする新しいアプリケーションを設計しています。システムリソースの使用率などの詳細なメトリクスを収集する必要があります。この収集システムのセットアップに必要な作業量を最小限に抑えながら、一元化されたGoogle Cloudサービスを使用したいと考えています。
この要件を満たすために、どうすればよいですか？

1. Google Cloud Operation Suite Debuggerパッケージをインポートし、タイミング情報を含むデバッグメッセージを出力するようにアプリケーションを設定します
2. 両方のロケーションにアプリケーションパフォーマンスモニタリング（APM）ツールをインストールし、分析のために中央データストレージロケーションへのエクスポートを構成します
3. Google Cloud Operation Suite Profilerパッケージをインポートし、さらなる解析のためにGoogle Cloud Operation Suiteに関数のタイミングデータをリレーするように設定します
4. タイミングライブラリを使ってコードを計測し、Google Cloud Operation Suiteによってスクレイピングされるヘルスチェックエンドポイント経由でメトリクスを公開します
<details><div>
    答え：3
説明
この問題では、Google Cloudと他のプラットフォームにデプロイする新しいアプリケーションで詳細なメトリクスを収集し、それらメトリクスの設定に必要な作業量を最小限に抑えるための戦略が求められています。システムのメトリクスの収集のためのツールやサービスを選択する際のポイントとしては、その手軽さ、一元化への対応力、そしてGoogle Cloudとの互換性が考慮すべき特徴となります。またGoogle Cloud内外両方の環境で使用できることも求められています。そこで選択肢は、適切なGoogle Cloud Operation Suiteのパッケージかツール選択に関するものとなります。
基本的な概念や原則：
Google Cloud Operation Suite：Google Cloudの監視、トラブルシューティング、アプリケーションのパフォーマンス分析を行うための統合されたツールセットです。このツールを使用すると、システムに関する詳細な情報を容易に収集できます。
Profilerパッケージ：Google Cloud Operation Suiteの一部で、実行中のアプリケーションからのパフォーマンス情報を収集します。詳細なプロファイリングデータを提供し、ボトルネックの解析などに使用できます。
Debuggerパッケージ：Google Cloud Operation Suiteの一部のデバッグツールです。アプリケーションの動作を詳細に追跡し、エラーや不具合の原因を特定します。
タイミングライブラリ：コードの実行時間を計測するためのツールやライブラリです。これを使って特定の処理のパフォーマンスを測定することが可能です。
ヘルスチェック：システムの健全性をモニタリングするためのテストです。Google Cloud Operation Suiteはヘルスチェックの結果を監視し、問題があればアラートを出します。
アプリケーションパフォーマンスモニタリング（APM）ツール：アプリケーションのパフォーマンスを継続的に監視し、問題を検出するためのツールです。実行時間、エラーレートなどのパフォーマンス指標を収集します。
正解についての説明：
（選択肢）
・Google Cloud Operation Suite Profilerパッケージをインポートし、さらなる解析のためにGoogle Cloud Operation Suiteに関数のタイミングデータをリレーするように設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Operation Suite（旧Google Cloud Operation Suite）は、Google Cloudの内外で動作するアプリケーションの監視、トラブルシューティング、アラートのためのパワフルな監視ツールです。ここで提案されているCloud Operations Profilerは、Operations Suiteの一部であり、実行中のアプリケーションをプロファイリングし、関数のタイミングやシステムリソースの利用状況などの詳細なメトリクスを収集し分析します。この情報をCloud Operation Suiteにリレーすることで、すべての情報を一元化し、パフォーマンス分析や問題解決を容易にします。
また、Profilerパッケージをインポートするだけで、アプリケーションにプロファイリング機能を追加できるため、セットアップに必要な作業量を最小限に抑えることができます。これらの理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：Google Cloud Operation Suite Debuggerパッケージをインポートし、タイミング情報を含むデバッグメッセージを出力するようにアプリケーションを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite Debuggerパッケージは、主にアプリケーションの不具合を解析する仕組みで、詳細なメトリクスやリソース使用状況の収集を主な目的としていません。設問の要件は詳細なメトリクスの収集と一元化された管理を求めているため、Cloud Operation Suite Profilerパッケージの使用が適切です。
選択肢：タイミングライブラリを使ってコードを計測し、Google Cloud Operation Suiteによってスクレイピングされるヘルスチェックエンドポイント経由でメトリクスを公開します
この選択肢が正しくない理由は以下の通りです。
タイミングライブラリを使用してコードを計測すると、セットアップに必要な作業量が増えます。
一方、Google Cloud Operation Suite Profilerパッケージをインポートする方が作業量を最小限に抑えながら詳細なメトリクスを取得できます。
選択肢：両方のロケーションにアプリケーションパフォーマンスモニタリング（APM）ツールをインストールし、分析のために中央データストレージロケーションへのエクスポートを構成します
この選択肢が正しくない理由は以下の通りです。
APMツールを両方のロケーションにインストールする方法は、セットアップに必要な作業量を増大させます。
そして、中央データストレージロケーションへのエクスポートを構成しなければならない点も面倒な作業となります。
それに対し、Google Cloud Operation Suite Profilerパッケージを利用することで作業量が大幅に削減できます。
参考リンク：
https://cloud.google.com/profiler/docs/profiling-external
https://cloud.google.com/profiler/docs
https://cloud.google.com/monitoring/docs
</div></details>

### Q. 問題10: 未回答
Google Kubernetes Engine（GKE）クラスター全体にいくつかの制約テンプレートを適用する必要があります。制約には、Kubernetes APIを制限するなどのポリシーパラメータが含まれます。ポリシーパラメータがGitHubリポジトリに保存され、変更が発生したときに自動的に適用されるようにする必要があります。
この要件を満たすために、どうすればよいですか？

1. GitHubに変更があった場合、Webフックを使ってAnthos Service Meshにリクエストを送信し、変更を適用します
2. GitHubリポジトリでConfig Connectorを設定します。リポジトリに変更があった場合、Config Connectorを使用して変更を適用します
3. Anthos Config ManagementをGitHubリポジトリに設定します。リポジトリに変更があった場合、Anthos Config Managementを使って変更を適用します
4. パラメータが変更されたときにCloud BuildをトリガーするGitHubアクションを設定します。Cloud Buildで、gcloud CLIコマンドを実行して変更を適用します
<details><div>
    答え：3
説明
この問題では、Google Kubernetes Engine（GKE）クラスター全体に制約テンプレートを適用し、その設定がGitHubリポジトリで管理されている状況を想定しています。GitHubリポジトリの変更内容が自動的に反映される仕組みを構築するための適切なGoogle Cloudのサービスを選択する必要があります。GitHubリポジトリの変更発生時に自動的にポリシーを適用する方法について、これらの情報から適切な選択肢を考えることが求められています。Google Cloudの各サービスの特性や機能を理解し、それらが問題の要件や目的にどのように対応するのかを検討することが重要です。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：Google Cloudが提供するKubernetesクラスター管理サービスです。Kubernetesの実行環境を簡単に作成、管理できます。
制約テンプレート：ポリシーや制約を設定するためのテンプレートです。Kubernetes APIの制限など、特定のポリシーパラメータを含むことができます。
Anthos Config Management：Anthosの一部で、gitリポジトリに保存された設定をクラスター全体に適用する機能を提供します。
GitHubリポジトリ：ソークスコードや設定などを格納しているGitHubの保存領域です。コードの変更履歴を管理することができます。
Cloud Build：Google Cloudのフルマネージド型CI/CDプラットフォームです。ソースコードの変更を自動的に検出し、ビルド、テスト、デプロイを自動化することができます。
gcloud CLIコマンド：Google Cloudのコマンドラインツールです。このツールを使用して、Google Cloudのリソースを作成、管理することができます。
Config Connector：Google CloudのリソースをKubernetesのカスタムリソースとして管理するためのアドオンです。Google Cloudリソースの設定をKubernetesのマニフェスト形式で扱うことができます。
正解についての説明：
（選択肢）
・Anthos Config ManagementをGitHubリポジトリに設定します。リポジトリに変更があった場合、Anthos Config Managementを使って変更を適用します
この選択肢が正解の理由は以下の通りです。
まず、Anthos Config ManagementはGoogle Cloudが提供するサービスの一つで、一元化された制御、セキュリティ、シンプルさを提供することを目的としています。その一部として、Kubernetesのカスタムリソース定義（CRD）を使用して、クラスター間での設定の一貫性を維持します。
具体的には、Anthos Config ManagementはGitリポジトリを使用してKubernetesの設定を管理します。すなわち、ポリシーパラメータのような設定をGitHubリポジトリに保存し、それらの設定を直接キューブクラスターに適用することが可能です。
また、GitHubリポジトリの内容が変更されると、それがAnthos Config Managementによって自動的に検出され、適用されます。これにより、GitHubリポジトリとクラスターの設定との間に一貫性を持たせることができます。
以上の理由から、Anthos Config ManagementをGitHubリポジトリに設定することは、要件を満たす最適な解決策であると言えます。
不正解についての説明：
選択肢：パラメータが変更されたときにCloud BuildをトリガーするGitHubアクションを設定します。Cloud Buildで、gcloud CLIコマンドを実行して変更を適用します
この選択肢が正しくない理由は以下の通りです。
まず、Cloud Buildとgcloud CLIを用いたこの方法では、GitHubリポジトリに制約テンプレートの変更があるたびに手動でトリガーを設定し、適用対象のGKEクラスターを直接指定する必要があります。これに対してAnthos Config Managementは、一度設定することで自動的に変更を検知し適用します。そのため、制約テンプレートの自動適用という要件をより効率的に満たします。
選択肢：GitHubに変更があった場合、Webフックを使ってAnthos Service Meshにリクエストを送信し、変更を適用します
この選択肢が正しくない理由は以下の通りです。
Anthos Service Meshはサービス間の通信を管理し、制御することに特化したツールですが、制約テンプレートやポリシーパラメータの自動適用に関しては特に対応していません。
これに対して、Anthos Config Managementはポリシーの一元管理や自動適用に適したツールであり、正解の選択肢です。
選択肢：GitHubリポジトリでConfig Connectorを設定します。リポジトリに変更があった場合、Config Connectorを使用して変更を適用します
この選択肢が正しくない理由は以下の通りです。
Config ConnectorはKubernetesのリソースモデルを使用してGoogle Cloudリソースを管理しますが、Kubernetes APIを制限するなどの制約テンプレートの適用はサポートしていません。そのため、この要件を満たすAnthos Config Managementとは異なる動作を提供します。
参考リンク：
https://cloud.google.com/anthos-config-management/docs
https://cloud.google.com/kubernetes-engine/docs/concepts/policy-controller
https://github.com/kubernetes-sigs/kustomize
</div></details>

### Q. 問題11: 未回答
あなたは会社のマルチクラウド環境でアプリケーションのCI/CDパイプラインを実装しています。アプリケーションは、カスタムのCompute Engineイメージと他のクラウドプロバイダーの同等のものを使用してデプロイされます。現在の環境にイメージをビルドしてデプロイでき、将来の変更にも対応できるソリューションを実装する必要があります。どのソリューションスタックを使用すべきですか？

1. kptによるCloud Build
2. PackerによるCloud Build
3. Google Cloud DeployによるGoogle Kubernetes Engine
4. Google Cloud DeployによるCloud Build
<details><div>
    答え：2
説明
この問題では、マルチクラウド環境でのCI/CDパイプライン実装に焦点を当てています。選択肢を考える際の重要な要点は、アプリケーションがカスタムのCompute Engineイメージと他のクラウドプロバイダーの同等のものを使用してデプロイされていることです。このため、画像のビルドとデプロイに対応し、同時に将来の変更にも対応可能なソリューションを選択する必要があります。これは、複数のクラウド環境での操作と互換性をサポートするツールを特定するための鍵となります。
基本的な概念や原則：
Packer：HashiCorpが開発したオープンソースのツールで、さまざまなプラットフォームやクラウドサービスに対応したイメージを自動でビルドできます。マルチクラウド環境での利用が可能です。
Cloud Build：Google Cloudのフルマネージド型のCI/CDプラットフォームで、ソースコードからコンテナイメージやアプリケーションをビルドし、テストし、デプロイすることができます。
Compute Engineイメージ：Google Cloud上で仮想マシンを作成するときに使用するディスクイメージです。Compute Engineイメージを使ってアプリケーションをデプロイすることも可能です。
Google Cloud Deploy：Google Cloudのマネージドサービスで、安全で高速なソフトウェアデプロイを可能にします。
Google Kubernetes Engine（GKE）：Google CloudのフルマネージドKubernetesサービスで、コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を行うことができます。
kpt：Google Cloudのオープンソースツールで、Kubernetesアプリケーションのパッケージングと設定を管理します。
正解についての説明：
（選択肢）
・PackerによるCloud Build
この選択肢が正解の理由は以下の通りです。
まず、PackerはHashiCorpが提供するオープンソースのツールで、さまざまなプラットフォーム（例えば、Amazon EC2、VMware、Dockerなど）のための一貫した環境の構築を自動化する機能があります。これは、カスタムのCompute Engineイメージ、そして対象となるマルチクラウド環境の他クラウド上のイメージを作成する際に大いに役立ちます。
次に、Cloud BuildはGoogle Cloudのフルマネージド型のCI/CD（Continuous Integration & Continuous Deployment）プラットフォームで、ソースコードからコンテナイメージやアプリケーションのアーティファクトをビルドしたりテストしたりするために利用されます。Cloud BuildとPackerを組み合わせれば、イメージをビルドしデプロイするプロセスやそのアップデートに対応するCI/CDパイプラインを効率的に実装でき、マルチクラウド環境でのアプリケーションの配備や管理を効率化し、自動化することが可能となります。
不正解についての説明：
選択肢：Google Cloud DeployによるCloud Build
この選択肢が正しくない理由は以下の通りです。
Google Cloud Deployは、Google Cloud上でのデプロイメントの自動化を提供しますが、マルチクラウド環境のアプリケーションデプロイには適用できません。
一方、Packerを用いたCloud Buildは、多様なクラウド環境でのイメージのビルドとデプロイが可能で、この要件に適合します。
選択肢：Google Cloud DeployによるGoogle Kubernetes Engine
この選択肢が正しくない理由は以下の通りです。
Google Cloud DeployによるGoogle Kubernetes Engineは、デプロイメントの自動化を実現しますが、特定のCompute Engineイメージや他のクラウドプロバイダーのイメージを生成する能力がありません。
一方、PackerによるCloud Buildは、任意のイメージを自動的にビルドし、マルチクラウド環境でのデプロイを容易にするため、問題の要件を満たします。
選択肢：kptによるCloud Build
この選択肢が正しくない理由は以下の通りです。
kptはYAMLファイルのパッケージングとカスタマイゼーションを行うツールであり、Compute Engineのイメージのビルドやデプロイには対応しておりません。
一方、Packerは複数のプラットフォームで使用できるイメージを作成し、Cloud Buildと組み合わせることでCI/CDパイプラインを構築するのに適しています。
参考リンク：
https://cloud.google.com/build/docs/building/build-vm-images-using-packer
https://cloud.google.com/build
https://www.packer.io/docs/builders/googlecompute
</div></details>

### Q. 問題12: 未回答
アプリケーションコンテナイメージをビルドするために、Cloud BuildでCI/CDパイプラインを作成しています。アプリケーションコードはGitHubに保存されています。あなたの会社では、本番イメージビルドはメインブランチに対してのみ実行され、変更管理チームはメインブランチへのすべてのプッシュを承認する必要があります。イメージのビルドはできるだけ自動化したいと考えています。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. リポジトリ上のメインブランチにブランチ保護ルールを設定します
2. トリガーのIncluded filesフィルターにOWNERSファイルを追加します
3. Cloud Buildジョブにトリガーを作成します。リポジトリイベントの設定を"ブランチにプッシュ"に設定します
4. トリガーの承認オプションを有効にします
5. Cloud Buildジョブにトリガーを作成します。リポジトリイベント設定を"Pull request"に設定します
<details><div>
    答え：1,3
説明
この問題では、ユーザーがCI/CDパイプラインを設定し、特定のルールに従ってイメージのビルドを制御したいという要件を明らかにしています。具体的には、本番イメージビルドをメインブランチに限定し、メインブランチへの全てのプッシュが変更管理チームによって承認される必要があるという条件が述べられています。これらの要件を満たすために適切な選択肢が2つ求められています。選択肢を評価するときには、これらの特定の要件を満たす選択肢を適切に識別することが試験のポイントとなります。
基本的な概念や原則：
Cloud Build：ソースコードからソフトウェアアーティファクトをビルドするためのGoogle Cloudのサービスです。CI/CDパイプラインの自動化に利用します。
トリガー：Cloud Buildを特定のイベント（例えば、リポジトリ上のブランチへのプッシュ）に対して自動的に反応させるための設定です。
リポジトリ：ソースコードやその他のデータを保存し、履歴管理や共有を行うためのシステムです。GitHubはその一例です。
ブランチ保護ルール：Gitリポジトリへの変更を制限するための設定です。例えば、あるブランチへのプッシュを特定のユーザーやチームだけに制限することができます。
GitHub：ソフトウェア開発プロジェクトのためのホスティングプラットフォームです。Gitを用いてソースコードのバージョン管理を行います。
正解についての説明：
（選択肢）
・Cloud Buildジョブにトリガーを作成します。リポジトリイベントの設定を"ブランチにプッシュ"に設定します
・リポジトリ上のメインブランチにブランチ保護ルールを設定します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Buildジョブにトリガーを作成し、リポジトリイベントの設定を"ブランチにプッシュ"に設定することで、メインブランチに対する変更があるたびに自動的にビルドがトリガーされます。これによりイメージのビルドを効率的に自動化し、メインブランチに対してのみ本番イメージビルドを実行するという要件を満たします。
また、リポジトリ上のメインブランチにブランチ保護ルールを設定することで、変更管理チームがメインブランチへの全てのプッシュを承認する必要がなくなります。具体的には、ブランチ保護ルールを使用すれば、特定のブランチに対する直接のコミットやプッシュを制限したり、プルリクエストの承認やステータスチェックの成功などの条件を満たさなければマージができないように設定できます。これにより、不適切な変更がメインブランチに適用されることを防ぐことができます。この2つの手段を組み合わせることで、上記の要件を満たすことができます。
不正解についての説明：
選択肢：Cloud Buildジョブにトリガーを作成します。リポジトリイベント設定を"Pull request"に設定します
この選択肢が正しくない理由は以下の通りです。
"Pull request"に設定されたトリガーはプルリクエストの作成時にイメージのビルドが開始しますが、要件はメインブランチへのプッシュ時のみビルドを行うことです。そのため、リポジトリイベントの設定を"ブランチにプッシュ"に設定するのが正しいです。
選択肢：トリガーのIncluded filesフィルターにOWNERSファイルを追加します
この選択肢が正しくない理由は以下の通りです。
OWNERSファイルをIncluded filesフィルターに追加することで、特定のファイルの変更にトリガーを絞ることができます。しかし、変更管理チームがメインブランチへの全てのプッシュを承認するという要件には関連性がありません。
また、この方法ではビルドの自動化という目的にも寄与しません。正解の選択肢では、特定のブランチへのプッシュをトリガーに設定し、保護ルールで承認制を加えます。
選択肢：トリガーの承認オプションを有効にします
この選択肢が正しくない理由は以下の通りです。
Cloud Buildには"トリガーの承認オプション"を有効にする機能が存在しません。代わりにブランチ保護ルールを設定することで、メインブランチへのプッシュが変更管理チームによる承認を経てから行われるように制御することが可能です。
参考リンク：
https://cloud.google.com/build/docs/automating-builds/create-manage-triggers
https://cloud.google.com/build/docs/securing-builds/configure-access-control
https://docs.github.com/en/github/administering-a-repository/managing-branch-protection-rules
</div></details>

### Q. 問題13: 未回答
あなたの会社は、すべての組織のログを7年間保存することを要求する、高度に規制された産業に属しています。マネージドサービスを利用することで、ロギングインフラの複雑さを最小限に抑えたいと考えています。将来、設定ミスや人為的ミスによるログの取得や保存されたログの損失を回避する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. Cloud Loggingを使用して、組織レベルで集約されたシンクを構成し、7年間の保持ポリシーとバケットロックですべてのログをCloud Storageにエクスポートします
2. Cloud Loggingを使用して、各プロジェクトレベルでエクスポートシンクを構成し、すべてのログをBigQueryデータセットにエクスポートします
3. Cloud Loggingを使用して、組織レベルで集約シンクを構成し、すべてのログをBigQueryデータセットにエクスポートします
4. Cloud Loggingを使用して、各プロジェクトレベルでエクスポートシンクを構成し、7年間の保持ポリシーとバケットロックですべてのログをCloud Storageにエクスポートします
<details><div>
    答え：1
説明
この問題では、高度に規制された産業に属する会社がマネージドサービスを使用して、複雑なログインフラを最小限に抑えつつ、適切にロギングを行うための最善の方法が問われています。ロギングの要件として、ログは7年間保存され、設定ミスや人為的ミスによるログの損失を防ぐ必要がある点に注目すると良いでしょう。これらを踏まえると、ログの収集や保存、エクスポートの方法、そしてダウンタイムやミスの防止策などが選択肢を選ぶ観点となります。適切な保存場所、保持ポリシー、防止策を選択することがポイントです。
基本的な概念や原則：
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションとシステムのログを一元的に収集、分析、ストレージという一連のワークフローを可能にします。
組織レベルでの集約シンク：組織全体のログを一つの場所に集約する設定を指します。これにより、ログの管理を簡素化し、全体的な可視性を向上させます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。大量のデータを格納、分析、取得するためのサービスで、保持ポリシーとバケットロック機能を用いて長期間のログ保持が可能です。
保持ポリシー：指定した期間データを保存することを指定する設定を意味します。特定の業界規制や企業方針に準拠するために使用されます。
バケットロック：Cloud Storageの機能で、データの不変性を保証します。設定された保持期間中、バケット内のデータは変更や削除ができない様になります。
BigQuery：Google Cloudの大規模データ分析ツールです。ただし、一部の規制を満たすためにはCloud Storageを使用する必要がある場合もあります。
プロジェクトレベルでのエクスポートシンク：各プロジェクト毎のログを対象とする設定を指します。組織レベルでの設定に比べて、余計な設定や管理が増える可能性があります。
正解についての説明：
（選択肢）
・Cloud Loggingを使用して、組織レベルで集約されたシンクを構成し、7年間の保持ポリシーとバケットロックですべてのログをCloud Storageにエクスポートします
この選択肢が正解の理由は以下の通りです。
まず、Cloud LoggingはGoogle Cloudのマネージドサービスであり、アプリケーションとシステムのログを保管し分析するためのツールです。このサービスを使用することで、インフラの複雑さを大いに減らすことができます。
ここでは、組織レベルでのシンクの設定が求められています。シンクは、特定のログエントリをフィルタリングして他のGoogle Cloudサービスにエクスポートするための機能です。組織レベルでシンクを設定することによって、すべての組織のログを包括的に管理できます。
次に、ログをCloud Storageにエクスポートするというアプローチも 制約に適しています。Cloud Storageは大量のデータを安全に、長期間保存するためのサービスであるため、7年間の保持要件を満たすことができます。
最後に、バケットロックはオブジェクトの削除を防ぐ保護機能で、設定ミスや人為的なミスからデータを保護することができます。これにより、一度保存されたログが未然に消失することを防ぐことができます。
DevOps 向けに Google Cloud 組織をブートストラップする
選択肢：Cloud Loggingを使用して、組織レベルで集約シンクを構成し、すべてのログをBigQueryデータセットにエクスポートします
この選択肢が正しくない理由は以下の通りです。
 
BigQueryデータセットは、長期間のログ保存に最適ではありません。BigQueryは主に分析クエリ実行用のツールであり、それによって発生するコストは7年間のログ保持に対しては配慮すべき要素です。Cloud Storageの方が長期保管に適しており、バケットロック機能も利用できます。
 
選択肢：Cloud Loggingを使用して、各プロジェクトレベルでエクスポートシンクを構成し、すべてのログをBigQueryデータセットにエクスポートします
この選択肢が正しくない理由は以下の通りです。
 
BigQueryデータセットへのエクスポートではなく、Cloud Storageへのエクスポートを選択する理由は、Cloud Storageがバケットロックという機能を提供していて、これにより設定ミスや人為的ミスによるログの損失を防ぐことが可能だからです。
 
また、各プロジェクトレベルでシンクを設定するよりも、組織全体で一度にロギング設定を行う方が効率的です。
 
選択肢：Cloud Loggingを使用して、各プロジェクトレベルでエクスポートシンクを構成し、7年間の保持ポリシーとバケットロックですべてのログをCloud Storageにエクスポートします
この選択肢が正しくない理由は以下の通りです。
 
プロジェクトレベルでのエクスポートシンク構成では、一部のプロジェクトで設定ミスが発生しやすく、全組織のログを完全にカバーするのが困難です。
 
また、プロジェクト数が多い場合、管理が煩雑になる可能性があります。反対に組織レベルでシンクを構成すると、一元管理が可能で、全組織のログが適切に保存されることを担保できます。
 
参考リンク：
https://cloud.google.com/logging/docs/storage
 
https://cloud.google.com/storage/docs/using-bucket-lock
 
https://cloud.google.com/logging/docs/aggregated-exports
 
</div></details>

### Q. 問題14: 未回答
Google Cloudでコンテナ化されたアプリケーションのCI/CDパイプラインを構築する必要があります。開発チームは、トランクベースの開発のために中央のGitリポジトリを使用しています。あなたは、品質を向上させるために、アプリケーションの新しいバージョンに対してパイプラインですべてのテストを実行したいと考えています。
この要件を満たすために、どうすればよいですか？

1. 1.Cloud Buildをトリガーしてアプリケーションコンテナをビルドし、コンテナでユニットテストを実行します
2.単体テストが成功したら、アプリケーションコンテナをテスト環境にデプロイし、統合テストを実行します
3.統合テストが成功したら、パイプラインはアプリケーションコンテナを本番環境にデプロイします。その後、受け入れテストを実行します
2. 1.コードを中央リポジトリにプッシュする前にユニットテストを実行するよう、開発者に要求するGitフックをインストールします
2.Cloud Buildをトリガーしてアプリケーションコンテナをビルドします。アプリケーションコンテナをテスト環境にデプロイし、統合テストを実行します
3.統合テストが成功したら、アプリケーションコンテナを本番環境にデプロイし、受け入れテストを実行します
3. 1.Gitフックをインストールして、開発者が中央リポジトリにコードをプッシュする前にユニットテストを実行するようにします。すべてのテストが成功したら、コンテナをビルドします
2.Cloud Buildをトリガーして、アプリケーションコンテナをテスト環境にデプロイし、統合テストと受け入れテストを実行します
3.すべてのテストに成功したら、コードを本番環境としてタグ付けします。Cloud Buildをトリガーして、アプリケーションコンテナをビルドし、本番環境にデプロイします
4. 1.コードがプッシュされると、Cloud Buildをトリガーしてユニットテストを実行します。すべてのユニットテストが成功したら、アプリケーションコンテナをビルドして中央レジストリにプッシュします
2.Cloud Buildをトリガーして、コンテナをテスト環境にデプロイし、統合テストと受け入れテストを実行します
3.すべてのテストが成功した場合、パイプラインはアプリケーションを本番環境にデプロイし、スモークテストを実行します
<details><div>
    答え：4
説明
この問題では、トランクベースの開発を行っている開発チームのために品質向上を目指したCI/CDパイプラインを構築する方法を選びます。具体的には、アプリケーションの新しいバージョンに対して、パイプライン内で全てのテストを実行したいとの要望があるので、アプリケーションの変更を持ち込む際にテストを組み込むことで品質を確保するシナリオを選ばなければなりません。この要求を満たすためには、Google CloudのCI/CDツールに対する理解と、効率的なテストとデプロイのフローについての知識が必要です。
基本的な概念や原則：
Cloud Build：Google Cloudの完全マネージド型のビルドサービスです。ソースコードからコンテナイメージやアプリケーションのアーティファクトをビルドし、テストすることができます。
CI/CDパイプライン：継続的インテグレーション（CI）と継続的デリバリー（CD）を組み合わせた開発プロセスです。コードの変更を自動的にビルド、テスト、デプロイすることで、高速かつ安定したソフトウェアリリースを支援します。
ユニットテスト：コードの一部（ユニット）が期待通りに動作するかを確認するテストです。全体の機能を保証するための基礎となります。
統合テスト：複数のユニットを組み合わせて、それらが正しく協調して働くかを確認するテストです。単体で動作したユニットが組み合わさったときにも動作保証をします。
スモークテスト：アプリケーションの主要機能が全体的に動作するか確認する基本的なテストです。デプロイの成功を素早く確認します。
正解についての説明：
（選択肢）
・1.コードがプッシュされると、Cloud Buildをトリガーしてユニットテストを実行します。すべてのユニットテストが成功したら、アプリケーションコンテナをビルドして中央レジストリにプッシュします
2.Cloud Buildをトリガーして、コンテナをテスト環境にデプロイし、統合テストと受け入れテストを実行します
3.すべてのテストが成功した場合、パイプラインはアプリケーションを本番環境にデプロイし、スモークテストを実行します
この選択肢が正解の理由は以下の通りです。
まず、プッシュされたコードに対してCloud Buildを使用してユニットテストを実行することで、新しいバージョンのアプリケーションの基本的な動作確認ができます。ユニットテストの目的は、早い段階で問題を見つけ出し修正することで、アプリケーションの品質を確保することです。
次に、ユニットテストが成功した後にコンテナをビルドし、中央レジストリにプッシュすることで、そのコンテナのバージョン管理が可能になります。テスト環境にデプロイし、統合テストと受け入れテストを実行することで、アプリケーション全体の動作確認ができ、予期しないバグや問題を発見することができます。
最後に、すべてのテストが成功した場合にのみ、アプリケーションを本番環境にデプロイし、スモークテストを実行します。これにより、リリース直後の深刻な問題をすぐに検出することができます。これらの手順はCI/CDパイプラインのステージごとにテストを実行することで、品質を向上させるためのビルドからデプロイまでの操作を自動化します。
不正解についての説明：
選択肢：1.コードを中央リポジトリにプッシュする前にユニットテストを実行するよう、開発者に要求するGitフックをインストールします
2.Cloud Buildをトリガーしてアプリケーションコンテナをビルドします。アプリケーションコンテナをテスト環境にデプロイし、統合テストを実行します
3.統合テストが成功したら、アプリケーションコンテナを本番環境にデプロイし、受け入れテストを実行します
この選択肢が正しくない理由は以下の通りです。
不正解選択肢は、コードがリポジトリにプッシュされる前にユニットテストを行うため、開発者がユニットテストをスキップしたり失敗してもプッシュしたりする可能性があります。しかし、正解選択肢では、コードがプッシュされると自動的にユニットテストが行われ、その結果次の段階に進めるかが決定されます。これは自動化と一貫性を確保するためのより良いアプローチです。
選択肢：1.Gitフックをインストールして、開発者が中央リポジトリにコードをプッシュする前にユニットテストを実行するようにします。すべてのテストが成功したら、コンテナをビルドします
2.Cloud Buildをトリガーして、アプリケーションコンテナをテスト環境にデプロイし、統合テストと受け入れテストを実行します
3.すべてのテストに成功したら、コードを本番環境としてタグ付けします。Cloud Buildをトリガーして、アプリケーションコンテナをビルドし、本番環境にデプロイします
この選択肢が正しくない理由は以下の通りです。
ユニットテストを開発者がコードをプッシュする前に行うというアプローチは、テストの速度と信頼性を損なう恐れがあります。
また、コンテナはすべてのテストが成功した後にのみビルドされるべきで、すべてのテストが成功した段階で本番環境としてタグ付けするという手順は効率的ではありません。正しいのは、まずコードがプッシュされたときにCloud Buildをトリガーしてすべてのテストを行い、その結果次第でコンテナのビルドとデプロイを行う手順です。
選択肢：1.Cloud Buildをトリガーしてアプリケーションコンテナをビルドし、コンテナでユニットテストを実行します
2.単体テストが成功したら、アプリケーションコンテナをテスト環境にデプロイし、統合テストを実行します
3.統合テストが成功したら、パイプラインはアプリケーションコンテナを本番環境にデプロイします。その後、受け入れテストを実行します
この選択肢が正しくない理由は以下の通りです。
まず、ユニットテストはビルド前に実施するべきで、ビルド後に行うと再ビルドの必要性や不必要なリソース使用を引き起こします。
また、スモークテストが含まれていない点も問題です。本番環境へデプロイ後に一定の機能を確認するスモークテストは重要で、これがないとデプロイ直後のアプリケーションの安定性確認が行えません。
参考リンク：
https://cloud.google.com/build/docs/automating-builds/build-repos-from-github
https://cloud.google.com/build/docs/deploying-builds/deploy-cloud-run
https://docs.docker.com/ci-cd/github-actions/
</div></details>

### Q. 問題15: 未回答
間もなく公開されるサービスのCloud Monitoring SLOを作成する必要があります。サービスに対するリクエストが、毎月あたり少なくとも90% の割合で300ms未満で処理されることを検証したいと考えています。使用するメトリックと評価方法を特定する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. リクエストベースの評価方法として、可用性の指標を選択します
2. ウィンドウベースの評価方法でレイテンシメトリックを選択します
3. ウィンドウベースの評価方法で、可用性の指標を選択します
4. リクエストベースの評価方法として、待ち時間の指標を選択します
<details><div>
    答え：4
説明
この問題では、サービスのパフォーマンスを評価するための適切なメトリックと評価方法を選択する必要があります。ここでのキーポイントは、リクエストが毎月あたり少なくとも90%の割合で300ms未満で処理されることを検証したいという目標です。したがって、この目標に合致するようなメトリックと評価方法を特定する必要があります。
基本的な概念や原則：
Cloud Monitoring：Google Cloudの監視、ログ記録、診断のためのフルスタックソリューションです。アプリケーションのパフォーマンス、可用性を監視し、問題発生時にアラートを作成します。
SLO（Service Level Objectives）：サービスレベル目標です。サービスの目標パフォーマンスを定義したもので、具体的な数値目標を含むことが一般的です。
リクエストベースの評価：個々のリクエストの成功または失敗を判定するために使用される評価方法です。
待ち時間メトリック：リクエストがどれだけ早く処理されたかを測定する指標です。一般的には、低い値がより良いパフォーマンスを意味します。
ウィンドウベースの評価：特定の時間窓内の成功率または失敗率を判定するために使用される評価方法です。
可用性メトリック：システムやサービスが機能しているかどうかを示す指標です。一般的には、高い値がより良いパフォーマンスを意味します。
正解についての説明：
（選択肢）
・リクエストベースの評価方法として、待ち時間の指標を選択します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Monitoringを使用してサービスレベル目標（SLO）を作成する場合、評価方法として特定のメトリックを選択します。SLOが要求された特性（この場合はリクエストの応答速度）に対する期待値を設定するためのガイドライン提供します。
待ち時間メトリックは、サービスの応答速度を監視するのに適しています。これは明確に"リクエストが300ミリ秒以内で処理されるべき"というSLOを測定するための指標となります。リクエストベースの評価方法を選択することで、毎月の90%達成率を定期的に確認することが容易になります。そのため、この選択肢は要件を正確に満たすことができると言えます。
不正解についての説明：
選択肢：ウィンドウベースの評価方法でレイテンシメトリックを選択します
この選択肢が正しくない理由は以下の通りです。
ウィンドウベースの評価方法は、一定期間内に特定の状態にあった時間の割合を測定するためのものです。今回の目的はリクエストが一定時間内に処理される割合を計測することなので、リクエストベースの評価方法が適しています。
選択肢：リクエストベースの評価方法として、可用性の指標を選択します
この選択肢が正しくない理由は以下の通りです。
サービスがリクエストを300ms未満で処理することを確認するために、待ち時間の指標が最も適当です。可用性の指標では、リクエストがどれだけ早く処理されるかを検証することはできず、サービスが利用可能であるかどうかを評価できます。これは今回の要件とは一致しません。
選択肢：ウィンドウベースの評価方法で、可用性の指標を選択します
この選択肢が正しくない理由は以下の通りです。
ウィンドウベースの評価方法と可用性の指標は、公開されたサービスが稼働している時間の割合を測定するのに適していますが、リクエストが特定の時間（300ms未満）で処理される割合を検証するには不適切です。
一方、リクエストベースの評価方法と待ち時間の指標は、各リクエストの処理時間を直接的に測定し、それらが設定値以内に収まっている割合を検証するのに適しています。
参考リンク：
https://cloud.google.com/monitoring/service-level-objectives#performance_slo
https://cloud.google.com/monitoring/api/metrics
https://www.oreilly.com/library/view/google-cloud-for/9781492057676/
</div></details>

### Q. 問題16: 未回答
あなたの組織は、サイト信頼性エンジニアリング（SRE）の文化と原則を導入したいと考えています。最近、あなたがサポートするサービスに限定的な障害が発生しました。他のチームのマネージャーは、彼らが改善策を講じることができるように、何が起こったのかについて正式な説明を提供するようあなたに求めています。
この要件を満たすために、どうすればよいですか？

1. 根本原因、解決策、学んだ教訓、優先順位をつけたアクションアイテムのリストを含むポストモーテムを作成します。これを、マネージャーとだけ共有します
2. 根本原因、解決策、学んだ教訓、責任者のリスト、各人のアクションアイテムのリストを含むポストモーテムを作成します。これをエンジニアリング組織の文書ポータルで共有します
3. 根本原因、解決策、学んだ教訓、責任者のリスト、各人のアクションアイテムのリストを含むポストモーテムを作成します。これを、マネージャーとだけ共有します
4. 根本原因、解決策、学んだ教訓、優先順位をつけたアクションアイテムのリストを含むポストモーテムを作成します。これをエンジニアリング組織の文書ポータルで共有します
<details><div>
    答え：4
説明
この問題では、サイト信頼性エンジニアリング（SRE）の文化を組織に浸透させるためのアプローチについて問われています。特に、障害発生後の対応として、どのように情報を共有し、各チームが改善策を講じることができるようにするかに焦点が置かれています。ここで重要なのは、ポストモーテムの内容と、それをどの範囲で共有するかです。情報を適切に共有することで、組織全体が共有しやすいSREの文化を醸成することができます。したがって、情報の詳細性と共有範囲に注意しながら選択肢を読み解くことが必要です。
基本的な概念や原則：
サイト信頼性エンジニアリング（SRE）：ソフトウェアエンジニアリングの原則をインフラストラクチャと運用の問題に適用することで、システムの信頼性、可用性、性能を向上させる方法です。
ポストモーテム：障害やインシデントが発生した後に行われる分析で、根本原因、解決策、学んだ教訓、優先順位付けされた行動アイテムを明らかにします。これにより、同様の問題が再発するのを防ぐことが目的です。
根本原因分析：問題の真の原因を特定し、それが再発しないようにするためのプロセスです。これにより、問題が再発するのを防ぐための改善策を立案することができます。
学んだ教訓：プロジェクトやタスクの完了後、またはインシデントの発生後に得られる知識や経験です。これにより、将来のプロジェクトやインシデント対応の効率化や改善が可能となります。
優先順位付けされた行動アイテム：特定の問題を解決するために実行する必要があるタスクのリストです。これは優先順位付けされ、最も重要なものから実行されます。
透明性：SREの核心的な原則の一つで、インシデントの詳細を関係者全員と共有することです。これにより、全員が同じ理解を持ち、効果的に対応することが可能となります。
正解についての説明：
（選択肢）
・根本原因、解決策、学んだ教訓、優先順位をつけたアクションアイテムのリストを含むポストモーテムを作成します。これをエンジニアリング組織の文書ポータルで共有します
この選択肢が正解の理由は以下の通りです。
SREの文化は、障害性や問題の反射的な改善、学習に重心が置かれています。問題や障害が発生したときには、問題の深層的な解析を通じて根本原因を把握し、解決策を練り、学んだ教訓を共有、そして問題を再発させないための具体的なアクションプランを立てることが求められます。このプロセスは、多くの場合、"ポストモーテム"と称される文書にまとめられます。その結果をエンジニアリング組織全体で共有することで、同じ問題が再発するのを防いだり、他のチームが類似の問題に直面したときに役立てたりすることができます。
したがって、一連の問題解析とその結果をまとめたポストモーテムを作成し、それをエンジニアリング組織全体で共有することが、SRE文化導入に沿った適切な対応と言えます。
不正解についての説明：
選択肢：根本原因、解決策、学んだ教訓、優先順位をつけたアクションアイテムのリストを含むポストモーテムを作成します。これを、マネージャーとだけ共有します
この選択肢が正しくない理由は以下の通りです。
サイト信頼性エンジニアリング（SRE）の原則には透明性が含まれており、限定的な障害に対するポストモーテムの共有はマネージャーだけでなくエンジニアリング組織全体に対して行うべきです。このような全体的な共有により、組織全体での学習と改善が促進されます。
選択肢：根本原因、解決策、学んだ教訓、責任者のリスト、各人のアクションアイテムのリストを含むポストモーテムを作成します。これを、マネージャーとだけ共有します
この選択肢が正しくない理由は以下の通りです。
SREの原則は共有と透明性を重視します。
したがって、ポストモーテムはマネージャーだけではなく、エンジニアリング組織全体で共有するべきです。
また、アクションアイテムは優先順位付けされ、個々の人に対する責任付けよりも、問題解決のアプローチに重点が置かれるべきです。
選択肢：根本原因、解決策、学んだ教訓、責任者のリスト、各人のアクションアイテムのリストを含むポストモーテムを作成します。これをエンジニアリング組織の文書ポータルで共有します
この選択肢が正しくない理由は以下の通りです。
ポストモーテムの目的は改善策のための共有と学習であり、特定の人を責任者として抽出することを目的としていません。個々の人のアクションアイテムも個人を非難するものになりかねません。そのため、これはSREの文化と一致していません。正解の選択肢と比べますと、この選択肢は文化的な側面に配慮していません。
参考リンク：
https://cloud.google.com/incident-response/docs/postmortem-culture
https://cloud.google.com/sre
https://landing.google.com/sre/sre-book/chapters/postmortem-culture/
</div></details>

### Q. 問題17: 未回答
新しいサービスを本番環境にデプロイする必要があります。サービスはマネージドインスタンスグループ（MIG）を使用して自動的にスケールする必要があり、複数のリージョンにデプロイする必要があります。このサービスは各インスタンスに多数のリソースを必要とするため、キャパシティを計画する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. サービスを1つのリージョンに配備し、グローバルロードバランサーを使ってこのリージョンにトラフィックをルーティングします
2. MIGのコンフィギュレーションでn1-highcpu-96マシンタイプを使用します
3. リソース要求が各リージョンの利用可能なクォータ制限内であることを検証します
4. Google Cloud Operation Suite Traceの結果を監視し、必要なリソースの量を決定します
<details><div>
    答え：3
説明
この問題では、新しいサービスを本番環境にデプロイする際のリソース管理とスケーリング戦略について考える必要があります。サービスはマネージドインスタンスグループ（MIG）を使って自動的にスケールし、複数のリージョンにデプロイされるべきで、各インスタンスには大量のリソースが必要とされています。ここで重要なのは、リソース要求が各リージョンの利用可能なクォータ制限内であるかどうかを検証しなければならないという点です。つまり、製品のデプロイメントとスケーリングに必要なリソースの需要と供給を正確に理解し、それが各リージョンのクォータ内に収まるように計画することが求められています。
基本的な概念や原則：
マネージドインスタンスグループ（MIG）：同一の設定を持つ仮想マシン（VM）の集合を管理するサービスです。自動スケーリングやロードバランシング、VMのヘルスチェック等が可能です。
クォータ：Google Cloud上で利用できるリソースの最大数です。リージョンごとに異なる可能性があり、注意深く管理する必要があります。
Google Cloud Operation Suite Trace：アプリケーションのパフォーマンスモニタリングを行うサービスです。サービス間の呼び出し依存関係を可視化し、パフォーマンス問題を特定しやすくします。
グローバルロードバランサー：リージョン間でトラフィックの分散を行うサービスです。マルチリージョン展開のアプリケーションで用いられ、トラフィックをユーザーに最も近いリージョンに自動的にルーティングします。
正解についての説明：
（選択肢）
・リソース要求が各リージョンの利用可能なクォータ制限内であることを検証します
この選択肢が正解の理由は以下の通りです。
全てのGoogle Cloudプロジェクトにはリージョン毎に利用可能な各種リソースに対するクォータ制限が設定されており、それを超える使用は許可されません。これは、ユーザーが無意識にリソースを過剰に消費することを防ぎ、さらにGoogle Cloudのリソースが適切に配分されることを確認するための重要な管理ツールです。
したがって、新しいサービスを複数のリージョンにデプロイし、マネージドインスタンスグループ（MIG）を使用して自動的にスケールさせる場合、そのサービスが各インスタンスに多数のリソースを必要とするため、初めに利用可能なクォータ制限内であることを検証することが必要となります。これにより、本番環境でのサービスデプロイメントがスムーズに行え、予期せぬ中断が避けられます。
不正解についての説明：
選択肢：MIGのコンフィギュレーションでn1-highcpu-96マシンタイプを使用します
この選択肢が正しくない理由は以下の通りです。
n1-highcpu-96マシンタイプを使用するだけでは、サービスが各インスタンスに多数のリソースを必要とするためのキャパシティを計画するという要件は満たせません。反対に、リソース要求が各リージョンの利用可能なクォータ制限内であることを検証する方が、キャパシティ計画を行う適切なアプローチとなります。
選択肢：Google Cloud Operation Suite Traceの結果を監視し、必要なリソースの量を決定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite Traceはアプリケーションのパフォーマンス問題を診断するツールであり、キャパシティ計画のための具体的なリソース要求量を提供するものではありません。
一方、各リージョンのクォータ制限内にリソース要求があることを確認するのは、サービスを複数のリージョンにデプロイし、適切にスケールするために必要です。
選択肢：サービスを1つのリージョンに配備し、グローバルロードバランサーを使ってこのリージョンにトラフィックをルーティングします
この選択肢が正しくない理由は以下の通りです。
問題文はサービスが複数のリージョンにデプロイされるべきであることを明示していますが、この選択肢はサービスを1つのリージョンに配置することを提案しています。これは問題の要件を満たしていません。
それに対して、正解はMIGを使用して複数のリージョンにデプロイするためのリソース計画を行うことを提案しており、要件に適合します。
参考リンク：
https://cloud.google.com/compute/docs/instance-groups/managing-groups
https://cloud.google.com/compute/quotas
https://cloud.google.com/compute/docs/regions-zones/global-regional-zonal-resources#globalresources
</div></details>

### Q. 問題18: 未回答
あなたはインフラストラクチャを定義するTerraformテンプレートの作成と修正を担当します。2人の新しいエンジニアが同じコードで作業することになるため、お互いのコードを上書きしないようなプロセスを定義し、ツールを採用する必要があります。また、すべてのアップデートを最新バージョンに取り込むことも必要です。
この要件を満たすために、どうすればよいですか？

1. コードをテキストファイルとしてGoogle Driveに保存し、ファイルを整理するフォルダ構造を定義します。毎日の終わりに、すべての変更がフォルダ構造内のファイルに取り込まれたことを確認します。フォルダ構造の名前を、バージョンをインクリメントする定義済みの命名規則で変更します
2. コードをGitベースのバージョン管理システムに保存します。コードを統合する前に、ピアコードレビューや、整合性と機能性を保証する単体テストを含むプロセスを確立します。リポジトリに完全に統合されたコードが最新のマスターバージョンになるプロセスを確立します
3. コードをテキストファイルとしてGoogle Driveに保存し、ファイルを整理するフォルダ構造を定義します。毎日の終わりに、すべての変更がフォルダ構造内のファイルに取り込まれたことを確認し、定義済みの命名規則で新しい.zipアーカイブを作成します。.zipアーカイブをバージョン管理されたCloud Storageバケットにアップロードし、最新バージョンとして受け入れます
4. コードをGitベースのバージョン管理システムに保存します。毎日の終わりに、開発者が自分の変更をマージできるプロセスを確立します。コードをパッケージ化し、最新のマスターバージョンとしてバージョン管理されたCloud Storageバスケットにアップロードします
<details><div>
    答え：2
説明
この問題では、何人ものエンジニアが同じコードに対して編集を行う状況下で、コードの競合を防ぎながら全てのアップデートを最新バージョンに統合するためのプロセスとツールの選択が求められています。バージョン管理システムであるGitが適切か、あるいはテキストファイルを保存するツールで対応するか、そのプロセスをどのように設定すべきかを探る問題です。重要な観点としては、コードの更新を適切に反映し競合を防ぐメカニズムと、全てのアップデートを最新バージョンに統合する効率的なプロセスが必要です。
基本的な概念や原則：
Terraform：インフラストラクチャーをコードで管理するためのオープンソースのツールです。一貫した方法でサービスやリソースを作成、更新、削除することができます。
Git：ソースコードのバージョン管理を行うためのツールです。複数人での開発を支援し、コードの上書きを防ぐためのブランチ機能や、バージョンの記録と復元が可能です。
ピアコードレビュー：他の開発者がコードを確認し、バグの特定やコード品質の向上を支援するプロセスです。同じチームのメンバーが互いのコードをレビューして、問題点を見つけ出します。
単体テスト：コードの正確性と品質を確認するためのテストです。特定の機能やメソッドが期待通りに動作することを確認します。
バージョン管理システム：ソースコードの変更履歴を管理するためのシステムです。複数人での開発作業を円滑に進めるために利用されます。
Google Drive：ファイルの保存と共有を行うためのCloud Storageサービスです。コードの保存場所としては適していません。
Cloud Storageバケット：Google Cloud Storageの基本的なコンテナです。データを格納するために使用され、バージョン管理の機能も提供します。
正解についての説明：
（選択肢）
・コードをGitベースのバージョン管理システムに保存します。コードを統合する前に、ピアコードレビューや、整合性と機能性を保証する単体テストを含むプロセスを確立します。リポジトリに完全に統合されたコードが最新のマスターバージョンになるプロセスを確立します
この選択肢が正解の理由は以下の通りです。
まず、Gitベースのバージョン管理システムの導入により、複数のエンジニアが同時にコードを編集しても、お互いの作業を上書きせず、また各自が作成や変更したコードのバージョンを追跡することが可能になります。このシステムがあれば、作業が重複したり、意図しない変更が加えられることを防ぐことができます。
また、ピアコードレビューのプロセスを設けることで、コードが統合される前に他のエンジニアによる検討とフィードバックが得られます。これにより、一貫性のあるアーキテクチャを維持し、品質を向上させることができます。
さらに、単体テストの導入により、変更がシステムの整合性や機能性に影響を与えないことを確認します。これは、エンジニアがコードを統合する前に、バグやエラーがないかどうかを検証する一環として不可欠です。
最後に、リポジトリの最新マスターバージョンとして完全に統合されたコードを採用するプロセスを確立することで、全てのアップデートを最新バージョンに取り込むという要件も満たせます。
不正解についての説明：
選択肢：コードをGitベースのバージョン管理システムに保存します。毎日の終わりに、開発者が自分の変更をマージできるプロセスを確立します。コードをパッケージ化し、最新のマスターバージョンとしてバージョン管理されたCloud Storageバスケットにアップロードします
この選択肢が正しくない理由は以下の通りです。
ただマージもしくはアップロードをするだけでは、コードの整合性及び機能性を保証するプロセスが存在しないため、互いのコードを上書きしないような状況を作ることが難しいです。
また、単に最新マスターバージョンをCloud Storageにアップロードするだけでは、バージョン管理がしっかりと行えていない可能性もあります。
選択肢：コードをテキストファイルとしてGoogle Driveに保存し、ファイルを整理するフォルダ構造を定義します。毎日の終わりに、すべての変更がフォルダ構造内のファイルに取り込まれたことを確認します。フォルダ構造の名前を、バージョンをインクリメントする定義済みの命名規則で変更します
この選択肢が正しくない理由は以下の通りです。
Google Driveにテキストファイルを保存するのは、拡張性が低く、バージョン管理やエンジニア間のコード上書き防止が困難です。ピアレビューやテスト機能も提供されていないため、コードの整合性と機能性の保証ができません。
一方、Gitのバージョン管理システムはこれらの問題を解決し、効率的な作業を可能にします。
選択肢：コードをテキストファイルとしてGoogle Driveに保存し、ファイルを整理するフォルダ構造を定義します。毎日の終わりに、すべての変更がフォルダ構造内のファイルに取り込まれたことを確認し、定義済みの命名規則で新しい.zipアーカイブを作成します。.zipアーカイブをバージョン管理されたCloud Storageバケットにアップロードし、最新バージョンとして受け入れます
この選択肢が正しくない理由は以下の通りです。
この方法では、複数のエンジニアが同時にコードを編集する場合、相互にコードを上書きする可能性があります。
また、Google Driveや.zipアーカイブはコードのバージョン管理には不適切で効率的ではありません。Gitなどのバージョン管理システムを使用することで、各エンジニアの変更を追跡し、必要に応じてマージできます。
参考リンク：
https://cloud.google.com/solutions/devops/devops-tech-version-control
https://cloud.google.com/architecture/devops/devops-process-promoting-and-deploying
https://www.terraform.io/docs/cli-index.html
</div></details>

### Q. 問題19: 未回答
あなたは、Google Kubernetes Engine（GKE）上で動作する本番アプリケーションの問題を調査しています。あなたは、コードの正確な変更は特定されていないものの、問題の原因が最近更新されたコンテナイメージであると判断しました。デプロイは現在、最新のタグを指しています。意図したとおりに機能するコンテナのバージョンを実行するようにクラスターを更新する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. 以前のGitタグから新しいコンテナをビルドし、新しいコンテナへのデプロイでローリングアップデートを行います
2. デプロイメントを変更し、以前作業していたコンテナのsha256ダイジェストを指すようにします
3. 以前に作業していたコンテナを指すstableという新しいタグを作成し、新しいタグを指すようにデプロイメントを変更します
4. 最新のタグを以前のコンテナイメージに適用し、デプロイメントのローリングアップデートを行います
<details><div>
    答え：2
説明
この問題では、GKEにデプロイされているアプリケーションの問題を解決するための適切な手順について尋ねています。問題は更新されたコンテナイメージにあると判断されており、機能していたバージョンに戻す必要があることが分かります。この問題を解く上で、特に重要なのは、GKEやコンテナのデプロイに関連する基本的な知識、具体的にはバージョニングやロールバックのプロセスを理解することです。選択肢をふるいにかける時には、各選択肢が提供する解決策が最善の方法であるか、または問題の解決につながるかどうかを注意深く調べる必要があります。
基本的な概念や原則：
sha256ダイジェスト：特定のイメージ準拠のユニークで変わらない識別子です。コンテナイメージのバージョンを特定・管理するために使用されます。
コンテナイメージタグ：イメージのバージョンを表す可変の識別子です。"最新"のようなタグは変更可能で、新しいイメージを古いタグに関連付け直すことが可能です。
ローリングアップデート：GKEのデプロイメントにおいて、新しいバージョンのアプリケーションを段階的にデプロイし、古いバージョンを取り下げる更新戦略です。ダウンタイムを最小限に抑えることができます。
デプロイメント：Kubernetesによって管理されるアプリケーションの生存期間を通じてレプリカの数が維持されるリソースです。Rolling Updateなど、アップデート戦略を指定することも可能です。
Google Kubernetes Engine：Google CloudのマネージドKubernetesサービスで、容易なコンテナ化アプリケーションのデプロイメント、スケーリング、管理を可能にします。
正解についての説明：
（選択肢）
・デプロイメントを変更し、以前作業していたコンテナのsha256ダイジェストを指すようにします
この選択肢が正解の理由は以下の通りです。
問題の原因が最近更新されたコンテナイメージにあると判断している状況で、以前動作していた状態に戻すためには、動作確認済みのコンテナイメージを指定してデプロイする必要があります。"Latest"タグを使用すると、イメージが更新されるたびにその最新のイメージがデプロイされます。これが原因で問題が生じているのなら、特定のバージョンのイメージを明示的に指定することで問題を解決できます。
sha256ダイジェストはコンテナイメージの一意で不変な識別子であり、特定のコンテナイメージバージョンを一意に指すものです。
したがって、デプロイメントを変更して以前動作していたコンテナのsha256ダイジェストを指定することで、クラスターを更新して特定のイメージを実行させることが可能になります。
不正解についての説明：
選択肢：以前に作業していたコンテナを指すstableという新しいタグを作成し、新しいタグを指すようにデプロイメントを変更します
この選択肢が正しくない理由は以下の通りです。
新しいタグを作成してデプロイメントを変更する方式は、以前のバージョンへのロールバックも可能ですが、タグはソースの変更を特定できず、それが更改されると問題が再発する可能性があります。
一方、sha256ダイジェストを指定すると、特定のイメージビルドを固定的に参照し、再現性と安定性が確保されます。
選択肢：以前のGitタグから新しいコンテナをビルドし、新しいコンテナへのデプロイでローリングアップデートを行います
この選択肢が正しくない理由は以下の通りです。
以前のGitタグから新しいコンテナをビルドすると、場合によっては完全に一致する保証がないため、問題が解消されるとは限りません。
一方、sha256ダイジェストを指定することで特定のコンテナイメージバージョンを厳密に指定でき、意図したとおりの動作を保証できます。
選択肢：最新のタグを以前のコンテナイメージに適用し、デプロイメントのローリングアップデートを行います
この選択肢が正しくない理由は以下の通りです。
最新のタグを以前のイメージに適用するとタグの一貫性が失われます。
また、ローリングアップデートは新しいポッドの作成と古いポッドの削除を行いますが、同じ最新タグが使われていれば新旧の区別がつかず正しく動作しません。
一方、SHA256ダイジェストはイメージの内容自体を一意に特定するので、これを指定することで直接問題のないバージョンを選択できます。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/concepts/deployment
https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps
https://kubernetes.io/docs/concepts/configuration/overview/
</div></details>

### Q. 問題20: 未回答
あなたは、キャッシュメモリに製品情報を保存するアプリケーションをサポートしています。キャッシュミスが発生するたびに、Cloud Loggingにエントリが記録されます。あなたは、キャッシュミスが発生する頻度を時系列で可視化したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. Google Cloud Operation Suite Profilerを設定し、ログに基づいてキャッシュミスが発生したタイミングを特定し、視覚化します
2. Cloud LoggingをGoogle Data Studioのソースとしてリンクします。キャッシュミスのログにフィルタをかける
3. BigQueryをGoogle Cloud Operation Suiteログのシンクとして設定します。キャッシュミスログをフィルタリングし、別のテーブルに書き込むスケジュールクエリを作成します
4. Cloud Loggingでログベースのメトリックを作成し、Google Cloud Operation Suite Monitoringでそのメトリックのダッシュボードを作成します
<details><div>
    答え：4
説明
この問題では、Cloud Loggingに記録されたキャッシュミスの頻度を時系列で可視化する方法が求められています。ここでは、リアルタイムでの監視と分析、メトリクスの視覚化、Cloud Loggingと他のGoogle Cloudサービスとの連携などが重要な要素となります。主にはログからメトリクスを生成し、それを視覚化するサービスを選択すれば解決策となります。Google Cloud Operation Suite MonitoringやGoogle Data Studio、Profiler、BigQueryなどが選択肢となるため、特定の要件に最適なサービスを選ぶことが適切な解答に繋がります。
基本的な概念や原則：
Cloud Logging：Google Cloudのロギングサービスです。システムやアプリケーションのログデータを管理し、リアルタイムで分析可能なツールを提供します。
ログベースのメトリック：Cloud Loggingに記録されたログエントリに基づいて生成されるカスタムメトリックです。これを使用すると、ログエントリの特定のデータを継続的に監視し、分析することが可能となります。
Google Cloud Operation Suite（旧オペレーションスイート）：Google Cloud上でのシステムのモニタリング、トラブルシューティング、アプリケーションのパフォーマンス向上などを支援するツール群です。
Google Cloud Operation Suite Monitoring：時系列データを表示、分析、アラート設定を行えるMonitoringサービスを提供します。これを使用すると特定のメトリックの振る舞いを時間軸で視覚化することが可能です。
Google Data Studio：Googleのビジュアル分析ツールです。データの吸上げをしダッシュボードの作成、共有が行えますが、直接的にCloud Loggingのデータを時系列で視覚化することはできません。
Google Cloud Operation Suite Profiler：アプリケーションのパフォーマンスボトルネックを視覚化するツールですがログの可視化には向いていません。
BigQuery：Google Cloudのビッグデータ分析ツールです。大量のデータに対してSQLクエリを実行できますが、リアルタイムの視覚化やログの直接的なハンドリングには適していません。
正解についての説明：
（選択肢）
・Cloud Loggingでログベースのメトリックを作成し、Google Cloud Operation Suite Monitoringでそのメトリックのダッシュボードを作成します
この選択肢が正解の理由は以下の通りです。
まず、Cloud LoggingはGoogle Cloudのログ管理サービスで、アプリケーションのさまざまなアクティビティのログを記録します。キャッシュミスの時系列データを取得するためには、このログ情報をメトリクスとして抽出する必要があります。そのためにログベースのメトリックを作成します。このメトリックは、ログデータの特定のパターンを数値化し、それを時間とともに追跡する機能を提供します。つまり、定義したパターンがログに登場するたびにそのカウントがインクリメントされ、これによりキャッシュミスの頻度を追跡することができます。
その後、Google Cloud Operation Suite Monitoringを使用してこれらのメトリクスを時系列で視覚化します。MonitoringはCloud上の資源とアプリケーションのパフォーマンスを時間経過に沿って監視したり可視化したりするためのサービスです。ここで作成されたダッシュボードを利用すれば、キャッシュミスの発生頻度を時系列で視覚的に理解することが可能となります。
不正解についての説明：
選択肢：Cloud LoggingをGoogle Data Studioのソースとしてリンクします。キャッシュミスのログにフィルタをかける
この選択肢が正しくない理由は以下の通りです。
Cloud Loggingは直接Google Data Studioにリンクすることができません。キャッシュミスの頻度を時系列で可視化するためには、Cloud Loggingでログベースのメトリックを作成し、それをGoogle Cloud Operation Suite Monitoringで視覚化するのが適切です。
選択肢：Google Cloud Operation Suite Profilerを設定し、ログに基づいてキャッシュミスが発生したタイミングを特定し、視覚化します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite Profilerはアプリケーションの性能問題を診断するためのツールであり、ログデータから時系列での可視化を作成するのには適しません。それに対してCloud LoggingとMonitoringはログデータを基にメトリックを作成、視覚化するのに最適なツールです。
選択肢：BigQueryをGoogle Cloud Operation Suiteログのシンクとして設定します。キャッシュミスログをフィルタリングし、別のテーブルに書き込むスケジュールクエリを作成します
この選択肢が正しくない理由は以下の通りです。
BigQueryを使用してログのフィルタリングを行うと確かに情報を取得できますが、これでは時系列での可視化を直接行うことはできません。問題の要件は時間経過と共にキャッシュミスの発生頻度を可視化することであり、これはGoogle Cloud Operation Suite Monitoringが提供する機能で可能です。
参考リンク：
https://cloud.google.com/logging/docs/logs-based-metrics
https://cloud.google.com/monitoring/api/metrics#Google Cloud-logging
https://cloud.google.com/logging/docs/view/overview
</div></details>

### Q. 問題21: 未回答
あなたはグローバルな組織で働いており、Compute Engine上でモノリシックアプリケーションを実行しています。最も少ないステップ数でCPU使用率を最適化するアプリケーションのマシンタイプを選択する必要があります。過去のシステムメトリクスを使用して、使用するアプリケーションのマシンタイプを特定したいと考えています。あなたは、Googleが推奨するプラクティスに従いたいと考えています。
この要件を満たすために、どうすればよいですか？

1. gcloud CLIを使用して、VMのフリート内にOps Agentをインストールします
2. すべてのVMにOps Agentを自動的にインストールするエージェントポリシーを作成します
3. VMのCloud Monitoringダッシュボードを確認し、CPU使用率が最も低いマシンタイプを選択します
4. レコメンダーAPIを使用し、提案された推奨事項を適用します
<details><div>
    答え：4
説明
この問題では、Compute Engineで実行されるモノリシックアプリケーションのCPU使用率を最適化するためのマシンタイプの選択に関して、Googleが推奨する行動を特定することが求められています。ここで注意すべきポイントは、"最も少ないステップ数で"の要求と"過去のシステムメトリクスを使用"するという要求、そしてこれらをふまえた上で、提示された選択肢の中から最適な手段を選ぶことです。
基本的な概念や原則：
レコメンダーAPI：Google Cloud上のリソースに対して最適化の推奨事項を提供するAPIです。利用することで、費用、パフォーマンス、セキュリティについて改善の可能性を見つけることができます。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。柔軟な仮想マシンの設定と自動スケーリングが可能です。
モノリシックアプリケーション：一つの単一のユニットとして構築、テスト、デプロイされるアプリケーションのこと。全ての機能が統合され、個々の機能が個別にスケーリングされることはないです。
Ops Agent：Google Cloudのリソース監視とログの収集を助けるAgentです。ただし、ワークロードの最適化自体はOps Agentではなくレコメンダーや他のツールを使うことが推奨されます。
Cloud Monitoring：Google Cloudのリソースやアプリケーションのパフォーマンスを監視し、警告を設定するサービスです。しかし、機械タイプの選択はCloud Monitoringではなく、レコメンダーAPIを使用することが推奨されます。
正解についての説明：
（選択肢）
・レコメンダーAPIを使用し、提案された推奨事項を適用します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのレコメンダーAPIは、過去のシステムメトリクスを元に最適なリソースの使用方法を提案する機能を持っています。つまり、Compute Engine上で実行しているモノリシックアプリケーションのCPU使用率を最適化するためのマシンタイプを提案してくれます。レコメンダーAPIを使用すれば、自身で各種メトリクスを分析し、マシンタイプを選ぶよりもはるかに少ないステップ数でCPU使用率を最適化することが可能です。
また、レコメンダーAPIはGoogleが提供する公式の機能なので、Googleの推奨するプラクティスに従っていると言えます。
したがって、この選択肢が要件を満たす最適解となります。
不正解についての説明：
選択肢：すべてのVMにOps Agentを自動的にインストールするエージェントポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
Ops Agentを自動的にインストールするエージェントポリシーは統計データやメトリクスを取得するためには役立ちますが、それだけではCPU使用率を最適化するためのマシンタイプを特定することはできません。
それに対して、正解のレコメンダーAPIは過去のメトリクスを基にした最適なマシンタイプの推奨を提供します。
選択肢：gcloud CLIを使用して、VMのフリート内にOps Agentをインストールします
この選択肢が正しくない理由は以下の通りです。
Ops Agentのインストールはシステムメトリクスの収集に役立ちますが、これ自体がマシンタイプを最適化または推奨するものではありません。
それに対して、レコメンダーAPIは過去のシステムメトリクスに基づいて最適なマシンタイプを推奨します。そのため、最も少ないステップ数でCPU使用率を最適化するにはレコメンダーAPIの利用が適しています。
選択肢：VMのCloud Monitoringダッシュボードを確認し、CPU使用率が最も低いマシンタイプを選択します
この選択肢が正しくない理由は以下の通りです。
Cloud Monitoringダッシュボードを使用して最もCPU使用率の低いマシンタイプを選択する方法は最適化の一部ですが、最も少ないステップ数や全体的かつ詳細な推奨事項には対応できません。
それに対して、レコメンダーAPIは全体的な使用パターンとトレンドに基づき具体的な推奨事項を提案し、より効率的な最適化を実現します。
参考リンク：
https://cloud.google.com/compute/docs/machine-types
https://cloud.google.com/recommender/docs/using-vm-right-sizing
https://cloud.google.com/monitoring/api/v3/aggregation
</div></details>

### Q. 問題22: 未回答
あなたの組織は、200,000円の投資で、アプリケーションの可用性目標を99.9%から99.99%に引き上げたいと考えています。このアプリケーションの現在の収益は100,000,000円です。可用性の向上が、1年間の使用に対する投資に値するかどうかを判断する必要があります。
この要件を満たすために、どうすればよいですか？

1. 稼働率向上の価値を100,000円と計算し、稼働率向上は投資に値すると判断します
2. 稼働率向上の価値を100,000円と計算し、稼働率向上は投資に見合わないと判断します
3. 稼働率向上の価値を900,000円と計算し、稼働率向上は投資に値すると判断します
4. 稼働率向上の価値を90,000円と計算し、稼働率向上は投資に見合わないと判断します
<details><div>
    答え：4
説明
この問題では、アプリケーションの可用性を向上させるための投資が適切かどうかを判断するため、まず可用性の現状と目標、そしてその向上に要する投資額を把握する必要があります。次に、それらの数値をもとに、アプリケーションの収入と可用性向上の価値を計算し、その価値が投資に見合うかどうかを評価する必要があります。選択肢の中には、同じ結論を導くものの計算方法が異なるものや、異なる結論を導くものが含まれているため、正確な計算と理解が求められます。
基本的な概念や原則：
可用性：システムが正常に動作し、ユーザーに利用可能である割合を表す指標です。通常、パーセンテージで表示され、大きい方が良いです。
SLA（Service Level Agreement）：プロバイダと顧客間のサービスレベルを定義した合意文書です。システムの可用性目標など、サービスの品質を保証するための基準が記載されます。
ROI（Return on Investment）：投資対効果を測定するための指標です。投資によって得られる収益（又は費用削減）を投資額で割ります。ROIが1以上なら、投資は元が取れると判断されます。
ダウンタイム：システムが停止してサービスを提供できない時間のことです。可用性が高いほどダウンタイムは少なくなります。
機会損失：何かを行う機会を逃したことによる損失のことです。本問題では、高い可用性を維持しないことによる収益の損失がこれに該当します。
正解についての説明：
（選択肢）
・稼働率向上の価値を90,000円と計算し、稼働率向上は投資に見合わないと判断します
この選択肢が正解の理由は以下の通りです。
まず、現在の可用性が99.9%から99.99%に引き上げることを考えると、これは年間のダウンタイムが0.1%から0.01%への改善を意味します。つまり、ダウンタイムが年間で0.09％改善されます。
したがって、ダウンタイムの改善による収益増加は、現在の収益である100,000,000円において、0.09%の増加、つまり90,000円と見積もられます。
しかしながら、改善には200,000円の投資が必要であるため、この投資による純利益は90,000円（改善による収益）から200,000円（投資）を引いた合計-110,000円となります。
以上の計算から、稼働率向上は投資に見合わないと判断できます。
不正解についての説明：
選択肢：稼働率向上の価値を100,000円と計算し、稼働率向上は投資に見合わないと判断します
この選択肢が正しくない理由は以下の通りです。
稼働率向上の価値を100,000円と計算するという方法は、アプリケーションの可用性目標を適切に評価できていません。正解の選択肢では稼働率向上の価値を90,000円と正確に計算していることから、投資が必要な量よりも価値が低いと正しく判断されています。
選択肢：稼働率向上の価値を100,000円と計算し、稼働率向上は投資に値すると判断します
この選択肢が正しくない理由は以下の通りです。
この選択肢は、稼働率向上の価値を100,000円と計算していますが、これは間違いです。正解の選択肢は稼働率向上の価値を90,000円と計算しており、これは200,000円の投資よりも低いため、投資に見合わないと判断されています。
したがって、不正解の選択肢は投資判断の数値が誤っているため、不適切です。
選択肢：稼働率向上の価値を900,000円と計算し、稼働率向上は投資に値すると判断します
この選択肢が正しくない理由は以下の通りです。
可用性の向上がもたらす収益増加は、現在の収益から可用性の向上分を計算することで導き出されます。これにより200,000円の投資に見合う収益増加が見込めるかを判断します。しかし、この選択肢での計算結果900,000円は、正しく計算された価値90,000円と比べて10倍も高く、実際の可用性向上分を大幅に過大評価しているため、不正解です。
参考リンク：
https://cloud.google.com/architecture/framework/reliability/availability
https://cloud.google.com/solutions/devops/devops-tech-high-availability
https://en.wikipedia.org/wiki/High_availability
</div></details>

### Q. 問題23: 未回答
あなたの組織にポストモーテムを導入する必要があります。ポストモーテムプロセスが好評であることを確認したいと考えています。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. 新入社員には、練習を通じてチームにポストモーテムを行うよう奨励します
2. シニアリーダーに、ポストモーテムを認め、参加するよう奨励します
3. 効果的なポストモーテムを書くことが報われ、称賛されるようにします
4. すべてのポストモーテムの実施に責任を持つ指定チームを作ります
5. 過去のポストモーテムをレビューする場を組織に提供します
<details><div>
    答え：2,3
説明
この問題では、ポストモーテム（プロジェクトまたはイベント後の逆説的な分析手続き）の導入とその成果物の評価について考える必要があります。選択肢の中で考えられるアクションは、主に組織の一員に対する行動を促し、その効果を評価するものです。評価の正しさを考えるためには、ポストモーテムが成功するための重要な要素の理解が必要です。選択肢の中から、ポストモーテムの適用を推進し、その成果を評価・称える方法を選ぶことが求められます。
基本的な概念や原則：
ポストモーテム：システム障害や重大なエラーが発生した後に行われる評価のことです。原因の特定、再発防止策の検討、改善のためのプロセスを理解し、学べます。
シニアリーダーの参加：運営のトップからの参加とサポートがあることで、組織全体の関与を促し、ポストモーテムが重視される雰囲気を作ることができます。
報われるシステム：ポストモーテムが正確で、有意義な情報を提供し、問題の解決に貢献するような行為を評価し、報いることで、全体の質を高めることができます。
正解についての説明：
（選択肢）
・シニアリーダーに、ポストモーテムを認め、参加するよう奨励します
・効果的なポストモーテムを書くことが報われ、称賛されるようにします
この選択肢が正解の理由は以下の通りです。
まず、シニアリーダーにポストモーテムを認め、参加するよう奨励することは重要です。リーダーシップがその価値を理解し、積極的に参加することで、他のメンバーもポストモーテムを重要なプロセスと認識し、受け入れます。リーダーシップからの推進とサポートなしには、新しいプロセスを組織全体に定着させることは非常に困難です。
次に、効果的なポストモーテムを書くことが報われ、称賛されるようにすることも重要です。ポストモーテムを成功させるためには、そのプロセスが価値ありと見なされ、感謝されるべきであり、これによりすべての関連スタッフが率先して参加します。これらの措置により、ポストモーテムプロセスが好評であることを確認できます。
不正解についての説明：
選択肢：新入社員には、練習を通じてチームにポストモーテムを行うよう奨励します
この選択肢が正しくない理由は以下の通りです。
新入社員だけにポストモーテムを行うよう奨励すると、組織全体の改善プロセスが偏ってしまいます。シニアリーダーにポストモーテムを認め、参加するよう奨励することで全体的な文化の変化を促し、効果的なポストモーテムが称賛されるようにすると全員がより良い結果を目指します。
選択肢：すべてのポストモーテムの実施に責任を持つ指定チームを作ります
この選択肢が正しくない理由は以下の通りです。
ポストモーテムは事象発生者が自身でアクションを振り返り、改善点を見つける手法であり、全てのポストモーテムを一部のチームが実施してしまうと、直接関与した者の学習の場が失われ、組織全体の透明性や改善などポストモーテムの目的に反します。
選択肢：過去のポストモーテムをレビューする場を組織に提供します
この選択肢が正しくない理由は以下の通りです。
過去のポストモーテムをレビューする場を提供することは、確かにポストモーテムの理解を深めるのに役立ちます。しかし、これだけではポストモーテムプロセスが好評であることを確認する手段にはならないからです。
一方、シニアリーダーにこのプロセスへの参加を奨励することや、効果的なポストモーテムを称賛することは、プロセスが尊重され活用されていることを確認する具体的な方法となります。
参考リンク：
https://cloud.google.com/sre/docs/sre-book/managing-incidents
https://cloud.google.com/blog/topics/inside-google-cloud/google-clouds-incident-management-process
https://landing.google.com/sre/sre-book/chapters/managing-incidents/
</div></details>

### Q. 問題24: 未回答
本番環境でJavaアプリケーションを分析しています。すべてのアプリケーションには、デフォルトでCloud ProfilerとCloud Traceがインストールされ構成されています。どのアプリケーションにパフォーマンスチューニングが必要かを判断したいと考えています。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. アプリケーションのウォールクロック時間とCPU時間のレイテンシを調べます。もしレイテンシ時間が徐々にエラーバジェットを消費し、ウォールクロック時間とCPU時間の差が最小であれば、アプリケーションを最適化のためにマークします
2. アプリケーションのウォールクロック時間とCPU時間を調べます。差が大きい場合は、CPUリソースの割り当てを増やします
3. アプリケーションのウォールクロック時間とCPU時間を調べます。この差が大きい場合は、ローカルディスクストレージの割り当てを増やします
4. アプリケーションのウォールクロック時間とCPU時間を調べます。差が大きい場合は、メモリリソースの割り当てを増やします
5. アプリケーションのヒープ使用量を調べます。使用率が低い場合は、アプリケーションを最適化の対象とします
<details><div>
    答え：1,5
説明
この問題では、Javaアプリケーションのパフォーマンスを最適化するための必要性を判断する方法が求められています。Cloud ProfilerとCloud Traceを用いてパフォーマンス監視をしており、このツールから得られる情報をもとに、どのアプリケーションにパフォーマンスチューニングが必要かを判断することが問われています。具体的には、ウォールクロック時間とCPU時間のレイテンシ、ヒープの使用率といった指標を見て、パフォーマンスチューニングの必要性を判断します。また、選択肢の中にはパフォーマンスの問題を診断し、解決するためにリソースを増やすような項目が含まれていますが、質問文の最適化という要件からすると、これらは適切な選択肢とは言えません。
基本的な概念や原則：
Cloud Profiler：Google Cloudのパフォーマンス分析ツールです。CPU使用率やメモリ使用率などのパフォーマンスデータを収集し、アプリケーションの最適化を補助します。
Cloud Trace：Google Cloudのアプリケーションのパフォーマンス監視ツールです。リクエストのレイテンシを視覚化し、パフォーマンスの問題を特定します。
ウォールクロック時間：計算またはタスクにかかった実際の時間です。CPU時間と比較することにより、パフォーマンスのボトルネックを特定できます。
CPU時間：プロセスがCPUを占有した実時間です。ウォールクロック時間と比較してプロセス効率性を評価します。
ヒープ使用量：Javaアプリケーションのランタイムヒープの使用状況を示します。ヒープの使用率が低い場合、アプリケーションが効率的にメモリを使用していない可能性があります。
CPUリソースの割り当て：CPUリソースをアプリケーションに割り当てることで、パフォーマンスを向上させます。ただし、過剰なCPU割り当ては非効率的で、コスト増につながります。
メモリリソースの割り当て：メモリリソースをアプリケーションに割り当てることで、パフォーマンスを向上させます。ただし、過剰なメモリ割り当ては非効率的で、コスト増につながります。
正解についての説明：
（選択肢）
・アプリケーションのウォールクロック時間とCPU時間のレイテンシを調べます。もしレイテンシ時間が徐々にエラーバジェットを消費し、ウォールクロック時間とCPU時間の差が最小であれば、アプリケーションを最適化のためにマークします
・アプリケーションのヒープ使用量を調べます。使用率が低い場合は、アプリケーションを最適化の対象とします
この選択肢が正解の理由は以下の通りです。
まず、ウォールクロック時間とCPU時間のレイテンシを調べることで、パフォーマンスボトルネックを特定することが可能です。ウォールクロック時間はアプリケーションがタスクを完了するために必要な実時間を示し、CPU時間はそのタスクにCPUが費やした時間を示します。これらの差が小さい＝CPUがタスクにほぼ全力で取り組んでいる、と解釈でき、その場合、そのアプリケーションは最適化の対象となります。これはCloud Traceを使用して調査します。
また、アプリケーションのヒープ使用量を調査することも重要です。ヒープとは、動的にメモリを割り当てるための領域で、使用率が低いということは、割り当てられたメモリが十分に活用されていない可能性を示します。つまり、メモリ管理の最適化が必要であることを示し、それがパフォーマンスのボトルネックとなっている可能性があります。ヒープ使用量はCloud Profilerを使用して調査します。これらの分析を通じて、パフォーマンスチューニングが必要なアプリケーションを特定したり、その最適化を進めたりすることができます。
不正解についての説明：
選択肢：アプリケーションのウォールクロック時間とCPU時間を調べます。差が大きい場合は、CPUリソースの割り当てを増やします
この選択肢が正しくない理由は以下の通りです。
ウォールクロック時間とCPU時間の差が大きい場合、それはCPUよりも他の要素（I/O、ネットワーク、待機時間など）がネックになっていることを示す可能性があります。そのため、単にCPUリソースの割り当てを増やすだけでは問題解決につながらない可能性が高いです。
選択肢：アプリケーションのウォールクロック時間とCPU時間を調べます。差が大きい場合は、メモリリソースの割り当てを増やします
この選択肢が正しくない理由は以下の通りです。
ウォールクロック時間とCPU時間の差が大きい場合、それはCPUが待機している時間が多いことを示していますが、これはメモリリソースの不足ではなく、IO待ちなど他の要因が主な原因となります。
したがって、メモリリソースの割り当てを増やすというアプローチは適切ではありません。
選択肢：アプリケーションのウォールクロック時間とCPU時間を調べます。この差が大きい場合は、ローカルディスクストレージの割り当てを増やします
この選択肢が正しくない理由は以下の通りです。
ウォールクロック時間とCPU時間の差が大きいことは、アプリケーションがディスクI/Oで待機している可能性を示しています。しかし、その解決策としてローカルディスクストレージの割り当てを増やすとは限りません。実際にはI/O操作の最適化や他のリソースの調整が必要かもしれません。
参考リンク：
https://cloud.google.com/profiler/docs
https://cloud.google.com/trace/docs
https://cloud.google.com/architecture/examining-application-performance-using-cloud-profiler-and-cloud-trace
</div></details>

### Q. 問題25: 未回答
アプリケーションの成果物は、CI/CDパイプラインを介してビルドされ、デプロイされます。CI/CDパイプラインがアプリケーションシークレットに安全にアクセスできるようにしたいと考えています。また、セキュリティ侵害に備えて、より簡単にシークレットをローテーションしたいと考えています。
この要件を満たすために、どうすればよいですか？

1. シークレットを暗号化し、ソースコードリポジトリに保管します。復号鍵を別のリポジトリに保管し、パイプラインにアクセス権を与えます
2. ビルド時に開発者に秘密の入力を促します。開発者に対し、休息時にシークレットを保存しないよう指示します
3. Cloud KMSからのキーで暗号化されたCloud Storageにシークレットを保存します。CI/CDパイプラインがIAM経由でCloud KMSにアクセスできるようにします
4. Git上の別の設定ファイルにシークレットを保存します。選ばれた開発者に設定ファイルへのアクセスを提供します
<details><div>
    答え：
説明
この問題では、アプリケーションのシークレットを安全に管理し、ローテーションを容易に行う方法を求められています。解答を選ぶ際には、シークレットのセキュリティ保護の要件（暗号化など）およびローテーション（更新や交換）の容易さを重視しなければなりません。不適切な選択肢は、シークレットの安全性が不十分であったり、ローテーションが困難であったりする場合があります。選択肢を評価する際には、これらの側面を念頭に置いてください。
基本的な概念や原則：
Cloud KMS：Google Cloudの暗号鍵管理サービスです。データの暗号化と復号化、またキーのローテーションと管理を行うことができます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データを安全に保存し、どこからでもアクセスできます。
IAM：Google CloudのIAM（Identity and Access Management）は、特定のユーザーが特定のリソースにどのようなアクセスを許可するかを制御します。
CI/CDパイプライン：継続的インテグレーション（CI）と継続的デリバリー（CD）の実践を組み合わせた工程です。コードの変更を自動的にビルド、テスト、デプロイすることで、高速かつ安定したソフトウェアリリースを支援します。
アプリケーションシークレット：アプリケーションが正常に機能するために必要な機密情報です。これにはAPIキー、データベースパスワードなどが含まれます。
暗号化：情報を秘密に保つために、元の情報を読み取れない形に変換することです。暗号化された情報は、適切な鍵を持つ人だけが復号化できます。
キーローテーション：定期的に暗号化キーを変更することで、セキュリティを強化する方法です。これにより、既存のキーが漏洩した場合でも情報が保護されます。
正解についての説明：
（選択肢）
・Cloud KMSからのキーで暗号化されたCloud Storageにシークレットを保存します。CI/CDパイプラインがIAM経由でCloud KMSにアクセスできるようにします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudでは、情報を保護するために暗号化が強力に推奨されています。Cloud KMS（Key Management Service）を使用することにより、シークレットに対するアクセスを管理し、それらを安全に暗号化することが可能です。Cloud KMSから取得したキーでシークレットを暗号化してCloud Storageに保存することで、データの安全性が高まります。
さらに、IAM（Identity and Access Management）を通じてCI/CDパイプラインからCloud KMSへのアクセスを認証および許可することは、セキュリティ上重要なロールを果たします。パイプラインがCloud KMSにアクセスできるようにすることで、自動化された方式でシークレットの管理とローテーションが可能になります。これにより、シークレットの使用やローテーションが適切に行われ、セキュリティの堅牢性が向上します。それぞれのパイプラインのアクセス権をIAMポリシーを通じて管理することで、セキュリティが強化され、CI/CDパイプラインの信頼性も向上します。
不正解についての説明：
選択肢：ビルド時に開発者に秘密の入力を促します。開発者に対し、休息時にシークレットを保存しないよう指示します
この選択肢が正しくない理由は以下の通りです。
ビルド時に開発者に秘密の入力を促す方法は、開発者が画面上に秘密情報を記入する操作が必要となり、セキュリティリスクが高まるほか、ローテーションの際の負荷が大きくなります。
一方、Cloud KMSとCloud Storageを利用する方法では、認証情報を一元管理してシームレスに更新できるため、要件に対してより適切です。
選択肢：Git上の別の設定ファイルにシークレットを保存します。選ばれた開発者に設定ファイルへのアクセスを提供します
この選択肢が正しくない理由は以下の通りです。
Git上の設定ファイルにシークレットを保存すると、暗号化されずに公開されてしまい、セキュリティ侵害のリスクが高まります。
また、シークレットのローテーションが煩雑になる可能性があります。
一方、Cloud KMSとCloud Storageを使用すると、セキュアにシークレットを保管し、必要な権限があるパイプラインだけがアクセスできるなど、セキュリティと操作性を向上させることができます。
選択肢：シークレットを暗号化し、ソースコードリポジトリに保管します。復号鍵を別のリポジトリに保管し、パイプラインにアクセス権を与えます
この選択肢が正しくない理由は以下の通りです。
シークレットをソースコードリポジトリに保管する方法はセキュリティリスクが高く、シークレットをローテーションする際にも手間がかかります。
一方、Cloud KMSとCloud Storageを利用すると、IAMを通したアクセス制御と鍵のローテーションが容易になり、要件を満たすことが可能です。
参考リンク：
https://cloud.google.com/storage/docs/encryption
https://cloud.google.com/kms/docs
https://cloud.google.com/solutions/secrets-management
</div></details>

### Q. 問題26: 未回答
Cloud Runアプリケーションは、構造化されていないログをテキスト文字列としてCloud Loggingに書き込みます。非構造化ログをJSONベースの構造化ログに変換したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. Cloud Runコンテナイメージにログエージェントをインストールし、ログエージェントを使用してログをCloud Loggingに転送します
2. Cloud Loggingソフトウェア開発キット（SDK）を使用するようにアプリケーションを修正し、jsonPayloadフィールドを持つログエントリを送信します
3. Fluent Bitサイドカーコンテナをインストールし、JSONパーサーを使います
4. ログのテキストペイロードをJSONペイロードに変換するようにログエージェントを設定します
<details><div>
    答え：2
説明
この問題では、Cloud Runアプリケーションが現在テキスト文字列としてCloud Loggingに書き込んでいる非構造化ログを、JSONベースの構造化ログにどう変換するかを問われています。アプリケーションが現在使用しているログ出力方法と、目指すログ形式の違いを理解することが重要です。選択肢を検討する際には、適切なツールや手法を通じてテキスト文字列をJSON形式に変換する解決策を選ぶ必要があります。
基本的な概念や原則：
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションとシステムからのログデータを集め、分析、エクスポートすることができます。
非構造化ログ：特定のデータ構造を持たないログデータのことです。分析や管理が難しい場合があります。
Cloud Logging SDK：Cloud Loggingにログエントリを送信するためのソフトウェア開発キットです。jsonPayloadフィールドを使用して、非構造化ログを構造化ログに変換することが可能です。
構造化ログ：特定の構造（例えばJSON）を持つログデータのことです。データ分析や管理が容易になります。
jsonPayloadフィールド：Cloud Loggingで使用されるフィールドで、ログエントリの本文をJSON形式で格納します。構造化ログの作成に使用されます。
正解についての説明：
（選択肢）
・Cloud Loggingソフトウェア開発キット（SDK）を使用するようにアプリケーションを修正し、jsonPayloadフィールドを持つログエントリを送信します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Loggingソフトウェア開発キット（SDK）は、アプリケーションログの作成と管理をGoogle Cloudで直接実行できるようにするためのツールキットです。その主な機能は通常のテキストベースのログだけでなく、構造化されたJSONベースのログを含んでいます。
したがって、Cloud Logging SDKを使用すると、アプリケーションから直接構造化ログをCloud Loggingに送信できます。
具体的には、SDKを使用してアプリケーションを修正し、jsonPayloadフィールドを持つログエントリを送信すれば、サーバーレス環境のCloud Runアプリケーションから生成された非構造化ログをJSONベースの構造化ログに変換することができます。これにより、ログデータの分析と管理が大幅に容易になります。この選択肢は正確で効率的な解決策を提供します。
不正解についての説明：
選択肢：Fluent Bitサイドカーコンテナをインストールし、JSONパーサーを使います
この選択肢が正しくない理由は以下の通りです。
Fluent BitサイドカーコンテナとJSONパーサーを使用する方法は、すでに存在するログデータの形式を変換する為によく使用されますが、それは既存のログを解析してJSON形式に変換するものであり、アプリケーションが直接構造化ログを出力する方法とは違います。正解の選択肢のCloud Logging SDKを使うことで、アプリケーション自身がJSONベースの構造化ログを出力、Cloud Loggingへと送信することが可能になります。
選択肢：Cloud Runコンテナイメージにログエージェントをインストールし、ログエージェントを使用してログをCloud Loggingに転送します
この選択肢が正しくない理由は以下の通りです。
Cloud Runの環境ではログエージェントをインストールすることができません。Cloud Runのログ取得は自動的に行われ、特別なログエージェントをインストールする必要はありません。
一方、Cloud Logging SDKを使用すればアプリケーションレベルでログの形式を制御し、jsonPayloadフィールドを持つログエントリを送信することが可能です。
選択肢：ログのテキストペイロードをJSONペイロードに変換するようにログエージェントを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのログエージェントはログの収集と転送を担いますが、ログの形式をテキストからJSONに変換する機能はありません。
一方、Cloud Logging SDKを使用すれば、アプリケーションが直接JSON形式のログを生成できるため、この問題の要件を満たします。
参考リンク：
https://cloud.google.com/logging/docs/structured-logging
https://cloud.google.com/logging/docs/reference/libraries
https://cloud.google.com/run/docs/logging
</div></details>

### Q. 問題27: 未回答
アプリケーションサービスはGoogle Kubernetes Engine（GKE）で実行されます。cloudjp-imagesプロジェクトで一元管理されているGoogle Container Registry（GCR）イメージレジストリからのイメージのみをクラスターにデプロイできるようにし、開発時間を最小限に抑えたいと考えています。
この要件を満たすために、どうすればよいですか？

1. イメージをgcr.io/cloudjp-imagesにのみプッシュするCloud Build用のカスタムビルダーを作成します
2. デプロイメントパイプラインにロジックを追加し、すべてのマニフェストにgcr.io/cloudjp-imagesからのイメージのみが含まれていることをチェックします
3. ホワイトリスト名パターンgcr.io/cloudjp-images/を含むバイナリ認証ポリシーを使用します
4. gcr.io/cloudjp-imagesの各イメージにタグを追加し、画像のデプロイ時にこのタグが存在することを確認します
<details><div>
    答え：3
説明
この問題では、Google Kubernetes Engine上でのアプリケーションサービスのデプロイ時に、特定のGoogle Container Registryからのイメージのみを使用することを求めています。また、開発時間を最小限に抑える必要があるため、繊細で時間をかける作業や追加のステップの導入は避けなければなりません。さらに言えば、GCRの一元管理されたプロジェクトに絞るという要件からは、すべてのトラフィックを特定のレジストリに制限するためのポリシー設定が関与することが推測されます。具体的なアクションとしては、バイナリ認証ポリシーの使用やカスタムビルダーの作成などが考えられます。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：Google CloudのマネージドKubernetesサービスです。Kubernetesのパワフルな機能をフル活用しながら、サーバーのメンテナンスやアップグレードなどの運用負荷をGoogleに委ねることができます。
Google Container Registry（GCR）：Dockerイメージをプライベートに保存・共有できるレジストリサービスです。高い可用性と安全性を備えており、Dockerクライアントからのプルプッシュやバージョン管理などが可能です。
バイナリ認証：Google Cloudのサービスで、クラスターにデプロイされるイメージの信頼性を確保します。特定の条件を満たすイメージのみをデプロイするように制限することができます。
ホワイトリスト：指定されたエンティティ（ここではGCRイメージ）だけがリソースへのアクセスを許可されるリストです。安全性の向上や不必要なアクセスの防止に役立ちます。
Cloud Build：Google Cloudの継続的インテグレーション/デリバリーサービスで、コードのビルド、テスト、デプロイを自動化します。まとまったコードの変更に対して反復的なプロセスを適用することで、開発効率を高めます。
デプロイメントパイプライン：アプリケーションのリリースを自動化するプロセスです。ビルド、テスト、デプロイなどのステップを一つのパイプラインにまとめて管理することで、新しいバージョンのリリースをスムーズに行えます。
正解についての説明：
（選択肢）
・ホワイトリスト名パターンgcr.io/cloudjp-images/を含むバイナリ認証ポリシーを使用します
この選択肢が正解の理由は以下の通りです。
まず、Binary Authorizationは、Google Cloud上でのデプロイ時にコンテナイメージの信頼性を確認するためのサービスで、デプロイするイメージのソースを制限するためのポリシーを適用できる機能があります。これにより、特定のイメージレジストリからのデプロイのみを許容するといった制御が可能になります。この問題の要件では、特定のGCR（Google Container Registry）レジストリからのイメージのみをデプロイできるようにするという制約があったため、このBinary Authorizationの用途が該当します。
したがって、ホワイトリスト名パターンgcr.io/cloudjp-images/を含むバイナリ認証ポリシーを使用することで、この制約を満たすことができます。
また、この方法は開発プロセスの重大な変更なしにこれらの制約を実装できるため、開発時間の増加も最小限に抑えられます。
不正解についての説明：
選択肢：イメージをgcr.io/cloudjp-imagesにのみプッシュするCloud Build用のカスタムビルダーを作成します
この選択肢が正しくない理由は以下の通りです。
カスタムビルダーを作成すると、開発時間を最小限に抑えられない可能性があります。
また、この方法ではクラスターにデプロイされるイメージのソースを制限することはできません。
一方、バイナリ認証ポリシーを使用すると、指定したソースからのイメージのみをクラスターにデプロイすることが可能です。
選択肢：デプロイメントパイプラインにロジックを追加し、すべてのマニフェストにgcr.io/cloudjp-imagesからのイメージのみが含まれていることをチェックします
この選択肢が正しくない理由は以下の通りです。
デプロイメントパイプラインにロジックを追加すると、開発時間が増加する可能性があります。
また、マニフェストのチェックは人為的なエラーが発生する可能性があるため、バイナリ認証ポリシーを使用して自動的に管理する方が効率的です。
選択肢：gcr.io/cloudjp-imagesの各イメージにタグを追加し、画像のデプロイ時にこのタグが存在することを確認します
この選択肢が正しくない理由は以下の通りです。
イメージにタグを追加し、デプロイ時にその存在を確認することは、手動でのチェック作業が増え、要件の"開発時間を最小限に抑える"ことが難しくなります。
一方、バイナリ認証ポリシーを使用すると、イメージの場所に基づいた自動化されたホワイトリスト作成が可能で、開発の効率化に寄与します。
参考リンク：
https://cloud.google.com/binary-authorization/docs
https://cloud.google.com/container-registry/docs/overview
https://kubernetes.io/docs/concepts/containers/images/#using-a-private-registry
</div></details>

### Q. 問題28: 未回答
サイト信頼性エンジニアとして、あなたは本番環境でGoogle Kubernetes Engine（GKE）上で動作するGoで書かれたアプリケーションをサポートしています。アプリケーションの新バージョンをリリースした後、アプリケーションが約15分間実行され、その後再起動することに気づきました。アプリケーションにCloud Profilerを追加することにしましたが、アプリケーションが再起動するまでヒープ使用量が常に増加していることに気づきました。
どうしたらよいですか？

1. アプリケーション展開のCPU制限を増やします
2. 高メモリのコンピュートノードをクラスターに追加します
3. アプリケーションデプロイメントのメモリ制限を増やします
4. アプリケーションにCloud Traceを追加し、再デプロイします
<details><div>
    答え：3
説明
この問題では、本番環境で動作するアプリケーションが新バージョンのリリース後に一定時間内で再起動し、ヒープ使用量が常に増加しているという状況を把握する必要があります。これはメモリリークと思われるため、問題解決に向けては、メモリ使用量やメモリリークに焦点を当てる必要があります。選択肢を見る時には、メモリに関する操作を重視供給、またはメモリリークの原因を探るアクションが必要です。
基本的な概念や原則：
Cloud Profiler：Google Cloudのパフォーマンス分析ツールです。アプリケーションのCPU使用量やメモリ使用量などの情報を視覚化し、パフォーマンス問題を診断しやすくします。
ヒープメモリ：プログラムがランタイムに動的に割り当てることができるメモリ領域です。アプリケーションのヒープ使用量が増加し続けると、メモリリークを示す可能性があります。
メモリ制限：Kubernetesで使用できるメモリの最大量を設定するパラメーターです。アプリケーションの需要に合わせて調整可能です。
Cloud Trace：Google Cloudの分散トレーシングシステムです。アプリケーションのパフォーマンス問題の特定と診断に役立ちます。
Google Kubernetes Engine：Google Cloudの登録管理サービスです。アプリケーションがKubernetesクラスター上でスムーズに動作することを保証します。
正解についての説明：
（選択肢）
・アプリケーションデプロイメントのメモリ制限を増やします
この選択肢が正解の理由は以下の通りです。
アプリケーションが15分間実行された後で突然再起動する原因としては、リソース不足が考えられます。特に、Cloud Profilerによりヒープ使用量が増加し続けていることが確認できているので、これが原因と考えられます。GKEのポッドにはメモリリソースの制限が設定されており、これを超えてしまうとKubernetesがポッドを終了し、再起動を試みます。
したがって、アプリケーションの再起動を防ぐためには、アプリケーションデプロイメントのメモリ制限を増やすことが有効です。
ただし、メモリリークなどの問題が存在する場合は、それを修正する必要があります。
不正解についての説明：
選択肢：アプリケーション展開のCPU制限を増やします
この選択肢が正しくない理由は以下の通りです。
Cloud Profilerが示している問題はヒープ使用量の増加すなわちメモリリークで、これはCPU制限の増加では解決できません。そのため、CPU制限を増やすという選択は目の前の問題解決に直接寄与しません。
それに対して、メモリ制限を増やすことは一時的な対応として適切であり、長期的にはメモリリークの原因を調査し修正する必要があります。
選択肢：高メモリのコンピュートノードをクラスターに追加します
この選択肢が正しくない理由は以下の通りです。
高メモリのコンピュートノードをクラスターに追加すると、それは単にアプリケーションが必要とする全体のメモリ容量を増やすことになりますが、それは一時的な対応に過ぎず、本質的なメモリリークの問題は解決しません。
一方、デプロイメントのメモリ制限を増やすことにより、アプリケーションごとのメモリ使用量が制限され、アプリケーションによるメモリの過剰使用を防ぐことができます。
選択肢：アプリケーションにCloud Traceを追加し、再デプロイします
この選択肢が正しくない理由は以下の通りです。
Cloud Traceはアプリケーションのパフォーマンスの問題を診断するためのものであり、メモリの問題、特にヒープの使用量が増え続ける問題を解決するものではありません。
一方、メモリ制限を増やすと、問題が再起動まで引き延ばせる可能性があります。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/vertical-pod-autoscaling
https://cloud.google.com/profiler/docs/profiling-go
https://golang.org/doc/faq#garbage_collection
</div></details>

### Q. 問題29: 未回答
Google Cloud上でホストされているアプリケーションを監視するためにGoogle Cloud Operation Suiteを使用しています。最近、新しいアプリケーションをデプロイしましたが、そのログがGoogle Cloud Operation Suiteのダッシュボードに表示されません。
この問題をトラブルシューティングする必要があります。
この要件を満たすために、どうすればよいですか？

1. ファイアウォールでポート25が開かれ、Google Cloud Operation Suiteへのメッセージが許可されていることを確認します
2. ホスト仮想マシンにGoogle Cloud Operation Suiteエージェントがインストールされていることを確認します
3. アカウントにGoogle Cloud Operation Suiteダッシュボードを使用するための適切な権限があることを確認します
4. アプリケーションが必要なクライアントライブラリを使用しており、サービスアカウントキーが適切な権限を持っていることを確認します
<details><div>
    答え：4
説明
この問題では、Google Cloud Operation Suiteを用いたサービス監視において、新しいアプリケーションのログがダッシュボードに表示されないトラブルシューティングを要求しています。この時、当該アプリケーションのクライアントライブラリの使用とサービスアカウントキーの権限に焦点を当てる必要があります。一般にロギングの問題は、適切なライブラリの使用、適切な権限の確保、またはそれらが適切に設定されていないことが原因で発生します。これらの要素をチェックすることが問題解決の主要な手段となります。
基本的な概念や原則：
Google Cloud Operation Suite：モニタリング、トラブルシューティング、アプリケーションのパフォーマンス改善を支援するGoogle Cloudのツール群です。
クライアントライブラリ：Google Cloudの各サービスを利用するためのプログラミングインターフェースです。適切なライブラリを使用することで、所定の機能やサービスを操作できます。
サービスアカウントキー：Google Cloudのサービスアカウントを認証するためのキーです。適切な権限が付与されていなければ、目的の操作を行うことはできません。
エージェント：特定の処理やタスクを実行するためのソフトウェアプログラムです。Google Cloud Operation Suiteエージェントは、特定のデータを取得し、解析するために使用します。
権限：特定のリソースへのアクセスや行動を許可する認証設定です。適切な権限が付与されていなければ、所定の操作を行うことはできません。
ファイアウォール：ネットワークを不正アクセスから守るためのシステムです。特定のポートが開いていても、適切な設定がなければ、特定のサービスとの通信は阻害されます。
正解についての説明：
（選択肢）
・アプリケーションが必要なクライアントライブラリを使用しており、サービスアカウントキーが適切な権限を持っていることを確認します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Operation Suiteにアプリケーションのログが表示されない一般的な問題の一つは、アプリケーションがログを適切に送信するためのクライアントライブラリを使用していないことです。各Google Cloudサービスには特定のクライアントライブラリが存在し、これを使用してサービスとのインターフェースを提供します。
したがって、アプリケーションが必要なライブラリを使用していることを確認することは非常に重要です。
また、Google Cloud Operation Suiteでデータを表示するためには、サービスアカウントが適切な権限を持っていることが必要です。それがなければ、アプリケーションはログを送信したとしても、それを表示する権限がないため、ダッシュボード上には表示されないでしょう。
したがって、サービスアカウントキーが適切な権限を持っていることも確認する必要があります。
不正解についての説明：
選択肢：ホスト仮想マシンにGoogle Cloud Operation Suiteエージェントがインストールされていることを確認します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suiteエージェントのインストールは、主に仮想マシンのシステムメトリクス収集を目的としており、特定のアプリケーションのログ表示問題を解決するものではありません。正しくログを送信するためには、アプリケーションが適切なクライアントライブラリを使用し、適切な権限を持つサービスアカウントキーがあることが重要です。
選択肢：アカウントにGoogle Cloud Operation Suiteダッシュボードを使用するための適切な権限があることを確認します
この選択肢が正しくない理由は以下の通りです。
ダッシュボード利用権限がアカウントにあっても、それはアプリケーションがGoogle Cloud Operation Suiteにログを送信するための問題解決に直接関連していません。そのため、この解決策は新しいアプリケーションのログが表示されない問題を解決することはできません。
選択肢：ファイアウォールでポート25が開かれ、Google Cloud Operation Suiteへのメッセージが許可されていることを確認します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suiteのログが表示されない原因は通常、ファイアウォールの設定やポート25が開いているかではなく、アプリケーションがクライアントライブラリを適切に使用していない、またはサービスアカウントキーが必要な権限を持っていないことによるものです。
したがって、この選択肢は問題解決には適切ではありません。
参考リンク：
https://cloud.google.com/logging/docs/setup
https://cloud.google.com/logging/docs/reference/libraries
https://cloud.google.com/iam/docs/understanding-roles#logging-roles
</div></details>

### Q. 問題30: 未回答
あなたは、マイクロサービスアーキテクチャでトラフィックの多いウェブアプリケーションをサポートしています。アプリケーションのホームページには、現在の天気、株価、ニュースヘッドラインなどのコンテンツを含む複数のウィジェットが表示されます。メインのサービングスレッドは、ウィジェットごとに専用のマイクロサービスを呼び出し、ユーザーにホームページを表示します。マイクロサービスは時々失敗します。そのような場合、サービングスレッドはホームページのコンテンツが欠落した状態で提供します。このデグレードがあまりに頻繁に発生すると、アプリケーションのユーザーは不満を感じますが、コンテンツがまったく提供されないよりは、何らかのコンテンツが提供される方がまだ良いと考えます。ユーザーエクスペリエンスが過度に低下しないように、サービスレベル目標（SLO）を設定します。
これを測定するために、どのようなサービスレベル指標（SLI）を使用すべきですか？

1. レイテンシSLI：マイクロサービス呼び出しの総数に対する、100ミリ秒未満で完了するマイクロサービス呼び出しの比率
2. 品質SLI：全回答に対するデグレードしていないレスポンスの比率
3. フレッシュネスSLI：過去10分以内に更新されたウィジェットの割合
4. 可用性SLI：マイクロサービスの総数に対する健全なマイクロサービスの比率
<details><div>
    答え：2
説明
この問題では、あなたがウェブアプリケーションをサポートしているマネージャーという立場から、マイクロサービスが時々失敗してウェブページのコンテンツが欠落する問題をどのように測定するかを解決しようとしています。この問題の重要な部分は、ユーザーが完全な欠落よりも一部のコンテンツ提供を好むという事実です。したがって、これを捉えるためには、完全なレスポンスではなく部分的なレスポンスも考慮して測定する必要があります。それを念頭に置いて、適切なサービスレベル指標（SLI）を選択することがポイントです。
基本的な概念や原則：
マイクロサービスアーキテクチャ：独立したサービス群で構築されるアプリケーションのアーキテクチャスタイルです。各マイクロサービスは個々にデプロイ、スケールすることが可能で、他のサービスとの通信はAPIを通じて行います。
サービスレベル目標（SLO）：サービスの品質や性能に関する具体的な目標を定めたものです。一定期間で達成すべきサービス運用の目標を指します。
サービスレベル指標（SLI）：SLOを測定するための定量的な指標です。SLIのデータはログやモニタリングシステムから集められます。
品質SLI：サービスの全体的な品質を測定するための指標です。例えば、全回答に対するデグレードしていないレスポンスの比率などが考えられます。
可用性SLI：サービスが正常に稼働している状態を測定するための指標です。マイクロサービスの総数に対する正常に動作しているサービスの割合で示されることが多いです。
フレッシュネスSLI：情報が最新のものであることを測定するための指標です。過去一定時間以内に更新されたデータの割合で示されます。
レイテンシSLI：サービスがユーザーの要求にどれくらい早く応答するかを測定するための指標です。特定の時間内で完了する処理の割合で示されます。
正解についての説明：
（選択肢）
・品質SLI：全回答に対するデグレードしていないレスポンスの比率
この選択肢が正解の理由は以下の通りです。
まず、サービスレベル指標（SLI）は、システムの品質、性能、可用性などを評価するための具体的な指標です。今回の問題文からは、マイクロサービスが一部失敗したときにユーザーが一部のコンテンツしか提供されない状態（デグレード状態）を避けることが重要と読み取れます。そのため、"品質SLI：全回答に対するデグレードしていないレスポンスの比率"というSLIを採用することで、ユーザー体験が低下しないようなサービス運用を目指すことが可能となります。
また、品質SLIはウェブサービスのアプリケーション性能を測定するのに非常に有用で、特にマイクロサービスアーキテクチャにおいては、個々のマイクロサービスの品質を正確に追跡することが重要であるため、この選択肢が最も効果的です。
不正解についての説明：
選択肢：可用性SLI：マイクロサービスの総数に対する健全なマイクロサービスの比率
この選択肢が正しくない理由は以下の通りです。
健全なマイクロサービスの比率はマイクロサービスの可用性を示すが、各マイクロサービスが何らかのコンテンツを提供できているか、つまり"ユーザーエクスペリエンスが過度に低下しない"ことを確実に保証する指標ではありません。
それに対して、デグレードしていないレスポンスの比率は直接ユーザーエクスペリエンスを反映する指標です。
選択肢：フレッシュネスSLI：過去10分以内に更新されたウィジェットの割合
この選択肢が正しくない理由は以下の通りです。
問題設定ではウィジェットの内容が古いことについては言及しておらず、デグレードした状態で提供されていないかどうかが重視されています。フレッシュネスSLIはウィジェットの更新頻度を測定しますが、ユーザーエクスペリエンスの低下を防ぐには、デグレードしていないレスポンスの比率を測定する品質SLIの方が適切です。
選択肢：レイテンシSLI：マイクロサービス呼び出しの総数に対する、100ミリ秒未満で完了するマイクロサービス呼び出しの比率
この選択肢が正しくない理由は以下の通りです。
レイテンシSLIはマイクロサービスの応答速度を測定しますが、問題の要件はデグレードの発生頻度の把握であり、データの欠落（品質）に関連するものです。レイテンシSLIは品質の問題を捉えることはできません。
参考リンク：
https://cloud.google.com/monitoring/api/metrics_Google Cloud#Google Cloud-lb
https://cloud.google.com/architecture/framework/reliability/slos
https://sre.google/workbook/implementing-slos/
</div></details>

### Q. 問題31: 未回答
あなたはCloud Loggingにログを書き込むアプリケーションを管理しています。あなたは一部のチームメンバーにログをエクスポートする機能を与える必要があります。
この要件を満たすために、どうすればよいですか？

1. logging.sinks.listとlogging.sink.getパーミッションを持つカスタムIAMロールを作成し、付与します
2. チームメンバーにCloud IAMのlogging.configWriterのIAMロールを付与します
3. これらのメンバーにのみログのエクスポートを許可するように、Access Context Managerを構成します
4. Cloud IAMで組織ポリシーを作成し、これらのメンバーにのみログエクスポートの作成を許可します
<details><div>
    答え：3
説明
この問題では、Cloud Loggingからログをエクスポートする能力を特定のチームメンバーに付与する方法を探しています。それを行うためには、特定のIAMロールやポリシーの付与、リソースに対するパーミッションの設定といった操作が考えられます。選択肢を検討するにあたっては、それぞれのメソッドの特性とCloud Loggingのエクスポート操作に必要な権限について理解を深めることが必要です。
基本的な概念や原則：
Cloud IAM（Identity and Access Management）：Google Cloudのリソースへのアクセスを制御するためのツールです。特定のユーザーに特定のリソースへの許可を与えたり、その許可を取り消したりすることが可能です。
IAMロール：IAMポリシーに付与できる許可の集合です。例えば、logging.configWriterロールは、Cloud Loggingの設定を作成および管理する権限を持つユーザーに付与されます。
ログのエクスポート：Cloud Loggingから外部のストレージやツールにログ数据を移動させる行為です。エクスポートは、ログの長期保存、コンプライアンス監査、または外部のログ分析ツールでの処理が必要な場合に使用されます。
Access Context Manager：Google Cloudのサービスで、組織全体のアクセスレベルを設定し管理することが可能です。しかし、特定の個々の操作（例えばログのエクスポート）を制御するためには、より細かい制御を提供するIAMが適しています。
組織ポリシー：Google Cloudの全てのリソースに適用されるルールで、特定の設定や制限を提供します。しかし、個々のユーザーの特定の操作に対する権限を制御するためには、よりパーソナライズされた権限を提供するIAMが適しています。
正解についての説明：
（選択肢）
・チームメンバーにCloud IAMのlogging.configWriterのIAMロールを付与します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud IAM（Identity and Access Management）は、Google Cloudの資源へのアクセスを制御する重要なツールであり、特定のロールを特定のユーザーまたはグループに付与することで精緻なアクセス制御が可能です。その中のlogging.configWriterロールは、Cloud Loggingの設定を操作するための許可を与えます。具体的には、Cloud Loggingのログビューやログベースのメトリクスを作成・更新し、ログエクスポート先に新しいシンクを作成する権限を持っています。
したがって、このロールをチームメンバーに付与することで、ログのエクスポートを可能にするという要件を満たすことができます。
不正解についての説明：
選択肢：これらのメンバーにのみログのエクスポートを許可するように、Access Context Managerを構成します
この選択肢が正しくない理由は以下の通りです。
Access Context Managerは、Google Cloudリソースへのアクセスを制御するために使用されますが、特定の操作（ログのエクスポートなど）へのアクセスを許可するロールを果たすものではありません。
これに対して、IAMのlogging.configWriterのロールはログのエクスポートを許可する権限を持っています。
選択肢：logging.sinks.listとlogging.sink.getパーミッションを持つカスタムIAMロールを作成し、付与します
この選択肢が正しくない理由は以下の通りです。
logging.sinks.listとlogging.sink.getパーミッションを持つカスタムIAMロールを作成し付与すると、ロールを付与されたユーザーはロギングシンクのリストを取得や特定のシンクデータの取得をすることができますが、エクスポートの設定を行う（書き込み）権限はありません。
それに対して、logging.configWriterのIAMロールはログエクスポートの設定に必要な全ての権限を持つため、正解の選択肢となります。
選択肢：Cloud IAMで組織ポリシーを作成し、これらのメンバーにのみログエクスポートの作成を許可します
この選択肢が正しくない理由は以下の通りです。
組織ポリシーは組織全体のリソースに対するアクセス制御を設定するもので、特定のメンバーにログエクスポートの操作権限を付与する趣旨とは異なります。
それに対して、IAMロールのlogging.configWriterを付与することでログのエクスポート許可を具体的なメンバーに与えることが可能です。
参考リンク：
https://cloud.google.com/logging/docs/access-control
https://cloud.google.com/iam/docs/understanding-roles#logging-roles
https://cloud.google.com/logging/docs/export/configure_export_v2
</div></details>

### Q. 問題32: 未回答
あなたの会社は、サイト信頼性エンジニアリングの手法に従っています。あなたは、顧客向けアプリケーションに影響を及ぼす大規模で進行中のインシデントのコミュニケーション担当者です。障害解決までの予定時間はまだありません。あなたは、障害に関する最新情報を求める社内の関係者からのメールや、何が起きているかを知りたがっている顧客からのメールを受け取っています。あなたは、障害の影響を受けるすべての人に効率的に最新情報を提供したいと考えています。
この要件を満たすために、どうすればよいですか？

1. すべてのステークホルダーに定期的な最新情報をタイムリーに提供します。すべてのコミュニケーションにおいて"次の更新"の時間を約束します
2. 社内関係者の電子メールへの対応を、インシデント対応チームの別のメンバーに委ねます。顧客に直接回答を提供することに専念します
3. 少なくとも30分ごとに社内のステークホルダーに対応することに重点を置きます。"次の更新"の時間を約束します
4. すべての社内関係者の電子メールをインシデントコマンダーに提供し、彼らが社内コミュニケーションを管理できるようにします。顧客への直接の回答に重点を置きます
<details><div>
    答え：1
説明
この問題では、大規模なインシデント発生時に、内部関係者と顧客へのコミュニケーションをどのように最適化するかが問われています。影響を受けるすべてのステークホルダーへ効率的に最新情報を提供する必要があり、その手法が重要です。また、次の更新のタイミングを明示することもキーとなります。明確なコミュニケーション戦略を持つことで、現在の状況と進行状況をステークホルダーと顧客に適切に伝達することができます。したがって、コミュニケーション戦略の最適化と情報更新の頻度が解答の選択に影響を与えます。
基本的な概念や原則：
サイト信頼性エンジニアリング（SRE）：システムやサービスの信頼性を高めるための手法で、ソフトウェアエンジニアリングの原則をインフラストラクチャと運用問題に適用します。
インシデント：サービスやシステムに予期しない問題が発生した場合の事象です。インシデントは通常、システムのダウンタイムやパフォーマンスの低下を引き起こし、ユーザー体験に影響を及ぼします。
インシデントのコミュニケーション：障害や問題が発生した場合の情報共有のプロセスです。定期的な更新を提供し、次の更新の時間を常に共有することが重要です。
ステークホルダー：プロジェクトやサービスの成果に関心を持つ人や組織です。これには、顧客、従業員、投資家、サプライヤー等が含まれます。
社内のステークホルダー：企業内部の関係者で、例えば経営陣や他の部門のメンバーなどが含まれます。彼らに対するコミュニケーションは重要ですが、顧客からの問い合わせにも対応することが重要です。
インシデント対応チーム：インシデント発生時に対応する専門のチームです。彼らのロールは、障害の原因を特定し対策を講じることで、サービスを早急に復旧させることです。
インシデントコマンダー：インシデント対応チームのリーダーで、問題の解決と合理的な判断を行う責任があります。
正解についての説明：
（選択肢）
・すべてのステークホルダーに定期的な最新情報をタイムリーに提供します。すべてのコミュニケーションにおいて"次の更新"の時間を約束します
この選択肢が正解の理由は以下の通りです。
まず、大規模なシステムの障害では、関係者全員が最新の情報を把握することが重要です。特に、期待された解決時間を提供することができない場合、定期的に情報を提供することがそれ以上の混乱を防ぐ上で不可欠となります。こうすることで、関係者が何が起こっているのか、どのように対処されているのかについて把握しやすくなり、信頼性が保たれます。
また、"次の更新"の時間を約束することは、関係者が情報を得られる時間を明確にする上で重要です。これにより、関係者は定期的な更新を確実に得られ、不要な問い合わせや混乱が軽減されます。
したがって、"すべてのステークホルダーに定期的な最新情報をタイムリーに提供し、すべてのコミュニケーションにおいて"次の更新"の時間を約束する"という選択肢は、大規模で進行中のインシデントに対する効率的でタイムリーなコミュニケーションスキーマとなります。
不正解についての説明：
選択肢：少なくとも30分ごとに社内のステークホルダーに対応することに重点を置きます。"次の更新"の時間を約束します
この選択肢が正しくない理由は以下の通りです。
障害に影響を受けているのは社内のステークホルダーだけではなく、何が起きているかを知りたいと思っている顧客もいます。
したがって、適切な通信は、社内のステークホルダーだけでなく、影響を受ける全ての人々に対してタイムリーに行わなければならないため、この選択肢は不適切です。
選択肢：社内関係者の電子メールへの対応を、インシデント対応チームの別のメンバーに委ねます。顧客に直接回答を提供することに専念します
この選択肢が正しくない理由は以下の通りです。
指定された選択肢では、社内関係者と顧客を別々に扱うことになり、情報が一貫していない可能性があります。正解は同じ情報を全員にタイムリーに提供することです。分散した対応は情報のニーズを満たす際の効率性と一貫性を損なう可能性があります。
選択肢：すべての社内関係者の電子メールをインシデントコマンダーに提供し、彼らが社内コミュニケーションを管理できるようにします。顧客への直接の回答に重点を置きます
この選択肢が正しくない理由は以下の通りです。
インシデントコマンダーに全ての社内関係者からのメールを管理させるというのは、彼らが本来の障害解決の任務から離れてしまうので効率的ではありません。
また、顧客への回答に重点を置くよりも、全てのステークホルダーに対して定期的に最新情報を提供する方が公平で透明性も担保できます。
参考リンク：
https://cloud.google.com/incident-response/docs
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://sre.google/sre-book/managing-incidents/
</div></details>

### Q. 問題33: 未回答
あなたは、同じGoogle Cloudプロジェクトで、Compute Engine上で動作する複数の本番システムを管理しています。それぞれのシステムには、専用のCompute Engineインスタンスがあります。各システムの実行にかかるコストを知りたいです。
この要件を満たすために、どうすればよいですか？

1. すべてのインスタンスに、実行するシステムに固有のラベルを割り当てます。BigQueryの課金エクスポートとラベルごとのクエリコストを設定します
2. すべてのインスタンスを、実行するシステムに固有のメタデータで強化します。BigQueryにエクスポートするCloud Loggingを設定し、メタデータに基づいてコストをクエリします
3. 各仮想マシン（VM）に実行するシステムの名前を付けます。Cloud Storageのバケットへの使用状況レポートのエクスポートを設定します。そのバケットをBigQueryのソースとして設定し、VM名に基づいてコストをクエリします
4. Google Cloud Consoleでは、Cost Breakdownセクションを使ってシステムごとのコストを可視化します
<details><div>
    答え：1
説明
この問題では、Google Cloudプロジェクトで実行される複数の本番システムがそれぞれCompute Engineインスタンスに存在し、それぞれのシステムの実行にかかるコストを知る方法を考えることが求められています。課題は、個々のシステムのコストを特定できるように（すなわちそれを追跡、履歴化、分析できるように）適切なリソース識別とコスト分析手段をどのように配置するかです。したがって、この問題を解くには、Google Cloudの課金とコスト管理、特にリソースへのラベルの適用、およびGoogle Cloudのデータ分析ツール（特にBigQuery）を理解することが必要です。
基本的な概念や原則：
Compute Engine：Google CloudのIaaS（Infrastructure as a Service）で、仮想マシンを提供します。
ラベル：Google Cloudのリソースをカテゴリに分ける機能です。ラベルを利用することで、リソースの管理や費用の追跡を容易にします。
BigQueryの課金エクスポート：Google Cloudの課金データをBigQueryにエクスポートする機能です。詳細なコスト分析や、長期間のトレンド分析が可能になります。
Google Cloud Console：Google Cloudのリソースを管理するためのウェブベースのインターフェースです。しかし、Cost Breakdownセクションでは各システムの実行コストを確認することはできません。
Cloud Logging：Google Cloudのログまり管理システムです。仮想マシンのメタデータに基づくコストのクエリは、Cloud Loggingではサポートされていません。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。しかし、VM名に関するコスト情報は使用状況レポートには含まれません。
正解についての説明：
（選択肢）
・すべてのインスタンスに、実行するシステムに固有のラベルを割り当てます。BigQueryの課金エクスポートとラベルごとのクエリコストを設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudではラベルを使用して、リソース（この場合はCompute Engineインスタンス）を分類し、それぞれのリソースにタグをつけることが可能です。これにより特定のラベルが付けられたリソース（インスタンス）の利用状況やコストを分析することが容易になります。
また、BigQueryを使用して課金情報をエクスポートすることでコスト情報を詳細に分析できます。BigQueryは高速でフレキシブルなデータ分析ツールなので、ラベルに基づくクエリを設定し、各システムの実行にかかるコストを把握するのに適しています。
したがって、各システムに専用のインスタンスが存在し、そのそれぞれの運用コストを把握したい場合、各インスタンスにシステム固有のラベルを付け、BigQueryの課金エクスポートとラベルごとのクエリコストを設定することで、必要な情報を取得できます。
不正解についての説明：
選択肢：Google Cloud Consoleでは、Cost Breakdownセクションを使ってシステムごとのコストを可視化します
この選択肢が正しくない理由は以下の通りです。
Google Cloud ConsoleのCost Breakdownセクションは、全体的なプロジェクトのコストブレークダウンを提供しますが、具体的なインスタンスレベルのコスト詳細は提供しないため、各システムの実行にかかるコストを特定するためには、ラベルと課金エクスポートを使用する方法が必要となります。
選択肢：すべてのインスタンスを、実行するシステムに固有のメタデータで強化します。BigQueryにエクスポートするCloud Loggingを設定し、メタデータに基づいてコストをクエリします
この選択肢が正しくない理由は以下の通りです。
まず、メタデータは課金に関連する情報を管理するためのものではなく、インスタンスに関する具体的な情報を提供します。
また、Cloud Loggingは主にシステムやアプリケーションのイベントをロギングするものであり、コスト管理のためには不適切です。反対に、ラベルと課金エクスポートを使用すると正確にコストを追跡できます。
選択肢：各仮想マシン（VM）に実行するシステムの名前を付けます。Cloud Storageのバケットへの使用状況レポートのエクスポートを設定します。そのバケットをBigQueryのソースとして設定し、VM名に基づいてコストをクエリします
この選択肢が正しくない理由は以下の通りです。
Google Cloudのコストを追跡するための主流の方法は、リソースへのラベルの割り当てと、それに基づいて課金エクスポートで取得することであり、VMの名前に基づいてコストを追跡することは可能ではありません。
また、使用状況レポートをCloud Storageにエクスポートしても、各VMの詳細なコストデータを提供するものではなく、そのためコスト追跡の要求を満たしません。
参考リンク：
https://cloud.google.com/billing/docs/how-to/labels
https://cloud.google.com/billing/docs/how-to/export-data-bigquery
https://cloud.google.com/bigquery/docs
</div></details>

### Q. 問題34: 未回答
あなたの会社のCTOは、社内で使用するために、すべてのインシデントに関するポストモーテムポリシーを導入するようあなたに依頼しました。あなたは、そのポリシーがあなたの会社で成功するように、良いポストモーテムとは何かを定義したいと思います。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. すべてのポストモーテムに、インシデントの原因、インシデントを引き起こした責任者またはチームの特定、インシデントの今後の発生を防止する方法を含めるようにします
2. すべてのポストモーテムに、何が原因でインシデンとが発生したのか、インシデンとがどのように悪化した可能性があるのか、また、将来、インシデンとが発生するのを防ぐにはどうすればよいのかを含めるようにします
3. すべてのポストモーテムに、すべてのインシデント参加者が含まれるようにし、ポストモーテムをできるだけ広く共有します
4. すべてのポストモーテムに、インシデントの重大性、インシデントの今後の発生を防止する方法、および内部システムコンポーネントの名前を挙げずにインシデントの原因を含めるようにします
5. すべてのポストモーテムに、顧客情報を名指しすることなく、インシデントの解決方法とインシデントの原因を含めるようにします
<details><div>
    答え：2,3
説明
この問題では、それぞれの選択肢が提供するポストモーテムのベストプラクティスと効用、それに関連する社内のimpacted stakeholders（影響を受けるステークホルダー）の参照や彼らへの情報共有の有無、その情報の具体性と精度を試されています。ポストモーテムを成功させるためには、全体的な透明性と責任の免責が重要であり、それはインシデントの理解と改善に役立つ全体的な学習と知識を共有することを目指すべきです。情報を十分に提供しつつ、個別のチームまたは個人への非難を避ける選択肢を見つけるのが重要です。
基本的な概念や原則：
ポストモーテム分析：インシデンとやインシデント後に行われるレビューのことで、何がうまくいかなかったのか、何が原因であったのか、どのように改善可能だったのかを理解し、将来のインシデントを防止するためのプラクティスです。
レビューの公開：ポストモーテムレビューは、関与者全員が参加できるように共有するべきです。これにより、全員が問題の解決に参加し、学びを共有することができます。
インシデントの原因分析：インシデンとやインシデントが発生した原因を適切に識別し、分析することが重要です。この情報は、同様の問題が再発するのを防ぐために使用されます。
フェイルセーフの設計：システムが故障した場合に問題がさらに悪化する可能性を考慮し、それを防止するための方法を特定することが重要です。
適切な情報の共有：ポストモーテム分析には適切な情報が含まれていることが重要で、個々の人やチームを責めたり、顧客情報を不適切に公開したりするべきではありません。重要なのは問題の解決と将来の問題の予防です。
正解についての説明：
（選択肢）
・すべてのポストモーテムに、何が原因でインシデンとが発生したのか、インシデンとがどのように悪化した可能性があるのか、また、将来、インシデンとが発生するのを防ぐにはどうすればよいのかを含めるようにします
・すべてのポストモーテムに、すべてのインシデント参加者が含まれるようにし、ポストモーテムをできるだけ広く共有します
この選択肢が正解の理由は以下の通りです。
まず、インシデンとの原因、インシデンとが悪化した可能性のある要因、そしてそれを防ぐための予防策を明確にすることで、ポストモーテムが具体的な学習をもたらす価値ある過程となります。このような情報は、それぞれのインシデントから学び、同じ問題が再発するのを防ぎ、システムの改善に直接つながる情報であり、ポストモーテムの主要なロールを果たします。
次に、全てのインシデント参加者の意見を反映し、ポストモーテムを広く共有することもまた重要です。このアプローチにより、ポストモーテムは専門家だけでなく関連するすべてのステークホルダーにとっての学習の機会となります。
また、インシデンとが関連するすべての部分を正確に把握し、全体像を理解することができ、一部の人だけが情報を持つという状況を防ぎます。これらがポストモーテムポリシーが社内で成功するための重要な要素です。
不正解についての説明：
選択肢：すべてのポストモーテムに、インシデントの原因、インシデントを引き起こした責任者またはチームの特定、インシデントの今後の発生を防止する方法を含めるようにします
この選択肢が正しくない理由は以下の通りです。
ポストモーテム文化の目的は、非難せずにインシデンとから学ぶためです。
したがって、インシデントを引き起こした責任者またはチームを特定することは、ポストモーテムの目的に反します。適切なポストモーテムは、原因と予防策を特定することに焦点を当てつつ、非難から遠ざけます。
選択肢：すべてのポストモーテムに、インシデントの重大性、インシデントの今後の発生を防止する方法、および内部システムコンポーネントの名前を挙げずにインシデントの原因を含めるようにします
この選択肢が正しくない理由は以下の通りです。
インシデント原因の分析と改善策の提案において、内部システムコンポーネントの名前を伏せてしまうと、真の原因を特定しにくく、解決の道筋を立てるのが難しくなります。効率的な問題解決のため、具体的な情報が必要となるためです。
選択肢：すべてのポストモーテムに、顧客情報を名指しすることなく、インシデントの解決方法とインシデントの原因を含めるようにします
この選択肢が正しくない理由は以下の通りです。
ポストモーテムではインシデントの解決方法と原因だけでなく、インシデンとがどのように悪化した可能性があり、将来のインシデンとを防ぐための改善策も含める必要があります。つまり、ただ原因と解決策を記すだけでは、重要な部分が欠けてしまいます。
参考リンク：
https://cloud.google.com/incident-response
https://cloud.google.com/architecture/creating-a-culture-of-observability
https://landing.google.com/sre/sre-book/chapters/postmortem-culture/
</div></details>

### Q. 問題35: 未回答
本番サービスの一部は、eu-west-1リージョンのGoogle Kubernetes Engine（GKE）で稼働しています。ビルドシステムはus-west-1リージョンで稼働しています。ビルドシステムからコンテナイメージをスケーラブルなレジストリにプッシュして、イメージをクラスターに転送する帯域幅を最大化したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. eu-west-1リージョンのCompute Engineインスタンスで実行されているプライベートイメージレジストリにイメージをプッシュします
2. gcr.ioホスト名を使用してGoogle Container Registry（GCR）にイメージをプッシュします
3. us.gcr.ioホスト名を使用して、Google Container Registry（GCR）にイメージをプッシュします
4. eu.gcr.ioホスト名を使用してGoogle Container Registry（GCR）にイメージをプッシュします
<details><div>
    答え：4
説明
この問題では、Google Kubernetes Engineとビルドシステムが異なるリージョンで稼働しており、その中で最も効率的にコンテナイメージを転送する方法を問われています。ここでは、Google Container Registry（GCR）の特性と利用方法を深く理解し、リージョナルGCRエンドポイントを適切に使用することが求められています。そのために、具体的なリージョンにまで細かく指定してアクセスする方法がかなり重要であり、リージョンの準拠性やイメージリポジトリを適切に管理するための理解が必要です。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：Google Cloudのマネージドコンテナオーケストレーションサービスです。コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を自動化します。
Google Container Registry（GCR）：Google Cloudのプライベートコンテナイメージレジストリサービスです。Dockerイメージを安全にホストし、共有します。
ホスト名によるレジストリの位置指定：GCRでは、ホスト名を変えることでレジストリの地理的な位置を指定できます。例えば、eu.gcr.ioはヨーロッパのレジストリ、us.gcr.ioはアメリカのレジストリを指します。
リージョナルリソース：Google Cloudでは、リソースを指定の地理的なリージョンに配置することができます。これはサービスの公用性、パフォーマンス、コンフライアンス要件に影響します。
ネットワーク帯域幅：データ転送速度を最大化するためには、物理的に近いレジストリを選択することが有効です。理想的には、コンテナイメージの実行場所と同じリージョンのレジストリが最適です。
プライベートイメージレジストリ：独自のコンテナイメージをホストするためのプライベートレジストリです。セキュリティを強化したい場合や特定の要件を満たすために使用しますが、管理が必要です。
正解についての説明：
（選択肢）
・eu.gcr.ioホスト名を使用してGoogle Container Registry（GCR）にイメージをプッシュします
この選択肢が正解の理由は以下の通りです。
Google Container Registry（GCR）は、欧州のeu.gcr.ioというホスト名でアクセス可能な、プライベートなコンテナイメージのストレージサービスです。このホスト名を使用することで、イメージはヨーロッパリージョン、つまり本番サービスが稼働しているeu-west-1と同じリージョンに保存されます。この構成により、クラスターへのイメージ転送時にGKEが高速でアクセスでき、帯域幅が最大化されます。
また、GCRはスケーラブルなレジストリであり、ビルドシステムからプッシュされるイメージの保存や転送に問題なく対処できます。
したがって、これが最適な選択肢になります。
不正解についての説明：
選択肢：gcr.ioホスト名を使用してGoogle Container Registry（GCR）にイメージをプッシュします
この選択肢が正しくない理由は以下の通りです。
"gcr.io"は北米に位置するデータセンターにデータを送ります。ビルドシステムはus-west-1にありますが、イメージを最終的に使用する本番サービスはeu-west-1に存在するため、ヨーロッパの"eu.gcr.io"を利用してイメージをプッシュした方が転送時間が短縮されます。
選択肢：us.gcr.ioホスト名を使用して、Google Container Registry（GCR）にイメージをプッシュします
この選択肢が正しくない理由は以下の通りです。
ビルドシステムがus-west-1リージョンで稼働しているとはいえ、本番サービスはeu-west-1リージョンで稼働しているため、us.gcr.ioを使用すると転送する帯域幅が最大化されません。そのため、eu.gcr.ioを使用することで、転送の帯域幅を最大化することができます。
選択肢：eu-west-1リージョンのCompute Engineインスタンスで実行されているプライベートイメージレジストリにイメージをプッシュします
この選択肢が正しくない理由は以下の通りです。
Compute Engineインスタンスで運用するプライベートイメージレジストリでは、帯域幅の最大化やスカラビリティの確保が困難です。逆にGCRはイメージ配布に最適化されており、帯域幅の最大化を実現できます。
参考リンク：
https://cloud.google.com/container-registry/docs/pushing-and-pulling
https://cloud.google.com/container-registry/docs/overview
https://kubernetes.io/docs/concepts/containers/images/#image-registries
</div></details>

### Q. 問題36: 未回答
あなたの会社は、サイト信頼性エンジニアリングの実践に従っています。あなたは、顧客に影響を与える新しいインシデントのインシデントコマンダーです。効果的なインシデント対応を支援するために、すぐに2つのインシデント管理のロールを割り当てる必要があります。どのようなロールを割り当てるべきですか？（2つ選択）

1. コミュニケーションリード
2. エンジニアリングリード
3. 社外顧客コミュニケーションリーダー
4. オペレーションリード
5. カスタマーインパクト評価者
<details><div>
    答え：1,4
説明
この問題では、サイト信頼性エンジニアリング（SRE）の実践が重視されており、新しいインシデントが発生した際に、どのようなロールを効果的に割り当てるべきかに焦点を当てています。ロールの割り当てがインシデント管理の成熟度、効率性、効果性にどのように影響するかを理解することが求められます。選択肢はSREの主要なロールを代表しており、これらのうちどの2つが具体的な状況に最も適しているかを判断する必要があります。
基本的な概念や原則：
インシデントコマンダー：インシデント対応の全体的な戦略を立て、他のロールと協力して問題の解決を図る責任者のロールです。
オペレーションリード：具体的なインシデントの解決策や作業手順を指示し、技術的な観点からインシデントを解決するロールです。
コミュニケーションリード：インシデントに関するコミュニケーションの責任を持ち、他のチームや顧客への情報の伝達を行うロールです。
サイト信頼性エンジニアリング：システムの信頼性、スケーラビリティ、効率性を向上させるためのエンジニアリング手法です。ソフトウェアエンジニアとシステムエンジニアのスキルセットを組み合わせており、開発と運用のギャップを埋めるロールを果たします。
正解についての説明：
（選択肢）
・オペレーションリード
・コミュニケーションリード
この選択肢が正解の理由は以下の通りです。
オペレーションリードとコミュニケーションリードは、インシデント管理における2つの重要なロールです。オペレーションリードは技術的側面を担当し、インシデントの解決に必要な技術的判断を下します。このロールは具体的な問題解決に焦点を当て、そのための戦略やタスクを導き出すロールを果たします。これにより、インシデントコマンダーは全体的な戦略に焦点を当てることができ、複数の問題の優先順位付けや多面的な問題解決に取り組むことが可能になります。
一方、コミュニケーションリードはインシデントのコミュニケーションを担当します。顧客、ステークホルダー、チーム間など、ステークホルダー全体との交流が必要な場合に重要なロールを果たします。インシデントが発生した際には、迅速かつ適切な情報の提供は必須であり、その情報を関係者に対して明確に伝える重要性は非常に大きいです。このロールが存在することで、インシデントコマンダーは混乱を避け、インシデントへの対応に注力でき、全体的な対策の効率化を図りつつ、信頼性を確保することが可能となります。
不正解についての説明：
選択肢：エンジニアリングリード
この選択肢が正しくない理由は以下の通りです。
サイト信頼性エンジニアリングの実践において、エンジニアリングリードというロールは存在しません。オペレーションリードはインシデント対応の実行、コミュニケーションリードは対外的な情報伝達を担当する重要なロールです。
選択肢：カスタマーインパクト評価者
この選択肢が正しくない理由は以下の通りです。
カスタマーインパクト評価者は具体的なインシデント管理のロールではありません。
一方、オペレーションリードはインシデント対応の詳細な技術的な実行を担当し、コミュニケーションリードは情報の伝達や外部とのコミュニケーションを担当するというロールが明確なロールです。
選択肢：社外顧客コミュニケーションリーダー
この選択肢が正しくない理由は以下の通りです。
インシデント管理において、社外顧客コミュニケーションリーダーという特定のロールは存在しません。正解選択肢のコミュニケーションリード以外の具体的なロールを設ける必要はありません。コミュニケーションリードは、社内外のコミュニケーション全般を担当します。
参考リンク：
https://cloud.google.com/incident-response/docs/incident-response-process#roles
https://cloud.google.com/blog/products/management-tools/incident-management-solution-in-cloud-operations
https://landing.google.com/sre/books/
</div></details>

### Q. 問題37: 未回答
あなたは、Webアプリケーションの新機能がユーザに好評かどうかを確認するための実験を行っています。その機能をカナリアリリースとしてデプロイした直後、ユーザに送信される500エラーの数が急増し、監視レポートが遅延の増加を示しました。あなたは、ユーザーへの悪影響を迅速に最小化したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. インシデントの事後処理のためのデータを記録します
2. レイテンシ、トラフィック、エラー、サチュレーションの監視を開始します
3. 実験的なカナリアのリリースを撤回します
4. 500エラーの発生源と遅延増加の根本原因を追跡します
<details><div>
    答え：3
説明
この問題では、システムへの変更後のエラー増加への対応を求められています。重要な観点は、"ユーザーへの悪影響を迅速に最小化したい"という意図です。選択肢を評価する際は、問題の症状に対処するものだけでなく、ユーザーペインの最小化に貢献する解決策を選ぶ必要があります。対症療法よりも早急な対応が求められていることを念頭に置くことが重要です。
基本的な概念や原則：
カナリアリリース：新しいバージョンのアプリケーションを限定的なユーザー群に対して先にリリースする方法です。全体にリリースする前に新機能の動作確認やユーザの反応を見ることができます。
500エラー：サーバーサイドのエラーを示すHTTPステータスコードです。アプリケーションのランタイムエラーやサーバーの設定ミスなどが原因で発生します。
リリースの撤回：不具合が発見された際や予期しない影響が出た時に、リリースしたバージョンを停止して元のバージョンに戻す操作です。ユーザーへの影響を最小限に抑えるために用いられます。
レイテンシ、トラフィック、エラー、サチュレーション（四つの黄金指標）：システムの健全性を評価するための指標です。これらの情報は監視システムで収集・分析され、アプリケーションのパフォーマンスと信頼性を維持するために使われます。
インシデントの事後処理：システム障害やエラーが発生した後に行われるプロセスで、問題の原因を特定し、再発を防止するための措置を立案します。
正解についての説明：
（選択肢）
・実験的なカナリアのリリースを撤回します
この選択肢が正解の理由は以下の通りです。
カナリアリリースは、新機能をすべてのユーザーに一度にリリースするのではなく、一部のユーザーに先行してリリースし、機能が適切に機能しユーザーにとって有益であることを確認する方法です。
この問題では、新機能のリリース後に500エラーが急増し、レスポンスタイムも遅くなっているため、新機能に問題があることが明らかです。最優先事項はユーザーへの悪影響を最小限に抑えることで、最も迅速な方法は実験的なカナリアリリースを撤回し、システムを新機能リリース前の状態に戻すことです。これにより、それ以上のユーザーが悪影響を受けるのを防ぎ、問題の特定と修正に時間をかけることができます。
不正解についての説明：
選択肢：レイテンシ、トラフィック、エラー、サチュレーションの監視を開始します
この選択肢が正しくない理由は以下の通りです。
新機能リリース後にエラー急増と遅延増加が発生しており、ユーザへの影響を迅速に最小化する必要がある状況で、レイテンシ、トラフィック、エラー、サチュレーションの監視を開始することは、時間的な緊急性を考慮すると妥当な対応とは言えません。直ちに問題の解決が必要であるため、カナリアリリースの撤回が適切です。
選択肢：インシデントの事後処理のためのデータを記録します
この選択肢が正しくない理由は以下の通りです。
インシデントの事後処理のためのデータを記録することはエラー解決に貢献しますが、ユーザへの影響を即座に最小化することはできません。実際の問題の解決はその後のステップで行われます。
一方、カナリアリリースを撤回すれば直ちに問題の影響を最小限に抑えることが可能です。
選択肢：500エラーの発生源と遅延増加の根本原因を追跡します
この選択肢が正しくない理由は以下の通りです。
500エラーの発生源と遅延増加の根本原因を追跡するのは時間がかかります。要件は"ユーザーへの悪影響を迅速に最小化"したいというものなので、即座に実験的なカナリアのリリースを撤回することが最も効率的な対応となります。
参考リンク：
https://cloud.google.com/architecture/best-practices-for-operating-containers
https://cloud.google.com/run/docs/rolling-out-updates
https://cloud.google.com/monitoring/api/metrics_Google Cloud#Google Cloud-loadbalancing
</div></details>

### Q. 問題38: 未回答
あなたはロードバランサーを使わずにHTTPエンドポイントを公開するアプリケーションを管理しています。HTTPレスポンスの待ち時間はユーザーエクスペリエンスにとって重要です。すべてのユーザーが経験しているHTTPレイテンシを把握したいと考えています。あなたはGoogle Cloud Operation Suite Monitoringを使用します。
この要件を満たすために、どうすればよいですか？

1. アプリケーションで、metricKindをMETRIC_KIND_UNSPECIFIEDに設定し、valueTypeをINT64に設定したメトリックを作成します。Google Cloud Operation SuiteのMetrics Explorerで、Stacked Areaグラフを使用してメトリックを視覚化します
2. アプリケーションで、metricKindをCUMULATIVEに設定し、valueTypeをDOUBLEに設定したメトリックを作成します。Google Cloud Operation SuiteのMetrics Explorerで、折れ線グラフを使用してメトリックを視覚化します
3. アプリケーションで、metricKindをGAUGEに設定し、valueTypeをDISTRIBUTIONに設定したメトリックを作成します。Google Cloud Operation SuiteのMetrics Explorerで、Heatmapグラフを使用してメトリックを視覚化します
4. アプリケーションで、metricKindをDELTAに設定し、valueTypeをDOUBLEに設定したメトリックを作成します。Google Cloud Operation SuiteのMetrics Explorerで、Stacked Bar graphを使用してメトリックを視覚化します
<details><div>
    答え：3
説明
この問題では、Google Cloud Operation Suite Monitoringを活用して、ユーザーエクスペリエンスに影響を与えるHTTPレイテンシを把握する方法について問われています。問題文から、ユーザー全体のHTTPレイテンシの分布を把握することが目的であり、メトリックの種類と値、さらには視覚化手段の選択が重要な要素であることが読み取れます。したがって、適切なメトリックスとその種類を選んで設定し、そしてこのデータをどのように視覚化するかがこの問題の重要なポイントです。
基本的な概念や原則：
Google Cloud Operation Suite Monitoring：Google Cloud上のアプリケーションやインフラストラクチャのパフォーマンスをモニタリングするサービスです。リアルタイムでの監視、優れたアラート機能、洞察に対する対応を可能にします。
metricKind：モニタリングデータの種類を指定します。ユースケースに応じてGAUGE、DELTA、CUMULATIVEから選択します。
valueType：モニタリングデータの型を指定します。数値型(double, int64等)や分布型（Distribution）、文字列型（string）などがあります。
メトリックの作成：Google Cloud Operation Suite Monitoringでは、質量（例えばHTTPレイテンシ）を表すメトリックを作成します。メトリックの値は時間とともに変化し、特定の時間帯におけるパフォーマンスを可視化するのに役立ちます。
メトリックの視覚化：Google Cloud Operation SuiteのMetrics Explorerを用いてメトリックを視覚化します。多様なグラフィカル表現が利用可能で、例えばHeatmapグラフはデータの分布を色彩を用いて表現します。
HTTPレイテンシ：ユーザがリクエストを送信してから、それがサーバに到達するまでの時間を指します。高い待ち時間はユーザーエクスペリエンスに悪影響を与えます。
ロードバランサー：トラフィックをリソースに均等に分散して負荷を管理するシステムです。回答例ではロードバランサーを使用せずにHTTPエンドポイントを公開するパターンに触れています。
正解についての説明：
（選択肢）
・アプリケーションで、metricKindをGAUGEに設定し、valueTypeをDISTRIBUTIONに設定したメトリックを作成します。Google Cloud Operation SuiteのMetrics Explorerで、Heatmapグラフを使用してメトリックを視覚化します
この選択肢が正解の理由は以下の通りです。
まず、HTTPレスポンスの待ち時間を計測するためには、メトリックによるモニタリングが必要です。Google Cloud Operation Suite Monitoringでは、カスタムメトリックを作成し、その値を視覚化することが可能です。
また、"metricKind"の設定はメトリックがどのように解釈されるかを管理します。GAUGEを設定すると、一定の時間間隔で計測されたその時点の値が記録されるため、レイテンシのようなリアルタイムな待ち時間を捉えることが可能となります。
次に、"valueType"のDISTRIBUTIONは、値の分布を表現するために使用されます。これにより、HTTPレスポンスの待ち時間の分布を取得できます。
加えて、Metrics ExplorerのHeatmapグラフを使用することで、全てのユーザーが経験しているHTTPレイテンシの分布を視覚的に確認することができます。このため、この選択肢が求められている解答であると言えます。
不正解についての説明：
選択肢：アプリケーションで、metricKindをDELTAに設定し、valueTypeをDOUBLEに設定したメトリックを作成します。Google Cloud Operation SuiteのMetrics Explorerで、Stacked Bar graphを使用してメトリックを視覚化します
この選択肢が正しくない理由は以下の通りです。
metricKindをDELTAに設定した場合、それは値の変化量を表すので、HTTPレイテンシのような一定期間の値分布を視覚化するには不適切です。
また、valueTypeをDOUBLEに設定したメトリックは単一の数値を表すので分布情報を持てません。
それに対して、正解では、GAUGEで瞬間的な値を取り、DISTRIBUTIONで分布情報を持つことで要件を満たします。
選択肢：アプリケーションで、metricKindをCUMULATIVEに設定し、valueTypeをDOUBLEに設定したメトリックを作成します。Google Cloud Operation SuiteのMetrics Explorerで、折れ線グラフを使用してメトリックを視覚化します
この選択肢が正しくない理由は以下の通りです。
metricKindをCUMULATIVEにし、valueTypeをDOUBLEに設定すると、時間経過に伴う累積データを得ることができますが、それだけでは全ユーザーのHTTPレイテンシの分布を正確に把握することができません。比較的に、GAUGEとDISTRIBUTION設定を用いると、ユーザー全体のHTTPレイテンシの分布が視覚的に理解しやすくなります。
選択肢：アプリケーションで、metricKindをMETRIC_KIND_UNSPECIFIEDに設定し、valueTypeをINT64に設定したメトリックを作成します。Google Cloud Operation SuiteのMetrics Explorerで、Stacked Areaグラフを使用してメトリックを視覚化します
この選択肢が正しくない理由は以下の通りです。
METRIC_KIND_UNSPECIFIEDやINT64では、値の分布やパターンを捉えることができません。これに比べ、正解の選択肢ではGAUGEとDISTRIBUTIONが使われ、全ユーザーの経験するHTTPレイテンシの詳細な分布を把握できます。Stacked Areaグラフでは分布の視覚化に限界があります。
参考リンク：
https://cloud.google.com/monitoring/custom-metrics/creating-metrics
https://cloud.google.com/monitoring/charts/metrics-explorer
https://www.oreilly.com/library/view/google-cloud-certified/9781492092234/
</div></details>

### Q. 問題39: 未回答
Cloud Runを使用してサーバーレスアプリケーションを構築し、そのアプリケーションを本番環境にデプロイしました。あなたはコスト最適化のためにアプリケーションのリソース使用率を特定したいと考えています。
この要件を満たすために、どうすればよいですか？

1. Cloud Opsを使用してログベースのメトリクスを作成し、アプリケーションのリソース使用率を監視します
2. 分散トレース機能付きのCloud Traceを使用して、アプリケーションのリソース使用率を監視します
3. Ops AgentとCloud Profilerを使用して、アプリケーションのCPUとメモリの使用率を監視します
4. Cloud Monitoringを使用して、アプリケーションのコンテナCPUとメモリ使用率を監視します
<details><div>
    答え：4
説明
この問題では、サーバーレスアプリケーションのリソース使用率を特定することが目的で、そのアプリケーションはCloud Runにデプロイされているという事実が重要です。そのため問題解決のためには、Cloud Run用の適切な監視ツールを選択することが重要です。選択肢の中からCloud Runのアプリケーションに適切な監視ツールを選ぶことが求められます。ここでは、リソース使用率を監視するために適切なツールの選択が問われているのでそれに注目することが求められています。
基本的な概念や原則：
Cloud Run：コンテナ化されたアプリケーションをフルマネージドで実行するサービスです。サーバーレス環境での実行を可能にします。
Cloud Monitoring：Google Cloudのアプリケーションやインフラストラクチャのパフォーマンスを追跡し、視覚化するための監視サービスです。リソース使用率などの重要なメトリクスを提供します。
Cloud Trace：アプリケーションのパフォーマンスボトルネックを特定するための分散トレーシングシステムです。しかし、リソース使用率の監視には使用できません。
Ops Agent：Google Cloudのロギング、メトリクス、トレーシングエージェントです。しかし、メモリやCPU使用率に特化した監視能力はなく、Cloud Monitoringと組み合わせて使用されることが一般的です。
Cloud Profiler：Google Cloudのアプリケーションパフォーマンス管理ツールです。アプリケーションの実行時間を視覚化し、パフォーマンス問題を特定します。しかし、リソース使用率の監視には使用できません。
Cloud Ops：Google Cloudのオペレーションスイートです。ログ管理、エラーレポーティング、トレーシング、モニタリングなどの機能を提供します。しかし、ログベースのメトリクス作成はリソース使用率の監視だけでなく、他の多くの目的にも使用されます。
正解についての説明：
（選択肢）
・Cloud Monitoringを使用して、アプリケーションのコンテナCPUとメモリ使用率を監視します
この選択肢が正解の理由は以下の通りです。
まず、Cloud MonitoringはGoogle Cloudの監視、警告、診断ツールであり、アプリケーションのパフォーマンス、稼働状況、リソース使用率を追跡および可視化する機能を提供します。これはコスト最適化のためにあなたが必要としている機能であり、リソース使用率の特定に役立ちます。
また、Cloud MonitoringではCloud Runの各アプリケーションが使用しているCPUとメモリの詳細データを取得することができます。これにより、過負荷や過剰なリソース配分を特定し、最適化することが可能です。
したがって、Cloud Runのアプリケーションのコスト最適化を追求する場合、Cloud Monitoringは有効なツールと言えます。特に、サーバーレスアプリケーションのリソース使用状況を監視し、パフォーマンスを最適化する上で欠かせないサービスです。
不正解についての説明：
選択肢：分散トレース機能付きのCloud Traceを使用して、アプリケーションのリソース使用率を監視します
この選択肢が正しくない理由は以下の通りです。
Cloud Traceの分散トレース機能はアプリケーションのパフォーマンス問題を診断するのに役立ちますが、リソースのCPUやメモリ利用率を監視するためのものではありません。
それに対して、Cloud Monitoringはリソース使用率を視覚的に監視し解析する機能を提供しています。
選択肢：Ops AgentとCloud Profilerを使用して、アプリケーションのCPUとメモリの使用率を監視します
この選択肢が正しくない理由は以下の通りです。
Ops AgentとCloud Profilerはインフラやアプリケーションのパフォーマンスの詳細監視やプロファイリングには役立つが、サーバーレス環境でのリソース使用率の監視は直接的には行えません。
一方、Cloud MonitoringはコンテナのCPUやメモリ使用率を直接監視可能なので、この問題の要件を満たします。
選択肢：Cloud Opsを使用してログベースのメトリクスを作成し、アプリケーションのリソース使用率を監視します
この選択肢が正しくない理由は以下の通りです。
Cloud Opsは、Cloud Operationsの略であり、その一部にCloud Monitoringが含まれます。しかし、リソースの使用率を監視するためには、Cloud Monitoringの機能が直接必要となるため、正解の選択肢の方が具体的に正しい操作を指しています。ログベースのメトリクスではリソース使用率の監視が十分に行われません。
参考リンク：
https://cloud.google.com/monitoring
https://cloud.google.com/run/docs/monitoring/metrics
https://cloud.google.com/trace/docs
</div></details>

### Q. 問題40: 未回答
あなたの組織には、オンプレミスで動作するコンテナ化されたWebアプリケーションがあります。Google Cloudへの移行計画の一環として、以下の受け入れ基準を満たすデプロイ戦略とプラットフォームを選択する必要があります：
1.プラットフォームは、AndroidデバイスからのトラフィックをAndroid固有のマイクロサービスに誘導できなければなりません。
2.プラットフォームは、任意のパーセンテージベースのトラフィック分割が可能である必要があります。
3.デプロイメント戦略により、あらゆるマイクロサービスの複数のバージョンを継続的にテストできなければなりません。
あなたはこの要件を満たすために、どうすればよいですか？

1. アプリケーションのカナリアリリースをApp Engineにデプロイします。トラフィックの分割を使用して、IPアドレスに基づいてユーザートラフィックのサブセットを新しいバージョンに誘導します
2. アプリケーションのカナリアリリースをCompute Engineにデプロイします。Compute EngineでAnthos Service Meshを使用し、仮想サービスを設定することで、ユーザートラフィックの10%をカナリアリリースに誘導します
3. アプリケーションのカナリアリリースをCloud Runにデプロイします。トラフィック分割を使用して、リビジョンタグに基づいて、ユーザートラフィックの10%をカナリアリリースに誘導します
4. Anthosサービスメッシュを使ってGoogle Kubernetes Engineにカナリアリリースをデプロイします。トラフィックの分割を使用して、仮想サービスに設定されたユーザーエージェントヘッダーに基づき、ユーザートラフィックの10%を新しいバージョンに誘導します
<details><div>
    答え：4
説明
この問題では、コンテナ化されたWebアプリケーションをGoogle Cloudに適切に移行し、特定の要件を満たす最適なデプロイ戦略とプラットフォームを選ぶ方法を問います。目標とする要件には、Androidデバイスのトラフィックを特定のマイクロサービスに誘導する能力、任意のパーセンテージベースでのトラフィック分割が可能であること、複数のマイクロサービスのバージョンを同時にテストできるデプロイ戦略の必要性が含まれています。Google Cloudのサービスの理解と、それがどのように上記の要件を満たすのかを評価することがキーとなります。選択肢を吟味する際には、それぞれが提供する機能と限界を考慮しながら選択肢の詳細を注意深く確認することが重要です。
基本的な概念や原則：
Anthos Service Mesh：Google Cloudのサービスで、マイクロサービス間の通信を統制し、セキュリティ、ロードバランシング、モニタリングおよび診断の機能を提供します。
Google Kubernetes Engine（GKE）：マネージドなKubernetesサービスで、エンタープライズレベルのコンテナ化されたアプリケーションを構築、デプロイ、スケーリングするためのプラットフォームです。
カナリアリリース：新バージョンのアプリケーションを一部のユーザーだけに配布するデプロイ戦略で、新機能の影響をリスクを最小限に留めながら確認することが可能です。
トラフィック分割：異なるバージョンのアプリケーションやサービス間でトラフィックを分割します。パーセンテージベースで調整可能で、段階的なロールアウトやABテストに使われます。
Cloud Run：フルマネージド型のサーバーレスプラットフォームで、コンテナ化されたアプリケーションをデプロイし、自動的にスケールアップダウンします。
App Engine：開発者がアプリケーションをビルド、デプロイ、スケールできるフルマネージド型のPaaSです。自動的なスケーリング、ロードバランシング、マネージドランタイムなどの機能を持ちます。
Compute Engine：Google CloudのIaaSプロダクトで、仮想マシンを作成、管理するためのサービスです。
正解についての説明：
（選択肢）
・Anthosサービスメッシュを使ってGoogle Kubernetes Engineにカナリアリリースをデプロイします。トラフィックの分割を使用して、仮想サービスに設定されたユーザーエージェントヘッダーに基づき、ユーザートラフィックの10%を新しいバージョンに誘導します
この選択肢が正解の理由は以下の通りです。
まず、Anthos Service Meshは、マイクロサービス間での通信の管理と制御を提供するサービスメッシュプラットフォームであり、Google Kubernetes Engine（GKE）と一緒に使用されます。この組み合わせは、ANDROIDデバイスからのトラフィックをAndroid固有のマイクロサービスに誘導する機能を持つエンヴォイベースのプロキシを提供します。これは、WebアプリケーションでUser-Agent HTTPヘッダーを使用してトラフィックルーティングを行う機能を意味します。
また、Anthos Service Meshは任意のパーセンテージのトラフィック分割もサポートしています。これにより、新旧バージョン間でトラフィックを効率的に分割し、新機能の影響を評価することが可能となります。
さらに、カナリアリリースとは新バージョンのサービスを限定的に展開し、問題がないことを確認しながら全体に展開していくデプロイ戦略のことを指し、これによって複数のバージョンを継続的にテストする要件にも対応します。この機能により、問題がある場合にはすぐにロールバックするなど、運用の柔軟性と安全性が高まります。
不正解についての説明：
選択肢：アプリケーションのカナリアリリースをCloud Runにデプロイします。トラフィック分割を使用して、リビジョンタグに基づいて、ユーザートラフィックの10%をカナリアリリースに誘導します
この選択肢が正しくない理由は以下の通りです。
Cloud Runはトラフィック分割機能を提供しますが、ユーザーエージェントヘッダーに基づいたトラフィックの誘導はサポートしておらず、特定のマイクロサービスにAndroidからのトラフィックを誘導するという要件を満たせません。これに対してAnthosサービスメッシュならこの機能をサポートしています。
選択肢：アプリケーションのカナリアリリースをApp Engineにデプロイします。トラフィックの分割を使用して、IPアドレスに基づいてユーザートラフィックのサブセットを新しいバージョンに誘導します
この選択肢が正しくない理由は以下の通りです。
App EngineのカナリアリリースはIPアドレスに基づいてユーザートラフィックを分割することが可能ですが、Androidデバイスからのトラフィックを特定のマイクロサービスに誘導することはできません。この要件を満たすためには、ユーザーエージェントヘッダーに基づくトラフィック誘導が可能なAnthosサービスメッシュのようなソリューションが必要です。
選択肢：アプリケーションのカナリアリリースをCompute Engineにデプロイします。Compute EngineでAnthos Service Meshを使用し、仮想サービスを設定することで、ユーザートラフィックの10%をカナリアリリースに誘導します
この選択肢が正しくない理由は以下の通りです。
Compute EngineはAnthos Service Meshのサポート対象外であるため、この設定を利用することはできません。
したがって、Compute Engineを使用したシナリオは提供要件を満たさない適切な解決策ではなく、Google Kubernetes Engineを使用するほうが適しています。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/concepts/traffic-management
https://cloud.google.com/anthos-service-mesh/docs
https://cloud.google.com/kubernetes-engine/docs/how-to/deploying-apps
</div></details>

### Q. 問題41: 未回答
あなたの開発チームは、自社サービスのAPIの新バージョンを作成しました。あなたは、サードパーティの開発者やサードパーティがインストールしたアプリケーションのエンドユーザーへの混乱を最小限に抑えながら、新バージョンのAPIをデプロイする必要があります。
この要件を満たすために、どうすればよいですか？

1. 旧バージョンのAPIの廃止をアナウンスします。新バージョンのAPIを導入します。旧バージョンのAPIを使用しているユーザーに連絡します。旧バージョンのAPIを廃止します。旧バージョンのAPIを停止します。旧バージョンのAPIを使用しているユーザーにベストエフォートサポートを提供します
2. 新バージョンのAPIを導入します。旧APIの残存ユーザーに連絡します。旧バージョンのAPIの非推奨をアナウンスします。旧バージョンのAPIを廃止します。旧バージョンのAPIを停止します。旧バージョンのAPI利用者にベストエフォートサポートを提供します
3. 新しいバージョンのAPIを導入します。旧バージョンのAPIの非推奨をアナウンスします。旧バージョンのAPIを廃止します。旧APIの残存ユーザーに連絡します。旧APIの利用者にベストエフォートサポートを提供します。旧バージョンのAPIを停止します
4. 旧バージョンのAPIの廃止をアナウンスします。旧バージョンのAPIを使用しているユーザーに連絡します。新バージョンのAPIを導入します。旧バージョンのAPIを廃止します。旧バージョンのAPI利用者にベストエフォートサポートを提供します。旧バージョンのAPIを停止します
<details><div>
    答え：3
説明
この問題では、新しいAPIバージョンをデプロイするにあたってどのように進めるべきかについて問われています。サードパーティの開発者やエンドユーザーを混乱させないためにどのようなステップを踏むべきかが重要です。旧バージョンの非推奨や直接停止、新しいバージョンの導入時や旧バージョンの停止時にどのような連絡を行う必要があるかなど、変更を追跡できるような適切なプロセスが求められています。それぞれの選択肢の内容や順序を慎重に比較検討しつつ、最も適切なAPIのバージョンアップ戦略を選びます。
基本的な概念や原則：
APIバージョニング：APIのバージョン管理は、APIの変更を他のサービスやアプリケーションが利用しやすいように調整するプロセスです。新しいバージョンのAPIを導入する際には、旧バージョンのAPIの廃止前に通知を行います。
非推奨アナウンス：非推奨とするAPIバージョンの情報を公告することで、利用者にバージョンアップの必要性を伝えます。これはエンドユーザーやサードパーティ開発者に対する混乱を最小限に抑えるために重要です。
APIの廃止：APIのバージョンが非推奨となった後、一定期間を経てAPIを完全に廃止します。これにより、利用者は新しいAPIバージョンへの移行を計画することができます。
ユーザーへの通知：非推奨となるAPIの利用者に対して通知を行い、新しいバージョンへの移行を促します。これにより、利用者が突然のAPI変更による影響を受けることを防ぎます。
ベストエフォートサポート：非推奨となったAPIバージョンの利用者に対して、限られたリソース内でのサポートを提供します。これにより、利用者が新バージョンへの移行をスムーズに行うことを支援します。
APIの停止：最終的には非推奨となったAPIバージョンを完全に停止します。これは新しいバージョンのAPIの導入および旧バージョンの廃止プロセスの最終ステップです。
正解についての説明：
（選択肢）
・新しいバージョンのAPIを導入します。旧バージョンのAPIの非推奨をアナウンスします。旧バージョンのAPIを廃止します。旧APIの残存ユーザーに連絡します。旧APIの利用者にベストエフォートサポートを提供します。旧バージョンのAPIを停止します
この選択肢が正解の理由は以下の通りです。
サードパーティの開発者やエンドユーザーへの混乱を最小限に抑えるためには、変更に対する透明性と段階的な移行が非常に重要となります。まず、新しいバージョンのAPIを導入することで、開発者達は新バージョンのAPIに対して十分な理解と準備を進めることができます。
そして、旧バージョンのAPIの非推奨をアナウンスすることで、開発者達は新バージョンへの移行を開始し、新旧APIの違いを把握する時間を与えることが可能となります。
さらに、旧バージョンのAPI廃止前に、残存ユーザーに通知することで、最終的な移行を促すことが可能となります。ベストエフォートサポートを提供することで、旧APIの利用者へも必要なサポートを提供し、無駄な混乱を避けることができます。そして最終的に旧バージョンのAPIを停止し、全てのユーザーを新バージョンのAPIへと移行します。
不正解についての説明：
選択肢：旧バージョンのAPIの廃止をアナウンスします。新バージョンのAPIを導入します。旧バージョンのAPIを使用しているユーザーに連絡します。旧バージョンのAPIを廃止します。旧バージョンのAPIを停止します。旧バージョンのAPIを使用しているユーザーにベストエフォートサポートを提供します
この選択肢が正しくない理由は以下の通りです。
新バージョンのAPIを導入する前に旧バージョンのAPIの廃止をアナウンスすると、ユーザーに混乱を与える可能性があります。まず新バージョンをリリースし、その後で旧バージョンの非推奨をアナウンスすることで、ユーザーは新旧バージョンの違いを理解しやすくなります。
選択肢：旧バージョンのAPIの廃止をアナウンスします。旧バージョンのAPIを使用しているユーザーに連絡します。新バージョンのAPIを導入します。旧バージョンのAPIを廃止します。旧バージョンのAPI利用者にベストエフォートサポートを提供します。旧バージョンのAPIを停止します
この選択肢が正しくない理由は以下の通りです。
新バージョンのAPIを導入する前に旧バージョンのAPIの廃止をアナウンスすると、サードパーティの開発者やエンドユーザーに混乱を引き起こします。新バージョンの導入とその利用方法を明確に伝えてから、旧バージョンの非推奨をアナウンスするほうがスムーズな移行が可能です。
選択肢：新バージョンのAPIを導入します。旧APIの残存ユーザーに連絡します。旧バージョンのAPIの非推奨をアナウンスします。旧バージョンのAPIを廃止します。旧バージョンのAPIを停止します。旧バージョンのAPI利用者にベストエフォートサポートを提供します
この選択肢が正しくない理由は以下の通りです。
旧APIの非推奨をアナウンスするのが残存ユーザーへの連絡よりも後となるため、サードパーティ開発者やエンドユーザーは予期せぬ影響を受ける可能性があります。処理の手順が正解の選択肢と異なり、混乱を最小限に抑えるという要件を満たしていません。
参考リンク：
https://cloud.google.com/endpoints/docs/openapi/versioning-an-api
https://cloud.google.com/apigee/docs/api-platform/publish/deprecations
https://cloud.google.com/architecture/api-design/versioning-apis
</div></details>

### Q. 問題42: 未回答
Google Kubernetes Engine（GKE）で動作するアプリケーションがあります。アプリケーションは、デプロイメントとサービスを使用してGKEにデプロイされた複数のマイクロサービスで構成されています。マイクロサービスの1つに、ポッドが5時間以上実行された後に403エラーを返す問題が発生しています。開発チームは解決策に取り組んでいますが、この問題は1ヶ月間解決しません。マイクロサービスが修正されるまで運用を継続する必要があります。Googleが推奨するプラクティスに従い、最も少ないステップ数で実行したいと考えています。
この要件を満たすために、どうすればよいですか？

1. ポッドが403エラーを返すたびに通知するアラートを設定します
2. Podを監視し、5時間以上稼働しているポッドを終了します
3. 5時間以上稼働しているポッドを終了させるcronジョブを作成します
4. マイクロサービスのデプロイメントにHTTP livenessプローブを追加します
<details><div>
    答え：4
説明
この問題では、GKEを利用したマイクロサービス環境で運用上の問題が発生しているときの対処法を求められています。5時間以上実行された後に発生する403エラーに対して、開発チームが修正策を探している間も運用を続けなければならないというのが要件です。それぞれの選択肢がこの問題をどの程度解決するかを了解した上で、最も効率的でGoogleが推奨するプラクティスに適合する策を選択する必要があります。
基本的な概念や原則：
HTTP livenessプローブ：Kubernetesの一部で、稼働中のポッドが正常に動作しているかを確認する手段です。定期的にエンドポイントへのHTTPリクエストを送ることで動作を確認します。レスポンスが異常な場合、ポッドを再起動します。
マイクロサービス：アプリケーションを機能単位に分割した独立したサービスのことです。各サービスを独立して開発、デプロイ、スケーリングすることができます。
Kubernetes Deployment：アプリケーションを管理するためのKubernetesオブジェクトです。デプロイメントを更新するとポッドのローリング更新が行われます。
Kubernetes Service：Kubernetesにおける永続的なサービスエンドポイントのことです。サービスはポッドを選択し、ネットワークトラフィックをルーティングします。
cronジョブ：定期的なタスクをスケジュールするためのUNIXのユーティリティです。Kubernetesでは、時間ベースのスケジュールでジョブを実行するためのオブジェクトを提供しています。
正解についての説明：
（選択肢）
・マイクロサービスのデプロイメントにHTTP livenessプローブを追加します
この選択肢が正解の理由は以下の通りです。
HTTP livenessプローブは、Kubernetesによって定期的にマイクロサービス（Pod）に対してリクエストを行い、その応答をもとにポッドの生存状況を判断するために使用されます。403エラーを返すという問題が発生しているのであれば、HTTP livenessプローブはそれを検出し、問題のあるポッドを自動的に再起動します。これにより、問題が発生したポッドがサービスから取り除かれ、新しいポッドが問題のポッドの代わりに生成・配置されます。
したがって、アプリケーションの持続的な可用性を確認することができます。
また、この冗長性の高さと自動修復の機能は、開発チームが問題を解決するまでの一時的な対処として効果的です。HTTP livenessプローブの設定は、マイクロサービスのデプロイメント設定に追加するだけで実行できるため、これが最も少ないステップ数で実行できる解決策と言えます。
不正解についての説明：
選択肢：5時間以上稼働しているポッドを終了させるcronジョブを作成します
この選択肢が正しくない理由は以下の通りです。
cronジョブを作成して5時間以上稼働しているポッドを終了させるのは、リソース管理が複雑化し、管理が難しくなる上にスケールする際の効率も良くありません。
それに対して、HTTP livenessプローブを使用することで、異常を検知した場合にKubernetes自身が自動的にポッドを再起動し問題を修正します。これにより、最も少ないステップ数で運用を継続できます。
選択肢：Podを監視し、5時間以上稼働しているポッドを終了します
この選択肢が正しくない理由は以下の通りです。
ポッドを監視して5時間以上稼働しているポッドを手動で終了する方法は、操作が煩雑であり、Googleが推奨する自動的なヘルスチェックに従っていません。
それに対し、HTTP livenessプローブを追加することで、自動的にヘルスチェックを行い、異常があった場合に自動でポッドの再起動が行われます。よって、より少ないステップ数で問題を解決できます。
選択肢：ポッドが403エラーを返すたびに通知するアラートを設定します
この選択肢が正しくない理由は以下の通りです。
ポッドが403エラーを返すたびに通知するアラートを設定するという手法は、問題の発生を監視・通知するだけであり、問題の根本的な解決にはつながりません。
一方で、HTTP livenessプローブを追加するという手法は、ポッドがエラーを返す場合に自動的に再起動し、運用を円滑に進めることが可能となります。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/monitoring
https://cloud.google.com/kubernetes-engine/docs/concepts/pod-lifecycle#liveness_and_readiness_probes
https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
</div></details>

### Q. 問題43: 未回答
アプリケーションイメージはCloud Buildを使ってビルドされ、Google Container Registry（GCR）にプッシュされます。ソース管理でタグ付けされたリリースバージョンに基づいて、デプロイ用にアプリケーションの特定のバージョンを指定できるようにしたいと考えています。
イメージをプッシュするときに何をすべきですか？

1. ソースコントロールタグをイメージ名のパラメータとして指定します
2. アプリケーションイメージにリリースバージョンタグを含めるには、Cloud Buildを使用します
3. GCRダイジェストバージョニングを使用して、ソースコントロールのタグとイメージを一致させます
4. ソースコントロールタグでイメージダイジェストを参照します
<details><div>
    答え：2
説明
この問題では、アプリケーションイメージのビルドとリリースバージョンの管理方法について扱っています。アプリケーションイメージがCloud Buildでビルドされ、Google Container Registryにプッシュされるという会社の実態を理解することが重要です。問題文から明らかになっている目標は、特定のアプリケーションのバージョンを指定してデプロイできるようにすることです。
基本的な概念や原則：
Cloud Build：Google Cloud上でのコードのビルド、テスト、デプロイなどを行うフルマネージドタイプのサービスです。Dockerコンテナのイメージビルドにも利用できます。
Google Container Registry（GCR）：Dockerイメージを安全にホストし、共有するためのプライベートコンテナイメージレジストリです。Cloud Buildと組み合わせて使うことで、CI/CDパイプラインを効率的に運用できます。
イメージタグ：Dockerイメージに付けるラベルです。通常、ソフトウェアのバージョンを示すために使われます。Cloud Buildでは、タグを使ってプッシュしたイメージを簡単に識別したり管理したりできます。
ダイジェスト：Dockerイメージの一意の識別子です。特定のイメージのインスタンスを一意に指定するために使用されます。しかし、識別にソースコントロールタグを使うことは推奨されません。
正解についての説明：
（選択肢）
・アプリケーションイメージにリリースバージョンタグを含めるには、Cloud Buildを使用します
この選択肢が正解の理由は以下の通りです。
Cloud Buildはアプリケーションコードのビルド、テスト、デプロイに役立つGoogle Cloudのサービスです。このサービスによって生成されたイメージは、Artifact Registryに保存され、ユーザーは任意のタグを付けることができます。それにより特定のバージョンのアプリケーションイメージを簡単に参照できます。
そして、タグ付けシステムは一貫性と組織の安定性を提供し、後で特定のバージョンのイメージにアクセスする際に簡単に照会を行えます。
したがって、リリースのバージョン管理が求められる場合、Cloud Buildを使用してアプリケーションイメージにリリースバージョンのタグを含めるのは良い選択と言えます。
不正解についての説明：
選択肢：ソースコントロールタグでイメージダイジェストを参照します
この選択肢が正しくない理由は以下の通りです。
ソースコントロールタグでイメージダイジェストを参照する方法は、特定のイメージバージョンを指定する事はできますが、それがリリースバージョンに基づいているとは限らず、タグ付けの自動化は行えません。
一方、Cloud Buildを使用してアプリケーションイメージにリリースバージョンタグを含めるなら、ビルドとデプロイのプロセスを自動化し、特定のリリースバージョンに基づいてイメージを指定することが可能になります。
選択肢：ソースコントロールタグをイメージ名のパラメータとして指定します
この選択肢が正しくない理由は以下の通りです。
ソースコントロールタグをイメージ名のパラメータとして指定しても、特定のバージョンのイメージをデプロイする際にそのバージョンを明示的に指定することは困難です。対比的に、Cloud Buildを使用してリリースバージョンタグを含めた場合、バージョンを指定してデプロイすることが容易になります。
選択肢：GCRダイジェストバージョニングを使用して、ソースコントロールのタグとイメージを一致させます
この選択肢が正しくない理由は以下の通りです。
ダイジェストバージョニングは、イメージのコンテンツに基づいて一意の識別子を生成するものであり、ソース管理のタグと一致させることはできません。
それに対して、Cloud Buildを使用してアプリケーションイメージにタグを付けることで、タグでバージョン管理するための関連付けを可能にします。
参考リンク：
https://cloud.google.com/build/docs/configuring-builds/store-images-artifacts
https://cloud.google.com/container-registry/docs/managing
https://docs.docker.com/engine/reference/commandline/tag/
</div></details>

### Q. 問題44: 未回答
あなたのチームは、データのバッチに対して計算負荷の高い処理を行うサービスを構築しています。データはマシンのCPUの速度と数に基づいて高速に処理されます。これらのデータバッチのサイズはさまざまで、複数のサードパーティソースから随時届く可能性があります。サードパーティがデータを安全にアップロードできるようにする必要があります。コストを最小限に抑えつつ、可能な限り迅速にデータを処理したいと考えています。
この要件を満たすために、どうすればよいですか？

1. サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。標準的なGoogle Kubernetes Engine（GKE）クラスターを使用し、2つのサービスを維持します。1つはデータのバッチを処理するサービス、もう1つは新しいデータのバッチがないかCloud Storageを監視するサービスです。処理するデータのバッチがないときは、処理サービスを停止します
2. 第三者がデータのバッチをアップロードできるように、Compute Engineインスタンス上に安全なファイル転送プロトコル（SFTP）サーバーを提供し、サーバーに適切な認証情報を提供します。google.storage.object.finalize Cloud Storageトリガーを使用してCloud Functionsを実装します。この関数がCompute Engineのオートスケーリングマネージドインスタンスグループをスケールアップできるようにコードを記述します。処理が完了するとインスタンスを終了するデータ処理ソフトウェアがあらかじめロードされたイメージを使用します
3. サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。Cloud Monitoringを使用して、バケット内の新しいデータバッチを検出し、データを処理するCloud Functionsをトリガーします。処理の実行時間を最小限に抑えるために、可能な限り最大のCPUを使用するようにCloud Functionsを設定します
4. サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。google.storage.object.finalize Cloud Storageトリガーを持つCloud Functionを作成します。処理が完了したらインスタンスを終了させるデータ処理ソフトウェアがあらかじめロードされたイメージを使用します
<details><div>
    答え：4
説明
この問題では、高負荷のバッチ処理を効率的かつコスト効果的に行うための最良の方法を選びます。異なるサードパーティソースからデータが任意のタイミングで送られてくるという条件に対応できる柔軟さ、データのアップロードのための安全な手段、そしてコスト効率の良さを考慮して適切な選択肢を選ぶことが求められています。Google Cloudの各サービスの特性とそれらを使ったコスト効率の高いデータ処理の方法について理解していなければなりません。
基本的な概念や原則：
Cloud Storage：Google Cloudのデータストレージサービスで、データのバッチを安全に保存し、アクセスし、共有することが可能です。
IAM（Identity and Access Management）：Google Cloudの認証と認可を管理するツールです。特定のユーザーやサービスに対してリソースへのアクセス権限を細かく制御することができます。
Cloud Functions：イベント駆動型のサーバーレス環境で、時間やリソースの管理をせずにコードを実行することができます。特定のイベントに対して自動的にスケーリングします。
Cloud Storageトリガー：Cloud Storageで特定のイベントが発生したときにCloud Functionsを自動的に呼び出す機能です。特定のバケットにデータが追加・変更された時点でトリガーされることが一般的です。
Compute Engine：仮想マシンを実行するGoogle Cloudのインフラストラクチャサービスです。必要な仕様と量を選び、デプロイ及びスケーリングが可能です。
オートスケーリング：負荷に基づいて自動的にリソースの数を増減させる機能です。Compute EngineではVMのインスタンス数を動的に調節します。
Google Kubernetes Engine（GKE）：Google CloudでKubernetes環境を簡単にセットアップ、運用できるサービスです。稼働中のアプリケーションのスケーリングと配信を管理します。
正解についての説明：
（選択肢）
・サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。google.storage.object.finalize Cloud Storageトリガーを持つCloud Functionを作成します。処理が完了したらインスタンスを終了させるデータ処理ソフトウェアがあらかじめロードされたイメージを使用します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Storageバケットをサードパーティに提供することで、データやバッチのアップロードが容易になるだけでなく、IAMを使用して適切なアクセス制限を設けることができます。これによりセキュリティが強化されます。
次に、google.storage.object.finalize Cloud Storageトリガーを持つCloud Functionを作成すると、オブジェクトがバケットに最終的にアップロードされたタイミングで自動的に関数が実行されます。これにより、新たなデータが追加されるたびに即座にデータの処理が開始されることになります。
最後に、処理が完了したらインスタンスを終了させるソフトウェアを使用すれば、必要な時間だけリソースを使うようになり、コストを最小限に抑えることができます。これらの理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：第三者がデータのバッチをアップロードできるように、Compute Engineインスタンス上に安全なファイル転送プロトコル（SFTP）サーバーを提供し、サーバーに適切な認証情報を提供します。google.storage.object.finalize Cloud Storageトリガーを使用してCloud Functionsを実装します。この関数がCompute Engineのオートスケーリングマネージドインスタンスグループをスケールアップできるようにコードを記述します。処理が完了するとインスタンスを終了するデータ処理ソフトウェアがあらかじめロードされたイメージを使用します
この選択肢が正しくない理由は以下の通りです。
SFTPサーバーの設定は管理が複雑であり、必要な認証単位の追加や削除を行うことに多くのオーバーヘッドが発生します。
これに対し、Cloud StorageバケットはIAMによりアクセス制御が可能で、より直接的で簡単な方法で第三者に安全なアップロードを可能にします。
また、コスト面でもCloud Storageの方が低コストで効率的です。
選択肢：サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。標準的なGoogle Kubernetes Engine（GKE）クラスターを使用し、2つのサービスを維持します。1つはデータのバッチを処理するサービス、もう1つは新しいデータのバッチがないかCloud Storageを監視するサービスです。処理するデータのバッチがないときは、処理サービスを停止します
この選択肢が正しくない理由は以下の通りです。
サービスを常に維持するための管理コストと、新たなバッチデータをチェックするために別のサービスを維持する手間が発生します。
また、処理サービスが停止している間もGKEクラスター自体は稼働し続けるためコスト効率が悪いです。正解の選択肢ではCloud Functionsがデータ処理のトリガーとして稼働し、必要に応じてインスタンスを起動・終了するため、コスト効率的です。
選択肢：サードパーティがデータのバッチをアップロードできるようにCloud Storageバケットを提供し、バケットへの適切なIAM（Identity and Access Management）アクセスを提供します。Cloud Monitoringを使用して、バケット内の新しいデータバッチを検出し、データを処理するCloud Functionsをトリガーします。処理の実行時間を最小限に抑えるために、可能な限り最大のCPUを使用するようにCloud Functionsを設定します
この選択肢が正しくない理由は以下の通りです。
まず、Cloud Monitoringはデータバッチの到着を直接検出するためのツールではありません。正解の選択肢では、google.storage.object.finalizeイベントをトリガーとして用いるCloud Functionが適切に使用されています。
また、Cloud FunctionsはCPUの選択肢に制限があるため、高度なCPU設定を求められる処理には不向きです。
参考リンク：
https://cloud.google.com/storage/docs/access-control/iam
https://cloud.google.com/functions/docs/calling/storage
https://cloud.google.com/compute/docs/autoscaler
</div></details>

### Q. 問題45: 未回答
あなたの組織は、Google CloudプロジェクトのCloud Operationsでダッシュボードを生成するために使用されるシステムログを収集したいと考えています。システムログを収集するために、現在および将来のすべてのCompute Engineインスタンスを設定する必要があります。
この要件を満たすために、どうすればよいですか？

1. スタートアップスクリプトを使用して、Compute EngineイメージにOps Agentをインストールします
2. gcloud CLIを使用してエージェントポリシーを作成します
3. gcloud CLIを使用して、Cloud Asset Inventoryにリストされている各VMにOps Agentをインストールします
4. Cloud Operations VMsダッシュボードのAgent StatusがNot detectedのVMをすべて選択します。次に、Install agentsを選択します
<details><div>
    答え：2
説明
この問題では、Google CloudプロジェクトのCloud Operationsでログを収集するための設定について問われています。特に現在および将来のすべてのCompute Engineインスタンスのシステムログを収集する方法について考える必要があります。選択肢を見る際には、現在だけでなく将来のインスタンスもカバーできる、効率的な自動化の方法を探し、その上でCloud Operationsのログ収集に適した策を選ぶべきです。この問題は、Google Cloudのログ管理に関する理解と、継続的かつ自動化されたログ収集の設定方法への理解を試すものとなります。
基本的な概念や原則：
gcloud CLI：Google Cloudコマンドラインインターフェースで、Google Cloudサービスを操作するためのツールです。各種設定やリソース管理などがコマンドラインから行えます。
エージェントポリシー：特定の操作を実行するためにシステムに導入されるソフトウェアルールのセットです。このポリシーを通じてログ収集などの行動を制御します。
Ops Agent：Google Cloudのオペレーションスイートのためのエージェントです。メトリクスの収集とログの送信を行います。
Compute Engineインスタンス：Google Cloud上で仮想マシンを実行するためのインスタンスです。特定の作業のために設定やリソースを割り当てることができます。
Cloud Operations：Google Cloudの監視、トラブルシューティング、および診断に役立つツールセットです。これにより、プロジェクトのパフォーマンスを評価し、障害の原因を特定できます。
正解についての説明：
（選択肢）
・gcloud CLIを使用してエージェントポリシーを作成します
この選択肢が正解の理由は以下の通りです。
まず、gcloud CLIを使ってエージェントポリシーを作成することは、システムログを収集するための最適な手段です。これは、Ops AgentやLogging AgentのようなエージェントはCompute Engineインスタンスでシステムメトリックやログを収集するためのツールだからです。gcloud CLIを使ってエージェントポリシーを作成することで、エージェントが必要とされるすべての現在または将来のインスタンスに自動的にインストールされます。
さらに、エージェントは収集した情報をCloud Operationsに送信し、ここで情報が統合されて分析・閲覧できます。
そして、これらの情報を基にダッシュボードを生成することが可能となります。
したがって、特定の要件を満たすためには、gcloud CLIを使用してエージェントポリシーを作成することが適切な選択肢となります。
不正解についての説明：
選択肢：gcloud CLIを使用して、Cloud Asset Inventoryにリストされている各VMにOps Agentをインストールします
この選択肢が正しくない理由は以下の通りです。
Ops AgentをCloud Asset Inventoryにリストされている各VMに個別にインストールする方法は、将来に作成されるVMに対してログ収集の設定が適用されないため、今後の全インスタンスに対応するという要件に適合しません。
代わりに、エージェントポリシーを作成することで現在及び将来作成される全VMに対する一元的なシステムログ収集を設定することができます。
選択肢：Cloud Operations VMsダッシュボードのAgent StatusがNot detectedのVMをすべて選択します。次に、Install agentsを選択します
この選択肢が正しくない理由は以下の通りです。
Cloud Operations VMsダッシュボードのAgent StatusがNot detectedのVMを選択し、Install agentsを選択する方法は、現在のCompute Engineインスタンスに対してのみエージェントをインストールします。しかし、要件は現在だけでなく将来のすべてのCompute Engineインスタンスにも適用することを求めています。
それに対して、gcloud CLIを使用してエージェントポリシーを作成すると、新たに生成されるCompute Engineインスタンスにも自動的に適用されます。
選択肢：スタートアップスクリプトを使用して、Compute EngineイメージにOps Agentをインストールします
この選択肢が正しくない理由は以下の通りです。
スタートアップスクリプトを用いてOps Agentをインストールする方法は、手動でVMを生成する度にスクリプトを実行する必要があり、将来的に追加されるすべてのCompute Engineインスタンスに対応しきれません。
一方、gcloud CLIを用いてエージェントポリシーを作成すれば、新規に作られるCompute Engineインスタンスにも自動的に適用されます。
参考リンク：
https://cloud.google.com/logging/docs/agent/ops-agent
https://cloud.google.com/compute/docs/instances/create-start-instance
https://cloud.google.com/sdk/gcloud/reference/compute/instances/add-metadata
</div></details>

### Q. 問題46: 未回答
Google Kubernetes Engine（GKE）にアプリケーションをビルドしてデプロイするために、複数ステップのCloud Buildパイプラインを使用します。ビルド情報をWebhookにHTTP POSTすることで、サードパーティの監視プラットフォームと統合したいと考えています。また、開発工数を最小限に抑えたいと考えています。
この要件を満たすために、どうすればよいですか？

1. Cloud Loggingを使用して、Cloud Buildログからログベースのメトリックを作成します。Webhook通知タイプでアラートを作成します
2. Cloud Buildのパイプラインの最後に、ビルド情報をWebhookにHTTP POSTする新しいステップを追加します
3. 各Cloud Buildステップに、ビルド情報をWebhookにHTTP POSTするロジックを追加します
4. Cloud Build cloud-builds PubSubトピックにCloud Pub/Subプッシュサブスクリプションを作成し、ビルド情報をWebhookにHTTP POSTします
<details><div>
    答え：4
説明
この問題では、Cloud Buildパイプラインを使用してアプリケーションを作成しデプロイするシナリオが提示されており、ビルド情報をサードパーティの監視プラットフォームに送信する必要があります。また、開発工数を最小限に抑えなければなりません。これは自動化と効率性が重要な要素であり、手動でのステップ追加や独自のロジック作成を避けることを示唆しています。解答選択肢を選ぶ際には、Google Cloudの既存サービスを活用し、よりシンプルで効率的な実装を重視することが求められます。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：Google Cloudで提供されている、Kubernetesをマネージド形式で使うことができるサービスです。Kubernetesは、コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を行うためのオープンソースのプラットフォームです。
Cloud Build：Google Cloudの継続的インテグレーションとデリバリーサービスで、ソースコードをビルド、テスト、デプロイします。
Webhook：HTTP POSTコールバックで、あるアクションが起きたときに通知を受ける方法です。
Cloud Pub/Sub：Google Cloudのリアルタイムメッセージングサービスで、独立したアプリケーション間でメッセージを送受信できます。
Cloud Logging：Google Cloudのログ管理サービスで、Google Cloudのリソースからのログを収集、分析、保存、エクスポートします。
パイプライン：連続するプロセスの一連のステップを指し、ここではソースコードのビルドからデプロイまでの一連の作業を指します。パイプラインにより、一貫性と効率性が確保されます。
正解についての説明：
（選択肢）
・Cloud Build cloud-builds PubSubトピックにCloud Pub/Subプッシュサブスクリプションを作成し、ビルド情報をWebhookにHTTP POSTします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Pub/SubはメッセージングとイベントドリブンシステムのためのGoogle Cloudのスケーラブルなサービスで、異なるサーバーアプリケーション間でメッセージを送受信します。Cloud Buildのビルド情報はcloud-buildsというPub/Subトピックに自動的に送信されます。そのため、このトピックにプッシュサブスクリプションを作成することで、ビルドが終了するたびに自動的に情報を取得できます。
次に、Pub/Subのプッシュサブスクリプションは、新しいメッセージがトピックに追加されるたびに、登録したエンドポイント（この場合Webhook）にHTTP POSTリクエストを送信します。これにより、手間をかけずにビルド情報をサードパーティの監視プラットフォームと統合できます。
したがって、Cloud Build cloud-builds PubSubトピックにPub/Subプッシュサブスクリプションを作成することで、開発工数を最小限に抑えつつ、問題の要件を満たすことができます。
不正解についての説明：
選択肢：各Cloud Buildステップに、ビルド情報をWebhookにHTTP POSTするロジックを追加します
この選択肢が正しくない理由は以下の通りです。
各Cloud Buildステップにロジックを追加すると、開発工数が増えてしまいます。
一方、Cloud Build cloud-builds PubSubトピックにCloud Pub/Subプッシュサブスクリプションを作成する方が、開発工数を最小限に抑えることが可能です。
また、これによりビルド情報をWebhookに一元的にHTTP POSTすることが可能となります。
選択肢：Cloud Buildのパイプラインの最後に、ビルド情報をWebhookにHTTP POSTする新しいステップを追加します
この選択肢が正しくない理由は以下の通りです。
新たにビルド情報をWebhookにHTTP POSTするステップを追加すると、開発工数が増加します。これは、工数を最小限に抑えるという要求に反しています。
一方で、Pub/Subサブスクリプションを作成すれば、独自のステップを追加せずにビルド情報をWebhookにPOSTすることが可能です。
選択肢：Cloud Loggingを使用して、Cloud Buildログからログベースのメトリックを作成します。Webhook通知タイプでアラートを作成します
この選択肢が正しくない理由は以下の通りです。
Cloud Loggingでログベースのメトリクスを作成し、Webhook通知タイプでアラートを作成すると、必要な開発工数が増えます。正解の選択肢であるCloud Pub/Subプッシュサブスクリプションを使用する方が直接的な統合が可能で、開発工数を最小限に抑えることができます。
参考リンク：
https://cloud.google.com/build/docs/configuring-builds/subscribe-build-notifications
https://cloud.google.com/pubsub/docs/overview
https://cloud.google.com/monitoring/support/notification-options#webhooks
</div></details>

### Q. 問題47: 未回答
あなたはPythonで書かれ、App Engineフレキシブル環境でホストされているトレーディングアプリケーションをサポートしています。Google Cloud Operation Suite Error Reportingに送信されるエラー情報をカスタマイズしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、App Engineフレキシブル環境でコードを実行します
2. Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、Google Kubernetes Engine上でコードを実行します
3. Google Cloud Operation Suite Error Reporting APIを使用して、アプリケーションからReportedErrorEventにエラーを書き込み、Cloud Loggingに適切な書式のエラーメッセージを含むログエントリを生成します
4. Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、Compute Engine VM上でコードを実行します
<details><div>
    答え：3
説明
この問題では、Pythonで作成されたトレーディングアプリケーションがApp Engineフレキシブル環境でホストされ、そのエラー情報のカスタマイズ方法が求められています。Google Cloud Operation Suite Error Reportingに関連するAPIやライブラリ、またその属する環境（Compute Engine VMやGoogle Kubernetes Engine等）について理解している必要があります。また、エラー情報のカスタマイズとはどういう動作を指すのか、Cloud Loggingにおけるログエントリとは何かといった要素への理解も必要です。これらを踏まえた上で、問題の正解選択肢を読み解くべきです。
基本的な概念や原則：
App Engineフレキシブル環境：App Engineの一部で、コンテナベースのランタイムを使用してアプリケーションを実行します。Pythonなど様々な言語がサポートされており、自由なカスタマイズが可能です。
Google Cloud Operation Suite Error Reporting：Google Cloudのサービスで、アプリケーションが発生するエラーを自動的に検出、分析、通知してくれます。
ReportedErrorEvent：Cloud Operation Suite Error Reporting APIで使用するエンティティでエラー情報を表現します。
Cloud Logging：Google Cloudのサービスで、アプリケーションやGoogle Cloudのサービスからのログを一元管理できます。ログのエクスポートやリアルタイム分析も可能です。
Google Cloud Operation Suite Error Reportingライブラリ：Google Cloudが提供するライブラリで、Pythonなどの言語でCloud Operation Suite Error Reportingの機能を利用するために使用します。
Compute Engine：Google Cloud Serviceの一つで、仮想マシンを提供します。比較的自由度が高いサービスですが、全ての環境設定をユーザーが行わなければならない場合があります。
Google Kubernetes Engine：Google Cloud Serviceの一つで、Kubernetesの管理環境を提供します。Dockerコンテナを管理するためのプラットフォームであり、アプリケーションをデプロイ、保守、スケーリングするために使用します。
正解についての説明：
（選択肢）
・Google Cloud Operation Suite Error Reporting APIを使用して、アプリケーションからReportedErrorEventにエラーを書き込み、Cloud Loggingに適切な書式のエラーメッセージを含むログエントリを生成します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Operation Suite Error Reporting APIを使用することで、エラー情報のカスタマイズが可能になります。これにより、エラー情報を手動で操作し、アプリケーション固有のエラー内容を追加したり、エラーメッセージのフォーマットを変更したりすることができます。
そして、ReportedErrorEventはAPIが提供するデータ構造で、エラー情報をGoogle Cloud Operation Suite Error Reportingに送信するために使用します。
そして、Cloud Loggingに生成されるログエントリは、Google Cloud Operation Suite Error Reporting APIを使用して送信されたエラー情報を格納します。よって、この選択肢はApp Engineフレキシブル環境でホストされるPythonアプリケーションからのエラー情報のカスタマイズと送信を実現します。
不正解についての説明：
選択肢：Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、Compute Engine VM上でコードを実行します
この選択肢が正しくない理由は以下の通りです。
要件はApp Engineフレキシブル環境でもエラー情報をカスタマイズしたいとする一方で、不正解の選択肢はCompute Engine VM上でエラーライブラリを実行するという点で乖離しています。これにより、必要でないリソースを使用し、期待されている結果が得られなかったという問題が発生する可能性があります。
選択肢：Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、Google Kubernetes Engine上でコードを実行します
この選択肢が正しくない理由は以下の通りです。
要件はApp Engineフレキシブル環境でのエラー情報のカスタマイズであり、Google Kubernetes Engine上での実行は関係していません。
また、ライブラリをインストールしてもカスタマイズは可能ではなく、APIを通じてエラーメッセージを生成・送信することが必要です。
選択肢：Python用のGoogle Cloud Operation Suite Error Reportingライブラリをインストールし、App Engineフレキシブル環境でコードを実行します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite Error Reportingライブラリをインストールするだけでは、エラー情報のカスタマイズは実現できません。エラーメッセージの内容を制御するために、APIを用いてReportedErrorEventにエラーを書き込む必要があります。
参考リンク：
https://cloud.google.com/error-reporting/docs
https://cloud.google.com/error-reporting/docs/formatting-error-messages
https://cloud.google.com/logging/docs/
</div></details>

### Q. 問題48: 未回答
あなたのチームは、Google Kubernetes Engine（GKE）にデプロイするための新しいアプリケーションを設計しています。様々なアプリケーションレベルのメトリクスを一元的に収集・集約するために、モニタリングをセットアップする必要があります。あなたは、モニタリングのセットアップに必要な作業量を最小限に抑えながら、Google Cloudのサービスを使用したいと考えています。
この要件を満たすために、どうすればよいですか？

1. Cloud Pub/Subクライアントライブラリをインストールし、アプリケーションからさまざまなメトリクスをさまざまなトピックにプッシュし、Google Cloud Operation Suiteで集約されたメトリクスをチェックします
2. アプリケーションから様々なメトリクスをGoogle Cloud Operation Suite Monitoring APIに直接パブリッシュし、Google Cloud Operation Suiteでこれらのカスタムメトリクスをチェックします
3. アプリケーションにOpenTelemetryクライアントライブラリをインストールし、Google Cloud Operation Suiteをメトリクスのエクスポート先として設定し、Google Cloud Operation Suiteでアプリケーションのメトリクスをチェックします
4. すべてのメトリクスをアプリケーション固有のログメッセージの形式で出力し、これらのメッセージをコンテナからGoogle Cloud Operation Suiteロギングコレクターに渡し、Google Cloud Operation Suiteでメトリクスをチェックします
<details><div>
    答え：3
説明
この問題では、Google Kubernetes Engine（GKE）にデプロイするための新しいアプリケーションのメトリクスを収集、集約するための最適なモニタリング方法を選定することが求められています。問題文からは、作業量を最小限に抑えつつ、Google Cloudのサービスを使用したいという要件が明らかにされています。メトリクスの収集と集約のための最適な方法とGoogle Cloudの適切なサービスを選び、それらを組み合わせることが重要です。OpenTelemetry、Google Cloud Operation Suite、Cloud Pub/Sub、その他のロギング手段など選択肢が出てくるので、これらの特性を理解して適切に選定することが求められます。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：コンテナ化されたアプリケーションのデプロイと管理を行うためのGoogle Cloudのフルマネージドサービスです。Kubernetes環境の設定やスケーリングなどを自動化します。
OpenTelemetry：分散トレーシングとメトリクスの収集を一元管理するためのオープンソースのフレームワークです。アプリケーションのパフォーマンス監視（APM）に使用されます。
Google Cloud Operation Suite：Google Cloudのモニタリング、ロギング、トレーシング、エラーレポートといったオペレーションのための統合ツールスイートです。
Google Cloud Operation Suite Monitoring API：Google Cloud Monitoringの機能をプログラムから制御するためのAPIです。メトリックの収集やダッシュボードの作成などが行えます。
Cloud Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。大量のデータを高速で処理し、アプリケーションの間でデータを配信します。
Google Cloud Operation Suiteロギングコレクター：Google Cloud Operation Suiteが提供する、ログデータの収集・処理・分析を行うためのエージェントです。
正解についての説明：
（選択肢）
・アプリケーションにOpenTelemetryクライアントライブラリをインストールし、Google Cloud Operation Suiteをメトリクスのエクスポート先として設定し、Google Cloud Operation Suiteでアプリケーションのメトリクスをチェックします
この選択肢が正解の理由は以下の通りです。
まず、OpenTelemetryはオープンソースの分散トレーシングおよびメトリクス収集フレームワークであり、様々なアプリケーションレベルのメトリクスを容易に収集することができます。アプリケーションにクライアントライブラリをインストールすることで、ミドルウェア、フレームワーク、言語ランタイムといった様々な部分からのデータを一元的に収集することが可能となります。
次に、Google Cloud Operation SuiteはGoogle Cloudの監視、トラブルシューティング、アプリケーションのパフォーマンス管理を行うための統合サービスです。OpenTelemetryから収集されたメトリクスをGoogle Cloud Operation Suiteにエクスポートすることで、アプリケーションのメトリクスを一元的に閲覧し、分析することができます。これにより、モニタリングのセットアップに必要な作業量を最小限に抑えつつ、効率的にアプリケーションのパフォーマンスを監視することが可能となります。
不正解についての説明：
選択肢：アプリケーションから様々なメトリクスをGoogle Cloud Operation Suite Monitoring APIに直接パブリッシュし、Google Cloud Operation Suiteでこれらのカスタムメトリクスをチェックします
この選択肢が正しくない理由は以下の通りです。
メトリクスを直接Google Cloud Operation Suite Monitoring APIにパブリッシュすると、セットアップに必要な作業量が増えます。これは、アプリケーションに直接APIを組み込む開発コストが必要になるからです。
一方、OpenTelemetryを使用すると、一般的なメトリクスが自動的に収集され、作業量を最小限に抑えられます。
選択肢：Cloud Pub/Subクライアントライブラリをインストールし、アプリケーションからさまざまなメトリクスをさまざまなトピックにプッシュし、Google Cloud Operation Suiteで集約されたメトリクスをチェックします
この選択肢が正しくない理由は以下の通りです。
Cloud Pub/Subクライアントライブラリを使うとメトリクスのプッシュに手間がかかります。
一方、OpenTelemetryクライアントライブラリを使えば、アプリケーションレベルのメトリクスを自動的にGoogle Cloud Operation Suiteへエクスポートでき、作業量が最小限に抑えられます。
選択肢：すべてのメトリクスをアプリケーション固有のログメッセージの形式で出力し、これらのメッセージをコンテナからGoogle Cloud Operation Suiteロギングコレクターに渡し、Google Cloud Operation Suiteでメトリクスをチェックします
この選択肢が正しくない理由は以下の通りです。
不正解な選択肢は、アプリケーション固有のログメッセージ形式で出力し、Cloud Loggingを使ってメトリクスを収集しようとしています。しかしメトリクス収集のためにログメッセージをパースする作業は効率的ではなく、手間がかかるため作業量を最小限にするという要件に反します。
一方、正解選択肢はOpenTelemetryクライアントライブラリを利用し、Cloud Monitoringに直接メトリクスを送ることで一元的な収集・集約が可能になります。
参考リンク：
https://cloud.google.com/stackdriver/docs/solutions/gke
https://cloud.google.com/monitoring/docs
https://opentelemetry.io/docs/collector/getting-started/
</div></details>

### Q. 問題49: 未回答
Google Cloudでのアプリケーションのパフォーマンスが、前回のリリース以降低下しています。下流の依存関係が、リクエストの完了に時間がかかる原因になっている可能性があります。原因を特定するために、アプリケーションで問題を調査する必要があります。
この要件を満たすために、どうすればよいですか？

1. アプリケーションでCloud Profilerを設定します
2. アプリケーションでGoogle Cloud Managed Service for Prometheusを設定します
3. アプリケーションでCloud Traceを設定します
4. アプリケーションでエラーレポートを設定します
<details><div>
    答え：3
説明
この問題では、Google Cloud上でパフォーマンス低下が発生しているアプリケーションのトラブルシューティングに適したツールを選ぶことが求められています。特に、"下流の依存関係がリクエストの完了に時間がかかる原因になっている可能性がある"という情報を重視し、それに対応可能なツールを選ぶことが鍵となります。各選択肢が提供する機能とその問題に対する適用度を熟知していることが必要です。
基本的な概念や原則：
Cloud Trace：Google Cloudの分散トレーシングシステムです。アプリケーションがリクエストを処理する時間を詳細に追跡し、表示することができます。これによりパフォーマンスのボトルネックや遅延の原因を特定することができます。
エラーレポート：Google Cloudのエラーレポートツールです。アプリケーションで発生したエラーを追跡し、バグの特定や修正を支援します。しかし、パフォーマンスの問題や遅延の原因を追跡するためのツールではありません。
Google Cloud Managed Service for Prometheus：Google Cloudで提供されているオープンソースの監視と警告ツールのマネージドサービスです。システムやアプリケーションのメトリックスを収集し、分析しますが、パフォーマンスの問題や遅延の原因を追跡するためのツールではありません。
Cloud Profiler：Google Cloudのパフォーマンスプロファイル生成ツールです。CPU使用率やメモリ使用率など、アプリケーションの実行時のパフォーマンスメトリクスを収集します。パフォーマンス改善のための情報を提供しますが、特定のリクエストのパフォーマンス問題の追跡には使用できません。
正解についての説明：
（選択肢）
・アプリケーションでCloud Traceを設定します
この選択肢が正解の理由は以下の通りです。
Cloud TraceはGoogle Cloudのサービスで、アプリケーションのパフォーマンスを調査し解析するためのツールです。アプリケーションが低下し、その原因を特定する必要がある場合、Cloud Traceを使用すると、アプリケーションの実行に関する詳細な情報を取得できます。特に、アプリケーションのリクエストのレイテンシの観点からパフォーマンスを分析できます。また下流の依存関係が問題になっている可能性があるという状況では、Cloud Traceのトレースデータを利用することで、依存関係のあるサービス間での時間の遅延を特定するのに役立ちます。
したがって、この情報を元に問題の解決やパフォーマンスの最適化を図ることが可能になります。
不正解についての説明：
選択肢：アプリケーションでエラーレポートを設定します
この選択肢が正しくない理由は以下の通りです。
エラーレポートはアプリケーションがエラーを投げた際にその情報を追跡・分析するためのツールであり、パフォーマンス低下の原因を追跡するのには適していません。
一方、Cloud Traceはリクエストがシステムを通過する際の遅延を視覚化し、パフォーマンスの問題の原因を特定します。
選択肢：アプリケーションでGoogle Cloud Managed Service for Prometheusを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Managed Service for Prometheusは、時系列データの監視とアラートを行うサービスであり、リクエストの遅延原因具体的に特定するのではなく、システムパフォーマンス全般を監視します。
それに対して、Cloud Traceはアプリケーションのリクエストを分析し、それぞれのリクエストがどこで遅延しているかを特定することが可能です。
選択肢：アプリケーションでCloud Profilerを設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Profilerはアプリケーションのパフォーマンスボトルネックを特定するためのサービスですが、それはコードレベルでの問題を追跡するのに使われます。しかし、今回のケースでは下流の依存関係が問題であるため、リクエストとレスポンスを追跡し調査するCloud Traceが適切です。
参考リンク：
https://cloud.google.com/trace/docs
https://cloud.google.com/error-reporting/docs
https://cloud.google.com/profiler/docs
</div></details>

### Q. 問題50: 未回答
ワークスペースプロジェクト内のダッシュボードで、CPU使用率のGoogle Cloud Operation Suiteチャートを作成しました。このチャートは、サイト信頼性エンジニアリング（SRE）チームでのみ共有します。あなたは、最小権限の原則に確実に従いたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？

1. ワークスペースのプロジェクトIDをSREチームと共有します。SREチームにワークスペースプロジェクトのダッシュボードビューアーIAMロールを割り当てます
2. ワークスペースのプロジェクトIDをSREチームと共有します。SREチームに、ワークスペースプロジェクトの監視ビューアIAMロールを割り当てます
3. "URLによるチャートの共有"をクリックし、SREチームにURLを提供します。ワークスペースプロジェクトのダッシュボードビューアーIAMロールをSREチームに割り当てます
4. "URLによるチャートの共有"をクリックし、SREチームにURLを提供します。ワークスペースプロジェクトで、SREチームにMonitoring Viewer IAMロールを割り当てます
<details><div>
    答え：
説明
この問題では、Google CloudのIAMの権限管理と最小権限の原則に関する理解が必要です。特定のユーザー（この場合はSREチーム）に対し、特定のリソース（この場合はワークスペース内のCPU使用率チャート）に対する最小限の権限を付与する方法を問いています。ここでは、ユーザーが受け取るべき具体的な権限、その権限がどのリソースに対して効果を発揮するのか、そしてその権限が付与される方法を、適切に理解して選択する必要があります。具体的な権限やその付与方法について正確に理解していることが求められる問題です。
基本的な概念や原則：
Google Cloud Operation Suite：Google Cloudの監視、トラブルシューティング、および診断のためのツールスイートです。これには、Logging, Monitoring, Trace, Profiler, Debuggなどの機能が含まれています。
CPU使用率：コンピュータのCPUがどれだけ利用されているかを示す指標です。ワークロードが高い場合や、ボトルネックが発生している場合などに使用します。
ダッシュボード：ユーザーが重要な情報を一目で確認できるように設計されたユーザーインターフェースです。Google Cloudでは、ユーザーが自分のプロジェクトやリソースの状態を監視するためにダッシュボードを作成することができます。
URLを共有します：特定の情報を共有する一般的な方法です。共有したいページのURLを他のユーザーと共有することで、そのユーザーも同じページを開くことができます。
サイト信頼性エンジニアリング（SRE）：システムやサービスの信頼性を維持しつつ、新しいリリースをスムーズに展開する方法論です。
最小権限の原則：セキュリティのベストプラクティスの1つで、各ユーザーまたはプログラムがそのタスクを達成するのに必要な最小限のアクセス権限のみを持つべきであると言うものです。
Monitoring Viewer IAMロール：Google CloudのIAMロールの一つで、リソースのモニタリングデータに対する読み取りアクセス権限を提供します。ダッシュボードを共有する際には、このロールが必要な場合があります。
正解についての説明：
（選択肢）
・"URLによるチャートの共有"をクリックし、SREチームにURLを提供します。ワークスペースプロジェクトで、SREチームにMonitoring Viewer IAMロールを割り当てます
この選択肢が正解の理由は以下の通りです。
まず、ワークスペースプロジェクト内のGoogle Cloud Operation Suiteダッシュボードのチャートを共有する方法にはいくつかありますが、最小権限の原則に基づくと、不要な権限を付与せずに必要な情報だけを共有できる"URLによるチャートの共有"が適しています。この方法であれば、SREチームはURLを通じてダッシュボードを参照できますが、他のプロジェクト情報にはアクセスできません。
しかし、URLによる共有だけでは、URLを取得したSREチームがダッシュボードを閲覧できません。そのため、SREチームに対してワークスペースプロジェクトでMonitoring Viewer IAMロールを割り当てます。これにより、SREチームはダッシュボードを閲覧する権限を得ますが、それ以上の権限（例えば編集権）は付与されないため、最小権限の原則に沿っています。
このような理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：ワークスペースのプロジェクトIDをSREチームと共有します。SREチームに、ワークスペースプロジェクトの監視ビューアIAMロールを割り当てます
この選択肢が正しくない理由は以下の通りです。
ワークスペースのプロジェクトIDを共有しても、それだけではSREチームはダッシュボードのチャートを参照できません。特定のダッシュボードチャートにアクセスさせるには、"URLによるチャートの共有"を選択し、具体的なURLを提供する必要があります。
選択肢：ワークスペースのプロジェクトIDをSREチームと共有します。SREチームにワークスペースプロジェクトのダッシュボードビューアーIAMロールを割り当てます
この選択肢が正しくない理由は以下の通りです。
まず、ワークスペースプロジェクトのダッシュボードビューアIAMロールは実在しません。正しいロールは、Monitoring Viewer IAMです。これによりSREチームは、必要な権限のみが割り当てられ、最小権限の原則が維持されます。
選択肢："URLによるチャートの共有"をクリックし、SREチームにURLを提供します。ワークスペースプロジェクトのダッシュボードビューアーIAMロールをSREチームに割り当てます
この選択肢が正しくない理由は以下の通りです。
ワークスペースプロジェクトのダッシュボードビューアーIAMロールというロールは存在しません。ゆえに該当のロールをSREチームに割り当てることは不可能です。対して正解の選択肢のMonitoring Viewer IAMロールは存在しており、彼らにCPU使用率のチャートを表示するための必要十分な権限を付与します。
参考リンク：
https://cloud.google.com/monitoring/charts/dashboards-sharing
https://cloud.google.com/monitoring/access-control
https://cloud.google.com/iam/docs/understanding-roles#monitoring-roles
</div></details>

## 2

## 3
## 4