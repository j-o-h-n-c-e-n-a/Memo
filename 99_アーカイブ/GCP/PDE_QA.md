## 1
### Q. 1
あなたは世界的な海運会社の一員です。あなたの目的は、40TBのデータを使用して予測モデルを構築し、様々な地域内の船舶による配送遅延の可能性を毎日予測することです。このモデルは、様々な情報源から収集された数多くの属性に依存しています。各船舶からの GeoJSON 位置情報を含むテレメトリーデータが 1 時間ごとに収集されます。あなたは、予測および地理空間処理のための組み込み機能を提供するストレージソリューションを求めています。 この目的のために、どのようなストレージ・ソリューションを選択すべきでしょうか？
1. BigQuery
2. Cloud Bigtable
3. クラウドデータストア
4. PostgreSQL向けクラウドSQL
<details><div>
    答え：1
説明
BigQueryはアナリティクスに最適化されたクラウドベースのストレージソリューションで、予測や地理空間処理のためのネイティブ機能を備えています。モデルのトレーニングに使用したい40TBのデータのような大規模なデータセットに適しています。また、ダッシュボード機能もあり、地域内で遅延が発生しそうな船舶の数や船舶を表示することができる。
不正確なオプション
Cloud Bigtableは、低レイテンシのルックアップに最適化され、大量のデータを格納できるNoSQLデータベースソリューションです。予測や地理空間処理のためのネイティブ機能がないため、このユースケースには最適ではない。
Cloud Datastoreは、スケーラビリティに最適化され、大量のデータを保存できるNoSQLデータベースソリューションです。予測や地理空間処理のためのネイティブ機能を備えていないため、このユースケースには最適な選択肢ではありません。
Cloud SQL for PostgreSQLは、トランザクションに最適化され、大量のデータを保存できるリレーショナルデータベースソリューションです。予測や地理空間処理のためのネイティブ機能を備えていないため、このユースケースには最適ではない。
参考リンク
Google BigQuery: https://cloud.google.com/bigquery
</div></details>

### Q. 2
あなたはApache Kafkaを利用したIoTパイプラインを管理しており、通常毎秒約5000メッセージを受信しています。あなたの目標は、Google Cloud Platformを採用して、1時間移動平均が毎秒4000メッセージを下回ったときにアラートを生成することです。
どのような手順を踏むべきですか？
1. Kafka IOを使用してDataflowでデータのストリームを消費する。5分ごとに1時間のスライディング・タイム・ウィンドウを設定する。ウィンドウが閉じたら平均を計算し、平均が4000メッセージ未満ならアラートを送信する。
2. 
3. 
4. 
<details><div>
    答え：1
説明
IoTパイプラインの1時間の移動平均が毎秒4000メッセージを下回るとすぐにアラートを作成するには、以下の方法を取る必要があります：
このアプローチが適している理由は以下の通り：
Kafka IOを使ったデータフローでは、入力されるデータのストリームを効率的に処理できます。
5分ごとに1時間のスライディングタイムウィンドウを使用することで、移動平均を継続的に計算することができます。
ウィンドウが閉じたときに平均を計算することで、移動平均をチェックする間隔が一定になります。
計算された平均が4000メッセージを下回ると簡単にアラートを送ることができ、リアルタイムのアラート・メカニズムになります。
誤ったオプション
オプションB、C、およびDは、1時間にわたって移動平均を計算し、それが特定のしきい値を下回ったときにアラートを生成するという要件に直接対応していません：
B. 1時間の固定時間ウィンドウを使用すると、移動平均は得られず、むしろ1時間の静的平均が得られる。
C. このアプローチは、BigtableとCloud Schedulerを使用しますが、移動平均を直接計算しません。
D. このアプローチもBigQueryとCloud Schedulerを使用しますが、移動平均の計算がありません。
</div></details>

### Q. 3
MySQLベースのクラウドSQLの実装を準備しており、ゾーン障害時に高可用性を維持するための対策が必要です。
そのためにはどのような手順を踏むべきでしょうか？
1. あるゾーンにCloud SQLインスタンスを作成し、同じリージョン内の別のゾーンにフェイルオーバー・レプリカを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
これは、ゾーン障害時に高可用性を確保するための最良のオプションです。フェイルオーバー・レプリカは、プライマリ・インスタンスに障害が発生した場合に引き継ぐことができるセカンダリ・インスタンスであり、プライマリ・インスタンスと同じリージョンになければなりません。
誤ったオプション
リードレプリカはスケーリングに使用されるセカンダリインスタンスであり、高可用性に使用されるものではないため、オプションBは正しくありません。
リードレプリカはプライマリインスタンスと同じリージョンになければならないので、オプションCは不正解です。
クラウドストレージのバケットにバックアップしても、ゾーン障害時の高可用性には役立たないので、オプションDは不正解です。
参考リンク
https://cloud.google.com/sql/docs/mysql/high-availability。
</div></details>

### Q. 4
データの取り込みと配信を一元化するために、貴社はどのシステムを選ぶべきか。
- トピック内の特定のオフセットへのシーク機能
-多数のトピックにおけるパブリッシュ/サブスクライブ・セマンティクスのサポート
- キーごとの順序付けを維持するか？
1. Apache Kafka
2. Cloud Storage
3. Dataflow
4. Firebase Cloud Messaging
<details><div>
    答え：1
説明
正しい選択肢は A. Apache Kafka です。
Apache Kafkaは、データ統合のための機能を備えたメッセージングシステムを提供する分散ストリーミングプラットフォームであり、トピック内の特定のオフセットにシークする機能、数百ものトピック上でパブリッシュ／サブスクライブセマンティクスをサポートする機能、キーごとの順序付けを保持する機能などを備えています。
不正解の選択肢
オプションB. Cloud Storageは、Apache Kafkaのようなデータ統合の機能を提供していないため、不正解です。
オプションC. Dataflowは、トピック内の特定のオフセットにシークする機能、数百のトピックでのパブリッシュ/サブスクライブ・セマンティクスのサポート、およびキーごとの順序付けを保持する機能を提供しないため、不正解です。
オプション D. Firebase Cloud Messaging は、トピック内の特定のオフセットへのシーク機能、何百ものトピックでの発行/購読セマンティクスのサポート、およびキーごとの順序付けの保持を提供していないため、不正解です。
</div></details>

### Q. 5
既存のオンプレミスのApache Hadoopデプロイメントをマネージドサービスを利用してクラウドに移行する場合、長時間実行するバッチジョブに対して最大限の耐障害性とコスト効率を確保するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：1
説明
選択肢Aが正解です。Dataprocクラスタをデプロイすることが、長時間実行するバッチジョブの耐障害性とコスト効率を確保する最善の方法です。
標準的な永続ディスクと50%のプリエンプティブワーカーを使用することで、コストを低く抑えることができます。データをクラウドストレージに保存し、スクリプト内の参照をhdfs://からgs://に変更することで、データへのアクセスと管理が容易になります。
不正解の選択肢
SSD永続ディスクを使用すると、標準の永続ディスクよりも高価になるため、オプションBは正しくありません。
オプションCは、標準インスタンスで10ノードのCompute Engineインスタンスグループを使用すると、プリエンプティブインスタンスを使用するよりもコストが高くなるため、不正解です。
オプションDは、HDFSにデータを保存するとクラウドストレージに保存するよりも高くつくので、間違っています。
参考リンク
Dataproc データアクセシビリティ:- https://cloud.google.com/dataproc/docs/resources/faq#data_access_availability
</div></details>

### Q. 6
あなたのチームは現在2値分類問題に取り組んでいます．サポートベクターマシン（SVM）分類器をデフォルトのパラメータでトレーニングした後、検証中に0.87の曲線下面積（AUC）スコアを得ました。あなたの目的は、モデルのAUCを向上させることです。
どのようにこの改善を達成できますか？
1. ハイパーパラメータ・チューニングの実行
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解 A. ハイパーパラメータ・チューニングの実行
ハイパーパラメータチューニングの実行は、モデルのAUCを向上させる最良のアプローチです。これは、データへの適合を高め、モデルのパフォーマンスを向上させるために、モデルのパラメータを調整することを含みます。
不正解のオプション
不正解の選択肢 B: ディープニューラルネットワークで分類器をトレーニングしても、デフォルトのパラメータを持つSVM分類器に勝てるとは限りません。データによっては、SVM分類器がニューラルネットワーク分類器を上回る可能性もあります。
不正解選択肢 C: モデルをデプロイして実世界の AUC を測定しても、それが検証の AUC よりも高くなることは保証されません。オーバーフィッティングやその他の要因によって、モデルが実世界でより悪いパフォーマンスを示す可能性があります。
不正解選択肢 D: 予測値をスケーリングしても、モデルの AUC が向上するとは限りません。モデルの性能が、スケーリングなしよりもスケーリングありの方が悪い可能性がある。
参考リンク
https://cloud.google.com/ml-engine/docs/tensorflow/hyperparameter-tuning- 概要
</div></details>

### Q. 7
Cloud Dataprocクラスタノードはリソースを取得するためにインターネットにアクセスしてはならないという会社のセキュリティポリシーに準拠しながら、既存の初期化アクションを使用して起動時にCloud Dataprocクラスタのすべてのノードに追加の依存関係を展開するにはどうすればよいですか？
1. 
2. 
3. すべての依存関係をVPCセキュリティ境界内のクラウドストレージバケットにコピーします。
4. 
<details><div>
    答え：3
説明
Cloud Dataprocノードがインターネットにアクセスすることなく、起動時にCloud Dataprocクラスタの全ノードに追加の依存関係をデプロイするには、この方法に従います：
これが適切な理由です：
VPCセキュリティ境界内のCloud Storageバケットに依存関係を配置することで、セキュリティポリシーを遵守しながらCloud Dataprocクラスタにアクセスできるようになります。
VPC内にCloud Storageバケットを作成し、VPC Service Controlsまたはオンプレミスホスト用のPrivate Google Accessを使用してCloud Dataprocクラスタノードにアクセスすることができます。
クラウド・ストレージ・バケットを初期化アクションやクラスタの起動時に必要なリソースのソースとして指定することができます。
誤ったオプション
オプションAとDは、ノードへの依存関係のデプロイとは直接関係ありません：
A. A. Cloud DataprocマスタにCloud SQL Proxyをデプロイすることは、Cloud SQLアクセスに特有であり、一般的な依存関係のデプロイには関係ありません。
D. サービス・アカウントをネットワーク・ユーザー・ロールに追加することは、ネットワーク権限に関することであり、依存関係のデプロイメントには対応していません。
オプションB、SSHトンネルを使用してCloud Dataprocクラスタにインターネットへのアクセスを与えることは、Cloud Dataprocノードがインターネットアクセスを持ってはならないという要件に違反するので、このシナリオには適していません。
</div></details>

### Q. 8
以下の仕様の新規プロジェクトにどのデータベースを選択しますか？
1. 完全な管理機能。
2. 自動スケーラビリティ。
3. トランザクションの一貫性。
4. 最大6TBまでのスケーラビリティ。
5. SQLクエリーのサポート
このプロジェクトではどのデータベースを選択しますか？
1. Cloud SQL
2. Cloud Bigtable
3. Cloud Spanner
4. Cloud Datastore
<details><div>
    答え：3
説明
C. Cloud Spanner
Cloud Spannerは、Google Cloudが提供する、完全に管理され、グローバルに分散された、一貫性の高いデータベースサービスです。シナリオで説明した要件を満たすように設計されています：
フルマネージド： Cloud Spannerはフルマネージドであり、Google Cloudがインフラ管理、アップデート、バックアップを行うため、アプリケーションに集中することができます。
自動的なスケールアップ：Cloud Spannerは水平方向のスケーラビリティを考慮して設計されています。データとクエリの負荷が増加した場合、アプリケーションのスケーリングニーズに自動的に対応できます。
トランザクションの一貫性： Cloud Spannerは強力なトランザクション一貫性を提供します。つまり、データのACID（原子性、一貫性、分離、耐久性）特性を保証し、信頼性と一貫性のあるトランザクションを必要とするアプリケーションに適しています。
最大6 TBまで拡張可能：Cloud Spannerはより大きなデータセットを扱うことができるため、最大6 TBまで拡張可能です。
SQLでクエリ可能： Cloud SpannerはSQLクエリをサポートしているため、SQLベースのデータベースに慣れている開発者にはなじみやすい。
不適切なオプション
A. Cloud SQL： Cloud SQLはマネージド・リレーショナル・データベース・サービスですが、Cloud Spannerほど簡単には自動スケールしません。また、Cloud Spannerのように分散したグローバルに一貫性のあるデータを扱うようには設計されていない。
B. Cloud Bigtable： Cloud BigtableはNoSQLデータベースで、特に分析や時系列のユースケースで大量のデータを扱うのに優れている。しかし、このシナリオの要件である強力なトランザクション一貫性は提供しない。
D. クラウド・データストア： Cloud Datastore（データストアモードのFirestore）は、拡張可能なNoSQLドキュメントデータベースだが、Cloud Spannerと同レベルのトランザクション一貫性は提供できない。また、一般的にSQLクエリに依存する従来のリレーショナル・データベースとは異なるユースケースで使用される。
参考リンク
Cloud Spanner: https://cloud.google.com/spanner
</div></details>

### Q. 9
あなたは、オンプレミスのデータベースからGoogle Cloud Platform（GCP）へ、業務システムのトランザクションデータを移行する仕事を任されている中堅企業に雇われています。このデータベースには、20テラバイトものデータが含まれています。このような状況を踏まえて、この移行に最も適したデータベースソリューションはどれでしょうか？
1. Cloud SQL
2. Cloud Bigtable
3. Cloud Spanner
4. Cloud Datastore
<details><div>
    答え：1
説明
回答 A. クラウドSQL
Cloud SQLは、Google Cloud Platform上でリレーショナル・データベースのセットアップ、保守、管理、運用を行うことができるフルマネージドのリレーショナル・データベース・サービスであるため、正しい選択肢です。トランザクション処理、データウェアハウス、eコマースなど、リレーショナルデータベースを必要とするアプリケーションに最適です。また、Cloud SQLは、最大20TBのデータベースを含む幅広いデータベースサイズをサポートしているため、オンプレミスのデータベースをGCPに移行する際にも適しています。
不正解の選択肢
Cloud Bigtableは大規模なスケーラビリティと高いパフォーマンスを実現するために設計されたNoSQLデータベースであり、Cloud Spannerはグローバルに分散されたリレーショナル・データベース・サービスであり、Cloud Datastoreは非リレーショナル・データを格納するためのNoSQLドキュメント・データベースであるためです。これらのオプションはいずれも、オンプレミスのデータベースをGCPに移行するのには適していない。
参考リンク
クラウドSQL: https://cloud.google.com/sql
</div></details>

### Q. 10
何百万台ものコンピュータのCPUとメモリ使用量に関する時系列データを効果的に保存するデータベースの選択に関する決断に迫られていると想像してほしい。要件は、このデータを1秒間隔で取得したサンプルとして保存することです。このデータはアナリストがリアルタイムのアドホック分析に使用するため、データベースは効率的なクエリ実行をサポートする必要があります。さらに、クエリを実行するたびに料金が発生するのを防ぎ、選択したスキーマ設計が将来的なデータセットの拡張に対応できることを目的としています。これらの目的に最適なデータベースとデータモデルはどれでしょうか？
1. 
2. 
3. 
4. 
<details><div>
    答え：3
説明
正解はCです。Bigtableに、コンピュータ・エンジンのコンピュータ識別子と各秒のサンプル時間を組み合わせた行キーを持つ狭いテーブルを作成します。
こうすることで、アナリストはデータをすばやく照会できるようになり、スキーマ設計がデータセットの将来の成長を可能にします。Bigtableは、データへの高速アクセスとクエリを可能にするので、この種のデータには最適です。
不正解の選択肢
BigQueryはリアルタイムのアドホック分析をサポートしていないため、オプションAは不正解です。
BigQueryはリアルタイムのアドホック分析をサポートしておらず、各秒の間隔で行を更新するのは効率的ではないため、オプションBは不正解です。
Bigtableはワイドテーブルをサポートしておらず、各秒の値を列データとして結合するのは非効率的であるため、オプションDは不正解です。
参考リンク
https://cloud.google.com/bigtable/docs/schema-design-time-series
</div></details>

### Q. 11
クラウド・ストレージ環境内にデータをアーカイブすることを意図しており、特に機密性の高い情報の保護に注意を払っています。最大限のセキュリティと機密性を確保するため、クラウドプロバイダーの担当者であっても不正アクセスを防止する「Trust No One」（TNO）暗号化アプローチの導入を強く希望しています。
クラウドストレージにデータを保存する前に、「Trust No One」（TNO）アプローチを使ってデータを安全に暗号化するには、どのような手順を踏むべきでしょうか？
1. gcloud kms keys createを使って共通鍵を作成します。次に、gcloud kms encryptを使用して、各アーカイブファイルをキーと一意の追加認証データ（AAD）で暗号化します。gsutil cpを使用して、暗号化された各ファイルをCloud Storageバケットにアップロードし、AADをGoogle Cloud外に保管します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
選択肢Aが正解です。
このオプションでは、Trust No One（TNO）アプローチを使用してデータを暗号化し、クラウドプロバイダのスタッフがデータを復号化できないようにします。対称キーは、キーと一意の追加認証データ（AAD）で各アーカイブファイルを暗号化するために使用されます。暗号化されたファイルはCloud Storageバケットにアップロードされ、AADはGoogle Cloudの外部に保管されます。
正しくないオプション
オプションBはTNOのアプローチを使用していないため、不正解です。対称鍵は各アーカイブファイルの暗号化に使用されるが、鍵は破棄されずローテーションされる。これは、クラウド・プロバイダーのスタッフが鍵にアクセスし、データの復号化に使用できる可能性があることを意味する。
オプションCはTNOのアプローチを使用していないため、誤りである。顧客提供の暗号化キー（CSEK）は.boto設定ファイルで指定され、アーカイブ・ファイルはクラウド・ストレージ・バケットにアップロードされる。CSEKはクラウドメモリストアに保存されますが、クラウドプロバイダーのスタッフがアクセスできないようにするには十分なセキュリティではありません。
オプションDはTNOのアプローチを使用していないため、不正解です。顧客提供の暗号化キー（CSEK）は.boto設定ファイルで指定され、アーカイブファイルはクラウドストレージバケットにアップロードされます。CSEKは別のプロジェクトに保存されますが、これはクラウド・プロバイダーのスタッフがアクセスできないことを保証するものではありません。
参考リンク
https://cloud.google.com/security/encryption-at-rest/customer-supplied-encryption-keys/
</div></details>

### Q. 12
BigQuery、Dataflow、Dataprocで運用中のデータパイプラインがあり、ヘルスアセスメントやパフォーマンスの監視を行う機能が必要な場合、どのように進めればよいのでしょうか。さらに、これらのパイプラインの監督を担当するチームに障害が発生した場合にアラートを出す必要があり、さまざまなプロジェクトでシームレスに運用できなければなりません。プラットフォームが管理する製品や機能を活用したいと考えています。
このシナリオでは、どのような手順を踏むべきでしょうか？
1. 情報をCloud Monitoringにエクスポートし、アラートポリシーを設定します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。
Cloud MonitoringはGoogle Cloud Platformが提供するマネージドサービスであり、データパイプラインの監視と管理を可能にするからです。Cloud MonitoringはGoogle Cloud Platformが提供するマネージドサービスであり、データパイプラインの監視と管理を可能にする。Cloud Monitoringはアラートポリシーを提供し、パイプラインに障害が発生した場合にパイプラインを管理するチームに通知するように設定できる。さらに、Cloud Monitoringは複数のプロジェクトで使用できるため、このような状況に最も適した選択肢となる。
不適切なオプション
Compute Engine with AirflowのVirtual Machinesはマネージドサービスではないため、選択肢Bは誤りです。
オプションCは、BigQueryがアラートポリシーを提供していないため、この状況に最適なオプションではないため、不正解です。
App Engine は、GCP API 呼び出しを使用してログを消費するアプリケーションを開発する必要があり、他の選択肢よりも複雑であるため、この状況では最適な選択肢ではないため、選択肢 D は正しくありません。
参考リンク
クラウド監視に関する Google Cloud Platform のドキュメント: https://cloud.google.com/monitoring
</div></details>

### Q. 13
顧客が自社の商品を購入する確率を予測するためにBigQuery MLで線形回帰モデルを開発する際、重要な予測要因として都市名の変数がありますが、モデルの学習と展開のためにデータを列に効率的に構造化し、必要な変数を保持しながら必要なコーディング工数を最小限に抑えるにはどうすればよいでしょうか？
1. 
2. BigQueryのSQLを使用して、ワンホットエンコーディング法を使用してstateカラムを変換し、各都市をバイナリ値を持つカラムにします。
3. 
4. 
<details><div>
    答え：2
説明
正解はBです。
これは各都市に新しい列を作成し、都市名に基づいて各行にバイナリ値を割り当てるので、データを準備する最も効率的な方法です。これにより、モデルは都市名を予測変数として使用できるようになります。
不正解の選択肢
A. 都市情報の列を含まない新しいビューをBigQueryで作成しても、都市を予測変数として使用するために必要な情報をモデルに提供することはできません。
C. C. TensorFlow を使用して語彙リストを持つカテゴリ変数を作成すると、時間がかかりすぎ、必要以上のコーディングが必要になる。
D. クラウドデータフュージョンを使って、各都市を1,2,3,4,5とラベル付けされた地域に割り当て、その番号を使ってモデルで都市を表すことは、予測変数として都市を使うために必要な情報をモデルに提供しない。
</div></details>

### Q. 14
あなたは、北米で広く事業を展開する有名銀行に雇われている。あなたの仕事は、銀行口座取引を管理するために設計されたデータストレージシステムを構築することです。あなたの具体的なニーズには、ACIDコンプライアンス原則の遵守と、SQLクエリを使用してデータを取得する機能が含まれます。この目的に適したソリューションは何でしょうか？
1. トランザクションデータをCloud Spannerに格納する。ステールリードを有効にしてレイテンシを減らす。
2. トランザクションデータをCloud Spannerに格納する。ロック付き読み書きトランザクションを使用する。
3. トランザクションデータをBigQueryに保存する。クエリキャッシュを無効にして一貫性を確保する。
4. トランザクションデータをCloud SQLに格納する。分析にはBigQueryとの連携クエリを使用する。
<details><div>
    答え：2
説明
オプションB：
Cloud Spannerはグローバルに分散され、ACIDコンプライアンスを提供する一貫性の強いデータベースサービスであるため、銀行口座のトランザクションを処理するのに適している。Cloud Spannerでロック付き読み書きトランザクションを使用すると、データの一貫性と整合性を確保できます。
以下はオプションBに関する考慮事項です：
強力な一貫性： Cloud Spannerは強力な一貫性を提供します。これは銀行環境でデータの整合性を維持するために極めて重要です。
ACIDコンプライアンス： Cloud SpannerはACIDに準拠しており、トランザクション・データ・ストレージの要件を満たしています。
読み書きトランザクションのロック 読み書きトランザクションをロックすることで、データへのアクセスを制御して競合を防ぎ、データの整合性を確保できます。
不正解の選択肢
A. 
Cloud SpannerはACIDに準拠しており、トランザクション・データに適していますが、ステール・リードを有効にするとデータの一貫性が損なわれる可能性があります。ステイル・リードを有効にすると、最新ではないデータを読み込むことができるため、データの整合性が重要な銀行口座のトランザクションには適していません。
C. 
BigQueryは分析ワークロード用に設計されており、トランザクションデータベースではない。ACID コンプライアンスや強力なトランザクション一貫性は提供しません。BigQueryのクエリキャッシュを無効にしても、これらの基本的な要件には対処できません。
D. 
Cloud SQL は、ACID コンプライアンスと強力な一貫性を提供するマネージド・リレーショナル・データベースであり、トランザクション・データの保存に適しています。BigQueryとの連携クエリを分析に使用することで、トランザクション処理と分析で両方のサービスの強みを活用できます。このアプローチはバランスが取れており、指定された要件を満たすことができます。
</div></details>

### Q. 15
ある運送会社では、荷物の追跡データをApache Kafkaストリームにリアルタイムで送信しています。このデータはBigQueryにロードされます。社内のアナリストは、BigQueryで追跡データを照会して、パッケージのライフサイクルにおける地理空間的傾向を分析したいと考えています。このテーブルは当初、インジェスト・デート・パーティショニングで作成されました。時間の経過とともに、クエリの処理時間が長くなっています。あなたのタスクは、BigQueryのクエリパフォーマンスを向上させるための修正を特定することです。
どのような対策を取るべきですか？
1. 
2. パッケージ追跡ID列にクラスタリングを実装する
3. 
4. 
<details><div>
    答え：2
説明
オプションB - 
BigQueryのクラスタリングは、クラスタリング列に基づいて各パーティション内のデータを物理的に整理することで、クエリ・パフォーマンスを最適化するために使用されます。パッケージ追跡 ID 列にクラスタリングを実装すると、パッケージ追跡 ID でデータをフィルタリングまたはソートするクエリにおいて、クエリ・パフォーマンスの向上に役立つ可能性があります。
クラスタリングは、フィルタ句を使用するクエリやデータを集約するクエリなど、特定のタイプのクエリのパフォーマンスを向上させます。クエリジョブまたはロードジョブによってクラスタ化テーブルにデータが書き込まれると、BigQueryはクラスタリング列の値を使用してデータをソートします。これらの値は、BigQueryストレージ内でデータを複数のブロックに整理するために使用されます。クラスタリング列に基づいてデータをフィルタリングする句を含むクエリを送信すると、BigQueryはソートされたブロックを使用して不要なデータのスキャンを排除します。
参考リンク
BigQuery クラスタ化テーブル:- https://cloud.google.com/bigquery/docs/clustered-tables
</div></details>

### Q. 16
現在、Spark、Hive、HDFSを利用した大規模なオンプレミスクラスターをコロケーション施設で使用していますが、コスト削減を最大化しつつ、クラウドへの移行をタイムリーに行うにはどうすればよいでしょうか？このクラスタはピーク時の利用を想定して設計されていますが、多くのバッチジョブがあるため、需要が変動しています。貴社はまた、オンプレミスのオーバーヘッドとメンテナンスコストの削減を目指し、クラウドのサーバーレス・オファリングを採用することで、インフラを近代化しようとしています。コロケーション施設の契約更新まで2カ月しかありませんが、これらの目的を達成するためにどのような移行戦略をお勧めしますか？
1. 
2. ワークロードをDataproc plus Cloud Storageに移行し、後でモダナイズする。
3. 
4. 
<details><div>
    答え：2
説明
クラウドに移行してオーバーヘッドを削減し、コスト削減のメリットを享受するという貴社の目標と、最初の移行期間が2カ月という限られた期間であることを考慮すると、推奨されるアプローチは次のようになります：
B. 
このアプローチが適している理由は以下の通りです：
混乱を最小限に抑える： Googleクラウド上のマネージドSparkおよびHadoopサービスであるDataprocにワークロードを移行することで、既存のSparkおよびHiveジョブの中断を最小限に抑えることができます。DataprocはSparkとHiveのワークロードを実行するための使い慣れた環境を提供するため、迅速な移行が容易です。
コスト効率： データストレージソリューションとしてDataprocとCloud Storageを併用することで、クラウドのコスト効率の高いストレージオプションを活用することができます。クラウドストレージは拡張性が高く、競争力のある価格設定なので、オンプレミスのインフラストラクチャのオーバーヘッドなしにデータを保存できます。
時間的制約： 初期移行に2ヶ月というタイトなスケジュールを考えると、短時間で比較的簡単に移行できる戦略を優先することが重要です。Dataprocとクラウド・ストレージへの移行は、ワークロードをすぐにモダナイズするのに比べ、より直接的な方法です。
近代化： 最初の移行が完了した後に、最新化を計画することができます。ワークロードがクラウドで実行されるようになったら、BigQuery for HiveのモダナイゼーションやDataflow for Sparkのモダナイゼーションのようなサーバーレスオファリングを徐々に検討し、サーバーレスの機能とコストの最適化を活用しながら進めることができます。
オプションC（SparkワークロードをDataprocとHDFSに移行し、HiveワークロードをBigQuery用にモダナイズする）は、Hiveをすぐにモダナイズする特定のニーズがある場合に検討できます。ただし、オプションBに比べて複雑さが増し、実行に時間がかかる可能性があります。
オプションD（SparkとHiveの両方のワークロードをすぐに最新化する）は、最新化の取り組みがコード、アーキテクチャ、およびプロセスの変更を伴う可能性があるため、特に2カ月の時間枠を考えると、より長くリスクの高い経路になる可能性があります。
参考リンク
Cloud Dataproc:- https://cloud.google.com/dataproc/
</div></details>

### Q. 17
オンライン登録サービスを提供する金融機関に勤務するあなたは、新規登録された顧客のユーザデータをBigQueryに取り込む前にPub/Subに送信する際、顧客の政府発行の識別番号を隠すことでセキュリティを強化することを選択しました。一方、顧客サービス担当者が必要に応じて変更前の値にアクセスできるようにするつもりです。そのためには、どのような行動を取るべきでしょうか？
1. 
2. 
3. 
4. データをBigQueryにロードする前に、クラウドデータ損失防止（DLP）を使用して、入力値を暗号化形式保持暗号化トークンに置き換えます。
<details><div>
    答え：4
説明
正解はDです。
これは、機密データを保護するための最良のオプションです。これは、カスタマーサービス担当者が必要に応じて元の値を表示できるようにするためです。
正しくないオプション
BigQueryに組み込まれているAEAD暗号化では、カスタマーサービス担当者が元の値を見ることができないため、オプションAは正しくありません。
BigQueryの列レベルのセキュリティでは、カスタマーサービス担当者が元の値を表示することはできないため、オプションBは正しくありません。
オプションCは、クラウドデータ損失防止（DLP）により、カスタマーサービス担当者が必要に応じて元の値を見ることができないため、不正解です。
参考リンク
クラウドDLP
</div></details>

### Q. 18
テーブルをBigQueryに移行してデータモデルを決定する際、クエリのパフォーマンスを最適化するためにテーブルをどのように構造化すべきでしょうか？問題のテーブルには、複数の店舗での購入に関するデータが含まれており、トランザクションのタイムスタンプ、購入したアイテム、店舗ID、各店舗の市や州などの詳細が含まれています。定期的なクエリでは、過去30日間の個々のアイテムの売上を追跡し、州、都市、特定の店舗に基づいて購入パターンを分析します。
1. トランザクション時間でパーティショニングし、最初に州、次に市、次に店舗IDでクラスタリングします。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。
このオプションを使用すると、トランザクションの時間、州、市、および店舗IDによってテーブルをすばやくクエリできるため、正解です。これにより、探している特定の店舗、市町村、州をすばやく絞り込むことができるため、テーブルをクエリする際に最高のパフォーマンスが得られます。
不適切なオプション
最初に店舗 ID でクラスタリングすると、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション B は正しくありません。
最初に州によってトップレベル・クラスタリングを行うと、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション C は正しくありません。
最初にストア ID を指定したトップレベル・クラスタリングでは、テーブルへのクエリ時に最高のパフォーマンスは得られないため、オプション D は正しくありません。
参照リンク
https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 19
Pub/Sub フィードのサブスクライバのコードを更新しています。展開時にサブスクライバが誤ってメッセージを承認してしまい、メッセージが失われることを懸念しています。サブスクライバは確認メッセージを保持するように設定されていません。
展開後のエラーからの回復を保証するにはどうすればよいですか?
1. ローカル・マシンにPub/Subエミュレータをセットアップします。本番環境にデプロイする前に、新しいサブスクライバ・ロジックの動作を検証してください。
2. 新しいサブスクライバコードをデプロイする前に、Pub/Sub スナップショットを作成します。Seek 処理を使用して、スナップショットの作成後に利用可能になったメッセージを再配信します。
3. デプロイには Cloud Build を使用します。デプロイ後にエラーが発生した場合は、Seek オペレーションを使用して、デプロイ開始時に Cloud Build によってログに記録されたタイムスタンプを検索します。
4. Pub/Sub トピックでデッドレタリングを有効にして、正常に承認されなかったメッセージを捕捉する。展開後にエラーが発生した場合は、デッド・レター・キューでキャプチャされたメッセージをすべて再配信します。
<details><div>
    答え：2
説明
オプション B. 
新しいサブスクライバ・コードをデプロイする前に Pub/Sub スナップショットを作成することで、特定の時点のサブスクリプションの状態を取得できます。新しいサブスクライバコードの問題により、誤って承認され失われたメッセージがある場合、Seek 操作を使用して、スナップショットの作成後に利用可能になったメッセージを再送信することができます。
この方法は、誤った確認応答によって失われたメッセージを回復するのに効果的です。ただし、メッセージの回復を確実に行うには、スナップショットの作成と管理に依存します。
誤ったオプション
A. 
ローカルでのテストは開発に不可欠な要素ですが、本番環境でのサブスクライバの動作にエラーがないことを保証するものではありません。Pub/Sub エミュレータは本番環境を完全に再現しているとは限らず、動作に違いが生じる可能性があります。さらに、このオプションは、デプロイ後にエラーが発生した場合にメッセージを回復するメカニズムを提供しません。
C. 
Cloud Build はデプロイメントを管理するための貴重なツールですが、Cloud Build によってログに記録されたタイムスタンプに依存してエラーを回復することは、最も単純で効率的な方法ではない可能性があります。手作業が必要であり、メッセージ復旧に必要なメッセージ固有の詳細を取得できない可能性があります。さらに、タイムスタンプだけでは、メッセージ処理の正確な状態をピンポイントで特定するには不十分な場合があります。
D. 
デッドレターを有効にすることは、正常に処理できなかったメッセージをキャプチャするための確立された方法です。これは、処理中にエラーが発生したメッセージを回復するための体系的かつ自動化された方法を提供し、デプロイ後のメッセージ回復を確実にするための、より強固なオプションとなります。
参考リンク
Cloud Pub/Sub:- https://cloud.google.com/pubsub/
</div></details>

### Q. 20
著名な不動産会社に勤務するあなたは、機械学習用に6TBもの膨大な住宅販売データを準備する仕事を任されています。あなたの目的は、データ変換にSQLを利用し、機械学習モデルを確立するためにBigQuery MLを採用することです。このモデルは、未処理の生のデータセットに対して予測を行うことを目的としています。予測段階でスキューを効果的に回避するために、ワークフローを構成する上でどのような手順を踏むべきですか？
1. モデルを作成する際、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データに対して変換を指定しません。
2. 
3. BigQueryビューを使用して前処理ロジックを定義します。モデルを作成する際、そのビューをモデルの学習データとして使用します。予測時には、生の入力データに対して変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
4. Dataflowを使用してすべてのデータを前処理する。予測時には、入力データに対してさらなる変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
<details><div>
    答え：1
説明
オプションA. 
モデル作成時には、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。モデルの学習時には、これらの前処理ステップが学習データに適用されます。
予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データには変換を指定しません。これは、予測を行う前にモデルが内部的に生の入力データに同じ前処理ステップを適用することに依存していることを意味します。
モデルの前処理ロジックが十分に定義され、トレーニングデータと一貫している場合、オプションAは効果的に機能するかもしれませんが、予測中にモデル自身が未加工の入力データの前処理を正しく処理する必要があります。このアプローチは、モデル内部の前処理が予測の歪みを防ぐのに十分であることを前提としています。
実際には、オプション A とオプション B のどちらを選択するかは、モデル内部の前処理ロジッ クの具体的な特性と信頼性、および予測プロセスにおける透明性と制御の要件によって決まります。どちらのオプションも有効ですが、前処理と予測の一貫性に対するアプローチが異なります。
正しくないオプション
オプションC - 
BigQueryビューを使用して前処理ロジックを定義することは、学習データと予測データ間の一貫性を確保するための有効なアプローチです。しかし、このオプションには、ML.EVALUATE を使用する前の生の入力データに対する明示的な変換ステップがありません。このビューは一貫した前処理ロジックを提供しますが、スキューを防止するために、生の入力データが同じ前処理ステップを受けることを確実にすることが重要です。
オプションD - 
Dataflowを使用してすべてのデータを前処理することは、データ変換と準備のための実行可能なソリューションです。しかし、このオプションはDataflowの前処理と予測中のモデル内部の前処理が同一であることを前提としています。また、前処理ステップには必要ないかもしれないが、Dataflowによってさらなる複雑さがもたらされる。
オプションCとオプションDの両方は、ML.EVALUATEを使用する前に生の入力データを一貫して変換する必要性に明示的に対処していません。
参考リンク
BigQuery ML:- https://cloud.google.com/bigquery/docs/bigqueryml-intro
</div></details>

### Q. 21
あなたはある会社の株価を分析しています。5秒ごとに、過去30秒分のデータの移動平均を計算する必要があります。あなたはPub/Subからデータを読み込み、DataFlowを使って分析を行っています。ウィンドウ・パイプラインをどのようにセットアップしますか？
1. 
2. 
3. 
4. 継続時間30秒、周期5秒のスライディング・ウィンドウを使用します。以下のトリガーを設定して結果を出力する： AfterWatermark.pastEndOfWindow()を設定する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
30秒のスライディング・ウィンドウ： 期間30秒のスライディング・ウィンドウを使用することは、移動平均計算のために直近の30秒間のデータを考慮し続けることを意味します。これはあなたの要求と一致しています。
期間5秒： 期間5秒は、ウィンドウが5秒ごとに前方にスライドすることを示します。こ れに よ り 、 直近 30 秒のデー タ に基づいて 5 秒ご と に移動平均を計算す る こ と が保証 さ れます。この設定は、5秒ごとに移動平均を計算するという要件に合致しています。
トリガー設定： トリガーは、透かしがウィンドウの最後を通過した後に結果を出すように設定されています。これにより、ウィンドウが前方にスライドしたときに計算がトリガーされ、移動平均計算の望ましいタイミングと一致します。
誤ったオプション
オプションA（5秒間の固定ウィンドウ）は、過去30秒分のデータを取り込みません。これは、5秒間の固定ウィンドウを提供しますが、要件を満たしていません。
オプションB（継続時間30秒の固定ウィンドウ）は、30秒のウィンドウをキャプチャしますが、5秒ごとに前方にスライドしません。これは、5秒ごとに移動平均を計算するという要件に合致しません。
オプションC（継続時間5秒のスライディング・ウィンドウ）は5秒のスライディング・ウィンドウをキャプチャしますが、過去30秒のデータの移動平均を計算するために必要な30秒の継続時間を持ちません。さらに、トリガー設定は30秒後にデータを処理するように設定されており、5秒間隔の要件とは一致しません。
参考リンク
ビーム・ウィンドウの基本:https://beam.apache.org/documentation/programming-guide/#windowing-basics
</div></details>

### Q. 22
データのスケーラブルな処理とBigQueryへのロードを保証すると同時に、これらのイベントをPub/Subトピックにパブリッシュするために構築しているパイプライン内で、メッセージのシーケンシングは気にしなくても、1時間ごとにアプリケーションイベントを集約できるようにするには、どのようなテクノロジを採用すべきでしょうか？
1. 
2. 
3. 
4. Pub/Subトピックから継続的に読み取り、タンブリング・ウィンドウを使用して必要な集約を実行するストリーミングDataflowジョブを作成します。
<details><div>
    答え：4
説明
正しい選択肢はDです。
ストリーミングDataflowジョブはPub/Subトピックからのメッセージを継続的に処理し、タンブリング・ウィンドウを使用して必要な集計を実行できるため、このオプションは正しい。これにより、大量のイベントに対応しながら、タイムリーにデータが処理され、BigQueryにロードされます。
不正解の選択肢
クラウド関数は、新しいメッセージがトピックにパブリッシュされたときにのみトリガされ、1時間ごとの区切りでイベントを処理および集計できないため、オプションAは不正解です。
オプション B は、クラウド関数が Pub/Sub トピックから利用可能なすべてのメッセージをプルし、1 回の実行で必要な集計を実行できるだけであり、1 時間ごとの区切りでイベントを処理および集計することはできないため、不正解です。
バッチデータフロージョブは、Pub/Subトピックから利用可能なすべてのメッセージをプルし、1回の実行で必要な集計を実行できるだけであり、不連続な時間間隔にわたってイベントを処理および集計することはできないため、オプションCは正しくありません。
参考リンク
https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines
</div></details>

### Q. 23
大手金融機関の従業員として、Dialogflowを使用してモバイルアプリケーション内でチャットボットを作成しようとしているあなたは、過去のチャット記録を綿密に調査し、顧客がカスタマーサービスに連絡した理由と一致する意図に従って、すべての会話を分類しました。顧客からの問い合わせの約70%は率直な要求が中心で、通常、最初の10件以内に解決されます。一方、残り30％の問い合わせは複雑で、対応にかなりの時間と労力を要する。このような状況を踏まえて、最初に自動化の優先順位をつけるべきインテントはどれでしょうか？
1. 生のエージェントがより複雑なリクエストに対応できるように、リクエストの70%をカバーする10のインテントを自動化する。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正しい選択肢 A. 
顧客リクエストの70%をカバーする最も一般的な10のインテントを自動化することは、現実的なアプローチです。自動化によって、顧客からの問い合わせの大部分に効率的に対応することに重点を置いています。これらのインテントを自動化することで、一般的なリクエストに対して迅速かつ一貫したレスポンスを提供できるようになり、効率が向上するだけでなく、ユーザーエクスペリエンスも向上します。
生身のエージェントが定型的で頻繁に発生するリクエストの処理から解放されることで、より複雑で個別対応が必要な残りの30%の問い合わせに、より多くの時間と注意を割くことができます。これにより、リソースの割り当てが最適化され、複雑な問題に対する全体的なサービス品質が向上します。
誤ったオプション
オプションB（「より複雑なリクエストを最初に自動化する」）は、場合によっては合理的なアプローチですが、大半の顧客からの問い合わせの効率を最適化するという当面の問題には対処できないかもしれません。複雑なリクエストに集中するあまり、最も一般的で簡単なリクエストがおろそかになる可能性がある。
オプションC（「最も短いインテントと最も長いインテントの混合を自動化する」）は、様々なインテントタイプで自動化のバランスを取ろうとしているが、顧客リクエストの分布と一致しない可能性がある。あまり一般的でないインテントを不必要に自動化する可能性がある。
オプションD（「"payment "などの一般的な単語が一度だけ出現する場所のインテントを自動化する」）は、必ずしも頻度や複雑さではなく、特定のキーワードに基づいてインテントを優先する。このアプローチでは、最も一般的または重要なインテントを捕捉できない可能性があります。
参考リンク
AI製品： https://cloud.google.com/products/ai/
</div></details>

### Q. 24
あなたは、現在構築中のBigQueryベースのデータウェアハウスのデータモデルを作成する責任を与えられました。スター型データスキーマを使用する既存のオンプレミス販売データウェアハウスをBigQueryプラットフォームに移行することが、目下の課題です。しかし、過去30日間の履歴データに対してクエリを実行したところ、パフォーマンスのボトルネックが発生しました。Googleが推奨するベストプラクティスに従って、ストレージ費用を抑えながらクエリ速度を向上させるには、どのような対策を講じればよいでしょうか？
1. 
2. 
3. 
4. トランザクションの日付でデータをパーティショニングします。
<details><div>
    答え：4
説明
BigQueryで過去30日分のデータをクエリする際に、データウェアハウスのストレージコストを増加させずにクエリのパフォーマンスを高速化するには、次のことを考慮する必要があります：
D. 
パーティショニング： パーティショニングとは、特定の属性（この場合はトランザクション日付など）に基づいて、データをより小さく管理しやすい塊に整理することです。パーティショニングは、時間ベースのデータのクエリ・パフォーマンスを向上させる効果的な方法です。データを日付でパーティショニングすると、BigQueryは特定の日付範囲のクエリを実行する際に、無関係なパーティションを効率的に削除することができます。
時間ベースのクエリ： パーティショニングは、過去30日間のデータをクエリする要件に適しています。これにより、BigQueryは関連するパーティションに焦点を当てることができ、データセット全体をスキャンするよりも大幅に高速化されます。
コスト効率： パーティショニングはデータの論理的な整理であるため、ストレージコストを増加させることはありません。使用するストレージの代金は支払いますが、パーティショニング自体がストレージ・コストを増加させることはありません。コストに影響を与えることなく、クエリのパフォーマンスを最適化します。
誤ったオプション
オプションA（データの非正規化）は、特定のタイプのクエリには役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスの問題には特に対応していません。
オプションB（顧客IDごとにデータをシャーディングする）は、日付ベースのクエリのパフォーマンスを直接改善しない可能性があり、特定の日付範囲のデータをクエリするときに複雑さをもたらす可能性があります。
オプションC（ビューで次元データをマテリアライズする）は、クエリを単純化するのに役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスを最適化するには、パーティショニングほど効果的ではないかもしれません。
参考リンク
BigQuery パーティショニング: https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 25
5年分のログデータをクラウドストレージにアップロードしました。あるユーザーから、ログの特定のデータポイントが想定される範囲から外れており、潜在的なエラーがあることを指摘されました。あなたの目的は、この問題を解決し、コンプライアンス目的で元のデータを保持しながら、将来的にプロセスを再実行できるようにすることです。どのような手順を踏むべきでしょうか？
1. 
2. 
3. データフローワークフローを作成し、クラウドストレージからデータを読み取り、予期される範囲外の値をチェックし、値を適切なデフォルトに設定し、更新されたレコードをクラウドストレージの新しいデータセットに書き込む。
4. 
<details><div>
    答え：3
説明
コンプライアンス上の理由から元のデータを保持しながら、ログデータ内の想定範囲外のデータポイントの問題に対処するには、次のことを検討する必要があります：
C. C. 
このオプションが適切な理由は以下の通り：
データ変換： データ変換： データフローを使用することで、元のデータセットを保持したまま、期待範囲外のデータポイントを識別して修正するデータ変換ロジックを実装することができます。これにより、誤ったデータが確実に修正されます。
オリジナルデータの保持： 更新されたレコードをクラウド・ストレージの新しいデータセットに書き込むことで、コンプライアンス上の理由からオリジナル・データの整合性を維持することができます。このアプローチでは、元のデータセットがそのまま維持され、分析や使用のために修正されたクリーンなバージョンが提供されます。
誤ったオプション
オプションA（データをBigQueryにインポートし、エラーのある行をスキップする）はうまくいくかもしれませんが、コンプライアンス上の理由で必要となる可能性がある、元のデータを変更されていない状態で保持することはできません。
オプションB（Compute Engineのインスタンスを作成し、エラーのある行をスキップしながらデータをコピーする）は、手作業で複雑なプロセスになる可能性があり、Dataflowのようなデータ処理フレームワークを使用するほど効率的ではないかもしれない。
オプションD（更新されたレコードをクラウドストレージの同じデータセットに書き込む）は、元のデータを上書きする。
</div></details>

### Q. 26
サーバーレスツールとSOL構文を活用して開発を加速し、パイプラインの実行時間を短縮しながら、スピードと処理要件を満たすGoogle Cloudパイプラインを構築するにはどうすればよいでしょうか？現在のアプローチでは、大規模なデータ変換にPySparkを使用しており、実行に12時間以上かかっています。生データがクラウドストレージに転送されていることは重要です。
1. 
2. 
3. Cloud StorageからBigQueryにデータを取り込み、PySparkコマンドをBigQuery SQLクエリに変換してデータを変換し、変換結果を新しいテーブルに書き込みます。
4. 
<details><div>
    答え：3
説明
Google Cloud上の構造化データで速度と処理要件を満たしながら、開発とパイプラインの実行時間を短縮するには、次のことを検討する必要があります：
C. C. 
サーバーレスでスケーラブル： BigQueryはサーバーレスデータウェアハウスであり、インフラストラクチャを管理することなく大規模なデータ処理を行うことができます。高速処理のために設計されているため、パイプラインの実行時間を短縮できる。
SQL構文： SQL構文を使用したいので、BigQueryは完全に管理された強力なSQLエンジンを提供します。PySparkのコマンドを直接BigQueryのSQLクエリに変換できるので、移行や変換のプロセスがスムーズになります。
クラウドストレージとの統合： BigQueryはクラウドストレージとシームレスに統合されており、クラウドストレージからBigQueryにデータを取り込んで分析や変換を行うことができます。
変換の書き込み： BigQueryはSQL変換の結果を新しいテーブルに書き出すことをサポートしており、元のデータを保持したまま、さらなる分析のために変換されたデータを保存できます。
誤ったオプション
オプションA（Dataproc上でパイプラインを実行する）では、Dataprocクラスタのセットアップと管理が必要になるため、BigQueryのようなフルマネージドサービスを使用する場合と比較して、コスト効率や利便性が劣る可能性があります。
オプションB（Cloud SQLにデータを取り込み、連携クエリを使用）は、データ処理に複数のサービスを使用するため複雑さが生じ、BigQueryのようなパフォーマンスメリットが得られない可能性がある。
オプションD（Apache Beam Python SDKの使用）は有効な選択肢ですが、BigQueryのビルトインSQL機能を活用するのに比べて開発工数がかかる可能性があります。Pythonの使用を好み、データ変換プロセスをより制御する必要がある場合は、Apache Beamが適切な選択肢になる可能性があります。
</div></details>

### Q. 27
テキストファイルを取り込んで変換するDataflowパイプラインをテストしています。Dataflowジョブは、圧縮されたgzipファイル、デッドレターキューによるエラー処理、データ結合のためのSideInputsの利用により、予想よりも遅く実行されています。パイプラインの完了を加速するために、どのようなアクションを取るべきでしょうか？
1. 
2. 
3. 
4. SideInputの代わりにCoGroupByKeyを使用する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
CoGroupByKey： CoGroupByKey: CoGroupByKeyは、Apache Beam（Dataflowの基盤）の変換で、複数の入力PCollectionsからのデータを共通のキーに基づいてグループ化する。複数のソースからのデータを効率的に結合するために使用できます。SideInputsの使用に関連したパフォーマンス問題が発生している場合、CoGroupByKeyに切り替えることが有効な最適化かもしれません。SideInputsは、特に大きなデータセットを扱う場合、要素ごとのルックアップを伴うため、オーバーヘッドが発生する可能性があります。
SideInputsの代わりにCoGroupByKeyを使用するように処理戦略を変更することで、パフォーマンスの問題に対処できる可能性があります。このオプションの選択は、パイプラインの仕様と、どこでボトルネックが発生しているかに依存します。パイプラインの動作とパフォーマンス特性を分析し、十分な情報を得た上で決定することが重要です。
誤ったオプション
オプションA（圧縮Avroファイルへの切り替え）は、主にデータストレージと圧縮効率に対処しますが、特にパフォーマンスのボトルネックが圧縮ではなくデータ処理にある場合、Dataflowジョブを直接迅速化しない可能性があります。
オプションB（バッチサイズを小さくする）は、ある程度ジョブ効率を向上させることができますが、SideInputsやjoinオペレーションに関連するパフォーマンス問題に対処する最も効果的な方法ではないかもしれません。小さいバッチは並列処理に役立つが、処理戦略を根本的に変えないかもしれない。
オプションC（エラーをスローしたレコードを再試行する）は、エラー処理に重点を置いており、ジョブ実行時間の問題に直接対処していない。エラーを効果的に処理することは不可欠ですが、ジョブの完了を早める主要な方法ではありません。
参考リンク
https://beam.apache.org/documentation/transforms/python/aggregation/cogroupbykey/
</div></details>

### Q. 28
あなたは、PII（個人を特定できる情報）データを含む可能性のあるファイルをクラウドストレージにストリームし、最終的にBigQueryにストリームするリアルタイム予測エンジンを構築しています。PIIデータへの不正アクセスを防ぐために、クラウドデータ損失防止API（DLP API）を使用して、名前や電子メールなどの機密データをマスキングしながら参照整合性を維持するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. PIIデータを暗号化フォーマット保持トークンで置き換えて偽名を作成する。
<details><div>
    答え：4
説明
参照整合性を維持しながら、PII データに権限のない個人がアクセスできないようにするには、次のアプローチを検討する必要があります：
D. D. 
このオプションが適切な理由は以下のとおりです：
暗号化形式保存トークン： 暗号化トークン：暗号化トークンを使用することで、PII データの形式と参照整合性を保持したまま、PII データを仮名化することができます。これにより、名前や電子メールなどの結合キーが引き続き効果的に使用できるようになります。
機密データの保護： 暗号化トークンを使用することで、強力なデータ保護が実現し、権限のない個人による機密PIIデータへのアクセスや悪用が困難になります。
不正なオプション
オプション A（暗号化トークンを作成し、トークン化されていないデータをロックダウンされたバケツに保存する）は、PII データを仮名化するという点ではオプション D に似ていますが、フォーマットと参照整合性を維持するために不可欠な暗号化フォーマット保持トークンの使用を指定していません。
オプションB（すべてのPIIデータを再編集する）は、機密情報を永久に削除します。これは、結合キーの参照整合性を維持する必要がある場合には適していない可能性があります。
オプションC（BigQueryのすべてのテーブルをスキャンし、検出したデータをPIIでマスクする）はBigQueryに有効かもしれませんが、クラウドストレージからのPIIデータ取り込みプロセスに直接対応しておらず、暗号化トークンの使用についても言及していません。
参考リンク
クラウドDLP
</div></details>

### Q. 29
図書館の本とその詳細(著者や出版年など)をモニタリングするアプリケーションをオンプレミスのデータ ウェアハウスから BigQuery に移行する際に、借りた書籍の著者に関する情報のクエリ速度を最速にするために、Google が推奨するスキーマ設計手法に従ってデータをどのように構成しますか?既存の設定では、著者の詳細を個別のテーブルに保持し、現在のリレーショナル データベース内の共有キーを介して書籍情報にリンクします。
1. スキーマを同じに保ち、書籍と各属性の異なるテーブルを維持し、現在行っているようにクエリを実行します
2. 幅が広く、作成者の銘、性、年月日など、各属性の列を含むテーブルを作成します
3. 書籍と著者に関する情報を含むテーブルを作成しますが、著者フィールドは著者列内にネストします。
4. スキーマを同じに保ち、すべてのテーブルを結合するビューを作成し、常にビューをクエリします
<details><div>
    答え：3
説明
図書館の図書追跡アプリケーションを BigQuery に移行する際に、借りた各書籍の著者に関するクエリの速度を最適化するには、次の方法を検討する必要があります。
C. 
ネストされたデータ: BigQuery は、テーブル内のネストされたフィールドと繰り返されるフィールドをサポートしています。著者情報を著者列内に入れ子にすることで、コストのかかる結合を回避しながら、書籍と著者の関係を維持できます。これにより、各書籍の著者に関する効率的なクエリが可能になります。
結合の削減: 著者情報を同じテーブル内に保持すると、著者の詳細と書籍の詳細を照会するときに結合が不要になります。これにより、クエリの実行が高速化され、待機時間が短縮されます。
簡略化されたクエリ: 入れ子になったデータを使用すると、クエリを簡略化し、複数のテーブルを結合する複雑さを回避できます。著者情報は、書籍情報と同じ行内で直接アクセスできます。
正しくないオプション -
オプション A (書籍と属性のテーブルを分けてスキーマを同じに保つ) は、結合が必要になる可能性が高く、著者に関するクエリでは効率的ではない可能性があります。
オプション B (各属性の列を含む幅の広いテーブルを作成する) は、特に作成者に複数の属性がある場合、スキーマが非正規化され、保守性が低下する可能性があります。
オプション D(すべてのテーブルを結合するビューを作成する)では、結合が必要になるため、クエリのパフォーマンスが低下する可能性があり、ネストされたデータ構造に対する BigQuery の機能を十分に活用できない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/nested-repeated
</div></details>

### Q. 30
データ ポイントを受信して GUID を生成するサービスを通じて、新しい Web サイト ユーザーにグローバル一意識別子 (GUID) を提供するときに、バックプレッシャーの懸念を最小限に抑えるためにパイプラインを構成するにはどうすればよいでしょうか。このデータは、内部システムと外部システムの両方から発生し、パイプライン内のマイクロサービスを介してHTTP呼び出しを介してアクセスされ、システムへのバックプレッシャーを回避しながら、マルチスレッドの可能性がある毎秒数万件の大量のメッセージの影響を受けます。
1. HTTP経由でサービスを呼び出します
2. パイプラインをクラス定義で静的に作成します
3. DnFnのstartbundleメソッドで新しいオブジェクトを作成します
4. ジョブを 10 秒単位でバッチ処理します。
<details><div>
    答え：4
説明
D. 
このオプションは、メッセージを 10 秒間隔でバッチ処理することを提案します。このアプローチの理論的根拠は次のとおりです。
バックプレッシャーの低減: 処理のためにメッセージをバッチ処理すると、メッセージの取り込みと処理の速度を制限することで、バックプレッシャーを減らすことができます。これにより、パイプラインへのデータフローを制御し、処理負荷の急増を防ぐことができます。
ただし、このアプローチにはトレードオフも生じることに注意することが重要です。
待機時間: メッセージをバッチ処理すると、一部のメッセージが次のバッチ ウィンドウまで遅延する可能性があるため、処理に待機時間が発生する可能性があります。これは、リアルタイムまたは低待機時間の処理が重要なシナリオには適していない可能性があります。
複雑さ: バッチ処理を実装すると、特にマイクロサービスや HTTP 呼び出しを処理する場合に、パイプラインが複雑になる可能性があります。定期的にバッチを管理およびフラッシュするメカニズムが必要になります。
正しくないオプション -
オプション A (HTTP 経由でサービスを呼び出す): このオプションは、通常、リアルタイムまたはほぼリアルタイムの処理に適していますが、バックプレッシャーを減らすという目標に合わない場合があります。各メッセージに対して HTTP 呼び出しを行う際の高スループットと潜在的なボトルネックを考慮することが重要です。
オプション B (クラス定義でパイプラインを静的に作成する) と C (DoFn の startBundle メソッドで新しいオブジェクトを作成する): これらのオプションは、バックプレッシャーに直接対処するのではなく、パイプライン コンポーネントの設計とインスタンス化に関連しています。これらは、高スループットのシナリオにおけるバックプレッシャーの懸念を本質的に軽減するものではありません。
</div></details>

### Q. 31
データ ウェアハウスを Google Cloud に移行し、オンプレミスのデータセンターをシャットダウンしているところです。この取り組みの優先度が高いことを認識した上で、クラウドへの初期データ転送に十分な帯域幅が提供されることを期待しています。移動するファイルの量はそれほど多くありませんが、個々のファイルは 90 ギガバイトを占有します。さらに、トランザクション システムから Google Cloud ベースのウェアハウスへの更新フローをリアルタイムで一定に維持することを目指しています。
データの移行と、ウェアハウスへの中断のない書き込みの保証の両方に推奨されるツールは何ですか?
1. 
2. 
3. gsutil (移行用)Pub/Sub と Dataflow によるリアルタイム更新。
4. 
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
データ移行(gsutil):
gsutil: Google Cloud Storage Utility(gsutil)は、Google Cloud Storage との間でデータを効率的に転送するためのコマンドライン ツールです。これは、90 GB のファイルなどの大きなファイルの移行を処理するのに適しています。これは、初期データ読み込みのための簡単で効率的な選択です。
リアルタイム更新(Pub/Sub とデータフロー):
Pub/Sub: Google Cloud Pub/Sub は、トランザクション システムからダウンストリーム サービスにリアルタイムでデータをストリーミングするために使用できるスケーラブルなメッセージング サービスです。リアルタイムのデータストリーミング用に設計されており、他のGoogle Cloudサービスとうまく統合できます。
データフロー: Google Cloud Dataflow は、強力なストリームおよびバッチ データ処理サービスです。Pub/Sub からのリアルタイム データ ストリームを処理し、変換、集計、その他のデータ処理タスクを実行するために使用できます。リアルタイムのデータ更新に適しており、複雑なデータ処理シナリオを処理できます。
正しくないオプション -
オプション A (移行用のストレージ転送サービス。Pub/Sub と Cloud Data Fusion (リアルタイム更新用):
ストレージ転送サービス: ストレージ転送サービスは大規模なデータ転送に効率的ですが、主に 1 回限りまたは定期的な転送用に設計されています。リアルタイムのデータストリーミングには最適化されていません。
Cloud Data Fusion: Cloud Data Fusion はデータ統合サービスですが、通常はリアルタイムの更新ではなく、バッチ処理や ETL 処理に使用されます。リアルタイムの更新に使用すると、ソリューションが複雑になりすぎる可能性があります。
オプション B(移行用の BigQuery Data Transfer Service。Pub/Sub と Dataproc (リアルタイム更新用):
BigQuery Data Transfer Service: BigQuery Data Transfer Service は、BigQuery への自動データインポートに重点を置いているため、Google Cloud Storage への大容量ファイルの移行には適していない場合があります。
Dataproc: Google Cloud Dataproc は、主に Apache Spark と Hadoop のジョブの実行に使用されますが、リアルタイムの更新には必要ない場合があります。バッチ処理に適しています。
オプション D(移行とリアルタイム更新の両方に gsutil):
gsutil: gsutil はデータ移行には適していますが、リアルタイムのデータ ストリーミングや処理用には設計されていません。リアルタイム更新に gsutil を使用するのは現実的ではありません。
参考リンク -
https://cloud.google.com/storage/docs/gsutil
</div></details>

### Q. 32
Bigtable を使用して取引アプリケーションでこれらのインデックスの株式市場データを保存および提供する際に、すべての主要インデックスの最新の株価にアクセスするための最もシンプルなクエリを確実に行うには、Bigtable 内で行キーとテーブルをどのように構成すればよいでしょうか。
1. 
2. すべてのインデックスに対して一意のテーブルを 1 つ作成し、行キーの設計として逆タイムスタンプを使用します。
3. 
4. 
<details><div>
    答え：2
説明
B. 
このオプションが適切であると考えられる理由は次のとおりです。
すべてのインデックスに対して 1 つのテーブル: すべてのインデックスに対して 1 つのテーブルを使用することで、複数のテーブルを作成する必要がなくなり、管理が簡素化されます。インデックスの数が多い場合は、それぞれに個別のテーブルを管理するのが面倒になる可能性があるため、特に便利です。
行キーとしての逆タイムスタンプ: 行キー設計として逆タイムスタンプを使用すると、最新の株価に簡単にアクセスできます。Bigtable は行を辞書式に並べ替えるため、最新のデータがテーブルの先頭に配置され、効率的に取得できます。
オプションBは機能しますが、いくつかのトレードオフと複雑さが伴います。
複雑な範囲クエリ: 最新のデータを取得するのは効率的ですが、履歴データに対して範囲クエリを実行するとより複雑になる場合があります。古いデータを効率的に取得するために、追加のロジックを実装する必要がある場合があります。
データの分離: 1 つのテーブルを使用すると、すべてのインデックスが一緒に格納されます。特定のインデックスを含むクエリを実行したり、特定のインデックスのデータを分離したりする必要がある場合は、追加のフィルター処理や処理が必要になることがあります。
正しくないオプション -
オプション A (すべてのインデックスに対して一意のテーブルを 1 つ作成し、インデックスとタイムスタンプを行キーの設計として使用します):
この方法では、タイムスタンプを抽出するために解析を必要とする複雑な行キー設計になる可能性があります。これにより、履歴データの範囲クエリの効率が低下する可能性があります。
オプション C (インデックスごとに個別のテーブルを用意し、行キーの設計としてタイムスタンプを使用します):
各インデックスのデータへのアクセスは簡素化されますが、インデックスの数が増えると、個別のテーブルを維持する必要があるため、管理オーバーヘッドが発生する可能性があります。
オプション D (インデックスごとに個別のテーブルを用意し、行キーの設計として逆タイムスタンプを使用します):
このオプションでは、インデックスごとに分離できますが、テーブルが急増し、管理が困難になる可能性があります。
参考リンク https://cloud.google.com/bigtable/docs/schema-design
</div></details>

### Q. 33
データの取り込みやレポート作成のパフォーマンスを損なうことなく 1 つのマスター データセットを維持するには、BigQuery のストリーミング API を使用して、Google が推奨するプラクティスに従って、レポートのみのデータ ウェアハウスのデータ読み込みプロセスをどのように構築すればよいのでしょうか?
1. 
2. 
3. ステージングされたデータを運用テーブルに移動し、ステージング テーブルの内容を 3 時間ごとに削除するステージング テーブルを用意します。
4. 
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
ステージング テーブル: ステージング テーブルを使用して、受信データを最初に取り込んで格納することは、一般的なベスト プラクティスです。これは、データ インジェスト用のバッファーを提供し、インジェスト プロセスを運用データセットから分離するのに役立ちます。
定期的な ETL: ステージング テーブルから運用テーブルに定期的に (この場合は 3 時間ごと) データを移動することで、マスター データセットの更新のタイミングを制御できます。これにより、レポートクエリが進行中の取り込みの影響を受けなくなります。
データのクリーンアップ: データを移動した後にステージング テーブルの内容を削除すると、過剰なデータが蓄積されることなく、新しいデータ インジェストに引き続き使用できます。
正しくないオプション -
オプション D (ステージング テーブルの内容を 30 分ごとに削除する) は、一部のユース ケースでは頻繁すぎる可能性があり、特に監査やエラー分析にデータ保持が必要な場合に、データ管理のオーバーヘッドが増加する可能性があります。
オプション A と B (3 時間または 90 分ごとに運用テーブルを更新する) では、レポート データセットの変更の反映に遅延が発生し、レポートの適時性に影響を与える可能性があります。
参考リンク -
https://cloud.google.com/bigquery/docs/streaming-data-into-bigquery
</div></details>

### Q. 34
新しい Dataflow バッチ ジョブを開始します。ジョブは正常に開始され、いくつかの要素を処理しますが、突然失敗して終了します。Dataflow モニタリング インターフェースにアクセスすると、パイプライン内の特定の DoFn に関連するエラー メッセージが検出されます。
これらのエラーの考えられる根本原因は何ですか?
1. 
2. ワーカー コードの例外
3. 
4. 
<details><div>
    答え：2
説明
B. 
Dataflow ジョブを開始すると、しばらくの間は正常に実行され、ワーカー コードの例外やエラーが原因で失敗することがあります。これらの例外により、ジョブが突然シャットダウンする可能性があります。特定の DoFn (パイプライン内の要素を処理するために定義する関数) に関連するエラーが表示される場合は、その DoFn 内のコードに問題がある可能性があります。
正しくないオプション -
A. ジョブの検証: Dataflow は通常、ジョブを開始する前に検証し、オプションの欠落や構成ミスなどの問題をチェックします。ジョブの検証で問題が発生した場合、ジョブは最初から開始されていない可能性があります。
C. グラフまたはパイプラインの構築: Dataflow パイプラインの構築方法の問題(コンポーネントの接続の誤りやフローの設定ミスなど)に関連します。これらの問題は通常、ジョブの検証または構築中に検出されますが、発生した場合、ジョブが開始時に失敗したり、期待どおりに実行されなかったりする可能性があります。
D. アクセス許可が不十分: これはアクセス許可とアクセス制御に関連しており、ジョブの開始や必要なリソースへのアクセスを妨げる可能性があります。アクセス許可が不十分な場合、ジョブが開始されなかったり、実行前に問題が発生したりする可能性があります。
参考リンク -
https://cloud.google.com/dataflow/docs/guides/common-errors
</div></details>

### Q. 35
新規顧客向けに、Google Cloud コンピューティング リソースの純消費量を詳細に記した日次レポートを迅速かつ効果的に作成し、これらのリソースのユーザーを特定するにはどうすればよいでしょうか。
1. Cloud Logging データを BigQuery に毎日エクスポートします。プロジェクト、ログタイプ、リソース、ユーザーでフィルタリングされたビューを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Google Cloud コンピューティング リソースの正味消費量とリソースを使用したユーザーを示す日次レポートを迅速かつ効率的に生成するには、次のオプションが最も適しています。
ある。
このオプションが適切な理由は次のとおりです。
Cloud Logging から BigQuery へ: ログデータを効率的に保存、分析するための一般的な方法は、Cloud Logging のデータを BigQuery にエクスポートする方法です。これにより、BigQuery のクエリ機能とスケーラビリティを活用できます。
フィルタリング用のビュー: BigQuery でビューを作成すると、プロジェクト、ログタイプ、リソース、ユーザーなどの特定の条件に基づいてデータを事前にフィルタリングできます。この事前フィルタリングにより、レポートを生成するための関連データを操作できるようになります。
毎日のエクスポート: 毎日のエクスポートを実行すると、レポートごとに新しいデータセットを操作でき、データを最新の状態に保つことができます。
正しくないオプション -
オプション B(プロジェクト、リソース、ユーザーで Cloud Logging のデータをフィルタリングし、そのデータを CSV 形式でエクスポートする)は機能する可能性がありますが、より複雑なクエリやレポート要件に対応する BigQuery の柔軟性と拡張性に欠けます。
オプション C(Cloud Logging でデータをフィルタリングして BigQuery にインポートする)では、追加のデータ移動手順が導入されるため、直接エクスポートよりも効率が悪く、タイムリーにならない可能性があります。
オプション D(Cloud Logging データを CSV 形式で Cloud Storage にエクスポートし、Dataprep を使用してクレンジングする)は複雑さを増し、日次レポートを生成するための BigQuery の直接的なアプローチほど効率的ではない可能性があります。
参考リンク -https://cloud.google.com/logging/docs/export/bigquery
</div></details>

### Q. 36
現在、単一のアジア地域内の顧客のみに対応しているスタートアップのWebアプリケーションが、最初はコストの最適化を優先し、後にネイティブJDBCドライバーを使用する要件でグローバルなプレゼンスとパフォーマンスの向上に焦点を当てながら、グローバルな顧客サービスを可能にするための資金を求める場合、どのような手順を踏む必要がありますか?
1. 最初に Cloud Spanner を使用して単一リージョンのインスタンスを構成し、資金を確保した後に複数リージョンの Cloud Spanner インスタンスを構成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
Cloud Spanner のスケーラビリティ: Cloud Spanner は、グローバルに分散された水平方向にスケーラブルなデータベースであり、複数のリージョン間で強力な一貫性を提供できます。単一リージョンのインスタンスから開始し、マルチリージョンのインスタンスを構成することは、資金を確保した後、グローバルなプレゼンスとパフォーマンスを最適化するという目標と一致します。
強力な整合性: Cloud Spanner は、強力な整合性が保証されていることで知られており、データの一貫性が重要なグローバル アプリケーションに適しています。
ネイティブ JDBC サポート: Cloud Spanner はネイティブ JDBC ドライバをサポートし、ウェブアプリケーションの要件との互換性を確保します。
正しくないオプション -
B. 最初に Cloud SQL for PostgreSQL の高可用性インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアのレプリケーションで Bigtable を使用します。
このオプションでは、可用性の高い Cloud SQL for PostgreSQL インスタンスから始めることをお勧めしますが、これは当初必要以上にコストが高くなる可能性があります。Bigtable はグローバル レプリケーションを提供できますが、Cloud SQL を最初に選択した時点では、資金調達前の費用最適化という目標に合致していない可能性があります。
C. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアで Bigtable を使用します。
オプション B と同様に、当初の費用最適化を主な目標としている場合、Cloud SQL for PostgreSQL から始めるのは最も費用対効果の高い選択肢ではない可能性があります。また、Cloud SQL のグローバル拡張機能は、Cloud Spanner に比べて制限されています。
D. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、可用性の高い構成の Cloud SQL for PostgreSQL を使用します。
このオプションでは、Bigtable や Cloud Spanner などのグローバルに分散されたデータベースを使用しないため、グローバルなプレゼンスとパフォーマンスを最適化するという資金調達後の目標に合わない可能性があります。
要約すると、オプション B、C、D にはそれぞれメリットがありますが、オプション A は、Cloud Spanner のグローバルなスケーラビリティと強力な整合性機能を活用して、初期費用の最適化目標と資金調達後のグローバル展開とパフォーマンスの最適化の両方の目標と一致するため、シナリオに最適な選択肢です。
参照リンク - リージョン構成とマルチリージョン構成 - Cloud Spanner
</div></details>

### Q. 37
大規模なデータ転送に関する Google が推奨するベスト プラクティスを遵守しながら、わずか数時間でデータ転送を完了することを目標に、オンプレミスのデータセンターから Google Cloud に 1 PB のデータを安全かつ効率的に移行するには、どのような手順を踏む必要がありますか?
1. 
2. Transfer Appliance を使用し、エンジニアに手動でデータの暗号化、復号化、検証を依頼します。
3. 
4. 
<details><div>
    答え：2
説明
Google が推奨するプラクティスに従いながら、安全な接続を介してオンプレミスのデータセンターから Google Cloud に 1 PB のデータを効率的に移行するには、次のアプローチを検討する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
Transfer Appliance: Google の Transfer Appliance は、大量のデータを安全かつ効率的に移行できるように設計されています。これは、データをオフラインで読み込み、Google Cloud Storage に取り込むために Google に送付するために使用できる物理ストレージ アプライアンスです。
手動暗号化: Transfer Applianceの使用中に、アプライアンスにロードする前にデータを手動で暗号化できます。これにより、転送中のデータセキュリティが確保されます。
手動検証:データ転送が完了した後、エンジニアはデータを復号化して元のデータセットと比較することで、データの整合性を手動で検証できます。この検証プロセスにより、データが正確に転送されたことが保証されます。
正しくないオプション -
オプションA(Cloud Interconnect and Storage Transfer Service)は、わずか数時間で1 PBのデータを移行するために必要な速度を提供しない可能性があるため、このような大量のデータ転送には適していない可能性があります。
オプション C(Cloud VPN、並列 gcloud compute scp ジョブ、チェックサム)は、このような大量のデータを迅速かつ安全に転送するための最も効率的な方法ではない可能性があります。
オプション D(データを 3 TB のバッチに削減し、gsutil を使用し、チェックサムを実行する)は、小規模なデータセットでは実現可能ですが、大量のデータが含まれるため、わずか数時間で 1 PB の移行を行うのは現実的ではない可能性があります。
速度、セキュリティ、Google のベスト プラクティスの遵守を目標とする 1 PB のデータ移行では、手動で暗号化と検証を行う Transfer Appliance の使用をおすすめします。この方法は、大規模なデータセットを Google Cloud に転送するための安全で効率的な方法を提供します。
参考リンク -
https://cloud.google.com/products/data-transfer/
</div></details>

### Q. 38
CSV ファイルを Cloud Storage から BigQuery に読み込む際に、1 つの列に STRING や INT64 などのデータ型が混在していたり、電話番号や住所などの値の形式に一貫性がなかったりするなど、ファイルの既知のデータ品質の問題を考慮して、データ品質を維持し、必要なクレンジングと変換を実行するためのデータ パイプラインをどのように確立すればよいのでしょうか。
1. BigQuery に読み込む前に、Data Fusion を使用してデータを変換します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
変換のための Data Fusion: Google Cloud Data Fusion は、ETL(抽出、変換、読み込み)プロセスのための強力なツールです。データ品質の問題に対処するために不可欠な、データ変換、クレンジング、エンリッチメントの機能を提供します。
高度な変換: Data Fusion では、ビジュアル インターフェースやカスタム コードを使用して複雑なデータ変換を実行できるため、データ型の不一致や一貫性のない書式設定などの問題を処理するのに適しています。
BigQuery との統合: Data Fusion は BigQuery とシームレスに統合できるため、変換されたデータを BigQuery テーブルに直接読み込むことができるため、データ パイプラインが簡素化されます。
オプション A は、BigQuery に読み込む前に Google Cloud Data Fusion を使用してデータ変換を行うもので、データ品質の問題に対処し、高度な変換機能を提供する包括的なアプローチです。これは、シナリオで説明されているように、複雑なデータ クレンジングと変換タスクを処理する場合に推奨される選択肢です。
正しくないオプション -
B. データを BigQuery に読み込む前に、Data Fusion を使用して CSV ファイルを AVRO などの自己記述型データ形式に変換します。
データ形式の変換は特定のシナリオでは役立ちますが、データ型の不一致や一貫性のない書式設定など、質問に記載されているデータ品質の問題に直接対処するものではありません。
C. 目的のスキーマを使用してステージング テーブルに CSV ファイルを読み込み、SQL で変換を実行してから、結果を最終的な変換先テーブルに書き込みます。
変換に SQL を使用することは有効なアプローチですが、データ品質の問題は SQL のみを使用して効果的に処理できることを前提としていますが、複雑な問題には当てはまらない場合があります。
D. 目的のスキーマでテーブルを作成し、CSV ファイルをテーブルにロードし、SQL を使用してその場で変換を実行します。
このオプションでは、最終的な変換先テーブルにデータを直接読み込む必要がありますが、データ品質の問題に事前に対処しないと危険です。一般に、データの検証と変換にはステージング テーブルを使用する方が安全です。
参照リンク: Data Fusion の概要
</div></details>

### Q. 39
e コマース プラットフォームでの顧客の購入確率を予測することを目的とした新しいディープ ラーニング モデルの開発に取り組んでいる間、初期トレーニング データセットと新しいテスト データセットの両方を使用して、モデルのパフォーマンスの評価を実施しました。この評価の結果、モデルが提供されたデータに対して過学習の傾向を示していることが明らかになりました。目的は、新しいデータの結果を予測する際に、モデルの精度を高めることです。この目標を達成するには、どのような手順を踏む必要がありますか?
1. 
2. トレーニング データセットのサイズを大きくし、入力特徴の数を減らします。
3. 
4. 
<details><div>
    答え：2
説明
新しいデータを予測する際の過学習に対処し、深層学習モデルの精度を向上させるには、次のことを行う必要があります。
B. 
このオプションが適切な理由は次のとおりです。
トレーニング データを増やす: トレーニング データセットのサイズを大きくすると、モデルの一般化が向上し、過学習を減らすことができます。データが多いほど、基になるパターンがより広く表現され、新しいデータでのモデルのパフォーマンスが向上する可能性があります。
入力特徴量を減らす: 入力特徴量が多すぎる過度に複雑なモデルは、トレーニング データ内のノイズをキャプチャできるため、過学習する傾向があります。入力特徴の数を減らすことで、モデルを単純化し、最も関連性の高い情報に焦点を合わせることができるため、汎化を改善できます。
過学習を軽減する最も効果的な方法は、トレーニング データセットのサイズを大きくすると同時に、入力フィーチャの数を減らしてモデルを単純化することです。この組み合わせにより、モデルの汎化が向上し、新しいデータの精度が向上します。
正しくないオプション -
オプション A、C、および D は、推奨されるアプローチではありません。
オプション A (データセットのサイズを増やし、入力特徴量を増やす): データセットのサイズと入力特徴の数の両方を増やすと、過学習がさらに悪化する可能性があります。モデルがすでに複雑すぎる場合は、データが多いだけでは役に立たない可能性があります。
オプション C (データセットのサイズを小さくし、入力フィーチャを増やす): データセットのサイズを小さくすると、モデルの一般化がさらに困難になる可能性があります。入力特徴量を増やしてデータを減らすと、モデルがさらにオーバーフィットになる可能性があります。
オプション D (データセットのサイズを小さくし、入力特徴量を減らす): データセットのサイズと入力特徴の数の両方を減らしても、モデルが意味のあるパターンを学習するための十分な情報が得られない可能性があります。
</div></details>

### Q. 40
オンライン小売業者の顧客サービスを強化するためのチャットボットを効果的に作成し、テキストと音声の両方のクエリを処理できると同時に、ローコードまたはノーコードのソリューションを模索し、キーワードベースの応答のための簡単なトレーニングを確保するにはどうすればよいでしょうか?
1. 
2. 
3. 
4. Dialogflow を使用してチャットボットを実装し、収集された最も一般的なクエリに基づいてインテントを定義します。
<details><div>
    答え：4
説明
D. 
Dialogflow は、モバイルアプリ、ウェブ アプリケーション、デバイス、ボット、自動音声応答システムなどに会話型ユーザー インターフェースを簡単に設計して統合できる自然言語理解プラットフォームです。Dialogflow を使用すると、ユーザーがプロダクトと対話するための新しい魅力的な方法を提供できます。Dialogflow では、テキスト入力や音声入力(電話や音声録音など)など、顧客からの複数のタイプの入力を分析できます。また、テキストまたは合成音声のいずれかで、いくつかの方法で顧客に応答することもできます。
参考リンク -
https://cloud.google.com/dialogflow/docs
</div></details>

### Q. 41
航空宇宙企業独自の形式から BigQuery にフライトデータを最も効果的にインポートし、リソース消費を最小限に抑えながら、この新しいデータソース間の接続を確立し、BigQuery へのデータ ストリーミングを容易にするにはどうすればよいでしょうか。
1. 
2. 
3. 
4. Apache Beam カスタム コネクタを使用して、データを Avro 形式で BigQuery にストリーミングする Dataflow パイプラインを作成します。
<details><div>
    答え：4
説明
オプション D. 
このシナリオでは、特定の形式の独自のフライト データがあり、最小限のリソース消費で効率的に BigQuery にインポートする必要があります。
Apache Beam カスタム コネクタと Dataflow を併用して Avro 形式で BigQuery にデータをストリーミングすることは、いくつかの理由から最適な選択肢です。
Apache Beam は、複雑なデータ インジェストと変換タスクを処理できる強力で柔軟なデータ処理フレームワークです。
Avro はコンパクトで効率的なデータシリアル化形式であり、大量のデータのストリーミングと保存に適しています。
カスタム コネクタを使用すると、データ インジェスト プロセスを独自のデータ形式に合わせて調整し、スムーズで効率的なデータ転送を確保できます。
Dataflow は、データ量に合わせて自動的にスケーリングできるマネージド サービスであり、リソースを手動で管理してプロビジョニングする必要性を減らします。
正しくないオプション -
A. 定期的な ETL バッチ ジョブの Cloud Functions の関数をトリガーするシェル スクリプトを記述する:
このオプションは、定期的なバッチジョブの実行を示唆していますが、リアルタイムのデータストリーミングには適していない可能性があります。
また、データのストリーミングに効率的である可能性のある Avro 形式の使用についても言及していません。
B. 標準の Dataflow パイプラインを使用して BigQuery に生データを保存し、後で形式を変換する:
このアプローチでは、データが未加工の形式で BigQuery に保存されますが、これは BigQuery の機能を利用する最も効率的な方法ではない可能性があります。
これには、既に保存されているデータを変換する追加の手順が含まれますが、これは、目的の形式でデータをストリーミングするほどリソース効率が良くない可能性があります。
C. Apache Hive を使用して、データを CSV 形式で BigQuery にストリーミングする Dataproc ジョブを作成します。
Apache Hive はバッチ処理には適したツールですが、リアルタイムのデータ ストリーミングには適していない可能性があります。
CSV 形式は Avro ほどストリーミングに効率的ではなく、より多くのリソースを消費する可能性があります。
オプション D は、Apache Beam とカスタム コネクタを活用して Avro 形式で BigQuery にデータをストリーミングし、リソース消費を最小限に抑えながら効率的かつリアルタイムのデータ取り込みを実現するため、最も適切な選択肢です。
参照リンク - Apache Beam のプログラミング モデル
</div></details>

### Q. 42
オンライン証券会社には、大量の取引処理アーキテクチャが必要です。ジョブをトリガーするセキュア・キューイング・システムを作成する必要があります。ジョブはGoogle Cloudで実行され、同社のPython APIを呼び出して取引を実行します。ソリューションを効率的に実装する必要があります。あなたは何をするべきか?
1. Pub/Sub プッシュ サブスクリプションを使用して Cloud Functions の関数をトリガーし、Python API にデータを渡します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Google Cloud で実行されるジョブをトリガーし、会社の Python API を呼び出して取引を実行する安全なキューイング システムを作成するための最も効率的で適切なオプションは次のとおりです。
オプション A: 
Google Cloud Pub/Sub は、独立したアプリケーション間でリアルタイムかつ信頼性の高いメッセージングを実現するために設計されたメッセージング サービスです。
このシナリオでは、取引リクエストが発行される Pub/Sub トピックを設定できます。
Pub/Sub トピックへのプッシュ サブスクリプションを作成すると、メッセージがトピックにパブリッシュされたときに Cloud Functions の関数が呼び出されます。
その後、Cloud Functions の関数は取引データを Python API に渡して実行できます。
このアーキテクチャは効率的でスケーラブルであり、大量の取引処理に適しています。
正しくないオプション -
オプション B では、Compute Engine インスタンスでホストされるアプリケーションを作成して、Pub/Sub トピックへのプッシュ サブスクリプションを作成することを提案しています。これは機能しますが、Compute Engine インスタンスの管理とスケーリングが必要であり、Cloud Functions を使用する場合ほど効率的ではなく、サーバーレスでもない可能性があります。
オプションCは、NoSQLデータベースでのキューの作成について言及しています。NoSQL データベースはキューイングなど多くの目的に使用できますが、Google Cloud Pub/Sub などの専用のキューイング システムを設定する方が効率的で、この種のタスクに特化して構築されています。
オプション D では、Google Cloud のマネージド ワークフロー オーケストレーション サービスである Cloud Composer の使用について言及しています。Cloud Composer はさまざまなタスクに使用できますが、この特定のユースケースで Pub/Sub で Cloud Functions を直接使用する場合と比較して、単純なメッセージ キューイングと Python API 呼び出しの実行用に Cloud Composer を設定すると、不必要に複雑になる可能性があります。
参考リンク -
https://cloud.google.com/run/docs/triggering/pubsub-push
</div></details>

### Q. 43
あなたの会社は、データベースに 10 TB を超える現在のシステムから医療情報の大きな結果セットを取得し、さらにクエリを実行するためにデータを新しいテーブルに格納できるようにしたいと考えています。データベースは、メンテナンスの少ないアーキテクチャを持ち、SQL経由でアクセスできる必要があります。大規模な結果セットのデータ分析をサポートできるコスト効率の高いソリューションを実装する必要があります。あなたは何をするべきか?
1. 
2. BigQuery をデータ ウェアハウスとして使用する。大きなクエリをキャッシュするための出力先を設定します。
3. 
4. 
<details><div>
    答え：2
説明
大規模な結果セットのデータ分析をサポートしながら、メンテナンスが少なく、SQLへのアクセス性も備えている、最も費用対効果の高いソリューションは次のとおりです。
オプション B: 
説明：
Google BigQuery は、大規模なデータセットや複雑なクエリを処理するために設計された、サーバーレスで拡張性が高く、費用対効果の高いデータ ウェアハウス ソリューションです。
BigQuery は SQL に似たクエリ機能を備えており、SQL 経由でアクセスできます。
ストレージ、インデックス作成、クエリ パフォーマンスの最適化など、データの管理を自動的に処理します。
BigQuery ではクエリ結果をキャッシュできるため、大きな結果セットを複数回取得する際のパフォーマンスが大幅に向上し、クエリ費用を削減できます。
これは完全に管理されたサービスであり、手動のメンテナンスとスケーリングの必要性を排除します。
正しくないオプション -
オプション A(Cloud SQL を使用)とオプション C(Compute Engine で MySQL クラスタを使用)は、手動管理が必要で、BigQuery ほどシームレスにスケーリングできず、データ量が多い場合はコストがかかる可能性があるため、非常に大規模なデータセットや複雑な分析を処理するには最適な選択肢ではない可能性があります。
オプション D(Cloud Spanner を使用)は、グローバルに分散された可用性の高いデータベース サービスですが、大規模な結果セットの分析ではなく、トランザクション データ向けに設計されています。このユースケースでは、最も費用対効果の高いオプションではない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/cached-results
</div></details>

### Q. 44
オンプレミスのデータセンターに 15 TB のデータがあり、Google Cloud に転送したいとします。データは毎週変更され、POSIX 準拠のソースに保存されます。ネットワーク運用チームは、パブリック インターネットに 500 Mbps の帯域幅を付与しました。Google が推奨する方法に従って、週単位で Google Cloud にデータを確実に転送したい。あなたは何をするべきか?
1. 
2. 
3. データ センターにオンプレミス データ用の Storage Transfer Service をインストールし、毎週の転送ジョブを構成します。
4. 
<details><div>
    答え：3
説明
パブリック インターネットへの帯域幅が 500 Mbps の場合、オンプレミスのデータセンターから Google Cloud に 15 TB のデータを毎週確実に転送するには、Google が推奨するデータ転送方法の使用を検討する必要があります。このシナリオでは、
オプション C: 
このオプションが適している理由は次のとおりです。
Storage Transfer Service は、Google Cloud が提供するマネージド サービスで、オンプレミスのデータソースまたは別のクラウド プロバイダから Google Cloud Storage にデータを転送するのに役立ちます。これは、大規模で定期的な転送を効率的に処理するように設計されています。
データセンターに Storage Transfer Service をインストールすると、スケジュールされた自動転送ジョブを設定して、定期的に(毎週など)Google Cloud にデータを移動できます。
Storage Transfer Service は、並列処理、再開可能な転送、および効率的で信頼性の高いデータ転送を保証するその他の機能を処理して、転送プロセスを最適化できます。
正しくないオプション -
オプション A(Cloud Scheduler を使用して gsutil をトリガーする)は機能しますが、gsutil コマンドとそのスケジュールを管理する必要があります。Storage Transfer Service と同じレベルの自動化と組み込みのデータ転送の最適化は提供されません。
オプション B (Transfer Appliance を使用) は、非常に大規模なデータセットや、ネットワーク帯域幅が制限要因となる状況に適しています。ただし、データが 15 TB で帯域幅が 500 Mbps のこのシナリオでは、必要以上に複雑でコストがかかる可能性があります。
オプション D(Google Cloud 仮想マシンへの Storage Transfer Service のインストール)は、標準または推奨されるアプローチではありません。Storage Transfer Service は、データ転送の目的でオンプレミスで実行するように設計されており、仮想マシンにインストールすると、不必要な複雑さが加わります。
参考リンク -
https://cloud.google.com/storage-transfer/docs/overview
</div></details>

### Q. 45
ACID準拠のデータベースを必要とするシステムを設計しています。障害が発生した場合に、システムが必要とする人間の介入が最小限であることを確認する必要があります。あなたは何をするべきか?
1. 
2. 高可用性を有効にして Cloud SQL for PostgreSQL インスタンスを構成するを選択する必要があります。
3. 
4. 
<details><div>
    答え：2
説明
障害発生時に人的介入を最小限に抑えた ACID 準拠のデータベースを必要とするシステムを設計するには、オプション B: 
Cloud SQL for PostgreSQL は、フルマネージドで可用性が高く、ACID 準拠のリレーショナル データベース サービスを提供します。これは、信頼性とデータの整合性で知られるPostgreSQLに基づいています。
Cloud SQL インスタンスの高可用性を有効にすると、同じリージョン内の別のゾーンにスタンバイ レプリカが作成されます。プライマリ・インスタンスに障害が発生すると、スタンバイへの自動フェイルオーバーが発生し、ダウンタイムが最小限に抑えられ、データの整合性が確保されます。
PostgreSQLは一般に、ACID(原子性、一貫性、分離性、耐久性)トランザクションを強力にサポートしているため、データの整合性と信頼性を必要とするアプリケーションに適しています。
誤ったオプション-
オプション A(ポイントインタイム リカバリを使用した Cloud SQL for MySQL)は適切な選択肢ですが、ACID トランザクションをより強力にサポートする PostgreSQL が好まれることがよくあります。
オプション C(複数のクラスタを持つ Bigtable)は、ACID 準拠のリレーショナル データベース機能を提供するようには設計されていません。Bigtable は、さまざまなタイプのワークロードに使用される NoSQL データベースです。
オプション D(マルチリージョン構成の BigQuery)は、このシナリオには適用されません。BigQuery はデータ ウェアハウスおよび分析サービスであり、トランザクション リレーショナル データベースではありません。
参考リンク -
https://cloud.google.com/sql/docs/postgres
</div></details>

### Q. 46
あなたは、小売企業のeコマースWebサイトのデータストレージソリューションの設計を担当しています。同社は毎日膨大な量の取引データを生成しています。高可用性とスケーラビリティを確保しながら、待機時間を最小限に抑えたい。どのGCPサービスまたはデータベースを選択しますか?
1. 
2. 
3. 
4. Cloud Spanner
<details><div>
    答え：4
説明
小売企業のeコマースWebサイト向けのデータストレージソリューションを設計し、高可用性、スケーラビリティ、低遅延に重点を置いたデータストレージソリューションを設計し、毎日膨大な量のトランザクションデータを処理する場合、最適なGCPサービスは次のとおりです。
D. 
高可用性: Cloud Spanner は高可用性を実現するように設計されています。グローバルな分散アーキテクチャにより、複数のリージョン間でデータを複製できるため、リージョンの障害が発生した場合でもデータの可用性を維持できます。
スケーラビリティ: Cloud Spanner は水平方向にスケーラブルなデータベースであり、ビジネスの成長に合わせて増加するワークロードを自動的に処理できます。自動シャーディングと負荷分散を提供するため、大規模なアプリケーションに適しています。
低レイテンシ: Cloud Spanner は、リアルタイムのインタラクションと応答性を必要とする e コマース アプリケーションに不可欠な、データへの低レイテンシの読み取りおよび書き込みアクセスを提供します。
正しくないオプション -
A. Bigtable: Bigtable は拡張性の高い NoSQL データベースですが、e コマース Web サイトのようなトランザクション データには最適ではない可能性があります。これは通常、大規模なデータセットに対して高スループット、低遅延の読み取りと書き込みを必要とするアプリケーションに使用されますが、複雑なトランザクション クエリには最適化されない場合があります。
B. Firestore: Firestore は、モバイル アプリケーションやウェブ アプリケーションに適した NoSQL ドキュメント データベースです。特定のユースケースではうまく機能しますが、eコマースのトランザクションデータに必要なレベルのトランザクションの一貫性が得られない場合があります。
C. Cloud SQL: Cloud SQL はマネージド リレーショナル データベース サービスです。トランザクションの一貫性を提供できますが、特に大量のデータを処理する場合は、非常に高いスケーラビリティと低遅延の要件には最適ではない可能性があります。
</div></details>

### Q. 47
メディアストリーミングプラットフォームは、動画の視聴回数やクリック率などのユーザーインタラクションデータを保存して分析する必要があります。そのためには、高い読み取りと書き込みのスループットを低レイテンシーで処理できるデータベースが必要です。このシナリオに最も適した GCP サービスはどれですか?
1. 
2. 
3. Bigtable
4. 
<details><div>
    答え：3
説明
このシナリオの正しいオプションは C.  です。
Bigtable は、低レイテンシの読み取りおよび書き込み操作で大量のデータを処理できるように設計された、非常にスケーラブルで高性能な NoSQL データベースです。これは、ビデオの視聴回数やクリックスルー率などのユーザー操作データを保存および分析するためにメディア ストリーミング プラットフォームが必要とする、高い読み取りおよび書き込みスループットを低遅延で処理する必要があるシナリオに適しています。
正しくないオプション -
A. BigQuery: BigQuery は、大規模なデータセットに対して SQL のようなクエリを実行するために最適化されたデータ ウェアハウスおよび分析プラットフォームです。Bigtable と比較してクエリのレイテンシが長くなる可能性があるため、リアルタイム、高スループット、低レイテンシのデータ ストレージと取得には最適ではありません。
B. クラウドストレージ:クラウドストレージは、主にファイルやオブジェクトなどの非構造化データを保存するために設計されたオブジェクトストレージサービスです。ユーザー操作のデータ分析に必要な、リアルタイムで低遅延のデータアクセスとクエリ機能は提供されません。
D. Firestore: Firestore は、ドキュメント指向のデータ用に設計された NoSQL データベースであり、モバイル アプリケーションやウェブ アプリケーションによく使用されます。リアルタイム データを処理できますが、メディア ストリーミング プラットフォームの高スループット、低レイテンシの要件に対しては、Bigtable ほどパフォーマンスが高くない可能性があります。また、Firestore にはドキュメントとコレクションの制限があり、非常に高速なデータのスケーラビリティに影響を与える可能性があります。
</div></details>

### Q. 48
組織は、モバイル アプリから収集されたユーザーの行動データに基づいてレコメンデーション システムを構築したいと考えています。複雑なクエリを効率的に処理し、リアルタイム分析機能を提供できるデータベースが必要です。どのGCPサービスを検討すべきですか?
1. 
2. BigQuery
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は B.  です。
ここで説明するシナリオでは、モバイルアプリから収集したユーザー行動データに基づいてレコメンデーションシステムを構築する必要があります。
複雑なクエリ: レコメンデーション システムの構築には、多くの場合、ユーザーの行動を分析し、パーソナライズされたレコメンデーションを生成するための複雑なクエリが含まれます。BigQuery は、大規模なデータセットに対して複雑な SQL クエリを実行するために最適化された、フルマネージドのサーバーレス データ ウェアハウスです。分析ワークロードの処理に優れているため、このシナリオには有力な選択肢となります。
効率性: BigQuery はクエリを効率的に実行するように設計されているため、リアルタイム分析タスクに適しています。大量のデータを処理でき、クエリの応答時間が短くなります。
正しくないオプション -
A. Cloud Bigtable: Bigtable は、高スループットで低レイテンシのデータ アクセス用に最適化された NoSQL データベースです。時系列データやキー値ストレージなどの特定のユースケースには優れていますが、複雑な分析クエリやリアルタイム分析には適していません。
C. Cloud Datastore: Cloud Datastore は、ウェブ アプリケーションやモバイル アプリケーションの構造化データの保存と取得に適した NoSQL データベースです。ただし、複雑なレコメンデーションシステムやリアルタイム分析に必要なパフォーマンスとクエリ機能が提供されない場合があります。
D. Cloud SQL: Cloud SQL はマネージド リレーショナル データベース サービスです。トランザクション ワークロードや構造化データには適していますが、BigQuery の方が適している複雑な分析クエリやリアルタイム分析には適していない可能性があります。
複雑なクエリを効率的に処理し、リアルタイム分析機能を提供する必要があるレコメンデーション システムの場合、分析ワークロードと大規模なデータセットの処理に強みを持つ BigQuery は、GCP サービスとして最適です。
</div></details>

### Q. 49
ある製造会社は、生産設備からのセンサーデータをリアルタイムで監視および分析しようとしています。高速データストリームを取り込んで処理できるデータベースが必要です。どのGCPサービスが最適ですか?
1. Cloud Pub/Sub
2. 
3. 
4. 
<details><div>
    答え：1
説明
このシナリオの正しいオプションは次のとおりです。 A. 
生産設備からのセンサーデータをリアルタイムでモニタリングして分析したいと考えている製造会社にとって、Cloud Pub/Sub は次のような理由から最適な選択肢です。
高速データ ストリームの取り込みと処理: Cloud Pub/Sub は、リアルタイムの高速データ ストリームの取り込みと処理を目的として設計されています。センサーやデバイスからの大量のデータを効率的に処理できます。
リアルタイム データ: Cloud Pub/Sub では、生産設備からのデータをモニタリングして対応するために不可欠なリアルタイムのデータ ストリーミングが可能です。
スケーラビリティ: 多くの構成を行うことなく、データ負荷の増加を処理するように拡張できるため、データ量が時間の経過とともに変化する可能性がある状況に適しています。
正しくないオプション -
B. BigQuery:
BigQuery は、リアルタイムのデータ取り込みや処理よりも、分析クエリやデータのバッチ処理に適しています。
高速データストリームの処理には最適化されておらず、リアルタイム監視に使用すると、複雑さと遅延が増します。
C. クラウドデータストア:
Cloud Datastore は、構造化データの保存と取得に適した NoSQL データベースですが、高速でのリアルタイムのデータ取り込みと処理に特化して設計されているわけではありません。
D. Cloud SQL:
Cloud SQL はマネージド リレーショナル データベース サービスであり、リアルタイムのデータ ストリーミングや高速データ処理には適していません。これは通常、構造化されたトランザクションデータに使用されます。
Cloud Pub/Sub は、リアルタイムのデータ ストリームを処理するために構築されており、製造環境のセンサーからデータを効率的に取り込んで処理できるため、このシナリオに最適です。
</div></details>

### Q. 50
あなたは、車両のリアルタイムの位置データを保存および取得する必要がある物流会社のデータストレージソリューションを設計しています。このユースケースに最適なGCPサービスはどれですか?
1. 
2. Bigtable
3. 
4. 
<details><div>
    答え：2
説明
このシナリオの正しいオプションは B.  です。
Bigtable は、高スループットで低レイテンシのデータ アクセスを実現するように設計された、フルマネージドの NoSQL データベース サービスです。大量のデータを処理でき、車両のリアルタイム位置データの保存に適しているため、このユースケースに最適です。車両の位置を効率的に追跡するために必要なスケーラビリティ、パフォーマンス、およびリアルタイムのデータアクセスを提供します。
正しくないオプション -
A. Cloud SQL: Cloud SQL はフルマネージドのリレーショナル データベース サービスであり、複数の車両のリアルタイムの位置データの保存と取得には適していません。構造化データに適しており、車両のリアルタイム追跡に必要なスケーラビリティとパフォーマンスは提供されません。
C. Firestore: Firestore は、柔軟でスケーラブルなリアルタイムのデータ ストレージ用に設計された NoSQL ドキュメント データベースです。リアルタイム データを処理できますが、車両の大量の位置データを保存するのには適していない場合があります。Firestore は、モバイルアプリやウェブアプリなど、ドキュメント形式のデータ ストレージを必要とするアプリケーションでより一般的に使用されます。
D. Cloud Pub/Sub: Cloud Pub/Sub は、独立したアプリケーション間でメッセージを送受信できるメッセージング サービスです。これはデータベースではなく、データを保存しません。これは、コンポーネント間のリアルタイムのイベントストリーミングとメッセージングに使用できますが、データストレージを目的としたものではありません。
スタート
演習テスト1: Google Cloud Professional Data Engineer - Practice Test #1
スタート
演習テスト2: Google Cloud Professional Data Engineer - Practice Test #2
スタート
演習テスト3: Google Cloud Professional Data Engineer - Practice Test #3
スタート
演習テスト4: Google Cloud Professional Data Engineer - Practice Test #4
法人向けサービスのお問い合わせ
Udemyで教える
出資
規約
ヘルプとサポート
サイトマップ
アクセシビリティに関する声明
特定商取引に関する表記
</div></details>

## 2
### Q. 質問1: 未回答
株式取引記録の保存を担当するデータベースと、カスタマイズ可能な期間内に指定された会社の平均株価を計算するために使用される関連アプリケーションを管理します。これらのレコードは Cloud Bigtable に保存され、取引日時が行キーの最初の部分として機能します。追加されるストックの数が増えるにつれて、数千人の同時ユーザーが発生するアプリケーションのパフォーマンスが低下する兆候が見られます。アプリケーションのパフォーマンスを向上させるには、どのようなアクションを実行する必要がありますか?
1. Cloud Bigtable テーブルの行キー構文を、株式記号で始まるように変更します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Cloud Bigtable から調整可能な期間の平均株価を取得する際のアプリケーションのパフォーマンスを向上させるには、次の点を考慮する必要があります。
A. 
銘柄記号から始まるように行キーの構文を変更することは、特定の銘柄コードの株式データを取得する際のクエリのパフォーマンスを向上させるための適切なアプローチです。
特定の企業の平均株価を照会する場合、それに応じて行キーを構成することで、その特定の銘柄に関連するデータに効率的にアクセスできます。
このアプローチにより、特定の会社の株式データを取得するときにスキャンする必要があるデータの量を減らすことができ、クエリのパフォーマンスが向上します。
正しくないオプション -
B. Cloud Bigtable テーブルの行キー構文を、乱数/秒で始まるように変更します。
このオプションは、特定の企業の平均株価を経時的に取得するユースケースには適していません。乱数を行キーとして使用すると、非効率的で予測不可能なクエリ パターンが発生し、必要なデータへのアクセスが困難になる可能性があります。
C. 株式取引の保存に BigQuery を使用するようにデータ パイプラインを変更し、アプリケーションを更新します。
BigQuery は分析ワークロードには適していますが、特に同時実行性の高いシナリオを扱う場合は、リアルタイムのトランザクション データの保存と取得には適していない可能性があります。
BigQuery に移行するには、データ パイプラインとアプリケーションの両方に大幅な変更が必要になり、複雑で時間がかかる可能性があります。
D. Cloud Dataflow を使用して、各日の株式取引の概要を Cloud Storage の Avro ファイルに書き込みます。Cloud Storage と Cloud Bigtable から読み取ってレスポンスを計算するようにアプリケーションを更新します。
このオプションでは、Cloud Dataflow と Cloud Storage の複雑さが増すため、ユースケースでは必要ない場合があります。
また、Cloud Storage に概要を書き込んでから読み取って計算する必要があるため、平均株価の計算プロセスにレイテンシが加わります。
</div></details>

### Q. 質問2: 未回答
指定した期間内に Cloud Pub/Sub サブスクリプション ソースからのイベントを集計し、その結果の集計を Cloud Storage バケットに保存する Cloud Dataflow ストリーミング パイプラインを管理しています。ソースは、データのスループットを一定に保ちます。パイプラインのデータ処理アクティビティを継続的に監視し、問題があれば警告するには、どのような種類の Stackdriver アラートを作成する必要がありますか?
1. 
2. ソースのサブスクリプション/num_undelivered_messagesの増加と、宛先のインスタンス/ストレージ/used_bytesの変更率の減少に基づくアラート。
3. 
4. 
<details><div>
    答え：2
説明
Cloud Dataflow ストリーミング パイプラインの動作をモニタリングするための Stackdriver アラートを作成するには、ソース(Cloud Pub/Sub サブスクリプション)とデスティネーション(Cloud Storage バケット)の両方の健全性とパフォーマンスを反映する指標に重点を置く必要があります。目標は、パイプラインがデータを正しく処理していることを確認することです。これに基づいて、最も適切なアラート構成は次のとおりです。
B.
この選択の根拠は次のとおりです。
ソースのアラート (Cloud Pub/Sub サブスクリプション):
ソースのサブスクリプション/num_undelivered_messagesを監視することは不可欠です。未配信のメッセージの増加は、データの取り込みまたは処理に問題があることを示している可能性があります。
宛先(Cloud Storage バケット)のアラート:
デスティネーション(Cloud Storage バケット)のインスタンス / ストレージ / used_bytes をモニタリングすることで、データが正しく書き込まれていることが確認されます。使用バイト数の減少は、パイプラインが期待どおりに宛先にデータを書き込んでいないことを示している可能性があります。
正しくないオプション -
オプションA:ソースのサブスクリプション/num_undelivered_messagesの減少は、必ずしも問題を示しているわけではありません。これは、メッセージが処理されるにつれて正常に減少する可能性があります。宛先のインスタンス/ストレージ/used_bytesの変更率の増加を監視するだけでは、パイプラインの動作に関する分析情報が得られない場合があります。
オプションC:ソースのインスタンス/ストレージ/used_bytesの削減は、パイプラインの動作とは直接関係ありません。宛先のサブスクリプション/num_undelivered_messagesの変更率の増加を監視することは、パイプラインの問題を検出するのにそれほど意味がない場合があります。
オプションD:ソースのインスタンス/ストレージ/used_bytesを増やしても、必ずしも問題を示しているとは限りません。これは、データの取り込みによる通常の増加である可能性があります。宛先のサブスクリプション/num_undelivered_messagesの変更率の低下を監視しても、パイプラインの正常性に関する必要な分析情報が得られない場合があります。
</div></details>

### Q. 質問3: 未回答
現在、米国東部のデータセンター内で単一のオンプレミス Kafka クラスターを管理し、グローバルな IoT デバイス メッセージの取り込みを処理しています。多くのリージョンでインターネットアクセスが不十分なため、メッセージがエッジに蓄積され、同時にKafkaクラスターに急増することがあり、その結果、負荷が上昇し、コストが過剰になります。
この状況でGoogleが推奨するクラウドネイティブアーキテクチャは何ですか?
1. 
2. 
3. Cloud Pub/Sub からメッセージを読み取って処理するための Cloud Dataflow を備えた IoT ゲートウェイ。
4. 
<details><div>
    答え：3
説明
メッセージをバッチで送信する IoT デバイスがグローバルにあり、このデータ フローをより効率的かつ費用対効果の高い方法で管理したいシナリオでは、通常、Google が推奨するクラウドネイティブ アーキテクチャでは、スケーラビリティと信頼性のためにマネージド サービスを活用します。この場合、最も適切なオプションは次のとおりです。
C. 
このオプションが推奨される理由は次のとおりです。
IoT ゲートウェイ:IoT ゲートウェイは、エッジの IoT デバイスとクラウドの間の仲介役として機能するデバイスまたはソフトウェアです。特にインターネット接続が不十分なエリアでデバイスを扱う場合に、データをより効率的にバッファリング、集約、および送信できます。ゲートウェイは、メッセージをローカルでバッチ処理し、接続が使用可能になったときにクラウドに送信できます。
Cloud Pub/Sub の場合:Google Cloud Pub/Sub は、世界中の IoT デバイスからのメッセージの取り込みを処理できる、スケーラブルで信頼性の高いメッセージング サービスです。バッチ処理されたメッセージを処理するために必要な柔軟性を提供し、信頼性の高い配信を保証します。
クラウドデータフロー:Google Cloud Dataflow は、サーバーレスのフルマネージド ストリームおよびバッチ データ処理サービスです。Cloud Pub/Sub からのデータを大規模に効率的に処理および変換できます。Dataflow は、自動的にスケーリングすることでメッセージ読み込みの急増に対処し、データ処理パイプラインの費用対効果と信頼性を確保します。
正しくないオプション -
オプション A (センサー デバイスとしてのエッジ TPU):エッジ TPU は、エッジでの機械学習推論用に設計されており、メッセージの保存と送信に最も効率的なソリューションではない可能性があります。これらは通常、特定の AI タスクに使用されます。
オプション B(Kafka クラスタに接続された Cloud Dataflow):Cloud Dataflow は Kafka データを処理できますが、特にグローバルな IoT デバイスを扱う場合は、Cloud Pub/Sub をフルマネージドでスケーラブルな取り込みサービスとして使用する方が効率的です。
オプション D(Compute Engine で仮想化された Kafka クラスタ):Compute Engine インスタンスでの Kafka クラスタの管理は複雑でコストがかかる場合があり、メッセージの急増を効率的に処理するという問題には対処できません。
</div></details>

### Q. 質問4: 未回答
Cloud Datastore を利用して、車両のテレメトリ データをリアルタイムで取り込むことを選択しました。目的は、費用対効果を維持しながら、長期的なデータの増加に対応するストレージソリューションを確立することです。また、このデータのスナップショットを定期的に生成して、代替環境での Cloud Datastore のポイントインタイム リカバリ(PIT)やデータのクローン作成を容易にします。2つの異なる方法を使用して、これらの目標を達成するにはどうすればよいでしょうか。(2つ選択)
1. マネージド エクスポートを使用し、Nearline クラスまたは Coldline クラスを使用して Cloud Storage バケットにデータを保存します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
車両のテレメトリ データをリアルタイムで Cloud Datastore に取り込み、コストを抑えながら長期保存用のデータのスナップショットを作成するという目標を達成するには、次の 2 つの方法を検討できます。
A. 
説明: Cloud Datastore の管理対象エクスポート機能を使用して、データを定期的にエクスポートできます。エクスポート後、データを Cloud Storage バケットに保存します。Nearline または Coldline ストレージクラスを選択することで、コストを低く抑えながら、スナップショットを長期保存用にアーカイブできます。
B. 管理対象エクスポートを使用してから、そのエクスポート用に予約された一意の名前空間の下にある別のプロジェクトの Cloud Datastore にインポートします。
説明: データのスナップショットを作成する別の方法として、Cloud Datastore の管理対象エクスポートを使用する方法があります。エクスポート後、そのエクスポート用に特別に予約された一意の名前空間を使用して、別の Cloud Datastore プロジェクトにデータをインポートできます。これにより、別の環境にデータのコピーを別個に作成できます。
正しくないオプション -
その他のオプション(C、D、E)は、Cloud Datastore データのスナップショットを作成し、コストを最小限に抑えながら長期保存用にアーカイブするという目標に直接対応していません。オプション C と D では、BigQuery にデータをインポートするか、データを管理するアプリケーションを作成するかについて説明しますが、これはスナップショットを作成する最も効率的な方法ではありません。オプションEでは、クラウドソースリポジトリにデータを保存することについて言及していますが、これはデータスナップショットには適していません。
</div></details>

### Q. 質問5: 未回答
あなたは、データサイエンスチームによる分析のために、時系列のトランザクションデータを BigQuery にコピーするデータパイプラインを設定する任務を負っています。このデータは 1 時間ごとに新しいステータスで更新され、初期データセット サイズは 1.5 PB で、毎日 3 TB ずつ増加します。データの構造が複雑で、データ サイエンス チームはそれを使用して機械学習モデルを構築することを計画しています。目的は、データ サイエンス チームのパフォーマンスと使いやすさを最適化することです。
この目標を達成するために、どの2つの戦略を採用すべきでしょうか?(2つ選択してください。
1. 可能な限りデータを非正規化します。
2. 
3. 
4. ステータスの更新が BigQuery に更新されるのではなく、追加されるデータ パイプラインを開発します。
5. 
<details><div>
    答え：1,4
説明
A. 
データを非正規化すると、特に大規模なデータセットを処理する場合に、クエリのパフォーマンスを向上させることができます。非正規化することで、複雑な結合の必要性が減り、クエリをより簡単にすることができます。場合によっては、これにより、データ サイエンティストの使いやすさとクエリのパフォーマンスが向上する可能性があります。
D. 
時系列データに追加のみのアプローチを使用することは、ストリーミング データや頻繁に更新されるデータを処理する場合の一般的な方法です。既存のレコードを更新する代わりに、期間ごとに新しいレコードを追加します(例:毎時)。このアプローチにより、履歴データが保持され、時系列データの自然な流れに合わせることができます。
正しくないオプション -
オプション B (データの構造を可能な限り保持する) は、一般に、データの整合性を維持し、データが理解しやすい状態を維持するための優れたプラクティスです。ただし、場合によっては、クエリのパフォーマンスのために非正規化が必要になることがあります。
オプション C(BigQuery UPDATE を使用してデータセットのサイズをさらに小さくする)は、既存のレコードが頻繁に更新されることを意味するため、時系列データには適していない可能性があります。追加のみのアプローチでは、既存のレコードを更新するのではなく、時間間隔ごとに新しいレコードを追加します。
オプション E(トランザクション データの日次スナップショットを Cloud Storage にコピーし、Avro ファイルとして保存します。BigQuery の外部データソースのサポートを使用してクエリを実行する)は、スナップショットのアーカイブと維持には有効な戦略ですが、トランザクション データのリアルタイム分析には最も効率的なアプローチではない可能性があります。これは、履歴分析やバックアップの目的に適しています。
</div></details>

### Q. 質問6: 未回答
あなたは、次の基準を満たしながら履歴データを処理するためのクラウドネイティブなソリューションを考案する任務を負っています。
- 分析対象のデータが CSV、Avro、PDF 形式で存在し、Dataproc、BigQuery、Compute Engine などの複数の分析ツールがアクセスする必要がある。
- バッチ パイプラインは、毎日のデータの移動を担当します。
- このソリューションでは、パフォーマンスは主な関心事ではありません。
- ソリューションの設計では、可用性を優先する必要があります。
このソリューションのデータストレージをどのように構成しますか?
1. 
2. 
3. 
4. 複数リージョンの Cloud Storage バケットにデータを保存します。Dataproc、BigQuery、Compute Engine を使用してデータに直接アクセスします。
<details><div>
    答え：4
説明
可用性を最大化し、Dataproc、BigQuery、Compute Engine などの複数の分析ツールからアクセスできるようにする必要があるクラウドネイティブの履歴データ処理システムの場合、推奨されるアプローチは次のとおりです。
D. 
このオプションが適している理由は次のとおりです。
マルチリージョンクラウドストレージバケット:マルチリージョンの Cloud Storage バケットにデータを保存することで、高可用性と耐久性が確保されます。データは複数のリージョンにレプリケートされるため、リージョンの停止によるデータ損失のリスクが軽減されます。
直接アクセス:Cloud Storage を使用すると、Dataproc、BigQuery、Compute Engine など、さまざまな Google Cloud サービスのデータに直接アクセスできます。これにより、複雑さとレイテンシーが最小限に抑えられ、分析用のデータへの効率的なアクセスが可能になります。
正しくないオプション -
オプション A(Dataproc 上の HDFS):HDFS は Dataproc で使用できますが、より複雑なソリューションであり、マルチリージョンの Cloud Storage ほど効果的に可用性を最大化できない可能性があります。
オプション B(BigQuery):BigQuery は強力な分析ツールですが、通常は構造化データに使用され、PDF ファイルの取り込みは困難な場合があります。さまざまな形式の未加工のストレージに BigQuery を使用することは、最も効率的なアプローチではない可能性があります。
高可用性が必要な場合は、オプション C (リージョン クラウド ストレージ バケット) が実行可能な選択肢になる可能性がありますが、可用性を最大化するには、特にマルチリージョン アクセスの場合は、オプション D が推奨されます。
</div></details>

### Q. 質問7: 未回答
ペタバイト規模の分析データを管理する任務を負っており、ストレージと処理のプラットフォームが必要です。目標は、Google Cloud でデータ ウェアハウス スタイルの分析を有効にし、データセットを他のクラウド プラットフォーム上のバッチ分析ツールのファイルとして利用できるようにすることです。
これを達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. リージョンの Cloud Storage バケットにデータを保存します。Dataproc、BigQuery、Compute Engine を使用してバケットに直接アクセスします。
4. 
<details><div>
    答え：3
説明
C. 
このオプションは、耐久性とアクセス性を確保するために、リージョンの Cloud Storage バケットにデータを保存する場合に適しています。このデータには、Dataproc、BigQuery、Compute Engine など、さまざまな Google Cloud サービスを使用して直接アクセスできます。このアプローチでは、データの使用方法と処理方法に関して柔軟性があります。
誤ったオプション-
オプション A(データセット全体を BigQuery に保存して処理する):BigQuery はデータ ウェアハウスと分析には優れていますが、特にデータのかなりの部分が頻繁にアクセスされない場合は、ペタバイト規模のデータに対して最も費用対効果の高いソリューションではない可能性があります。すべてのデータを BigQuery に保存すると、コストが高くなる可能性があります。
オプション B(データセット全体を Bigtable に保存して処理する):Bigtable は、高スループットの NoSQL スタイルのワークロード向けに設計されており、従来のデータ ウェアハウス スタイルの分析には適していません。SQLクエリ機能がありません。
オプション D(ウォームデータをファイルとして Cloud Storage に保存し、アクティブデータを BigQuery に保存する):このアプローチは、アクティブなデータとアクティブでないデータを明確に分離している場合には意味があるかもしれませんが、他のクラウド プロバイダーでバッチ分析のためにデータをファイルとして公開する必要性に直接対処するものではありません。アクティブ データを BigQuery に保存することは適切な選択ですが、耐久性のためにウォーム データは引き続き Cloud Storage に保存される可能性があります。
</div></details>

### Q. 質問8: 未回答
あなたは、それぞれ独自のサプライヤーから約 750 の異なるコンポーネントを調達する製造会社の一員です。データセットには、平均して、コンポーネントごとに 1000 個のラベル付き例が含まれています。目的は、倉庫スタッフがコンポーネントの写真から入荷コンポーネントを識別するのに役立つアプリを作成することです。最初の動作バージョンを概念実証として迅速に開発することを目指しています。
どのように進めればよいですか?
1. 既存のデータセットで Cloud Vision AutoML を使用します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
Cloud Vision AutoML はカスタム画像認識タスク専用に設計された機械学習サービスであるため、これは正しいオプションです。これにより、シナリオに不可欠な既存のデータセットを使用してカスタム画像認識モデルをトレーニングできます。オプションAが最良の選択である理由は次のとおりです。
カスタマイズ：Cloud Vision AutoMLを使用すると、特定のユースケースに合わせたカスタムモデルを構築できます。シナリオでは、倉庫作業員が撮影した写真からさまざまなコンポーネントを認識するには、正確な結果を得るためにカスタマイズされたソリューションが必要です。
精度：カスタム モデルは、ドメイン固有のデータでトレーニングされるため、多くの場合、汎用モデルよりもパフォーマンスが高くなります。既存のデータセットを使用してモデルをトレーニングすることで、コンポーネントの認識精度を高めることができます。
使いやすさ:カスタム機械学習モデルのトレーニングは複雑になりがちですが、Cloud Vision AutoML を使用するとプロセスが簡素化され、機械学習の深い専門知識がなくてもアクセスできるようになります。これは、迅速な概念実証という目標とよく一致します。
正しくないオプション -
オプション B: Cloud Vision AutoML を使用しますが、データセットを 2 回削減します。
データセットを減らすと、貴重なトレーニングデータが失われ、モデルの精度に悪影響を与える可能性があります。PoC では、最良の結果を得るために、できるだけ多くの関連データを使用する必要があります。
オプション C: 認識のヒントとしてカスタム ラベルを指定して、Cloud Vision API を使用します。
Cloud Vision API はさまざまな画像分析タスクに役立ちますが、カスタム画像認識を必要とする特定のシナリオには適していない可能性があります。カスタムラベルをヒントとして指定すると認識が向上しますが、ラベル付けされた画像のデータセットが大量にある場合は、Cloud Vision AutoMLでカスタムモデルをトレーニングするほど効果的ではありません。
オプション D: 転移学習手法を活用して独自の画像認識モデルをトレーニングします。
転移学習手法を使用して独自の画像認識モデルをトレーニングすることは有効なアプローチであり、特定のシナリオでは非常に効果的ですが、画像内のコンポーネントを認識するための迅速な概念実証 (PoC) の作成を含む特定の状況には最適な選択肢ではない可能性があります。
</div></details>

### Q. 質問9: 未回答
あなたは画像認識に関連する特殊なプロジェクトに携わっており、チームは、開発したカスタム C++ TensorFlow 操作に主に依存するモデルを作成しました。これらの操作は、主要なトレーニング プロセスに不可欠であり、リソースを大量に消費する行列の乗算を伴います。現在、モデルのトレーニング プロセスが完了するまでに数日かかる場合があります。目標は、Google Cloud アクセラレータを活用して費用対効果を維持しながら、このトレーニング時間を大幅に短縮することです。
この目標を達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. CPU を使用したまま、モデルをトレーニングするクラスターのサイズを増やします。
<details><div>
    答え：4
説明
D. 
カスタム C++ TensorFlow Ops:モデルは、カスタム C++ TensorFlow 演算に大きく依存しています。TPU や GPU とシームレスに連携するようにこれらの運用を移行することは、複雑で時間のかかるプロセスであり、多くの場合、これらのアクセラレータの最適化には大幅なコード変更と専門知識が必要です。
TPUの:Cloud TPU は、特定のディープ ラーニング ワークロード向けの優れたアクセラレータですが、アーキテクチャと互換性のある TensorFlow オペレーション向けに最適化されています。カスタム演算を TPU で実行するように適応させるのは困難な場合があり、モデルが特殊なハードウェアを最大限に活用できない限り、大きなメリットが得られない可能性があります。
GPUサポート:カスタム演算に GPU カーネル サポートを実装することは、GPU の使用を計画している場合、正しい方向への一歩です。ただし、GPU と TPU はアーキテクチャが異なるため、個別の最適化が必要です。このオプションは、特にGPUアクセラレーションをターゲットとしている場合に適しています。
クラスタのスケーリング:CPU にとどまり、クラスターのサイズを増やすことで、複数の CPU ノードにワークロードを分散できます。これにより、計算負荷の高いタスクであっても、トレーニング時間を大幅に短縮できます。多くの場合、トレーニングをスピードアップするための最も簡単で費用対効果の高い方法です。
コストに関する考慮事項:TPU と GPU は、CPU ベースのクラスターと比較して、使用コストが高くなる可能性があります。CPU にとどまり、クラスターをスケーリングすることで、パフォーマンスとコスト効率のバランスを取ることができます。
カスタム C++ TensorFlow 演算を使用するシナリオと、コストを低く抑えながらトレーニング時間を最小限に抑える必要があることを考えると、CPU にとどまり、クラスターをスケーリングする (オプション D) ことが、最も実用的でコスト効率の高いアプローチです。TPU や GPU などのアクセラレータへの移行は長期的な目標かもしれませんが、これらのハードウェア プラットフォーム向けのカスタム運用の最適化に伴う複雑さとコストを慎重に検討して取り組む必要があります。
</div></details>

### Q. 発行： 未回答
自然言語処理領域内の回帰問題に取り組んでおり、1 億個のラベル付き例を含むデータセットを備えています。データをランダムにシャッフルし、90/10 の比率でトレーニング セットとテスト セットに分割しました。ニューラル ネットワークに学習させ、テスト セットでそのパフォーマンスを評価すると、トレーニング セットの二乗平均平方根誤差 (RMSE) がテスト セットの誤差の 2 倍であることがわかります。
モデルのパフォーマンスを向上させるには、どのような手順を実行する必要がありますか?
1. 
2. 
3. 正則化手法 (ドロップアウトやバッチ正規化など) を試して、過学習を回避します。
4. 
<details><div>
    答え：3
説明
モデルの二乗平均平方根誤差 (RMSE) が、トレーニング セットではテスト セットの 2 倍であるという観察結果は、過学習を示しています。過学習は、モデルが学習データに近づきすぎて、一般的なパターンではなく学習データにノイズや特異性をキャプチャすることを学習した場合に発生します。モデルのパフォーマンスを向上させるには、過学習を減らすことに重点を置く必要があります。正しいアプローチは次のとおりです。
C. 
正則化手法:ドロップアウト、バッチ正規化、L2 正則化などの手法は、過学習を軽減するように設計されています。トレーニング中にモデルのパラメーターに制約を導入し、トレーニング データに近づきすぎないようにし、目に見えないデータへの一般化を促進します。
テストセットサイズの拡大(オプションA):トレーニングとテストの分割でテスト サンプルのシェアを増やしても、過学習には直接対処できません。重要なのは、既存のテストセットの相対的なパフォーマンスであり、そのサイズではありません。
より多くのデータを収集する(オプションB):より多くのデータを収集すると、特定のケースでは役立ちますが、必ずしも過学習が解決されるとは限りません。一般に、データセットのサイズを増やすことを検討する前に、まずモデルを最適化し、正則化手法を適用することをお勧めします。
モデルの複雑性を増す(オプションD):モデルの複雑さが増すと、過学習が解決されるどころか悪化する可能性があります。複雑なモデルほどパフォーマンスが向上するというのは、よくある誤解です。適切な正則化を備えた単純なモデルは、多くの場合、過度に複雑なモデルよりも優れた性能を発揮します。
正しくないオプション -
A. トレーニングとテストの分割でテスト サンプルのシェアを増やします。
トレーニングとテストの分割でテスト サンプルの割合を増やしても、過学習の問題に直接対処できるわけではありません。トレーニングとテストの間でデータの割り当てが変更されるだけで、モデルの動作には影響しません。
問題は、テストセットのサイズではなく、モデルがトレーニングセットから未知のデータにうまく一般化できないことです。このオプションでは、過学習の根本原因には対処できません。
B. より多くのデータを収集し、データセットのサイズを大きくしてみてください。
より多くのデータを収集することは、特に意味のあるパターンを学習するための十分なデータがモデルにない場合に、場合によっては有用な戦略となる可能性があります。ただし、このシナリオでは、既にかなりのデータセット (100M の例) があります。
データセットのサイズを大きくしても、過学習の問題に直接対処できない場合があります。過学習は、多くの場合、モデルが複雑すぎるか、使用可能なデータの量に対してパラメーターが多すぎることが原因です。一般に、大規模なデータセットがある場合は、モデルの正則化に重点を置く方が効果的です。
D. 追加のレイヤーを導入したり、使用する語彙や n-gram のサイズを増やしたりするなどして、モデルの複雑さを増します。
モデルの複雑さが増すと、過学習は解決されるどころか悪化する可能性があります。より複雑なモデルでは、トレーニング データにノイズや特異性が当てはめられやすく、一般化が不十分になる可能性があります。
過学習は、通常、モデルが既に複雑すぎて使用可能なデータがない場合に発生します。複雑さを増すことは、推奨されるアプローチではありません。代わりに、モデルを単純化し、正則化手法を適用して過学習を防ぐことをお勧めします。
</div></details>

### Q. 質問11: 未回答
一元化された分析設定では、BigQuery がコア プラットフォームとして機能します。毎日データがアップロードされ、ユーザーに提示する前にデータ変換を担当するETLパイプラインを運用します。ETL パイプラインは頻繁に変更され、時折エラーが発生し、その一部は 2 週間の遅延後にのみ表面化する場合があります。これらのエラーの回復メカニズムを確立すると同時に、バックアップ ストレージのコストを最適化する必要があります。
BigQuery でデータを構造化し、バックアップ戦略を管理するには、どのようなアプローチが推奨されますか?
1. 
2. 月ごとにデータを個別のテーブルに整理し、データをエクスポート、圧縮して Cloud Storage に保存します。
3. 
4. 
<details><div>
    答え：2
説明
オプション B: 
このオプションでは、データを月ごとに個別のテーブルに整理することを提案し、データ管理の適切な方法を提供します。さらに、データをエクスポート、圧縮し、Cloud Storage に保存することをお勧めします。
これが正解である理由は次のとおりです。
月ごとに個別のテーブル:月ごとにデータを個別のテーブルに整理すると、データが分離されます。ETL プロセス中にエラーが発生した場合、またはデータが破損した場合、他の月に影響を与えることなく、影響を受けた月のデータを簡単に特定して回復できます。
エクスポートと圧縮:データをエクスポートして Cloud Storage に保存することは、バックアップの一形態として機能します。データを圧縮することで、ストレージコストを最適化できます。データの破損やエラーが発生した場合は、バックアップしたデータを Cloud Storage から取得し、BigQuery に読み込むことができます。
正しくないオプション -
オプション A: データを 1 つのテーブルに整理し、BigQuery データをエクスポートして圧縮し、Cloud Storage に保存します。
このオプションでは、すべてのデータを 1 つのテーブルに格納することを提案します。Cloud Storage にデータをエクスポートして保存することについては言及していますが、データを時間単位で整理することの利点については考慮されていません。すべてのデータを 1 つのテーブルに格納すると、エラーが発生した場合に特定の期間を分離して回復することが困難になる可能性があります。
オプション C: 月ごとにデータを別々のテーブルに整理し、BigQuery の別のデータセットにデータを複製します。
BigQuery 内の別のデータセットにデータを複製すると、ストレージ費用が大幅に増加する可能性があります。データ復旧のための効率的なバックアップ戦略は提供されません。さらに、正確なポイントインタイムリカバリを可能にするスナップショットデコレーターは利用されません。
オプション D: 月ごとにデータを個別のテーブルに整理し、スナップショット デコレーターを使用してテーブルを破損前の時点に復元します。
BigQuery のスナップショット デコレーターは、特定の時点までデータを復元するのに便利な機能ですが、いくつかの制限があり、このシナリオでは最適な選択ではない可能性があります。
</div></details>

### Q. 質問12: 未回答
組織のマーケティング チームは、顧客データセットのセグメントの更新を定期的に提供します。BigQuery で更新する必要がある 100 万件のレコードを含む CSV ファイルが作成されました。ただし、BigQuery で UPDATE ステートメントを使用しようとすると、quotaExceeded エラーが発生します。
この問題に対処するには、どのような手順を実行する必要がありますか?
1. 
2. 
3. 
4. CSV ファイルから新しい BigQuery テーブルに新しいレコードをインポートします。新しいレコードを既存のレコードとマージし、結果を新しい BigQuery テーブルに書き込む BigQuery ジョブを作成します。
<details><div>
    答え：4
説明
BigQuery で UPDATE ステートメントを使用しているときに quotaExceeded エラーが発生した場合は、通常、1 回のクエリ ジョブで実行できる更新数の上限に達していることを示しています。この問題に対処するための正しいアプローチは次のとおりです。
D. 
このアプローチが最も適している理由は次のとおりです。
拡張性:新しいレコードを別の BigQuery テーブルにインポートすることで、1 つの DML ステートメントで更新の割り当て制限に達することを回避できます。BigQuery は大規模なデータセットのクエリと処理に最適化されており、このアプローチにより、新しいレコードと既存のレコードを効率的にマージできます。
コントロール：この方法では、更新プロセスをより詳細に制御できます。マージ操作は SQL ステートメントを使用して実行できるため、特定の要件に基づいて管理およびカスタマイズしやすくなります。
データの整合性:新しいレコードを別のテーブルにインポートすると、既存のデータを誤って上書きしたり変更したりすることがなくなります。マージ操作の結果をメイン データセットにコミットする前に確認できるため、より安全なアプローチです。
パフォーマンス：BigQuery は大規模なデータセットのクエリ用に設計されており、マージクエリを使用して更新操作を実行することは、大量のデータを効率的に処理するのに適しています。
正しくないオプション -
対照的に、他のオプション(A、B、C)は quotaExceeded エラーに直接対処しないため、BigQuery で大規模なデータセットを更新するための効果的なソリューションではない可能性があります。オプション D は、更新を効率的に処理し、クォータの制限を回避するための構造化されたスケーラブルなアプローチを提供します。
</div></details>

### Q. 質問13: 未回答
組織での GCP の使用が拡大するにつれて、さまざまなチームが独自のプロジェクトを生成し、さまざまなデプロイ フェーズやオーディエンス ターゲティングにさらに拡張しています。各プロジェクトには、個別のアクセス制御設定が必要です。中央の IT 部門では、すべてのプロジェクトにわたるユニバーサル アクセスが必要です。また、Cloud Storage バケットと BigQuery データセットは、プロジェクト間で柔軟に共有する必要があります。ポリシーの数を減らすことでアクセス制御を合理化することを目指しています。
どの 2 つのアクションを追求すべきですか?(2つ選択してください。
1. 
2. アクセス コントロール ポリシーの継承を活用するためのリソース階層を導入します。
3. チームごとに個別のグループを作成し、Cloud IAM ポリシーでグループを指定します。
4. 
5. 
<details><div>
    答え：2,3
説明
アクセス制御管理を簡素化し、ポリシーの数を最小限に抑えながら、組織での GCP の使用の拡大に対応するには、次の手順を検討する必要があります。
B. 
リソース階層を使用すると、それらのプロジェクト内のプロジェクト、フォルダー、およびリソースによって継承される組織レベルのポリシーを定義できます。このアプローチにより、組織レベルで高レベルのアクセス制御ポリシーを設定しながら、プロジェクトレベルでより具体的なポリシーを管理することができます。
C. 
チームごとに個別のグループを作成し、Cloud IAM ポリシーでこれらのグループを指定することで、アクセス管理を効率化できます。ユーザーを個別に指定する代わりに、グループに権限を割り当てることができるため、複数のプロジェクトにまたがるチームのアクセス制御を簡単に管理できます。
正しくないオプション -
A. Cloud Deployment Manager を使用して、アクセスのプロビジョニングを自動化します。
Cloud Deployment Manager は、主に、Infrastructure as Code を含むクラウド リソースのプロビジョニングと管理に使用されます。リソースのプロビジョニングを自動化することはできますが、アクセス制御管理の簡素化やポリシーの最小化には直接対応していません。
D. サービス アカウントは、Cloud Storage バケットと BigQuery データセットのデータを共有する場合にのみ使用します。
サービス アカウントは、自動化されたプロセスやアプリケーションへのアクセスを許可するのに便利ですが、人間のユーザーやチームとアドホックな方法でデータを共有するのには適していない場合があります。サービス アカウントは、通常、特定のプログラムによるアクセスに使用されます。
E.Cloud Storage バケットまたは BigQuery データセットごとに、アクセスが必要なプロジェクトを決定します。これらのプロジェクトへのアクセス権を持つすべてのアクティブ メンバーを検索し、Cloud IAM ポリシーを作成して、これらのすべてのユーザーにアクセス権を付与します。
このアプローチでは、各リソースのユーザーを手動で識別してアクセス権を付与します。時間がかかり、プロジェクトやリソースの数が増えるにつれてエラーが発生しやすくなります。リソース階層とグループを使用すると、アクセス制御に対してよりスケーラブルで組織化されたアプローチを提供できます。
</div></details>

### Q. 質問14: 未回答
米国を拠点とする会社は、ユーザー操作を評価して対応するために設計されたアプリケーションを開発しました。メインデータベーステーブルのデータ量は、毎秒250,000レコードの割合で増加しています。さまざまなサードパーティエンティティが、アプリケーションのAPIを利用して、その機能をフロントエンドアプリケーションに統合します。アプリケーションの API が次の基準に準拠していることを確認する必要があります。
- 単一のグローバルエンドポイントを維持します。
- ANSI SQL のサポートを提供します。
- 最新のデータへの一貫したアクセスを保証します。
これらの要件を満たすには、どのような手順を踏む必要がありますか?
1. 
2. 北米のリーダーである Cloud Spanner と、アジアとヨーロッパで読み取り専用レプリカを実装する
3. 
4. 
<details><div>
    答え：2
説明
アプリケーションが単一のグローバル エンドポイント、ANSI SQL サポート、および最新のデータへの一貫したアクセスを必要とするこのシナリオでは、最適なオプションは次のとおりです。
オプション B: 
その理由は次のとおりです。
グローバルエンドポイント:Cloud Spanner には、アプリケーション用に 1 つのグローバル エンドポイントを作成できるグローバル分散機能が用意されています。これは、世界中のどこからでも要求を処理できる、グローバルで強力な一貫性のあるデータベースを提供するため、サードパーティが API を使用しているシナリオに最適です。
ANSI SQL サポート:Cloud Spanner は ANSI SQL をサポートしているため、標準の SQL クエリと互換性があります。これにより、前述の要件であるSQLを使用してデータを簡単に操作できます。
一貫性：Cloud Spanner は強力なグローバル整合性を備えているため、読み取り専用レプリカを含むすべてのレプリカがリーダーとの整合性が保たれます。これにより、アプリケーションとサードパーティのアプリケーションがどこにあっても、最新のデータにアクセスできるようになります。
グローバル・レプリケーション:アジアとヨーロッパに読み取り専用レプリカを持つことで、北米の主要なリーダーとの一貫性を維持しながら、これらの地域のユーザーとアプリケーションのデータへの低レイテンシーのアクセスを確保できます。
正しくないオプション -
オプション A(BigQuery):BigQuery は大規模なデータセットの分析とクエリ用に設計されていますが、トランザクション システムに必要なリアルタイムの一貫性とグローバル エンドポイント機能を提供しない場合があります。
オプション C(Cloud SQL for PostgreSQL):Cloud SQL はマネージド リレーショナル データベース サービスですが、Cloud Spanner と同じグローバルな分散とスケーラビリティを提供しない場合があり、PostgreSQL は同じレベルのグローバルな一貫性を提供しない可能性があります。
オプション D(Bigtable):Bigtable は、高スループットで大規模なデータ用に最適化された NoSQL データベースです。ANSI SQL をサポートしていない可能性があり、整合性モデルは Cloud Spanner ほど強力ではありません。
</div></details>

### Q. 質問15: 未回答
データ サイエンティストが BigQuery ML モデルを開発し、予測を配信するための ML パイプラインの構築についてサポートを求めています。REST API アプリケーションは、100 ミリ秒未満の待ち時間内に個々のユーザー ID の予測を提供するという基準を満たす必要があります。使用される予測クエリは、SELECT predicted_label、user_id FROM ML.PREDICT (MODEL 'dataset.model', table user_features) です。
この ML パイプラインの作成にはどうすればよいでしょうか。
1. 
2. 
3. 
4. BigQueryIO を使用して Dataflow パイプラインを作成し、クエリからすべてのユーザーの予測を読み取り、BigtableIO を使用して結果を Bigtable に書き込み、アプリケーションが Bigtable から個々のユーザーの予測を読み取れるように、アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与することです。
<details><div>
    答え：4
説明
REST API アプリケーションで BigQuery ML を使用して低レイテンシで予測を提供する場合、最適なオプションは、オプション D: 
その理由は次のとおりです。
レイテンシーに関する考慮事項:個々のユーザー ID のレイテンシーが 100 ミリ秒未満の予測を提供することは、困難な要件です。BigQuery への直接クエリは、この低レイテンシの要件を常に満たしているとは限りません。
データフロー パイプライン:Dataflow パイプラインを作成することで、データを効率的に処理、変換できます。Dataflow は BigQuery から予測を読み取り、低レイテンシのアクセスに最適化された別のストレージ システム(Bigtable など)に書き込むことができます。
Bigtable ストレージ:Bigtable は、低レイテンシ、高スループットのストレージを提供する NoSQL データベースです。Bigtable に予測を保存すると、個々のユーザー ID の予測をすばやく取得できます。
ロールベースのアクセス制御:アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与すると、Bigtable から予測を読み取るために必要な権限がアプリケーションに付与されます。
正しくないオプション -
オプション A (クエリへの WHERE 句の追加とデータ閲覧者ロールの付与):このオプションでは低レイテンシの要件には対応しておらず、BigQuery を直接クエリしてもレイテンシの目標を達成できない可能性があります。
オプション B (承認済みビューの作成):承認済みビューの作成は、特定のデータへのアクセスを制御するのに役立ちますが、必ずしも低レイテンシーの要件に対応できるわけではなく、低レイテンシーで予測を提供する必要があります。
オプション C(クエリから結果を読み取るための Dataflow パイプラインの作成):このオプションはデータの処理に使用できますが、低レイテンシーの要件には対応しておらず、低レイテンシーで予測を提供するソリューションが必要になります。
</div></details>

### Q. 質問 16: 未回答
金融市場データを消費者に配布するアプリケーションを開発する場合、データはリアルタイムで収集されるため、さまざまな手段でこのデータを消費者に配信するための最も適切なソリューションを決定する必要があります。
- リアルタイムイベントストリーム
- ANSI SQLによるリアルタイムストリームおよび履歴データへのアクセス
- バッチ履歴エクスポート
このタスクを効果的に実行するには、どのようなソリューションを採用する必要がありますか?
1. 
2. Cloud Pub/Sub、Cloud Storage、BigQuery
3. 
4. 
<details><div>
    答え：2
説明
金融市場データを消費者とリアルタイムで共有し、リアルタイムのストリームと履歴データへの ANSI SQL アクセスを提供し、履歴のバッチ エクスポートをサポートするアプリケーションを構築する場合、最適なソリューションはオプション B: Cloud Pub/Sub、Cloud Storage、BigQuery です。
このオプションが適している理由は次のとおりです。
Cloud Pub/Sub の場合:これは、リアルタイムのイベントストリームを処理するための優れた選択肢です。市場データを Pub/Sub トピックにパブリッシュして、消費者がリアルタイムでデータをサブスクライブして受信できるようにすることができます。
クラウドストレージ:Cloud Storage を使用して履歴データを保存し、消費者がバッチ エクスポートを通じてアクセスできるようにすることができます。これにより、耐久性、スケーラビリティ、および履歴データへの容易なアクセスが提供されます。
BigQuery の場合:BigQuery は、リアルタイムのストリーム データ(ストリーミング テーブルのクエリ)と履歴データ(保存されたテーブルのクエリによる)への ANSI SQL アクセスを提供する強力なデータ ウェアハウスです。これにより、ストリーミング データに対してリアルタイム分析を実行し、履歴データに対する複雑なクエリをサポートできます。
オプションBは、リアルタイムデータストリーミング、SQLアクセス、およびバッチ履歴エクスポートの効率的かつ費用対効果の高いすべての要件をカバーしています。
他のオプション(A、C、D)では、この特定のユースケースに必要な同じレベルの統合と機能が提供されない場合があります。
</div></details>

### Q. 質問17: 未回答
スケーラブルなデータ収集を必要とする新しいアプリケーションを開発しています。データは一日中アプリケーションから継続的にストリーミングされ、年末までに毎日約 150 GB の JSON データが出力されると予想されています。仕様には次のものが含まれます。
- 生産者と消費者の分離
- 費用対効果に重点を置いた生の取り込みデータを効率的に保存し、無期限に保持する
- ほぼリアルタイムのSQLクエリの実現
- 少なくとも2年分の履歴データを保持し、SQLクエリでアクセス可能
これらの要件を満たすには、どのようなタイプのデータパイプラインを採用する必要がありますか?
1. 
2. 
3. 
4. Cloud Pub/Sub にイベントを発行するアプリケーションを作成し、JSON イベント ペイロードを Avro に変換して Cloud Storage と BigQuery にデータを書き込む Cloud Dataflow パイプラインを作成する必要があります。
<details><div>
    答え：4
説明
所定の要件を満たすには、オプション D: 
オプションDが最良の選択である理由は次のとおりです。
プロデューサとコンシューマのデカップリング:Cloud Pub/Sub を使用すると、プロデューサー(アプリケーション)とコンシューマ(Dataflow パイプラインと BigQuery)を切り離すことができます。これにより、データの取り込みと処理が緊密に結合されなくなります。
スペースとコスト効率の高いストレージ:Avro は、生の JSON と比較して、よりスペース効率が高く、費用対効果の高い形式です。Cloud Storage に Avro 形式でデータを保存すると、ストレージ費用とクエリ パフォーマンスの両面で効率的です。
ほぼリアルタイムの SQL クエリ:Cloud Dataflow はほぼリアルタイムでデータを処理できるため、取り込み後すぐに SQL クエリでデータを利用できるようになります。
履歴データの更新:BigQuery を使用すると、少なくとも 2 年間は履歴データを効率的に保存し、クエリを実行できます。
正しくないオプション -
オプション A: API を提供するアプリケーションを作成します。API をポーリングし、データを gzip 圧縮された JSON ファイルとして Cloud Storage に書き込むツールを作成します。
このオプションには、リアルタイムのデータ インジェストがありません。API をポーリングすると、データ インジェストが遅延し、ほぼリアルタイムではなくなります。
データを gzip 圧縮された JSON ファイルとして Cloud Storage に保存すると、スペース効率が悪くなり、Avro を使用する場合と比較してストレージ コストが高くなる可能性があります。
生データを Cloud Storage に保存することはできますが、ほぼリアルタイムの SQL クエリを効率的に実行することはできません。
このアプローチでは、履歴データを維持し、SQLでクエリを実行することは困難であり、パフォーマンスが低下します。
オプション B: Cloud SQL データベースに書き込み、データを保存するアプリケーションを作成します。データベースを定期的にエクスポートして Cloud Storage に書き込み、BigQuery に読み込むように設定します。
大量の生データの保存に Cloud SQL を使用すると、コストがかかる場合があり、データ ストレージの費用対効果が高くない可能性があります。
Cloud SQL から Cloud Storage に定期的にエクスポートすると、データの可用性にレイテンシが生じる可能性があります。
この設定で SQL を使用して履歴データを効率的にクエリすることは、特に大規模なデータセットの場合、困難な場合があります。
オプション C: Cloud Pub/Sub にイベントを発行するアプリケーションを作成し、Cloud Dataproc で Spark ジョブを作成して、JSON データを Avro 形式に変換し、永続ディスク上の HDFS に保存します。
このオプションでは、Cloud Dataproc で Spark ジョブを設定して管理するため、ソリューションが複雑になります。
永続ディスク上のHDFSにデータを保存することは、長期ストレージにとって最も費用対効果が高くスケーラブルなアプローチではない可能性があります。
JSON データを Avro に変換しますが、Cloud Dataflow が提供するほぼリアルタイムの SQL クエリ機能はありません。
</div></details>

### Q. 質問 18: 未回答
Pub/Sub トピックからメッセージを取り込み、その結果を EU 内の BigQuery データセットに保存する Dataflow パイプラインを運用しています。現在、パイプラインは europe-west4 にあり、それぞれタイプ n1-standard-1 の最大 3 人のワーカーを雇用しています。ピーク時には、特に 3 つのワーカーすべてが CPU 容量をフルに稼働している場合に、パイプラインでレコードを迅速に処理するという課題が発生することがわかりました。
パイプラインのパフォーマンスを向上させるために実行できる 2 つのアクションは何ですか?(2つ選択)
1. 最大ワーカー数を増やします。
2. Dataflow ワーカーには、より大きなインスタンスタイプを使用します。
3. 
4. 
<details><div>
    答え：1,2
説明
A. 
ワーカーの数を増やすと、Dataflow パイプラインでより多くのデータを並行して処理できるようになります。ピーク時に既存のワーカーが最大 CPU 使用率に達していることが観察された場合、ワーカーを追加することで負荷をより効果的に分散し、スループットと処理速度を向上させることができます。
B. 
より大きなインスタンスタイプを使用すると、各ワーカーにより多くの CPU とメモリリソースが提供されます。これは、CPU 使用率がボトルネックになっている場合に、Dataflow パイプラインのパフォーマンスを向上させるのに特に効果的です。より大きなインスタンスにアップグレードすると、ワーカーが処理ワークロードをより効率的に処理するのに役立ちます。
正しくないオプション -
オプション C は当初、ゾーンの変更として言及されていましたが、通常、Dataflow ジョブのパフォーマンスに直接影響することはありません。地理的な配置が重要です。
オプション D の Bigtable で一時テーブルをバッファとして作成するという方法は、バッファリングのアプローチですが、複雑さとストレージ コストが増す可能性があります。これは、Dataflow のパフォーマンスを向上させるための最も簡単なソリューションではありません。
オプション E(Cloud Spanner に一時テーブルをバッファとして作成する)は有効なアプローチですが、Dataflow パイプラインの CPU 使用率の問題に対処するための主要なソリューションではない可能性があります。CPUのボトルネックに直接対処するのではなく、データのバッファリングとデータの整合性の維持に重点を置いています。
</div></details>

### Q. 質問19: 未回答
時系列指標の集計と Bigtable への書き込みを担当する Dataflow ジョブを特徴とするデータ パイプラインを管理しています。Bigtable 内でデータ更新の遅延が発生していますが、このデータは、組織内の何千人ものユーザーがアクセスするダッシュボードにとって非常に重要です。パフォーマンスを向上させ、より多くの同時ユーザーに対応し、データの書き込み時間を短縮するには、2 つの推奨アクションは何ですか?(2つ選択してください。
1. 
2. PipelineOptions で maxNumWorkers を設定して、Dataflow ワーカーの最大数を増やします。
3. Bigtable クラスタのノード数を増やします。
4. 
5. 
<details><div>
    答え：2,3
説明
Dataflow パイプラインのパフォーマンスを向上させ、Bigtable へのデータ書き込みに必要な時間を短縮しながら、追加の同時ユーザーをサポートするには、次のアクションを検討する必要があります。
B. 
Dataflow ワーカーの数を増やすと、パイプラインでデータの処理と書き込みを並行して行うことができるため、Bigtable への書き込みパフォーマンスが大幅に向上します。このアクションは、ワークロードをより効果的に分散し、データの更新を高速化するのに役立ちます。
C. 
Bigtable クラスタにノードを追加すると、容量とスループットが向上します。これにより、Bigtable は大量の書き込み操作を処理できるため、レイテンシが短縮され、データの更新がより迅速に行われるようになります。Bigtable を適切にスケーリングすることは、書き込みパフォーマンスを向上させるために重要です。
正しくないオプション -
オプション A は、ローカル実行を使用するように Dataflow パイプラインを構成するもので、通常、開発とデバッグの目的で使用されます。これは、実稼動パイプラインのパフォーマンスを向上させるための適切なアプローチではありません。
オプション D では、Bigtable への書き込み前にフラット化変換を使用すると、パイプライン内のデータ変換に役立つ可能性がありますが、Bigtable へのデータ書き込みのパフォーマンスには直接対処しません。
CoGroupByKey 変換を使用するオプション E は、通常、より複雑なシナリオでデータをグループ化して結合するために使用されます。これは、Bigtable への書き込みパフォーマンスの向上とは直接関係がない可能性があります。
</div></details>

### Q. 発行： 未回答
スケジュールに従って動作する Cloud Dataproc クラスタで、複数の Spark ジョブ(一部は順番に実行し、他は同時に実行)の実行を自動化するにはどうすればよいでしょうか。
1. 
2. 
3. Cloud Composer で有向非巡回グラフ(DAG)を作成する:
4. 
<details><div>
    答え：3
説明
オプション C: Cloud Composer で有向非巡回グラフ(DAG)を作成する:
正しいオプションの説明:Cloud Composer は、Google Cloud のマネージド Apache Airflow サービスで、複雑なワークフローを調整するために設計されています。Airflow では、有向非巡回グラフ (DAG) を作成して、ワークフローを定義およびスケジュールできます。このコンテキストでは、Spark ジョブのシーケンスと依存関係を表す DAG を作成できます。この DAG をスケジュールして、目的の順序でジョブを実行できます。
正しくないオプション -
オプション A: Cloud Dataproc ワークフロー テンプレートを作成します。
Dataproc ワークフロー テンプレートを作成して Dataproc ジョブのスケジュールを設定することはできますが、Spark ジョブ間の複雑な依存関係の管理やジョブの同時実行には適していない可能性があります。Dataproc ワークフロー テンプレートは、ジョブの順次実行をより簡単に行うことができます。
オプション B: ジョブを実行するための初期化アクションを作成します。
初期化アクションは、通常、起動時に Dataproc クラスタを構成するために使用されます。これらは、ジョブのオーケストレーションや依存関係を管理するようには設計されていません。このオプションでは、複雑なジョブ シーケンスをきれいに表現することはできません。
オプション D: Bash スクリプトを作成します。
Bash スクリプトを使用してクラスターを手動で作成し、ジョブを実行し、クラスターを破棄すると、エラーが発生しやすくなり、ジョブの依存関係とスケジュールを管理するための組み込み機能が不足しています。これは、Airflow(オプションC)のような専用のワークフローオーケストレーションツールと比較して、効率と拡張性に欠けるソリューションです。
</div></details>

### Q. 質問21: 未回答
現在、ジョブジェネレーターとジョブランナーという 2 つの異なるカテゴリのアプリケーション間でのデータ共有を容易にするデータパイプラインを構築しているところです。ソリューションには、使用量の増加に適応できるスケーラビリティがあり、既存のアプリケーションのパフォーマンスに悪影響を与えることなく、新しいアプリケーションをシームレスに統合できることが不可欠です。この目標を達成するために、どのように進めるべきでしょうか?
1. 
2. Cloud Pub/Sub トピックを使用してジョブを発行し、サブスクリプションを使用してジョブを実行します。
3. 
4. 
<details><div>
    答え：2
説明
既存のアプリケーションに悪影響を与えることなく、使用量の増加と新しいアプリケーションに対応できるスケーラブルなデータパイプラインを構築するための最も適切な選択肢は次のとおりです。
B. 
このオプションが適している理由は次のとおりです。
拡張性:Cloud Pub/Sub は、大量のメッセージや複数のサブスクライバーへの配信を処理できる、拡張性の高いメッセージング サービスです。使用量が増えると、Pub/Sub は追加の負荷をシームレスに処理できます。
コンポーネントのデカップリング:Cloud Pub/Sub では、ジョブジェネレータ(パブリッシャー)とジョブランナー(サブスクライバー)を切り離すことができます。新しいアプリケーションは、既存のトピックに影響を与えることなく、関連する Pub/Sub トピックをサブスクライブするだけで済みます。この分離により、新しいアプリケーションを追加しても、既存のアプリケーションのパフォーマンスに悪影響を与えることはありません。
柔軟性：Pub/Sub は柔軟性が高く、さまざまなメッセージ形式に対応できるため、さまざまなタイプのアプリケーションに適しています。
非同期：Pub/Sub は非同期で動作するため、システムのさまざまなコンポーネント間で効率的かつ応答性の高い通信が可能になります。
正しくないオプション -
オプション A(App Engine で API を作成する)は機能しますが、使用量の増加に応じて、エンドポイントの管理とスケーリングに関する考慮事項が必要になる場合があります。既存のアプリケーションに影響を与えずに新しいアプリケーションを追加するには、それほどシームレスではない可能性があります。
オプション C(Cloud SQL を使用)と D(Cloud Spanner を使用)にはリレーショナル データベースが含まれるため、大量のメッセージやアプリケーション間の非同期通信の処理には Pub/Sub ほど適していない可能性があります。
</div></details>

### Q. 質問22: 未回答
Cloud Spanner で、商品の販売データを保存する新しいトランザクション テーブルを作成する必要があります。主キーとして何を使用するかを決定します。パフォーマンスの観点から、どの戦略を選択する必要がありますか?
1. 
2. 
3. ランダムな汎用一意識別子番号 (バージョン 4 UUID):
4. 
<details><div>
    答え：3
説明
オプション C: 
UUID (Universally Unique Identifier) を主キーとして使用すると、一意性を強力に保証できます。UUID は分散システム間で一意になるように生成されるため、特に複数リージョンのデプロイで重要な競合を回避するのに役立ちます。
正しくないオプション -
オプション A: 現在のエポック時間:
現在のエポック時間を主キーとして使用すると、書き込み負荷の高いシナリオで問題が発生する可能性があります。複数のトランザクションが同時に発生すると、同じタイムスタンプが共有され、競合やパフォーマンスの問題が発生する可能性があります。
オプション B: 製品名と現在のエポック時間の連結:
オプション A と同様に、この選択では書き込み競合の問題が発生する可能性があります。同じ商品の複数の販売が同時に発生すると、同じキーを共有し、パフォーマンスのボトルネックにつながる可能性があります。
オプション D: 販売システムからの元の注文識別番号 (単調に増加する整数)。
単調に増加する整数は特定のシナリオに適している可能性がありますが、すべてのユース ケースに最適な選択であるとは限りません。特に書き込み集中型の状況では、ホットスポットや不均一なデータ分散につながる可能性があります。注文が必ずしも厳密な順序で到着するとは限らない販売システムでは、単調に増加する整数だけに頼ることは理想的ではない場合があります。
</div></details>

### Q. 質問23: 未回答
貴社のデータ アナリストは、プロジェクトで Cloud IAM オーナーのロールを保持し、さまざまな GCP プロダクトでの作業を円滑に進めます。会社のポリシーにより、BigQuery のデータ アクセスログを 6 か月間保持することが義務付けられています。あなたの仕事は、これらのログへのアクセスを、すべてのプロジェクトにわたって指定された監査担当者に制限することです。
これを達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 集計されたエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。エクスポートされたログを含むプロジェクトへのアクセスを制限します。
<details><div>
    答え：4
説明
社内の監査担当者のみがすべてのプロジェクトのデータアクセスログにアクセスでき、ログを 6 か月間保持できるようにするための正しいアプローチは、オプション D です。
オプション D: 
このオプションが最も適している理由は次のとおりです。
集約されたエクスポート シンク:集約されたエクスポート シンクを使用すると、複数のプロジェクトから 1 つの場所にログをエクスポートできるため、監査ログの一元的な管理とアクセスが容易になります。
クラウドストレージバケット:Cloud Storage バケットへのログのエクスポートは、ログを安全に保存するための一般的で効率的な方法です。
監査ログ用に新しく作成されたプロジェクト:監査ログ専用の別のプロジェクトを作成すると、ログを分離してセキュリティで保護するのに役立ちます。このプロジェクトにアクセスできるのは、許可された担当者のみです。
アクセスの制限:エクスポートされたログを含むプロジェクトでIAMポリシーとアクセス制御を設定することで、アクセスを監査担当者のみに制限し、許可された個人のみがログにアクセスして確認できるようにすることができます。
正しくないオプション -
オプション A: 各データ アナリストのプロジェクトでデータ アクセス ログを有効にします。Cloud IAM ロールによる Stackdriver Logging へのアクセスを制限します。
このオプションでは、各データ アナリストのプロジェクトでデータ アクセス ログを個別に有効にしてから、Stackdriver Logging へのアクセスを制限します。ただし、このオプションにはいくつかの欠点があります。
複雑さ：複数のプロジェクトでデータアクセスログを個別に有効にすることは、特にプロジェクトとデータアナリストの数が増えるにつれて、管理が複雑になる可能性があります。
限定的な中央集権化:ログは複数のプロジェクトに分散し、アクセス制御を効果的に一元化して管理することが困難になります。
潜在的なギャップ:個々のプロジェクト構成によっては、一部のログがキャプチャされず、監査にギャップが生じる可能性があります。
限定的な保持制御:すべてのプロジェクトで一貫した保持期間を管理することは困難な場合があります。
オプション B: プロジェクトレベルのエクスポート シンクを介して、データ アナリストのプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。Cloud Storage バケットへのアクセスを制限します。
このオプションでは、各データアナリストのプロジェクト内の Cloud Storage バケットにログをエクスポートし、アクセスを制限します。問題は次のとおりです。
分散ストレージ:ログは複数のプロジェクトに分散され、中央監査が複雑になる可能性があります。
限定的な制御:データアクセスログの保持とアクセス制御は、プロジェクトごとに個別に管理されるため、統一されたポリシーを適用することは困難でした。
アクセスの複雑さ:プロジェクトごとに個々の Cloud Storage バケットのアクセス制御を管理するのは面倒な場合があり、権限の一貫性を確保するのは困難です。
オプション C: プロジェクトレベルのエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータ アクセス ログをエクスポートします。エクスポートされたログでプロジェクトへのアクセスを制限します。
このオプションでは、監査ログ用の新しいプロジェクトを作成しますが、個々のプロジェクトからログをエクスポートします。このアプローチには、次のような問題があります。
散在エクスポート:監査ログ用の中央プロジェクトを作成しても、ログは個々の Data Analyst プロジェクトからエクスポートされるため、一元化されません。
アクセス制御の複雑さ:ログを含む中央プロジェクトでのアクセス制御の管理は複雑になる可能性があり、アクセスを完全に一元化するわけではありません。
保持管理:一貫した保存期間を確保することは、依然として困難な場合があります。
</div></details>

### Q. 質問24: 未回答
組織内の各分析チームが、それぞれのプロジェクト内で BigQuery ジョブを運用し、プロジェクト固有のスロットの使用状況を効果的にモニタリング、追跡できるようにするにはどうすればよいでしょうか。
1. 
2. BigQuery の指標スロット数 / allocated_for_projectに基づいて Cloud Monitoring ダッシュボードを作成する
3. 
4. 
<details><div>
    答え：2
説明
B. 
その理由は次のとおりです。
BigQuery にはスロット割り当て用のネイティブ指標が用意されており、スロット数/allocated_for_project指標はプロジェクトに割り当てられたスロット数を追跡するために特別に設計されています。このメトリックを使用すると、プロジェクト・レベルでスロットの使用状況をモニターできます。
このネイティブ指標に基づいて Cloud Monitoring ダッシュボードを作成することは、各分析チームのプロジェクトのスロットの使用状況をモニタリングする最も簡単で正確な方法です。
正しくないオプション -
A. BigQuery 指標クエリに基づいて Cloud Monitoring ダッシュボードを作成するscanned_bytes
このメトリックは、スロット割り当てではなくクエリによってスキャンされたデータに関連しており、プロジェクト レベルでのスロットの使用状況に関する直接的な分析情報は提供されません。
C. 各プロジェクトのログ エクスポートを作成し、BigQuery ジョブ実行ログをキャプチャし、totalSlotM に基づいてカスタム指標を作成し、カスタム指標に基づいて Cloud Monitoring ダッシュボードを作成します
このオプションには、ログのエクスポート、カスタムメトリックの作成、ダッシュボードの構成など、より複雑な設定が含まれます。可能ですが、より複雑で、ネイティブのスロット/allocated_for_projectメトリックと同じレベルの精度と使いやすさが得られない場合があります。
D. 組織レベルで集計ログのエクスポートを作成し、BigQuery ジョブの実行ログをキャプチャし、totalSlotMs に基づいてカスタム指標を作成し、カスタム指標に基づいて Cloud Monitoring ダッシュボードを作成します
オプションCと同様に、これには複雑なセットアップが必要であり、目的であるプロジェクトレベルでのきめ細かな監視が提供されない可能性があります。さらに、組織レベルでのログのエクスポートは、プロジェクト固有の監視に効率的でないか、必要ではない場合があります。
</div></details>

### Q. 質問25: 未回答
あなたはストリーミング Cloud Dataflow パイプラインを担当しています。エンジニアは、個別のウィンドウ処理アルゴリズムとトリガー戦略を組み込んだ新しいバージョンのパイプラインを開発しました。目的は、更新中のすべてのデータの保持を保証しながら、この新しいバージョンで既存の実行中のパイプラインをアップグレードすることです。
どうすればこれを実現できますか?
1. 
2. 
3. 
4. [ドレイン] オプションを使用して Cloud Dataflow パイプラインを停止します。更新されたコードで新しい Cloud Dataflow ジョブを作成します。
<details><div>
    答え：4
説明
D. 
正しい説明は次のとおりです。
オプション D では、既存の Cloud Dataflow パイプラインを [ドレイン] オプションで停止します。「ドレーン」オプションを使用すると、既存のジョブは停止する前に残りのデータの処理を完了できます。ドレインが完了したら、更新したコードで新しい Cloud Dataflow ジョブを作成し、開始できます。このアプローチにより、新しいジョブに移行する前にすべてのデータが古いジョブによって処理され、データ損失が最小限に抑えられ、スムーズな移行が保証されます。
誤ったオプション-
オプション A では、同じジョブ名を使用して --update オプションで既存のジョブを更新すると、更新で問題やデータ損失が発生した場合、実行中のジョブに影響を与える可能性があるため、リスクが伴う可能性があります。クリーンな移行は提供されません。
オプション B では、新しい一意のジョブ名を使用して --update オプションで既存のジョブを更新することが有効なアプローチになる場合がありますが、2 つのジョブが同時に実行される可能性があり、リソースが限られている場合は望ましくない可能性があります。
オプション C の [キャンセル] オプションを使用して Cloud Dataflow パイプラインを停止すると、既存のジョブが突然停止し、データの損失や処理の不完全な状態につながる可能性があります。スムーズな移行には適していません。
</div></details>

### Q. 質問26: 未回答
送信ネットワーク容量が 20 Mb/秒に制限されている場合、6 か月間に 2 PB の履歴データをオンプレミス ストレージ アプライアンスから Cloud Storage に転送するにはどうすればよいでしょうか?
1. Transfer Appliance を使用してデータを Cloud Storage にコピーする
2. 
3. 
4. 
<details><div>
    答え：1
説明
正しいオプションは A. Transfer Appliance を使用してデータを Cloud Storage にコピーする です。
Transfer Appliance は、大規模なデータ転送を容易にするために Google が提供する物理デバイスです。2 PB の履歴データを 6 か月以内に移行するという制約と、送信ネットワーク容量が 20 Mb/秒に制限されていることを考えると、Transfer Appliance を使用するのが最も効率的で効果的なアプローチです。Transfer Appliance を使用すると、大量のデータをアプライアンスにオフラインでコピーし、それを Google に返送して Cloud Storage に直接データを取り込むことができます。この方法では、ネットワークの制約が回避され、大規模なデータセットを高速かつ確実に転送できます。
正しくないオプション -
オプション B (コンテンツの圧縮に使用) は、ここでの主な制約は送信ネットワーク容量の制限であり、データを圧縮してもそれには対処されないため、大きな利点が得られない可能性があります。gsutil cp -J
オプション C (ストレージ転送サービスを使用) では、インターネットを使用してデータを転送しますが、ネットワーク容量が限られているため、効率的ではない可能性があります。
オプション D ( を使用、または ) は、 によって使用される帯域幅を制限することを目的としていますが、このような大量のデータをタイムリーに転送するには、最も効果的なソリューションではない可能性があります。trickleionicegsutil cpgsutil cp
参考リンク -
データ転送:- https://cloud.google.com/products/data-transfer/
</div></details>

### Q. 質問27: 未回答
サードパーティからCSV形式の月次データファイルを定期的に受信しており、データクレンジングのソリューションが必要です。ただし、ファイル スキーマは 3 か月ごとに変更されます。このトランスフォーメーションプロセスの主な要件は次のとおりです。
- 変換の実行をスケジュールする。
- 開発者以外のアナリストが変換を変更できるようにする。
- 変換を設計するためのグラフィカルツールを提供します。
これらの要件を満たすには、どのような手順またはアプローチを取る必要がありますか?
1. Dataprep by Trifacta を使用して変換レシピを構築および管理し、スケジュールに基づいて実行する
2. 
3. 
4. 
<details><div>
    答え：1
説明
要件に最適なオプションは、A. Dataprep by Trifacta を使用して変換レシピを構築および管理し、スケジュールに基づいて実行することです。
その理由は次のとおりです。
スケジュールに従った変換の実行: Dataprep by Trifacta では、変換レシピの実行をスケジュールできます。定期的なジョブを設定して、受信する月次 CSV データを自動的に処理できます。
デベロッパー以外のアナリストが変換を変更できるようにする: Dataprep は、コーディングのスキルを必要としない、使いやすいグラフィカル インターフェースを提供します。デベロッパー以外のアナリストは、Dataprep が提供するビジュアル ツールを使用して変換を設計、変更できます。
変換をデザインするためのグラフィカル ツールの提供: Dataprep は、データ変換レシピをデザインするためのビジュアル インターフェースを提供します。アナリストは、コードを記述することなく、これらの変換を簡単に作成、変更、およびテストできます。
正しくないオプション -
オプション B(BigQuery にデータを読み込み、SQL クエリを使用する)は、固定スキーマでは機能する可能性がありますが、3 か月ごとのスキーマ変更に対応できる柔軟性はありません。また、開発者以外のアナリストに必要なグラフィカル ツールも提供されません。
オプション C(Python で Dataflow パイプラインを記述する)はコーディングを伴い、特にデベロッパー以外のアナリストにとっては使い勝手が悪い場合があります。また、スキーマの変更を処理するために、かなりの開発作業が必要です。
オプション D(Dataproc で Apache Spark を使用)は、より複雑な設定が必要で、アナリストにとって使い勝手が悪い場合があります。また、グラフィカルで開発者に適していない側面も強調されていません。
</div></details>

### Q. 質問28: 未回答
オンプレミスの Hadoop セットアップを Cloud Dataproc に移行することを目指しており、Hive が主要なツールであり、Optimized Row Columnar(ORC)がデータ形式です。これで、すべての ORC ファイルが Cloud Storage コンテナに効果的に転送されました。パフォーマンスを向上させるには、特定のデータをクラスターのローカルの Hadoop Distributed File System (HDFS) に複製する必要があります。
Cloud Dataproc 内で Hive の使用を開始するには、どのような方法がありますか?(2つ選択)
1. gsutil ユーティリティを実行して、すべての ORC ファイルを Cloud Storage バケットから HDFS に転送します。Hive テーブルをローカルにマウントします。
2. 
3. 
4. Cloud Storage Connector for Hadoop を活用して、ORC ファイルを外部 Hive テーブルとしてマウントします。外部 Hive テーブルをネイティブ テーブルにレプリケートします。
<details><div>
    答え：1,4
説明
オプション A: 
このオプションでは、gsutil を使用して Cloud Storage から Dataproc クラスタ上の Hadoop Distributed File System(HDFS)に ORC ファイルをコピーします。その後、HDFSのデータの上にHiveテーブルを作成し、ローカルにマウントできます。
オプション D: 
このオプションでは、Cloud Storage Connector for Hadoop を使用して Cloud Storage 内の ORC ファイルに直接アクセスし、それらに基づいて外部 Hive テーブルを作成します。これらの外部 Hive テーブルからネイティブ Hive テーブルにデータをレプリケートできます。
パフォーマンスを最適化するためにデータをHDFSに複製する場合は、オプションAが適切な選択です。データをHDFSに複製せずに外部表を操作する場合は、オプションDが適切です。
</div></details>

### Q. 質問29: 未回答
特定の順序に従う必要があり、シェル スクリプトの実行、Hadoop ジョブの実行、BigQuery でのクエリの実行を含む、相互に依存する複数のステップを持つバッチ ジョブを管理するプロセスでは、数分から数時間の範囲で、障害が発生した場合に一定の再試行が必要になると予想されますが、ジョブの実行を監視するためにどのサービスを採用する必要がありますか?
1. 
2. 
3. 
4. Cloud Composer
<details><div>
    答え：4
説明
相互に依存するステップ、再試行、特定の注文要件を持つ複雑なバッチ ジョブの実行を管理するには、Cloud Composer(オプション D)を使用する必要があります。
Cloud Composer は、Apache Airflow 上に構築されたフルマネージドのワークフロー オーケストレーション サービスです。これにより、ワークフローを有向非巡回グラフ (DAG) として定義、スケジュール、および監視できます。タスク間の依存関係を持つ複雑なワークフローを作成したり、再試行ポリシーを指定したり、タスクの実行順序を設定したりできます。さらに、シェル スクリプトの実行、Hadoop ジョブ、BigQuery クエリなど、さまざまな GCP サービスをワークフローに統合できます。
正しくないオプション -
Cloud Scheduler(オプション A)は、主にスケジュールに従って HTTP/S エンドポイントまたは Pub/Sub トピックをトリガーするように設計されています。タスク間の依存関係を持つ複雑なワークフローの管理には適していません。
Cloud Dataflow(オプション B)は、汎用のバッチ ジョブ オーケストレーションよりも、データ処理やストリーム処理のジョブに適しています。
Cloud Functions(オプション C)は、サーバーレスのイベントドリブン関数向けに設計されているため、依存関係のある実行時間の長い複雑なバッチ ジョブの管理には適していない可能性があります。
</div></details>

### Q. 質問30: 未回答
あなたは、荷物が仕分けのために配送ラインを通過する配送センターを運営する運送会社に雇用されています。同社は、配送ラインにカメラを導入することで、荷物の取り扱いプロセスを強化することを目指しています。これらのカメラは、輸送中のパッケージの視覚的な損傷を特定して監視することを目的としています。あなたの仕事は、損傷したパッケージをリアルタイムで検出し、その後、輸送中の人間によるレビューのためにそのようなパッケージにタグを付けるための自動化システムを考案することです。このシナリオに最も適したソリューションはどれですか?
1. 
2. AutoML モデルをトレーニングする
3. 
4. 
<details><div>
    答え：2
説明
オプション B ():
カスタマイズ：AutoML (Auto Machine Learning) を使用すると、特定のデータセット (この場合は破損したパッケージの画像) に基づいてカスタム機械学習モデルをトレーニングできます。
統合：AutoML モデルを中心に API を構築できるため、パッケージ追跡アプリケーションと簡単に統合でき、リアルタイム分析が可能になります。
精度：カスタム モデルは、多くの場合、汎用モデルと比較して、特定のタスクに対してより高い精度を提供します。
正しくないオプション -
オプション C (Cloud Vision API を使用):
使いやすさ:Cloud Vision API は、一般的なユースケース向けに事前トレーニング済みのモデルを提供するマネージド サービスです。物体や一部の損傷を検出できますが、パッケージの特定の種類の損傷を特定するなど、高度に専門的なタスクでは精度が低くなる可能性があります。
カスタマイズ：これは、パッケージに固有の微妙な損傷タイプを検出するためのカスタムトレーニング済みモデルほど柔軟ではない可能性があります。
オプション D(TensorFlow と Datalab を使用):
複雑さ：カスタム TensorFlow モデルを構築して維持するには、データの前処理、モデルのトレーニング、デプロイなど、多大な開発作業が必要です。これは複雑で時間がかかる場合があります。
リアルタイム検出:リアルタイムの検出と荷物追跡アプリケーションとの統合には、追加のインフラストラクチャと開発作業が必要になります。
オプション A(BigQuery 機械学習を使用する):
バッチ処理:BigQuery の機械学習は、リアルタイムの画像分析ではなく、バッチ処理とデータ分析用に設計されています。輸送中の荷物の損傷を検出するのには適していません。
</div></details>

### Q. 質問31: 未回答
データ ウェアハウスを BigQuery に移行し、データをデータセット テーブルに統合すると、組織内のさまざまなユーザーのアクセスを制御する必要が生じます。具体的には、ユーザーがチーム メンバーシップに基づいて特定のテーブルのみを表示してアクセスできるようにします。BigQuery でこのテーブルレベルのアクセス制御を実現するためにユーザー権限を構成するには、どのような方法が推奨されますか?
1. 各テーブルのテーブル レベルでユーザー/グループのデータ閲覧者アクセス権を割り当てます
2. 
3. 
4. 
<details><div>
    答え：1
説明
正しいオプション: オプション A - 。
BigQuery では、データセット レベルとテーブル レベルの両方でアクセス制御を割り当てることができます。
テーブル レベルでのデータ閲覧者アクセス権の割り当ては、データセット内の特定のテーブルへのアクセス権をユーザーまたはグループに付与し、他のユーザーへのアクセスを制限する場合に適しています。
このオプションを使用すると、アクセス許可を微調整して、ユーザーが必要なテーブルにのみアクセスできるようにし、同じデータセット内の他のユーザーへのアクセスを拒否できるようにすることができます。
各テーブルにはアクセス制御リスト (ACL) を定義できるため、ユーザーまたはチームの要件に基づいてきめ細かく制御できます。
正しくないオプション -
オプション B (同じデータセット内の各チームの SQL ビューを作成する):
SQL ビューは、データ アクセス用の抽象化レイヤーを提供できますが、基になるテーブルへのアクセスを本質的に制限するものではありません。
ビューを含むデータセットへのアクセス権を持つユーザーは、追加のアクセス制御が適用されない限り、ベース テーブルを直接クエリできる可能性があります。
オプション C (同じデータセット内の各チームの承認済みビューを作成する):
許可されたビューは、通常、異なるテーブルへのアクセスを制御するためではなく、テーブル内の列のサブセットへのアクセスを提供する場合に使用されます。
これらは、チーム メンバーシップに基づいてテーブル レベルでアクセスを制御するようには設計されていません。
オプション D (チームごとに個別のデータセットで承認されたビューを作成する):
このオプションは非常に複雑であり、1 つのデータセット内のチーム メンバーシップに基づいてテーブルへのアクセスを制御するためには必要ありません。
複数のデータセットを作成して管理する必要があり、管理オーバーヘッドにつながる可能性があります。
</div></details>

### Q. 質問32: 未回答
マネージドHadoopシステムをデータレイクとして構築したい。データ変換プロセスは、順番に実行される一連のHadoopジョブで構成されます。ストレージとコンピューティングを分離する設計を実現するために、Cloud Storage コネクタを使用して、すべての入力データ、出力データ、中間データを保存することにしました。ただし、オンプレミスのベアメタル Hadoop 環境(100 GB の RAM を搭載した 8 コア ノード)と比較すると、Cloud Dataproc では 1 つの Hadoop ジョブの実行が非常に遅いことに気付きました。分析によると、この特定のHadoopジョブはディスクI/Oを大量に消費します。問題を解決したい。あなたは何をするべきか?
1. 
2. Hadoopクラスターに十分な永続ディスク領域を割り当て、その特定のHadoopジョブの中間データをネイティブHDFSに格納します。
3. 
4. 
<details><div>
    答え：2
説明
正しいオプションは次のとおりです。
B. 
このオプションが正しい理由は次のとおりです。
問題のHadoopジョブは、ディスクI/Oのために低速であり、ストレージとの間でのデータの読み取りと書き込みによってボトルネックになっています。
Hadoopクラスタに十分な永続ディスク容量を割り当て、中間データをネイティブHDFS(Hadoop Distributed File System)に保存することで、パフォーマンスを大幅に向上させることができます。
HDFSは分散データストレージ向けに最適化されており、オブジェクトストレージサービスであるCloud Storageと比較して、データの読み取りおよび書き込み操作が大幅に高速化されます。中間データを HDFS に保存すると、Cloud Storage のデータへのアクセスに関連するネットワーク レイテンシとオーバーヘッドが削減されます。
このアプローチでは、中間データ ストレージに HDFS の利点を活用しながら、長期ストレージに Cloud Storage を使用し、ストレージをコンピューティングから切り離します。
誤ったオプション-
A. より多くのメモリを割り当てると、ジョブのパフォーマンスの特定の側面に役立つ場合がありますが、ディスク I/O のボトルネックに直接対処できない場合があります。
C. CPU コアまたはインスタンスの割り当てを増やしても、問題は CPU バウンドの処理ではなくデータ アクセス速度に関連しているため、ディスク I/O の問題が解決する可能性は低いです。
D. ネットワークインターフェイスの追加やリンクアグリゲーションの設定は、ネットワーク帯域幅に関するものであり、Hadoopジョブが直面しているディスクI/Oの問題に直接対処するものではありません。
</div></details>

### Q. 質問33: 未回答
広告会社に勤務し、広告ブロックのクリックスルー率を予測するためのSpark MLモデルを作成しました。以前はオンプレミスのデータセンターで作業していましたが、データセンターの閉鎖が間近に迫っているため、会社は Google Cloud に移行しています。データを BigQuery に移行し、Spark ML モデルを定期的に再トレーニングするため、既存のトレーニング パイプラインを Google Cloud に迅速に移行する必要があります。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 既存の Spark ML モデルのトレーニングには Dataproc を使用しますが、BigQuery から直接データの読み取りを開始します。
4. 
<details><div>
    答え：3
説明
オプション C: 
このオプションは、Google Cloud への移行中に既存の Spark ML モデルを移行する場合に適しています。これが正しいオプションである理由は次のとおりです。
Dataproc の互換性:Google Cloud Dataproc は、Spark やその他のビッグデータ フレームワークをシームレスに実行できるように設計されています。これにより、大規模な書き換えを行うことなく、既存の Spark ML モデルを引き続き使用できます。
BigQuery との統合:Dataproc は BigQuery からデータを直接読み取ることができるため、BigQuery に保存されているデータで Spark ML モデルを効率的にトレーニングできます。この統合により、データの移動が最小限に抑えられ、複雑さと遅延が軽減されます。
正しくないオプション -
A. トレーニングに Vertex AI を使用する: Vertex AI は Google Cloud の強力な機械学習プラットフォームですが、主に TensorFlow モデルと scikit-learn モデルをサポートしています。既存の Spark ML モデルを Vertex AI に移行するには、大幅な変更が必要になる場合があり、迅速なリフト&シフト移行に対応できない場合があります。
B. TensorFlow でモデルを書き換え、Vertex AI を使用する: このオプションでは、既存の Spark ML モデルを TensorFlow で書き換える必要がありますが、これには時間がかかり、迅速な移行には適さない場合があります。
D. Compute Engine で Spark クラスタを起動する: Compute Engine で Spark を実行することもできますが、このオプションではインフラストラクチャを自分で設定して管理する必要があります。移行プロセスが複雑になる可能性があり、この特定のシナリオでは Dataproc と BigQuery の統合を使用する明確なメリットはありません。
</div></details>

### Q. 質問34: 未回答
あなたは、配送ラベルを読み取るためにハンドヘルドスキャナーを採用している配送会社に雇用されています。同社は厳格なデータプライバシー規制を遵守しており、イベントが生成されたときにのみスキャナーが追跡番号をKafkaトピックに送信することを義務付けています。最近のソフトウェアアップデートにより、これらのスキャナーは受信者の個人を特定できる情報(PII)を誤って分析システムに送信し始め、ユーザーのプライバシー規制を侵害しました。クラウドネイティブなマネージドサービスを使用してスケーラブルなソリューションを迅速に確立し、分析システムへのPIIの露出を防ぐには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. トピックを読み取り、Cloud Data Loss Prevention(Cloud DLP)API を呼び出す Cloud Functions の関数を作成します。タグ付けレベルと信頼度レベルを使用して、レビューのためにバケット内のデータを渡すか隔離します。
<details><div>
    答え：4
説明
クラウドネイティブなマネージドサービスを使用してスケーラブルなソリューションを迅速に構築し、分析システムへのPIIの公開を防ぐには、次のことを行う必要があります。
D. 
このオプションが適切な理由は次のとおりです。
Cloud Functions: Cloud Functionsはサーバーレスでイベント駆動型であるため、Kafkaトピックに到着したデータを効率的に処理できます。
Cloud Data Loss Prevention(Cloud DLP)API: Cloud DLP は、PII などの機密データを特定して保護するように設計されています。Cloud DLP API を呼び出すことで、受信データの PII をスキャンできます。
タグ付けと信頼度: Cloud DLP は、検出された機密情報のタグ付けと信頼度を提供します。これらのタグと信頼度を使用して、データを渡すか、レビューのために検疫するかを決定できます。
このソリューションにより、機密情報が分析システムに到達する前に適切に識別および処理され、データプライバシー基準への準拠を維持できます。
オプション D は、Cloud Functions と Cloud DLP API を利用して、到着したデータをスキャンして処理することで、データ プライバシー基準へのコンプライアンスを確保しながら、PII が分析システムに公開されるのを防ぐためのスケーラブルで効果的なアプローチを提供します。
正しくないオプション -
オプション A(BigQuery で承認済みビューを作成する): このオプションでは、BigQuery のデータへのアクセスを制御することに重点を置いていますが、そもそも機密データが分析システムに到達するのを防ぐことはできません。
オプション B(サードパーティのデータ検証ツールを Compute Engine 仮想マシンにインストールする): データ検証ツールは便利ですが、複雑さが増し、クラウドネイティブ ソリューションほどスケーラブルで費用対効果が高くない可能性があります。
オプション C(Cloud Logging を使用してデータを分析): Cloud Logging はログの分析に役立ちますが、データが流出したときに積極的に防止するよりも、後処理やモニタリングに適しています。
</div></details>

### Q. 質問35: 未回答
これで、3 つのデータ処理タスクが作成されました。1 つ目は、Cloud Storage に保存されているデータを変換し、その結果を BigQuery に読み込むための Cloud Dataflow パイプラインを実行します。2 つ目のタスクでは、オンプレミス サーバーからデータを取り込み、Cloud Storage にアップロードします。3 つ目のタスクは、サードパーティ プロバイダからデータを取得して Cloud Storage にアップロードする Cloud Dataflow パイプラインで構成されています。要件は、これら 3 つのワークフローのスケジューリングおよび監視システムを確立し、必要に応じて手動で実行できるようにすることです。これを達成するには、どのような手順を踏む必要がありますか?
1. Cloud Composer で直接非巡回グラフを作成し、ジョブをスケジュールしてモニタリングします。
2. 
3. 
4. 
<details><div>
    答え：1
説明
これら 3 つのデータ処理ジョブの実行をスケジュールして監視し、必要に応じて手動で実行するには、次の操作を行う必要があります。
A. 
このオプションが適切な理由は次のとおりです。
Cloud Composer: Cloud Composer は、Apache Airflow 上に構築されたフルマネージドのワークフロー オーケストレーション サービスです。これにより、複雑なワークフローを簡単に定義、スケジュール、および監視できます。
スケジュールされた実行: Cloud Composer で DAG(Direct Acyclic Graphs)を作成して、指定した間隔または時間にデータ処理ジョブの実行をスケジュールできます。
モニタリング: Cloud Composer にはモニタリング機能とロギング機能が組み込まれており、ジョブの進行状況の追跡、ログの表示、問題のトラブルシューティングを行うことができます。
手動実行: 必要に応じて Cloud Composer で DAG を手動でトリガーできるため、オンデマンドでジョブを柔軟に実行できます。
正しくないオプション -
オプション B(Stackdriver Monitoring を使用し、Webhook でアラートを設定する): Stackdriver Monitoring はモニタリング機能を提供できますが、Cloud Composer のようなワークフローのスケジュール設定機能やオーケストレーション機能は提供しません。
オプション C(App Engine アプリケーションの開発): ジョブのスケジュール設定とモニタリング用にカスタム App Engine アプリケーションを構築するには、追加の開発作業とメンテナンスが必要になります。Cloud Composer は、よりわかりやすいソリューションです。
オプション D(Compute Engine インスタンスで cron ジョブを設定する): Compute Engine での cron ジョブの使用は拡張性が低く、ジョブの実行とモニタリングに手動のスクリプトが必要になる場合がありますが、Cloud Composer はマネージドで統合されたソリューションを提供します。
Cloud Composer は、クラウドネイティブ環境でのデータ処理ジョブのスケジューリング、モニタリング、オーケストレーションに特化して構築されており、お客様の要件に最適なオプションです。
参考リンク -
https://cloud.google.com/composer/docs/how-to/using/writing-dags
</div></details>

### Q. 質問36: 未回答
Node.js で記述された Cloud Functions があり、Cloud Pub/Sub からメッセージを取得して BigQuery にデータを送信します。Pub/Sub トピックのメッセージ処理速度が予想よりも桁違いに高いことがわかりますが、Cloud Logging にはエラーは記録されません。この問題の最も可能性の高い 2 つの原因は何ですか?(2つ選択してください。
1. 
2. 
3. サブスクライバー コードでのエラー処理がランタイム エラーを適切に処理していません。
4. 
<details><div>
    答え：3
説明
C. 
このオプションは、サブスクライバー コードで適切に処理されないランタイム エラーが検出されると、メッセージ処理フローが中断される可能性があるため、正しい方法です。未処理のエラーにより、サブスクライバーがメッセージの処理を停止し、バックログが発生する可能性があります。また、エラーの詳細が正しく記録されていない場合、Cloud Logging にエラー メッセージが表示されず、トラブルシューティングが困難になる可能性があります。
E.サブスクライバー・コードは、プルするメッセージを確認しません。
Cloud Pub/Sub はメッセージが正常に処理されたかどうかをメッセージ確認に基づいて判断するため、このオプションは正しいです。処理後にサブスクライバー コードがメッセージを確認しない場合、Pub/Sub はメッセージが未処理であると見なして再配信するため、メッセージの処理速度が効果的に向上します。メッセージのフローを維持するためには、メッセージを適切に確認することが重要です。
正しくないオプション -
A. パブリッシャーのスループット クォータが小さすぎます。
このオプションは、パブリッシャーのスループット クォータがメッセージが Pub/Sub トピックにパブリッシュされるレートに関連しているため、問題の原因となる可能性は低くなります。サブスクライバーがメッセージを消費および処理できる速度には直接影響しません。パブリッシャーのスループット クォータを超えた場合、メッセージの発行に影響を与える可能性がありますが、サブスクライバー側のメッセージ処理速度が急激に増加することはありません。
B. 未処理のメッセージの合計が最大 10 MB を超えています。
また、このオプションは、観察された問題の原因である可能性も低くなります。10 MB の最大制限は、通常、個々のメッセージのサイズを指します。この制限を超えると、メッセージ サイズの問題が発生する可能性がありますが、メッセージ処理速度の大幅な増加には直接つながりません。これにより、メッセージのサイズに関連する問題が発生する可能性がありますが、メッセージの処理速度には関連しません。
D. サブスクライバ コードがメッセージに追いつかない。
Pub/Sub トピックのメッセージ処理レートが、Cloud Functions の関数サブスクライバー コードでメッセージを処理できるレートよりもはるかに高い場合、未処理のメッセージのバックログが発生します。
正しいオプションは C と E で、サブスクライバー コードの問題と、メッセージを適切に処理および確認する機能に直接関連しているため、観察された問題につながる可能性があります。
</div></details>

### Q. 質問37: 未回答
Google Cloud で新しいパイプラインを作成し、Cloud Pub/Sub から Cloud Dataflow を介して BigQuery に IoT データをストリーミングします。データをプレビューしていると、データの約 2% が破損しているように見えます。Cloud Dataflow パイプラインを変更して、この破損したデータを除外する必要があります。あなたは何をするべきか?
1. 
2. Cloud Dataflow に ParDo 変換を追加して、破損した要素を破棄します。
3. 
4. 
<details><div>
    答え：2
説明
回答: B. 
Cloud Dataflow に ParDo 変換を追加することは、破損したデータを除外するための最良の方法です。SideInput は、要素が破損している場合に Boolean を返しますが、実際には要素を破棄しません。パーティション変換では、有効なデータと破損したデータを分離できますが、破損したデータは破棄されません。GroupByKey 変換では、すべての有効なデータをグループ化できますが、破損したデータは破棄されません。
</div></details>

### Q. 質問38: 未回答
過去 3 年間の履歴データが BigQuery に保存され、毎日データ パイプラインが新しいデータにフィードされるため、データ サイエンス チームによるクエリで 30 日から 90 日分のデータの日付列をフィルタリングすると、テーブル全体がスキャンされ、費用が増加することがわかりました。目的は、SQL クエリ機能を維持しながら、この問題に効率的に対処することです。
最も費用対効果の高いソリューションは何ですか?
1. DDL を使用してテーブルを再作成します。TIMESTAMP型またはDATE型を含む列でテーブルをパーティション分割します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
BigQuery の履歴データに対して SQL クエリを実行する機能を維持しながら、クエリのパフォーマンスを最適化して費用を削減するには、パーティション分割の使用を検討する必要があります。オプション A は、TIMESTAMP または DATE 型を含む列でテーブルをパーティション分割することを推奨しており、最も適切なアプローチです。
A. 
このオプションは正しいです。BigQuery でのテーブルのパーティション分割は、クエリのパフォーマンスを最適化し、費用を削減する効果的な方法です。TIMESTAMP または DATE 列に基づいてテーブルをパーティション分割することで、データをより小さく、より管理しやすいパーティションに整理できるため、date 列をフィルター処理するクエリで、テーブル全体をスキャンするのではなく、関連するパーティションのみをスキャンできます。これにより、クエリのコストが大幅に削減され、クエリのパフォーマンスが向上します。
正しくないオプション -
テーブルを Cloud Storage の CSV ファイルにエクスポートするオプション B は、BigQuery で直接 SQL クエリを実行する機能を維持したい場合、実用的なソリューションではありません。
オプション C では、データを 2 つのテーブル (最近と履歴) に分割することを提案しており、最近のデータのクエリ コストを削減するのに役立ちますが、大規模なデータセットのパーティション分割ほど効率的ではない可能性があります。これにより、データの管理とクエリが複雑になる可能性があります。
オプション D では、1 日ごとに個別の BigQuery テーブルを作成することを提案していますが、時間の経過とともにテーブルの数が多くなり、データの効率的な管理とクエリが困難になる可能性があります。パーティション分割は、よりスケーラブルでコスト効率の高いアプローチです。
</div></details>

### Q. 質問39: 未回答
あなたは、車両ベースのセンサーからのイベント配信の信頼性を高めることを目的とした物流会社を経営しています。イベントキャプチャ用のグローバルデータセンターを維持します。ただし、イベント収集インフラストラクチャーをイベント処理インフラストラクチャーに接続する専用回線は、待ち時間が不確実であるため、一貫性がありません。
コストを最小限に抑えながら、これに対処するにはどうすればよいでしょうか。
1. 
2. データ取得デバイスで Cloud Pub/Sub にデータをパブリッシュします。
3. 
4. 
<details><div>
    答え：2
説明
正解は B.
Cloud Pub/Sub は、アプリケーションとサービス間でデータを送受信できるフルマネージドのリアルタイム メッセージング サービスです。これにより、リモート・データ・センターからイベント処理インフラストラクチャーに、確実かつコスト効率よくデータを配信できます。これは、遅延が予測できない信頼性の低い専用回線の問題に対処するための最も費用対効果の高い方法です。
正しくないオプション -
A: 小規模な Kafka クラスターをデータセンターにデプロイしてイベントをバッファリングしても、レイテンシーが予測できない信頼性の低い専用回線の問題には対処できません。
C: すべてのリモート データセンターと Google の間にクラウド インターコネクトを確立しても、遅延が予測できない信頼性の低い専用回線の問題には対処できません。
D: セッション ウィンドウ内のすべてのデータを集約する Cloud Dataflow パイプラインを作成しても、レイテンシが予測できない信頼性の低い専用回線の問題には対処できません。
</div></details>

### Q. 質問40: 未回答
Google Homeなどのさまざまな在宅アシスタントとのオンライン販売の統合を強化することを目指している小売業者として、顧客の音声コマンドを解釈し、バックエンドシステム内で注文を開始するには、どのようなソリューションを選択する必要がありますか?
1. 
2. 
3. Dialogflow Enterprise エディション
4. 
<details><div>
    答え：3
説明
Google Home などの在宅アシスタントとの統合のコンテキストで顧客の音声コマンドを解釈し、バックエンド システムに注文を発行するには、次のものを選択する必要があります。
C. 
Dialogflow は、チャットボットや音声起動アプリケーションなどの会話型インターフェースの作成に特化して設計されています。これにより、自然言語でユーザー入力を理解して応答できるため、顧客からの音声コマンドを解釈するのに適しています。
その他のオプション(A、B、D)は Google Cloud エコシステムの重要なコンポーネントですが、それぞれ目的が異なります。
Speech-to-Text API (オプション A): この API は、音声言語を書き言葉に変換するために使用されます。音声コマンド処理のコンポーネントにはなりますが、Dialogflow が提供する自然言語理解や会話管理機能は提供されません。
Cloud Natural Language API(オプション B): この API は、感情分析やエンティティ認識など、テキストから分析情報を分析および抽出するために使用されます。これは主に、リアルタイムの会話で音声コマンドを解釈するために設計されたものではありません。
AutoML Natural Language (オプション D): AutoML Natural Language を使用すると、自然言語理解タスク用のカスタム機械学習モデルを構築できます。強力ではありますが、音声コマンドの解釈に Dialogflow などの専用ツールを使用する場合と比較して、より多くの開発作業が必要になる場合があります。
音声コマンド処理と会話管理には、提供されているオプションの中から Dialogflow Enterprise Edition が最も適しています。
</div></details>

### Q. 質問41: 未回答
異なるクラウドプロバイダーサービス間のデータ移動と、これらの各プロバイダーからのサービスの利用を含む複雑なデータパイプラインを持つ企業のハイブリッドクラウドイニシアチブのコンテキストでは、パイプライン全体をオーケストレーションするのに最も適した特定のクラウドネイティブサービスはどれですか?
1. 
2. Cloud Composer
3. 
4. 
<details><div>
    答え：2
説明
正解は B. Cloud Composer です。
Cloud Composer は、複数のクラウド プロバイダにまたがる複雑なデータ パイプラインのオーケストレーションに使用されるクラウドネイティブ サービスであるため、正しい選択です。Cloud Dataflow はデータ パイプラインと ETL ジョブを作成するためのマネージド サービス、Cloud Dataprep はデータ ラングリング サービス、Cloud Dataproc はマネージド Spark および Hadoop サービス、Cloud Functions はサーバーレス コンピューティング サービスです。これらのサービスはいずれも、複数のクラウドプロバイダーにまたがる複雑なデータパイプラインをオーケストレーションするために設計されたものではありません。
参考リンク -
https://cloud.google.com/composer#
</div></details>

### Q. 質問42: 未回答
サードパーティ企業に分析のために BigQuery のデータセットへのアクセス権を付与する際に、データの鮮度を維持し、データ共有費用を最小限に抑えるには、どのソリューションを選択すればよいでしょうか?
1. Analytics Hub を使用してデータ アクセスを制御し、サードパーティ企業にデータセットへのアクセスを提供します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
Analytics Hubを使用してデータアクセスを制御することは、コストを低く抑え、データを最新の状態に保ちながら、サードパーティ企業にデータセットへのアクセスを提供できるため、最適なソリューションです。
正しくないオプション -
Cloud Scheduler はジョブとタスクのスケジュール設定に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション B は正しくありません。
BigQuery で別のデータセットを作成することは、最も費用対効果の高いソリューションではなく、データが最新であることを保証できないため、オプション C は正しくありません。
Dataflow はデータの処理と変換に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション D は正しくありません。
</div></details>

### Q. 質問43: 未回答
現在、オンプレミスのデータ ウェアハウス ソリューションを BigQuery に移行している会社では、さまざまなトランザクション データベース ソースからの更新を毎日適用するために、変更データ キャプチャ(CDC)プロセスを強化したいと考えています。この改善は、データ ウェアハウス変更アプリケーションのパフォーマンスの最適化に重点を置き、ログベースの CDC ストリームを介して BigQuery でソース システムからの変更にすばやくアクセスできるようにすることを目的としています。BigQuery レポートの表で変更を利用できるようにするためのレイテンシを最小限に抑えながら、コンピューティングのオーバーヘッドを削減するには、どの 2 つのアクションを実行すべきでしょうか。(2つ選択)
1. 
2. 新しい各 CDC レコードと対応する操作の種類をステージング テーブルにリアルタイムで挿入します。
3. 
4. DML MERGE を定期的に使用して、レポート テーブルで複数の DML INSERT、UPDATE、および DELETE 操作を同時に実行します。
5. 
<details><div>
    答え：2,4
説明
B. 
この手順は、ソース システムから変更をリアルタイムでキャプチャし、ステージング テーブルに格納するために不可欠です。ステージング テーブルは、受信 CDC データのバッファーを提供し、データをレポート表に移動する前に、必要なビジネス ロジックを検証、変換、および適用できます。このアプローチは、レポート データセットの一部になる前に、データの一貫性と正確性を確保するのに役立ちます。
D. 
定期的な MERGE 操作の使用は、累積された変更をステージング テーブルからレポート テーブルに適用するための効果的な戦略です。これにより、複数の CDC レコードを 1 つの DML 操作に統合し、個々の INSERT、UPDATE、または DELETE に関連するオーバーヘッドを削減できます。このアプローチにより、計算コストが最適化され、レポート テーブルを効率的に維持できます。
正しくないオプション -
A. DML INSERT、UPDATE、または DELETE を実行して、個々の CDC レコードをレポート テーブルに直接リアルタイムで直接レプリケートします。
このオプションを使用すると、すべての CDC レコードのレポート テーブルで個々の DML 操作が大量に発生する可能性があり、リソースを大量に消費し、最適なクエリ パフォーマンスが得られない可能性があります。
C. レポート テーブルから古いレコードを定期的に削除します。
古いレコードの削除はデータ管理に必要ですが、CDC データのほぼリアルタイムの処理要件には対応していません。このオプションは、タイムリーな更新ではなく、データ保持に重点を置いています。
E. 新しい各 CDC レコードと対応する操作の種類をレポート テーブルにリアルタイムで挿入し、具体化されたビューを使用して、一意の各レコードの最新バージョンのみを公開します。
具体化されたビューはクエリのパフォーマンスを最適化するのに役立ちますが、このアプローチでは CDC データ自体のリアルタイム処理には対応していません。具体化されたビューは、通常、集計または概要を事前に計算するために使用され、リアルタイムのデータキャプチャや変換用には設計されていません。
待機時間を最小限に抑え、コンピューティング オーバーヘッドを削減してほぼリアルタイムの CDC を実現するには、手順 B と D を組み合わせることをお勧めします。ステージング テーブル (B) で変更をリアルタイムでキャプチャし、これらの変更をレポート テーブル (D) に定期的にマージして、データセットを効率的に更新します。
</div></details>

### Q. 質問44: 未回答
負荷の増加に応じて自動的にスケーリングできるデータ処理パイプラインを設計し、メッセージが少なくとも 1 回処理されるようにし、1 時間以内に順序を維持する必要があります。このソリューションをどのように設計する必要がありますか?
1. 
2. 
3. 
4. メッセージの取り込みには Cloud Pub/Sub を使用し、ストリーミング分析には Cloud Dataflow を使用します。
<details><div>
    答え：4
説明
D. 
このオプションは、Cloud Pub/Sub と Cloud Dataflow の両方の長所を活用しているため、要件に適した選択肢となります。
Cloud Pub/Sub は、高スループットのメッセージ取り込みを処理できるマネージド メッセージング サービスです。これにより、メッセージの少なくとも 1 回分の配信が保証され、メッセージの順序を維持できるため、1 時間以内にメッセージを順序付けするという要件に合わせることができます。
Cloud Dataflow は、負荷に応じて自動的にスケーリングできるマネージド ストリームおよびバッチ データ処理サービスです。これにより、ウィンドウ処理やトリガーなどの処理パイプラインを定義して、リアルタイムまたは最小限のレイテンシーでデータを処理できます。この選択により、1 時間以内に目的のメッセージ処理を実現できます。
正しくないオプション -
A. メッセージの取り込みには Apache Kafka を使用し、ストリーミング分析には Cloud Dataproc を使用します。Apache Kafka はメッセージの取り込みに適しており、メッセージの順序を維持できますが、ストリーミング分析に Cloud Dataproc(マネージド Spark および Hadoop サービス)を使用すると、Cloud Dataflow と比較してリアルタイム処理の効率が低くなります。Cloud Dataproc は通常、バッチ処理やアドホック データ分析に使用されます。
B. メッセージの取り込みには Apache Kafka を使用し、ストリーミング分析には Cloud Dataflow を使用します。このオプションも有効な選択であり、うまく機能します。取り込みには Kafka を、ストリーミング分析には Cloud Dataflow を組み合わせています。私の以前の応答は、このオプションを誤って却下しました。見落としをお詫びします。
C. メッセージの取り込みに Cloud Pub/Sub を使用し、ストリーミング分析に Cloud Dataproc を使用します。前述したように、ストリーミング分析に Cloud Dataproc を使用することは、最も効率的な選択ではない可能性があります。Cloud Dataflow は、Google Cloud のエコシステムでのリアルタイム ストリーミング分析に適しています。
</div></details>

### Q. 質問45: 未回答
指定された条件を満たすには、BigQuery データへのアクセスを提供する必要があります。
- 各部門は、自分のデータにのみアクセスできるようにする必要があります。
- 各部門には、テーブルを作成および更新してチームに提供できる必要がある 1 人以上のリードがいます。
- 各部門にはデータアナリストがおり、データのクエリはできるが、変更はできない。
BigQuery のデータへのアクセスをどのように設定すればよいですか?
1. 
2. 部門ごとにデータセットを作成します。部門リーダーに WRITER の役割を割り当て、データ アナリストにデータセットの READER の役割を割り当てます。
3. 
4. 
<details><div>
    答え：2
説明
正解は、
B. 
部門ごとにデータセットを作成することは、データを論理的に分離し、各部門がデータ用に分離されたスペースを確保するための優れた方法です。
部門リーダーを WRITER ロールに割り当てると、データセット内のテーブルを作成および変更するアクセス許可が付与されます。これは、リードがテーブルを作成および更新できる必要があるという要件と一致しています。
データセットに対してデータアナリストにREADERのロールを割り当てると、データアナリストはデータのクエリはできますが、変更はできないため、データアナリストはデータのクエリはできますが、変更はできないという要件と一致します。
正しくないオプション -
オプションA(正しくない):
このオプションでは、部門リーダーに OWNER のロールが付与され、データセットを削除する権限など、必要以上の権限が付与されます。これは、部門リーダーがテーブルを作成および更新するための要件を超えています。
データアナリストに WRITER の役割を割り当てると、データアナリストはテーブルを作成できますが、その役割がデータを変更せずにクエリを実行する場合は、必要以上のアクセス権限が必要になります。
オプションC(正しくない):
部門ごとにテーブルを作成することは、BigQuery でアクセス制御とデータの分離を管理するのに理想的な方法ではありません。
部門をプロジェクトレベルで所有者の役割に割り当てると、プロジェクト全体にわたる幅広い権限が付与され、必要以上のアクセス権が含まれる場合があります。
オプションD(正しくない):
オプション C と同様に、部門ごとに個別のテーブルを作成することは、アクセス制御とデータ編成のために推奨される方法ではありません。
部門リーダーをプロジェクトレベルで編集者の役割に割り当てると、データセット、テーブル、その他のプロジェクトリソースを編集する機能が含まれるため、必要以上に幅広い権限が与えられます。
</div></details>

### Q. 質問46: 未回答
金融機関は、機密性の高い顧客データを安全に保管し、規制コンプライアンスを確保する必要があります。これには、暗号化、監査ログ、きめ細かなアクセス制御を備えたマネージド・データベース・サービスが必要です。どのGCPサービスを選ぶべきか?
1. Cloud SQL
2. 
3. 
4. 
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. 
Cloud SQL は、機密データを処理するように設計された Google Cloud のマネージド リレーショナル データベース サービスです。保存中および転送中の暗号化、自動バックアップ、きめ細かなアクセス制御などの機能を提供します。これは、規制コンプライアンスと機密性の高い顧客データの安全なストレージを必要とするアプリケーションに適しています。構造化されたリレーショナルデータベースの使用は、取引データやコンプライアンスの目的で金融機関で好まれることがよくあります。
正しくないオプション -
B. Bigtable は、主に高スループットでスケーラブルなワークロード向けに設計された NoSQL データベースであり、機密性の高い顧客データを安全に保存し、規制コンプライアンスを確保するには最適な選択肢ではない可能性があります。Cloud SQL と同じレベルの組み込みのセキュリティ機能やコンプライアンス機能は提供されません。
C. Firestore は、一般的に柔軟でスキーマレスのデータ ストレージに使用される NoSQL ドキュメント データベースですが、金融機関が必要とする特定のセキュリティおよびコンプライアンス機能を提供しない場合があります。Firestore は通常、より柔軟で俊敏なデータ ストレージのニーズに合わせて選択されます。
D. BigQuery は、大規模なデータセットの分析とクエリに使用される、サーバーレスで拡張性の高いデータ ウェアハウスです。データ分析には使用できますが、主にトランザクション データベースではなく、Cloud SQL と同じレベルのセキュリティとコンプライアンス機能を提供していません。
Cloud SQL は、必要なセキュリティとコンプライアンスの機能に加えて、機密性の高い顧客データを金融機関に安全に保管するために必要な構造を備えているため、最も適切な選択肢です。
</div></details>

### Q. 質問47: 未回答
あなたの会社は、投稿、コメント、いいねなどのユーザー生成コンテンツを保存するために、柔軟でスキーマレスなデータベースを必要とするソーシャルメディアプラットフォームを開発しています。このシナリオに適したGCPデータベースサービスはどれですか?
1. 
2. Firestore
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は B. Firestore です。
このシナリオの要件は、ソーシャル メディア プラットフォームの投稿、コメント、いいねなどのユーザー生成コンテンツを保存することです。時間の経過とともに変化する可能性のある、このユーザー生成コンテンツのさまざまな構造に対応するには、柔軟なスキーマレスデータベースが必要です。
Firestore は、柔軟でスキーマレスなデータ ストレージを提供する NoSQL ドキュメント データベースです。非構造化データや半構造化データを簡単に処理できるため、ユーザーが作成したコンテンツをソーシャルメディアプラットフォームに保存するための優れた選択肢となります。Firestore は、このようなアプリケーションに不可欠なリアルタイムの同期とスケーラビリティも提供します。
正しくないオプション -
A. BigQueryの場合:BigQuery は分析用のデータ ウェアハウスであり、ユーザーが生成したコンテンツを保存するための柔軟なスキーマレス データベースではありません。構造化データに対して複雑なSQLクエリを実行するように設計されているため、ソーシャルメディアの投稿やコメントなどの非構造化コンテンツや半構造化コンテンツにはあまり適していません。
C. クラウドデータストア:Cloud Datastore も Google Cloud が提供する NoSQL データベースですが、より最新の機能と優れたスケーラビリティにより、Firestore がほぼこれに取って代わりました。このシナリオでも Cloud Datastore は機能しますが、新しいプロジェクトでは一般的に Firestore をおすすめします。
D. Cloud SQL:Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。固定スキーマが適用されるため、ソーシャルメディアプラットフォームにおけるユーザー生成コンテンツの柔軟でスキーマレスな性質にはあまり適していません。Cloud SQL は、構造化データ ストレージとリレーショナル データベースのニーズに適しています。
</div></details>

### Q. 質問48: 未回答
オンラインゲーム会社は、スコア、実績、ゲームの進行状況などのプレーヤー統計をリアルタイムで保存して処理したいと考えています。頻繁な更新とクエリを処理できるデータベースが必要です。どのGCPサービスをお勧めしますか?
1. Bigtable
2. 
3. 
4. 
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. Bigtable
このシナリオでは、オンラインゲーム会社は、頻繁な更新とクエリを使用して、プレーヤーの統計をリアルタイムで保存および処理する必要があります。Bigtable は、Google Cloud Platform(GCP)上の NoSQL で拡張性が高く、低レイテンシのデータベース サービスであり、大量のデータを高い読み取りおよび書き込みスループットで処理するように設計されています。
リアルタイム データ処理: Bigtable は、リアルタイム データを低レイテンシで処理することに優れているため、ゲームプレイ中にリアルタイムで更新されるプレイヤーの統計情報を保存および処理するのに適しています。
スケーラビリティ: Bigtable は、多数のプレイヤーと広範な統計を扱うゲーム会社にとって不可欠な、大量のデータに対応するために簡単に拡張できます。
頻繁な更新とクエリ: Bigtable の設計は、高頻度の読み取りおよび書き込み操作に最適化されているため、プレイヤーの統計情報の記録と取得に適しています。
正しくないオプション -
B. クラウドデータストア:
Cloud Datastore も NoSQL データベースですが、一般的には、より構造化されたトランザクション データ ストレージを必要とするアプリケーションに適しています。頻繁な更新とクエリを伴うリアルタイムのゲーム統計については、Bigtable ほどパフォーマンスが高くない可能性があります。
C. BigQueryの場合:
BigQuery は、大規模なデータセットの分析とクエリ用に設計されたデータ ウェアハウス サービスです。これは、このシナリオの主要な要件であるリアルタイムのデータストレージと処理にはあまり適していません。
D. Cloud SQL:
Cloud SQL は、マネージド リレーショナル データベース サービスです。構造化データやトランザクションデータには適していますが、頻繁な更新やクエリを伴うリアルタイムのゲーム統計に必要なパフォーマンスとスケーラビリティを提供しない場合があります。
Bigtable は、リアルタイム処理機能、スケーラビリティ、頻繁な更新やクエリを処理する能力など、ゲーム会社のプレイヤー統計の要件に合致しているため、最も適切な選択肢です。
</div></details>

### Q. 質問49: 未回答
組織はニュース Web サイトを運営しており、ユーザーの行動データを分析してコンテンツのレコメンデーションをパーソナライズする必要があります。リアルタイムのデータストリーミングと複雑な分析を効率的に処理できるGCPデータベースサービスはどれですか?
1. 
2. 
3. 
4. BigQuery
<details><div>
    答え：4
説明
質問の正しいオプションは D. BigQuery です。
BigQuery は、フルマネージドのサーバーレス データ ウェアハウスであり、リアルタイムのデータ ストリーミングや複雑な分析の処理に適しています。BigQuery は、大規模なデータセットの複雑な分析に優れたデータ ウェアハウスおよび分析プラットフォームです。ストリーミング挿入などの機能を通じてリアルタイムのデータストリーミングを効率的に処理でき、強力な分析のためのSQLのようなクエリ言語を提供します。これは、ユーザーの行動データに対して複雑なクエリを実行してコンテンツのレコメンデーションをパーソナライズするのに適しており、このシナリオに最も適した選択肢です。
コンテンツのレコメンデーションをパーソナライズするためにユーザーの行動データを分析する必要がある場合や、リアルタイムのデータ ストリーミングと複雑な分析が必要な場合、BigQuery は要件に最適な GCP データベース サービスです。
正しくないオプション -
A. Cloud Pub/Sub の場合: Cloud Pub/Sub は、イベントドリブン システムの構築とデータのストリーミングのためのメッセージング サービスです。データのストリーミングには便利ですが、BigQuery のようなデータベース サービスではなく、複雑な分析は実行しません。これは通常、メッセージ キューイングとイベント ドリブン アーキテクチャに使用されます。
B. Bigtable の場合: Bigtable は、高スループット、低レイテンシ、スケーラビリティを実現するように設計された NoSQL データベースです。大量のデータへの高速な読み取りおよび書き込みアクセスを必要とするアプリケーションには適していますが、複雑な分析には最適化されていません。Bigtable は、時系列データやキー値ストレージなどのユースケースに適しています。
C. Firestore: Firestore は、モバイル アプリケーションやウェブ アプリケーション向けに設計された NoSQL データベースです。リアルタイム データを処理できますが、主にトランザクション データに使用され、複雑な分析には使用されません。これはドキュメントベースのストレージ用に設計されており、クライアント間でデータをリアルタイムで同期する必要があるアプリケーションに適しています。
</div></details>

### Q. 質問50: 未回答
ある医療企業は、患者記録管理システムを構築しています。そのためには、強力な一貫性と自動シャーディングを備えた、可用性の高いグローバルに分散されたデータベースが必要です。これらの要件に当てはまる GCP サービスはどれですか?
1. 
2. Cloud Spanner
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しいオプションは B. Cloud Spanner です。
Cloud Spanner:
Cloud Spanner は、グローバルに分散され、水平方向にスケーラブルで、強力な一貫性を持つデータベース サービスです。これは、質問に記載されている要件を満たすように特別に設計されています。自動シャーディングを提供し、グローバルな分散を提供することで、複数のリージョン間でデータの可用性と一貫性を確保します。
Cloud Spanner は、医療における患者記録管理システムなど、データの整合性、強力な一貫性、グローバルな可用性が重要なアプリケーションに最適です。
正しくないオプション -
クラウドデータストア:
Cloud Datastore は NoSQL データベースですが、グローバルに分散した患者記録管理システムに必要な強力な整合性と自動シャーディングは提供されません。
高可用性を実現するように設計されていますが、医療データに必要なレベルのグローバル分散と強力な一貫性は提供されない場合があります。
Bigtable の場合:
Bigtable は、大規模な分析および運用ワークロード向けに最適化された NoSQL データベースですが、医療アプリケーションの重要な要件である強力な一貫性をすぐに提供することはできません。
大量のデータを処理でき、高可用性を提供しますが、強力な一貫性を必要とするアプリケーションには最適ではありません。
クラウド SQL:
Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。自動シャーディングは提供されておらず、医療患者記録管理システムに必要なレベルのグローバル分散と強力な一貫性を提供しない可能性があります。
従来のリレーショナルデータベースのユースケースには適していますが、このシナリオには最適ではありません。
</div></details>

## 3
### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>
