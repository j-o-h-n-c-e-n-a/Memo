## 1
### Q. 1
あなたは世界的な海運会社の一員です。あなたの目的は、40TBのデータを使用して予測モデルを構築し、様々な地域内の船舶による配送遅延の可能性を毎日予測することです。このモデルは、様々な情報源から収集された数多くの属性に依存しています。各船舶からの GeoJSON 位置情報を含むテレメトリーデータが 1 時間ごとに収集されます。あなたは、予測および地理空間処理のための組み込み機能を提供するストレージソリューションを求めています。 この目的のために、どのようなストレージ・ソリューションを選択すべきでしょうか？
1. BigQuery
2. Cloud Bigtable
3. クラウドデータストア
4. PostgreSQL向けクラウドSQL
<details><div>
    答え：1
説明
BigQueryはアナリティクスに最適化されたクラウドベースのストレージソリューションで、予測や地理空間処理のためのネイティブ機能を備えています。モデルのトレーニングに使用したい40TBのデータのような大規模なデータセットに適しています。また、ダッシュボード機能もあり、地域内で遅延が発生しそうな船舶の数や船舶を表示することができる。
不正確なオプション
Cloud Bigtableは、低レイテンシのルックアップに最適化され、大量のデータを格納できるNoSQLデータベースソリューションです。予測や地理空間処理のためのネイティブ機能がないため、このユースケースには最適ではない。
Cloud Datastoreは、スケーラビリティに最適化され、大量のデータを保存できるNoSQLデータベースソリューションです。予測や地理空間処理のためのネイティブ機能を備えていないため、このユースケースには最適な選択肢ではありません。
Cloud SQL for PostgreSQLは、トランザクションに最適化され、大量のデータを保存できるリレーショナルデータベースソリューションです。予測や地理空間処理のためのネイティブ機能を備えていないため、このユースケースには最適ではない。
参考リンク
Google BigQuery: https://cloud.google.com/bigquery
</div></details>

### Q. 2
あなたはApache Kafkaを利用したIoTパイプラインを管理しており、通常毎秒約5000メッセージを受信しています。あなたの目標は、Google Cloud Platformを採用して、1時間移動平均が毎秒4000メッセージを下回ったときにアラートを生成することです。
どのような手順を踏むべきですか？
1. Kafka IOを使用してDataflowでデータのストリームを消費する。5分ごとに1時間のスライディング・タイム・ウィンドウを設定する。ウィンドウが閉じたら平均を計算し、平均が4000メッセージ未満ならアラートを送信する。
2. 
3. 
4. 
<details><div>
    答え：1
説明
IoTパイプラインの1時間の移動平均が毎秒4000メッセージを下回るとすぐにアラートを作成するには、以下の方法を取る必要があります：
このアプローチが適している理由は以下の通り：
Kafka IOを使ったデータフローでは、入力されるデータのストリームを効率的に処理できます。
5分ごとに1時間のスライディングタイムウィンドウを使用することで、移動平均を継続的に計算することができます。
ウィンドウが閉じたときに平均を計算することで、移動平均をチェックする間隔が一定になります。
計算された平均が4000メッセージを下回ると簡単にアラートを送ることができ、リアルタイムのアラート・メカニズムになります。
誤ったオプション
オプションB、C、およびDは、1時間にわたって移動平均を計算し、それが特定のしきい値を下回ったときにアラートを生成するという要件に直接対応していません：
B. 1時間の固定時間ウィンドウを使用すると、移動平均は得られず、むしろ1時間の静的平均が得られる。
C. このアプローチは、BigtableとCloud Schedulerを使用しますが、移動平均を直接計算しません。
D. このアプローチもBigQueryとCloud Schedulerを使用しますが、移動平均の計算がありません。
</div></details>

### Q. 3
MySQLベースのクラウドSQLの実装を準備しており、ゾーン障害時に高可用性を維持するための対策が必要です。
そのためにはどのような手順を踏むべきでしょうか？
1. あるゾーンにCloud SQLインスタンスを作成し、同じリージョン内の別のゾーンにフェイルオーバー・レプリカを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
これは、ゾーン障害時に高可用性を確保するための最良のオプションです。フェイルオーバー・レプリカは、プライマリ・インスタンスに障害が発生した場合に引き継ぐことができるセカンダリ・インスタンスであり、プライマリ・インスタンスと同じリージョンになければなりません。
誤ったオプション
リードレプリカはスケーリングに使用されるセカンダリインスタンスであり、高可用性に使用されるものではないため、オプションBは正しくありません。
リードレプリカはプライマリインスタンスと同じリージョンになければならないので、オプションCは不正解です。
クラウドストレージのバケットにバックアップしても、ゾーン障害時の高可用性には役立たないので、オプションDは不正解です。
参考リンク
https://cloud.google.com/sql/docs/mysql/high-availability。
</div></details>

### Q. 4
データの取り込みと配信を一元化するために、貴社はどのシステムを選ぶべきか。
- トピック内の特定のオフセットへのシーク機能
-多数のトピックにおけるパブリッシュ/サブスクライブ・セマンティクスのサポート
- キーごとの順序付けを維持するか？
1. Apache Kafka
2. Cloud Storage
3. Dataflow
4. Firebase Cloud Messaging
<details><div>
    答え：1
説明
正しい選択肢は A. Apache Kafka です。
Apache Kafkaは、データ統合のための機能を備えたメッセージングシステムを提供する分散ストリーミングプラットフォームであり、トピック内の特定のオフセットにシークする機能、数百ものトピック上でパブリッシュ／サブスクライブセマンティクスをサポートする機能、キーごとの順序付けを保持する機能などを備えています。
不正解の選択肢
オプションB. Cloud Storageは、Apache Kafkaのようなデータ統合の機能を提供していないため、不正解です。
オプションC. Dataflowは、トピック内の特定のオフセットにシークする機能、数百のトピックでのパブリッシュ/サブスクライブ・セマンティクスのサポート、およびキーごとの順序付けを保持する機能を提供しないため、不正解です。
オプション D. Firebase Cloud Messaging は、トピック内の特定のオフセットへのシーク機能、何百ものトピックでの発行/購読セマンティクスのサポート、およびキーごとの順序付けの保持を提供していないため、不正解です。
</div></details>

### Q. 5
既存のオンプレミスのApache Hadoopデプロイメントをマネージドサービスを利用してクラウドに移行する場合、長時間実行するバッチジョブに対して最大限の耐障害性とコスト効率を確保するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：1
説明
選択肢Aが正解です。Dataprocクラスタをデプロイすることが、長時間実行するバッチジョブの耐障害性とコスト効率を確保する最善の方法です。
標準的な永続ディスクと50%のプリエンプティブワーカーを使用することで、コストを低く抑えることができます。データをクラウドストレージに保存し、スクリプト内の参照をhdfs://からgs://に変更することで、データへのアクセスと管理が容易になります。
不正解の選択肢
SSD永続ディスクを使用すると、標準の永続ディスクよりも高価になるため、オプションBは正しくありません。
オプションCは、標準インスタンスで10ノードのCompute Engineインスタンスグループを使用すると、プリエンプティブインスタンスを使用するよりもコストが高くなるため、不正解です。
オプションDは、HDFSにデータを保存するとクラウドストレージに保存するよりも高くつくので、間違っています。
参考リンク
Dataproc データアクセシビリティ:- https://cloud.google.com/dataproc/docs/resources/faq#data_access_availability
</div></details>

### Q. 8
以下の仕様の新規プロジェクトにどのデータベースを選択しますか？
1. 完全な管理機能。
2. 自動スケーラビリティ。
3. トランザクションの一貫性。
4. 最大6TBまでのスケーラビリティ。
5. SQLクエリーのサポート
このプロジェクトではどのデータベースを選択しますか？
1. Cloud SQL
2. Cloud Bigtable
3. Cloud Spanner
4. Cloud Datastore
<details><div>
    答え：3
説明
C. Cloud Spanner
Cloud Spannerは、Google Cloudが提供する、完全に管理され、グローバルに分散された、一貫性の高いデータベースサービスです。シナリオで説明した要件を満たすように設計されています：
フルマネージド： Cloud Spannerはフルマネージドであり、Google Cloudがインフラ管理、アップデート、バックアップを行うため、アプリケーションに集中することができます。
自動的なスケールアップ：Cloud Spannerは水平方向のスケーラビリティを考慮して設計されています。データとクエリの負荷が増加した場合、アプリケーションのスケーリングニーズに自動的に対応できます。
トランザクションの一貫性： Cloud Spannerは強力なトランザクション一貫性を提供します。つまり、データのACID（原子性、一貫性、分離、耐久性）特性を保証し、信頼性と一貫性のあるトランザクションを必要とするアプリケーションに適しています。
最大6 TBまで拡張可能：Cloud Spannerはより大きなデータセットを扱うことができるため、最大6 TBまで拡張可能です。
SQLでクエリ可能： Cloud SpannerはSQLクエリをサポートしているため、SQLベースのデータベースに慣れている開発者にはなじみやすい。
不適切なオプション
A. Cloud SQL： Cloud SQLはマネージド・リレーショナル・データベース・サービスですが、Cloud Spannerほど簡単には自動スケールしません。また、Cloud Spannerのように分散したグローバルに一貫性のあるデータを扱うようには設計されていない。
B. Cloud Bigtable： Cloud BigtableはNoSQLデータベースで、特に分析や時系列のユースケースで大量のデータを扱うのに優れている。しかし、このシナリオの要件である強力なトランザクション一貫性は提供しない。
D. クラウド・データストア： Cloud Datastore（データストアモードのFirestore）は、拡張可能なNoSQLドキュメントデータベースだが、Cloud Spannerと同レベルのトランザクション一貫性は提供できない。また、一般的にSQLクエリに依存する従来のリレーショナル・データベースとは異なるユースケースで使用される。
参考リンク
Cloud Spanner: https://cloud.google.com/spanner
</div></details>

### Q. 10
何百万台ものコンピュータのCPUとメモリ使用量に関する時系列データを効果的に保存するデータベースの選択に関する決断に迫られていると想像してほしい。要件は、このデータを1秒間隔で取得したサンプルとして保存することです。このデータはアナリストがリアルタイムのアドホック分析に使用するため、データベースは効率的なクエリ実行をサポートする必要があります。さらに、クエリを実行するたびに料金が発生するのを防ぎ、選択したスキーマ設計が将来的なデータセットの拡張に対応できることを目的としています。これらの目的に最適なデータベースとデータモデルはどれでしょうか？
1. 
2. 
3. 
4. 
<details><div>
    答え：3
説明
正解はCです。Bigtableに、コンピュータ・エンジンのコンピュータ識別子と各秒のサンプル時間を組み合わせた行キーを持つ狭いテーブルを作成します。
こうすることで、アナリストはデータをすばやく照会できるようになり、スキーマ設計がデータセットの将来の成長を可能にします。Bigtableは、データへの高速アクセスとクエリを可能にするので、この種のデータには最適です。
不正解の選択肢
BigQueryはリアルタイムのアドホック分析をサポートしていないため、オプションAは不正解です。
BigQueryはリアルタイムのアドホック分析をサポートしておらず、各秒の間隔で行を更新するのは効率的ではないため、オプションBは不正解です。
Bigtableはワイドテーブルをサポートしておらず、各秒の値を列データとして結合するのは非効率的であるため、オプションDは不正解です。
参考リンク
https://cloud.google.com/bigtable/docs/schema-design-time-series
</div></details>

### Q. 11
クラウド・ストレージ環境内にデータをアーカイブすることを意図しており、特に機密性の高い情報の保護に注意を払っています。最大限のセキュリティと機密性を確保するため、クラウドプロバイダーの担当者であっても不正アクセスを防止する「Trust No One」（TNO）暗号化アプローチの導入を強く希望しています。
クラウドストレージにデータを保存する前に、「Trust No One」（TNO）アプローチを使ってデータを安全に暗号化するには、どのような手順を踏むべきでしょうか？
1. gcloud kms keys createを使って共通鍵を作成します。次に、gcloud kms encryptを使用して、各アーカイブファイルをキーと一意の追加認証データ（AAD）で暗号化します。gsutil cpを使用して、暗号化された各ファイルをCloud Storageバケットにアップロードし、AADをGoogle Cloud外に保管します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
選択肢Aが正解です。
このオプションでは、Trust No One（TNO）アプローチを使用してデータを暗号化し、クラウドプロバイダのスタッフがデータを復号化できないようにします。対称キーは、キーと一意の追加認証データ（AAD）で各アーカイブファイルを暗号化するために使用されます。暗号化されたファイルはCloud Storageバケットにアップロードされ、AADはGoogle Cloudの外部に保管されます。
正しくないオプション
オプションBはTNOのアプローチを使用していないため、不正解です。対称鍵は各アーカイブファイルの暗号化に使用されるが、鍵は破棄されずローテーションされる。これは、クラウド・プロバイダーのスタッフが鍵にアクセスし、データの復号化に使用できる可能性があることを意味する。
オプションCはTNOのアプローチを使用していないため、誤りである。顧客提供の暗号化キー（CSEK）は.boto設定ファイルで指定され、アーカイブ・ファイルはクラウド・ストレージ・バケットにアップロードされる。CSEKはクラウドメモリストアに保存されますが、クラウドプロバイダーのスタッフがアクセスできないようにするには十分なセキュリティではありません。
オプションDはTNOのアプローチを使用していないため、不正解です。顧客提供の暗号化キー（CSEK）は.boto設定ファイルで指定され、アーカイブファイルはクラウドストレージバケットにアップロードされます。CSEKは別のプロジェクトに保存されますが、これはクラウド・プロバイダーのスタッフがアクセスできないことを保証するものではありません。
参考リンク
https://cloud.google.com/security/encryption-at-rest/customer-supplied-encryption-keys/
</div></details>

### Q. 12
BigQuery、Dataflow、Dataprocで運用中のデータパイプラインがあり、ヘルスアセスメントやパフォーマンスの監視を行う機能が必要な場合、どのように進めればよいのでしょうか。さらに、これらのパイプラインの監督を担当するチームに障害が発生した場合にアラートを出す必要があり、さまざまなプロジェクトでシームレスに運用できなければなりません。プラットフォームが管理する製品や機能を活用したいと考えています。
このシナリオでは、どのような手順を踏むべきでしょうか？
1. 情報をCloud Monitoringにエクスポートし、アラートポリシーを設定します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。
Cloud MonitoringはGoogle Cloud Platformが提供するマネージドサービスであり、データパイプラインの監視と管理を可能にするからです。Cloud MonitoringはGoogle Cloud Platformが提供するマネージドサービスであり、データパイプラインの監視と管理を可能にする。Cloud Monitoringはアラートポリシーを提供し、パイプラインに障害が発生した場合にパイプラインを管理するチームに通知するように設定できる。さらに、Cloud Monitoringは複数のプロジェクトで使用できるため、このような状況に最も適した選択肢となる。
不適切なオプション
Compute Engine with AirflowのVirtual Machinesはマネージドサービスではないため、選択肢Bは誤りです。
オプションCは、BigQueryがアラートポリシーを提供していないため、この状況に最適なオプションではないため、不正解です。
App Engine は、GCP API 呼び出しを使用してログを消費するアプリケーションを開発する必要があり、他の選択肢よりも複雑であるため、この状況では最適な選択肢ではないため、選択肢 D は正しくありません。
参考リンク
クラウド監視に関する Google Cloud Platform のドキュメント: https://cloud.google.com/monitoring
</div></details>

### Q. 13
顧客が自社の商品を購入する確率を予測するためにBigQuery MLで線形回帰モデルを開発する際、重要な予測要因として都市名の変数がありますが、モデルの学習と展開のためにデータを列に効率的に構造化し、必要な変数を保持しながら必要なコーディング工数を最小限に抑えるにはどうすればよいでしょうか？
1. 
2. BigQueryのSQLを使用して、ワンホットエンコーディング法を使用してstateカラムを変換し、各都市をバイナリ値を持つカラムにします。
3. 
4. 
<details><div>
    答え：2
説明
正解はBです。
これは各都市に新しい列を作成し、都市名に基づいて各行にバイナリ値を割り当てるので、データを準備する最も効率的な方法です。これにより、モデルは都市名を予測変数として使用できるようになります。
不正解の選択肢
A. 都市情報の列を含まない新しいビューをBigQueryで作成しても、都市を予測変数として使用するために必要な情報をモデルに提供することはできません。
C. C. TensorFlow を使用して語彙リストを持つカテゴリ変数を作成すると、時間がかかりすぎ、必要以上のコーディングが必要になる。
D. クラウドデータフュージョンを使って、各都市を1,2,3,4,5とラベル付けされた地域に割り当て、その番号を使ってモデルで都市を表すことは、予測変数として都市を使うために必要な情報をモデルに提供しない。
</div></details>

### Q. 14
あなたは、北米で広く事業を展開する有名銀行に雇われている。あなたの仕事は、銀行口座取引を管理するために設計されたデータストレージシステムを構築することです。あなたの具体的なニーズには、ACIDコンプライアンス原則の遵守と、SQLクエリを使用してデータを取得する機能が含まれます。この目的に適したソリューションは何でしょうか？
1. トランザクションデータをCloud Spannerに格納する。ステールリードを有効にしてレイテンシを減らす。
2. トランザクションデータをCloud Spannerに格納する。ロック付き読み書きトランザクションを使用する。
3. トランザクションデータをBigQueryに保存する。クエリキャッシュを無効にして一貫性を確保する。
4. トランザクションデータをCloud SQLに格納する。分析にはBigQueryとの連携クエリを使用する。
<details><div>
    答え：2
説明
オプションB：
Cloud Spannerはグローバルに分散され、ACIDコンプライアンスを提供する一貫性の強いデータベースサービスであるため、銀行口座のトランザクションを処理するのに適している。Cloud Spannerでロック付き読み書きトランザクションを使用すると、データの一貫性と整合性を確保できます。
以下はオプションBに関する考慮事項です：
強力な一貫性： Cloud Spannerは強力な一貫性を提供します。これは銀行環境でデータの整合性を維持するために極めて重要です。
ACIDコンプライアンス： Cloud SpannerはACIDに準拠しており、トランザクション・データ・ストレージの要件を満たしています。
読み書きトランザクションのロック 読み書きトランザクションをロックすることで、データへのアクセスを制御して競合を防ぎ、データの整合性を確保できます。
不正解の選択肢
A. 
Cloud SpannerはACIDに準拠しており、トランザクション・データに適していますが、ステール・リードを有効にするとデータの一貫性が損なわれる可能性があります。ステイル・リードを有効にすると、最新ではないデータを読み込むことができるため、データの整合性が重要な銀行口座のトランザクションには適していません。
C. 
BigQueryは分析ワークロード用に設計されており、トランザクションデータベースではない。ACID コンプライアンスや強力なトランザクション一貫性は提供しません。BigQueryのクエリキャッシュを無効にしても、これらの基本的な要件には対処できません。
D. 
Cloud SQL は、ACID コンプライアンスと強力な一貫性を提供するマネージド・リレーショナル・データベースであり、トランザクション・データの保存に適しています。BigQueryとの連携クエリを分析に使用することで、トランザクション処理と分析で両方のサービスの強みを活用できます。このアプローチはバランスが取れており、指定された要件を満たすことができます。
</div></details>

### Q. 15
ある運送会社では、荷物の追跡データをApache Kafkaストリームにリアルタイムで送信しています。このデータはBigQueryにロードされます。社内のアナリストは、BigQueryで追跡データを照会して、パッケージのライフサイクルにおける地理空間的傾向を分析したいと考えています。このテーブルは当初、インジェスト・デート・パーティショニングで作成されました。時間の経過とともに、クエリの処理時間が長くなっています。あなたのタスクは、BigQueryのクエリパフォーマンスを向上させるための修正を特定することです。
どのような対策を取るべきですか？
1. 
2. パッケージ追跡ID列にクラスタリングを実装する
3. 
4. 
<details><div>
    答え：2
説明
オプションB - 
BigQueryのクラスタリングは、クラスタリング列に基づいて各パーティション内のデータを物理的に整理することで、クエリ・パフォーマンスを最適化するために使用されます。パッケージ追跡 ID 列にクラスタリングを実装すると、パッケージ追跡 ID でデータをフィルタリングまたはソートするクエリにおいて、クエリ・パフォーマンスの向上に役立つ可能性があります。
クラスタリングは、フィルタ句を使用するクエリやデータを集約するクエリなど、特定のタイプのクエリのパフォーマンスを向上させます。クエリジョブまたはロードジョブによってクラスタ化テーブルにデータが書き込まれると、BigQueryはクラスタリング列の値を使用してデータをソートします。これらの値は、BigQueryストレージ内でデータを複数のブロックに整理するために使用されます。クラスタリング列に基づいてデータをフィルタリングする句を含むクエリを送信すると、BigQueryはソートされたブロックを使用して不要なデータのスキャンを排除します。
参考リンク
BigQuery クラスタ化テーブル:- https://cloud.google.com/bigquery/docs/clustered-tables
</div></details>

### Q. 16
現在、Spark、Hive、HDFSを利用した大規模なオンプレミスクラスターをコロケーション施設で使用していますが、コスト削減を最大化しつつ、クラウドへの移行をタイムリーに行うにはどうすればよいでしょうか？このクラスタはピーク時の利用を想定して設計されていますが、多くのバッチジョブがあるため、需要が変動しています。貴社はまた、オンプレミスのオーバーヘッドとメンテナンスコストの削減を目指し、クラウドのサーバーレス・オファリングを採用することで、インフラを近代化しようとしています。コロケーション施設の契約更新まで2カ月しかありませんが、これらの目的を達成するためにどのような移行戦略をお勧めしますか？
1. 
2. ワークロードをDataproc plus Cloud Storageに移行し、後でモダナイズする。
3. 
4. 
<details><div>
    答え：2
説明
クラウドに移行してオーバーヘッドを削減し、コスト削減のメリットを享受するという貴社の目標と、最初の移行期間が2カ月という限られた期間であることを考慮すると、推奨されるアプローチは次のようになります：
B. 
このアプローチが適している理由は以下の通りです：
混乱を最小限に抑える： Googleクラウド上のマネージドSparkおよびHadoopサービスであるDataprocにワークロードを移行することで、既存のSparkおよびHiveジョブの中断を最小限に抑えることができます。DataprocはSparkとHiveのワークロードを実行するための使い慣れた環境を提供するため、迅速な移行が容易です。
コスト効率： データストレージソリューションとしてDataprocとCloud Storageを併用することで、クラウドのコスト効率の高いストレージオプションを活用することができます。クラウドストレージは拡張性が高く、競争力のある価格設定なので、オンプレミスのインフラストラクチャのオーバーヘッドなしにデータを保存できます。
時間的制約： 初期移行に2ヶ月というタイトなスケジュールを考えると、短時間で比較的簡単に移行できる戦略を優先することが重要です。Dataprocとクラウド・ストレージへの移行は、ワークロードをすぐにモダナイズするのに比べ、より直接的な方法です。
近代化： 最初の移行が完了した後に、最新化を計画することができます。ワークロードがクラウドで実行されるようになったら、BigQuery for HiveのモダナイゼーションやDataflow for Sparkのモダナイゼーションのようなサーバーレスオファリングを徐々に検討し、サーバーレスの機能とコストの最適化を活用しながら進めることができます。
オプションC（SparkワークロードをDataprocとHDFSに移行し、HiveワークロードをBigQuery用にモダナイズする）は、Hiveをすぐにモダナイズする特定のニーズがある場合に検討できます。ただし、オプションBに比べて複雑さが増し、実行に時間がかかる可能性があります。
オプションD（SparkとHiveの両方のワークロードをすぐに最新化する）は、最新化の取り組みがコード、アーキテクチャ、およびプロセスの変更を伴う可能性があるため、特に2カ月の時間枠を考えると、より長くリスクの高い経路になる可能性があります。
参考リンク
Cloud Dataproc:- https://cloud.google.com/dataproc/
</div></details>

### Q. 17
オンライン登録サービスを提供する金融機関に勤務するあなたは、新規登録された顧客のユーザデータをBigQueryに取り込む前にPub/Subに送信する際、顧客の政府発行の識別番号を隠すことでセキュリティを強化することを選択しました。一方、顧客サービス担当者が必要に応じて変更前の値にアクセスできるようにするつもりです。そのためには、どのような行動を取るべきでしょうか？
1. 
2. 
3. 
4. データをBigQueryにロードする前に、クラウドデータ損失防止（DLP）を使用して、入力値を暗号化形式保持暗号化トークンに置き換えます。
<details><div>
    答え：4
説明
正解はDです。
これは、機密データを保護するための最良のオプションです。これは、カスタマーサービス担当者が必要に応じて元の値を表示できるようにするためです。
正しくないオプション
BigQueryに組み込まれているAEAD暗号化では、カスタマーサービス担当者が元の値を見ることができないため、オプションAは正しくありません。
BigQueryの列レベルのセキュリティでは、カスタマーサービス担当者が元の値を表示することはできないため、オプションBは正しくありません。
オプションCは、クラウドデータ損失防止（DLP）により、カスタマーサービス担当者が必要に応じて元の値を見ることができないため、不正解です。
参考リンク
クラウドDLP
</div></details>

### Q. 18
テーブルをBigQueryに移行してデータモデルを決定する際、クエリのパフォーマンスを最適化するためにテーブルをどのように構造化すべきでしょうか？問題のテーブルには、複数の店舗での購入に関するデータが含まれており、トランザクションのタイムスタンプ、購入したアイテム、店舗ID、各店舗の市や州などの詳細が含まれています。定期的なクエリでは、過去30日間の個々のアイテムの売上を追跡し、州、都市、特定の店舗に基づいて購入パターンを分析します。
1. トランザクション時間でパーティショニングし、最初に州、次に市、次に店舗IDでクラスタリングします。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。
このオプションを使用すると、トランザクションの時間、州、市、および店舗IDによってテーブルをすばやくクエリできるため、正解です。これにより、探している特定の店舗、市町村、州をすばやく絞り込むことができるため、テーブルをクエリする際に最高のパフォーマンスが得られます。
不適切なオプション
最初に店舗 ID でクラスタリングすると、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション B は正しくありません。
最初に州によってトップレベル・クラスタリングを行うと、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション C は正しくありません。
最初にストア ID を指定したトップレベル・クラスタリングでは、テーブルへのクエリ時に最高のパフォーマンスは得られないため、オプション D は正しくありません。
参照リンク
https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 19
Pub/Sub フィードのサブスクライバのコードを更新しています。展開時にサブスクライバが誤ってメッセージを承認してしまい、メッセージが失われることを懸念しています。サブスクライバは確認メッセージを保持するように設定されていません。
展開後のエラーからの回復を保証するにはどうすればよいですか?
1. ローカル・マシンにPub/Subエミュレータをセットアップします。本番環境にデプロイする前に、新しいサブスクライバ・ロジックの動作を検証してください。
2. 新しいサブスクライバコードをデプロイする前に、Pub/Sub スナップショットを作成します。Seek 処理を使用して、スナップショットの作成後に利用可能になったメッセージを再配信します。
3. デプロイには Cloud Build を使用します。デプロイ後にエラーが発生した場合は、Seek オペレーションを使用して、デプロイ開始時に Cloud Build によってログに記録されたタイムスタンプを検索します。
4. Pub/Sub トピックでデッドレタリングを有効にして、正常に承認されなかったメッセージを捕捉する。展開後にエラーが発生した場合は、デッド・レター・キューでキャプチャされたメッセージをすべて再配信します。
<details><div>
    答え：2
説明
オプション B. 
新しいサブスクライバ・コードをデプロイする前に Pub/Sub スナップショットを作成することで、特定の時点のサブスクリプションの状態を取得できます。新しいサブスクライバコードの問題により、誤って承認され失われたメッセージがある場合、Seek 操作を使用して、スナップショットの作成後に利用可能になったメッセージを再送信することができます。
この方法は、誤った確認応答によって失われたメッセージを回復するのに効果的です。ただし、メッセージの回復を確実に行うには、スナップショットの作成と管理に依存します。
誤ったオプション
A. 
ローカルでのテストは開発に不可欠な要素ですが、本番環境でのサブスクライバの動作にエラーがないことを保証するものではありません。Pub/Sub エミュレータは本番環境を完全に再現しているとは限らず、動作に違いが生じる可能性があります。さらに、このオプションは、デプロイ後にエラーが発生した場合にメッセージを回復するメカニズムを提供しません。
C. 
Cloud Build はデプロイメントを管理するための貴重なツールですが、Cloud Build によってログに記録されたタイムスタンプに依存してエラーを回復することは、最も単純で効率的な方法ではない可能性があります。手作業が必要であり、メッセージ復旧に必要なメッセージ固有の詳細を取得できない可能性があります。さらに、タイムスタンプだけでは、メッセージ処理の正確な状態をピンポイントで特定するには不十分な場合があります。
D. 
デッドレターを有効にすることは、正常に処理できなかったメッセージをキャプチャするための確立された方法です。これは、処理中にエラーが発生したメッセージを回復するための体系的かつ自動化された方法を提供し、デプロイ後のメッセージ回復を確実にするための、より強固なオプションとなります。
参考リンク
Cloud Pub/Sub:- https://cloud.google.com/pubsub/
</div></details>

### Q. 20
著名な不動産会社に勤務するあなたは、機械学習用に6TBもの膨大な住宅販売データを準備する仕事を任されています。あなたの目的は、データ変換にSQLを利用し、機械学習モデルを確立するためにBigQuery MLを採用することです。このモデルは、未処理の生のデータセットに対して予測を行うことを目的としています。予測段階でスキューを効果的に回避するために、ワークフローを構成する上でどのような手順を踏むべきですか？
1. モデルを作成する際、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データに対して変換を指定しません。
2. 
3. BigQueryビューを使用して前処理ロジックを定義します。モデルを作成する際、そのビューをモデルの学習データとして使用します。予測時には、生の入力データに対して変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
4. Dataflowを使用してすべてのデータを前処理する。予測時には、入力データに対してさらなる変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
<details><div>
    答え：1
説明
オプションA. 
モデル作成時には、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。モデルの学習時には、これらの前処理ステップが学習データに適用されます。
予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データには変換を指定しません。これは、予測を行う前にモデルが内部的に生の入力データに同じ前処理ステップを適用することに依存していることを意味します。
モデルの前処理ロジックが十分に定義され、トレーニングデータと一貫している場合、オプションAは効果的に機能するかもしれませんが、予測中にモデル自身が未加工の入力データの前処理を正しく処理する必要があります。このアプローチは、モデル内部の前処理が予測の歪みを防ぐのに十分であることを前提としています。
実際には、オプション A とオプション B のどちらを選択するかは、モデル内部の前処理ロジッ クの具体的な特性と信頼性、および予測プロセスにおける透明性と制御の要件によって決まります。どちらのオプションも有効ですが、前処理と予測の一貫性に対するアプローチが異なります。
正しくないオプション
オプションC - 
BigQueryビューを使用して前処理ロジックを定義することは、学習データと予測データ間の一貫性を確保するための有効なアプローチです。しかし、このオプションには、ML.EVALUATE を使用する前の生の入力データに対する明示的な変換ステップがありません。このビューは一貫した前処理ロジックを提供しますが、スキューを防止するために、生の入力データが同じ前処理ステップを受けることを確実にすることが重要です。
オプションD - 
Dataflowを使用してすべてのデータを前処理することは、データ変換と準備のための実行可能なソリューションです。しかし、このオプションはDataflowの前処理と予測中のモデル内部の前処理が同一であることを前提としています。また、前処理ステップには必要ないかもしれないが、Dataflowによってさらなる複雑さがもたらされる。
オプションCとオプションDの両方は、ML.EVALUATEを使用する前に生の入力データを一貫して変換する必要性に明示的に対処していません。
参考リンク
BigQuery ML:- https://cloud.google.com/bigquery/docs/bigqueryml-intro
</div></details>

### Q. 21
あなたはある会社の株価を分析しています。5秒ごとに、過去30秒分のデータの移動平均を計算する必要があります。あなたはPub/Subからデータを読み込み、DataFlowを使って分析を行っています。ウィンドウ・パイプラインをどのようにセットアップしますか？
1. 
2. 
3. 
4. 継続時間30秒、周期5秒のスライディング・ウィンドウを使用します。以下のトリガーを設定して結果を出力する： AfterWatermark.pastEndOfWindow()を設定する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
30秒のスライディング・ウィンドウ： 期間30秒のスライディング・ウィンドウを使用することは、移動平均計算のために直近の30秒間のデータを考慮し続けることを意味します。これはあなたの要求と一致しています。
期間5秒： 期間5秒は、ウィンドウが5秒ごとに前方にスライドすることを示します。こ れに よ り 、 直近 30 秒のデー タ に基づいて 5 秒ご と に移動平均を計算す る こ と が保証 さ れます。この設定は、5秒ごとに移動平均を計算するという要件に合致しています。
トリガー設定： トリガーは、透かしがウィンドウの最後を通過した後に結果を出すように設定されています。これにより、ウィンドウが前方にスライドしたときに計算がトリガーされ、移動平均計算の望ましいタイミングと一致します。
誤ったオプション
オプションA（5秒間の固定ウィンドウ）は、過去30秒分のデータを取り込みません。これは、5秒間の固定ウィンドウを提供しますが、要件を満たしていません。
オプションB（継続時間30秒の固定ウィンドウ）は、30秒のウィンドウをキャプチャしますが、5秒ごとに前方にスライドしません。これは、5秒ごとに移動平均を計算するという要件に合致しません。
オプションC（継続時間5秒のスライディング・ウィンドウ）は5秒のスライディング・ウィンドウをキャプチャしますが、過去30秒のデータの移動平均を計算するために必要な30秒の継続時間を持ちません。さらに、トリガー設定は30秒後にデータを処理するように設定されており、5秒間隔の要件とは一致しません。
参考リンク
ビーム・ウィンドウの基本:https://beam.apache.org/documentation/programming-guide/#windowing-basics
</div></details>

### Q. 22
データのスケーラブルな処理とBigQueryへのロードを保証すると同時に、これらのイベントをPub/Subトピックにパブリッシュするために構築しているパイプライン内で、メッセージのシーケンシングは気にしなくても、1時間ごとにアプリケーションイベントを集約できるようにするには、どのようなテクノロジを採用すべきでしょうか？
1. 
2. 
3. 
4. Pub/Subトピックから継続的に読み取り、タンブリング・ウィンドウを使用して必要な集約を実行するストリーミングDataflowジョブを作成します。
<details><div>
    答え：4
説明
正しい選択肢はDです。
ストリーミングDataflowジョブはPub/Subトピックからのメッセージを継続的に処理し、タンブリング・ウィンドウを使用して必要な集計を実行できるため、このオプションは正しい。これにより、大量のイベントに対応しながら、タイムリーにデータが処理され、BigQueryにロードされます。
不正解の選択肢
クラウド関数は、新しいメッセージがトピックにパブリッシュされたときにのみトリガされ、1時間ごとの区切りでイベントを処理および集計できないため、オプションAは不正解です。
オプション B は、クラウド関数が Pub/Sub トピックから利用可能なすべてのメッセージをプルし、1 回の実行で必要な集計を実行できるだけであり、1 時間ごとの区切りでイベントを処理および集計することはできないため、不正解です。
バッチデータフロージョブは、Pub/Subトピックから利用可能なすべてのメッセージをプルし、1回の実行で必要な集計を実行できるだけであり、不連続な時間間隔にわたってイベントを処理および集計することはできないため、オプションCは正しくありません。
参考リンク
https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines
</div></details>

### Q. 23
大手金融機関の従業員として、Dialogflowを使用してモバイルアプリケーション内でチャットボットを作成しようとしているあなたは、過去のチャット記録を綿密に調査し、顧客がカスタマーサービスに連絡した理由と一致する意図に従って、すべての会話を分類しました。顧客からの問い合わせの約70%は率直な要求が中心で、通常、最初の10件以内に解決されます。一方、残り30％の問い合わせは複雑で、対応にかなりの時間と労力を要する。このような状況を踏まえて、最初に自動化の優先順位をつけるべきインテントはどれでしょうか？
1. 生のエージェントがより複雑なリクエストに対応できるように、リクエストの70%をカバーする10のインテントを自動化する。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正しい選択肢 A. 
顧客リクエストの70%をカバーする最も一般的な10のインテントを自動化することは、現実的なアプローチです。自動化によって、顧客からの問い合わせの大部分に効率的に対応することに重点を置いています。これらのインテントを自動化することで、一般的なリクエストに対して迅速かつ一貫したレスポンスを提供できるようになり、効率が向上するだけでなく、ユーザーエクスペリエンスも向上します。
生身のエージェントが定型的で頻繁に発生するリクエストの処理から解放されることで、より複雑で個別対応が必要な残りの30%の問い合わせに、より多くの時間と注意を割くことができます。これにより、リソースの割り当てが最適化され、複雑な問題に対する全体的なサービス品質が向上します。
誤ったオプション
オプションB（「より複雑なリクエストを最初に自動化する」）は、場合によっては合理的なアプローチですが、大半の顧客からの問い合わせの効率を最適化するという当面の問題には対処できないかもしれません。複雑なリクエストに集中するあまり、最も一般的で簡単なリクエストがおろそかになる可能性がある。
オプションC（「最も短いインテントと最も長いインテントの混合を自動化する」）は、様々なインテントタイプで自動化のバランスを取ろうとしているが、顧客リクエストの分布と一致しない可能性がある。あまり一般的でないインテントを不必要に自動化する可能性がある。
オプションD（「"payment "などの一般的な単語が一度だけ出現する場所のインテントを自動化する」）は、必ずしも頻度や複雑さではなく、特定のキーワードに基づいてインテントを優先する。このアプローチでは、最も一般的または重要なインテントを捕捉できない可能性があります。
参考リンク
AI製品： https://cloud.google.com/products/ai/
</div></details>

### Q. 24
あなたは、現在構築中のBigQueryベースのデータウェアハウスのデータモデルを作成する責任を与えられました。スター型データスキーマを使用する既存のオンプレミス販売データウェアハウスをBigQueryプラットフォームに移行することが、目下の課題です。しかし、過去30日間の履歴データに対してクエリを実行したところ、パフォーマンスのボトルネックが発生しました。Googleが推奨するベストプラクティスに従って、ストレージ費用を抑えながらクエリ速度を向上させるには、どのような対策を講じればよいでしょうか？
1. 
2. 
3. 
4. トランザクションの日付でデータをパーティショニングします。
<details><div>
    答え：4
説明
BigQueryで過去30日分のデータをクエリする際に、データウェアハウスのストレージコストを増加させずにクエリのパフォーマンスを高速化するには、次のことを考慮する必要があります：
D. 
パーティショニング： パーティショニングとは、特定の属性（この場合はトランザクション日付など）に基づいて、データをより小さく管理しやすい塊に整理することです。パーティショニングは、時間ベースのデータのクエリ・パフォーマンスを向上させる効果的な方法です。データを日付でパーティショニングすると、BigQueryは特定の日付範囲のクエリを実行する際に、無関係なパーティションを効率的に削除することができます。
時間ベースのクエリ： パーティショニングは、過去30日間のデータをクエリする要件に適しています。これにより、BigQueryは関連するパーティションに焦点を当てることができ、データセット全体をスキャンするよりも大幅に高速化されます。
コスト効率： パーティショニングはデータの論理的な整理であるため、ストレージコストを増加させることはありません。使用するストレージの代金は支払いますが、パーティショニング自体がストレージ・コストを増加させることはありません。コストに影響を与えることなく、クエリのパフォーマンスを最適化します。
誤ったオプション
オプションA（データの非正規化）は、特定のタイプのクエリには役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスの問題には特に対応していません。
オプションB（顧客IDごとにデータをシャーディングする）は、日付ベースのクエリのパフォーマンスを直接改善しない可能性があり、特定の日付範囲のデータをクエリするときに複雑さをもたらす可能性があります。
オプションC（ビューで次元データをマテリアライズする）は、クエリを単純化するのに役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスを最適化するには、パーティショニングほど効果的ではないかもしれません。
参考リンク
BigQuery パーティショニング: https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 25
5年分のログデータをクラウドストレージにアップロードしました。あるユーザーから、ログの特定のデータポイントが想定される範囲から外れており、潜在的なエラーがあることを指摘されました。あなたの目的は、この問題を解決し、コンプライアンス目的で元のデータを保持しながら、将来的にプロセスを再実行できるようにすることです。どのような手順を踏むべきでしょうか？
1. 
2. 
3. データフローワークフローを作成し、クラウドストレージからデータを読み取り、予期される範囲外の値をチェックし、値を適切なデフォルトに設定し、更新されたレコードをクラウドストレージの新しいデータセットに書き込む。
4. 
<details><div>
    答え：3
説明
コンプライアンス上の理由から元のデータを保持しながら、ログデータ内の想定範囲外のデータポイントの問題に対処するには、次のことを検討する必要があります：
C. C. 
このオプションが適切な理由は以下の通り：
データ変換： データ変換： データフローを使用することで、元のデータセットを保持したまま、期待範囲外のデータポイントを識別して修正するデータ変換ロジックを実装することができます。これにより、誤ったデータが確実に修正されます。
オリジナルデータの保持： 更新されたレコードをクラウド・ストレージの新しいデータセットに書き込むことで、コンプライアンス上の理由からオリジナル・データの整合性を維持することができます。このアプローチでは、元のデータセットがそのまま維持され、分析や使用のために修正されたクリーンなバージョンが提供されます。
誤ったオプション
オプションA（データをBigQueryにインポートし、エラーのある行をスキップする）はうまくいくかもしれませんが、コンプライアンス上の理由で必要となる可能性がある、元のデータを変更されていない状態で保持することはできません。
オプションB（Compute Engineのインスタンスを作成し、エラーのある行をスキップしながらデータをコピーする）は、手作業で複雑なプロセスになる可能性があり、Dataflowのようなデータ処理フレームワークを使用するほど効率的ではないかもしれない。
オプションD（更新されたレコードをクラウドストレージの同じデータセットに書き込む）は、元のデータを上書きする。
</div></details>

### Q. 26
サーバーレスツールとSOL構文を活用して開発を加速し、パイプラインの実行時間を短縮しながら、スピードと処理要件を満たすGoogle Cloudパイプラインを構築するにはどうすればよいでしょうか？現在のアプローチでは、大規模なデータ変換にPySparkを使用しており、実行に12時間以上かかっています。生データがクラウドストレージに転送されていることは重要です。
1. 
2. 
3. Cloud StorageからBigQueryにデータを取り込み、PySparkコマンドをBigQuery SQLクエリに変換してデータを変換し、変換結果を新しいテーブルに書き込みます。
4. 
<details><div>
    答え：3
説明
Google Cloud上の構造化データで速度と処理要件を満たしながら、開発とパイプラインの実行時間を短縮するには、次のことを検討する必要があります：
C. C. 
サーバーレスでスケーラブル： BigQueryはサーバーレスデータウェアハウスであり、インフラストラクチャを管理することなく大規模なデータ処理を行うことができます。高速処理のために設計されているため、パイプラインの実行時間を短縮できる。
SQL構文： SQL構文を使用したいので、BigQueryは完全に管理された強力なSQLエンジンを提供します。PySparkのコマンドを直接BigQueryのSQLクエリに変換できるので、移行や変換のプロセスがスムーズになります。
クラウドストレージとの統合： BigQueryはクラウドストレージとシームレスに統合されており、クラウドストレージからBigQueryにデータを取り込んで分析や変換を行うことができます。
変換の書き込み： BigQueryはSQL変換の結果を新しいテーブルに書き出すことをサポートしており、元のデータを保持したまま、さらなる分析のために変換されたデータを保存できます。
誤ったオプション
オプションA（Dataproc上でパイプラインを実行する）では、Dataprocクラスタのセットアップと管理が必要になるため、BigQueryのようなフルマネージドサービスを使用する場合と比較して、コスト効率や利便性が劣る可能性があります。
オプションB（Cloud SQLにデータを取り込み、連携クエリを使用）は、データ処理に複数のサービスを使用するため複雑さが生じ、BigQueryのようなパフォーマンスメリットが得られない可能性がある。
オプションD（Apache Beam Python SDKの使用）は有効な選択肢ですが、BigQueryのビルトインSQL機能を活用するのに比べて開発工数がかかる可能性があります。Pythonの使用を好み、データ変換プロセスをより制御する必要がある場合は、Apache Beamが適切な選択肢になる可能性があります。
</div></details>

### Q. 27
テキストファイルを取り込んで変換するDataflowパイプラインをテストしています。Dataflowジョブは、圧縮されたgzipファイル、デッドレターキューによるエラー処理、データ結合のためのSideInputsの利用により、予想よりも遅く実行されています。パイプラインの完了を加速するために、どのようなアクションを取るべきでしょうか？
1. 
2. 
3. 
4. SideInputの代わりにCoGroupByKeyを使用する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
CoGroupByKey： CoGroupByKey: CoGroupByKeyは、Apache Beam（Dataflowの基盤）の変換で、複数の入力PCollectionsからのデータを共通のキーに基づいてグループ化する。複数のソースからのデータを効率的に結合するために使用できます。SideInputsの使用に関連したパフォーマンス問題が発生している場合、CoGroupByKeyに切り替えることが有効な最適化かもしれません。SideInputsは、特に大きなデータセットを扱う場合、要素ごとのルックアップを伴うため、オーバーヘッドが発生する可能性があります。
SideInputsの代わりにCoGroupByKeyを使用するように処理戦略を変更することで、パフォーマンスの問題に対処できる可能性があります。このオプションの選択は、パイプラインの仕様と、どこでボトルネックが発生しているかに依存します。パイプラインの動作とパフォーマンス特性を分析し、十分な情報を得た上で決定することが重要です。
誤ったオプション
オプションA（圧縮Avroファイルへの切り替え）は、主にデータストレージと圧縮効率に対処しますが、特にパフォーマンスのボトルネックが圧縮ではなくデータ処理にある場合、Dataflowジョブを直接迅速化しない可能性があります。
オプションB（バッチサイズを小さくする）は、ある程度ジョブ効率を向上させることができますが、SideInputsやjoinオペレーションに関連するパフォーマンス問題に対処する最も効果的な方法ではないかもしれません。小さいバッチは並列処理に役立つが、処理戦略を根本的に変えないかもしれない。
オプションC（エラーをスローしたレコードを再試行する）は、エラー処理に重点を置いており、ジョブ実行時間の問題に直接対処していない。エラーを効果的に処理することは不可欠ですが、ジョブの完了を早める主要な方法ではありません。
参考リンク
https://beam.apache.org/documentation/transforms/python/aggregation/cogroupbykey/
</div></details>

### Q. 28
あなたは、PII（個人を特定できる情報）データを含む可能性のあるファイルをクラウドストレージにストリームし、最終的にBigQueryにストリームするリアルタイム予測エンジンを構築しています。PIIデータへの不正アクセスを防ぐために、クラウドデータ損失防止API（DLP API）を使用して、名前や電子メールなどの機密データをマスキングしながら参照整合性を維持するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. PIIデータを暗号化フォーマット保持トークンで置き換えて偽名を作成する。
<details><div>
    答え：4
説明
参照整合性を維持しながら、PII データに権限のない個人がアクセスできないようにするには、次のアプローチを検討する必要があります：
D. D. 
このオプションが適切な理由は以下のとおりです：
暗号化形式保存トークン： 暗号化トークン：暗号化トークンを使用することで、PII データの形式と参照整合性を保持したまま、PII データを仮名化することができます。これにより、名前や電子メールなどの結合キーが引き続き効果的に使用できるようになります。
機密データの保護： 暗号化トークンを使用することで、強力なデータ保護が実現し、権限のない個人による機密PIIデータへのアクセスや悪用が困難になります。
不正なオプション
オプション A（暗号化トークンを作成し、トークン化されていないデータをロックダウンされたバケツに保存する）は、PII データを仮名化するという点ではオプション D に似ていますが、フォーマットと参照整合性を維持するために不可欠な暗号化フォーマット保持トークンの使用を指定していません。
オプションB（すべてのPIIデータを再編集する）は、機密情報を永久に削除します。これは、結合キーの参照整合性を維持する必要がある場合には適していない可能性があります。
オプションC（BigQueryのすべてのテーブルをスキャンし、検出したデータをPIIでマスクする）はBigQueryに有効かもしれませんが、クラウドストレージからのPIIデータ取り込みプロセスに直接対応しておらず、暗号化トークンの使用についても言及していません。
参考リンク
クラウドDLP
</div></details>

### Q. 29
図書館の本とその詳細(著者や出版年など)をモニタリングするアプリケーションをオンプレミスのデータ ウェアハウスから BigQuery に移行する際に、借りた書籍の著者に関する情報のクエリ速度を最速にするために、Google が推奨するスキーマ設計手法に従ってデータをどのように構成しますか?既存の設定では、著者の詳細を個別のテーブルに保持し、現在のリレーショナル データベース内の共有キーを介して書籍情報にリンクします。
1. スキーマを同じに保ち、書籍と各属性の異なるテーブルを維持し、現在行っているようにクエリを実行します
2. 幅が広く、作成者の銘、性、年月日など、各属性の列を含むテーブルを作成します
3. 書籍と著者に関する情報を含むテーブルを作成しますが、著者フィールドは著者列内にネストします。
4. スキーマを同じに保ち、すべてのテーブルを結合するビューを作成し、常にビューをクエリします
<details><div>
    答え：3
説明
図書館の図書追跡アプリケーションを BigQuery に移行する際に、借りた各書籍の著者に関するクエリの速度を最適化するには、次の方法を検討する必要があります。
C. 
ネストされたデータ: BigQuery は、テーブル内のネストされたフィールドと繰り返されるフィールドをサポートしています。著者情報を著者列内に入れ子にすることで、コストのかかる結合を回避しながら、書籍と著者の関係を維持できます。これにより、各書籍の著者に関する効率的なクエリが可能になります。
結合の削減: 著者情報を同じテーブル内に保持すると、著者の詳細と書籍の詳細を照会するときに結合が不要になります。これにより、クエリの実行が高速化され、待機時間が短縮されます。
簡略化されたクエリ: 入れ子になったデータを使用すると、クエリを簡略化し、複数のテーブルを結合する複雑さを回避できます。著者情報は、書籍情報と同じ行内で直接アクセスできます。
正しくないオプション -
オプション A (書籍と属性のテーブルを分けてスキーマを同じに保つ) は、結合が必要になる可能性が高く、著者に関するクエリでは効率的ではない可能性があります。
オプション B (各属性の列を含む幅の広いテーブルを作成する) は、特に作成者に複数の属性がある場合、スキーマが非正規化され、保守性が低下する可能性があります。
オプション D(すべてのテーブルを結合するビューを作成する)では、結合が必要になるため、クエリのパフォーマンスが低下する可能性があり、ネストされたデータ構造に対する BigQuery の機能を十分に活用できない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/nested-repeated
</div></details>

### Q. 30
データ ポイントを受信して GUID を生成するサービスを通じて、新しい Web サイト ユーザーにグローバル一意識別子 (GUID) を提供するときに、バックプレッシャーの懸念を最小限に抑えるためにパイプラインを構成するにはどうすればよいでしょうか。このデータは、内部システムと外部システムの両方から発生し、パイプライン内のマイクロサービスを介してHTTP呼び出しを介してアクセスされ、システムへのバックプレッシャーを回避しながら、マルチスレッドの可能性がある毎秒数万件の大量のメッセージの影響を受けます。
1. HTTP経由でサービスを呼び出します
2. パイプラインをクラス定義で静的に作成します
3. DnFnのstartbundleメソッドで新しいオブジェクトを作成します
4. ジョブを 10 秒単位でバッチ処理します。
<details><div>
    答え：4
説明
D. 
このオプションは、メッセージを 10 秒間隔でバッチ処理することを提案します。このアプローチの理論的根拠は次のとおりです。
バックプレッシャーの低減: 処理のためにメッセージをバッチ処理すると、メッセージの取り込みと処理の速度を制限することで、バックプレッシャーを減らすことができます。これにより、パイプラインへのデータフローを制御し、処理負荷の急増を防ぐことができます。
ただし、このアプローチにはトレードオフも生じることに注意することが重要です。
待機時間: メッセージをバッチ処理すると、一部のメッセージが次のバッチ ウィンドウまで遅延する可能性があるため、処理に待機時間が発生する可能性があります。これは、リアルタイムまたは低待機時間の処理が重要なシナリオには適していない可能性があります。
複雑さ: バッチ処理を実装すると、特にマイクロサービスや HTTP 呼び出しを処理する場合に、パイプラインが複雑になる可能性があります。定期的にバッチを管理およびフラッシュするメカニズムが必要になります。
正しくないオプション -
オプション A (HTTP 経由でサービスを呼び出す): このオプションは、通常、リアルタイムまたはほぼリアルタイムの処理に適していますが、バックプレッシャーを減らすという目標に合わない場合があります。各メッセージに対して HTTP 呼び出しを行う際の高スループットと潜在的なボトルネックを考慮することが重要です。
オプション B (クラス定義でパイプラインを静的に作成する) と C (DoFn の startBundle メソッドで新しいオブジェクトを作成する): これらのオプションは、バックプレッシャーに直接対処するのではなく、パイプライン コンポーネントの設計とインスタンス化に関連しています。これらは、高スループットのシナリオにおけるバックプレッシャーの懸念を本質的に軽減するものではありません。
</div></details>

### Q. 31
データ ウェアハウスを Google Cloud に移行し、オンプレミスのデータセンターをシャットダウンしているところです。この取り組みの優先度が高いことを認識した上で、クラウドへの初期データ転送に十分な帯域幅が提供されることを期待しています。移動するファイルの量はそれほど多くありませんが、個々のファイルは 90 ギガバイトを占有します。さらに、トランザクション システムから Google Cloud ベースのウェアハウスへの更新フローをリアルタイムで一定に維持することを目指しています。
データの移行と、ウェアハウスへの中断のない書き込みの保証の両方に推奨されるツールは何ですか?
1. 
2. 
3. gsutil (移行用)Pub/Sub と Dataflow によるリアルタイム更新。
4. 
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
データ移行(gsutil):
gsutil: Google Cloud Storage Utility(gsutil)は、Google Cloud Storage との間でデータを効率的に転送するためのコマンドライン ツールです。これは、90 GB のファイルなどの大きなファイルの移行を処理するのに適しています。これは、初期データ読み込みのための簡単で効率的な選択です。
リアルタイム更新(Pub/Sub とデータフロー):
Pub/Sub: Google Cloud Pub/Sub は、トランザクション システムからダウンストリーム サービスにリアルタイムでデータをストリーミングするために使用できるスケーラブルなメッセージング サービスです。リアルタイムのデータストリーミング用に設計されており、他のGoogle Cloudサービスとうまく統合できます。
データフロー: Google Cloud Dataflow は、強力なストリームおよびバッチ データ処理サービスです。Pub/Sub からのリアルタイム データ ストリームを処理し、変換、集計、その他のデータ処理タスクを実行するために使用できます。リアルタイムのデータ更新に適しており、複雑なデータ処理シナリオを処理できます。
正しくないオプション -
オプション A (移行用のストレージ転送サービス。Pub/Sub と Cloud Data Fusion (リアルタイム更新用):
ストレージ転送サービス: ストレージ転送サービスは大規模なデータ転送に効率的ですが、主に 1 回限りまたは定期的な転送用に設計されています。リアルタイムのデータストリーミングには最適化されていません。
Cloud Data Fusion: Cloud Data Fusion はデータ統合サービスですが、通常はリアルタイムの更新ではなく、バッチ処理や ETL 処理に使用されます。リアルタイムの更新に使用すると、ソリューションが複雑になりすぎる可能性があります。
オプション B(移行用の BigQuery Data Transfer Service。Pub/Sub と Dataproc (リアルタイム更新用):
BigQuery Data Transfer Service: BigQuery Data Transfer Service は、BigQuery への自動データインポートに重点を置いているため、Google Cloud Storage への大容量ファイルの移行には適していない場合があります。
Dataproc: Google Cloud Dataproc は、主に Apache Spark と Hadoop のジョブの実行に使用されますが、リアルタイムの更新には必要ない場合があります。バッチ処理に適しています。
オプション D(移行とリアルタイム更新の両方に gsutil):
gsutil: gsutil はデータ移行には適していますが、リアルタイムのデータ ストリーミングや処理用には設計されていません。リアルタイム更新に gsutil を使用するのは現実的ではありません。
参考リンク -
https://cloud.google.com/storage/docs/gsutil
</div></details>

### Q. 32
Bigtable を使用して取引アプリケーションでこれらのインデックスの株式市場データを保存および提供する際に、すべての主要インデックスの最新の株価にアクセスするための最もシンプルなクエリを確実に行うには、Bigtable 内で行キーとテーブルをどのように構成すればよいでしょうか。
1. 
2. すべてのインデックスに対して一意のテーブルを 1 つ作成し、行キーの設計として逆タイムスタンプを使用します。
3. 
4. 
<details><div>
    答え：2
説明
B. 
このオプションが適切であると考えられる理由は次のとおりです。
すべてのインデックスに対して 1 つのテーブル: すべてのインデックスに対して 1 つのテーブルを使用することで、複数のテーブルを作成する必要がなくなり、管理が簡素化されます。インデックスの数が多い場合は、それぞれに個別のテーブルを管理するのが面倒になる可能性があるため、特に便利です。
行キーとしての逆タイムスタンプ: 行キー設計として逆タイムスタンプを使用すると、最新の株価に簡単にアクセスできます。Bigtable は行を辞書式に並べ替えるため、最新のデータがテーブルの先頭に配置され、効率的に取得できます。
オプションBは機能しますが、いくつかのトレードオフと複雑さが伴います。
複雑な範囲クエリ: 最新のデータを取得するのは効率的ですが、履歴データに対して範囲クエリを実行するとより複雑になる場合があります。古いデータを効率的に取得するために、追加のロジックを実装する必要がある場合があります。
データの分離: 1 つのテーブルを使用すると、すべてのインデックスが一緒に格納されます。特定のインデックスを含むクエリを実行したり、特定のインデックスのデータを分離したりする必要がある場合は、追加のフィルター処理や処理が必要になることがあります。
正しくないオプション -
オプション A (すべてのインデックスに対して一意のテーブルを 1 つ作成し、インデックスとタイムスタンプを行キーの設計として使用します):
この方法では、タイムスタンプを抽出するために解析を必要とする複雑な行キー設計になる可能性があります。これにより、履歴データの範囲クエリの効率が低下する可能性があります。
オプション C (インデックスごとに個別のテーブルを用意し、行キーの設計としてタイムスタンプを使用します):
各インデックスのデータへのアクセスは簡素化されますが、インデックスの数が増えると、個別のテーブルを維持する必要があるため、管理オーバーヘッドが発生する可能性があります。
オプション D (インデックスごとに個別のテーブルを用意し、行キーの設計として逆タイムスタンプを使用します):
このオプションでは、インデックスごとに分離できますが、テーブルが急増し、管理が困難になる可能性があります。
参考リンク https://cloud.google.com/bigtable/docs/schema-design
</div></details>

### Q. 33
データの取り込みやレポート作成のパフォーマンスを損なうことなく 1 つのマスター データセットを維持するには、BigQuery のストリーミング API を使用して、Google が推奨するプラクティスに従って、レポートのみのデータ ウェアハウスのデータ読み込みプロセスをどのように構築すればよいのでしょうか?
1. 
2. 
3. ステージングされたデータを運用テーブルに移動し、ステージング テーブルの内容を 3 時間ごとに削除するステージング テーブルを用意します。
4. 
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
ステージング テーブル: ステージング テーブルを使用して、受信データを最初に取り込んで格納することは、一般的なベスト プラクティスです。これは、データ インジェスト用のバッファーを提供し、インジェスト プロセスを運用データセットから分離するのに役立ちます。
定期的な ETL: ステージング テーブルから運用テーブルに定期的に (この場合は 3 時間ごと) データを移動することで、マスター データセットの更新のタイミングを制御できます。これにより、レポートクエリが進行中の取り込みの影響を受けなくなります。
データのクリーンアップ: データを移動した後にステージング テーブルの内容を削除すると、過剰なデータが蓄積されることなく、新しいデータ インジェストに引き続き使用できます。
正しくないオプション -
オプション D (ステージング テーブルの内容を 30 分ごとに削除する) は、一部のユース ケースでは頻繁すぎる可能性があり、特に監査やエラー分析にデータ保持が必要な場合に、データ管理のオーバーヘッドが増加する可能性があります。
オプション A と B (3 時間または 90 分ごとに運用テーブルを更新する) では、レポート データセットの変更の反映に遅延が発生し、レポートの適時性に影響を与える可能性があります。
参考リンク -
https://cloud.google.com/bigquery/docs/streaming-data-into-bigquery
</div></details>

### Q. 34
新しい Dataflow バッチ ジョブを開始します。ジョブは正常に開始され、いくつかの要素を処理しますが、突然失敗して終了します。Dataflow モニタリング インターフェースにアクセスすると、パイプライン内の特定の DoFn に関連するエラー メッセージが検出されます。
これらのエラーの考えられる根本原因は何ですか?
1. 
2. ワーカー コードの例外
3. 
4. 
<details><div>
    答え：2
説明
B. 
Dataflow ジョブを開始すると、しばらくの間は正常に実行され、ワーカー コードの例外やエラーが原因で失敗することがあります。これらの例外により、ジョブが突然シャットダウンする可能性があります。特定の DoFn (パイプライン内の要素を処理するために定義する関数) に関連するエラーが表示される場合は、その DoFn 内のコードに問題がある可能性があります。
正しくないオプション -
A. ジョブの検証: Dataflow は通常、ジョブを開始する前に検証し、オプションの欠落や構成ミスなどの問題をチェックします。ジョブの検証で問題が発生した場合、ジョブは最初から開始されていない可能性があります。
C. グラフまたはパイプラインの構築: Dataflow パイプラインの構築方法の問題(コンポーネントの接続の誤りやフローの設定ミスなど)に関連します。これらの問題は通常、ジョブの検証または構築中に検出されますが、発生した場合、ジョブが開始時に失敗したり、期待どおりに実行されなかったりする可能性があります。
D. アクセス許可が不十分: これはアクセス許可とアクセス制御に関連しており、ジョブの開始や必要なリソースへのアクセスを妨げる可能性があります。アクセス許可が不十分な場合、ジョブが開始されなかったり、実行前に問題が発生したりする可能性があります。
参考リンク -
https://cloud.google.com/dataflow/docs/guides/common-errors
</div></details>

### Q. 35
新規顧客向けに、Google Cloud コンピューティング リソースの純消費量を詳細に記した日次レポートを迅速かつ効果的に作成し、これらのリソースのユーザーを特定するにはどうすればよいでしょうか。
1. Cloud Logging データを BigQuery に毎日エクスポートします。プロジェクト、ログタイプ、リソース、ユーザーでフィルタリングされたビューを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Google Cloud コンピューティング リソースの正味消費量とリソースを使用したユーザーを示す日次レポートを迅速かつ効率的に生成するには、次のオプションが最も適しています。
ある。
このオプションが適切な理由は次のとおりです。
Cloud Logging から BigQuery へ: ログデータを効率的に保存、分析するための一般的な方法は、Cloud Logging のデータを BigQuery にエクスポートする方法です。これにより、BigQuery のクエリ機能とスケーラビリティを活用できます。
フィルタリング用のビュー: BigQuery でビューを作成すると、プロジェクト、ログタイプ、リソース、ユーザーなどの特定の条件に基づいてデータを事前にフィルタリングできます。この事前フィルタリングにより、レポートを生成するための関連データを操作できるようになります。
毎日のエクスポート: 毎日のエクスポートを実行すると、レポートごとに新しいデータセットを操作でき、データを最新の状態に保つことができます。
正しくないオプション -
オプション B(プロジェクト、リソース、ユーザーで Cloud Logging のデータをフィルタリングし、そのデータを CSV 形式でエクスポートする)は機能する可能性がありますが、より複雑なクエリやレポート要件に対応する BigQuery の柔軟性と拡張性に欠けます。
オプション C(Cloud Logging でデータをフィルタリングして BigQuery にインポートする)では、追加のデータ移動手順が導入されるため、直接エクスポートよりも効率が悪く、タイムリーにならない可能性があります。
オプション D(Cloud Logging データを CSV 形式で Cloud Storage にエクスポートし、Dataprep を使用してクレンジングする)は複雑さを増し、日次レポートを生成するための BigQuery の直接的なアプローチほど効率的ではない可能性があります。
参考リンク -https://cloud.google.com/logging/docs/export/bigquery
</div></details>

### Q. 36
現在、単一のアジア地域内の顧客のみに対応しているスタートアップのWebアプリケーションが、最初はコストの最適化を優先し、後にネイティブJDBCドライバーを使用する要件でグローバルなプレゼンスとパフォーマンスの向上に焦点を当てながら、グローバルな顧客サービスを可能にするための資金を求める場合、どのような手順を踏む必要がありますか?
1. 最初に Cloud Spanner を使用して単一リージョンのインスタンスを構成し、資金を確保した後に複数リージョンの Cloud Spanner インスタンスを構成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
Cloud Spanner のスケーラビリティ: Cloud Spanner は、グローバルに分散された水平方向にスケーラブルなデータベースであり、複数のリージョン間で強力な一貫性を提供できます。単一リージョンのインスタンスから開始し、マルチリージョンのインスタンスを構成することは、資金を確保した後、グローバルなプレゼンスとパフォーマンスを最適化するという目標と一致します。
強力な整合性: Cloud Spanner は、強力な整合性が保証されていることで知られており、データの一貫性が重要なグローバル アプリケーションに適しています。
ネイティブ JDBC サポート: Cloud Spanner はネイティブ JDBC ドライバをサポートし、ウェブアプリケーションの要件との互換性を確保します。
正しくないオプション -
B. 最初に Cloud SQL for PostgreSQL の高可用性インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアのレプリケーションで Bigtable を使用します。
このオプションでは、可用性の高い Cloud SQL for PostgreSQL インスタンスから始めることをお勧めしますが、これは当初必要以上にコストが高くなる可能性があります。Bigtable はグローバル レプリケーションを提供できますが、Cloud SQL を最初に選択した時点では、資金調達前の費用最適化という目標に合致していない可能性があります。
C. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアで Bigtable を使用します。
オプション B と同様に、当初の費用最適化を主な目標としている場合、Cloud SQL for PostgreSQL から始めるのは最も費用対効果の高い選択肢ではない可能性があります。また、Cloud SQL のグローバル拡張機能は、Cloud Spanner に比べて制限されています。
D. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、可用性の高い構成の Cloud SQL for PostgreSQL を使用します。
このオプションでは、Bigtable や Cloud Spanner などのグローバルに分散されたデータベースを使用しないため、グローバルなプレゼンスとパフォーマンスを最適化するという資金調達後の目標に合わない可能性があります。
要約すると、オプション B、C、D にはそれぞれメリットがありますが、オプション A は、Cloud Spanner のグローバルなスケーラビリティと強力な整合性機能を活用して、初期費用の最適化目標と資金調達後のグローバル展開とパフォーマンスの最適化の両方の目標と一致するため、シナリオに最適な選択肢です。
参照リンク - リージョン構成とマルチリージョン構成 - Cloud Spanner
</div></details>

### Q. 37
大規模なデータ転送に関する Google が推奨するベスト プラクティスを遵守しながら、わずか数時間でデータ転送を完了することを目標に、オンプレミスのデータセンターから Google Cloud に 1 PB のデータを安全かつ効率的に移行するには、どのような手順を踏む必要がありますか?
1. 
2. Transfer Appliance を使用し、エンジニアに手動でデータの暗号化、復号化、検証を依頼します。
3. 
4. 
<details><div>
    答え：2
説明
Google が推奨するプラクティスに従いながら、安全な接続を介してオンプレミスのデータセンターから Google Cloud に 1 PB のデータを効率的に移行するには、次のアプローチを検討する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
Transfer Appliance: Google の Transfer Appliance は、大量のデータを安全かつ効率的に移行できるように設計されています。これは、データをオフラインで読み込み、Google Cloud Storage に取り込むために Google に送付するために使用できる物理ストレージ アプライアンスです。
手動暗号化: Transfer Applianceの使用中に、アプライアンスにロードする前にデータを手動で暗号化できます。これにより、転送中のデータセキュリティが確保されます。
手動検証:データ転送が完了した後、エンジニアはデータを復号化して元のデータセットと比較することで、データの整合性を手動で検証できます。この検証プロセスにより、データが正確に転送されたことが保証されます。
正しくないオプション -
オプションA(Cloud Interconnect and Storage Transfer Service)は、わずか数時間で1 PBのデータを移行するために必要な速度を提供しない可能性があるため、このような大量のデータ転送には適していない可能性があります。
オプション C(Cloud VPN、並列 gcloud compute scp ジョブ、チェックサム)は、このような大量のデータを迅速かつ安全に転送するための最も効率的な方法ではない可能性があります。
オプション D(データを 3 TB のバッチに削減し、gsutil を使用し、チェックサムを実行する)は、小規模なデータセットでは実現可能ですが、大量のデータが含まれるため、わずか数時間で 1 PB の移行を行うのは現実的ではない可能性があります。
速度、セキュリティ、Google のベスト プラクティスの遵守を目標とする 1 PB のデータ移行では、手動で暗号化と検証を行う Transfer Appliance の使用をおすすめします。この方法は、大規模なデータセットを Google Cloud に転送するための安全で効率的な方法を提供します。
参考リンク -
https://cloud.google.com/products/data-transfer/
</div></details>

### Q. 38
CSV ファイルを Cloud Storage から BigQuery に読み込む際に、1 つの列に STRING や INT64 などのデータ型が混在していたり、電話番号や住所などの値の形式に一貫性がなかったりするなど、ファイルの既知のデータ品質の問題を考慮して、データ品質を維持し、必要なクレンジングと変換を実行するためのデータ パイプラインをどのように確立すればよいのでしょうか。
1. BigQuery に読み込む前に、Data Fusion を使用してデータを変換します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
変換のための Data Fusion: Google Cloud Data Fusion は、ETL(抽出、変換、読み込み)プロセスのための強力なツールです。データ品質の問題に対処するために不可欠な、データ変換、クレンジング、エンリッチメントの機能を提供します。
高度な変換: Data Fusion では、ビジュアル インターフェースやカスタム コードを使用して複雑なデータ変換を実行できるため、データ型の不一致や一貫性のない書式設定などの問題を処理するのに適しています。
BigQuery との統合: Data Fusion は BigQuery とシームレスに統合できるため、変換されたデータを BigQuery テーブルに直接読み込むことができるため、データ パイプラインが簡素化されます。
オプション A は、BigQuery に読み込む前に Google Cloud Data Fusion を使用してデータ変換を行うもので、データ品質の問題に対処し、高度な変換機能を提供する包括的なアプローチです。これは、シナリオで説明されているように、複雑なデータ クレンジングと変換タスクを処理する場合に推奨される選択肢です。
正しくないオプション -
B. データを BigQuery に読み込む前に、Data Fusion を使用して CSV ファイルを AVRO などの自己記述型データ形式に変換します。
データ形式の変換は特定のシナリオでは役立ちますが、データ型の不一致や一貫性のない書式設定など、質問に記載されているデータ品質の問題に直接対処するものではありません。
C. 目的のスキーマを使用してステージング テーブルに CSV ファイルを読み込み、SQL で変換を実行してから、結果を最終的な変換先テーブルに書き込みます。
変換に SQL を使用することは有効なアプローチですが、データ品質の問題は SQL のみを使用して効果的に処理できることを前提としていますが、複雑な問題には当てはまらない場合があります。
D. 目的のスキーマでテーブルを作成し、CSV ファイルをテーブルにロードし、SQL を使用してその場で変換を実行します。
このオプションでは、最終的な変換先テーブルにデータを直接読み込む必要がありますが、データ品質の問題に事前に対処しないと危険です。一般に、データの検証と変換にはステージング テーブルを使用する方が安全です。
参照リンク: Data Fusion の概要
</div></details>

### Q. 39
e コマース プラットフォームでの顧客の購入確率を予測することを目的とした新しいディープ ラーニング モデルの開発に取り組んでいる間、初期トレーニング データセットと新しいテスト データセットの両方を使用して、モデルのパフォーマンスの評価を実施しました。この評価の結果、モデルが提供されたデータに対して過学習の傾向を示していることが明らかになりました。目的は、新しいデータの結果を予測する際に、モデルの精度を高めることです。この目標を達成するには、どのような手順を踏む必要がありますか?
1. 
2. トレーニング データセットのサイズを大きくし、入力特徴の数を減らします。
3. 
4. 
<details><div>
    答え：2
説明
新しいデータを予測する際の過学習に対処し、深層学習モデルの精度を向上させるには、次のことを行う必要があります。
B. 
このオプションが適切な理由は次のとおりです。
トレーニング データを増やす: トレーニング データセットのサイズを大きくすると、モデルの一般化が向上し、過学習を減らすことができます。データが多いほど、基になるパターンがより広く表現され、新しいデータでのモデルのパフォーマンスが向上する可能性があります。
入力特徴量を減らす: 入力特徴量が多すぎる過度に複雑なモデルは、トレーニング データ内のノイズをキャプチャできるため、過学習する傾向があります。入力特徴の数を減らすことで、モデルを単純化し、最も関連性の高い情報に焦点を合わせることができるため、汎化を改善できます。
過学習を軽減する最も効果的な方法は、トレーニング データセットのサイズを大きくすると同時に、入力フィーチャの数を減らしてモデルを単純化することです。この組み合わせにより、モデルの汎化が向上し、新しいデータの精度が向上します。
正しくないオプション -
オプション A、C、および D は、推奨されるアプローチではありません。
オプション A (データセットのサイズを増やし、入力特徴量を増やす): データセットのサイズと入力特徴の数の両方を増やすと、過学習がさらに悪化する可能性があります。モデルがすでに複雑すぎる場合は、データが多いだけでは役に立たない可能性があります。
オプション C (データセットのサイズを小さくし、入力フィーチャを増やす): データセットのサイズを小さくすると、モデルの一般化がさらに困難になる可能性があります。入力特徴量を増やしてデータを減らすと、モデルがさらにオーバーフィットになる可能性があります。
オプション D (データセットのサイズを小さくし、入力特徴量を減らす): データセットのサイズと入力特徴の数の両方を減らしても、モデルが意味のあるパターンを学習するための十分な情報が得られない可能性があります。
</div></details>

### Q. 40
オンライン小売業者の顧客サービスを強化するためのチャットボットを効果的に作成し、テキストと音声の両方のクエリを処理できると同時に、ローコードまたはノーコードのソリューションを模索し、キーワードベースの応答のための簡単なトレーニングを確保するにはどうすればよいでしょうか?
1. 
2. 
3. 
4. Dialogflow を使用してチャットボットを実装し、収集された最も一般的なクエリに基づいてインテントを定義します。
<details><div>
    答え：4
説明
D. 
Dialogflow は、モバイルアプリ、ウェブ アプリケーション、デバイス、ボット、自動音声応答システムなどに会話型ユーザー インターフェースを簡単に設計して統合できる自然言語理解プラットフォームです。Dialogflow を使用すると、ユーザーがプロダクトと対話するための新しい魅力的な方法を提供できます。Dialogflow では、テキスト入力や音声入力(電話や音声録音など)など、顧客からの複数のタイプの入力を分析できます。また、テキストまたは合成音声のいずれかで、いくつかの方法で顧客に応答することもできます。
参考リンク -
https://cloud.google.com/dialogflow/docs
</div></details>

### Q. 41
航空宇宙企業独自の形式から BigQuery にフライトデータを最も効果的にインポートし、リソース消費を最小限に抑えながら、この新しいデータソース間の接続を確立し、BigQuery へのデータ ストリーミングを容易にするにはどうすればよいでしょうか。
1. 
2. 
3. 
4. Apache Beam カスタム コネクタを使用して、データを Avro 形式で BigQuery にストリーミングする Dataflow パイプラインを作成します。
<details><div>
    答え：4
説明
オプション D. 
このシナリオでは、特定の形式の独自のフライト データがあり、最小限のリソース消費で効率的に BigQuery にインポートする必要があります。
Apache Beam カスタム コネクタと Dataflow を併用して Avro 形式で BigQuery にデータをストリーミングすることは、いくつかの理由から最適な選択肢です。
Apache Beam は、複雑なデータ インジェストと変換タスクを処理できる強力で柔軟なデータ処理フレームワークです。
Avro はコンパクトで効率的なデータシリアル化形式であり、大量のデータのストリーミングと保存に適しています。
カスタム コネクタを使用すると、データ インジェスト プロセスを独自のデータ形式に合わせて調整し、スムーズで効率的なデータ転送を確保できます。
Dataflow は、データ量に合わせて自動的にスケーリングできるマネージド サービスであり、リソースを手動で管理してプロビジョニングする必要性を減らします。
正しくないオプション -
A. 定期的な ETL バッチ ジョブの Cloud Functions の関数をトリガーするシェル スクリプトを記述する:
このオプションは、定期的なバッチジョブの実行を示唆していますが、リアルタイムのデータストリーミングには適していない可能性があります。
また、データのストリーミングに効率的である可能性のある Avro 形式の使用についても言及していません。
B. 標準の Dataflow パイプラインを使用して BigQuery に生データを保存し、後で形式を変換する:
このアプローチでは、データが未加工の形式で BigQuery に保存されますが、これは BigQuery の機能を利用する最も効率的な方法ではない可能性があります。
これには、既に保存されているデータを変換する追加の手順が含まれますが、これは、目的の形式でデータをストリーミングするほどリソース効率が良くない可能性があります。
C. Apache Hive を使用して、データを CSV 形式で BigQuery にストリーミングする Dataproc ジョブを作成します。
Apache Hive はバッチ処理には適したツールですが、リアルタイムのデータ ストリーミングには適していない可能性があります。
CSV 形式は Avro ほどストリーミングに効率的ではなく、より多くのリソースを消費する可能性があります。
オプション D は、Apache Beam とカスタム コネクタを活用して Avro 形式で BigQuery にデータをストリーミングし、リソース消費を最小限に抑えながら効率的かつリアルタイムのデータ取り込みを実現するため、最も適切な選択肢です。
参照リンク - Apache Beam のプログラミング モデル
</div></details>

### Q. 42
オンライン証券会社には、大量の取引処理アーキテクチャが必要です。ジョブをトリガーするセキュア・キューイング・システムを作成する必要があります。ジョブはGoogle Cloudで実行され、同社のPython APIを呼び出して取引を実行します。ソリューションを効率的に実装する必要があります。あなたは何をするべきか?
1. Pub/Sub プッシュ サブスクリプションを使用して Cloud Functions の関数をトリガーし、Python API にデータを渡します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Google Cloud で実行されるジョブをトリガーし、会社の Python API を呼び出して取引を実行する安全なキューイング システムを作成するための最も効率的で適切なオプションは次のとおりです。
オプション A: 
Google Cloud Pub/Sub は、独立したアプリケーション間でリアルタイムかつ信頼性の高いメッセージングを実現するために設計されたメッセージング サービスです。
このシナリオでは、取引リクエストが発行される Pub/Sub トピックを設定できます。
Pub/Sub トピックへのプッシュ サブスクリプションを作成すると、メッセージがトピックにパブリッシュされたときに Cloud Functions の関数が呼び出されます。
その後、Cloud Functions の関数は取引データを Python API に渡して実行できます。
このアーキテクチャは効率的でスケーラブルであり、大量の取引処理に適しています。
正しくないオプション -
オプション B では、Compute Engine インスタンスでホストされるアプリケーションを作成して、Pub/Sub トピックへのプッシュ サブスクリプションを作成することを提案しています。これは機能しますが、Compute Engine インスタンスの管理とスケーリングが必要であり、Cloud Functions を使用する場合ほど効率的ではなく、サーバーレスでもない可能性があります。
オプションCは、NoSQLデータベースでのキューの作成について言及しています。NoSQL データベースはキューイングなど多くの目的に使用できますが、Google Cloud Pub/Sub などの専用のキューイング システムを設定する方が効率的で、この種のタスクに特化して構築されています。
オプション D では、Google Cloud のマネージド ワークフロー オーケストレーション サービスである Cloud Composer の使用について言及しています。Cloud Composer はさまざまなタスクに使用できますが、この特定のユースケースで Pub/Sub で Cloud Functions を直接使用する場合と比較して、単純なメッセージ キューイングと Python API 呼び出しの実行用に Cloud Composer を設定すると、不必要に複雑になる可能性があります。
参考リンク -
https://cloud.google.com/run/docs/triggering/pubsub-push
</div></details>

### Q. 43
あなたの会社は、データベースに 10 TB を超える現在のシステムから医療情報の大きな結果セットを取得し、さらにクエリを実行するためにデータを新しいテーブルに格納できるようにしたいと考えています。データベースは、メンテナンスの少ないアーキテクチャを持ち、SQL経由でアクセスできる必要があります。大規模な結果セットのデータ分析をサポートできるコスト効率の高いソリューションを実装する必要があります。あなたは何をするべきか?
1. 
2. BigQuery をデータ ウェアハウスとして使用する。大きなクエリをキャッシュするための出力先を設定します。
3. 
4. 
<details><div>
    答え：2
説明
大規模な結果セットのデータ分析をサポートしながら、メンテナンスが少なく、SQLへのアクセス性も備えている、最も費用対効果の高いソリューションは次のとおりです。
オプション B: 
説明：
Google BigQuery は、大規模なデータセットや複雑なクエリを処理するために設計された、サーバーレスで拡張性が高く、費用対効果の高いデータ ウェアハウス ソリューションです。
BigQuery は SQL に似たクエリ機能を備えており、SQL 経由でアクセスできます。
ストレージ、インデックス作成、クエリ パフォーマンスの最適化など、データの管理を自動的に処理します。
BigQuery ではクエリ結果をキャッシュできるため、大きな結果セットを複数回取得する際のパフォーマンスが大幅に向上し、クエリ費用を削減できます。
これは完全に管理されたサービスであり、手動のメンテナンスとスケーリングの必要性を排除します。
正しくないオプション -
オプション A(Cloud SQL を使用)とオプション C(Compute Engine で MySQL クラスタを使用)は、手動管理が必要で、BigQuery ほどシームレスにスケーリングできず、データ量が多い場合はコストがかかる可能性があるため、非常に大規模なデータセットや複雑な分析を処理するには最適な選択肢ではない可能性があります。
オプション D(Cloud Spanner を使用)は、グローバルに分散された可用性の高いデータベース サービスですが、大規模な結果セットの分析ではなく、トランザクション データ向けに設計されています。このユースケースでは、最も費用対効果の高いオプションではない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/cached-results
</div></details>

### Q. 44
オンプレミスのデータセンターに 15 TB のデータがあり、Google Cloud に転送したいとします。データは毎週変更され、POSIX 準拠のソースに保存されます。ネットワーク運用チームは、パブリック インターネットに 500 Mbps の帯域幅を付与しました。Google が推奨する方法に従って、週単位で Google Cloud にデータを確実に転送したい。あなたは何をするべきか?
1. 
2. 
3. データ センターにオンプレミス データ用の Storage Transfer Service をインストールし、毎週の転送ジョブを構成します。
4. 
<details><div>
    答え：3
説明
パブリック インターネットへの帯域幅が 500 Mbps の場合、オンプレミスのデータセンターから Google Cloud に 15 TB のデータを毎週確実に転送するには、Google が推奨するデータ転送方法の使用を検討する必要があります。このシナリオでは、
オプション C: 
このオプションが適している理由は次のとおりです。
Storage Transfer Service は、Google Cloud が提供するマネージド サービスで、オンプレミスのデータソースまたは別のクラウド プロバイダから Google Cloud Storage にデータを転送するのに役立ちます。これは、大規模で定期的な転送を効率的に処理するように設計されています。
データセンターに Storage Transfer Service をインストールすると、スケジュールされた自動転送ジョブを設定して、定期的に(毎週など)Google Cloud にデータを移動できます。
Storage Transfer Service は、並列処理、再開可能な転送、および効率的で信頼性の高いデータ転送を保証するその他の機能を処理して、転送プロセスを最適化できます。
正しくないオプション -
オプション A(Cloud Scheduler を使用して gsutil をトリガーする)は機能しますが、gsutil コマンドとそのスケジュールを管理する必要があります。Storage Transfer Service と同じレベルの自動化と組み込みのデータ転送の最適化は提供されません。
オプション B (Transfer Appliance を使用) は、非常に大規模なデータセットや、ネットワーク帯域幅が制限要因となる状況に適しています。ただし、データが 15 TB で帯域幅が 500 Mbps のこのシナリオでは、必要以上に複雑でコストがかかる可能性があります。
オプション D(Google Cloud 仮想マシンへの Storage Transfer Service のインストール)は、標準または推奨されるアプローチではありません。Storage Transfer Service は、データ転送の目的でオンプレミスで実行するように設計されており、仮想マシンにインストールすると、不必要な複雑さが加わります。
参考リンク -
https://cloud.google.com/storage-transfer/docs/overview
</div></details>

### Q. 45
ACID準拠のデータベースを必要とするシステムを設計しています。障害が発生した場合に、システムが必要とする人間の介入が最小限であることを確認する必要があります。あなたは何をするべきか?
1. 
2. 高可用性を有効にして Cloud SQL for PostgreSQL インスタンスを構成するを選択する必要があります。
3. 
4. 
<details><div>
    答え：2
説明
障害発生時に人的介入を最小限に抑えた ACID 準拠のデータベースを必要とするシステムを設計するには、オプション B: 
Cloud SQL for PostgreSQL は、フルマネージドで可用性が高く、ACID 準拠のリレーショナル データベース サービスを提供します。これは、信頼性とデータの整合性で知られるPostgreSQLに基づいています。
Cloud SQL インスタンスの高可用性を有効にすると、同じリージョン内の別のゾーンにスタンバイ レプリカが作成されます。プライマリ・インスタンスに障害が発生すると、スタンバイへの自動フェイルオーバーが発生し、ダウンタイムが最小限に抑えられ、データの整合性が確保されます。
PostgreSQLは一般に、ACID(原子性、一貫性、分離性、耐久性)トランザクションを強力にサポートしているため、データの整合性と信頼性を必要とするアプリケーションに適しています。
誤ったオプション-
オプション A(ポイントインタイム リカバリを使用した Cloud SQL for MySQL)は適切な選択肢ですが、ACID トランザクションをより強力にサポートする PostgreSQL が好まれることがよくあります。
オプション C(複数のクラスタを持つ Bigtable)は、ACID 準拠のリレーショナル データベース機能を提供するようには設計されていません。Bigtable は、さまざまなタイプのワークロードに使用される NoSQL データベースです。
オプション D(マルチリージョン構成の BigQuery)は、このシナリオには適用されません。BigQuery はデータ ウェアハウスおよび分析サービスであり、トランザクション リレーショナル データベースではありません。
参考リンク -
https://cloud.google.com/sql/docs/postgres
</div></details>

### Q. 46
あなたは、小売企業のeコマースWebサイトのデータストレージソリューションの設計を担当しています。同社は毎日膨大な量の取引データを生成しています。高可用性とスケーラビリティを確保しながら、待機時間を最小限に抑えたい。どのGCPサービスまたはデータベースを選択しますか?
1. 
2. 
3. 
4. Cloud Spanner
<details><div>
    答え：4
説明
小売企業のeコマースWebサイト向けのデータストレージソリューションを設計し、高可用性、スケーラビリティ、低遅延に重点を置いたデータストレージソリューションを設計し、毎日膨大な量のトランザクションデータを処理する場合、最適なGCPサービスは次のとおりです。
D. 
高可用性: Cloud Spanner は高可用性を実現するように設計されています。グローバルな分散アーキテクチャにより、複数のリージョン間でデータを複製できるため、リージョンの障害が発生した場合でもデータの可用性を維持できます。
スケーラビリティ: Cloud Spanner は水平方向にスケーラブルなデータベースであり、ビジネスの成長に合わせて増加するワークロードを自動的に処理できます。自動シャーディングと負荷分散を提供するため、大規模なアプリケーションに適しています。
低レイテンシ: Cloud Spanner は、リアルタイムのインタラクションと応答性を必要とする e コマース アプリケーションに不可欠な、データへの低レイテンシの読み取りおよび書き込みアクセスを提供します。
正しくないオプション -
A. Bigtable: Bigtable は拡張性の高い NoSQL データベースですが、e コマース Web サイトのようなトランザクション データには最適ではない可能性があります。これは通常、大規模なデータセットに対して高スループット、低遅延の読み取りと書き込みを必要とするアプリケーションに使用されますが、複雑なトランザクション クエリには最適化されない場合があります。
B. Firestore: Firestore は、モバイル アプリケーションやウェブ アプリケーションに適した NoSQL ドキュメント データベースです。特定のユースケースではうまく機能しますが、eコマースのトランザクションデータに必要なレベルのトランザクションの一貫性が得られない場合があります。
C. Cloud SQL: Cloud SQL はマネージド リレーショナル データベース サービスです。トランザクションの一貫性を提供できますが、特に大量のデータを処理する場合は、非常に高いスケーラビリティと低遅延の要件には最適ではない可能性があります。
</div></details>

### Q. 47
メディアストリーミングプラットフォームは、動画の視聴回数やクリック率などのユーザーインタラクションデータを保存して分析する必要があります。そのためには、高い読み取りと書き込みのスループットを低レイテンシーで処理できるデータベースが必要です。このシナリオに最も適した GCP サービスはどれですか?
1. 
2. 
3. Bigtable
4. 
<details><div>
    答え：3
説明
このシナリオの正しいオプションは C.  です。
Bigtable は、低レイテンシの読み取りおよび書き込み操作で大量のデータを処理できるように設計された、非常にスケーラブルで高性能な NoSQL データベースです。これは、ビデオの視聴回数やクリックスルー率などのユーザー操作データを保存および分析するためにメディア ストリーミング プラットフォームが必要とする、高い読み取りおよび書き込みスループットを低遅延で処理する必要があるシナリオに適しています。
正しくないオプション -
A. BigQuery: BigQuery は、大規模なデータセットに対して SQL のようなクエリを実行するために最適化されたデータ ウェアハウスおよび分析プラットフォームです。Bigtable と比較してクエリのレイテンシが長くなる可能性があるため、リアルタイム、高スループット、低レイテンシのデータ ストレージと取得には最適ではありません。
B. クラウドストレージ:クラウドストレージは、主にファイルやオブジェクトなどの非構造化データを保存するために設計されたオブジェクトストレージサービスです。ユーザー操作のデータ分析に必要な、リアルタイムで低遅延のデータアクセスとクエリ機能は提供されません。
D. Firestore: Firestore は、ドキュメント指向のデータ用に設計された NoSQL データベースであり、モバイル アプリケーションやウェブ アプリケーションによく使用されます。リアルタイム データを処理できますが、メディア ストリーミング プラットフォームの高スループット、低レイテンシの要件に対しては、Bigtable ほどパフォーマンスが高くない可能性があります。また、Firestore にはドキュメントとコレクションの制限があり、非常に高速なデータのスケーラビリティに影響を与える可能性があります。
</div></details>

### Q. 48
組織は、モバイル アプリから収集されたユーザーの行動データに基づいてレコメンデーション システムを構築したいと考えています。複雑なクエリを効率的に処理し、リアルタイム分析機能を提供できるデータベースが必要です。どのGCPサービスを検討すべきですか?
1. 
2. BigQuery
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は B.  です。
ここで説明するシナリオでは、モバイルアプリから収集したユーザー行動データに基づいてレコメンデーションシステムを構築する必要があります。
複雑なクエリ: レコメンデーション システムの構築には、多くの場合、ユーザーの行動を分析し、パーソナライズされたレコメンデーションを生成するための複雑なクエリが含まれます。BigQuery は、大規模なデータセットに対して複雑な SQL クエリを実行するために最適化された、フルマネージドのサーバーレス データ ウェアハウスです。分析ワークロードの処理に優れているため、このシナリオには有力な選択肢となります。
効率性: BigQuery はクエリを効率的に実行するように設計されているため、リアルタイム分析タスクに適しています。大量のデータを処理でき、クエリの応答時間が短くなります。
正しくないオプション -
A. Cloud Bigtable: Bigtable は、高スループットで低レイテンシのデータ アクセス用に最適化された NoSQL データベースです。時系列データやキー値ストレージなどの特定のユースケースには優れていますが、複雑な分析クエリやリアルタイム分析には適していません。
C. Cloud Datastore: Cloud Datastore は、ウェブ アプリケーションやモバイル アプリケーションの構造化データの保存と取得に適した NoSQL データベースです。ただし、複雑なレコメンデーションシステムやリアルタイム分析に必要なパフォーマンスとクエリ機能が提供されない場合があります。
D. Cloud SQL: Cloud SQL はマネージド リレーショナル データベース サービスです。トランザクション ワークロードや構造化データには適していますが、BigQuery の方が適している複雑な分析クエリやリアルタイム分析には適していない可能性があります。
複雑なクエリを効率的に処理し、リアルタイム分析機能を提供する必要があるレコメンデーション システムの場合、分析ワークロードと大規模なデータセットの処理に強みを持つ BigQuery は、GCP サービスとして最適です。
</div></details>

### Q. 49
ある製造会社は、生産設備からのセンサーデータをリアルタイムで監視および分析しようとしています。高速データストリームを取り込んで処理できるデータベースが必要です。どのGCPサービスが最適ですか?
1. Cloud Pub/Sub
2. 
3. 
4. 
<details><div>
    答え：1
説明
このシナリオの正しいオプションは次のとおりです。 A. 
生産設備からのセンサーデータをリアルタイムでモニタリングして分析したいと考えている製造会社にとって、Cloud Pub/Sub は次のような理由から最適な選択肢です。
高速データ ストリームの取り込みと処理: Cloud Pub/Sub は、リアルタイムの高速データ ストリームの取り込みと処理を目的として設計されています。センサーやデバイスからの大量のデータを効率的に処理できます。
リアルタイム データ: Cloud Pub/Sub では、生産設備からのデータをモニタリングして対応するために不可欠なリアルタイムのデータ ストリーミングが可能です。
スケーラビリティ: 多くの構成を行うことなく、データ負荷の増加を処理するように拡張できるため、データ量が時間の経過とともに変化する可能性がある状況に適しています。
正しくないオプション -
B. BigQuery:
BigQuery は、リアルタイムのデータ取り込みや処理よりも、分析クエリやデータのバッチ処理に適しています。
高速データストリームの処理には最適化されておらず、リアルタイム監視に使用すると、複雑さと遅延が増します。
C. クラウドデータストア:
Cloud Datastore は、構造化データの保存と取得に適した NoSQL データベースですが、高速でのリアルタイムのデータ取り込みと処理に特化して設計されているわけではありません。
D. Cloud SQL:
Cloud SQL はマネージド リレーショナル データベース サービスであり、リアルタイムのデータ ストリーミングや高速データ処理には適していません。これは通常、構造化されたトランザクションデータに使用されます。
Cloud Pub/Sub は、リアルタイムのデータ ストリームを処理するために構築されており、製造環境のセンサーからデータを効率的に取り込んで処理できるため、このシナリオに最適です。
</div></details>

### Q. 50
あなたは、車両のリアルタイムの位置データを保存および取得する必要がある物流会社のデータストレージソリューションを設計しています。このユースケースに最適なGCPサービスはどれですか?
1. 
2. Bigtable
3. 
4. 
<details><div>
    答え：2
説明
このシナリオの正しいオプションは B.  です。
Bigtable は、高スループットで低レイテンシのデータ アクセスを実現するように設計された、フルマネージドの NoSQL データベース サービスです。大量のデータを処理でき、車両のリアルタイム位置データの保存に適しているため、このユースケースに最適です。車両の位置を効率的に追跡するために必要なスケーラビリティ、パフォーマンス、およびリアルタイムのデータアクセスを提供します。
正しくないオプション -
A. Cloud SQL: Cloud SQL はフルマネージドのリレーショナル データベース サービスであり、複数の車両のリアルタイムの位置データの保存と取得には適していません。構造化データに適しており、車両のリアルタイム追跡に必要なスケーラビリティとパフォーマンスは提供されません。
C. Firestore: Firestore は、柔軟でスケーラブルなリアルタイムのデータ ストレージ用に設計された NoSQL ドキュメント データベースです。リアルタイム データを処理できますが、車両の大量の位置データを保存するのには適していない場合があります。Firestore は、モバイルアプリやウェブアプリなど、ドキュメント形式のデータ ストレージを必要とするアプリケーションでより一般的に使用されます。
D. Cloud Pub/Sub: Cloud Pub/Sub は、独立したアプリケーション間でメッセージを送受信できるメッセージング サービスです。これはデータベースではなく、データを保存しません。これは、コンポーネント間のリアルタイムのイベントストリーミングとメッセージングに使用できますが、データストレージを目的としたものではありません。
スタート
演習テスト1: Google Cloud Professional Data Engineer - Practice Test #1
スタート
演習テスト2: Google Cloud Professional Data Engineer - Practice Test #2
スタート
演習テスト3: Google Cloud Professional Data Engineer - Practice Test #3
スタート
演習テスト4: Google Cloud Professional Data Engineer - Practice Test #4
法人向けサービスのお問い合わせ
Udemyで教える
出資
規約
ヘルプとサポート
サイトマップ
アクセシビリティに関する声明
特定商取引に関する表記
</div></details>

## 2
### Q. 質問4: 未回答
Cloud Datastore を利用して、車両のテレメトリ データをリアルタイムで取り込むことを選択しました。目的は、費用対効果を維持しながら、長期的なデータの増加に対応するストレージソリューションを確立することです。また、このデータのスナップショットを定期的に生成して、代替環境での Cloud Datastore のポイントインタイム リカバリ(PIT)やデータのクローン作成を容易にします。2つの異なる方法を使用して、これらの目標を達成するにはどうすればよいでしょうか。(2つ選択)
1. マネージド エクスポートを使用し、Nearline クラスまたは Coldline クラスを使用して Cloud Storage バケットにデータを保存します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
車両のテレメトリ データをリアルタイムで Cloud Datastore に取り込み、コストを抑えながら長期保存用のデータのスナップショットを作成するという目標を達成するには、次の 2 つの方法を検討できます。
A. 
説明: Cloud Datastore の管理対象エクスポート機能を使用して、データを定期的にエクスポートできます。エクスポート後、データを Cloud Storage バケットに保存します。Nearline または Coldline ストレージクラスを選択することで、コストを低く抑えながら、スナップショットを長期保存用にアーカイブできます。
B. 管理対象エクスポートを使用してから、そのエクスポート用に予約された一意の名前空間の下にある別のプロジェクトの Cloud Datastore にインポートします。
説明: データのスナップショットを作成する別の方法として、Cloud Datastore の管理対象エクスポートを使用する方法があります。エクスポート後、そのエクスポート用に特別に予約された一意の名前空間を使用して、別の Cloud Datastore プロジェクトにデータをインポートできます。これにより、別の環境にデータのコピーを別個に作成できます。
正しくないオプション -
その他のオプション(C、D、E)は、Cloud Datastore データのスナップショットを作成し、コストを最小限に抑えながら長期保存用にアーカイブするという目標に直接対応していません。オプション C と D では、BigQuery にデータをインポートするか、データを管理するアプリケーションを作成するかについて説明しますが、これはスナップショットを作成する最も効率的な方法ではありません。オプションEでは、クラウドソースリポジトリにデータを保存することについて言及していますが、これはデータスナップショットには適していません。
</div></details>

### Q. 質問5: 未回答
あなたは、データサイエンスチームによる分析のために、時系列のトランザクションデータを BigQuery にコピーするデータパイプラインを設定する任務を負っています。このデータは 1 時間ごとに新しいステータスで更新され、初期データセット サイズは 1.5 PB で、毎日 3 TB ずつ増加します。データの構造が複雑で、データ サイエンス チームはそれを使用して機械学習モデルを構築することを計画しています。目的は、データ サイエンス チームのパフォーマンスと使いやすさを最適化することです。
この目標を達成するために、どの2つの戦略を採用すべきでしょうか?(2つ選択してください。
1. 可能な限りデータを非正規化します。
2. 
3. 
4. ステータスの更新が BigQuery に更新されるのではなく、追加されるデータ パイプラインを開発します。
5. 
<details><div>
    答え：1,4
説明
A. 
データを非正規化すると、特に大規模なデータセットを処理する場合に、クエリのパフォーマンスを向上させることができます。非正規化することで、複雑な結合の必要性が減り、クエリをより簡単にすることができます。場合によっては、これにより、データ サイエンティストの使いやすさとクエリのパフォーマンスが向上する可能性があります。
D. 
時系列データに追加のみのアプローチを使用することは、ストリーミング データや頻繁に更新されるデータを処理する場合の一般的な方法です。既存のレコードを更新する代わりに、期間ごとに新しいレコードを追加します(例:毎時)。このアプローチにより、履歴データが保持され、時系列データの自然な流れに合わせることができます。
正しくないオプション -
オプション B (データの構造を可能な限り保持する) は、一般に、データの整合性を維持し、データが理解しやすい状態を維持するための優れたプラクティスです。ただし、場合によっては、クエリのパフォーマンスのために非正規化が必要になることがあります。
オプション C(BigQuery UPDATE を使用してデータセットのサイズをさらに小さくする)は、既存のレコードが頻繁に更新されることを意味するため、時系列データには適していない可能性があります。追加のみのアプローチでは、既存のレコードを更新するのではなく、時間間隔ごとに新しいレコードを追加します。
オプション E(トランザクション データの日次スナップショットを Cloud Storage にコピーし、Avro ファイルとして保存します。BigQuery の外部データソースのサポートを使用してクエリを実行する)は、スナップショットのアーカイブと維持には有効な戦略ですが、トランザクション データのリアルタイム分析には最も効率的なアプローチではない可能性があります。これは、履歴分析やバックアップの目的に適しています。
</div></details>

### Q. 質問6: 未回答
あなたは、次の基準を満たしながら履歴データを処理するためのクラウドネイティブなソリューションを考案する任務を負っています。
- 分析対象のデータが CSV、Avro、PDF 形式で存在し、Dataproc、BigQuery、Compute Engine などの複数の分析ツールがアクセスする必要がある。
- バッチ パイプラインは、毎日のデータの移動を担当します。
- このソリューションでは、パフォーマンスは主な関心事ではありません。
- ソリューションの設計では、可用性を優先する必要があります。
このソリューションのデータストレージをどのように構成しますか?
1. 
2. 
3. 
4. 複数リージョンの Cloud Storage バケットにデータを保存します。Dataproc、BigQuery、Compute Engine を使用してデータに直接アクセスします。
<details><div>
    答え：4
説明
可用性を最大化し、Dataproc、BigQuery、Compute Engine などの複数の分析ツールからアクセスできるようにする必要があるクラウドネイティブの履歴データ処理システムの場合、推奨されるアプローチは次のとおりです。
D. 
このオプションが適している理由は次のとおりです。
マルチリージョンクラウドストレージバケット:マルチリージョンの Cloud Storage バケットにデータを保存することで、高可用性と耐久性が確保されます。データは複数のリージョンにレプリケートされるため、リージョンの停止によるデータ損失のリスクが軽減されます。
直接アクセス:Cloud Storage を使用すると、Dataproc、BigQuery、Compute Engine など、さまざまな Google Cloud サービスのデータに直接アクセスできます。これにより、複雑さとレイテンシーが最小限に抑えられ、分析用のデータへの効率的なアクセスが可能になります。
正しくないオプション -
オプション A(Dataproc 上の HDFS):HDFS は Dataproc で使用できますが、より複雑なソリューションであり、マルチリージョンの Cloud Storage ほど効果的に可用性を最大化できない可能性があります。
オプション B(BigQuery):BigQuery は強力な分析ツールですが、通常は構造化データに使用され、PDF ファイルの取り込みは困難な場合があります。さまざまな形式の未加工のストレージに BigQuery を使用することは、最も効率的なアプローチではない可能性があります。
高可用性が必要な場合は、オプション C (リージョン クラウド ストレージ バケット) が実行可能な選択肢になる可能性がありますが、可用性を最大化するには、特にマルチリージョン アクセスの場合は、オプション D が推奨されます。
</div></details>

### Q. 質問7: 未回答
ペタバイト規模の分析データを管理する任務を負っており、ストレージと処理のプラットフォームが必要です。目標は、Google Cloud でデータ ウェアハウス スタイルの分析を有効にし、データセットを他のクラウド プラットフォーム上のバッチ分析ツールのファイルとして利用できるようにすることです。
これを達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. リージョンの Cloud Storage バケットにデータを保存します。Dataproc、BigQuery、Compute Engine を使用してバケットに直接アクセスします。
4. 
<details><div>
    答え：3
説明
C. 
このオプションは、耐久性とアクセス性を確保するために、リージョンの Cloud Storage バケットにデータを保存する場合に適しています。このデータには、Dataproc、BigQuery、Compute Engine など、さまざまな Google Cloud サービスを使用して直接アクセスできます。このアプローチでは、データの使用方法と処理方法に関して柔軟性があります。
誤ったオプション-
オプション A(データセット全体を BigQuery に保存して処理する):BigQuery はデータ ウェアハウスと分析には優れていますが、特にデータのかなりの部分が頻繁にアクセスされない場合は、ペタバイト規模のデータに対して最も費用対効果の高いソリューションではない可能性があります。すべてのデータを BigQuery に保存すると、コストが高くなる可能性があります。
オプション B(データセット全体を Bigtable に保存して処理する):Bigtable は、高スループットの NoSQL スタイルのワークロード向けに設計されており、従来のデータ ウェアハウス スタイルの分析には適していません。SQLクエリ機能がありません。
オプション D(ウォームデータをファイルとして Cloud Storage に保存し、アクティブデータを BigQuery に保存する):このアプローチは、アクティブなデータとアクティブでないデータを明確に分離している場合には意味があるかもしれませんが、他のクラウド プロバイダーでバッチ分析のためにデータをファイルとして公開する必要性に直接対処するものではありません。アクティブ データを BigQuery に保存することは適切な選択ですが、耐久性のためにウォーム データは引き続き Cloud Storage に保存される可能性があります。
</div></details>

### Q. 質問8: 未回答
あなたは、それぞれ独自のサプライヤーから約 750 の異なるコンポーネントを調達する製造会社の一員です。データセットには、平均して、コンポーネントごとに 1000 個のラベル付き例が含まれています。目的は、倉庫スタッフがコンポーネントの写真から入荷コンポーネントを識別するのに役立つアプリを作成することです。最初の動作バージョンを概念実証として迅速に開発することを目指しています。
どのように進めればよいですか?
1. 既存のデータセットで Cloud Vision AutoML を使用します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
Cloud Vision AutoML はカスタム画像認識タスク専用に設計された機械学習サービスであるため、これは正しいオプションです。これにより、シナリオに不可欠な既存のデータセットを使用してカスタム画像認識モデルをトレーニングできます。オプションAが最良の選択である理由は次のとおりです。
カスタマイズ：Cloud Vision AutoMLを使用すると、特定のユースケースに合わせたカスタムモデルを構築できます。シナリオでは、倉庫作業員が撮影した写真からさまざまなコンポーネントを認識するには、正確な結果を得るためにカスタマイズされたソリューションが必要です。
精度：カスタム モデルは、ドメイン固有のデータでトレーニングされるため、多くの場合、汎用モデルよりもパフォーマンスが高くなります。既存のデータセットを使用してモデルをトレーニングすることで、コンポーネントの認識精度を高めることができます。
使いやすさ:カスタム機械学習モデルのトレーニングは複雑になりがちですが、Cloud Vision AutoML を使用するとプロセスが簡素化され、機械学習の深い専門知識がなくてもアクセスできるようになります。これは、迅速な概念実証という目標とよく一致します。
正しくないオプション -
オプション B: Cloud Vision AutoML を使用しますが、データセットを 2 回削減します。
データセットを減らすと、貴重なトレーニングデータが失われ、モデルの精度に悪影響を与える可能性があります。PoC では、最良の結果を得るために、できるだけ多くの関連データを使用する必要があります。
オプション C: 認識のヒントとしてカスタム ラベルを指定して、Cloud Vision API を使用します。
Cloud Vision API はさまざまな画像分析タスクに役立ちますが、カスタム画像認識を必要とする特定のシナリオには適していない可能性があります。カスタムラベルをヒントとして指定すると認識が向上しますが、ラベル付けされた画像のデータセットが大量にある場合は、Cloud Vision AutoMLでカスタムモデルをトレーニングするほど効果的ではありません。
オプション D: 転移学習手法を活用して独自の画像認識モデルをトレーニングします。
転移学習手法を使用して独自の画像認識モデルをトレーニングすることは有効なアプローチであり、特定のシナリオでは非常に効果的ですが、画像内のコンポーネントを認識するための迅速な概念実証 (PoC) の作成を含む特定の状況には最適な選択肢ではない可能性があります。
</div></details>

### Q. 質問9: 未回答
あなたは画像認識に関連する特殊なプロジェクトに携わっており、チームは、開発したカスタム C++ TensorFlow 操作に主に依存するモデルを作成しました。これらの操作は、主要なトレーニング プロセスに不可欠であり、リソースを大量に消費する行列の乗算を伴います。現在、モデルのトレーニング プロセスが完了するまでに数日かかる場合があります。目標は、Google Cloud アクセラレータを活用して費用対効果を維持しながら、このトレーニング時間を大幅に短縮することです。
この目標を達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. CPU を使用したまま、モデルをトレーニングするクラスターのサイズを増やします。
<details><div>
    答え：4
説明
D. 
カスタム C++ TensorFlow Ops:モデルは、カスタム C++ TensorFlow 演算に大きく依存しています。TPU や GPU とシームレスに連携するようにこれらの運用を移行することは、複雑で時間のかかるプロセスであり、多くの場合、これらのアクセラレータの最適化には大幅なコード変更と専門知識が必要です。
TPUの:Cloud TPU は、特定のディープ ラーニング ワークロード向けの優れたアクセラレータですが、アーキテクチャと互換性のある TensorFlow オペレーション向けに最適化されています。カスタム演算を TPU で実行するように適応させるのは困難な場合があり、モデルが特殊なハードウェアを最大限に活用できない限り、大きなメリットが得られない可能性があります。
GPUサポート:カスタム演算に GPU カーネル サポートを実装することは、GPU の使用を計画している場合、正しい方向への一歩です。ただし、GPU と TPU はアーキテクチャが異なるため、個別の最適化が必要です。このオプションは、特にGPUアクセラレーションをターゲットとしている場合に適しています。
クラスタのスケーリング:CPU にとどまり、クラスターのサイズを増やすことで、複数の CPU ノードにワークロードを分散できます。これにより、計算負荷の高いタスクであっても、トレーニング時間を大幅に短縮できます。多くの場合、トレーニングをスピードアップするための最も簡単で費用対効果の高い方法です。
コストに関する考慮事項:TPU と GPU は、CPU ベースのクラスターと比較して、使用コストが高くなる可能性があります。CPU にとどまり、クラスターをスケーリングすることで、パフォーマンスとコスト効率のバランスを取ることができます。
カスタム C++ TensorFlow 演算を使用するシナリオと、コストを低く抑えながらトレーニング時間を最小限に抑える必要があることを考えると、CPU にとどまり、クラスターをスケーリングする (オプション D) ことが、最も実用的でコスト効率の高いアプローチです。TPU や GPU などのアクセラレータへの移行は長期的な目標かもしれませんが、これらのハードウェア プラットフォーム向けのカスタム運用の最適化に伴う複雑さとコストを慎重に検討して取り組む必要があります。
</div></details>

### Q. 発行： 未回答
自然言語処理領域内の回帰問題に取り組んでおり、1 億個のラベル付き例を含むデータセットを備えています。データをランダムにシャッフルし、90/10 の比率でトレーニング セットとテスト セットに分割しました。ニューラル ネットワークに学習させ、テスト セットでそのパフォーマンスを評価すると、トレーニング セットの二乗平均平方根誤差 (RMSE) がテスト セットの誤差の 2 倍であることがわかります。
モデルのパフォーマンスを向上させるには、どのような手順を実行する必要がありますか?
1. 
2. 
3. 正則化手法 (ドロップアウトやバッチ正規化など) を試して、過学習を回避します。
4. 
<details><div>
    答え：3
説明
モデルの二乗平均平方根誤差 (RMSE) が、トレーニング セットではテスト セットの 2 倍であるという観察結果は、過学習を示しています。過学習は、モデルが学習データに近づきすぎて、一般的なパターンではなく学習データにノイズや特異性をキャプチャすることを学習した場合に発生します。モデルのパフォーマンスを向上させるには、過学習を減らすことに重点を置く必要があります。正しいアプローチは次のとおりです。
C. 
正則化手法:ドロップアウト、バッチ正規化、L2 正則化などの手法は、過学習を軽減するように設計されています。トレーニング中にモデルのパラメーターに制約を導入し、トレーニング データに近づきすぎないようにし、目に見えないデータへの一般化を促進します。
テストセットサイズの拡大(オプションA):トレーニングとテストの分割でテスト サンプルのシェアを増やしても、過学習には直接対処できません。重要なのは、既存のテストセットの相対的なパフォーマンスであり、そのサイズではありません。
より多くのデータを収集する(オプションB):より多くのデータを収集すると、特定のケースでは役立ちますが、必ずしも過学習が解決されるとは限りません。一般に、データセットのサイズを増やすことを検討する前に、まずモデルを最適化し、正則化手法を適用することをお勧めします。
モデルの複雑性を増す(オプションD):モデルの複雑さが増すと、過学習が解決されるどころか悪化する可能性があります。複雑なモデルほどパフォーマンスが向上するというのは、よくある誤解です。適切な正則化を備えた単純なモデルは、多くの場合、過度に複雑なモデルよりも優れた性能を発揮します。
正しくないオプション -
A. トレーニングとテストの分割でテスト サンプルのシェアを増やします。
トレーニングとテストの分割でテスト サンプルの割合を増やしても、過学習の問題に直接対処できるわけではありません。トレーニングとテストの間でデータの割り当てが変更されるだけで、モデルの動作には影響しません。
問題は、テストセットのサイズではなく、モデルがトレーニングセットから未知のデータにうまく一般化できないことです。このオプションでは、過学習の根本原因には対処できません。
B. より多くのデータを収集し、データセットのサイズを大きくしてみてください。
より多くのデータを収集することは、特に意味のあるパターンを学習するための十分なデータがモデルにない場合に、場合によっては有用な戦略となる可能性があります。ただし、このシナリオでは、既にかなりのデータセット (100M の例) があります。
データセットのサイズを大きくしても、過学習の問題に直接対処できない場合があります。過学習は、多くの場合、モデルが複雑すぎるか、使用可能なデータの量に対してパラメーターが多すぎることが原因です。一般に、大規模なデータセットがある場合は、モデルの正則化に重点を置く方が効果的です。
D. 追加のレイヤーを導入したり、使用する語彙や n-gram のサイズを増やしたりするなどして、モデルの複雑さを増します。
モデルの複雑さが増すと、過学習は解決されるどころか悪化する可能性があります。より複雑なモデルでは、トレーニング データにノイズや特異性が当てはめられやすく、一般化が不十分になる可能性があります。
過学習は、通常、モデルが既に複雑すぎて使用可能なデータがない場合に発生します。複雑さを増すことは、推奨されるアプローチではありません。代わりに、モデルを単純化し、正則化手法を適用して過学習を防ぐことをお勧めします。
</div></details>

### Q. 質問11: 未回答
一元化された分析設定では、BigQuery がコア プラットフォームとして機能します。毎日データがアップロードされ、ユーザーに提示する前にデータ変換を担当するETLパイプラインを運用します。ETL パイプラインは頻繁に変更され、時折エラーが発生し、その一部は 2 週間の遅延後にのみ表面化する場合があります。これらのエラーの回復メカニズムを確立すると同時に、バックアップ ストレージのコストを最適化する必要があります。
BigQuery でデータを構造化し、バックアップ戦略を管理するには、どのようなアプローチが推奨されますか?
1. 
2. 月ごとにデータを個別のテーブルに整理し、データをエクスポート、圧縮して Cloud Storage に保存します。
3. 
4. 
<details><div>
    答え：2
説明
オプション B: 
このオプションでは、データを月ごとに個別のテーブルに整理することを提案し、データ管理の適切な方法を提供します。さらに、データをエクスポート、圧縮し、Cloud Storage に保存することをお勧めします。
これが正解である理由は次のとおりです。
月ごとに個別のテーブル:月ごとにデータを個別のテーブルに整理すると、データが分離されます。ETL プロセス中にエラーが発生した場合、またはデータが破損した場合、他の月に影響を与えることなく、影響を受けた月のデータを簡単に特定して回復できます。
エクスポートと圧縮:データをエクスポートして Cloud Storage に保存することは、バックアップの一形態として機能します。データを圧縮することで、ストレージコストを最適化できます。データの破損やエラーが発生した場合は、バックアップしたデータを Cloud Storage から取得し、BigQuery に読み込むことができます。
正しくないオプション -
オプション A: データを 1 つのテーブルに整理し、BigQuery データをエクスポートして圧縮し、Cloud Storage に保存します。
このオプションでは、すべてのデータを 1 つのテーブルに格納することを提案します。Cloud Storage にデータをエクスポートして保存することについては言及していますが、データを時間単位で整理することの利点については考慮されていません。すべてのデータを 1 つのテーブルに格納すると、エラーが発生した場合に特定の期間を分離して回復することが困難になる可能性があります。
オプション C: 月ごとにデータを別々のテーブルに整理し、BigQuery の別のデータセットにデータを複製します。
BigQuery 内の別のデータセットにデータを複製すると、ストレージ費用が大幅に増加する可能性があります。データ復旧のための効率的なバックアップ戦略は提供されません。さらに、正確なポイントインタイムリカバリを可能にするスナップショットデコレーターは利用されません。
オプション D: 月ごとにデータを個別のテーブルに整理し、スナップショット デコレーターを使用してテーブルを破損前の時点に復元します。
BigQuery のスナップショット デコレーターは、特定の時点までデータを復元するのに便利な機能ですが、いくつかの制限があり、このシナリオでは最適な選択ではない可能性があります。
</div></details>

### Q. 質問12: 未回答
組織のマーケティング チームは、顧客データセットのセグメントの更新を定期的に提供します。BigQuery で更新する必要がある 100 万件のレコードを含む CSV ファイルが作成されました。ただし、BigQuery で UPDATE ステートメントを使用しようとすると、quotaExceeded エラーが発生します。
この問題に対処するには、どのような手順を実行する必要がありますか?
1. 
2. 
3. 
4. CSV ファイルから新しい BigQuery テーブルに新しいレコードをインポートします。新しいレコードを既存のレコードとマージし、結果を新しい BigQuery テーブルに書き込む BigQuery ジョブを作成します。
<details><div>
    答え：4
説明
BigQuery で UPDATE ステートメントを使用しているときに quotaExceeded エラーが発生した場合は、通常、1 回のクエリ ジョブで実行できる更新数の上限に達していることを示しています。この問題に対処するための正しいアプローチは次のとおりです。
D. 
このアプローチが最も適している理由は次のとおりです。
拡張性:新しいレコードを別の BigQuery テーブルにインポートすることで、1 つの DML ステートメントで更新の割り当て制限に達することを回避できます。BigQuery は大規模なデータセットのクエリと処理に最適化されており、このアプローチにより、新しいレコードと既存のレコードを効率的にマージできます。
コントロール：この方法では、更新プロセスをより詳細に制御できます。マージ操作は SQL ステートメントを使用して実行できるため、特定の要件に基づいて管理およびカスタマイズしやすくなります。
データの整合性:新しいレコードを別のテーブルにインポートすると、既存のデータを誤って上書きしたり変更したりすることがなくなります。マージ操作の結果をメイン データセットにコミットする前に確認できるため、より安全なアプローチです。
パフォーマンス：BigQuery は大規模なデータセットのクエリ用に設計されており、マージクエリを使用して更新操作を実行することは、大量のデータを効率的に処理するのに適しています。
正しくないオプション -
対照的に、他のオプション(A、B、C)は quotaExceeded エラーに直接対処しないため、BigQuery で大規模なデータセットを更新するための効果的なソリューションではない可能性があります。オプション D は、更新を効率的に処理し、クォータの制限を回避するための構造化されたスケーラブルなアプローチを提供します。
</div></details>

### Q. 質問13: 未回答
組織での GCP の使用が拡大するにつれて、さまざまなチームが独自のプロジェクトを生成し、さまざまなデプロイ フェーズやオーディエンス ターゲティングにさらに拡張しています。各プロジェクトには、個別のアクセス制御設定が必要です。中央の IT 部門では、すべてのプロジェクトにわたるユニバーサル アクセスが必要です。また、Cloud Storage バケットと BigQuery データセットは、プロジェクト間で柔軟に共有する必要があります。ポリシーの数を減らすことでアクセス制御を合理化することを目指しています。
どの 2 つのアクションを追求すべきですか?(2つ選択してください。
1. 
2. アクセス コントロール ポリシーの継承を活用するためのリソース階層を導入します。
3. チームごとに個別のグループを作成し、Cloud IAM ポリシーでグループを指定します。
4. 
5. 
<details><div>
    答え：2,3
説明
アクセス制御管理を簡素化し、ポリシーの数を最小限に抑えながら、組織での GCP の使用の拡大に対応するには、次の手順を検討する必要があります。
B. 
リソース階層を使用すると、それらのプロジェクト内のプロジェクト、フォルダー、およびリソースによって継承される組織レベルのポリシーを定義できます。このアプローチにより、組織レベルで高レベルのアクセス制御ポリシーを設定しながら、プロジェクトレベルでより具体的なポリシーを管理することができます。
C. 
チームごとに個別のグループを作成し、Cloud IAM ポリシーでこれらのグループを指定することで、アクセス管理を効率化できます。ユーザーを個別に指定する代わりに、グループに権限を割り当てることができるため、複数のプロジェクトにまたがるチームのアクセス制御を簡単に管理できます。
正しくないオプション -
A. Cloud Deployment Manager を使用して、アクセスのプロビジョニングを自動化します。
Cloud Deployment Manager は、主に、Infrastructure as Code を含むクラウド リソースのプロビジョニングと管理に使用されます。リソースのプロビジョニングを自動化することはできますが、アクセス制御管理の簡素化やポリシーの最小化には直接対応していません。
D. サービス アカウントは、Cloud Storage バケットと BigQuery データセットのデータを共有する場合にのみ使用します。
サービス アカウントは、自動化されたプロセスやアプリケーションへのアクセスを許可するのに便利ですが、人間のユーザーやチームとアドホックな方法でデータを共有するのには適していない場合があります。サービス アカウントは、通常、特定のプログラムによるアクセスに使用されます。
E.Cloud Storage バケットまたは BigQuery データセットごとに、アクセスが必要なプロジェクトを決定します。これらのプロジェクトへのアクセス権を持つすべてのアクティブ メンバーを検索し、Cloud IAM ポリシーを作成して、これらのすべてのユーザーにアクセス権を付与します。
このアプローチでは、各リソースのユーザーを手動で識別してアクセス権を付与します。時間がかかり、プロジェクトやリソースの数が増えるにつれてエラーが発生しやすくなります。リソース階層とグループを使用すると、アクセス制御に対してよりスケーラブルで組織化されたアプローチを提供できます。
</div></details>

### Q. 質問14: 未回答
米国を拠点とする会社は、ユーザー操作を評価して対応するために設計されたアプリケーションを開発しました。メインデータベーステーブルのデータ量は、毎秒250,000レコードの割合で増加しています。さまざまなサードパーティエンティティが、アプリケーションのAPIを利用して、その機能をフロントエンドアプリケーションに統合します。アプリケーションの API が次の基準に準拠していることを確認する必要があります。
- 単一のグローバルエンドポイントを維持します。
- ANSI SQL のサポートを提供します。
- 最新のデータへの一貫したアクセスを保証します。
これらの要件を満たすには、どのような手順を踏む必要がありますか?
1. 
2. 北米のリーダーである Cloud Spanner と、アジアとヨーロッパで読み取り専用レプリカを実装する
3. 
4. 
<details><div>
    答え：2
説明
アプリケーションが単一のグローバル エンドポイント、ANSI SQL サポート、および最新のデータへの一貫したアクセスを必要とするこのシナリオでは、最適なオプションは次のとおりです。
オプション B: 
その理由は次のとおりです。
グローバルエンドポイント:Cloud Spanner には、アプリケーション用に 1 つのグローバル エンドポイントを作成できるグローバル分散機能が用意されています。これは、世界中のどこからでも要求を処理できる、グローバルで強力な一貫性のあるデータベースを提供するため、サードパーティが API を使用しているシナリオに最適です。
ANSI SQL サポート:Cloud Spanner は ANSI SQL をサポートしているため、標準の SQL クエリと互換性があります。これにより、前述の要件であるSQLを使用してデータを簡単に操作できます。
一貫性：Cloud Spanner は強力なグローバル整合性を備えているため、読み取り専用レプリカを含むすべてのレプリカがリーダーとの整合性が保たれます。これにより、アプリケーションとサードパーティのアプリケーションがどこにあっても、最新のデータにアクセスできるようになります。
グローバル・レプリケーション:アジアとヨーロッパに読み取り専用レプリカを持つことで、北米の主要なリーダーとの一貫性を維持しながら、これらの地域のユーザーとアプリケーションのデータへの低レイテンシーのアクセスを確保できます。
正しくないオプション -
オプション A(BigQuery):BigQuery は大規模なデータセットの分析とクエリ用に設計されていますが、トランザクション システムに必要なリアルタイムの一貫性とグローバル エンドポイント機能を提供しない場合があります。
オプション C(Cloud SQL for PostgreSQL):Cloud SQL はマネージド リレーショナル データベース サービスですが、Cloud Spanner と同じグローバルな分散とスケーラビリティを提供しない場合があり、PostgreSQL は同じレベルのグローバルな一貫性を提供しない可能性があります。
オプション D(Bigtable):Bigtable は、高スループットで大規模なデータ用に最適化された NoSQL データベースです。ANSI SQL をサポートしていない可能性があり、整合性モデルは Cloud Spanner ほど強力ではありません。
</div></details>

### Q. 質問15: 未回答
データ サイエンティストが BigQuery ML モデルを開発し、予測を配信するための ML パイプラインの構築についてサポートを求めています。REST API アプリケーションは、100 ミリ秒未満の待ち時間内に個々のユーザー ID の予測を提供するという基準を満たす必要があります。使用される予測クエリは、SELECT predicted_label、user_id FROM ML.PREDICT (MODEL 'dataset.model', table user_features) です。
この ML パイプラインの作成にはどうすればよいでしょうか。
1. 
2. 
3. 
4. BigQueryIO を使用して Dataflow パイプラインを作成し、クエリからすべてのユーザーの予測を読み取り、BigtableIO を使用して結果を Bigtable に書き込み、アプリケーションが Bigtable から個々のユーザーの予測を読み取れるように、アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与することです。
<details><div>
    答え：4
説明
REST API アプリケーションで BigQuery ML を使用して低レイテンシで予測を提供する場合、最適なオプションは、オプション D: 
その理由は次のとおりです。
レイテンシーに関する考慮事項:個々のユーザー ID のレイテンシーが 100 ミリ秒未満の予測を提供することは、困難な要件です。BigQuery への直接クエリは、この低レイテンシの要件を常に満たしているとは限りません。
データフロー パイプライン:Dataflow パイプラインを作成することで、データを効率的に処理、変換できます。Dataflow は BigQuery から予測を読み取り、低レイテンシのアクセスに最適化された別のストレージ システム(Bigtable など)に書き込むことができます。
Bigtable ストレージ:Bigtable は、低レイテンシ、高スループットのストレージを提供する NoSQL データベースです。Bigtable に予測を保存すると、個々のユーザー ID の予測をすばやく取得できます。
ロールベースのアクセス制御:アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与すると、Bigtable から予測を読み取るために必要な権限がアプリケーションに付与されます。
正しくないオプション -
オプション A (クエリへの WHERE 句の追加とデータ閲覧者ロールの付与):このオプションでは低レイテンシの要件には対応しておらず、BigQuery を直接クエリしてもレイテンシの目標を達成できない可能性があります。
オプション B (承認済みビューの作成):承認済みビューの作成は、特定のデータへのアクセスを制御するのに役立ちますが、必ずしも低レイテンシーの要件に対応できるわけではなく、低レイテンシーで予測を提供する必要があります。
オプション C(クエリから結果を読み取るための Dataflow パイプラインの作成):このオプションはデータの処理に使用できますが、低レイテンシーの要件には対応しておらず、低レイテンシーで予測を提供するソリューションが必要になります。
</div></details>

### Q. 質問19: 未回答
時系列指標の集計と Bigtable への書き込みを担当する Dataflow ジョブを特徴とするデータ パイプラインを管理しています。Bigtable 内でデータ更新の遅延が発生していますが、このデータは、組織内の何千人ものユーザーがアクセスするダッシュボードにとって非常に重要です。パフォーマンスを向上させ、より多くの同時ユーザーに対応し、データの書き込み時間を短縮するには、2 つの推奨アクションは何ですか?(2つ選択してください。
1. 
2. PipelineOptions で maxNumWorkers を設定して、Dataflow ワーカーの最大数を増やします。
3. Bigtable クラスタのノード数を増やします。
4. 
5. 
<details><div>
    答え：2,3
説明
Dataflow パイプラインのパフォーマンスを向上させ、Bigtable へのデータ書き込みに必要な時間を短縮しながら、追加の同時ユーザーをサポートするには、次のアクションを検討する必要があります。
B. 
Dataflow ワーカーの数を増やすと、パイプラインでデータの処理と書き込みを並行して行うことができるため、Bigtable への書き込みパフォーマンスが大幅に向上します。このアクションは、ワークロードをより効果的に分散し、データの更新を高速化するのに役立ちます。
C. 
Bigtable クラスタにノードを追加すると、容量とスループットが向上します。これにより、Bigtable は大量の書き込み操作を処理できるため、レイテンシが短縮され、データの更新がより迅速に行われるようになります。Bigtable を適切にスケーリングすることは、書き込みパフォーマンスを向上させるために重要です。
正しくないオプション -
オプション A は、ローカル実行を使用するように Dataflow パイプラインを構成するもので、通常、開発とデバッグの目的で使用されます。これは、実稼動パイプラインのパフォーマンスを向上させるための適切なアプローチではありません。
オプション D では、Bigtable への書き込み前にフラット化変換を使用すると、パイプライン内のデータ変換に役立つ可能性がありますが、Bigtable へのデータ書き込みのパフォーマンスには直接対処しません。
CoGroupByKey 変換を使用するオプション E は、通常、より複雑なシナリオでデータをグループ化して結合するために使用されます。これは、Bigtable への書き込みパフォーマンスの向上とは直接関係がない可能性があります。
</div></details>

### Q. 発行： 未回答
スケジュールに従って動作する Cloud Dataproc クラスタで、複数の Spark ジョブ(一部は順番に実行し、他は同時に実行)の実行を自動化するにはどうすればよいでしょうか。
1. 
2. 
3. Cloud Composer で有向非巡回グラフ(DAG)を作成する:
4. 
<details><div>
    答え：3
説明
オプション C: Cloud Composer で有向非巡回グラフ(DAG)を作成する:
正しいオプションの説明:Cloud Composer は、Google Cloud のマネージド Apache Airflow サービスで、複雑なワークフローを調整するために設計されています。Airflow では、有向非巡回グラフ (DAG) を作成して、ワークフローを定義およびスケジュールできます。このコンテキストでは、Spark ジョブのシーケンスと依存関係を表す DAG を作成できます。この DAG をスケジュールして、目的の順序でジョブを実行できます。
正しくないオプション -
オプション A: Cloud Dataproc ワークフロー テンプレートを作成します。
Dataproc ワークフロー テンプレートを作成して Dataproc ジョブのスケジュールを設定することはできますが、Spark ジョブ間の複雑な依存関係の管理やジョブの同時実行には適していない可能性があります。Dataproc ワークフロー テンプレートは、ジョブの順次実行をより簡単に行うことができます。
オプション B: ジョブを実行するための初期化アクションを作成します。
初期化アクションは、通常、起動時に Dataproc クラスタを構成するために使用されます。これらは、ジョブのオーケストレーションや依存関係を管理するようには設計されていません。このオプションでは、複雑なジョブ シーケンスをきれいに表現することはできません。
オプション D: Bash スクリプトを作成します。
Bash スクリプトを使用してクラスターを手動で作成し、ジョブを実行し、クラスターを破棄すると、エラーが発生しやすくなり、ジョブの依存関係とスケジュールを管理するための組み込み機能が不足しています。これは、Airflow(オプションC)のような専用のワークフローオーケストレーションツールと比較して、効率と拡張性に欠けるソリューションです。
</div></details>

### Q. 質問21: 未回答
現在、ジョブジェネレーターとジョブランナーという 2 つの異なるカテゴリのアプリケーション間でのデータ共有を容易にするデータパイプラインを構築しているところです。ソリューションには、使用量の増加に適応できるスケーラビリティがあり、既存のアプリケーションのパフォーマンスに悪影響を与えることなく、新しいアプリケーションをシームレスに統合できることが不可欠です。この目標を達成するために、どのように進めるべきでしょうか?
1. 
2. Cloud Pub/Sub トピックを使用してジョブを発行し、サブスクリプションを使用してジョブを実行します。
3. 
4. 
<details><div>
    答え：2
説明
既存のアプリケーションに悪影響を与えることなく、使用量の増加と新しいアプリケーションに対応できるスケーラブルなデータパイプラインを構築するための最も適切な選択肢は次のとおりです。
B. 
このオプションが適している理由は次のとおりです。
拡張性:Cloud Pub/Sub は、大量のメッセージや複数のサブスクライバーへの配信を処理できる、拡張性の高いメッセージング サービスです。使用量が増えると、Pub/Sub は追加の負荷をシームレスに処理できます。
コンポーネントのデカップリング:Cloud Pub/Sub では、ジョブジェネレータ(パブリッシャー)とジョブランナー(サブスクライバー)を切り離すことができます。新しいアプリケーションは、既存のトピックに影響を与えることなく、関連する Pub/Sub トピックをサブスクライブするだけで済みます。この分離により、新しいアプリケーションを追加しても、既存のアプリケーションのパフォーマンスに悪影響を与えることはありません。
柔軟性：Pub/Sub は柔軟性が高く、さまざまなメッセージ形式に対応できるため、さまざまなタイプのアプリケーションに適しています。
非同期：Pub/Sub は非同期で動作するため、システムのさまざまなコンポーネント間で効率的かつ応答性の高い通信が可能になります。
正しくないオプション -
オプション A(App Engine で API を作成する)は機能しますが、使用量の増加に応じて、エンドポイントの管理とスケーリングに関する考慮事項が必要になる場合があります。既存のアプリケーションに影響を与えずに新しいアプリケーションを追加するには、それほどシームレスではない可能性があります。
オプション C(Cloud SQL を使用)と D(Cloud Spanner を使用)にはリレーショナル データベースが含まれるため、大量のメッセージやアプリケーション間の非同期通信の処理には Pub/Sub ほど適していない可能性があります。
</div></details>

### Q. 質問22: 未回答
Cloud Spanner で、商品の販売データを保存する新しいトランザクション テーブルを作成する必要があります。主キーとして何を使用するかを決定します。パフォーマンスの観点から、どの戦略を選択する必要がありますか?
1. 
2. 
3. ランダムな汎用一意識別子番号 (バージョン 4 UUID):
4. 
<details><div>
    答え：3
説明
オプション C: 
UUID (Universally Unique Identifier) を主キーとして使用すると、一意性を強力に保証できます。UUID は分散システム間で一意になるように生成されるため、特に複数リージョンのデプロイで重要な競合を回避するのに役立ちます。
正しくないオプション -
オプション A: 現在のエポック時間:
現在のエポック時間を主キーとして使用すると、書き込み負荷の高いシナリオで問題が発生する可能性があります。複数のトランザクションが同時に発生すると、同じタイムスタンプが共有され、競合やパフォーマンスの問題が発生する可能性があります。
オプション B: 製品名と現在のエポック時間の連結:
オプション A と同様に、この選択では書き込み競合の問題が発生する可能性があります。同じ商品の複数の販売が同時に発生すると、同じキーを共有し、パフォーマンスのボトルネックにつながる可能性があります。
オプション D: 販売システムからの元の注文識別番号 (単調に増加する整数)。
単調に増加する整数は特定のシナリオに適している可能性がありますが、すべてのユース ケースに最適な選択であるとは限りません。特に書き込み集中型の状況では、ホットスポットや不均一なデータ分散につながる可能性があります。注文が必ずしも厳密な順序で到着するとは限らない販売システムでは、単調に増加する整数だけに頼ることは理想的ではない場合があります。
</div></details>

### Q. 質問23: 未回答
貴社のデータ アナリストは、プロジェクトで Cloud IAM オーナーのロールを保持し、さまざまな GCP プロダクトでの作業を円滑に進めます。会社のポリシーにより、BigQuery のデータ アクセスログを 6 か月間保持することが義務付けられています。あなたの仕事は、これらのログへのアクセスを、すべてのプロジェクトにわたって指定された監査担当者に制限することです。
これを達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 集計されたエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。エクスポートされたログを含むプロジェクトへのアクセスを制限します。
<details><div>
    答え：4
説明
社内の監査担当者のみがすべてのプロジェクトのデータアクセスログにアクセスでき、ログを 6 か月間保持できるようにするための正しいアプローチは、オプション D です。
オプション D: 
このオプションが最も適している理由は次のとおりです。
集約されたエクスポート シンク:集約されたエクスポート シンクを使用すると、複数のプロジェクトから 1 つの場所にログをエクスポートできるため、監査ログの一元的な管理とアクセスが容易になります。
クラウドストレージバケット:Cloud Storage バケットへのログのエクスポートは、ログを安全に保存するための一般的で効率的な方法です。
監査ログ用に新しく作成されたプロジェクト:監査ログ専用の別のプロジェクトを作成すると、ログを分離してセキュリティで保護するのに役立ちます。このプロジェクトにアクセスできるのは、許可された担当者のみです。
アクセスの制限:エクスポートされたログを含むプロジェクトでIAMポリシーとアクセス制御を設定することで、アクセスを監査担当者のみに制限し、許可された個人のみがログにアクセスして確認できるようにすることができます。
正しくないオプション -
オプション A: 各データ アナリストのプロジェクトでデータ アクセス ログを有効にします。Cloud IAM ロールによる Stackdriver Logging へのアクセスを制限します。
このオプションでは、各データ アナリストのプロジェクトでデータ アクセス ログを個別に有効にしてから、Stackdriver Logging へのアクセスを制限します。ただし、このオプションにはいくつかの欠点があります。
複雑さ：複数のプロジェクトでデータアクセスログを個別に有効にすることは、特にプロジェクトとデータアナリストの数が増えるにつれて、管理が複雑になる可能性があります。
限定的な中央集権化:ログは複数のプロジェクトに分散し、アクセス制御を効果的に一元化して管理することが困難になります。
潜在的なギャップ:個々のプロジェクト構成によっては、一部のログがキャプチャされず、監査にギャップが生じる可能性があります。
限定的な保持制御:すべてのプロジェクトで一貫した保持期間を管理することは困難な場合があります。
オプション B: プロジェクトレベルのエクスポート シンクを介して、データ アナリストのプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。Cloud Storage バケットへのアクセスを制限します。
このオプションでは、各データアナリストのプロジェクト内の Cloud Storage バケットにログをエクスポートし、アクセスを制限します。問題は次のとおりです。
分散ストレージ:ログは複数のプロジェクトに分散され、中央監査が複雑になる可能性があります。
限定的な制御:データアクセスログの保持とアクセス制御は、プロジェクトごとに個別に管理されるため、統一されたポリシーを適用することは困難でした。
アクセスの複雑さ:プロジェクトごとに個々の Cloud Storage バケットのアクセス制御を管理するのは面倒な場合があり、権限の一貫性を確保するのは困難です。
オプション C: プロジェクトレベルのエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータ アクセス ログをエクスポートします。エクスポートされたログでプロジェクトへのアクセスを制限します。
このオプションでは、監査ログ用の新しいプロジェクトを作成しますが、個々のプロジェクトからログをエクスポートします。このアプローチには、次のような問題があります。
散在エクスポート:監査ログ用の中央プロジェクトを作成しても、ログは個々の Data Analyst プロジェクトからエクスポートされるため、一元化されません。
アクセス制御の複雑さ:ログを含む中央プロジェクトでのアクセス制御の管理は複雑になる可能性があり、アクセスを完全に一元化するわけではありません。
保持管理:一貫した保存期間を確保することは、依然として困難な場合があります。
</div></details>

### Q. 質問24: 未回答
組織内の各分析チームが、それぞれのプロジェクト内で BigQuery ジョブを運用し、プロジェクト固有のスロットの使用状況を効果的にモニタリング、追跡できるようにするにはどうすればよいでしょうか。
1. 
2. BigQuery の指標スロット数 / allocated_for_projectに基づいて Cloud Monitoring ダッシュボードを作成する
3. 
4. 
<details><div>
    答え：2
説明
B. 
その理由は次のとおりです。
BigQuery にはスロット割り当て用のネイティブ指標が用意されており、スロット数/allocated_for_project指標はプロジェクトに割り当てられたスロット数を追跡するために特別に設計されています。このメトリックを使用すると、プロジェクト・レベルでスロットの使用状況をモニターできます。
このネイティブ指標に基づいて Cloud Monitoring ダッシュボードを作成することは、各分析チームのプロジェクトのスロットの使用状況をモニタリングする最も簡単で正確な方法です。
正しくないオプション -
A. BigQuery 指標クエリに基づいて Cloud Monitoring ダッシュボードを作成するscanned_bytes
このメトリックは、スロット割り当てではなくクエリによってスキャンされたデータに関連しており、プロジェクト レベルでのスロットの使用状況に関する直接的な分析情報は提供されません。
C. 各プロジェクトのログ エクスポートを作成し、BigQuery ジョブ実行ログをキャプチャし、totalSlotM に基づいてカスタム指標を作成し、カスタム指標に基づいて Cloud Monitoring ダッシュボードを作成します
このオプションには、ログのエクスポート、カスタムメトリックの作成、ダッシュボードの構成など、より複雑な設定が含まれます。可能ですが、より複雑で、ネイティブのスロット/allocated_for_projectメトリックと同じレベルの精度と使いやすさが得られない場合があります。
D. 組織レベルで集計ログのエクスポートを作成し、BigQuery ジョブの実行ログをキャプチャし、totalSlotMs に基づいてカスタム指標を作成し、カスタム指標に基づいて Cloud Monitoring ダッシュボードを作成します
オプションCと同様に、これには複雑なセットアップが必要であり、目的であるプロジェクトレベルでのきめ細かな監視が提供されない可能性があります。さらに、組織レベルでのログのエクスポートは、プロジェクト固有の監視に効率的でないか、必要ではない場合があります。
</div></details>

### Q. 質問25: 未回答
あなたはストリーミング Cloud Dataflow パイプラインを担当しています。エンジニアは、個別のウィンドウ処理アルゴリズムとトリガー戦略を組み込んだ新しいバージョンのパイプラインを開発しました。目的は、更新中のすべてのデータの保持を保証しながら、この新しいバージョンで既存の実行中のパイプラインをアップグレードすることです。
どうすればこれを実現できますか?
1. 
2. 
3. 
4. [ドレイン] オプションを使用して Cloud Dataflow パイプラインを停止します。更新されたコードで新しい Cloud Dataflow ジョブを作成します。
<details><div>
    答え：4
説明
D. 
正しい説明は次のとおりです。
オプション D では、既存の Cloud Dataflow パイプラインを [ドレイン] オプションで停止します。「ドレーン」オプションを使用すると、既存のジョブは停止する前に残りのデータの処理を完了できます。ドレインが完了したら、更新したコードで新しい Cloud Dataflow ジョブを作成し、開始できます。このアプローチにより、新しいジョブに移行する前にすべてのデータが古いジョブによって処理され、データ損失が最小限に抑えられ、スムーズな移行が保証されます。
誤ったオプション-
オプション A では、同じジョブ名を使用して --update オプションで既存のジョブを更新すると、更新で問題やデータ損失が発生した場合、実行中のジョブに影響を与える可能性があるため、リスクが伴う可能性があります。クリーンな移行は提供されません。
オプション B では、新しい一意のジョブ名を使用して --update オプションで既存のジョブを更新することが有効なアプローチになる場合がありますが、2 つのジョブが同時に実行される可能性があり、リソースが限られている場合は望ましくない可能性があります。
オプション C の [キャンセル] オプションを使用して Cloud Dataflow パイプラインを停止すると、既存のジョブが突然停止し、データの損失や処理の不完全な状態につながる可能性があります。スムーズな移行には適していません。
</div></details>

### Q. 質問27: 未回答
サードパーティからCSV形式の月次データファイルを定期的に受信しており、データクレンジングのソリューションが必要です。ただし、ファイル スキーマは 3 か月ごとに変更されます。このトランスフォーメーションプロセスの主な要件は次のとおりです。
- 変換の実行をスケジュールする。
- 開発者以外のアナリストが変換を変更できるようにする。
- 変換を設計するためのグラフィカルツールを提供します。
これらの要件を満たすには、どのような手順またはアプローチを取る必要がありますか?
1. Dataprep by Trifacta を使用して変換レシピを構築および管理し、スケジュールに基づいて実行する
2. 
3. 
4. 
<details><div>
    答え：1
説明
要件に最適なオプションは、A. Dataprep by Trifacta を使用して変換レシピを構築および管理し、スケジュールに基づいて実行することです。
その理由は次のとおりです。
スケジュールに従った変換の実行: Dataprep by Trifacta では、変換レシピの実行をスケジュールできます。定期的なジョブを設定して、受信する月次 CSV データを自動的に処理できます。
デベロッパー以外のアナリストが変換を変更できるようにする: Dataprep は、コーディングのスキルを必要としない、使いやすいグラフィカル インターフェースを提供します。デベロッパー以外のアナリストは、Dataprep が提供するビジュアル ツールを使用して変換を設計、変更できます。
変換をデザインするためのグラフィカル ツールの提供: Dataprep は、データ変換レシピをデザインするためのビジュアル インターフェースを提供します。アナリストは、コードを記述することなく、これらの変換を簡単に作成、変更、およびテストできます。
正しくないオプション -
オプション B(BigQuery にデータを読み込み、SQL クエリを使用する)は、固定スキーマでは機能する可能性がありますが、3 か月ごとのスキーマ変更に対応できる柔軟性はありません。また、開発者以外のアナリストに必要なグラフィカル ツールも提供されません。
オプション C(Python で Dataflow パイプラインを記述する)はコーディングを伴い、特にデベロッパー以外のアナリストにとっては使い勝手が悪い場合があります。また、スキーマの変更を処理するために、かなりの開発作業が必要です。
オプション D(Dataproc で Apache Spark を使用)は、より複雑な設定が必要で、アナリストにとって使い勝手が悪い場合があります。また、グラフィカルで開発者に適していない側面も強調されていません。
</div></details>

### Q. 質問28: 未回答
オンプレミスの Hadoop セットアップを Cloud Dataproc に移行することを目指しており、Hive が主要なツールであり、Optimized Row Columnar(ORC)がデータ形式です。これで、すべての ORC ファイルが Cloud Storage コンテナに効果的に転送されました。パフォーマンスを向上させるには、特定のデータをクラスターのローカルの Hadoop Distributed File System (HDFS) に複製する必要があります。
Cloud Dataproc 内で Hive の使用を開始するには、どのような方法がありますか?(2つ選択)
1. gsutil ユーティリティを実行して、すべての ORC ファイルを Cloud Storage バケットから HDFS に転送します。Hive テーブルをローカルにマウントします。
2. 
3. 
4. Cloud Storage Connector for Hadoop を活用して、ORC ファイルを外部 Hive テーブルとしてマウントします。外部 Hive テーブルをネイティブ テーブルにレプリケートします。
<details><div>
    答え：1,4
説明
オプション A: 
このオプションでは、gsutil を使用して Cloud Storage から Dataproc クラスタ上の Hadoop Distributed File System(HDFS)に ORC ファイルをコピーします。その後、HDFSのデータの上にHiveテーブルを作成し、ローカルにマウントできます。
オプション D: 
このオプションでは、Cloud Storage Connector for Hadoop を使用して Cloud Storage 内の ORC ファイルに直接アクセスし、それらに基づいて外部 Hive テーブルを作成します。これらの外部 Hive テーブルからネイティブ Hive テーブルにデータをレプリケートできます。
パフォーマンスを最適化するためにデータをHDFSに複製する場合は、オプションAが適切な選択です。データをHDFSに複製せずに外部表を操作する場合は、オプションDが適切です。
</div></details>

### Q. 質問29: 未回答
特定の順序に従う必要があり、シェル スクリプトの実行、Hadoop ジョブの実行、BigQuery でのクエリの実行を含む、相互に依存する複数のステップを持つバッチ ジョブを管理するプロセスでは、数分から数時間の範囲で、障害が発生した場合に一定の再試行が必要になると予想されますが、ジョブの実行を監視するためにどのサービスを採用する必要がありますか?
1. 
2. 
3. 
4. Cloud Composer
<details><div>
    答え：4
説明
相互に依存するステップ、再試行、特定の注文要件を持つ複雑なバッチ ジョブの実行を管理するには、Cloud Composer(オプション D)を使用する必要があります。
Cloud Composer は、Apache Airflow 上に構築されたフルマネージドのワークフロー オーケストレーション サービスです。これにより、ワークフローを有向非巡回グラフ (DAG) として定義、スケジュール、および監視できます。タスク間の依存関係を持つ複雑なワークフローを作成したり、再試行ポリシーを指定したり、タスクの実行順序を設定したりできます。さらに、シェル スクリプトの実行、Hadoop ジョブ、BigQuery クエリなど、さまざまな GCP サービスをワークフローに統合できます。
正しくないオプション -
Cloud Scheduler(オプション A)は、主にスケジュールに従って HTTP/S エンドポイントまたは Pub/Sub トピックをトリガーするように設計されています。タスク間の依存関係を持つ複雑なワークフローの管理には適していません。
Cloud Dataflow(オプション B)は、汎用のバッチ ジョブ オーケストレーションよりも、データ処理やストリーム処理のジョブに適しています。
Cloud Functions(オプション C)は、サーバーレスのイベントドリブン関数向けに設計されているため、依存関係のある実行時間の長い複雑なバッチ ジョブの管理には適していない可能性があります。
</div></details>

### Q. 質問30: 未回答
あなたは、荷物が仕分けのために配送ラインを通過する配送センターを運営する運送会社に雇用されています。同社は、配送ラインにカメラを導入することで、荷物の取り扱いプロセスを強化することを目指しています。これらのカメラは、輸送中のパッケージの視覚的な損傷を特定して監視することを目的としています。あなたの仕事は、損傷したパッケージをリアルタイムで検出し、その後、輸送中の人間によるレビューのためにそのようなパッケージにタグを付けるための自動化システムを考案することです。このシナリオに最も適したソリューションはどれですか?
1. 
2. AutoML モデルをトレーニングする
3. 
4. 
<details><div>
    答え：2
説明
オプション B ():
カスタマイズ：AutoML (Auto Machine Learning) を使用すると、特定のデータセット (この場合は破損したパッケージの画像) に基づいてカスタム機械学習モデルをトレーニングできます。
統合：AutoML モデルを中心に API を構築できるため、パッケージ追跡アプリケーションと簡単に統合でき、リアルタイム分析が可能になります。
精度：カスタム モデルは、多くの場合、汎用モデルと比較して、特定のタスクに対してより高い精度を提供します。
正しくないオプション -
オプション C (Cloud Vision API を使用):
使いやすさ:Cloud Vision API は、一般的なユースケース向けに事前トレーニング済みのモデルを提供するマネージド サービスです。物体や一部の損傷を検出できますが、パッケージの特定の種類の損傷を特定するなど、高度に専門的なタスクでは精度が低くなる可能性があります。
カスタマイズ：これは、パッケージに固有の微妙な損傷タイプを検出するためのカスタムトレーニング済みモデルほど柔軟ではない可能性があります。
オプション D(TensorFlow と Datalab を使用):
複雑さ：カスタム TensorFlow モデルを構築して維持するには、データの前処理、モデルのトレーニング、デプロイなど、多大な開発作業が必要です。これは複雑で時間がかかる場合があります。
リアルタイム検出:リアルタイムの検出と荷物追跡アプリケーションとの統合には、追加のインフラストラクチャと開発作業が必要になります。
オプション A(BigQuery 機械学習を使用する):
バッチ処理:BigQuery の機械学習は、リアルタイムの画像分析ではなく、バッチ処理とデータ分析用に設計されています。輸送中の荷物の損傷を検出するのには適していません。
</div></details>

### Q. 質問33: 未回答
広告会社に勤務し、広告ブロックのクリックスルー率を予測するためのSpark MLモデルを作成しました。以前はオンプレミスのデータセンターで作業していましたが、データセンターの閉鎖が間近に迫っているため、会社は Google Cloud に移行しています。データを BigQuery に移行し、Spark ML モデルを定期的に再トレーニングするため、既存のトレーニング パイプラインを Google Cloud に迅速に移行する必要があります。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 既存の Spark ML モデルのトレーニングには Dataproc を使用しますが、BigQuery から直接データの読み取りを開始します。
4. 
<details><div>
    答え：3
説明
オプション C: 
このオプションは、Google Cloud への移行中に既存の Spark ML モデルを移行する場合に適しています。これが正しいオプションである理由は次のとおりです。
Dataproc の互換性:Google Cloud Dataproc は、Spark やその他のビッグデータ フレームワークをシームレスに実行できるように設計されています。これにより、大規模な書き換えを行うことなく、既存の Spark ML モデルを引き続き使用できます。
BigQuery との統合:Dataproc は BigQuery からデータを直接読み取ることができるため、BigQuery に保存されているデータで Spark ML モデルを効率的にトレーニングできます。この統合により、データの移動が最小限に抑えられ、複雑さと遅延が軽減されます。
正しくないオプション -
A. トレーニングに Vertex AI を使用する: Vertex AI は Google Cloud の強力な機械学習プラットフォームですが、主に TensorFlow モデルと scikit-learn モデルをサポートしています。既存の Spark ML モデルを Vertex AI に移行するには、大幅な変更が必要になる場合があり、迅速なリフト&シフト移行に対応できない場合があります。
B. TensorFlow でモデルを書き換え、Vertex AI を使用する: このオプションでは、既存の Spark ML モデルを TensorFlow で書き換える必要がありますが、これには時間がかかり、迅速な移行には適さない場合があります。
D. Compute Engine で Spark クラスタを起動する: Compute Engine で Spark を実行することもできますが、このオプションではインフラストラクチャを自分で設定して管理する必要があります。移行プロセスが複雑になる可能性があり、この特定のシナリオでは Dataproc と BigQuery の統合を使用する明確なメリットはありません。
</div></details>

### Q. 質問36: 未回答
Node.js で記述された Cloud Functions があり、Cloud Pub/Sub からメッセージを取得して BigQuery にデータを送信します。Pub/Sub トピックのメッセージ処理速度が予想よりも桁違いに高いことがわかりますが、Cloud Logging にはエラーは記録されません。この問題の最も可能性の高い 2 つの原因は何ですか?(2つ選択してください。
1. 
2. 
3. サブスクライバー コードでのエラー処理がランタイム エラーを適切に処理していません。
4. 
<details><div>
    答え：3
説明
C. 
このオプションは、サブスクライバー コードで適切に処理されないランタイム エラーが検出されると、メッセージ処理フローが中断される可能性があるため、正しい方法です。未処理のエラーにより、サブスクライバーがメッセージの処理を停止し、バックログが発生する可能性があります。また、エラーの詳細が正しく記録されていない場合、Cloud Logging にエラー メッセージが表示されず、トラブルシューティングが困難になる可能性があります。
E.サブスクライバー・コードは、プルするメッセージを確認しません。
Cloud Pub/Sub はメッセージが正常に処理されたかどうかをメッセージ確認に基づいて判断するため、このオプションは正しいです。処理後にサブスクライバー コードがメッセージを確認しない場合、Pub/Sub はメッセージが未処理であると見なして再配信するため、メッセージの処理速度が効果的に向上します。メッセージのフローを維持するためには、メッセージを適切に確認することが重要です。
正しくないオプション -
A. パブリッシャーのスループット クォータが小さすぎます。
このオプションは、パブリッシャーのスループット クォータがメッセージが Pub/Sub トピックにパブリッシュされるレートに関連しているため、問題の原因となる可能性は低くなります。サブスクライバーがメッセージを消費および処理できる速度には直接影響しません。パブリッシャーのスループット クォータを超えた場合、メッセージの発行に影響を与える可能性がありますが、サブスクライバー側のメッセージ処理速度が急激に増加することはありません。
B. 未処理のメッセージの合計が最大 10 MB を超えています。
また、このオプションは、観察された問題の原因である可能性も低くなります。10 MB の最大制限は、通常、個々のメッセージのサイズを指します。この制限を超えると、メッセージ サイズの問題が発生する可能性がありますが、メッセージ処理速度の大幅な増加には直接つながりません。これにより、メッセージのサイズに関連する問題が発生する可能性がありますが、メッセージの処理速度には関連しません。
D. サブスクライバ コードがメッセージに追いつかない。
Pub/Sub トピックのメッセージ処理レートが、Cloud Functions の関数サブスクライバー コードでメッセージを処理できるレートよりもはるかに高い場合、未処理のメッセージのバックログが発生します。
正しいオプションは C と E で、サブスクライバー コードの問題と、メッセージを適切に処理および確認する機能に直接関連しているため、観察された問題につながる可能性があります。
</div></details>

### Q. 質問37: 未回答
Google Cloud で新しいパイプラインを作成し、Cloud Pub/Sub から Cloud Dataflow を介して BigQuery に IoT データをストリーミングします。データをプレビューしていると、データの約 2% が破損しているように見えます。Cloud Dataflow パイプラインを変更して、この破損したデータを除外する必要があります。あなたは何をするべきか?
1. 
2. Cloud Dataflow に ParDo 変換を追加して、破損した要素を破棄します。
3. 
4. 
<details><div>
    答え：2
説明
回答: B. 
Cloud Dataflow に ParDo 変換を追加することは、破損したデータを除外するための最良の方法です。SideInput は、要素が破損している場合に Boolean を返しますが、実際には要素を破棄しません。パーティション変換では、有効なデータと破損したデータを分離できますが、破損したデータは破棄されません。GroupByKey 変換では、すべての有効なデータをグループ化できますが、破損したデータは破棄されません。
</div></details>

### Q. 質問42: 未回答
サードパーティ企業に分析のために BigQuery のデータセットへのアクセス権を付与する際に、データの鮮度を維持し、データ共有費用を最小限に抑えるには、どのソリューションを選択すればよいでしょうか?
1. Analytics Hub を使用してデータ アクセスを制御し、サードパーティ企業にデータセットへのアクセスを提供します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
Analytics Hubを使用してデータアクセスを制御することは、コストを低く抑え、データを最新の状態に保ちながら、サードパーティ企業にデータセットへのアクセスを提供できるため、最適なソリューションです。
正しくないオプション -
Cloud Scheduler はジョブとタスクのスケジュール設定に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション B は正しくありません。
BigQuery で別のデータセットを作成することは、最も費用対効果の高いソリューションではなく、データが最新であることを保証できないため、オプション C は正しくありません。
Dataflow はデータの処理と変換に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション D は正しくありません。
</div></details>

### Q. 質問43: 未回答
現在、オンプレミスのデータ ウェアハウス ソリューションを BigQuery に移行している会社では、さまざまなトランザクション データベース ソースからの更新を毎日適用するために、変更データ キャプチャ(CDC)プロセスを強化したいと考えています。この改善は、データ ウェアハウス変更アプリケーションのパフォーマンスの最適化に重点を置き、ログベースの CDC ストリームを介して BigQuery でソース システムからの変更にすばやくアクセスできるようにすることを目的としています。BigQuery レポートの表で変更を利用できるようにするためのレイテンシを最小限に抑えながら、コンピューティングのオーバーヘッドを削減するには、どの 2 つのアクションを実行すべきでしょうか。(2つ選択)
1. 
2. 新しい各 CDC レコードと対応する操作の種類をステージング テーブルにリアルタイムで挿入します。
3. 
4. DML MERGE を定期的に使用して、レポート テーブルで複数の DML INSERT、UPDATE、および DELETE 操作を同時に実行します。
5. 
<details><div>
    答え：2,4
説明
B. 
この手順は、ソース システムから変更をリアルタイムでキャプチャし、ステージング テーブルに格納するために不可欠です。ステージング テーブルは、受信 CDC データのバッファーを提供し、データをレポート表に移動する前に、必要なビジネス ロジックを検証、変換、および適用できます。このアプローチは、レポート データセットの一部になる前に、データの一貫性と正確性を確保するのに役立ちます。
D. 
定期的な MERGE 操作の使用は、累積された変更をステージング テーブルからレポート テーブルに適用するための効果的な戦略です。これにより、複数の CDC レコードを 1 つの DML 操作に統合し、個々の INSERT、UPDATE、または DELETE に関連するオーバーヘッドを削減できます。このアプローチにより、計算コストが最適化され、レポート テーブルを効率的に維持できます。
正しくないオプション -
A. DML INSERT、UPDATE、または DELETE を実行して、個々の CDC レコードをレポート テーブルに直接リアルタイムで直接レプリケートします。
このオプションを使用すると、すべての CDC レコードのレポート テーブルで個々の DML 操作が大量に発生する可能性があり、リソースを大量に消費し、最適なクエリ パフォーマンスが得られない可能性があります。
C. レポート テーブルから古いレコードを定期的に削除します。
古いレコードの削除はデータ管理に必要ですが、CDC データのほぼリアルタイムの処理要件には対応していません。このオプションは、タイムリーな更新ではなく、データ保持に重点を置いています。
E. 新しい各 CDC レコードと対応する操作の種類をレポート テーブルにリアルタイムで挿入し、具体化されたビューを使用して、一意の各レコードの最新バージョンのみを公開します。
具体化されたビューはクエリのパフォーマンスを最適化するのに役立ちますが、このアプローチでは CDC データ自体のリアルタイム処理には対応していません。具体化されたビューは、通常、集計または概要を事前に計算するために使用され、リアルタイムのデータキャプチャや変換用には設計されていません。
待機時間を最小限に抑え、コンピューティング オーバーヘッドを削減してほぼリアルタイムの CDC を実現するには、手順 B と D を組み合わせることをお勧めします。ステージング テーブル (B) で変更をリアルタイムでキャプチャし、これらの変更をレポート テーブル (D) に定期的にマージして、データセットを効率的に更新します。
</div></details>

### Q. 質問44: 未回答
負荷の増加に応じて自動的にスケーリングできるデータ処理パイプラインを設計し、メッセージが少なくとも 1 回処理されるようにし、1 時間以内に順序を維持する必要があります。このソリューションをどのように設計する必要がありますか?
1. 
2. 
3. 
4. メッセージの取り込みには Cloud Pub/Sub を使用し、ストリーミング分析には Cloud Dataflow を使用します。
<details><div>
    答え：4
説明
D. 
このオプションは、Cloud Pub/Sub と Cloud Dataflow の両方の長所を活用しているため、要件に適した選択肢となります。
Cloud Pub/Sub は、高スループットのメッセージ取り込みを処理できるマネージド メッセージング サービスです。これにより、メッセージの少なくとも 1 回分の配信が保証され、メッセージの順序を維持できるため、1 時間以内にメッセージを順序付けするという要件に合わせることができます。
Cloud Dataflow は、負荷に応じて自動的にスケーリングできるマネージド ストリームおよびバッチ データ処理サービスです。これにより、ウィンドウ処理やトリガーなどの処理パイプラインを定義して、リアルタイムまたは最小限のレイテンシーでデータを処理できます。この選択により、1 時間以内に目的のメッセージ処理を実現できます。
正しくないオプション -
A. メッセージの取り込みには Apache Kafka を使用し、ストリーミング分析には Cloud Dataproc を使用します。Apache Kafka はメッセージの取り込みに適しており、メッセージの順序を維持できますが、ストリーミング分析に Cloud Dataproc(マネージド Spark および Hadoop サービス)を使用すると、Cloud Dataflow と比較してリアルタイム処理の効率が低くなります。Cloud Dataproc は通常、バッチ処理やアドホック データ分析に使用されます。
B. メッセージの取り込みには Apache Kafka を使用し、ストリーミング分析には Cloud Dataflow を使用します。このオプションも有効な選択であり、うまく機能します。取り込みには Kafka を、ストリーミング分析には Cloud Dataflow を組み合わせています。私の以前の応答は、このオプションを誤って却下しました。見落としをお詫びします。
C. メッセージの取り込みに Cloud Pub/Sub を使用し、ストリーミング分析に Cloud Dataproc を使用します。前述したように、ストリーミング分析に Cloud Dataproc を使用することは、最も効率的な選択ではない可能性があります。Cloud Dataflow は、Google Cloud のエコシステムでのリアルタイム ストリーミング分析に適しています。
</div></details>

### Q. 質問46: 未回答
金融機関は、機密性の高い顧客データを安全に保管し、規制コンプライアンスを確保する必要があります。これには、暗号化、監査ログ、きめ細かなアクセス制御を備えたマネージド・データベース・サービスが必要です。どのGCPサービスを選ぶべきか?
1. Cloud SQL
2. 
3. 
4. 
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. 
Cloud SQL は、機密データを処理するように設計された Google Cloud のマネージド リレーショナル データベース サービスです。保存中および転送中の暗号化、自動バックアップ、きめ細かなアクセス制御などの機能を提供します。これは、規制コンプライアンスと機密性の高い顧客データの安全なストレージを必要とするアプリケーションに適しています。構造化されたリレーショナルデータベースの使用は、取引データやコンプライアンスの目的で金融機関で好まれることがよくあります。
正しくないオプション -
B. Bigtable は、主に高スループットでスケーラブルなワークロード向けに設計された NoSQL データベースであり、機密性の高い顧客データを安全に保存し、規制コンプライアンスを確保するには最適な選択肢ではない可能性があります。Cloud SQL と同じレベルの組み込みのセキュリティ機能やコンプライアンス機能は提供されません。
C. Firestore は、一般的に柔軟でスキーマレスのデータ ストレージに使用される NoSQL ドキュメント データベースですが、金融機関が必要とする特定のセキュリティおよびコンプライアンス機能を提供しない場合があります。Firestore は通常、より柔軟で俊敏なデータ ストレージのニーズに合わせて選択されます。
D. BigQuery は、大規模なデータセットの分析とクエリに使用される、サーバーレスで拡張性の高いデータ ウェアハウスです。データ分析には使用できますが、主にトランザクション データベースではなく、Cloud SQL と同じレベルのセキュリティとコンプライアンス機能を提供していません。
Cloud SQL は、必要なセキュリティとコンプライアンスの機能に加えて、機密性の高い顧客データを金融機関に安全に保管するために必要な構造を備えているため、最も適切な選択肢です。
</div></details>

### Q. 質問47: 未回答
あなたの会社は、投稿、コメント、いいねなどのユーザー生成コンテンツを保存するために、柔軟でスキーマレスなデータベースを必要とするソーシャルメディアプラットフォームを開発しています。このシナリオに適したGCPデータベースサービスはどれですか?
1. 
2. Firestore
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は B. Firestore です。
このシナリオの要件は、ソーシャル メディア プラットフォームの投稿、コメント、いいねなどのユーザー生成コンテンツを保存することです。時間の経過とともに変化する可能性のある、このユーザー生成コンテンツのさまざまな構造に対応するには、柔軟なスキーマレスデータベースが必要です。
Firestore は、柔軟でスキーマレスなデータ ストレージを提供する NoSQL ドキュメント データベースです。非構造化データや半構造化データを簡単に処理できるため、ユーザーが作成したコンテンツをソーシャルメディアプラットフォームに保存するための優れた選択肢となります。Firestore は、このようなアプリケーションに不可欠なリアルタイムの同期とスケーラビリティも提供します。
正しくないオプション -
A. BigQueryの場合:BigQuery は分析用のデータ ウェアハウスであり、ユーザーが生成したコンテンツを保存するための柔軟なスキーマレス データベースではありません。構造化データに対して複雑なSQLクエリを実行するように設計されているため、ソーシャルメディアの投稿やコメントなどの非構造化コンテンツや半構造化コンテンツにはあまり適していません。
C. クラウドデータストア:Cloud Datastore も Google Cloud が提供する NoSQL データベースですが、より最新の機能と優れたスケーラビリティにより、Firestore がほぼこれに取って代わりました。このシナリオでも Cloud Datastore は機能しますが、新しいプロジェクトでは一般的に Firestore をおすすめします。
D. Cloud SQL:Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。固定スキーマが適用されるため、ソーシャルメディアプラットフォームにおけるユーザー生成コンテンツの柔軟でスキーマレスな性質にはあまり適していません。Cloud SQL は、構造化データ ストレージとリレーショナル データベースのニーズに適しています。
</div></details>

### Q. 質問48: 未回答
オンラインゲーム会社は、スコア、実績、ゲームの進行状況などのプレーヤー統計をリアルタイムで保存して処理したいと考えています。頻繁な更新とクエリを処理できるデータベースが必要です。どのGCPサービスをお勧めしますか?
1. Bigtable
2. 
3. 
4. 
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. Bigtable
このシナリオでは、オンラインゲーム会社は、頻繁な更新とクエリを使用して、プレーヤーの統計をリアルタイムで保存および処理する必要があります。Bigtable は、Google Cloud Platform(GCP)上の NoSQL で拡張性が高く、低レイテンシのデータベース サービスであり、大量のデータを高い読み取りおよび書き込みスループットで処理するように設計されています。
リアルタイム データ処理: Bigtable は、リアルタイム データを低レイテンシで処理することに優れているため、ゲームプレイ中にリアルタイムで更新されるプレイヤーの統計情報を保存および処理するのに適しています。
スケーラビリティ: Bigtable は、多数のプレイヤーと広範な統計を扱うゲーム会社にとって不可欠な、大量のデータに対応するために簡単に拡張できます。
頻繁な更新とクエリ: Bigtable の設計は、高頻度の読み取りおよび書き込み操作に最適化されているため、プレイヤーの統計情報の記録と取得に適しています。
正しくないオプション -
B. クラウドデータストア:
Cloud Datastore も NoSQL データベースですが、一般的には、より構造化されたトランザクション データ ストレージを必要とするアプリケーションに適しています。頻繁な更新とクエリを伴うリアルタイムのゲーム統計については、Bigtable ほどパフォーマンスが高くない可能性があります。
C. BigQueryの場合:
BigQuery は、大規模なデータセットの分析とクエリ用に設計されたデータ ウェアハウス サービスです。これは、このシナリオの主要な要件であるリアルタイムのデータストレージと処理にはあまり適していません。
D. Cloud SQL:
Cloud SQL は、マネージド リレーショナル データベース サービスです。構造化データやトランザクションデータには適していますが、頻繁な更新やクエリを伴うリアルタイムのゲーム統計に必要なパフォーマンスとスケーラビリティを提供しない場合があります。
Bigtable は、リアルタイム処理機能、スケーラビリティ、頻繁な更新やクエリを処理する能力など、ゲーム会社のプレイヤー統計の要件に合致しているため、最も適切な選択肢です。
</div></details>

### Q. 質問49: 未回答
組織はニュース Web サイトを運営しており、ユーザーの行動データを分析してコンテンツのレコメンデーションをパーソナライズする必要があります。リアルタイムのデータストリーミングと複雑な分析を効率的に処理できるGCPデータベースサービスはどれですか?
1. 
2. 
3. 
4. BigQuery
<details><div>
    答え：4
説明
質問の正しいオプションは D. BigQuery です。
BigQuery は、フルマネージドのサーバーレス データ ウェアハウスであり、リアルタイムのデータ ストリーミングや複雑な分析の処理に適しています。BigQuery は、大規模なデータセットの複雑な分析に優れたデータ ウェアハウスおよび分析プラットフォームです。ストリーミング挿入などの機能を通じてリアルタイムのデータストリーミングを効率的に処理でき、強力な分析のためのSQLのようなクエリ言語を提供します。これは、ユーザーの行動データに対して複雑なクエリを実行してコンテンツのレコメンデーションをパーソナライズするのに適しており、このシナリオに最も適した選択肢です。
コンテンツのレコメンデーションをパーソナライズするためにユーザーの行動データを分析する必要がある場合や、リアルタイムのデータ ストリーミングと複雑な分析が必要な場合、BigQuery は要件に最適な GCP データベース サービスです。
正しくないオプション -
A. Cloud Pub/Sub の場合: Cloud Pub/Sub は、イベントドリブン システムの構築とデータのストリーミングのためのメッセージング サービスです。データのストリーミングには便利ですが、BigQuery のようなデータベース サービスではなく、複雑な分析は実行しません。これは通常、メッセージ キューイングとイベント ドリブン アーキテクチャに使用されます。
B. Bigtable の場合: Bigtable は、高スループット、低レイテンシ、スケーラビリティを実現するように設計された NoSQL データベースです。大量のデータへの高速な読み取りおよび書き込みアクセスを必要とするアプリケーションには適していますが、複雑な分析には最適化されていません。Bigtable は、時系列データやキー値ストレージなどのユースケースに適しています。
C. Firestore: Firestore は、モバイル アプリケーションやウェブ アプリケーション向けに設計された NoSQL データベースです。リアルタイム データを処理できますが、主にトランザクション データに使用され、複雑な分析には使用されません。これはドキュメントベースのストレージ用に設計されており、クライアント間でデータをリアルタイムで同期する必要があるアプリケーションに適しています。
</div></details>

### Q. 質問50: 未回答
ある医療企業は、患者記録管理システムを構築しています。そのためには、強力な一貫性と自動シャーディングを備えた、可用性の高いグローバルに分散されたデータベースが必要です。これらの要件に当てはまる GCP サービスはどれですか?
1. 
2. Cloud Spanner
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しいオプションは B. Cloud Spanner です。
Cloud Spanner:
Cloud Spanner は、グローバルに分散され、水平方向にスケーラブルで、強力な一貫性を持つデータベース サービスです。これは、質問に記載されている要件を満たすように特別に設計されています。自動シャーディングを提供し、グローバルな分散を提供することで、複数のリージョン間でデータの可用性と一貫性を確保します。
Cloud Spanner は、医療における患者記録管理システムなど、データの整合性、強力な一貫性、グローバルな可用性が重要なアプリケーションに最適です。
正しくないオプション -
クラウドデータストア:
Cloud Datastore は NoSQL データベースですが、グローバルに分散した患者記録管理システムに必要な強力な整合性と自動シャーディングは提供されません。
高可用性を実現するように設計されていますが、医療データに必要なレベルのグローバル分散と強力な一貫性は提供されない場合があります。
Bigtable の場合:
Bigtable は、大規模な分析および運用ワークロード向けに最適化された NoSQL データベースですが、医療アプリケーションの重要な要件である強力な一貫性をすぐに提供することはできません。
大量のデータを処理でき、高可用性を提供しますが、強力な一貫性を必要とするアプリケーションには最適ではありません。
クラウド SQL:
Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。自動シャーディングは提供されておらず、医療患者記録管理システムに必要なレベルのグローバル分散と強力な一貫性を提供しない可能性があります。
従来のリレーショナルデータベースのユースケースには適していますが、このシナリオには最適ではありません。
</div></details>

## 3
### Q. 質問2: 未回答
地震データを解析するシステムを設計します。抽出、変換、読み込み (ETL) プロセスは、Apache Hadoop クラスターで一連の MapReduce ジョブとして実行されます。ETLプロセスでは、一部のステップで計算コストがかかるため、データセットの処理に数日かかります。次に、センサーのキャリブレーション手順が省略されていることがわかります。今後、センサーのキャリブレーションを体系的に実施するために、ETLプロセスをどのように変更する必要がありますか?
1. 
2. 新しい MapReduce ジョブを導入して、センサーのキャリブレーションを生データに適用し、この後、他のすべての MapReduce ジョブがチェーンされるようにします。
3. 
4. 
<details><div>
    答え：2
説明
正しいアプローチは B です。 
オプションBでは、センサーキャリブレーション専用のMapReduceジョブを導入し、すべてのデータがこの重要なステップを経てからさらに処理されるようにします。センサーキャリブレーションの省略に対処するための体系的かつ組織的な方法を提供し、ETLパイプラインで処理されるすべてのデータが将来一貫してキャリブレーションされることを保証します。
正しくないオプション -
A. 変換 MapReduce ジョブを変更して、他の処理を行う前にセンサーのキャリブレーションを適用します。
このオプションは、既存の変換ジョブを変更するだけなので、過去のセンサー調整の省略の問題には対処しません。今後のデータはキャリブレーションされますが、キャリブレーションされていないデータを遡及的に修正することはありません。
C. ETL プロセスの出力にセンサー キャリブレーション データを追加し、すべてのユーザーがセンサー キャリブレーションを自分で適用する必要があることを文書化します。
このオプションでは、センサのキャリブレーションの責任がエンドユーザーに移るため、体系的で信頼性の高いプロセスには理想的ではありません。ユーザーはキャリブレーションを忘れたり、誤って適用したりして、不整合につながる可能性があります。
D. シミュレーションを通じてアルゴリズムを開発し、キャリブレーション係数に基づいて最後の MapReduce ジョブから出力されたデータ出力の分散を予測し、その補正をすべてのデータに適用します。
このアプローチは洗練されているように聞こえますが、シミュレーションと予測に依存しているため、信頼性の高いセンサーのキャリブレーションには十分な精度が得られない可能性があります。また、複雑で、ある程度の不確実性が生じます。
</div></details>

### Q. 質問3: 未回答
オンライン小売業者の既存のアプリケーションは、Google App Engine でホストされています。新しい会社のイニシアチブでは、顧客との直接取引を可能にするためにアプリケーションを拡張しる必要があります。ビジネス インテリジェンス(BI)ツールを使用してショッピング トランザクションを効果的に管理し、複数のソースからのデータを分析するために、単一の Google Cloud データベースを活用することを目指しています。この要件には、どの Google Cloud データベースを選択すればよいでしょうか?
1. 
2. Cloud SQL
3. 
4. 
<details><div>
    答え：2
説明
オンライン小売業者がショッピング トランザクションを管理する必要があるこのシナリオでは、データベース ソリューションとして Cloud SQL(オプション B)を選択するのが適切です。
Cloud SQL が適している理由は次のとおりです。
トランザクション データ: Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。これは、トランザクション データの保存と管理用に設計されており、ショッピング トランザクションを管理する要件と一致しています。
ACIDコンプライアンス: Cloud SQLデータベースは、ACID(原子性、一貫性、分離性、耐久性)に準拠し、トランザクションの信頼性と一貫性を確保します。
互換性: 小売業者の既存のアプリケーションがすでに Google App Engine で実行されている場合、Cloud SQL は App Engine とシームレスに統合されるため、自然な選択です。
BIツールの統合:Cloud SQLは、さまざまなBIツールのデータソースとして使用でき、小売業者は必要に応じてデータ分析を実行できます。
構造化データ: Cloud SQL は構造化データに適していますが、これは通常、トランザクション システムの場合です。
正しくないオプション -
BigQuery(オプション A): BigQuery は分析ワークロードや大規模なデータセットのクエリには優れていますが、通常、トランザクション データのプライマリ データベースとしては使用されません。これは、履歴データまたは集計データの保存と分析に適しています。
Cloud Bigtable(オプション C): Cloud Bigtable は、高スループット、低レイテンシの読み取り/書き込みオペレーション用に最適化された NoSQL データベースです。これは、大規模なリアルタイムのデータアクセスを必要とするアプリケーションに適していますが、従来のトランザクションデータには最適な選択ではない可能性があります。
Cloud Datastore(オプション D):Cloud Datastore は、高可用性とスケーラビリティを必要とするアプリケーションに適した NoSQL データベースです。ただし、一般的には非構造化データまたは半構造化データに使用され、トランザクション データ管理には適していない場合があります。
</div></details>

### Q. 質問5: 未回答
分析チームは、さまざまな指標を利用して、会社と再び関わる可能性が高い顧客を特定するための基本的な統計モデルを作成しようとしています。このモデルは Apache Spark を使用して実行し、データは Google Cloud Storage に保存される予定で、このタスクに Google Cloud Dataproc を利用することを提案しました。初期テストでは、このジョブは 30 ノード クラスタで約 15 分で完了し、結果は Google BigQuery に保存されることが示されています。目的は、このタスクを毎週実行することです。コスト効率を高めるためにクラスタ構成を最適化するにはどうすればよいでしょうか。
1. ワークロードを Google Cloud Dataflow に移行します。
2. クラスターにプリエンプティブル仮想マシン (VM) を使用します。
3. メモリの大きいノードを使用して、ジョブの実行を高速化します。
4. ワーカー ノードで SSD を使用して、ジョブの実行を高速化します。
<details><div>
    答え：2
説明
Google Cloud Dataproc の Apache Spark で週単位のワークロードを実行する際に、クラスタのコストを最適化するための正しいオプションは次のとおりです。
B. 
プリエンプティブル VM: プリエンプティブル VM は、標準のオンデマンド VM よりも大幅に安価であるため、Google Cloud の費用対効果の高いオプションです。ただし、Google Cloud によっていつでもプリエンプト(終了)される可能性があり、通常は短期間(最大 24 時間)でプリエンプト(終了)される可能性があります。週単位の統計モデルの実行など、長期的なアップタイムを必要としないワークロードでは、プリエンプティブル VM を使用すると、かなりのコストを節約できます。
正しくないオプション -
A. 
Google Cloud Dataflow への移行はオプションかもしれませんが、これは別のテクノロジーであり、既存の Apache Spark ベースのワークロードに大幅な変更が必要になる場合があります。これにより、複雑さが増し、開発作業が増える可能性があります。また、Dataflow と Dataproc のコストへの影響は、特定のユースケースによって異なります。
C. 
メモリの大きいノードを使用すると、ジョブのパフォーマンスが向上する可能性がありますが、コストが大幅に増加する可能性もあります。コストを最適化するこのシナリオでは、特にジョブが小さなプリエンプティブル ノードで効率的に実行される場合、より大きなノードを選択することは最も効率的なアプローチではない可能性があります。
D. 
ワーカー ノードに SSD を追加すると、データの読み取り/書き込みパフォーマンスが向上する可能性がありますが、必ずしもコスト最適化戦略ではありません。SSD はインフラストラクチャ コストを増加させる可能性があり、30 ノード クラスターで既に 15 分で実行されているジョブのパフォーマンス向上は大きくない可能性があります。コストの最適化が主な目的である場合、このオプションは最適な選択ではない可能性があります。
</div></details>

### Q. 質問6: 未回答
会社は、バッチベースとストリームベースのイベントデータの両方を受信します。Google Cloud Dataflow を使用して、予測可能な期間にわたってデータを処理したい。ただし、場合によっては、データが遅れたり、順序どおりに届かなかったりすることがあります。
遅延したデータや順序が正しくないデータを処理するために、Cloud Dataflow パイプラインをどのように設計すればよいですか?
1. 
2. 
3. 透かしとタイムスタンプを使用して、時間差データをキャプチャします。
4. 
<details><div>
    答え：3
説明
Google Cloud Dataflow パイプラインで遅延または順序が正しくないデータを処理するには、次のことを行う必要があります。
C. 
ウォーターマークとタイムスタンプ: Google Cloud Dataflow のようなストリーム処理パイプラインでは、ウォーターマークとタイムスタンプは、遅延データや順不同のデータを処理するために不可欠な概念です。ウォーターマークはイベント時間の進行状況を表し、特定の期間にデータが完了したと見なすのが安全である時期を Dataflow が理解するのに役立ちます。タイムスタンプは、イベントがいつ発生したかを示します。
ウォーターマークとタイムスタンプを使用すると、次のことができます。
処理時間ではなくイベント時間に基づいてウィンドウを定義します。これにより、遅れて到着しても、関連する時間枠に属するデータを取得できます。
イベントが到着したときにタイムスタンプを割り当て、ウォーターマークを使用してイベント時間の進行状況を追跡することで、順不同のデータを処理します。Dataflow は、イベントのタイムスタンプに基づいて、適切なウィンドウにイベントを正しく配置できます。
正しくないオプション -
A. すべてのデータを取得するために 1 つのグローバル ウィンドウを設定します。
このアプローチでは、データの遅延や順序の乱れの問題には対処できません。すべてのデータが 1 つのウィンドウにあるかのように扱われ、指定された時間枠の後に到着したイベントを正しく処理するために必要な柔軟性は提供されません。
B. スライディング ウィンドウを設定して、すべての時間差データをキャプチャします。
スライディング ウィンドウは、一定の間隔でデータをキャプチャする場合に便利ですが、本質的に遅延データや順序が正しくないデータは処理されません。遅延データはスライディング ウィンドウの範囲外にある可能性があり、スライディング ウィンドウのみを使用してそのようなデータを処理するのに十分ではない可能性があります。
D. すべてのデータソースの種類 (ストリームまたはバッチ) にタイムスタンプがあることを確認し、タイムスタンプを使用して時間差データのロジックを定義します。
データソースにタイムスタンプを付けることはおすすめの方法ですが、Dataflow パイプライン内で遅延したデータや順序が正しくないデータを処理するという主要な問題には対処できません。タイムスタンプだけでは、イベント時間処理の複雑さを処理し、遅延データが処理ウィンドウで正しく考慮されるようにするには不十分です。
</div></details>

### Q. 質問8: 未回答
Google Cloud でデータ パイプラインを構築しています。機械学習プロセスでは、カジュアルな方法を使用してデータを準備する必要があります。ロジスティック回帰モデルをサポートする場合。また、null 値を監視して調整する必要もありますが、null 値は実数値のままで、削除することはできません。あなたは何をするべきか?
1. 
2. Cloud Dataprep を使用して、サンプルソースデータ内の null 値を見つけます。Cloud Dataprep ジョブを使用して、すべての null を 0 に変換します。
3. 
4. 
<details><div>
    答え：2
説明
ロジスティック回帰モデル用のデータを準備しながら、実数値を維持する必要がある NULL 値を監視および処理するには、次のオプションを検討する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
Cloud Dataprep: Cloud Dataprep は、データを視覚的に探索、クリーニング、変換できるデータ準備サービスです。null 値を 0 などの特定の値に置き換える機能など、null 値を処理するための使いやすいツールを提供します。
Null 値の処理: 機械学習では、特に実数値の特徴を操作する場合、null 値を 0 などの特定の数値に置き換えるのが一般的です。このアプローチにより、データが実数値のままになり、ロジスティック回帰モデルで効果的に使用できます。
正しくないオプション -
A. Cloud Dataprep を使用して、サンプルのソースデータから null 値を見つけます。Cloud Dataprep ジョブを使用して、すべての null を「none」に変換します。
null を 'none' に変換すると、数値以外の値がデータに導入され、ロジスティック回帰には適していません。ロジスティック回帰には数値入力特徴が必要です。
C. Cloud Dataflow を使用して、サンプル ソース データ内の null 値を検索します。Cloud Dataprep ジョブを使用して、すべての null を「none」に変換します。
Cloud Dataflow は強力なデータ処理サービスですが、通常、単純な null 値の置換タスクには使用されません。さらに、null を 'none' に変換することは、ロジスティック回帰モデルには適していない場合があります。
D. Cloud Dataflow を使用して、サンプルのソースデータで null 値を見つけます。カスタムスクリプトを使用してすべてのnullを0に変換します。
Cloud Dataflow はデータの前処理タスクに使用できますが、カスタム スクリプトを使用して null を 0 に置き換えると、不必要に複雑になる可能性があります。Cloud Dataprep は、このようなデータ準備タスクをよりユーザーフレンドリーで効率的に処理する方法を提供します。
</div></details>

### Q. 質問10: 未回答
Google Cloud で動画レコメンデーション アプリケーションを開発しています。アプリケーションは、顧客が以前に視聴したビデオに基づいて、新しいビデオを顧客に表示する必要があります。また、アプリケーションは、顧客が視聴したビデオ内のエンティティ(俳優、監督、ジャンルなど)のラベルを生成する必要があります。アプリケーションの設計では、数テラバイトのデータに対する他の顧客の好みからのデータに基づいて、非常に高速なフィルタリングの提案を提供できる必要があります。このアプリケーションを実装するには、どのような手順を実行する必要がありますか?
1. 
2. 
3. Cloud Video Intelligence API を呼び出してラベルを生成するアプリケーションを構築します。Cloud Bigtable にデータを保存し、予測ラベルをフィルタリングしてユーザーの視聴履歴と一致させ、設定を生成します。
4. 
<details><div>
    答え：3
説明
C. 
Cloud Video Intelligence API: Cloud Video Intelligence API は、動画コンテンツの分析に特化して設計されています。ビデオからラベルやその他の洞察を生成できるため、ビデオコンテンツから情報を抽出するタスクに適しています。
Cloud Bigtable: Cloud Bigtable は、大量のデータを効率的に処理できるスケーラブルな NoSQL データベースです。Cloud Bigtable にデータを保存すると、設定のフィルタリングと生成に必要なデータに高速にアクセスできます。
データのフィルタリング: このオプションでは、パーソナライズされたレコメンデーションを作成するために不可欠な、ユーザーの視聴履歴と一致するように予測ラベルをフィルタリングすることを提案します。Cloud Bigtable はこれを効率的に処理できます。
正しくないオプション -
A. Spark MLlib を使用して複雑な分類モデルを構築してトレーニングし、ラベルを生成し、結果をフィルター処理します。Cloud Dataproc を使用してモデルをデプロイします。アプリケーションからモデルを呼び出します。
Spark MLlib と Cloud Dataproc は機械学習のタスクには強力ですが、このタスクに複雑な分類モデルを使用すると、過剰に設計されたソリューションになる可能性があります。Cloud Video Intelligence API などの特殊な API を使用するよりも、リソースを大量に消費し、時間がかかる場合があります。
B. Spark MLlib を使用して分類モデルを構築してトレーニングし、ラベルを生成します。Spark MLlib を使用して 2 番目の分類モデルを構築してトレーニングし、顧客の好みに合わせて結果をフィルター処理します。Cloud Dataproc を使用してモデルをデプロイします。アプリケーションからモデルを呼び出します。
オプション A と同様に、このアプローチでは複雑な分類モデルを使用するため、ビデオ ラベルとレコメンデーションを生成するタスクには必要ない場合があります。これにより、複雑さが増し、メンテナンスのオーバーヘッドが発生します。
D. Cloud Video Intelligence API を呼び出してラベルを生成するアプリケーションを構築します。Cloud SQL にデータを保存し、予測されたラベルを結合してフィルタリングし、ユーザーの視聴履歴と一致させて設定を生成します。
ラベルの生成には Cloud Video Intelligence API の使用が適していますが、大規模なデータの保存とフィルタリングには Cloud SQL が適していない可能性があります。通常、Cloud Bigtable は大量のデータを効率的に処理するのに適しています。
</div></details>

### Q. 質問13: 未回答
あなたは、Google Cloud のデータ パイプラインに大量のテキスト ファイル用のストレージを作成する任務を負っています。目的は、ANSI SQL クエリを有効にし、圧縮を実装し、Google のベスト プラクティスに準拠しながら、入力場所からの並列読み込みを容易にすることです。これらの目標を達成するには、どのような手順を踏む必要がありますか?
1. 
2. Cloud Dataflow を使用して、テキスト ファイルを圧縮された Avro に変換します。クエリには Cloud Storage と BigQuery の永続的なリンク テーブルを使用します。
3. 
4. 
<details><div>
    答え：2
説明
Google Cloud 上のデータ パイプライン用に非常に大きなテキスト ファイルのストレージを設計し、ANSI SQL クエリをサポートし、Google が推奨するプラクティスに従って入力場所からの圧縮と並列読み込みをサポートするには、次のオプションを検討する必要があります。
B. 
Cloud Dataflow: Cloud Dataflow を使用すると、並列読み込みをサポートしながら、テキスト ファイルを Avro 形式に変換できます。データ変換機能を提供し、大規模なデータセットを効率的に処理できます。
Cloud Storage: 変換されたデータを Cloud Storage に保存することは、効率的なデータ ストレージの一般的な方法です。Cloud Storage は、大量のデータを処理するように設計されており、データの耐久性と可用性を提供します。
BigQuery: データのクエリに BigQuery を使用すると、ANSI SQL を分析に活用できます。Cloud Storage のデータを参照する永続的なリンク テーブルを BigQuery で作成することで、データをクエリするための便利でパフォーマンスの高い方法が提供されます。
正しくないオプション -
A. Cloud Dataflow を使用して、テキスト ファイルを圧縮された Avro に変換します。ストレージとクエリに BigQuery を使用する:
BigQuery は Avro ファイルを保存できますが、Cloud Storage と比較して最も効率的なストレージ形式ではありません。さらに、Cloud Storage を参照する BigQuery でリンク テーブルを使用すると、柔軟性と制御性が向上します。
C. Grid Computing Tools を使用してテキスト ファイルを gzip に圧縮します。ストレージとクエリに BigQuery を使用する:
BigQuery は gzip 圧縮データを処理できますが、このオプションでは、クエリ最適化のためのより構造化された効率的なストレージを提供できる Avro 形式へのテキスト ファイルの変換には対応していません。
D. Grid Computing Tools を使用してテキストファイルを gzip に圧縮します。Cloud Storage を使用し、クエリのために Cloud Bigtable にインポートします。
Cloud Bigtable は、BigQuery のような ANSI SQL クエリの実行ではなく、高スループットで低レイテンシの NoSQL データ向けに設計されています。このオプションは、ANSI SQL クエリをサポートするための要件には適合しておらず、NoSQL ワークロードに適しています。
</div></details>

### Q. 質問15: 未回答
入力データが CSV 形式である Google Cloud 上のデータ パイプライン デプロイ用に 20 TB のテキスト ファイルのストレージを計画する場合、目的は、さまざまなエンジンを介して Cloud Storage のデータにアクセスする複数のユーザーの集計値をクエリするコストを削減することです。この目標を達成するには、どのようなストレージ サービスとスキーマの設計を選択する必要がありますか?
1. 
2. 
3. ストレージには Cloud Storage を使用します。クエリ用に BigQuery の永続的なテーブルとしてリンクします。
4. 
<details><div>
    答え：3
説明
複数のエンジンを使用して Cloud Storage 内のデータをクエリする複数のユーザーの集計値をクエリするコストを最小限に抑えるには、次のオプションを検討する必要があります。
C. 
クラウドストレージ: 20 TB のテキストファイルを Cloud Storage に保存することは、大量のデータを処理するための費用対効果が高く効率的なオプションです。
BigQuery: BigQuery でデータを永続的なテーブルとしてリンクすると、データに対して SQL クエリを効率的に実行できます。BigQuery は分析用に設計されており、複雑なクエリをサポートし、大規模なデータセットを処理できます。
正しくないオプション -
A. ストレージには Cloud Bigtable を使用します。Compute Engine インスタンスに HBase シェルをインストールして、Cloud Bigtable データをクエリします。
Cloud Bigtable は、BigQuery のような ANSI SQL クエリの実行ではなく、高スループットの NoSQL ワークロード向けに設計されています。HBase をインストールして Compute Engine インスタンスを使用すると、複雑さが増し、ユースケースの費用対効果が高くない可能性があります。
B. ストレージに Cloud Bigtable を使用する。クエリ用に BigQuery の永続的なテーブルとしてリンクする:
BigQuery で Cloud Bigtable データをリンクすることは可能ですが、通常は NoSQL ストレージに特定の要件があり、BigQuery のデータに対して SQL のようなクエリを実行する必要がある場合に使用されます。ただし、CSV テキストデータを処理するには、Cloud Storage の方が費用対効果が高く、わかりやすいオプションです。
D. ストレージには Cloud Storage を使用します。クエリ用に BigQuery の一時テーブルとしてリンクする:
BigQuery でデータを一時テーブルとしてリンクすることは、一時データや永続化する必要のないデータのためのオプションです。20 TB のデータがあるため、効率的なクエリには永続的なテーブルを使用する方が適切です。
</div></details>

### Q. 質問17: 未回答
金融サービス組織は、クラウドテクノロジーに移行し、50TBの金融時系列データをクラウド環境に保存することを目指しています。このデータは頻繁に更新され、新しい情報が継続的にストリーミングされます。同時に、同社は現在のApache Hadoopジョブをクラウドに移行し、このデータから洞察を引き出す予定です。このデータを効果的に保存し、目的のクラウドベースの運用をサポートするには、どの特定の製品を採用する必要がありますか?
1. Cloud Bigtable
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
Cloud Bigtable が正しい選択と見なされる理由は次のとおりです。
スケーラビリティ: Cloud Bigtable は、高スループットで水平方向にスケーラブルなワークロード向けに設計された NoSQL データベースです。大量のデータを処理でき、頻繁な更新やデータのストリーミングを行うシナリオに適しています。
低レイテンシー: 特にリアルタイムの洞察が必要な場合に、金融時系列データに不可欠なデータへの低レイテンシーアクセスを提供します。
Apache Hadoop の統合: Cloud Bigtable は HBase API を介して Apache Hadoop と統合されているため、既存の Apache Hadoop ジョブをクラウドに移行して、大幅な変更を行うことなく Bigtable に保存されているデータを分析できます。
正しくないオプション -
B. Google BigQuery:
BigQuery は、大規模なデータセットに対して SQL のようなクエリを実行するのに最適ですが、主要なストレージ ソリューションではありません。これは、生の時系列データを格納するよりも、分析ワークロードに適しています。BigQuery にデータを読み込んで分析することはできますが、特にリアルタイムの更新と低レイテンシのアクセスが不可欠な場合は、50 TB の金融時系列データのプライマリ ストレージには最適ではない可能性があります。
C. Google Cloud Storage:
Cloud Storage はオブジェクト ストレージ サービスであり、Cloud Bigtable のようなデータベース システムと同じリアルタイムのデータ アクセス機能やクエリ機能を提供しない場合があります。Cloud Storage にデータを保存することもできますが、通常は耐久性のあるストレージ レイヤとして使用され、追加の処理を行わないとトランザクションや分析のワークロードには適さない場合があります。
D. Google Cloud データストア:
Cloud Datastore は、特定のユースケースに適した NoSQL データベースですが、大量の財務時系列データを処理し、Apache Hadoop ジョブをサポートするには、Cloud Bigtable と同じレベルのパフォーマンスとスケーラビリティを備えていない可能性があります。
</div></details>

### Q. 質問18: 未回答
組織は、ユーザーレベルのデータを含むテーブルを含む Google BigQuery データセットを維持しています。このデータの集計を他の Google Cloud プロジェクトに公開しながら、ユーザーレベルのデータへのアクセスを制御したいと考えています。さらに、全体的なストレージ コストを最小限に抑え、他のプロジェクトの分析コストがそれらのプロジェクトに割り当てられるようにする必要があります。彼らは何をすべきか?
1. 
2. 集計結果を提供する新しいデータセットとビューを作成して共有します。
3. 
4. 
<details><div>
    答え：2
説明
ユーザーレベルのデータへのアクセスを制御し、ストレージ コストを最小限に抑え、他のプロジェクトの分析コストがそれらのプロジェクトに割り当てられるようにしながら、Google BigQuery データセットのユーザーレベルのデータの集計を他の Google Cloud プロジェクトに公開するには、組織は次のオプションを検討する必要があります。
B. 
新しいデータセット: 集計結果専用の新しいデータセットを作成することで、集計データをユーザーレベルのデータから分離し、アクセス制御と権限を分離することができます。これは、生のユーザーレベルデータへのアクセスを制御するのに役立ちます。
ビュー: 新しいデータセット内にビューを作成すると、ユーザーレベルのデータから必要な集計を生成するSQLクエリを定義できます。ビューは仮想テーブルとして機能し、データのフィルター処理および集計されたパースペクティブを提供します。
共有: その後、新しいデータセットとそれに関連するビューを他の Google Cloud プロジェクトと共有して、元のデータセット内のユーザーレベルのデータを安全に保ちながら、それらのプロジェクトが集計データにアクセスできるようにすることができます。
コスト管理: データセットとビューを分離することで、コストをより適切に管理および割り当てることができます。新しいデータセットとビューのクエリを実行するときに他のプロジェクトによって発生する分析コストは、それらのプロジェクトに関連付けられ、組織の全体的なコストが最小限に抑えられます。
正しくないオプション -
オプション A の、集計結果を提供する許可済みビューを作成して共有することも有効なアプローチです。ただし、新しいデータセットとビューを作成すると、集計されたデータがユーザーレベルのデータからより適切に分離され、長期的にはよりクリーンでスケーラブルなソリューションになる可能性があります。
オプション C では、集計結果を含む新しいデータセットとテーブルを作成して共有できますが、特にストレージ コストが懸念される場合は、集計を個別のテーブルに具体化するよりも、集計のビューを作成する方が一般的に効率的です。
オプション D は、データセットに dataViewer Identity and Access Management (IAM) ロールを作成して共有を有効にすることですが、それだけでは十分ではありません。それでも、ユーザーレベルのデータへのアクセスを制御しながら、特定の集計結果を提供するために、新しいデータセットまたはビューを作成する必要があります。
</div></details>

### Q. 質問20: 未回答
ニューラルネットワークモデルのトレーニングに数日かかっています。トレーニング速度を上げたい。その他のオプション
1. 
2. トレーニングデータセットをサブサンプリングします。
3. 
4. 
<details><div>
    答え：2
説明
B. 
説明: トレーニングデータセットのサブサンプリングでは、ニューラルネットワークのトレーニングに、より小さく代表的なデータのサブセットを使用します。このアプローチが効果的な理由はいくつかあります。
計算の高速化: トレーニング データセットが小さいほど、各トレーニング イテレーションで必要な計算とメモリが少なくなり、トレーニング時間が短縮されます。
ノイズの低減: サブサンプリングは、トレーニング データのノイズと分散を減らすのに役立ち、収束の高速化と汎化の向上につながる可能性があります。
仮説の検証: 機械学習では、多くの場合、さまざまなモデル アーキテクチャとハイパーパラメーターを試す必要があります。最初の実験に小さなデータセットを使用すると、モデルの可能性を検証しながら時間を節約できます。
正しくないオプション -
A. テストデータセットをサブサンプリングします。
説明: テスト データセットのサブサンプリングは、トレーニング速度を上げるための一般的な方法ではありません。テスト データセットは、トレーニング後のモデルのパフォーマンスを評価するために使用されます。テストデータセットのサイズを変更すると、評価結果に影響を与える可能性があり、トレーニングプロセスは高速化されません。モデルの汎化パフォーマンスを正確に評価するには、代表的なテスト データセットを維持することが不可欠です。
C. モデルへの入力特徴の数を増やします。
説明: 通常、入力特徴の数を増やすと、モデルが複雑になり、その結果、トレーニング時間が長くなります。機能を追加すると、モデルの次元が増加する可能性があり、トレーニングにより多くの計算リソースと時間が必要になる場合があります。このオプションは、トレーニングを高速化するよりも遅くする可能性が高くなります。
D. ニューラルネットワークの層数を増やします。
説明: ニューラルネットワークに層を追加すると、ニューラルネットワークが深くなり、複雑になる可能性があります。ディープ ネットワークはデータの複雑なパターンをキャプチャできますが、特に多くのパラメーターが含まれている場合は、トレーニングに時間がかかることがよくあります。レイヤー数を増やすことは、トレーニングを高速化するための推奨される戦略ではありません。これにより、トレーニング時間が長くなり、追加の計算リソースが必要になる場合があります。
</div></details>

### Q. 質問22: 未回答
会社では、GCP とのハイブリッド デプロイを維持しており、匿名化された顧客データに対して分析が実行されます。データは、GCP で実行されているデータ転送サーバーへの並列アップロードを通じて、データセンターから Cloud Storage にインポートされます。経営陣は、毎日の転送に時間がかかりすぎることを通知し、問題を解決するように求めました。転送速度を最大にしたい。どのアクションを実行する必要がありますか?
1. 
2. 
3. データセンターから GCP へのネットワーク帯域幅を増やします。
4. 
<details><div>
    答え：3
説明
データセンターから Google Cloud Storage への毎日のアップロードの転送速度を最大化するには、次の点を考慮する必要があります。
C. 
ネットワーク帯域幅: データセンターと Google Cloud 間のデータ転送速度は、利用可能なネットワーク帯域幅に大きく依存します。データセンターから GCP へのネットワーク帯域幅を増やすことで、Cloud Storage へのデータのアップロード速度を向上させることができます。
ボトルネック:多くの場合、データ転送が遅いのは、クラウドインフラストラクチャ内ではなく、データセンター側の帯域幅の制限が原因です。データセンターの帯域幅を増やすことで、このボトルネックを軽減できます。
正しくないオプション -
オプション A と B(CPU サイズまたはサーバー上の Google Persistent Disk のサイズを増やす)は、主にサーバーの処理能力とストレージ能力に影響します。これらのアップグレードは、サーバーがボトルネックになっている場合は役立つ可能性がありますが、ネットワーク帯域幅が主な制限要因である場合、データ転送速度を大幅に向上させることはできません。
オプション D(Compute Engine から Cloud Storage へのネットワーク帯域幅の増加)は、Google Cloud インフラストラクチャ自体でボトルネックが発生した場合に役立ちます。ただし、この質問はデータセンターからの毎日のアップロードを改善することに焦点を当てているため、最も効果的なアクションは、データセンターからGCPへのネットワーク帯域幅に対処することです(オプションC)。
</div></details>

### Q. 質問24: 未回答
あなたは、それぞれ異なる優先順位と予算を持つ複数の事業部門を持つ大企業のBI責任者です。オンデマンドを使用する BigQuery の料金(プロジェクトあたり 2K の同時オンデマンド スロットの割り当てあり)。組織のユーザーは、クエリを実行するためのスロットを取得しない場合があり、これを修正する必要があります。アカウントに新しいプロジェクトを導入しないようにしたい。あなたは何をするべきか?
1. 
2. 
3. 定額価格に切り替え、プロジェクトの階層的な優先順位モデルを確立します。
4. 
<details><div>
    答え：3
説明
プロジェクトごとに 2K のオンデマンド同時スロットの割り当てがあり、新しいプロジェクトの導入を避けたい場合に、ユーザーが BigQuery でクエリを実行するスロットを取得できないという問題に対処するには、次の点を考慮する必要があります。
C. 
定額料金: BigQuery で定額料金に切り替えると、割り当て制限のあるオンデマンド スロットに頼るのではなく、組織専用の固定数のスロットを購入できます。これにより、より予測可能で一貫性のあるクエリパフォーマンスが実現します。
階層型優先度モデル: 定額価格設定では、プロジェクトの階層型優先度モデルを確立できます。組織内の各部署またはプロジェクトに、優先順位と予算に基づいて特定の数のスロットを割り当てることができます。これにより、重要な事業部門は、リソース割り当ての制御を維持しながら、必要なリソースを確実に取得できます。
正しくないオプション -
オプション A (バッチ クエリを対話型クエリに変換する) は、クエリの実行を最適化することである程度役立つ場合がありますが、根本的なリソース割り当ての問題には対処しません。
オプション B (追加のプロジェクトの作成) は複雑さを増すため、既存のプロジェクト内でリソース割り当てを効果的に管理できる場合、最も効率的なソリューションではない可能性があります。
オプション D([割り当て] ページでプロジェクトごとの同時スロット数を増やす)は、Google Cloud の割り当てポリシーの対象となるため実現できない可能性があり、定額料金と階層的な優先度モデルが提供するレベルのリソース管理と制御が提供されない可能性があります。
</div></details>

### Q. 質問26: 未回答
Hadoop ジョブをオンプレミス クラスタから dataproc と GCS に移行しました。Spark ジョブは、多くのシャッフル操作で構成される複雑な分析ワークロードであり、初期データは Parquet ファイル (それぞれ平均 200 から 400 MB のサイズ) です。Dataproc への移行後にパフォーマンスが低下したため、最適化する必要があります。組織はコストに敏感な組織であるため、このワークロードではプリエンプティブル(2 つの非プリエンプティブル ワーカーのみ)で Dataproc を引き続き使用する必要があります。あなたは何をするべきか?
1. Parquetファイルのサイズを大きくして、最小1GBになるようにする
2. 
3. 
4. HDD から SSD に切り替え、プリエンプティブル VM 構成をオーバーライドして、ブート ディスク サイズを増やします。
<details><div>
    答え：1
説明
既存にプロセスをコスト増に繋がらない形でチューニングする必要があります。
従って、プロセスで使用しているコンピューティングリソース自体の最適化は避けるべきです。
Parquet は効率的なカラム型ファイル形式であり、Spark でアプリケーションの実行に必要なデータのみを読み取ることができます。
SparkジョブでParquetファイルを使用する場合、ファイルサイズの目安は1GBと言われています。
今回のケースでは、Parquetサイズが200~400MBと小さいため、この点は改善の余地がある点になります。
したがって、正解は「Parquetファイルのサイズを大きくして、最小1GBになるようにする」です。
参照：
https://cloud.google.com/dataproc/docs/support/spark-job-tuning
https://cloud.google.com/architecture/hadoop/hadoop-gcp-migration-jobs
https://community.databricks.com/s/question/0D53f00001HKHWDCA5/what-is-an-optimal-size-for-file-partitions-using-parquet

誤り説明
D. 
SSD への切り替え: HDD を SSD に交換すると、I/O パフォーマンスが大幅に向上します。SSD は HDD と比較して読み取りと書き込みの速度が速いため、シャッフル操作やデータ集約型のワークロードを伴う Spark ジョブに役立ちます。
ブート ディスク サイズの増加: プリエンプティブル VM のブート ディスク サイズを増やすことで、オペレーティング システムと Spark によって生成される一時データの両方により多くのストレージ容量を提供します。これにより、潜在的なストレージのボトルネックを回避し、Sparkジョブに十分な一時ストレージを確保できます。
正しくないオプション -
A. Parquet ファイルのサイズを増やして、最小 1 GB になるようにします。
Parquet ファイルのサイズを大きくしても、HDD の使用によって引き起こされる I/O パフォーマンスの問題に直接対処できない場合があります。 ファイル サイズが大きくなると、HDD の読み取り/書き込み速度の低下に関連するパフォーマンスの低下を完全に軽減できない場合があります。
B. Parquet ファイルではなく、TFRecords 形式 (ファイルあたり約 200 MB) に切り替えます。
ファイル形式を変更すると、ストレージのオーバーヘッドを削減できる場合がありますが、基になる HDD 関連の I/O パフォーマンスの問題に直接対処するわけではありません。
C. HDD から SSD に切り替え、GCS から HDFS に初期データをコピーし、Spark ジョブを実行して、結果を GCS にコピーします。
SSDに切り替えてHDFSを使用すると、ストレージとデータの局所性に役立ちますが、コスト削減のために引き続き使用したいとおっしゃった既存のプリエンプティブルVMは活用されません。
</div></details>

### Q. 質問27: 未回答
社内で ETL の開発とメンテナンスを担当するチームとして、入力データのエラーが原因で Dataflow ジョブの 1 つが失敗する状況に遭遇しました。失敗したすべてのデータを再処理する機能など、パイプラインの信頼性を高めるには、どのような手順を実行する必要がありますか?
1. 
2. 
3. 
4. try...catch ブロックをデータを変換する DoFn に追加し、sideOutput を使用して、後で Pub/Sub に保存できる PCollection を作成します。
<details><div>
    答え：4
説明
Dataflow パイプラインの信頼性(失敗したすべてのデータを再処理する機能など)を向上させるには、次の点を考慮する必要があります。
D. 
try...catch ブロック:トライを追加しています...DoFn 内の catch ブロックを使用すると、データ変換中のエラーを適切に処理できます。エラーが発生した場合は、それをキャッチして特定のアクションを実行できます。
サイド出力: Dataflow で sideOutput を使用すると、別の PCollection を作成して、エラーのあるデータ レコードをキャプチャできます。エラーが発生した場合は、問題のあるレコードをこちら側の出力に出力して、メインのデータ処理フローを中断しないようにすることができます。
Pub/Sub への保存: エラーのあるレコードを PCollection に保存し、後で Pub/Sub に送信できるようにすることで、データを再処理することができます。Pub/Sub は、再処理や詳細な分析が必要なデータの信頼性の高いメッセージ ブローカーとして機能します。
正しくないオプション -
オプション A (エラーをスキップするフィルター処理ステップの追加) は、エラーによるパイプラインの中断を防ぐ可能性がありますが、信頼性とトラブルシューティングに不可欠な潜在的な再処理のためにエラーのあるデータをキャプチャして保存することはありません。
オプション B (try...catch ブロックを side 出力なしで使用) を使用すると、エラーを処理できますが、エラーのあるデータを格納して再処理するメカニズムは提供されません。データが失われる可能性があります。
オプション C(DoFn から Pub/Sub に誤った行を直接書き込む)は機能しますが、DoFn ロジックが複雑になる可能性があり、サイド出力を使用するほど単純ではない可能性があります。
</div></details>

### Q. 質問29: 未回答
MariaDB SQL データベースを GCE VM インスタンスにデプロイ中であり、監視とアラートの設定が必要です。目標は、最小限の開発作業でネットワーク接続、ディスク IO、レプリケーション ステータスなどの指標を MariaDB から収集し、StackDriver を利用してダッシュボードとアラートを作成することです。この構成をどのように実現できますか?
1. 
2. 
3. 
4. Ops Agent をインストールし、MySQL プラグインを設定します。
<details><div>
    答え：4
説明
最小限の開発労力で MariaDB から指標を収集し、ダッシュボードとアラートに StackDriver を使用するには、次の点を考慮する必要があります。
D. 
StackDriver エージェント: StackDriver Agent は、最小限の労力で VM インスタンスからシステムとアプリケーションの指標を収集するように設計されています。これにより、指標を収集して StackDriver にエクスポートするプロセスが簡素化されます。
MySQLプラグイン:StackDriver Agentには、MariaDBなどのMySQL互換データベースからデータベース関連の指標を収集するために特別に設計されたMySQLプラグインが含まれています。このプラグインは、ネットワーク接続、ディスク I/O、レプリケーション ステータスなどの重要なメトリックをキャプチャできます。
正しくないオプション -
オプション A(OpenCensus Agent をインストールし、カスタム指標収集アプリケーションを作成する)では、MariaDB 指標を収集して StackDriver にエクスポートするために、より多くの開発作業とカスタム コーディングが必要になります。これは、StackDriver エージェントが提供する組み込みの MySQL プラグインを使用する場合と比較して、より複雑なソリューションです。
オプション B(ヘルスチェックを使用して MariaDB インスタンスをインスタンス グループに配置する)は、主にインスタンスの可用性に対応しますが、データベース固有の指標を直接収集して StackDriver にエクスポートすることはありません。
オプション C(StackDriver Logging Agent をインストールし、MariaDB ログを読み取るための fluentd in_tail プラグインの構成)は、ログの収集に重点を置いており、データベースから詳細なパフォーマンスと正常性の指標を収集するのには適していません。
参照：
https://cloud.google.com/monitoring/custom-metrics/open-census
</div></details>

### Q. 質問31: 未回答
2 TB のリレーショナル データベースを Google Cloud Platform に移行するという課題があり、アプリケーションのリファクタリングに制限があり、費用対効果に重点が置かれています。このシナリオでは、データの保存と提供にどの Google Cloud サービスを選択すればよいですか?
1. 
2. 
3. 
4. Cloud SQL
<details><div>
    答え：4
説明
2 TB のリレーショナル データベースを Google Cloud Platform に移行する要件を考えると、コストを主な懸念事項とし、アプリケーションの大幅なリファクタリングを行わずに、次のオプションを検討する必要があります。
D. クラウド SQL
リレーショナル データベースの互換性: Cloud SQL は、MySQL、PostgreSQL、SQL Server などの一般的なデータベース エンジンと互換性のあるマネージド リレーショナル データベース サービスを提供します。既存のデータベースがリレーショナルの場合、Cloud SQL はアプリケーション コードへの変更を最小限に抑えた簡単な移行パスを提供します。
費用対効果: Cloud SQL にはさまざまな料金階層と柔軟なスケーリング オプションが用意されているため、ワークロードと予算に適した構成を選択できます。ニーズに合わせて適切なマシンタイプとストレージ容量を選択できるため、コストを管理できます。
正しくないオプション -
オプション A、B、および C は、2 TB のリレーショナル データベースの単純な移行には適していない場合があります。
A. Cloud Spanner: Cloud Spanner は拡張性が高く、グローバルに分散されたデータベース サービスですが、トランザクション ワークロードの高可用性とスケーラビリティを実現するように設計されています。2TBのリレーショナルデータベースは、通常、ミッションクリティカルなグローバルに分散されたアプリケーションに使用されるため、コストが主な懸念事項である場合、やり過ぎになる可能性があります。
B. Cloud Bigtable: Cloud Bigtable は、通常、分析データや時系列データに使用される大規模な NoSQL データを保存および提供するために設計されています。これはリレーショナルデータベースではないため、従来の2TBリレーショナルデータベースの移行には適していない可能性があります。
C. Cloud Firestore: Cloud Firestore は、主にモバイルおよびウェブ アプリケーション向けに設計された NoSQL ドキュメント データベースです。通常、従来のリレーショナル データベースの移行には使用されず、大幅なアプリケーション リファクタリングが必要になる場合があります。
</div></details>

### Q. 質問32: 未回答
リアルタイム アプリケーションに Bigtable を使用しており、読み取りと書き込みが混在する負荷が高い。最近、追加のユース ケースを特定し、データベース全体の特定の統計を計算するために分析ジョブを時間単位で実行する必要があります。本番アプリケーションの信頼性と分析ワークロードの両方を確保する必要があります。あなたは何をするべきか?
1. 
2. 
3. 単一クラスタ ルーティングで 2 番目のクラスタを追加する
4. 
<details><div>
    答え：3
説明
オプション C: 
このオプションでは、分析ワークロードを処理するために、Bigtable インスタンスに別のクラスタを追加します。この分離により、運用アプリケーションのリアルタイム トラフィックと分析ジョブが異なるクラスターで実行されることが保証され、分離レベルが提供されます。
単一クラスター ルーティングを使用すると、アプリ プロファイル (運用環境の場合はライブ トラフィック、分析の場合はバッチ分析) に基づいて、どのクラスターがどのタイプのトラフィックを処理するかを指定できます。このアプローチにより、トラフィック ルーティングを効果的に管理できます。
主な利点は、ワークロードを同じインスタンス内に保持しながら、ワークロードをある程度分離できるため、費用対効果と運用効率が高いことです。
正しくないオプション -
オプション A(Bigtable ダンプを GCS にエクスポート):Bigtable データを Google Cloud Storage(GCS)にエクスポートし、エクスポートしたファイルに対して分析を実行するのはバッチ指向のアプローチであり、リアルタイム分析や本番アプリケーションとのシームレスな統合はできません。また、分析プロセスの複雑さと遅延も増します。
オプション B(マルチクラスタ ルーティング):マルチクラスター ルーティングはワークロードの分離に適していますが、このオプションでは、運用環境にライブ トラフィック アプリ プロファイルを使用し、分析にバッチ分析プロファイルを使用することをお勧めします。ただし、ライブ トラフィック プロファイルはリアルタイム トラフィック用に設計されており、分析に使用すると、運用アプリケーションの信頼性に影響を与える可能性があります。
オプション D (既存のクラスターのサイズを 2 回増やす):既存のクラスターのサイズを増やすと、スケーリングに役立つ場合がありますが、リアルタイムのワークロードと分析のワークロードを明確に分離することはできません。このオプションは、リソースの競合につながる可能性があり、信頼性の問題に効果的に対処できない可能性があります。
</div></details>

### Q. 質問34: 未回答
適切に設計された行キーを使用して Cloud Bigtable にデータを書き込むデータ パイプラインがあります。パイプラインをモニタリングして、Cloud Bigtable クラスタのサイズをいつ増やすかを判断します。これを達成するために、どのような 2 つのアクションを実行できますか?(2つ選択してください。
1. 
2. 
3. 書き込み操作の待機時間を監視します。書き込みレイテンシが持続的に増加する場合は、Cloud Bigtable クラスタのサイズを増やします。
4. ストレージ使用率を監視します。使用率が最大容量の 70% を超えたら、Cloud Bigtable クラスタのサイズを増やします。
5. 
<details><div>
    答え：3,4
説明
C. 
このオプションは確かに正しいです。書き込み操作のレイテンシは、書き込みワークロードを処理する際の Cloud Bigtable クラスタのパフォーマンスを直接反映するため、非常に重要です。書き込みレイテンシーは、時間の経過に伴う書き込みレイテンシーの増加は、クラスターが受信書き込みの効率的な処理に苦労している可能性があることを示唆しているため、監視すべき重要なメトリックです。書き込みレイテンシが持続的に増加している場合は、増大する書き込み負荷をより効果的に処理するために Cloud Bigtable クラスタをスケールアップする必要があることを示しています。
D. 
このオプションも正しいです。ストレージ使用率のモニタリングは、Cloud Bigtable インスタンスを効果的に管理するために不可欠です。ストレージ使用率が最大容量の 70% に近づくか、それを超えると、インスタンスの領域が不足していることを示します。通常はノードを追加して Cloud Bigtable クラスタのサイズを増やすと、データ量の増加に対応し、ストレージの制限によるパフォーマンスの低下を防ぐことができます。
正しくないオプション -
A. キー ビジュアライザーのメトリックを確認します。Cloud Bigtable クラスタのサイズを増やすには、読み取りプレッシャー インデックスが 100 を超えます。
Key Visualizer の読み取り圧力インデックスは、書き込みワークロードではなく、読み取りワークロードに関連しています。読み取りプレッシャーの監視は、読み取りパフォーマンスを最適化するために不可欠ですが、書き込み負荷の高いワークロードのクラスター サイズをいつ増やすかを決定することには直接関係ありません。
B. キービジュアライザーの指標を確認します。Cloud Bigtable クラスタのサイズを増やすには、書き込みプレッシャー インデックスが 100 を超えます。
書き込みプレッシャー インデックスは書き込みワークロードに関連していますが、クラスター サイズの調整を決定するために使用される一般的なメトリックではありません。書き込みレイテンシーとストレージ使用率は、書き込みワークロードに応じてスケーリングを決定するための、より一般的で実用的なメトリックです。
E. 読み取り操作の待機時間を監視します。読み取り操作に 100 ミリ秒以上かかる場合は、Cloud Bigtable クラスタのサイズを増やします。
読み取り待機時間の監視は、応答性の高いクエリのパフォーマンスを確保するために不可欠ですが、書き込みワークロードの問題や、書き込み要求に応じてクラスター サイズを増やすタイミングに関する直接的な分析情報は提供されません。
</div></details>

### Q. 質問36: 未回答
履歴データは Cloud Storage に保存します。履歴データに対して分析を実行する必要があります。ソリューションを使用して無効なデータエントリを検出し、プログラミングや SQL の知識を必要としないデータ変換を実行したい。あなたは何をするべきか?
1. 
2. Cloud Dataprep とレシピを使用して、エラーを検出し、変換を実行します。
3. 
4. 
<details><div>
    答え：2
説明
プログラミングや SQL の知識を必要とせずに、Cloud Storage に保存された履歴データに対してエラーを検出し、データ変換を実行するには、次のオプションが最適です。
B. 
このオプションが最良の選択である理由は次のとおりです。
ユーザーフレンドリーなインターフェース:Cloud Dataprep は、データの準備と変換のためのユーザーフレンドリーで視覚的なインターフェースを提供します。データクリーニングと変換のレシピは、コードやSQL問合せを記述せずに作成できます。これにより、さまざまなレベルの技術的専門知識を持つユーザーがアクセスできるようになります。
データ品質チェック:Cloud Dataprep には、欠損値、外れ値、データ形式のエラーなどのデータ品質の問題を検出する機能が含まれています。ルールと変換を視覚的に定義して、データをクリーンアップおよび修正できます。
拡張性:Cloud Dataprep は大規模なデータセットを処理できるため、Cloud Storage に保存されている履歴データの分析に適しています。
統合：Cloud Dataprep は他の Google Cloud サービスとシームレスに統合されるため、Cloud Storage からデータを取り込み、変換を実行してから、クリーニングしたデータを BigQuery やその他の分析ツールに読み込むことができます。
正しくないオプション -
オプション A(Cloud Dataflow と Beam)とオプション C(Cloud Dataproc と Hadoop ジョブ)は、よりプログラム的なソリューションであり、コーディングとデータ処理フレームワークの知識が必要です。
オプション D(クエリを使用した BigQuery のフェデレーション テーブル)では、SQL クエリを記述する必要があるため、特に SQL コードやプログラミング コードを記述したくない場合は、データのクリーニングと変換のタスクを Cloud Dataprep ほど簡単に行えない可能性があります。
</div></details>

### Q. 質問37: 未回答
会社は、履歴データを Cloud Storage に安全にアップロードする必要があります。セキュリティ・ルールでは、内部IPアドレスからオンプレミス・リソースへのアクセスのみが許可されます。最初のアップロード後、既存のオンプレミス アプリケーションから新しいデータが毎日追加されます。これを達成するための最良の方法は何ですか?
1. オンプレミス サーバーから gsutil rsync を実行します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
このオプションでは、gsutil rsync コマンドを使用して、オンプレミス サーバーから Cloud Storage にデータを同期します。これは、最初のアップロードとその後の毎日の更新の両方で機能しますが、Dataflow と同じレベルのデータ変換と処理機能を提供しない場合があります。ただし、これはデータ転送の簡単な方法であり、適切なアクセス制御と認証が実施されていれば安全です。
正しくないオプション -
オプション B: Dataflow を使用して Cloud Storage にデータを書き込む。
Dataflow は堅牢なデータ処理および変換ツールであり、特に重要なデータ変換が不要な場合は、単純なデータ転送タスク用に過剰に設計されたソリューションになる可能性があります。これは、データ転送プロセスの一部として複雑なデータ変換を実行する必要がある場合に適しています。
オプション C: Dataproc でジョブ テンプレートを作成して、データ転送を実行します。
Dataproc は、分散データ処理ジョブ(通常はバッチ処理やリアルタイム データ分析)を実行するために設計されています。単純なデータ転送タスクに Dataproc を使用すると、不必要に複雑になる可能性があります。
オプション D: Compute Engine VM に FTP サーバーをインストールしてファイルを受信し、Cloud Storage に移動します。
このオプションでは、Compute Engine VM での FTP サーバーのセットアップとメンテナンスを行います。データ転送には機能しますが、VM の管理とセキュリティ構成に関して追加のオーバーヘッドが発生します。
オプションAとオプションBのどちらを選択するかは、特定の要件によって異なります。オプション A(gsutil rsync)は、よりシンプルでわかりやすいデータ転送方法であり、オプション B(データフロー)は、データの変換と処理の柔軟性を高めます。ユースケースで基本的なデータ転送のみが必要で、セキュリティが懸念される場合は、オプションAの方が簡単な選択肢になる可能性があります。ただし、今後、より複雑なデータ処理が必要になることが予想される場合や、転送中にデータ変換を実行する必要がある場合は、オプション B (データフロー) の方が適している可能性があります。
</div></details>

### Q. 質問38: 未回答
タイムスタンプ列と ID 列の WHERE 句を使用して BigQuery テーブルをフィルタリングするクエリがあります。bq query '"-dry_run を使用すると、タイムスタンプと ID のフィルターによってデータ全体のごく一部が選択されている場合でも、クエリによってテーブルのフル スキャンがトリガーされることがわかります。既存の SQL クエリへの変更を最小限に抑えて、BigQuery でスキャンされるデータの量を減らしたい。あなたは何をするべきか?
1. 
2. 
3. パーティション列とクラスタリング列を含むテーブルを再作成します。
4. 
<details><div>
    答え：3
説明
既存の SQL クエリへの変更を最小限に抑えて BigQuery でスキャンされるデータの量を減らすには、オプション C を検討する必要があります。
C. 
このオプションが適切な選択である理由は次のとおりです。
パーティション 分割：タイムスタンプ列に基づいてテーブルをパーティション分割することで(日付またはタイムスタンプ タイプの場合)、BigQuery は関連データを含まないパーティションのスキャンをスキップできます。これにより、タイムスタンプに基づいてクエリを実行するときにスキャンされるデータの量が削減されます。
クラスタ リング：クラスタリングカラムは、クエリのパフォーマンスをさらに向上させることができます。ID 列に基づいてテーブルをクラスタリングすることで、同じ ID 値を持つデータがディスクにまとめて格納され、ID でフィルタリングするときにスキャンされるデータの量が削減されます。
最小限のクエリ変更:このオプションでは、既存の SQL クエリに対する変更が最小限で済みます。同じ SQL クエリを引き続き使用でき、BigQuery の最適化が有効になり、スキャンされるデータの量が削減されます。
正しくないオプション -
オプション A (ID ごとに個別のテーブルを作成する) では、データ構造とクエリが大幅に変更され、多くの ID 値を処理するときに管理上の課題が発生する可能性があります。
オプション B (LIMIT キーワードを使用) では、返される行数を制限できますが、スキャンされるデータの量が必ずしも減るわけではなく、コストの最適化に不可欠です。
オプション D (--maximum_bytes_billed フラグを使用) は、データ・スキャンの最適化というよりは、照会コストの制御に関するものです。不要なデータのスキャンの問題には対処していません。
</div></details>

### Q. 質問39: 未回答
50,000 個のセンサーから BigQuery テーブルに分単位のデータを挿入する必要があります。データ量の大幅な増加が予想され、集計された傾向をリアルタイムで分析するために、取り込みから 1 分以内にデータを利用できるようにする必要があります。どのような手順を踏む必要がありますか?
1. 
2. Cloud Dataflow パイプラインを使用して、BigQuery テーブルにデータをストリーミングします。
3. 
4. 
<details><div>
    答え：2
説明
50,000 個のセンサーから分単位のデータを BigQuery テーブルに挿入し、リアルタイムで分析できるようにするという要件を満たすには、オプション B を選択する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
リアルタイムのデータ取り込み:Cloud Dataflow を使用すると、リアルタイムのデータ パイプラインを構築できます。Dataflow を使用して BigQuery にデータをストリーミングすると、取り込みから数秒以内にデータを分析できるようになり、リアルタイム分析の要件を満たすことができます。
拡張性:Dataflow は、多数のセンサー(この場合は 50,000 個)からのデータの取り込みを処理でき、データ量の増加に合わせてスケーリングできます。
BigQuery との統合:Dataflow は BigQuery とシームレスに統合されているため、BigQuery テーブルにデータを簡単にストリーミングできます。
分単位のデータを挿入する:これは、データを1分に1回の頻度で記録する必要があることを意味します。
50,000個のセンサー:これは、データを生成するセンサーが多数あることを意味します。
BigQuery テーブル:これは、データの保存と分析に使用される BigQuery のデータ構造です。
データ量の大幅な増加:これは、生成されるデータの量が急速に増加すると予想されることを意味します。
1分間の摂取:つまり、データは生成後 1 分以内に BigQuery で利用できるようになる必要があります。
集計された傾向のリアルタイム分析:つまり、傾向を特定するためにデータをリアルタイムで分析する必要があります。
正しくないオプション -
オプション A (bq load を使用して 60 秒ごとにバッチを読み込む) は、バッチ処理に適しており、必要なリアルタイム機能は提供されません。
オプション C (INSERT ステートメントを使用して 60 秒ごとにバッチを挿入する) では、手動のスクリプト作成とスケジュール設定が必要であり、リアルタイム要件を効果的に満たさない可能性があります。
オプション D (MERGE ステートメントを使用して 60 秒ごとにバッチで更新を適用する) は、主に既存のデータを更新するためのものであり、リアルタイムのデータ インジェスト要件には対応していません。
</div></details>

### Q. 質問41: 未回答
ここでは、BigQuery データ ウェアハウスのメイン インベントリ テーブルを読み取る、ほぼリアルタイムのインベントリ ダッシュボードを作成します。履歴在庫データは、品目および場所ごとの在庫残高として保存されます。毎時間、数千件のインベントリーの更新があります。ダッシュボードのパフォーマンスを可能な限り向上させ、データが正確であることを確認する必要があります。どのような手順を踏む必要がありますか?
1. 
2. 
3. BigQuery ストリーミングを使用して、日次在庫移動テーブルに変更をストリーミングします。履歴在庫残高テーブルに結合するビューで残高を計算します。在庫残高表を毎晩更新します。
4. 
<details><div>
    答え：3
説明
C. 
オプション C が推奨される理由は次のとおりです。
ほぼリアルタイムのデータ:BigQuery ストリーミングを使用すると、在庫の変更が発生したときにキャプチャできるため、在庫移動表をほぼリアルタイムで最新の状態に保つことができます。これは、インベントリ ダッシュボードにとって非常に重要です。
パフォーマンス：履歴在庫残高テーブルを在庫移動テーブルから分離することで、移動データを照会するときにスキャンされるデータの量を減らすことができます。これにより、クエリのパフォーマンスが大幅に向上します。
精度：ビューでの残高の日次計算により、在庫残高テーブルに最も正確なデータが反映されます。このプロセス中に、必要なデータクレンジングと検証を実行する機会があります。
効率：在庫残高テーブルを毎晩更新することで、データを統合して最適化し、クエリのパフォーマンスにより適したものにすることができます。これは、ダッシュボードの速度を維持するのに役立ちます。
キーポイント -
ほぼリアルタイムのインベントリ ダッシュボードを作成する必要があります。
ダッシュボードは、BigQuery データ ウェアハウスのメイン インベントリ テーブルを読み取ります。
履歴在庫データは、品目および場所ごとの在庫残高として保存されます。
毎時間、数千件のインベントリーの更新があります。
ダッシュボードのパフォーマンスを可能な限り向上させ、データが正確であることを確認する必要があります。
正しくないオプション -
オプション A(BigQuery UPDATE ステートメントを使用)は、同時実行の問題が発生する可能性があるため、リアルタイム更新に適しておらず、クエリのパフォーマンスに影響を与える可能性があります。オプション B (在庫残高テーブルのパーティション分割) では、クエリのパフォーマンスは向上しますが、リアルタイムの更新やデータの正確性はオプション C ほど効果的には対応できません。
オプション D(BigQuery バルクローダーを使用)は、バッチ読み込みのシナリオに適しており、インベントリ ダッシュボードに必要なほぼリアルタイムのデータ更新を提供できない場合があります。したがって、このコンテキストでは最適な選択ではありません。
</div></details>

### Q. 質問42: 未回答
BigQuery にデータが保存されている。BigQuery データセットのデータは、高可用性を備えている必要があります。このデータのストレージ、バックアップ、およびリカバリ戦略を定義して、コストを最小限に抑える必要があります。目標復旧時点(RPO)が 30 日の BigQuery テーブルをどのように構成すればよいですか?
1. 
2. 
3. BigQuery データセットをマルチリージョンに設定します。緊急時には、特定の時点のスナップショットを使用してデータを回復します。
4. 
<details><div>
    答え：3
説明
C. 
このオプションは、いくつかの理由で正しいです。
マルチリージョンデータセット:複数リージョンの BigQuery データセットを作成すると、データが複数の地理的リージョンに複製され、高可用性と冗長性が確保されます。このアプローチは、リージョンの障害によるデータ損失を防ぐのに役立ちます。
ポイント・イン・タイム・スナップショット:BigQuery のポイントインタイム スナップショット機能を使用すると、過去 30 日以内の特定の時点にデータを復元できます。これは、目標復旧時点 (RPO) の目標値である 30 日と一致します。
正しくないオプション -
A. BigQuery データセットをリージョンに設定します。緊急時には、特定の時点のスナップショットを使用してデータを回復します。
このオプションでは、特定の時点のスナップショットの使用が推奨されますが、リージョンの冗長性しか提供されないため、高可用性とディザスター リカバリーには十分ではない可能性があります。リージョン データセットは、マルチリージョン データセットと同じレベルのリージョン停止に対する保護を提供しません。
B. BigQuery データセットをリージョンに設定します。スケジュールされたクエリを作成して、バックアップの時刻のサフィックスが付いたテーブルにデータのコピーを作成します。緊急の場合は、テーブルのバックアップコピーを使用してください。
このオプションでは、スケジュールされたクエリ バックアップを作成する必要がありますが、これはデータ復旧の効果的な戦略です。ただし、特にデータセットが大きい場合は、バックアップの管理と保守が複雑になり、追加コストが発生します。BigQuery にはすでにネイティブのバックアップと復元機能が用意されているため、スケジュールされたクエリのコピーは不要になります。
D. BigQuery データセットをマルチリージョンに設定します。スケジュールされたクエリを作成して、バックアップの時刻のサフィックスが付いたテーブルにデータのコピーを作成します。緊急の場合は、テーブルのバックアップコピーを使用してください。
オプション B と同様に、このアプローチでは、マルチリージョン ストレージとスケジュールされたクエリ バックアップが組み合わされます。マルチリージョン ストレージによる冗長性は提供されますが、スケジュールされたクエリを使用してデータのバックアップ コピーを維持することに関連する複雑さと不要なコストも発生する可能性があります。BigQuery のリカバリとポイントインタイム スナップショットのネイティブ機能は、より効率的で費用対効果が高く、目的の RPO を達成します。
</div></details>

### Q. 質問43: 未回答
BigQuery テーブル内のデータのサンプルで Dataprep レシピを作成しました。このレシピを使用して、ロード・ジョブの実行が完了した後、同じスキーマを持つデータの新しい日次アップロードをクリーンアップおよび変換します。どのように進めればよいですか?
1. 
2. 
3. 
4. Dataprep ジョブを Dataflow テンプレートとしてエクスポートし、Composer ジョブに組み込むことです。
<details><div>
    答え：4
説明
正しいオプションは D. 
データフローテンプレートとしてエクスポートする:Dataprep ジョブを Dataflow テンプレートとしてエクスポートすると、受信データに対して実行できる再利用可能なデータ変換ワークフローが作成されます。
Composerジョブに組み込む:Google Cloud Composer は、複雑なワークフローをオーケストレーションできるマネージド Apache Airflow サービスです。Dataflow テンプレートを Composer ジョブに組み込むことで、大規模なデータ処理パイプラインの一部として Dataprep ベースのデータ変換の実行をスケジュールし、管理することができます。
正しくないオプション -
A. Dataprep で cron スケジュールを作成します。Dataprep ではジョブの実行をスケジュールできますが、これらのスケジュールは通常、Dataprep 環境内で Dataprep ジョブを実行するためのものであり、このシナリオで必要な外部でのオーケストレーションのためのものではありません。
B. App Engine の cron ジョブを作成します。App Engine の cron ジョブは、HTTP エンドポイントのトリガーなど、App Engine 環境に固有のタスクには適していますが、データ変換ワークフローやその他の外部プロセスのオーケストレーションを目的としたものではありません。
C. レシピを Dataprep テンプレートとしてエクスポートし、Cloud Scheduler でジョブを作成します。Cloud Scheduler を使用してジョブをトリガーすることもできますが、Dataprep ジョブは通常、Dataprep 環境内で実行されます。このオプションでは、Dataprep ジョブの実行を大規模なデータ パイプラインにシームレスに組み込むことはできません。
参考リンク -
クラウドコンポーザー:- https://cloud.google.com/composer/
</div></details>

### Q. 質問45: 未回答
Cloud Dataproc クラスタの管理者である。クラスターで進行中の作業を失うことなく、コストを最小限に抑えながら、実行時間の長いジョブをより高速に実行する必要があります。具体的にどのようなステップを踏むべきでしょうか?
1. 
2. 
3. 
4. プリエンプティブルワーカーノードでクラスタサイズを増やし、グレースフルデコミッションを使用するように構成します。
<details><div>
    答え：4
説明
正しいオプションは D です。 
プリエンプティブル・ワーカー・ノード:プリエンプティブル VM は、Google Cloud 上の有効期間が短く、費用対効果の高いコンピューティング インスタンスです。通常の VM よりも安価ですが、必要な容量が増加したときに Google がプリエンプト(終了)できます。コスト削減にはなりますが、いつでもプリエンプトされる可能性があるため、信頼性が低下する可能性もあります。
グレースフルデコミッショニング:グレースフルデコミッションを使用するようにプリエンプティブルワーカーノードを構成すると、プリエンプションノードで現在実行中のワークロードをプリエンプションされる前に、クラスタで終了できます。これにより、進行中の作業が失われるリスクが最小限に抑えられ、プリエンプティブルノードが停止した場合でもジョブが正常に完了します。
プリエンプティブルワーカーノードでクラスターサイズを拡大し、グレースフルデコミッションを使用することで、プリエンプティブルインスタンスのコスト削減を効果的に活用しながら、ジョブが中断することなく作業を完了できるようにし、ジョブの実行を高速化し、コストを最小限に抑えることができます。
正しくないオプション -
A. プリエンプティブルでないワーカーを増やしてクラスタサイズを増やします。クラスター サイズを大きくするとジョブのパフォーマンスが向上しますが、プリエンプティブルでないワーカーを追加すると、プリエンプティブル ノードが終了するという問題に直接対処せずにコストが増加します。
B. プリエンプティブルワーカーノードでクラスタサイズを増やし、強制的に使用停止するように構成します。プリエンプティブル・ワーカー・ノードを強制的に使用停止にすると、進行中の作業が失われる可能性があり、データを失うことなくジョブをより高速に実行するためには望ましくありません。
C. プリエンプティブル ワーカー ノードでクラスタ サイズを増やし、Cloud Stackdriver を使用してスクリプトをトリガーして作業を保持します。モニタリングとアラートに Stackdriver を使用することは重要ですが、グレースフルな廃止の必要性に直接対処することはできません。グレースフル デコミッションは、プリエンプティブル ノードの終了をより効率的に処理するための Dataproc の組み込みメカニズムです。
</div></details>

### Q. 質問46: 未回答
ある小売チェーンは、さまざまな地域の店舗で顧客の購入パターンを分析したいと考えています。複雑なSQLクエリをサポートし、大量のデータを処理できるデータウェアハウスソリューションが必要です。どのGCPサービスを使用すべきか?
1. 
2. BigQuery
3. 
4. 
<details><div>
    答え：2
説明
質問の正しいオプションは次のとおりです。 B. BigQuery
このシナリオでは、小売チェーンは、異なる地域の店舗間で顧客の購入パターンを分析する必要があります。これには、複雑な SQL クエリのサポートと大量のデータを処理する機能という 2 つの主要な要件があります。
BigQuery は、SQL クエリを使用して大規模なデータセットを分析するために設計された、フルマネージドのサーバーレス データ ウェアハウス ソリューションです。複雑な分析クエリの処理に優れており、大量のデータを効率的に処理できます。また、パーティション分割やクラスタリングなどの機能も提供して、クエリのパフォーマンスを最適化します。したがって、店舗全体の顧客の購入パターンを分析するという小売チェーンのニーズと完全に一致しています。
正しくないオプション -
A. Cloud Bigtable の場合: Cloud Bigtable は、大規模で高スループットのワークロード向けに設計された NoSQL データベースです。複雑な SQL クエリには適しておらず、複雑なデータ ウェアハウスやクエリ タスクではなく、主にリアルタイムの運用分析と時系列データに使用されます。
C. Firestore: Firestore は、主にモバイルおよびウェブ アプリケーション開発向けに設計された、柔軟でスケーラブルな NoSQL データベースです。リアルタイムのデータ同期や低レイテンシのクエリには適していますが、複雑な SQL クエリや大規模なデータ ウェアハウスを BigQuery ほど効率的に処理できない場合があります。
D. クラウドデータストア: Cloud Datastore は、運用アプリケーションやリアルタイム データに適した NoSQL データベースでもありますが、複雑なデータ ウェアハウス タスクに必要な堅牢なクエリ機能やパフォーマンスは提供されない場合があります。
</div></details>

### Q. 質問47: 未回答
研究機関は、世界中で行われている実験から大規模な科学データを収集し、処理します。そのためには、ペタバイト規模のデータを低遅延で効率的に管理できるストレージソリューションが必要です。このシナリオにはどのGCPサービスが適していますか?
1. 
2. 
3. Google クラウドストレージ
4. 
<details><div>
    答え：3
説明
研究機関が大規模な科学データを効率的に収集して処理し、ペタバイト規模のデータを低遅延で管理する必要があるシナリオに適したオプションは次のとおりです。
C. Google クラウドストレージ
Google Cloud Storage(オプション C): Google Cloud Storage は、ペタバイト規模のデータを含む大量のデータを保存および取得するように設計されています。オブジェクトへの低遅延アクセスを提供し、大規模なデータを効率的に格納および管理する必要があるシナリオに適しています。耐久性、スケーラビリティ、高可用性を提供し、データストレージの信頼できる選択肢となっています。
正しくないオプション -
A. Cloud Pub/Sub(オプション A):
Cloud Pub/Sub は、イベントドリブン システム向けのメッセージング サービスです。リアルタイムのメッセージングとイベントの取り込みに使用されますが、大規模なデータストレージ用には設計されていません。
B. Bigtable(オプション B):
Bigtable は、高スループットで低レイテンシのワークロード向けに設計された NoSQL データベースですが、大規模な科学データの保存と管理には適していない可能性があります。これは、大規模なデータセットの長期保存ではなく、高速でリアルタイムのデータアクセスと分析に適しています。
D. クラウドデータストア(オプション D):
Cloud Datastore は NoSQL データベース サービスであり、ウェブやモバイル アプリケーションのデータ ストレージには適していますが、ペタバイト規模の科学データの管理には適していない可能性があります。トランザクション データに重点を置いており、この特定のユースケースでは Google Cloud Storage と同じスケーラビリティと費用対効果を提供できない場合があります。
</div></details>

### Q. 質問48: 未回答
eラーニングプラットフォームは、生徒の進捗状況とクイズの結果をリアルタイムで追跡する必要があります。また、レポートと分析を生成する必要もあります。このユースケースに適したデータベースを提供するGCPサービスはどれですか?
1. 
2. 
3. BigQuery
4. 
<details><div>
    答え：3
説明
生徒の進捗状況や小テストの結果をリアルタイムで追跡したり、eラーニングプラットフォームでレポートや分析を生成したりするには、BigQuery(オプションC)が最適なGCPサービスです。その理由は次のとおりです。
正しいオプションは C. BigQuery -
BigQuery は、大規模なデータセットの処理と複雑な SQL クエリの迅速な実行を専門とする、フルマネージドでサーバーレスかつ拡張性の高いデータ ウェアハウスです。
リアルタイム分析用に設計されており、データ分析とレポート作成タスクに優れたパフォーマンスを提供します。
データをリアルタイムで取り込んで分析できるため、生徒の進捗状況やクイズの結果をその都度追跡するのに適しています。
大量のデータを処理できるため、レポートや分析の生成に適しています。
正しくないオプション -
A. Firestore:
Firestore は、クライアント(モバイル アプリケーションやウェブ アプリケーションなど)間での柔軟なリアルタイムのデータ ストレージと同期に適した NoSQL ドキュメント データベースです。Firestore はリアルタイムのデータ更新を処理でき、学生関連のデータの管理には適していますが、BigQuery と比較すると、複雑な分析やレポート作成のタスクには適していない可能性があります。
B. Cloud SQL:
Cloud SQL はマネージド リレーショナル データベース サービスですが、従来のリレーショナル データベースの制限により、リアルタイムの分析やレポート作成には適していない場合があります。構造化データやトランザクション ワークロード向けに設計されているため、複雑な分析クエリでは BigQuery ほど効率的に実行できない場合があります。
D. クラウドデータストア:
Cloud Datastore は、半構造化データの保存とクエリに適した NoSQL データベースです。リアルタイムのウェブスケール アプリケーション向けに設計されていますが、BigQuery が提供する詳細なレポートと分析に必要な堅牢な分析機能は提供されない場合があります。
</div></details>

### Q. 質問49: 未回答
スマートシティに展開されたIoTデバイスからセンサーデータを収集して分析するプロジェクトに取り組んでいます。膨大な量の受信データを処理し、リアルタイム分析をサポートできるGCPサービスはどれですか?
1. 
2. Bigtable
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は、B. Bigtable です。
このシナリオでは、スマート シティに展開されたデバイスからの IoT センサー データを処理しており、通常は大量の受信データが生成されます。また、リアルタイム分析のサポートも必要です。
Bigtable は、大量のデータを低レイテンシと高スループットで処理するために設計された NoSQL データベースです。大量のセンサー データの取り込みと保存に適しています。Bigtable はリアルタイムのデータ取り込みを処理でき、効率的なクエリをサポートしているため、大規模なデータセットのリアルタイム分析に適しています。センサーの読み取り値などの時系列データに最適化されているため、このユースケースに適しています。
正しくないオプション -
A. Cloud Pub/Sub の場合:
Cloud Pub/Sub は、リアルタイムのイベントの取り込みと配信のために設計されたメッセージング サービスです。リアルタイム データの取り込みには適していますが、分析に必要なストレージとクエリ機能は提供されません。大規模なデータの処理と分析の実行に必要なストレージとクエリ機能が不足しています。
C. BigQueryの場合:
BigQuery は、大規模なデータセットに対して SQL に似たクエリを実行するために設計されたデータ ウェアハウスですが、リアルタイムのデータ取り込みには最適化されていません。BigQuery は分析クエリやバッチ処理には優れていますが、大量のリアルタイム データ インジェストを処理するには最適な選択肢ではない可能性があります。
D. Firestore:
Firestore は柔軟な NoSQL データベースですが、ドキュメントベースのデータの管理に適しており、一般的にモバイル アプリケーションやウェブ アプリケーションに使用されます。IoTセンサーからの大量の時系列データを処理し、リアルタイム分析を実行するには最適な選択ではない可能性があります。
</div></details>

### Q. 質問50: 未回答
マーケティング会社は、Web、モバイルアプリ、メールキャンペーンなど、さまざまなソースからの顧客データを保存して分析したいと考えています。複数のチャネルからのデータを統合して分析できるデータベースが必要です。どのGCPサービスを検討すべきでしょうか?
1. BigQuery
2. 
3. 
4. 
<details><div>
    答え：1
説明
さまざまなソースからの顧客データを保存および分析し、複数のチャネルからのデータを統合および分析することを検討しているマーケティング会社にとって、検討すべき最適なGCPサービスはA.BigQueryです。
BigQuery は、大規模なデータセットを処理し、分析とデータ ウェアハウスのために複雑な SQL クエリを実行するように設計されています。複数のソースとチャネルからのデータの統合と分析を効率的に処理できます。
正しくないオプション -
B. Firestore は、主にモバイルおよび Web アプリケーションの開発に使用される NoSQL ドキュメント データベースです。アプリケーションの構造化データの管理には適していますが、複数のチャネルにまたがる複雑なデータ分析には適していない可能性があります。
C. Cloud Datastore は、ウェブおよびモバイル アプリケーション用に設計された NoSQL データベースでもあります。Firestore と同様に、アプリケーションの構造化データの保存には適していますが、BigQuery のような分析機能やクエリ パフォーマンスには欠けています。
D. Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。トランザクションデータベースには最適ですが、さまざまなソースやチャネルからのデータを扱うマーケティング会社が必要とする複雑な分析やデータ統合には最適化されていません。
</div></details>

## 4
### Q. 質問1: 未回答
Google データポータル 360 で、Google BigQuery をデータソースとして使用するレポートを作成します。レポートの視覚化には、1 時間未満のデータが表示されていません。
これを修正するにはどうすればよいですか?
1. レポート設定を編集して、キャッシュを無効にします。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Google BigQuery をデータソースとして使用している場合に、1 時間未満のデータが Google データポータルのレポートに表示されるようにするには、次のことを行う必要があります。
A. レポート設定を編集して、キャッシュを無効にします。
このオプションが正しい選択である理由は次のとおりです。
キャッシュ: Google データポータルでは、パフォーマンス向上のためにデータをキャッシュすることがあります。このキャッシュ メカニズムにより、キャッシュされたデータが使用されているために、視覚化に最新のデータが表示されない状況が発生する場合があります。
キャッシュの無効化: レポート設定でキャッシュを無効にすると、レポートにアクセスするたびにデータソース(この場合は Google BigQuery)からデータを直接取得するように Google データポータルに指示できます。これにより、ビジュアライゼーションには常に最新のデータが反映されます。
正しくないオプション -
オプション B の「テーブルの詳細を編集して BigQuery のキャッシュを無効にする」は、Google データポータルのキャッシュ設定には適用されません。キャッシュ設定は、通常、データソース自体ではなく、レポートツール内で制御されます。
オプション C と D の [視覚化を表示するブラウザー タブを更新する] と [過去 1 時間のブラウザー履歴を消去してから、視覚化を表示するタブを再読み込みする] は、ブラウザーに表示されるデータを更新するのに役立つ場合があります。ただし、これらのオプションでは Google データポータルのキャッシュ設定には対応していないため、レポートに常に <> 時間未満のデータが表示されるようにするために必要な調整を行う必要があります。
</div></details>

### Q. 質問2: 未回答
外部顧客から、データベースからのデータのダンプが毎日提供されます。データはカンマ区切り値(CSV)ファイルとして Google Cloud Storage GCS に送られます。このデータを Google BigQuery で分析したいが、データに誤った形式または破損した行が含まれている可能性があります。
このパイプラインをどのように構築する必要がありますか?
1. 
2. 
3. 
4. Google Cloud Dataflow バッチ パイプラインを実行してデータを BigQuery にインポートし、分析のために別の配信不能テーブルにエラーをプッシュします。
<details><div>
    答え：4
説明
Google BigQuery の Google Cloud Storage(GCS)にある日次 CSV ファイルのデータを分析しながら、破損または形式が正しくない可能性のある行を処理するパイプラインを構築するには、次の方法をお勧めします。
D. Google Cloud Dataflow バッチ パイプラインを実行してデータを BigQuery にインポートし、分析のために別の配信不能テーブルにエラーをプッシュします。
このアプローチが適切な理由は次のとおりです。
データの変換と検証: Google Cloud Dataflow は、データの変換と検証のための強力なツールです。Dataflow を使用して GCS から CSV ファイルを取り込み、データの検証と変換ロジックを適用してから、クリーンなデータを BigQuery に読み込むことができます。これにより、BigQuery に挿入する前に、必要に応じてデータのクリーニング、エンリッチメント、修正を行うことができます。
エラー処理: Dataflow は堅牢なエラー処理機能を提供します。正しく書式設定されていない行や破損している行は、配信不能テーブルにリダイレクトされ、そこで問題を個別に分析およびデバッグできます。これにより、不良データによって BigQuery への正常なデータの読み込みが妨げられることがなくなります。
バッチ処理: 毎日のデータ ダンプを処理するため、Dataflow などのバッチ処理アプローチがこのシナリオに適しています。これにより、データを継続的に監視するのではなく、より大きなチャンクでデータを処理できます。
正しくないオプション -
オプション A(フェデレーション データ ソースを使用)は、単純なケースでは機能する可能性がありますが、Dataflow と同じレベルの制御とエラー処理は提供されません。SQL クエリでのデータ品質の問題の処理は、複雑で効率が低下する可能性があります。
オプション B(Google Stackdriver で BigQuery モニタリングを有効にしてアラートを作成する)は、BigQuery 自体のパフォーマンスと運用上の問題のモニタリングとアラートに重点が置かれており、データ品質やデータのインポートの問題には直接対処していません。
オプション C(gcloud CLI を使用して BigQuery にデータをインポートし、max_bad_records を 0 に設定する)では、BigQuery にデータが読み込まれますが、破損した行や形式が正しくない行を処理するための堅牢なメカニズムは提供されません。max_bad_records を 0 に設定すると、エラーのある行が拒否され、データが失われる可能性があります。
</div></details>

### Q. 質問3: 未回答
天気予報アプリは、15 分ごとにデータベースを照会して、現在の気温を取得します。フロントエンドはGoogle App Engineを搭載しており、何百万人ものユーザーにサービスを提供しています。
データベース障害に対応するフロントエンドを設計する最良の方法は何ですか?
1. 
2. エクスポネンシャル バックオフを使用して、最大 15 分までクエリを再試行します。
3. 
4. 
<details><div>
    答え：2
説明
何百万人ものユーザーにサービスを提供する Google App Engine で稼働する天気予報アプリが、現在の気温をデータベースに問い合わせる場合、データベースの障害に対応する適切な方法は次のとおりです。
B. エクスポネンシャル バックオフを使用して、最大 15 分までクエリを再試行します。
このアプローチが推奨される理由は次のとおりです。
エクスポネンシャル バックオフによる再試行: エクスポネンシャル バックオフは、一時的なデータベースの停止などの一時的な障害を処理するために広く使用されている戦略です。データベース障害が発生した場合、すぐにクエリを再試行すると、問題が悪化し、データベースの負荷が増加し、さらに問題が発生する可能性があります。エクスポネンシャル バックオフでは、各再試行の間隔が長くなるため、データベースの負荷が軽減され、復旧に時間がかかるようになります。これは、障害を処理するためのより適切でリソース効率の高い方法です。
15 分の上限: エクスポネンシャル バックオフの上限を 15 分に設定すると、天気予報アプリがデータベースの復旧を無期限に待機することがなくなります。これにより、データベースを復旧する時間を与えることと、データが古くなりすぎないようにすることのバランスが取れます。待機時間が長すぎると (オプション D)、許容できないデータの古さが生じる可能性がありますが、データベース サーバーを再起動するコマンドを発行するコマンド (オプション A) は、通常、フロントエンドの責任ではなく、意図しない結果をもたらす可能性があります。
継続的な再試行: 継続的な再試行 (オプション C) は、特にデータベースが長期間ダウンすることが予想される場合に、フロントエンドとデータベースの両方に不要な負荷をかける可能性があります。エクスポネンシャル バックオフにより、再試行間隔が増加し、時間が経つにつれて再試行の頻度が減り、リソースをより効率的に使用できます。
</div></details>

### Q. 質問6: 未回答
あなたの会社は規制の厳しい業界に属しており、個々のユーザーが業務に必要な最小限の情報にのみアクセスできるようにするデータセキュリティポリシーを実装する必要があります。Google BigQuery を使用してこのポリシーを適用します。次の 3 つのアプローチのうち、どれを選びますか?(3つ選択してください。
1. 
2. テーブルへのアクセスをロールで制限します。
3. 
4. BigQuery API へのアクセスを承認済みのユーザーに制限する
5. 複数のテーブルまたはデータベース間でデータを分離します。
6. 
<details><div>
    答え：2,4,5
説明
個々のユーザーが Google BigQuery で業務を行うために必要な最小限の情報にのみアクセスできるようにするという要件を適用するには、次の方法を使用できます。
B. テーブルへのアクセスをロールで制限します。さまざまなレベルのアクセス権限を持つさまざまなロールをユーザーまたはグループに割り当てます。これにより、特定のテーブルまたはデータセットをクエリまたは変更できるユーザーを制御できます。
D. BigQuery API へのアクセスを承認済みのユーザーに制限する:API アクセスを管理することで、BigQuery API を使用してデータを操作できるユーザーを制限できます。承認されたユーザーまたはアプリケーションのみがアクセスできるようにする必要があります。
E. 複数のテーブルまたはデータベース間でデータを分離します。アクセス要件に基づいてデータを異なるテーブルまたはデータセットに分割して整理します。これにより、ユーザーは自分のロールに関連するデータにのみアクセスできます。
これらのアプローチは、規制の厳しい業界におけるデータアクセス制御と規制へのコンプライアンスを確保するのに役立ちます。オプション A、C、および F は、全体的なデータ セキュリティとガバナンスにも役割を果たす可能性がありますが、ユーザー固有のデータ アクセス制限を適用するための直接的なメカニズムではありません。
</div></details>

### Q. 質問7: 未回答
eコマース企業向けにバスケット放棄システムを設計しています。システムは、次の条件が満たされた場合にユーザーにメッセージを送信します。
ユーザーが 1 時間 Web サイトを操作していない。
ユーザーは、30ドル相当の製品をカートに追加しました。
ユーザーはトランザクションを完了していません。
Google Cloud Dataflow を使用してデータを処理し、メッセージを送信するかどうかを決定します。パイプラインをどのように設計すべきか?
1. 
2. 
3. ギャップ期間が 60 分のセッション ウィンドウを使用
4. 
<details><div>
    答え：3
説明
正しいオプション - C (ギャップ期間が 60 分のセッション ウィンドウを使用):
このシナリオでは、30 ドル相当の商品をカートに追加し、サイトを 1 時間操作していないユーザーを特定します。
ギャップ期間が 60 分のセッション ウィンドウを使用すると、セッション内のユーザー アクティビティをキャプチャし、アクティビティ間に 60 分以上のギャップがある場合に検出できるため、適切な選択です。
セッション・ウィンドウを定義して、この時間枠内のユーザー・アクティビティーをグループ化できます。セッションが終了すると (つまり、60 分間アクティビティがない場合)、セッションの内容を分析し、ユーザーにメッセージを送信するための条件を満たしているかどうかを判断できます。
正しくないオプション -
オプション A (期間が 60 分の固定時間枠を使用):
期間が 60 分の固定時間枠を使用することは、ユーザー セッションやユーザー アクティビティのギャップを考慮しないため、適切ではありません。60 分間隔の重複しないウィンドウが作成されるだけで、ユーザーの動作と一致しない可能性があります。
オプション B (期間が 60 分のスライディング タイム ウィンドウを使用):
スライディング タイム ウィンドウはデータを継続的に移動し、ユーザーが 60 分間非アクティブになったときに、関心のある特定のセッションをキャプチャできない場合があります。スライディング ウィンドウは、連続的なリアルタイム処理に適しています。
オプション D (60 分の遅延を持つ時間ベースのトリガーを持つグローバル ウィンドウを使用):
グローバルウィンドウでは、セッションの境界やユーザーアクティビティは考慮されません。すべてのデータを 1 つの連続したストリームとして扱うため、ユーザー セッションや非アクティブな期間の特定には役立たない場合があります。
参考リンク -
ビームウィンドウの基本:- https://beam.apache.org/documentation/programming-guide/#windowing-basics
</div></details>

### Q. 質問8: 未回答
あなたの会社は、さまざまなクライアントのデータ処理を処理しています。各クライアントは独自の分析ツールスイートを使用することを好み、Google BigQueryを介して直接クエリにアクセスできるものもあります。クライアントが互いのデータを見ることができないように、データをセキュリティで保護する必要があります。データへの適切なアクセスを確保する必要があります。どの3つのステップを踏むべきですか?(3つ選択してください。
1. 
2. クライアントごとに異なるデータセットにデータを読み込みます。
3. 
4. クライアントのデータセットを承認されたユーザーに制限します。
5. 
6. 各クライアントのユーザーに適切な Identity and Access Management (IAM) ロールを使用します。
<details><div>
    答え：2,4,6
説明
データをセキュリティで保護し、適切なアクセスを許可しながら、クライアントが互いのデータを表示できないようにするには、次の 3 つの手順を実行する必要があります。
B. クライアントごとに異なるデータセットにデータを読み込みます。
クライアントごとにデータを個別のデータセットに整理します。これにより、データセットレベルでのデータ分離が保証され、各クライアントのデータに対するアクセスとアクセス許可の管理が容易になります。
D. クライアントのデータセットを承認されたユーザーに制限します。
データセットへのアクセスを許可するユーザーまたはグループを指定することで、データセットレベルでアクセス制御を実装します。これにより、許可された個人のみが特定のクライアントのデータセット内のデータを表示およびクエリできるようになります。
F. 各クライアントのユーザーに適切な Identity and Access Management (IAM) ロールを使用します。
各クライアントのユーザーまたはグループに固有の IAM ロールを割り当てます。IAM ロールは、データセット内で実行できるアクションを制御し、各クライアントが自分のデータに適切なレベルのアクセス権を持ち、他のクライアントのデータへのアクセスが制限されるようにします。
これらの手順をまとめて、Google BigQuery 内の各クライアントのデータにデータの分離、アクセス制御、セキュリティを提供し、クライアントデータを安全かつ独立して管理できるようにします。
</div></details>

### Q. 質問9: 未回答
Google Cloud Platform で実行される POS アプリケーションを開発しています。アプリケーションは支払いトランザクションを処理し、ユーザーベースが指数関数的に増加すると予想されます。データベースのインフラストラクチャのスケーリングを管理したくないため、スケーラブルで信頼性が高く、安全な Google データベース サービスを選択する必要があります。
どのGoogleデータベースサービスを使用する必要がありますか?
1. Cloud SQL
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解 - A. Cloud SQL
ユーザーベースが急激に増加する可能性があると予想される POS アプリケーションで支払いトランザクションを処理する場合、インフラストラクチャのスケーリングの管理を避けたい場合は、Cloud SQL が適しています。その理由は次のとおりです。
1. Cloud SQL はフルマネージドのリレーショナル データベース サービスです: スケーリングやメンテナンスなどのインフラストラクチャ管理を行うため、アプリケーションの開発とビジネス ロジックに集中できます。
2. ACID コンプライアンス: Cloud SQL は、支払いトランザクションを処理し、データの一貫性と信頼性を確保するために不可欠な強力な ACID(Atomicity、Consistency、Isolation、Durability)コンプライアンスを提供します。
3. 一般的なデータベースエンジンとの互換性: Cloud SQL は、MySQL、PostgreSQL、SQL Server など、複数のデータベースエンジンをサポートしているため、アプリケーション固有の要件に柔軟に対応できます。
正しくないオプション -
BigQuery(オプション B)、Cloud Bigtable(オプション C)、Cloud Datastore(オプション D)は価値ある Google Cloud データベース サービスですが、ユースケースは異なります。
- BigQuery は、フルマネージドでサーバーレス、かつ拡張性の高いデータ ウェアハウス サービスであり、支払いトランザクションなどのトランザクション処理ではなく、主に分析やビジネス インテリジェンスのワークロードに使用されます。
- Cloud Bigtable は、高スループット、低レイテンシ、スケーラビリティを実現するように設計された NoSQL データベース サービスで、通常、大規模な高速な読み取りおよび書き込み操作を必要とするアプリケーションに使用されます。トランザクション処理には最適ではない可能性があります。
- Cloud Datastore は、ウェブ アプリケーションやモバイル アプリケーションの構築に適した NoSQL ドキュメント データベース サービスですが、特定の ACID 要件により、支払いトランザクションの処理には最適ではない場合があります。
</div></details>

### Q. 質問10: 未回答
組織サンプルに関する情報のデータベースを使用して、将来の組織サンプルを正常または変異のいずれかに分類します。組織サンプルを分類するための教師なし異常検出方法を評価しています。この方法をサポートする 2 つの特性はどれですか?(2つ選択してください。
1. 正常なサンプルと比較して突然変異の発生はほとんどありません。
2. 
3. 将来の突然変異は、データベース内の突然変異したサンプルとは異なる特徴を持つと予想されます。
4. 
<details><div>
    答え：1,3
説明
組織サンプルを正常または変異として分類するための教師なし異常検出法をサポートする2つの特性は次のとおりです。
ある。正常なサンプルと比較して突然変異の発生はほとんどありません。
- 教師なし異常検出では、この方法は通常、異常(この場合は変異した組織サンプル)を、標準(正常組織サンプル)からの逸脱に基づいて識別します。正常なサンプルと比較して変異の発生が非常に少ない場合は、異常がまれで目立つため、異常検出がより効果的になります。
C. 将来の突然変異は、データベース内の突然変異したサンプルとは異なる特徴を持つと予想されます。
- 教師なし異常検出法は、異常が大部分のデータ(正常サンプル)と比較して明確な特徴または特性を持っているという考えに基づいて異常を検出することを目的としています。将来の変異が、データベースにすでに存在する変異したサンプルとは異なる特徴を持つことが予想される場合、これは特徴の違いに基づいて異常を特定するという前提と一致します。
正しくないオプション -
オプションBは、正常サンプルと変異サンプルの両方がほぼ等しい発生であっても、異常の効果的な識別に必ずしも役立つとは限らないため、通常、教師なし異常検出をサポートする特性ではありません。
また、オプションDは、教師なし異常検出を直接サポートする特性ではありません。将来の突然変異がデータベース内の突然変異したサンプルと類似した特徴を持っている場合、特徴ベースの方法を使用してそれらを異常として区別することは困難である可能性があります。
オプションEは、どのサンプルが変異し、どのサンプルが正常であるかを示すラベルを持つことに言及しており、教師なしアプローチではなく教師ありアプローチを示唆しています。教師なし異常検出は、トレーニング用のラベル付きデータがないが、標準からの逸脱に基づいてデータセット内の異常を検出する場合に使用されます。
</div></details>

### Q. 質問11: 未回答
あなたは、毎分 10,000 メッセージの割合で Google BigQuery にソーシャル メディアの投稿を保存および分析するアプリケーションを設計する任務を負っています。このアプリケーションでは、ストリーミング挿入を使用して、個々の投稿をほぼリアルタイムで BigQuery に挿入します。アプリケーションは、ストリーミング挿入の直後にデータ集計も実行します。ただし、ストリーミング挿入後のクエリは厳密な一貫性を示さず、クエリからのレポートで処理中のデータが失われる可能性があることがわかります。
アプリケーションの設計を調整して、クエリの一貫性が保たれ、レポートが処理中のデータを見逃さないようにするにはどうすればよいでしょうか。
1. 
2. 
3. 
4. ストリーミング挿入後のデータ可用性の平均待機時間を推定し、常に 2 倍の待機時間後にクエリを実行します。
<details><div>
    答え：4
説明
D. ストリーミング挿入後のデータ可用性の平均待機時間を推定し、常に 2 倍の待機時間後にクエリを実行します。
ストリーミング挿入後に BigQuery でデータが使用可能になるまでの平均レイテンシを計算します。このレイテンシーは変動する可能性があるため、正確に見積もるには監視と分析が必要です。
レイテンシーを見積もった後、推定レイテンシーよりも長い期間待機した後に実行するようにクエリを設定します。たとえば、平均待機時間が 1 分の場合、クエリを 3 分ごとに実行するようにスケジュールできます。
予想されるデータ可用性の待機時間よりも長く待機することで、クエリは、最近挿入されたデータと、すぐには使用できなかった可能性のある処理中のデータの両方を確実にキャプチャします。
このアプローチにより、クエリの一貫性を確保し、処理中のデータを見逃すことなくすべての関連データをキャプチャできます。これは、ほぼリアルタイムの分析を維持しながら、データの可用性の変動に対処するための実用的な方法です。
正しくないオプション -
A. 蓄積されたデータを 2 分ごとにロードするようにアプリケーションを書き直します。
このアプローチでは、BigQuery に読み込む前に 2 分間データを蓄積することを提案します。これにより、データの読み込み頻度は減る可能性がありますが、転送中のデータの一貫性の問題には対処できません。それでも、この 2 分間の間にデータが欠落する可能性があるという同じ問題に直面します。
B. ストリーミング挿入コードを個々のメッセージのバッチ読み込みに変換します。
ストリーミング挿入からバッチ読み込みに切り替えると、強力な一貫性が得られる場合がありますが、ほぼリアルタイムの処理という目標に大きな影響を与えます。通常、バッチ読み込みは遅く、ほぼリアルタイムで到着するデータを分析するための要件には適合しません。
C. 元のメッセージを Google Cloud SQL に読み込み、ストリーミング挿入を使用してテーブルを 1 時間ごとに BigQuery にエクスポートします。
このアプローチでは、Google Cloud SQL と BigQuery への時間単位のエクスポートが関係するため、複雑さが増します。時間間隔内では強力な一貫性が提供される場合がありますが、ほぼリアルタイムで毎分 10,000 メッセージの速度でデータを処理するのには適していません。
</div></details>

### Q. 質問12: 未回答
スタートアップが正式なセキュリティポリシーを実装していない。現在、社内の全員が Google BigQuery に保存されているデータセットにアクセスできます。チームは、適切と思われるサービスを自由に使用できますが、ユースケースを文書化していません。データウェアハウスをセキュリティで保護するように求められました。みんなが何をしているのかを知る必要があります。最初に何をすべきですか?
1. Google Stackdriver 監査ログを使用して、データアクセスを確認します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
データウェアハウスを保護し、全員が何をしているかを理解するために取るべき最初のステップは次のとおりです。
A. Google Stackdriver 監査ログを使用して、データアクセスを確認します。
Google Stackdriver 監査ログは、Google Cloud 環境で誰が、どこで、いつ、何をしたかに関する詳細情報を提供します。これらのログを確認することで、BigQuery データセットにアクセスしているユーザーや、そのユーザーが実行しているアクションを把握できます。これは、データアクセスの現状を把握し、潜在的なセキュリティリスクや不正アクセスを特定するための重要な最初のステップです。
正しくないオプション -
B. 各テーブルの ID およびアクセス管理 (IAM) ポリシーを取得することは、アクセス制御ポリシーの定義と適用に役立ちますが、継続的なデータ アクセスの全体像を把握できない場合があります。
C. Stackdriver Monitoring を使用して BigQuery クエリスロットの使用状況を確認する方法は、データアクセスの監査ではなく、クエリのパフォーマンスとリソース使用率のモニタリングに重点が置かれています。
D. Google Cloud Billing API を使用してウェアハウスがどのアカウントに請求されているかを確認することは、請求とコスト追跡に関連しており、これは重要ですが、データ アクセスを理解して保護する必要性に直接対処するものではありません。
</div></details>

### Q. 質問13: 未回答
会社には、オンプレミスに 30 ノードの Apache Hadoop クラスターがあります。このクラスタを Google Cloud Platform(GCP)に移行しながら、既存の Hadoop ジョブを再利用できるようにしたいと考えています。また、クラスターの管理を可能な限り最小限に抑え、クラスターの存続期間を超えてデータを保持できるようにしたいと考えています。
このクラスタを GCP に移行するには、どのような手順が必要ですか?
1. 
2. 
3. 
4. Google Cloud Storage コネクタを使用する Cloud Dataproc クラスタを作成します。
<details><div>
    答え：4
説明
D. Google Cloud Storage コネクタを使用する Cloud Dataproc クラスタを作成します。
オプションDは、Hadoopクラスタをクラウドに移行しながら、管理を最小限に抑え、データの永続性を有効にするための有効な選択肢です。その理由は次のとおりです。
Google Cloud Dataproc: Dataproc は Google Cloud 上のマネージド Hadoop および Spark サービスであり、クラスタ管理の複雑さの多くを抽象化します。
Google Cloud Storage Connector: Google Cloud Storage コネクタを使用すると、Hadoop データに耐久性と拡張性に優れたストレージを提供する Google Cloud Storage にデータを保存できます。
Hadoop ジョブの再利用: Dataproc は Apache Hadoop と完全に互換性があり、大幅な変更なしで既存の Hadoop ジョブを再利用できます。
管理の最小化: Dataproc は、クラスタのプロビジョニング、サイズ変更、管理タスクを簡素化し、運用上のオーバーヘッドを削減します。
データの永続性: Google Cloud Storage はデータの永続性を重視して設計されているため、データはクラスタのライフサイクルとは無関係に保存されます。
この設定では、Hadoop ジョブは Google Cloud Storage に対してデータの読み取りと書き込みを行うことができるため、クラスタの寿命が尽きるまでデータの耐久性を確保できます。
Dataproc に関するよくある質問: https://cloud.google.com/dataproc/docs/resources/faq
オプション B(HDFS 用の永続ディスクを含む Dataproc クラスタを作成する)も有効なアプローチであり、HDFS によるデータの永続性を提供します。オプションBとオプションDのどちらを選択するかは、特定の要件と、HadoopデータのストレージレイヤーとしてHDFSとGoogle Cloud Storageのどちらを使用するかによって異なります。どちらのオプションも、ユースケースに応じて効果的に機能します。
参考リンク -
Google Cloud Dataproc: https://cloud.google.com/dataproc
Hadoop から Cloud Dataproc への移行: https://cloud.google.com/dataproc/docs/tutorials/migrating-hadoop
</div></details>

### Q. 質問14: 未回答
あなたの会社の事業主は、銀行取引のデータベースをあなたに与えました。各行には、ユーザー ID、トランザクション・タイプ、トランザクション・ロケーション、およびトランザクション金額が含まれます。データに適用できる機械学習の種類を調査するように求められます。使用できる機械学習アプリケーションを 3 つ選ぶのはどれですか?(3つ選択してください。
1. 
2. どの取引が不正である可能性が最も高いかを判断するための教師なし学習。
3. 特徴の類似性に基づいてトランザクションを N 個のカテゴリに分割するクラスタリング。
4. トランザクションの場所を予測するための教師あり学習。
<details><div>
    答え：2,3,4
説明
正解は -
B. どの取引が不正である可能性が最も高いかを判断するための教師なし学習。
異常検出やクラスタリングなどの教師なし学習は、ラベル付けされた例を必要とせずに、トランザクションデータのパターンや異常を特定するために使用できます。これは、通常の動作からの逸脱に基づいて、不正の可能性があるトランザクションを検出するのに役立ちます。
C. 特徴の類似性に基づいてトランザクションを N 個のカテゴリに分割するクラスタリング。
クラスタリングは、特徴の類似性に基づいてトランザクションをカテゴリまたはクラスターにグループ化できる教師なし学習手法です。これは、データ内のパターンやグループを特定するのに役立ち、一般的なトランザクションの動作や特性を明らかにすることができます。
D. トランザクションの場所を予測するための教師あり学習。
教師あり学習は、場所がターゲット変数である履歴データに基づいてトランザクションの場所を予測するためにも使用できます。モデルをトレーニングして、他の特徴量からトランザクションの場所を予測することができ、これはロケーションベースのサービスや分析に役立ちます。
</div></details>

### Q. 質問16: 未回答
自動車メーカーに勤務し、Google Cloud Pub/Sub を使用してデータ パイプラインを設定し、異常なセンサー イベントをキャプチャしました。Cloud Pub/Sub でプッシュ サブスクリプションを使用していて、作成したカスタム HTTPS エンドポイントを呼び出して、これらの異常なイベントが発生したときにアクションを実行しています。カスタム HTTPS エンドポイントで、重複するメッセージが大量に受信され続けます。これらの重複メッセージの最も可能性の高い原因は何ですか?
1. 
2. 
3. 
4. カスタム エンドポイントが、受信確認の期限内にメッセージを確認していません。
<details><div>
    答え：4
説明
D. カスタム エンドポイントが、受信確認の期限内にメッセージを確認していません。
このシナリオで重複するメッセージを受信する原因として最も可能性が高いのは、カスタム HTTPS エンドポイントが確認の期限内に Cloud Pub/Sub からのメッセージを認識していないことです。
Cloud Pub/Sub では、メッセージがサブスクライバー(この場合はカスタム HTTPS エンドポイント)に配信されると、サブスクライバーはメッセージの受信を確認する必要があります。確認の期限内に確認応答が受信されなかった場合、Cloud Pub/Sub はメッセージがサブスクライバーによって正常に処理されなかったと見なし、再配信します。
重複したメッセージを受信しないようにするには、カスタム HTTPS エンドポイントがメッセージを正常に処理したら、すぐに確認応答するようにする必要があります。これにより、メッセージが処理されたことが Cloud Pub/Sub に通知され、再配信されません。
カスタム エンドポイントのロジックを確認して、重複を防ぐために、予想される期間内にメッセージを確認するようにします。
</div></details>

### Q. 質問17: 未回答
会社では、独自のシステムを使用して、6 時間ごとにクラウドベースのデータ インジェスト サービスにインベントリ データを送信しています。データには、在庫品目 ID、名前、数量、場所など、いくつかのフィールドのペイロードが含まれます。送信のタイムスタンプも含まれます。送信に懸念がある場合は、システムによってデータが再送信されます。データの重複排除を最も効率的に行うにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 各データエントリのハッシュ値とその他のメタデータを格納するデータベーステーブルを維持します。
<details><div>
    答え：4
説明
D. 各データエントリのハッシュ値とその他のメタデータを格納するデータベーステーブルを維持します。
送信されたデータの重複排除を行う最も効率的な方法は、各データエントリのハッシュ値とその他のメタデータを格納するデータベーステーブルを維持することです。このアプローチが効率的である理由は次のとおりです。
1.ハッシュ:各データエントリのハッシュ値の計算は、高速で効率的なプロセスです。ハッシュ関数は、データの内容に基づいて固定サイズのハッシュコードを生成し、比較的迅速に計算できます。
2.ストレージ:ハッシュ値やその他のメタデータをデータベーステーブルに格納することで、効率的なインデックス作成とクエリが可能になります。ハッシュ値を主キーとして使用したり、インデックス付き列で使用して高速検索を行ったりすることができます。
3.重複排除:新しいデータを受信すると、そのハッシュ値を計算し、データベースにすでに保存されているハッシュ値と比較できます。一致するハッシュ値が見つかった場合は、データが重複していることをすばやく判断し、適切なアクションを実行できます。
4.タイムスタンプ:データには送信のタイムスタンプが含まれます。このタイムスタンプをハッシュ値とともに使用して、再送信の場合に特定のデータエントリの最新バージョンを識別できます。
ハッシュ値とメタデータを使用してデータベーステーブルを維持することは、特に再送信やその他の問題のためにデータ転送に重複が含まれる可能性がある場合に、データの重複を排除するためのスケーラブルで効率的な方法です。このアプローチにより、受信データの迅速かつ信頼性の高い重複排除が可能になります。
</div></details>

### Q. 質問18: 未回答
あなたの会社は、Google Cloud に保存されている非常に大規模なデータセットに対して複雑な分析を実行したいと考えている新しいデータ サイエンティストを採用しました ストレージと Google Compute Engine の Cassandra クラスタ内。サイエンティストは、主に機械学習プロジェクト用のラベル付きデータセットと、いくつかの視覚化タスクを作成したいと考えています。彼女は、ラップトップがタスクを実行するのに十分なパワーがなく、速度が低下していると報告しています。あなたは彼女がタスクを実行するのを手伝いたいです。 あなたは何をするべきか?
1. 
2. 
3. 
4. Google Compute Engine 上の仮想マシン(VM)に Google Cloud Datalab をデプロイします。
<details><div>
    答え：4
説明
Datalab は廃止され、Datalab create コマンドを使用して新しい Datalab インスタンスを作成することはできません。詳細については、以下の参照リンクを参照してください。
D. Google Compute Engine 上の仮想マシン(VM)に Google Cloud Datalab をデプロイします。
Google Cloud Datalab は、データの探索、分析、可視化のための強力なインタラクティブ ツールです。これは、データ サイエンスと機械学習のタスクに合わせて調整された Jupyter Notebook 環境を提供します。このシナリオでは、いくつかの理由から、Google Compute Engine 上の VM に Google Cloud Datalab をデプロイするのが最適なオプションです。
1. パフォーマンス: Google Cloud Datalab は、十分なコンピューティング リソースを備えた VM にデプロイできるため、データ サイエンティストは、大規模なデータセットを操作したり、複雑な分析を実行したりするための強力なコンピューティング環境にアクセスできます。
2. スケーラビリティ: Google Compute Engine 上の VM は、データ サイエンティストの特定の要件を満たすために、さまざまなレベルの CPU およびメモリ リソースでプロビジョニングできます。このスケーラビリティにより、より大きなデータセットを効率的に操作できます。
3. 統合: Google Cloud Datalab は、Google Cloud Storage、Cassandra、およびその他の Google Cloud Platform サービスとシームレスに統合されます。これにより、データサイエンティストは、単一の環境内で複数のソースからのデータに簡単にアクセスして分析できます。
4. コラボレーション: Google Cloud Datalab はチーム メンバーと共同で共有できるため、データ分析や機械学習プロジェクトでの効果的なコラボレーションが可能になります。
5. バージョン管理: Datalab ノートブックは、Git などのツールを使用してバージョン管理でき、データ分析コードとドキュメントを管理するための構造化された整理されたアプローチを提供します。
Google Cloud Datalab を Google Compute Engine にデプロイすることで、データ サイエンティストはデータ分析、可視化、機械学習のタスクに堅牢で柔軟な環境を提供し、ノートパソコンの限界に関する懸念に対処できます。
参考リンク -
https://cloud.google.com/vertex-ai/docs/workbench/introduction
</div></details>

### Q. 質問19: 未回答
10,000 台の新しい IoT デバイスを導入して、世界中の倉庫の温度データを収集しています。これらのデバイスからのデータは非常に高い速度で生成され、リアルタイムで処理、保存、分析する必要があります。
このプロセスに関連する主な考慮事項と手順は何ですか?
1. 
2. Google Cloud Pub/Sub にデータを送信し、Cloud Pub/Sub を Google Cloud Dataflow にストリーミングして、Google BigQuery にデータを保存します。
3. 
4. 
<details><div>
    答え：2
説明
正しいオプション: B. Google Cloud Pub/Sub にデータを送信し、Cloud Pub/Sub を Google Cloud Dataflow にストリーミングして、Google BigQuery にデータを保存します。
このオプションは、次の理由により、モノのインターネット (IoT) デバイスからの非常に大きなデータセットをリアルタイムで処理、保存、分析する場合に最も適しています。
Google Cloud Pub/Sub の場合:Google Cloud Pub/Sub は、高スループットのリアルタイム データ インジェスト向けに設計されています。これは、IoTデバイスからの受信データストリームを効率的に処理できるメッセージングサービスとして機能します。
Google Cloud データフロー:Google Cloud Dataflow は、フルマネージドのストリームおよびバッチ データ処理サービスです。Cloud Pub/Sub からの受信データをリアルタイムで処理し、必要に応じて変換や集計を適用してから、処理したデータを目的の宛先(Google BigQuery など)に送信できます。
Google BigQueryの場合:Google BigQuery は、大規模なデータセットの高速クエリ用に設計されたサーバーレス データ ウェアハウスおよび分析プラットフォームです。IoTデータをBigQueryに保存することで、データのリアルタイムなクエリと分析が可能になり、倉庫の温度データの監視と分析に適しています。
主な考慮事項は次のとおりです。
データ量:10,000台のIoTデバイスによって生成されるデータは非常に大きくなります。このデータを保存および処理するために必要なインフラストラクチャが整っていることを確認する必要があります。
データ処理の速度: データを迅速に処理できるように、データをリアルタイムで処理する必要があります。大量のデータを処理できるプラットフォームを使用する必要があります。
データのセキュリティ:IoTデバイスによって収集されるデータは機密性が高く、保護する必要があります。不正アクセスからデータを保護できる安全なプラットフォームを使用する必要があります。
ソリューションのスケーラビリティ: 倉庫内の IoT デバイスの数は、将来的に増加する可能性があります。選択したソリューションがスケーラブルであることを確認して、デバイスを簡単に追加できるようにする必要があります。
正しくないオプション -
A. Google Cloud Datastore にデータを送信し、BigQuery にエクスポートします。
Google Cloud Datastore は、よりシンプルなクエリのニーズで構造化データを保存するのに適しています。大規模なIoTデータストレージやリアルタイム分析には理想的な選択肢ではないかもしれません。
Datastore から BigQuery にデータをエクスポートすると、レイテンシが発生する可能性があり、リアルタイム分析に適していない可能性があります。
C. データを Cloud Storage に送信し、分析が必要なときはいつでも、必要に応じて Google Cloud Dataproc で Apache Hadoop クラスタを起動します。
オブジェクト ストレージには Cloud Storage が適していますが、Hadoop クラスタをオンデマンドでスピンアップすると複雑さが増し、リアルタイムの IoT データ処理のための Cloud Dataflow や BigQuery などのマネージド サービスほど費用対効果や拡張性に欠ける可能性があります。
このアプローチは、リアルタイム分析よりもバッチ処理に適しています。
D. ログを Google Cloud Storage にバッチでエクスポートし、Google Cloud SQL インスタンスを起動し、Cloud Storage からデータをインポートして、必要に応じて分析を実行します。
Google Cloud SQLはリレーショナルデータベースサービスであり、大規模なIoTデータの処理には適していない可能性があります。
Cloud SQL でバッチ処理を実行することは、IoT データのリアルタイム分析を実行する最も効率的な方法ではありません。
このアプローチでは、より合理化された Cloud Pub/Sub、Cloud Dataflow、BigQuery パイプラインと比較して、複雑さとレイテンシが生じる可能性があります。
</div></details>

### Q. 質問20: 未回答
CSV ファイルから Google BigQuery テーブル CLICK_STREAMにデータをロードしました。列 DT には、クリック イベントのエポック タイムが格納されます。最初に、すべてのフィールドが STRING 型として扱われる単純なスキーマを選択しました。次に、サイトを訪問するユーザーの Web セッション時間を計算し、DT のデータ型を TIMESTAMP 型に変更します。移行の労力を最小限に抑え、将来のクエリの計算コストが高くならないようにする必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
5. 組み込み関数を使用して列 DT の文字列を TIMESTAMP 値にキャストしながら、テーブルCLICK_STREAMのすべての行を返すクエリを作成します。列 TS が TIMESTAMP 型である宛先テーブル NEW_CLICK_STREAMに対してクエリを実行します。今後は、表CLICK_STREAMの代わりに表NEW_CLICK_STREAM参照します。今後、新しいデータがテーブルNEW_CLICK_STREAMにロードされます。
<details><div>
    答え：5
説明
E. 組み込み関数を使用して列 DT の文字列を TIMESTAMP 値にキャストしながら、テーブルCLICK_STREAMのすべての行を返すクエリを作成します。列 TS が TIMESTAMP 型である宛先テーブル NEW_CLICK_STREAMに対してクエリを実行します。今後は、表CLICK_STREAMの代わりに表NEW_CLICK_STREAM参照します。今後、新しいデータがテーブルNEW_CLICK_STREAMにロードされます。
データ変換: オプション E では、DT 列の文字列を TIMESTAMP 値にキャストするクエリを使用して、既存のテーブル (CLICK_STREAM) 内のデータを変換します。この変換はクエリの実行中に行われるため、元のテーブル スキーマは変更されません。
新しいテーブル: このクエリの結果は、DT 列が TIMESTAMP に変換され、TS という名前が付けられた新しいテーブル (NEW_CLICK_STREAM) に保存されます。このテーブルには、目的のデータ型のデータが含まれます。
最小限の移行作業: データの移動を伴う元のテーブルを削除または再作成する必要はありません。代わりに、適切なスキーマを使用して新しいテーブルを作成します。これにより、移行の労力が最小限に抑えられます。
下位互換性: CLICK_STREAM テーブルを参照する既存のクエリは、変更なしで引き続き機能します。必要に応じて、新しいテーブルを参照するようにクエリを段階的に更新できます。
将来のデータに効率的: 新しいデータをNEW_CLICK_STREAMテーブルに直接ロードできるため、挿入時のデータ変換が不要になります。これにより、将来のデータを効率的に処理できます。
正しくないオプション -
A. テーブルの削除と再作成 (オプション A) は、すべてのデータを再読み込みする必要があるため、時間がかかり、テーブルを参照するクエリの変更が必要になる場合があります。
B. 既存の列 (DT) と並行して新しい列 (TS) を追加し、データを移行する (オプション B) とすると、テーブルが複雑になり、冗長になり、メンテナンスが困難になる可能性があります。
C. ビュー (オプション C) を作成すると、データ型の表示が変更される可能性がありますが、基になるデータ型は実際には変更されず、クエリのパフォーマンスに影響を与える可能性があります。
D. 列 (TS と IS_NEW) を追加し、IS_NEW フラグ (オプション D) に基づいてデータを管理すると、スキーマが不必要に複雑になり、ユース ケースの効率的なソリューションではない可能性があります。
</div></details>

### Q. 質問21: 未回答
Google Stackdriver Logging を使用して Google BigQuery の使用状況をモニタリングしたい。挿入ジョブを使用して特定のテーブルに新しいデータが追加されたときに即座に通知を受け取る必要がありますが、他のテーブルの通知は受け取りたくない。
どうすればこれを実現できますか?
1. 
2. 
3. 
4. Stackdriver API を使用して、Pub/Sub にエクスポートする高度なログ フィルタを含むプロジェクト シンクを作成し、モニタリング ツールからトピックをサブスクライブします。
<details><div>
    答え：4
説明
D. Stackdriver API を使用して、Pub/Sub にエクスポートする高度なログ フィルタを含むプロジェクト シンクを作成し、モニタリング ツールからトピックをサブスクライブします。
このオプションでは、Stackdriver API を使用して、特定のログエントリを Google Cloud Pub/Sub にエクスポートするカスタムログシンクを作成します。
高度なログフィルタを使用すると、Pub/Sub トピックにエクスポートするログエントリを正確に定義できます。この場合、BigQuery の挿入ジョブを使用して特定のテーブルに新しいデータが追加されたときに通知を受け取り、それに応じてフィルタを設定できます。
Stackdriver API は、ログのエクスポートをきめ細かく制御できるため、特定の要件に合わせてログのエクスポートを調整する必要がある、より複雑なユースケースに適しています。
モニタリング ツールから Pub/Sub トピックをサブスクライブすると、フィルタ条件に一致する新しいログエントリがパブリッシュされたときにリアルタイムで通知を受け取ることができます。
正しくないオプション -
A. Stackdriver API を呼び出してすべてのログを一覧表示し、高度なフィルタを適用します。
このオプションでは、Stackdriver API を使用してすべてのログを手動で一覧表示し、高度なフィルタを適用することを提案します。この方法でログをフィルタリングすることはできますが、ログが多数ある場合や、リアルタイムの通知が必要な場合は、実用的なアプローチではありません。
B.Stackdriver のログ管理インターフェースで、BigQuery へのログシンクのエクスポートを有効にします。
このオプションでは、ログシンクを使用してログを BigQuery にエクスポートし、分析と保存に役立てることができます。ただし、求めているリアルタイム通知機能は提供されません。これは、長期的なログ ストレージとクエリに重点を置いています。
C. Stackdriver のログ管理インターフェースで、Google Cloud Pub/Sub へのログシンクのエクスポートを有効にし、モニタリング ツールからトピックをサブスクライブします。
このオプションは、リアルタイムのイベントドリブン ワークフローで一般的に使用される Pub/Sub の使用に言及することで、正しい方向に進んでいます。ただし、BigQuery で特定のテーブルの挿入ジョブの通知のみを受信するという特定の要件は考慮されていません。高度なフィルタを使用しない場合、すべてのログが Pub/Sub に送信されます。
</div></details>

### Q. 質問22: 未回答
プライベートなユーザーデータを含む機密性の高いプロジェクトに取り組んでいる。Google Cloud Platform にプロジェクトを設定し、社内で作業を格納しました。外部コンサルタントが、プロジェクトの Google Cloud Dataflow パイプラインでの複雑な変換のコーディングを支援します。ユーザーのプライバシーをどのように保護する必要がありますか?
1. 
2. 
3. 
4. コンサルタントが別のプロジェクトで作業するためのデータの匿名化されたサンプルを作成することです。
<details><div>
    答え：4
説明
正解は、オプション D: コンサルタントが別のプロジェクトで作業するためのデータの匿名化されたサンプルを作成することです。
オプションDは、データのプライバシーとセキュリティを優先するため、正しい選択です。これには、次の手順が含まれます。
1. データの匿名化: 外部コンサルタントとデータを共有する前に、機密性の高いユーザーデータのサニタイズまたは匿名化されたサンプルを作成します。これは、プライバシーを確保するために、個人を特定できる情報(PII)や機密情報を削除または難読化することを意味します。
2. 別のプロジェクト: コンサルタントが作業する別のプロジェクトまたは環境を設定します。このプロジェクトには、匿名化されたデータセットと、Dataflow パイプラインの開発に必要なツールが含まれています。
3. コラボレーション: コンサルタントは、実際の機密データにアクセスすることなく、この制御された環境内でコラボレーションを行うことができます。匿名化されたデータセットを使用して Dataflow パイプラインを開発、テスト、最適化できます。
正しくないオプション -
A. オプション A では、コンサルタントにプロジェクトの閲覧者ロールを付与することを提案します。これにより、すべてのリソースへの読み取り専用アクセスが許可されますが、データのプライバシーや分離には対処されません。
B. オプション B では、コンサルタントにプロジェクトの Cloud Dataflow デベロッパー ロールを付与することをおすすめします。Dataflow パイプラインの開発は可能ですが、データのプライバシーを確保したり、コンサルタントの作業を機密データから分離したりすることはできません。
C. オプション C では、アクセスを管理する方法であるサービス アカウントの作成について言及していますが、データのプライバシーと分離を維持する方法は指定されていません。通常、サービス アカウントは認証と承認に使用されますが、データ アクセスを制御するには慎重に構成する必要があります。
</div></details>

### Q. 質問25: 未回答
あなたの会社は、工場の現場から Bigtable にリアルタイムのセンサー データをストリーミングしています。このデータは、リアルタイムのダッシュボードに入力するために使用されています。ただし、ダッシュボードに入力するクエリのパフォーマンスは低下します。クエリのパフォーマンスを向上させるために、行キーをどのように再設計する必要がありますか?
1. 
2. 
3. 
4. #<sensorid>#<timestamp>
<details><div>
    答え：4
説明
D. >#<sensorid>#<timestamp> という形式の行キーを使用します。
Bigtable では、行キーの選択は、データへのアクセス方法やクエリ方法など、さまざまな要因によって異なります。行キーとして #<sensorid>#<timestamp> を使用すると、リアルタイム ダッシュボード クエリのパフォーマンスが向上する場合は、それが正しい選択です。この形式は、特にクエリにセンサー ID とタイムスタンプによるフィルター処理が頻繁に含まれる場合に、データの分散とアクセス パターンに役立つ可能性があります。
参考リンク -
https://cloud.google.com/bigtable/docs/schema-design
</div></details>

### Q. 質問26: 未回答
多くの場合、会社の顧客データベースと注文データベースには大きな負荷がかかっています。これにより、運用に支障をきたすことなく分析を実行することが困難になります。データベースはMySQLクラスタ内にあり、mysqldumpを使用して夜間バックアップが取得されます。運用への影響を最小限に抑えて分析を実行したい。あなたは何をするべきか?
1. 
2. ETL ツールを使用して、MySQL から Google BigQuery にデータをロードします。
3. 
4. 
<details><div>
    答え：2
説明
B. ETL ツールを使用して、MySQL から Google BigQuery にデータをロードします。
その理由は次のとおりです。
最小限の影響:ETL(抽出、変換、ロード)ツールを使用してGoogle BigQueryにデータをロードすると、運用中のMySQLクラスタに大きな影響を与えることなく分析を実行できます。ETLプロセスは、中断を最小限に抑えるために、オフピーク時にスケジュールできます。
スケーラビリティ: Google BigQuery は、大規模なデータ分析を処理するように設計されています。大規模なデータセットを効率的に処理およびクエリできるため、ソースMySQLクラスタに過負荷をかけることなく分析タスクに適しています。
懸念事項の分離: データを BigQuery に移動することで、分析ワークロードをオペレーショナル データベースから分離します。この分離は、分析タスクが顧客データベースと注文データベースのパフォーマンスと可用性に影響を与えないようにするためのベストプラクティスです。
リアルタイム分析: Google BigQuery はリアルタイムのデータストリーミングをサポートしているため、データが利用可能になったときにデータを取り込むことができます。これは、夜間のバックアップを待たずにほぼリアルタイムの分析を行うのに役立ちます。
正しくないオプション -
MySQL クラスターにノードを追加する (オプション A) やオンプレミスの Apache Hadoop クラスターに接続する (オプション C) などのオプションは分析に役立つ可能性がありますが、ソース データベースに追加の負荷がかかる可能性があります。Google Cloud Dataproc とバックアップを含むオプション D も機能しますが、分析に BigQuery を直接使用するほど簡単で効率的ではない可能性があります。したがって、ETLプロセスでGoogle BigQueryを使用することが、このユースケースに推奨されるアプローチです。
</div></details>

### Q. 質問27: 未回答
Google Cloud Dataflow ストリーミング パイプラインが実行されており、Google Cloud Pub/Sub サブスクリプションからデータを受信している。このパイプラインのコードを更新する必要がありますが、この更新により、新しいパイプラインは現在のパイプラインと互換性がなくなります。この更新を行うときにデータが失われないようにします。
データが失われないようにするには、どのような手順を踏む必要がありますか?
1. 現在のパイプラインを更新し、"drain" フラグを使用します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解: A. 現在のパイプラインを更新し、"drain" フラグを使用します。
Google Cloud Pub/Sub サブスクリプションをソースとして Google Cloud Dataflow ストリーミング パイプラインを実行している場合、その過程でデータを失うことなくパイプラインを更新することが不可欠です。「drain」フラグは、この目的のために Dataflow が提供する機能です。その仕組みは次のとおりです。
現在のパイプライン コードを更新して「drain」フラグを使用すると、すでに転送中または処理中の既存のデータの処理を続行するように Dataflow に指示されます。
同時に、Dataflow は Pub/Sub サブスクリプションから新しいデータを受け付けません。これにより、移行中にデータが失われることはありません。
既存のデータは、完全に処理されるまでパイプラインを通過し続け、データが取り残されないようにします。
正しくないオプション -
B. 現在のパイプラインを更新し、変換マッピング JSON オブジェクトを指定します。
このオプションでは、更新中のデータの継続性の問題には対処されません。変換マッピング JSON オブジェクトを提供するだけでは、データが中断されることなく処理されるとは限りません。
C. 同じ Cloud Pub/Sub サブスクリプションを持つ新しいパイプラインを作成し、古いパイプラインをキャンセルします。
新しいパイプラインを作成し、古いパイプラインを取り消すと、データ処理が中断されます。更新中のデータ損失を回避する必要がある場合は、適切なソリューションではありません。
D. 新しい Cloud Pub/Sub サブスクリプションを持つ新しいパイプラインを作成し、古いパイプラインをキャンセルします。
同様に、新しいサブスクリプションで新しいパイプラインを作成し、古いパイプラインを取り消すと、データが失われ、データ処理が中断されます。
参考リンク -
https://cloud.google.com/dataflow/docs/guides/stopping-a-pipeline
</div></details>

### Q. 質問28: 未回答
あなたの会社は、ホリデーシーズン中にリアルタイムデータを分析して様々なオファーを提供する、最初の動的キャンペーンを実施しています。データサイエンティストは、30日間のキャンペーン期間中、毎時間急速に増加するテラバイトのデータを収集しています。Google Cloud Dataflow を使用してデータを前処理し、Google Cloud Bigtable の機械学習モデルに必要な特徴量(シグナル)データを収集しています。チームは、10 TB のデータの初期読み込みの読み取りと書き込みで、最適ではないパフォーマンスを観察しています。彼らは、コストを最小限に抑えながら、このパフォーマンスを向上させたいと考えています。彼らは何をすべきか?
1. 表の行スペースに読み取りと書き込みを均等に分散して、スキーマを再定義します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解は:
A. 表の行スペースに読み取りと書き込みを均等に分散して、スキーマを再定義します。
この回答は、Google Cloud Bigtable のパフォーマンスを向上させるには、読み取りと書き込みがテーブルの行スペース全体に均等に分散されるようにスキーマを慎重に設計する必要があることを示唆しています。つまり、特定の行が不釣り合いに多くの操作 (読み取りまたは書き込み) を受け取るデータ内のホットスポットを防ぐことを目的としています。アクセス パターンを均等に分散することで、Bigtable のスケーラビリティと並列処理を効果的に活用できます。
正しくないオプション -
B.パフォーマンスの問題は、Bigtable クラスタのサイズが大きくなるにつれて、時間の経過とともに解決されるはずです。
Bigtable クラスタのサイズを大きくすると、大量のデータのスケーリングと処理に役立ちますが、基盤となるスキーマが最適でない場合は、パフォーマンスの問題に直接対処できない可能性があります。スキーマ設計を改善すると、多くの場合、パフォーマンスの問題に対処する方が効果的です。
C. 1 つの行キーを使用して、クラスター内で頻繁に更新する必要がある値を識別するようにスキーマを再設計します。
頻繁に更新される値に 1 つの行キーを使用すると、特定のユースケースでは役立ちますが、Bigtable の全体的なパフォーマンスの問題に対する主要な解決策にはならない場合があります。読み取りと書き込みを均等に分散するという問題に必ずしも対処できるわけではありません。
D. オファーを表示するユーザーごとに順番に増加する数値 ID に基づく行キーを使用するようにスキーマを再設計します。
行キーで連続した数値 ID を使用すると、一部のシナリオでは有益な場合がありますが、Bigtable の全体的なパフォーマンスの問題に対処するには十分ではない場合があります。これは、操作の均等な分散を確保することよりも、データ編成に重点を置いています。
参考リンク -
ビッグテーブルパフォーマンス
</div></details>

### Q. 質問29: 未回答
すべてのメッセージに単純な JSON 形式を使用するソフトウェア アプリケーションを開発しています。これらのメッセージは Google Cloud Pub/Sub に公開され、Google Cloud Dataflow で処理されて CFO 向けのリアルタイム ダッシュボードが作成されます。テスト中に、ダッシュボードに一部のメッセージが表示されないことに気付きました。ログを確認すると、すべてのメッセージが Cloud Pub/Sub に正常にパブリッシュされています。
問題のトラブルシューティングを行うには、次に何をする必要がありますか?
1. 
2. Cloud Dataflow パイプラインで固定データセットを実行し、出力を分析します。
3. 
4. 
<details><div>
    答え：2
説明
B. Cloud Dataflow パイプラインで固定データセットを実行し、出力を分析します。
これにより、問題がパイプラインにあるのか、ダッシュボードアプリケーションにあるのかを判断できます。出力を分析することで、メッセージが正しく処理されているかどうかを確認し、不一致や欠落しているメッセージがあるかどうかを判断できます。問題がパイプラインにある場合は、デバッグして必要な更新を行い、すべてのメッセージが正しく処理されるようにすることができます。ダッシュボード アプリケーションに問題がある場合は、その問題の解決に集中できます。
このアプローチにより、制御された効率的な方法で、欠落しているメッセージの根本原因を分離して特定できます。
</div></details>

### Q. 質問30: 未回答
あなたの会社は最近急速に成長し、以前よりも大幅に高い速度でデータを取り込んでいます。毎日のバッチ MapReduce 分析ジョブは、Apache Hadoop で管理します。しかし、最近のデータの増加により、バッチジョブは遅れをとっています。開発チームがコストを増やさずに分析の応答性を向上させる方法を推奨するように求められました。あなたは彼らに何をすることを勧めるべきですか?
1. 
2. Apache Spark でジョブを書き換える
3. 
4. 
<details><div>
    答え：2
説明
正解 - オプション B. Apache Spark でジョブを書き換える
Apache Spark は、既存の Hadoop インフラストラクチャを考慮すると、コストを大幅に増やすことなく分析ジョブの応答性を向上させるのに非常に適した選択肢です。これが正解である理由は次のとおりです。
パフォーマンスの向上:Apache Spark はインメモリ処理用に設計されているため、従来の Hadoop MapReduce と比較して、分析ジョブの実行が大幅に高速化されます。これは、バッチ ジョブをより迅速に完了できることを意味します。
使いやすさ:Sparkは、Scala、Python、Javaなどの言語で高レベルのAPIを提供し、開発者にとってより使いやすいものになっています。これにより、開発が迅速化され、分析ジョブのメンテナンスが容易になります。
資源効率:データをメモリにキャッシュする Spark の機能により、Hadoop 分散ファイル システム (HDFS) からの反復読み取りの必要性を減らすことができます。これにより、Hadoopクラスターへの負担が軽減され、データ取り込み速度の増加に追いつくことができる可能性があります。
互換性：SparkはHadoopとシームレスに統合できるため、既存のHadoopデータとインフラストラクチャを再利用できます。つまり、エコシステムを完全に見直すことなくSparkに移行できます。
正しくないオプション -
オプションA:Pigでジョブを書き換える
Pig は MapReduce プログラムを作成するための高レベルのプラットフォームですが、Apache Spark と同じレベルのパフォーマンス向上は提供されない可能性があります。Pig 自体は MapReduce フレームワークに依存しているため、データ インジェスト レートの増加に効果的に対処する能力が制限される可能性があります。
オプション C: Hadoop クラスターのサイズを増やす
ノードを追加してHadoopクラスタをスケールアップすると、パフォーマンスが向上する可能性がありますが、インフラストラクチャのコストも増加します。さらに、スケールアップでは、特に分析ジョブが現在クラスター サイズではなく処理速度によってボトルネックになっている場合は、応答性の問題に完全に対処しない可能性があります。
オプション D: Hadoop クラスターのサイズを小さくするが、Hive のジョブも書き換える
クラスターのサイズを小さくすると、コストが削減される可能性がありますが、パフォーマンスは向上しない可能性があります。さらに、Hadoop の別のクエリ言語である Hive でジョブを書き換えても、Hive のバッチ指向処理の性質上、Spark と同じパフォーマンス上の利点が得られない可能性があります。
</div></details>

### Q. 質問31: 未回答
あなたは製造工場のデータエンジニアです。プラントは、毎日午前 2:00 に、プラントのすべてのマシンからのアプリケーション ログを含む <> つのログ ファイルを生成します。このログファイルを処理する Google Cloud Dataflow ジョブを作成しました。ログ ファイルは <> 日に <> 回、できるだけ安価に処理する必要があります。
あなたは何をするべきか?
1. 
2. 
3. Google App Engine Cron サービスを使用して cron ジョブを作成し、Cloud Dataflow ジョブを実行します。
4. 
<details><div>
    答え：3
説明
正解 - オプション C: Google App Engine Cron サービスを使用して cron ジョブを作成し、Cloud Dataflow ジョブを実行します。
Google App Engine Cron Service では、毎日午前 2:00 など、指定した間隔でタスクをスケジュールでき、ログファイルを <> 日に <> 回処理するという要件に合わせることができます。
このアプローチにより自動化が実現し、手動による介入なしに Dataflow ジョブが目的の時間に実行されるようになります。
これは、ジョブの実行時にのみコストが発生し、ログ ファイルのバッチ処理に合わせてスケジュールできるため、費用対効果の高いソリューションです。
正しくないオプション -
オプション A: 代わりに Google Cloud Dataproc を使用するように処理ジョブを変更します。
Google Cloud Dataproc は、Hadoop や Spark ジョブなどの分散データ処理タスクの実行には適していますが、毎日のログファイルを処理するだけではやり過ぎかもしれません。
Dataproc に移行するには、既存の Dataflow ジョブを書き直して調整する必要があるため、複雑さが増し、コストが高くなる可能性があります。
オプション B: 毎朝オフィスに出社したら、Cloud Dataflow ジョブを手動で開始します。
このアプローチでは、高レベルの手動介入と人間の操作への依存が導入され、エラー、遅延、信頼性の欠如につながる可能性があります。
これは、午前 2:00 に実行される自動化された毎日のプロセスの要件とうまく一致しません。
オプション D: Cloud Dataflow ジョブをストリーミング ジョブとして構成し、ログデータをすぐに処理します。
バッチ ジョブをストリーミング ジョブに変換すると、データの処理方法が根本的に変わります。ストリーミング ジョブは、特定の時間に毎日バッチ処理を行うのではなく、リアルタイムのデータ処理用に設計されています。
このオプションでは、リアルタイム処理が必要でない場合、不必要な複雑さとコストが発生する可能性があります。
</div></details>

### Q. 質問32: 未回答
あなたは経済コンサルティング会社のデータエンジニアです。あなたの仕事は、顧客データを最も一般的な 100 の商品の平均価格と関連付けることにより、企業が経済動向を特定できるように支援することです。これらの商品の平均価格は30分ごとに更新されます。このデータを常に最新の状態に保ち、BigQuery の他のデータとできるだけ安価に組み合わせられるようにする必要があります。
あなたは何をするべきか?
1. 
2. リージョンの Google Cloud Storage バケットにデータを保存して更新し、BigQuery でフェデレーテッドデータソースを作成します。
3. 
4. 
<details><div>
    答え：2
説明
正しいオプションは次のとおりです。
B. リージョンの Google Cloud Storage バケットにデータを保存して更新し、BigQuery でフェデレーテッドデータソースを作成します。
Google Cloud Storage バケット:リージョンの Google Cloud Storage バケットにデータを保存して更新することは、費用対効果が高く効率的なアプローチです。バケット内のデータは、必要な頻度 (この場合は 30 分ごと) に更新できます。
BigQuery のフェデレーテッド データソース:BigQuery でフェデレーション データソースを作成すると、Google Cloud Storage などの外部の場所に保存されているデータを、BigQuery テーブルに読み込まなくてもクエリできます。これにより、BigQuery 内で追加のストレージ コストが発生しないため、コストが低く抑えられます。
正しくないオプション -
A. BigQuery の新しいパーティション テーブルに 30 分ごとにデータを読み込みます。
30 分ごとに BigQuery テーブルにデータを読み込むと、蓄積される履歴データが増えるため、ストレージ費用が増加する可能性があります。
パーティション分割はクエリのパフォーマンス向上に役立ちますが、長期的にはコストが高くなるため、BigQuery テーブルにデータを読み込む必要がなくなるわけではありません。
C. Google Cloud Datastore にデータを保存します。Google Cloud Dataflow を使用して BigQuery をクエリし、Cloud Datastore に保存されているデータとプログラムでデータを結合します。
このアプローチでは、不必要な複雑さと追加サービス(Cloud Datastore と Dataflow)が導入されます。
Datastore は主に NoSQL データベースであり、商品の平均価格などの時系列データには理想的なストレージ ソリューションではない可能性があります。
外部データのクエリを簡素化できる BigQuery のフェデレーション データソース機能は利用されません。
D. リージョンの Google Cloud Storage バケット内のファイルにデータを格納します。Cloud Dataflow を使用して BigQuery をクエリし、Google Cloud Storage に保存されているデータとプログラムでデータを結合します。
Dataflow を使用して BigQuery をクエリし、プログラムでデータを結合することは、フェデレーション データソースのアプローチと比較して、より複雑でコストがかかる可能性があります。
また、BigQuery から直接データをクエリする場合と比較して、追加の処理オーバーヘッドが必要になります。
</div></details>

### Q. 質問33: 未回答
会社では、カンマ区切り値(CSV)ファイルを Google BigQuery に読み込んでいます。データは正常にインポートされましたが、BigQuery のデータはソース ファイルのデータとバイト単位で一致していません。この不一致の最も可能性の高い原因は何ですか?
1. 
2. 
3. BigQuery に読み込まれた CSV データが BigQuery のデフォルトのエンコードを使用していない。
4. 
<details><div>
    答え：3
説明
C. BigQuery に読み込まれた CSV データが BigQuery のデフォルトのエンコードを使用していない。
正解は、BigQuery に読み込まれた CSV データが正しいエンコードを使用していない場合に、インポートされたデータとソース ファイルの間に不一致が発生する可能性があるということです。BigQuery では、データがデフォルトで UTF-8 エンコードであることを前提としています。CSV ファイルで ISO-8859-1 などの異なる文字エンコードが使用されている場合、文字のバイト表現に違いが生じ、データの不一致が生じる可能性があります。
正しくないオプション -
ある。BigQuery に読み込まれた CSV データに CSV のフラグが設定されていない: このオプションは、バイト間の一致の問題とは直接関係ありません。データに CSV としてフラグを設定することは形式仕様ですが、エンコードの違いには対応しません。
イ.CSV データには、インポート時にスキップされた無効な行があります: このオプションは、データ品質と潜在的な行スキップに関連していますが、ソース ファイルとインポートされたデータのバイト表現の違いを直接説明するものではありません。
D.CSV データが BigQuery に読み込まれる前に ETL フェーズを経ていない: データの準備には ETL(抽出、変換、読み込み)プロセスが不可欠ですが、ETL プロセスがないことが、インポートされたデータのバイトレベルの違いの主な原因ではありません。
ソースファイルとインポートしたデータのバイト単位の違いの問題を解決するには、CSV データが UTF-8(BigQuery で想定されるデフォルトのエンコード)で適切にエンコードされていることを確認します。このエンコードの一貫性は、インポート プロセス中にバイト間の一致を維持するのに役立ちます。
</div></details>

### Q. 質問34: 未回答
あなたの会社では、毎時 20,000 個のファイルが作成されています。各データ ファイルは、4 KB 未満のカンマ区切り値 (CSV) ファイルとして書式設定されます。すべてのファイルは、処理する前に Google Cloud Platform に取り込む必要があります。会社のサイトから Google Cloud へのレイテンシは 200 ミリ秒で、インターネット接続帯域幅は 50 Mbps に制限されています。現在、Google Compute Engine の仮想マシンにセキュアな FTP(SFTP)サーバーをデータ インジェスト ポイントとしてデプロイしています。ローカルのSFTPクライアントは、CSVファイルをそのまま送信するために専用マシン上で実行されます。目標は、毎日午前 10:00 までに前日のデータを含むレポートをエグゼクティブが利用できるようにすることです。この設計は、帯域幅の使用率がかなり低いにもかかわらず、現在のボリュームにほとんど追いつくことができません。季節性により、今後 <> か月間にファイル数が <> 倍になると予想されているとします。どの <> つのアクションを実行する必要がありますか?(<>つ選択してください。
1. 
2. 
3. gsutil ツールを使用して CSV ファイルをストレージ バケットに並行して送信するように、データ インジェスト プロセスを再設計します。
4. 1,000 個のファイルをテープ アーカイブ (TAR) ファイルにアセンブルします。代わりにTARファイルを送信し、受信時にクラウド内のCSVファイルを逆アセンブルします。
<details><div>
    答え：3,4
説明
C. gsutil ツールを使用して CSV ファイルをストレージ バケットに並行して送信するように、データ インジェスト プロセスを再設計します。
gsutil を使用して CSV ファイルを Google Cloud Storage バケットに並行して送信することは、利用可能な帯域幅を活用し、増加したデータ量を効率的に処理するための効果的な方法です。
D. 1,000 個のファイルをテープ アーカイブ (TAR) ファイルにアセンブルします。代わりにTARファイルを送信し、受信時にクラウド内のCSVファイルを逆アセンブルします。
TAR ファイルは、複数のファイルを 1 つのアーカイブにバンドルするためによく使用され、多数の小さなファイルを転送するオーバーヘッドを削減できます。TARファイルの送信は、特にファイルが小さくて数が多い場合に、データ転送を最適化する効果的な方法です。転送後にクラウドで分解すると、データ処理に役立ちます。
</div></details>

### Q. 質問35: 未回答
あなたは、何百万ものIoTデバイスからのテレメトリデータを格納するためのNoSQLデータベースを選択する任務を負っています。データ量は年間 100 TB で増加しており、各データ エントリには約 100 個の属性があります。データ処理パイプラインは ACID 準拠を必要としませんが、高可用性と低待機時間が必要です。また、個々のフィールドに対してクエリを実行してデータを分析できる必要もあります。
これらの要件を満たす 3 つの NoSQL データベースはどれですか?
1. 
2. HBase
3. 
4. MongoDB
5. Cassandra
<details><div>
    答え：2,4,5
説明
正解-
B. HBase: HBase は、高可用性と低遅延で大量のデータを処理するのに適した分散 NoSQL データベースです。大規模なデータセットを格納して管理するように設計されているため、IoT テレメトリ データに適しています。
D. MongoDB:MongoDBは、スキーマ設計に柔軟性を提供し、大量のデータを処理できるNoSQLデータベースです。スケーラビリティに定評があり、リアルタイムのデータ分析とクエリに使用できます。
E. Cassandra: Cassandra は、高可用性、低遅延、スケーラビリティを提供する分散型 NoSQL データベースです。大規模なデータセットを処理するように設計されており、リアルタイム分析に使用できるため、IoT データ処理に適しています。
正しくないオプション -
A. Redis: Redis は、主にキャッシュとキー値ストアとして使用されるインメモリ データ ストアです。低遅延の点では優れていますが、メモリ内の性質上、容量が制限され、大規模なデータセットの保存にコストがかかる可能性があるため、大量の IoT テレメトリ データの保存とクエリには理想的な選択肢ではない可能性があります。
C. MySQL:MySQLは、ACID準拠とデータの一貫性で知られるリレーショナルデータベース管理システム(RDBMS)です。ただし、個々のフィールドの取り込みとクエリの速度が高い大量の IoT データの場合は、柔軟性とスケーラビリティが高いため、MongoDB、Cassandra、HBase などの NoSQL データベースの方が適している場合があります。
F. HDFS と Hive: Hive と組み合わせた HDFS (Hadoop Distributed File System) は、Hadoop エコシステムを使用したビッグ データの保存とクエリの一般的なソリューションです。ただし、バッチ処理と分析に特化しているため、IoT データ処理に必要な低遅延のリアルタイム クエリ機能は提供されない場合があります。
</div></details>

### Q. 質問36: 未回答
スパム分類子をトレーニングしています。学習データを過剰適合していることに気付きます。この問題を解決するために実行できる 3 つのアクションはどれですか?(3つ選択してください。
1. より多くのトレーニング例を取得する
2. 
3. より小さな特徴セットを使用する
4. 
5. 正則化パラメーターを増やす
6. 
<details><div>
    答え：1,3,5
説明
正解-
A. より多くのトレーニング例を取得する: より多くのトレーニング例を取得することは、モデルの一般化に役立つため、過学習を減らすための一般的な方法です。
C. より小さな特徴セットを使用する: 特徴の数を減らすと、モデルが単純化され、過学習を減らすことができます。このアクションは効果的です。
E. 正則化パラメーターを増やす: L1 または L2 正則化の強度などの正則化パラメーターを増やすと、複雑なモデルにペナルティを課すことで過学習を減らすことができます。したがって、このアクションも有効なアプローチです。
正しくないオプション -
B. 学習例の数を減らす: 学習例の数を減らすと、通常、過学習の問題が悪化します。一般に、トレーニング例が多いと、モデルが一般化をより適切に学習するのに役立ちます。これらを減らすと、モデルがさらに過剰適合する可能性があります。
D. より多くの特徴セットを使用する: 特徴の数を増やすと、モデルが複雑になるため、過学習が悪化する可能性があります。新しい特徴が適切でなかったり、ノイズが発生したりすると、モデルがトレーニング データに近づきすぎて、過学習が発生する可能性があります。
F. 正則化パラメーターを減らす: L1 または L2 正則化の強度を下げるなど、正則化パラメーターを減らすと、過学習が増加する傾向があります。正則化は、モデルがトレーニング データに近づきすぎないようにするために使用されます。これらのパラメーターを減らすと、モデルがより複雑になり、データが過剰適合する可能性があります。
</div></details>

### Q. 質問41: 未回答
あなたの会社は、多数のニューロンと層を持つ TensorFlow ニューラルネットワークモデルを構築しました。モデルはトレーニング データによく適合しますが、新しいデータに対してテストするとパフォーマンスが低下します。
この問題に対処するためにどのような方法を採用できますか?
1. 
2. 
3. ドロップアウト方法
4. 
<details><div>
    答え：3
説明
TensorFlow ニューラル ネットワーク モデルがトレーニング データではうまく機能し、新しいデータではパフォーマンスが低いという問題に対処するには、以下を使用できます。
C. ドロップアウト方法
ドロップアウトは、深層学習で過学習を防ぐために一般的に使用される正則化手法です。過学習は、モデルがトレーニング データから一般化するのではなく、トレーニング データを記憶することを学習するときに発生し、新しい未知のデータのパフォーマンスが低下する可能性があります。ドロップアウトは、学習中にニューロンの一部をランダムに「ドロップアウト」することで過学習を軽減し、ネットワークに、よりロバストで一般化された特徴を学習させるのに役立ちます。
ドロップアウトの仕組みは次のとおりです。
1.トレーニング中、フォワードパスとバックワードパスごとに、ニューロンのランダムなサブセットが特定の確率(ドロップアウト率)で非アクティブ化(ゼロに設定)されます。これは、一部のニューロンがその特定の反復の計算から「ドロップアウト」されることを意味します。
2.ニューロンをドロップアウトすることで、モデルは個々のニューロンや特徴への依存度が低くなり、より堅牢になり、過剰適合する可能性が低くなります。
3.推論(テストまたは予測)中、ドロップアウトは通常オフになり、すべてのニューロンが予測に使用されます。
TensorFlow ニューラルネットワークでドロップアウト法を使用することで、トレーニングデータから新しい未知のデータに一般化する機能を向上させ、テストデータのパフォーマンス低下の問題に対処できる可能性があります。
正しくないオプション -
スレッド化 (オプション A) とシリアル化 (オプション B) は、ニューラル ネットワーク モデルの過学習の軽減や一般化の改善には直接関係しません。
次元削減 (オプション D) は、データセット内の特徴の数を減らすために使用される手法であり、特定の状況でモデルの複雑さを軽減し、汎化を改善するのに役立ちます。ただし、ドロップアウト法は、モデルがトレーニング データにうまく適合するが、新しいデータではパフォーマンスが低い場合に一般的な問題であるディープ ニューラル ネットワークの過学習に対処するのにより直接的に適しています。
参考リンク -
ドロップアウト方式
</div></details>

### Q. 質問42: 未回答
衣料品のレコメンデーションを行うモデルを構築しています。ユーザーのファッションの好みは時間の経過とともに変化する可能性が高いことがわかっているので、新しいデータが利用可能になったときにモデルにストリーミングするデータ パイプラインを構築します。
このデータを使用してモデルをトレーニングするにはどうすればよいでしょうか。
1. 
2. 既存のデータと新しいデータの組み合わせでモデルを継続的に再トレーニングします。
3. 
4. 
<details><div>
    答え：2
説明
衣料品のレコメンデーションを目的としており、ユーザーのファッションの好みが時間の経過と共に変化する可能性が高いモデルの場合、モデルのトレーニングに新しいデータを使用する最適なアプローチは次のとおりです。
B. 既存のデータと新しいデータの組み合わせでモデルを継続的に再トレーニングします。
履歴ナレッジの保持: 既存のデータと新しいデータの組み合わせでモデルを継続的に再トレーニングすることで、モデルがユーザーの好みに関する知識を長期にわたって保持できるようにします。ファッションのトレンドやユーザーの嗜好は進化しますが、過去の嗜好やトレンドに関する貴重な情報も履歴データに含まれています。既存のデータと新しいデータを組み合わせることで、モデルは古いパターンと最近のパターンの両方から学習できます。
コンセプトのずれを防ぐ:ユーザーの嗜好は徐々に変化し、特定のファッションの嗜好が安定している期間があるかもしれません。新しいデータのみで継続的に再トレーニングを行うと (オプション A)、モデルが最近の傾向に過剰適合し、過去の好みに基づいて推奨事項を提供する機能が失われる可能性があります。古いデータと新しいデータの組み合わせで再トレーニングを行うことで、概念のずれを防ぐことができます。
評価と検証: 既存のデータをトレーニング データセットの一部として使用すると、履歴データに対するモデルのパフォーマンスを検証でき、モデルが好みの変化にどの程度適応できるかの尺度として機能します。その後、新しいデータに対するモデルのパフォーマンスも評価できます。
バランスの取れたトレーニング: 古いデータと新しいデータを組み合わせることで、時間の経過に伴うさまざまなユーザーの好みや傾向を反映したバランスの取れたデータセットを作成できます。これにより、モデルをより適切に一般化し、最近のデータに偏らないレコメンデーションを行うことができます。
正しくないオプション -
オプション C (新しいデータをテスト セットとして使用しながら既存のデータでトレーニングする) とオプション D (既存のデータをテスト セットとして使用しながら新しいデータでトレーニングする) は、トレーニングに完全なデータセットを利用しないため、通常、このシナリオには適していません。モデルが履歴データと新しいデータの両方から学習して、最も正確で適応性の高いレコメンデーションを提供する必要があります。
</div></details>

### Q. 質問44: 未回答
Google Kubernetes Engine(GKE)上で動作するデータ処理アプリケーションがあります。コンテナーは、コンテナー レジストリから使用可能な最新の構成で起動する必要があります。GKE ノードには、GPU、ローカル SSD、8 Gbps の帯域幅が必要です。データ処理インフラストラクチャを効率的にプロビジョニングし、デプロイ プロセスを管理する必要があります。
あなたは何をするべきか?
1. 
2. Cloud Build を使用して Terraform ビルドを使用してジョブをスケジュールし、インフラストラクチャをプロビジョニングし、最新のコンテナ イメージで起動します。
3. 
4. 
<details><div>
    答え：2
説明
GPU、ローカル SSD、および 8 Gbps 帯域幅を使用してデータ処理インフラストラクチャを効率的にプロビジョニングし、展開プロセスを管理するには、オプション B が最適です。
B. Cloud Build を使用して Terraform ビルドを使用してジョブをスケジュールし、インフラストラクチャをプロビジョニングし、最新のコンテナ イメージで起動します。
Cloud Build: Cloud Build は、アプリケーションをビルド、テスト、デプロイできるマネージド CI / CD サービスです。これを使用して、コンテナー イメージをビルドおよびデプロイするための自動化されたワークフローを作成できます。Cloud Build でジョブをスケジュールすることで、インフラストラクチャとコンテナを常に最新の状態に保つことができます。
Terraform: Terraform は、宣言的な方法でインフラストラクチャを定義およびプロビジョニングできる一般的なコードとしてのインフラストラクチャ (IaC) ツールです。Terraform を使用して、GPU、ローカル SSD、ネットワーク構成など、必要な仕様で GKE クラスタを作成、管理できます。
コンテナ イメージ: Cloud Build は、ソースコードやコンテナ構成に変更があった場合に、最新のコンテナ イメージをビルドしてコンテナ レジストリにプッシュするように設定できます。これにより、コンテナーで常に最新のイメージが使用されるようになります。
効率性: Terraform と Cloud Build を使用することで、インフラストラクチャのプロビジョニングとコンテナのデプロイ プロセスを自動化し、効率性と一貫性を高めることができます。
正しくないオプション -
オプション A(Compute Engine スタートアップ スクリプトを使用)とオプション C(GKE を使用してコンテナを自動スケーリング)は、GPU やローカル SSD などの特定の要件を持つ GKE クラスタのプロビジョニングと管理には適していません。
オプション D(Dataflow と Cloud Scheduler を使用)は、GPU、ローカル SSD、8 Gbps 帯域幅を使用して GKE クラスタをプロビジョニングする要件とは無関係のようです。データフローは通常、インフラストラクチャのプロビジョニングではなく、データ処理に使用されます。
</div></details>

### Q. 質問45: 未回答
複数のベンダーからの連続ストリーミング データをほぼリアルタイムで処理できる機械学習モデルを作成したいと考えています。データに無効な値が含まれている可能性があります。BigQuery ML と Vertex AI を使用してこのモデルを作成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. Pub/Sub トピックを作成し、すべてのベンダー データをそのトピックに送信します。Dataflow を使用して Pub/Sub データを処理およびサニタイズし、BigQuery にストリーミングします。
<details><div>
    答え：4
説明
BigQuery ML を使用して機械学習モデルを作成し、Vertex AI を使用してモデルをホストするためのエンドポイントを作成し、無効な値の可能性がある連続ストリーミング データを処理するには、次の方法が最適です。
D. Pub/Sub トピックを作成し、すべてのベンダー データをそのトピックに送信します。Dataflow を使用して Pub/Sub データを処理およびサニタイズし、BigQuery にストリーミングします。
Pub/Sub によるデータ インジェスト: Pub/Sub を使用すると、複数のベンダーからデータを効率的に収集できます。これはメッセージキューとして機能し、データの取り込みと配布を処理します。
データ処理のための Dataflow: Google Cloud Dataflow は、リアルタイムモードとバッチモードでデータを処理できるように設計されています。Dataflow を使用して Pub/Sub からデータを取り込み、データの前処理とサニタイズを実行してから、クリーニングしたデータを BigQuery にストリーミングできます。
サニタイズ: データに無効な値が含まれている可能性があるため、Dataflow を使用して受信データのクリーニング、検証、変換を行い、分析に適した形式にすることができます。これは、モデルのトレーニングと予測の精度にとって重要です。
BigQuery 統合: 処理されたデータを BigQuery にストリーミングすると、分析や機械学習モデルのトレーニングに利用できるようになります。このデータを使用して BigQuery ML モデルを作成し、トレーニングできます。
正しくないオプション -
オプション C では、Cloud Functions を使用してデータを処理しますが、Dataflow と同じレベルのデータ変換機能は提供されません。Dataflow は、複雑なデータ処理タスク、特に無効な可能性のあるデータを処理する場合に適しています。
オプション A では、データの取り込みに BigQuery ML を使用することを提案していますが、これは主なユースケースではありません。BigQuery ML は、データの取り込みやデータの前処理ではなく、機械学習モデルの構築を目的として設計されています。
オプション B では、BigQuery ストリーミング挿入を直接使用することを提案していますが、その場合、必要なデータの前処理とサニタイズを行うことができません。
</div></details>

### Q. 質問46: 未回答
あなたは大手eコマース企業のデータエンジニアです。現在、会社では Cloud Dataproc を使用して、顧客の購入履歴の大規模なデータセットを処理しています。しかし、Cloud Dataproc ではスケーラビリティとパフォーマンスの面でニーズを満たしていないことがわかりました。顧客の購入履歴の大規模なデータセットを処理するために Cloud Dataproc を置き換えるために、次の GCP サービスのうちどれを会社にお勧めしますか?
1. 
2. 
3. BigQuery
4. 
<details><div>
    答え：3
説明
正解はBigQueryです。BigQuery は、大規模なデータセットを簡単に処理できる、ペタバイト規模のフルマネージド分析データ ウェアハウスです。また、拡張性とパフォーマンスも高いため、顧客の購入履歴の大規模なデータセットを処理するのに最適です。
正しくないオプション -
A. Cloud Data Fusion は、フルマネージドのクラウドネイティブ データ統合サービスです。大規模なデータセットを処理するようには設計されていません。
B. Cloud Dataflow は、フルマネージドのストリーミング データ処理サービスです。顧客の購入履歴の大規模なデータセットを処理するようには設計されていません。
D. Cloud Dataproc は、Hadoop と Spark のマネージド サービスです。大規模なデータセットを処理するための BigQuery ほどスケーラブルでもパフォーマンスも高くありません。
</div></details>

### Q. 質問47: 未回答
IoT デバイスからリアルタイム データを取り込んで処理するためのデータ パイプラインを設計しています。このデータは、リアルタイムのダッシュボードと分析を強化するために使用されます。
このパイプラインを設計する最適な方法は、次のうちどれですか?
1. Cloud Pub/Sub を使用してデータを取り込み、BigQuery に保存します。Dataflow を使用して BigQuery のデータを処理し、リアルタイムの指標を生成します。Cloud Data Studio を使用して、リアルタイムのダッシュボードを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. Cloud Pub/Sub を使用してデータを取り込み、BigQuery に保存します。Dataflow を使用して BigQuery のデータを処理し、リアルタイムの指標を生成します。Cloud Data Studio を使用して、リアルタイムのダッシュボードを作成します。
IoT デバイスからリアルタイム データを取り込んで処理するデータ パイプラインを設計する最善の方法は、Cloud Pub/Sub、BigQuery、Dataflow、Cloud Data Studio を使用することです。
Cloud Pub/Sub は、IoT デバイスからデータを取り込むために使用できるフルマネージドのリアルタイム メッセージング サービスです。BigQuery は、データの保存と処理に使用できるペタバイト規模のフルマネージド分析データ ウェアハウスです。Dataflow は、ストリーミング パイプラインとバッチ データ処理パイプラインを構築して実行するためのフルマネージド サービスです。Cloud Data Studio は、リアルタイムのダッシュボードの作成に使用できるデータ可視化ツールです。
このパイプラインを実装するには、まず、IoT デバイスから取り込むデータの種類ごとに Cloud Pub/Sub トピックを作成する必要があります。次に、これらのトピックにデータを発行するように IoT デバイスを構成する必要があります。
次に、データを保存するための BigQuery データセットを作成する必要があります。次に、Dataflow パイプラインを作成して、Cloud Pub/Sub トピックからデータを読み取り、BigQuery データセットに書き込む必要があります。
最後に、Cloud Data Studio のレポートを作成して、データをリアルタイムで可視化する必要があります。
このパイプラインは、大量のリアルタイム データを処理でき、増大するニーズに合わせてスケーラブルになります。
</div></details>

### Q. 質問48: 未回答
あなたの会社は、グローバルに展開する大規模なeコマース企業です。購入履歴、製品レビュー、人口統計など、顧客データの膨大なデータセットがあります。このデータを使用して、顧客離反を予測する機械学習モデルを構築します。データセットは非常に大きく、複雑です。また、複数のGCPリージョンに分散されています。スケーラブルで効率的な方法でデータをクリーニング、変換し、機械学習プラットフォームに読み込むためのデータ処理パイプラインを設計する必要があります。
データ処理パイプラインのオーケストレーションに最適なGCPサービスは、次のうちどれですか?
1. 
2. 
3. Google Cloud Composer
4. 
<details><div>
    答え：3
説明
C. Google Cloud Composer
Google Cloud Composer は、Apache Airflow のマネージド サービスです。Airflowは、複雑なデータパイプラインを作成および管理できる、人気のあるオープンソースのワークフローオーケストレーションプラットフォームです。Airflow ワークフローは Python で記述されているため、開発と保守が容易です。
Google Cloud Composer には、データ処理パイプラインのオーケストレーションに最適な次のような機能が多数用意されています。
ワークフローを作成および管理するための Web ベースの UI
一般的なデータ処理タスク用の事前構築済み演算子のライブラリ
スケジュールに従ってワークフローを実行するための組み込みスケジューラ
他の GCP サービス(Cloud Dataproc、Cloud Dataflow、Cloud Storage など)との統合
正しくないオプション -
A. Google Cloud Dataproc は、Apache Spark と Hadoop のマネージド サービスです。バッチ データ処理ジョブの実行には適していますが、複雑なデータ パイプラインを調整するようには設計されていません。
B. Google Cloud Dataflow は、ストリーミング データ処理のためのマネージド サービスです。リアルタイムのデータストリームを処理するには適していますが、複雑なデータパイプラインを調整するようには設計されていません。
D. Google Cloud Data Fusion は、フルマネージドのクラウドネイティブなデータ統合サービスです。データ統合パイプラインの構築と管理には適していますが、Google Cloud Composer と同じレベルのワークフロー オーケストレーション機能は提供されません。
</div></details>

### Q. 質問49: 未回答
あなたは大手eコマース企業のデータエンジニアです。お客様は、BigQuery 上に構築された会社のデータ ウェアハウスの設計と管理を担当します。同社には、数十億行のデータを含む大規模で複雑なデータセットがあります。
同社のマーケティングチームは、複数のセッションにわたる顧客の行動を分析する新しいタイプのクエリを実行したいと考えています。このクエリは非常に複雑で、複数のテーブルを結合する必要があります。クエリが遅すぎて、他のユーザーのデータウェアハウスのパフォーマンスに影響を与えることが懸念されます。
クエリのパフォーマンスを最適化し、他のユーザーへの影響を最小限に抑える最善の方法は何ですか?
1. 必要なデータのマテリアライズドビューを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。 必要なデータのマテリアライズドビューを作成します。
クエリのパフォーマンスを最適化し、他のユーザーへの影響を最小限に抑える最善の方法は、具体化されたビューを作成することです。マテリアライズドビューは、複雑なクエリの結果を含む事前計算されたテーブルです。
具体化されたビューを作成するには、まず、マーケティング チームが必要とするクエリの最も重要な部分を特定する必要があります。次に、クエリのこれらの部分の結果を含む具体化されたビューを作成します。
具体化されたビューが作成されると、マーケティング チームは元のテーブルではなく、具体化されたビューに対してクエリを実行できます。これにより、クエリのパフォーマンスが向上し、他のユーザーへの影響が最小限に抑えられます。
正しくないオプション -
B. クエリに割り当てるスロットの数を増やします。これにより、クエリのパフォーマンスは向上しますが、データ ウェアハウスで実行されている他のクエリのパフォーマンスにも影響します。
C. オフピーク時にクエリを実行します。これにより、他のユーザーへの影響は最小限に抑えられますが、マーケティング チームがクエリの結果を迅速に必要とする場合は、実用的ではない可能性があります。
D. 別のデータベース エンジンを使用します。BigQuery は、大規模で複雑なクエリを処理するために設計された、拡張性の高いデータベース エンジンです。別のデータベース エンジンを使用しても、クエリのパフォーマンスが大幅に向上することはほとんどありません。
</div></details>

### Q. 質問50: 未回答
あなたは大手eコマース企業のデータエンジニアです。お客様は、数十億行の顧客データを含む BigQuery データセットの管理を担当します。過去 10 日間に購入した顧客の間で最も人気のある上位 30 個の製品を特定するクエリを記述する必要があります。
このクエリを記述する最も効率的な方法は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：2
説明
正解はオプションBです。
SELECT product_id, COUNT(*) AS num_orders
FROM `my_dataset.my_table`
WHERE purchase_date >= CURRENT_DATE() - INTERVAL 30 DAY
GROUP BY product_id
ORDER BY num_orders DESC
LIMIT 10;
このクエリは、次の理由で効率的です。
WHERE 句を使用してデータをフィルター処理し、購入日が過去 30 日以内の行のみを含めます。
GROUP BY 句を使用して、製品を製品 ID でグループ化し、各製品 ID の注文数をカウントします。
ORDER BY 句を使用して、注文数でデータを降順に並べ替えます。
LIMIT句を使用して、最も人気のある上位10個の製品に結果を限定します。
正しくないオプション -
オプション A.
SELECT * FROM `my_dataset.my_table`
WHERE purchase_date >= CURRENT_DATE() - INTERVAL 30 DAY
ORDER BY num_orders DESC
LIMIT 10;
このクエリは、クエリに必要な product_id 列と purchase_date 列のみであっても、テーブルからすべての列を選択するため、非効率的です。すべての列を選択すると、特にテーブルが非常に大きい場合に、クエリのコストが大幅に増加する可能性があります。
オプションC:
SELECT product_id, COUNT(*) AS num_orders
FROM `my_dataset.my_table`
WHERE purchase_date >= CURRENT_DATE() - INTERVAL 30 DAY
GROUP BY product_id
HAVING num_orders > 10;
このクエリは、HAVING 句を使用してデータをフィルター処理し、注文数が 10 を超える行のみを含めるため、非効率的です。LIMIT句は、すでに結果を最も人気のある上位10個の製品に制限しているため、これは不要です。
オプションD:
SELECT product_id, COUNT(*) AS num_orders
FROM `my_dataset.my_table`
WHERE purchase_date >= CURRENT_DATE() - INTERVAL 30 DAY
GROUP BY product_id
ORDER BY num_orders DESC;
このクエリは LIMIT 句を使用しないため、非効率的です。つまり、クエリは、行数が 10 より大きい場合でも、すべてのデータ行を返します。これにより、クエリのコストが増加し、実行が遅くなる可能性があります。
</div></details>

## 5
### Q. 問題28: 正解
Google Cloud上のデータパイプラインのために、Cloud Pub/SubからBigQueryへのJSONメッセージの書き込みと変換を行うサービスを選択しています。サービスのコストは最小限に抑えたいと考えています。また、サイズが変化する入力データ量を監視し、最小限の手動操作で対応したいと考えています。
要件を達成するためにするべきことは何ですか？
1. 
2. 
3. Cloud Dataflowを使用して変換を実行する。Cloud Monitoringでジョブシステムの遅延を監視する。ワーカーインスタンスにデフォルトのオートスケーリング設定を使用する
4. 
<details><div>
    答え：3
説明
Pub/Subのデータを処理するスケーラブルなサービスを選択する必要があります。
また、データ量の監視も自動的に行えるようにする必要があります。
Pub/Sub は、スケーラブルで耐久性のあるイベントの取り込みおよび配信システムです。
Dataflow は、メッセージの重複排除、1 回限りの処理、タイムスタンプ付きイベントからのデータ ウォーターマークの生成により、Pub/Sub のスケーラブルな「最低 1 回」配信モデルを補完する。
Dataflow を使用するには、Apache Beam SDK でパイプラインを記述し、Dataflow サービスでパイプライン コードを実行する。
データ量監視についてはCloud Monitoring（Cloud Monitoring）が有効です。
Cloud Monitoring は、Google Cloud、Amazon Web Services（AWS）、ホストされた稼働時間プローブ、アプリケーション インストゥルメンテーションから指標、イベント、メタデータを収集する。
BindPlane サービスを使用して、150 以上の共通のアプリケーション コンポーネント、オンプレミス システム、ハイブリッド クラウド システムからデータを収集することもできます。
データを取り込むと、Google Cloud のオペレーション スイートはダッシュボード、グラフ、アラートを介して分析情報を提供する。
したがって、正解は「Cloud Dataflowを使用して変換を実行する。Cloud Monitoringでジョブシステムの遅延を監視する。ワーカーインスタンスにデフォルトのオートスケーリング設定を使用する」です。
参照：
https://cloud.google.com/Pub/Sub/docs/Pub/Sub-dataflow
https://cloud.google.com/migrate/compute-engine/docs/4.8/how-to/monitoring/using-Cloud Monitoring-monitoring
</div></details>

## 6
### Q. 問題6: 正解
ある運送会社では、荷物追跡のライブデータをリアルタイムでApache Kafkaストリームに送信しています。このデータはBigQueryにロードされます。会社のアナリストは、BigQuery でトラッキング データを照会して、パッケージのライフサイクルにおける地理的な傾向を分析したいと考えています。このテーブルは元々、日付ごとのパーティショニングで作成されました。時間の経過とともに、クエリの処理時間が長くなりました。あなたは、BigQuery のクエリパフォーマンスを向上させる変更を実装する必要があります。
要件を達成するためにするべきことは何ですか？
1. 
2. BigQuery でパッケージ・トラッキング ID カラムにクラスタリングを実装する
3. 
4. 
<details><div>
    答え：2
説明
クエリパフォーマンスを向上させるために、テーブルを再編成する必要があります。
BigQuery でクラスタ化テーブルを作成すると、テーブルのスキーマ内の 1 つ以上の列の内容に基づいてテーブルのデータが自動的に編成されます。
指定した列は、関連するデータを同じ場所に配置するために使用されます。
複数の列を使用してテーブルをクラスタ化する場合は、指定する列の順序が重要です。
指定した列の順序によって、データの並べ替え順序が決まります。
クラスタリングは、フィルタ句を使用するクエリやデータを集計するクエリなど、特定のタイプのクエリのパフォーマンスを向上させることができます。
クエリジョブまたは読み込みジョブによってデータがクラスタ化テーブルに書き込まれると、BigQuery はクラスタリング列の値を使用してデータを並べ替えます。
これらの値は、BigQuery ストレージ内の複数のブロックにデータを整理するために使用されます。
クラスタリング列に基づいてデータをフィルタする句を含むクエリを送信すると、BigQuery は並べ替えられたブロックを使用して不要なデータのスキャンを省略します。
テーブルまたはパーティションが 1 GB 未満の場合、クラスタ化テーブルと非クラスタ化テーブルとの間のクエリ パフォーマンスに大きな違いはない可能性があります。
同様に、クラスタリング列の値に基づいてデータを集計するクエリを送信すると、ブロックの並べ替えによって類似の値を持つ行が同じ場所に配置されるため、パフォーマンスが向上します。
したがって、正解は「BigQuery でパッケージ・トラッキング ID カラムにクラスタリングを実装する」です。
参照：
https://cloud.google.com/bigquery/docs/clustered-tables
</div></details>

### Q. 問題8: 不正解
あなたの会社のデータアナリストは、プロジェクトで複数のGCPサービスを使用できるようにするために、プロジェクトでCloud IAM Ownerロールを割り当てられています。会社のルールとして、すべてのBigQueryデータアクセスログを6ヶ月間保持する必要があります。あなたは、会社の監査担当者のみがすべてのプロジェクトのデータアクセスログにアクセスできるようにする必要があります。
要件を達成するためにするべきことは何ですか？
1. 
2. 
3. 
4. データアクセスログを、監査ログ用に新規作成されたプロジェクトのCloud Storageバケットに、集約されたエクスポートシンクを介してエクスポートする。エクスポートされたログを含むプロジェクトへのアクセスを制限する
<details><div>
    答え：4
説明
監査人が全てのプロジェクトのアクセスログに正しくアクセスできるような設定を行う必要があります。
集約シンクは、組織またはフォルダに含まれる Google Cloud リソースからのログエントリを結合してルーティングします。
たとえば、組織に含まれるすべてのフォルダの監査ログエントリを集約し、Cloud Storage バケットに転送できます。
集約シンク機能がないと、シンクは、シンクが作成された正確なリソース（Google Cloud プロジェクト、組織、フォルダ、請求先アカウント）からのログエントリのルーティングに限定されます。
Google Cloud のフォルダと組織に対して集約シンクを作成できます。
Cloud プロジェクトと請求先アカウントには子リソースが含まれていないため、これらのリソースの集約シンクは作成できません。
したがって、正解は「データアクセスログを、監査ログ用に新規作成されたプロジェクトのCloud Storageバケットに、集約されたエクスポートシンクを介してエクスポートする。エクスポートされたログを含むプロジェクトへのアクセスを制限する」です。
参照：
https://cloud.google.com/iam/docs/roles-audit-logging#scenario_external_auditors
https://cloud.google.com/iam/docs/job-functions/auditing#scenario_operational_monitoring
</div></details>

### Q. 問題10: 不正解
BigQueryデータウェアハウスの主要な在庫テーブルを読み込む、ほぼリアルタイムの在庫ダッシュボードを作成する必要があります。過去の在庫データは、品目と場所ごとの在庫残高として保存されています。1時間ごとに数千件の在庫更新があります。ダッシュボードのパフォーマンスを最大化し、データの正確性を確保したいと思います。
要件を達成するためにするべきことは何ですか？
1. BigQuery の UPDATE 文を活用して、在庫残高が変化しているときに更新する
2. 
3. 
4. 
<details><div>
    答え：1
説明
BigQueryのINSERT、UPDATE、DELETE、MERGEといったデータ操作言語（DML）文により、Google CloudのエンタープライズデータウェアハウスであるBigQueryに保存されているデータの追加、変更、削除を行うことができるようになります。
BigQueryのDMLは、1つのジョブでテーブル内の任意の数の行を挿入、更新、削除することをサポートしています。
2020年3月までは、DMLの１日あたりの上限がありましたが、それ以降は上限が撤廃されました。
これによって、今回のような1時間に数千回データ更新がある場合でもDMLを用いてパフォーマンスを最大化することが可能です。
したがって、正解は「BigQuery の UPDATE 文を活用して、在庫残高が変化しているときに更新する」です。
参照：
https://cloud.google.com/blog/products/data-analytics/dml-without-limits-now-in-bigquery
</div></details>

### Q. 問題17: 不正解
あなたは、ECサイトでユーザーに衣服を推薦するためのモデルを構築しています。ユーザーのファッションの好みは時間とともに変化することがわかっているので、新しいデータが利用可能になったときにモデルにストリーミングするためのデータパイプラインを構築します。
このデータをどのようにモデルのトレーニングに利用すればよいですか？
1. 
2. 既存のデータと新しいデータの組み合わせでモデルを継続的に再学習する
3. 
4. 
<details><div>
    答え：2
説明
データドリフトを防止するための適切な継続的な学習プロセスを選択する必要があります。
一般的に、ML ワークフローでは、特定のモデルを 1 回トレーニングしデプロイするだけでは不十分なことがよくあります。
最初はモデルの精度が望ましいレベルであっても、予測リクエストに使用されるデータが（おそらく、時間の経過に応じて）最初にモデルのトレーニングに使用したデータとまったく違うものになっている場合、精度が変わってくることがあります。
例えば、ある顧客が自分に合ったオファーを受けたときに、そのサービスを購入する可能性はどの程度あるのか、といった顧客の行動を予測しようとするモデルがあるとする。
明らかに、市場は時間とともに変化し、顧客の嗜好は変化し、競合は新たな施策を投入する。
そのため、定期的に再トレーニングを行う必要があります。このような場合、新しいデータを追加するだけでなく、以前学習に使用されていたデータも利用することが一般的に有効とされています。
したがって、正解は「既存のデータと新しいデータの組み合わせでモデルを継続的に再学習する」です。
参照：
https://cloud.google.com/blog/ja/topics/developers-practitioners/event-triggered-detection-data-drift-ml-workflows
https://qiita.com/tshowis/items/f4c1f5579079e4d264d3
</div></details>

### Q. 問題21: 不正解
あなたは、荷物を適切に配送するために配送ライン上を移動する物流センターを持つ運送会社で働いています。この会社は、配送ラインにカメラを追加して、輸送中の荷物の視覚的な損傷を検出して追跡したいと考えています。あなたは、ダメージを受けた荷物の検出を自動化し、輸送中の荷物にリアルタイムで人間が確認できるようフラグを立てる方法を作る必要があります。
どのソリューションを選ぶべきでしょうか？
1. 
2. 画像のコーパスで AutoML モデルを学習し、そのモデルを中心に API を構築してパッケージ追跡アプリケーションと統合する
3. 
4. 
<details><div>
    答え：2
説明
運送会社が扱う荷物は人の顔などとは異なり、一般的な学習済みモデルを使用することができません。
そのため今回は、新たに固有データを教師データとしたモデルを作成する必要があります。
AutoML Vision を使用すると、ラベル付きデータからパターンを認識するようコンピュータをトレーニングする「教師あり学習」を実行できます。
教師あり学習を使用することで、関心のあるパターンやコンテンツを画像で認識するようモデルをトレーニングできます。
AutoML Vision を使用してカスタムモデルをトレーニングするには、分類する画像のラベル付きサンプル（入力）と、ML システムに予測させるカテゴリまたはラベル（回答）を提供する必要があります。
AutoML Vision のトレーニングでは、カテゴリ / ラベルごとに最低でも 100 枚の画像が必要です。
各ラベル用の高品質のサンプルが増えるにつれて、ラベルをうまく認識する可能性が高まります。
一般的には、トレーニング プロセスに取り入れるラベル付きデータが多いほど、モデル品質は向上します。
したがって、正解は「画像のコーパスで AutoML モデルを学習し、そのモデルを中心に API を構築してパッケージ追跡アプリケーションと統合する」です。
参照：
https://cloud.google.com/vision/automl/docs/beginners-guide
</div></details>

### Q. 問題24: 不正解
あなたは、eコマース企業のためのカート自動リセットシステムを設計しています。このシステムは、以下のルールに基づいてユーザーにメッセージを送信します。
- 60分の間、ユーザーがサイト上で何も操作していない
- 30ドル以上の商品をバスケットに入れた場合
- トランザクションを完了していない
Google Cloud Dataflow を使用してデータを処理し、メッセージを送信すべきかどうかを判断します。
パイプラインはどのように設計すればよいですか？
1. 
2. 
3. ギャップタイムを60分に設定したセッションウィンドウを使用する
4. 
<details><div>
    答え：3
説明
ランダムな時間にアクションをする各々のユーザーに対して60分の放置を検知するためのウィンドウ設計をする必要があります。
ウィンドウ関数は、個々の要素のタイムスタンプで制限なしコレクションをグループ化する。
各ウィンドウには一定数の要素が入ります。
Apache Beam SDK または Dataflow SQL ストリーミング拡張機能で次のウィンドウを設定する。
- タンブリング ウィンドウ（Apache Beam では固定ウィンドウ）
- ホッピング ウィンドウ（Apache Beam ではスライディング ウィンドウ）
- セッション ウィンドウ
タンブリング ウィンドウとは、データ ストリームを重なりなく分ける一定の時間間隔を表する。
たとえば、30 秒のタンブリング ウィンドウに設定すると、タイムスタンプ値が [0:00:00-0:00:30] の要素が最初のウィンドウに表示されます。
2 番目のウィンドウには、[0:00:30-0:01:00] のタイムスタンプ値を持つ要素が表示されます。
ホッピング ウィンドウとは、データ ストリーム内の一定の時間間隔を表する。
タンブリング ウィンドウは重なりませんが、ホッピング ウィンドウは重なることがあります。
たとえば、ホッピング ウィンドウが 30 秒ごとに開始し、1 分間のデータとウィンドウを持つ場合があります。
ホッピング ウィンドウの開始間隔はピリオドといいます。
セッション ウィンドウには、別の要素とのギャップ期間に存在する複数の要素が含まれます。
ギャップ期間とは、データ ストリームの新しいデータの間隔を表する。
ギャップ期間の後にデータを取得すると、そのデータには新しいウィンドウが割り当てられます。
たとえば、セッション ウィンドウでは、ユーザーのマウスの操作を表すデータ ストリームを分割できます。
このデータ ストリームでは、長時間アイドル状態が続き、クリックが多い期間が点在する。
セッション ウィンドウには、クリックで生成されたデータを含めることができます。
したがって、正解は「ギャップタイムを60分に設定したセッションウィンドウを使用する」です。
参照：
https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines
</div></details>

### Q. 問題32: 不正解
Cloud Dataprep を使用して、BigQuery テーブル内のデータのサンプルにレシピを作成しました。このレシピを、実行時間が変動するロードジョブが完了した後、同じスキーマのデータを毎日アップロードする際に再利用したいと考えています。
要件を達成するためにするべきことは何ですか？
1. 
2. 
3. 
4. Cloud Dataprep ジョブを Cloud Dataflow テンプレートとしてエクスポートし、Cloud Composer ジョブに組み込む
<details><div>
    答え：4
説明
Dataprepの機能を利用して、スキーマのデータを再利用する方法を選択する必要があります。
Dataprepは、オーケストレーションAPIを公開しているため、スケジューラーやCloud Composerなどのオーケストレーションソリューション内でCloud Dataprepを統合することができます。
これにより、他のツールに直接統合することで、Cloud Dataflowテンプレート以外の自動化を拡大し、分析やAI/MLイニシアティブのための反復可能なデータパイプラインを作成し、時間の節約と信頼性を高めることができます。
さらに、このAPIでは、Cloud Dataflowテンプレートでは利用できないCloud Dataprep変数またはパラメータを使用して、動的な入出力を使用できます。
その結果、1つのCloud Dataprepフローを再利用して、実行時に評価されるさまざまな入出力値で実行することができます。
したがって、正解は「Cloud Dataprep ジョブを Cloud Dataflow テンプレートとしてエクスポートし、Cloud Composer ジョブに組み込む」です。
参照：
https://cloud.google.com/blog/products/data-analytics/how-to-orchestrate-cloud-dataprep-jobs-using-cloud-composer
</div></details>

### Q. 問題43: 不正解
スタートアップ企業は、正式なセキュリティポリシーを導入していません。現在、社内の誰もがGoogle BigQueryに保存されているデータセットにアクセスできます。各チームはサービスを自由に利用しており、ユースケースを文書化していません。あなたはこの状況を改善するために、データウェアハウスのセキュリティ確保を依頼されました。そのために、各チームの利用状況を把握する必要があります。
あなたはまず何をすべきでしょうか？
1. Google Cloud Monitoring 監査ログ を使用してデータアクセスを確認する
2. 
3. 
4. 
<details><div>
    答え：1
説明
各チームの利用状況を確認するためには、監査ログを利用することが有効です。
Cloud 監査ログ は Google Cloud が提供するログの集まりで、Google Cloud サービスの使用に関連する運用上の懸念事項を把握することができます。
したがって、正解は「Google Cloud Monitoring 監査ログ を使用してデータアクセスを確認する」です。
参照：
https://cloud.google.com/bigquery/docs/reference/auditlogs/#mapping-audit-entries-to-log-streams
https://cloud.google.com/bigquery/docs/monitoring#slots-available
</div></details>

### Q. 問題44: 不正解
あなたの会社ではCloud Storageに、アプリケーションの過去データを保存しています。あなたはこれらのデータに対して分析を行う必要があります。プログラミングやSQLの知識を必要とせずに、無効なデータエントリを検出し、データ変換を実行するソリューションを使用したいと考えています。
要件を達成するためにするべきことは何ですか？
1. 
2. レシピ付きのCloud Dataprepを使用して、エラーを検出し、変換を実行する
3. 
4. 
<details><div>
    答え：2
説明
プログラミングやSQLのコーディングを行わない分析を実現するサービスを選択する必要があります。
Cloud Dataprep by Trifacta は、分析、レポート、機械学習に使用する構造化データと非構造化データを視覚的に探索、クリーニング、準備できるインテリジェント データ サービスです。
Dataprep はサーバーレスで、規模に関係なく稼働します。
デプロイや管理が必要なインフラストラクチャはありません。
また、理想的なデータ変換操作が UI 入力のたびに提案、予測されるため、コードを書く必要がありません。
したがって、正解は「レシピ付きのCloud Dataprepを使用して、エラーを検出し、変換を実行する」です。
参照：
https://cloud.google.com/dataprep/
</div></details>

### Q. 問題45: 不正解
タイムスタンプとIDカラムのWHERE句を使用してBigQueryテーブルをフィルタリングするクエリがあります。bq query "" -dry_runを使用すると、timestampとIDのフィルタが全体のデータのごく一部を選択しているにもかかわらず、このクエリがテーブルのフルスキャンをトリガーすることが分かっています。あなたは、既存のSQLクエリに最小限の変更を加えるだけで、BigQueryによってスキャンされるデータ量を減らしたいと考えています。
要件を達成するためにするべきことは何ですか？
1. 
2. 
3. パーティショニング・カラムとクラスタリング・カラムを持つテーブルを再作成する
4. 
<details><div>
    答え：3
説明
BigQueryのベストプラクティスに則りコスト最適化を行う必要があります。
クラスタリングとパーティショニングにより、クエリで処理されるデータの量を削減できます。
クラスタ化テーブルまたはパーティション分割テーブルをクエリする際にスキャンされるパーティション数を制限するには、述部フィルタを使用します。
クラスタ化テーブルにクエリを実行する場合、そのクエリにクラスタ化された列のフィルタが含まれていると、BigQuery はフィルタ式とブロック メタデータを使用して、クエリでスキャンされるブロックをプルーニングします。
パーティション分割テーブルをクエリすると、パーティショニング列のフィルタがパーティションのプルーニングに使用され、クエリの費用を抑えることができます。
したがって、正解は「パーティショニング・カラムとクラスタリング・カラムを持つテーブルを再作成する」です。
参照：
https://cloud.google.com/bigquery/docs/best-practices-costs</div></details>

