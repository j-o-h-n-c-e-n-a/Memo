## 1
### Q. 1
あなたは世界的な海運会社の一員です。あなたの目的は、40TBのデータを使用して予測モデルを構築し、様々な地域内の船舶による配送遅延の可能性を毎日予測することです。このモデルは、様々な情報源から収集された数多くの属性に依存しています。各船舶からの GeoJSON 位置情報を含むテレメトリーデータが 1 時間ごとに収集されます。あなたは、予測および地理空間処理のための組み込み機能を提供するストレージソリューションを求めています。 この目的のために、どのようなストレージ・ソリューションを選択すべきでしょうか？
1. BigQuery
2. Cloud Bigtable
3. クラウドデータストア
4. PostgreSQL向けクラウドSQL
<details><div>
    答え：1
説明
BigQueryはアナリティクスに最適化されたクラウドベースのストレージソリューションで、予測や地理空間処理のためのネイティブ機能を備えています。モデルのトレーニングに使用したい40TBのデータのような大規模なデータセットに適しています。また、ダッシュボード機能もあり、地域内で遅延が発生しそうな船舶の数や船舶を表示することができる。
不正確なオプション
Cloud Bigtableは、低レイテンシのルックアップに最適化され、大量のデータを格納できるNoSQLデータベースソリューションです。予測や地理空間処理のためのネイティブ機能がないため、このユースケースには最適ではない。
Cloud Datastoreは、スケーラビリティに最適化され、大量のデータを保存できるNoSQLデータベースソリューションです。予測や地理空間処理のためのネイティブ機能を備えていないため、このユースケースには最適な選択肢ではありません。
Cloud SQL for PostgreSQLは、トランザクションに最適化され、大量のデータを保存できるリレーショナルデータベースソリューションです。予測や地理空間処理のためのネイティブ機能を備えていないため、このユースケースには最適ではない。
参考リンク
Google BigQuery: https://cloud.google.com/bigquery
</div></details>

### Q. 2
あなたはApache Kafkaを利用したIoTパイプラインを管理しており、通常毎秒約5000メッセージを受信しています。あなたの目標は、Google Cloud Platformを採用して、1時間移動平均が毎秒4000メッセージを下回ったときにアラートを生成することです。
どのような手順を踏むべきですか？
1. Kafka IOを使用してDataflowでデータのストリームを消費する。5分ごとに1時間のスライディング・タイム・ウィンドウを設定する。ウィンドウが閉じたら平均を計算し、平均が4000メッセージ未満ならアラートを送信する。
2. 
3. 
4. 
<details><div>
    答え：1
説明
IoTパイプラインの1時間の移動平均が毎秒4000メッセージを下回るとすぐにアラートを作成するには、以下の方法を取る必要があります：
このアプローチが適している理由は以下の通り：
Kafka IOを使ったデータフローでは、入力されるデータのストリームを効率的に処理できます。
5分ごとに1時間のスライディングタイムウィンドウを使用することで、移動平均を継続的に計算することができます。
ウィンドウが閉じたときに平均を計算することで、移動平均をチェックする間隔が一定になります。
計算された平均が4000メッセージを下回ると簡単にアラートを送ることができ、リアルタイムのアラート・メカニズムになります。
誤ったオプション
オプションB、C、およびDは、1時間にわたって移動平均を計算し、それが特定のしきい値を下回ったときにアラートを生成するという要件に直接対応していません：
B. 1時間の固定時間ウィンドウを使用すると、移動平均は得られず、むしろ1時間の静的平均が得られる。
C. このアプローチは、BigtableとCloud Schedulerを使用しますが、移動平均を直接計算しません。
D. このアプローチもBigQueryとCloud Schedulerを使用しますが、移動平均の計算がありません。
</div></details>

### Q. 3
MySQLベースのクラウドSQLの実装を準備しており、ゾーン障害時に高可用性を維持するための対策が必要です。
そのためにはどのような手順を踏むべきでしょうか？
1. あるゾーンにCloud SQLインスタンスを作成し、同じリージョン内の別のゾーンにフェイルオーバー・レプリカを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
これは、ゾーン障害時に高可用性を確保するための最良のオプションです。フェイルオーバー・レプリカは、プライマリ・インスタンスに障害が発生した場合に引き継ぐことができるセカンダリ・インスタンスであり、プライマリ・インスタンスと同じリージョンになければなりません。
誤ったオプション
リードレプリカはスケーリングに使用されるセカンダリインスタンスであり、高可用性に使用されるものではないため、オプションBは正しくありません。
リードレプリカはプライマリインスタンスと同じリージョンになければならないので、オプションCは不正解です。
クラウドストレージのバケットにバックアップしても、ゾーン障害時の高可用性には役立たないので、オプションDは不正解です。
参考リンク
https://cloud.google.com/sql/docs/mysql/high-availability。
</div></details>

### Q. 4
データの取り込みと配信を一元化するために、貴社はどのシステムを選ぶべきか。
- トピック内の特定のオフセットへのシーク機能
-多数のトピックにおけるパブリッシュ/サブスクライブ・セマンティクスのサポート
- キーごとの順序付けを維持するか？
1. Apache Kafka
2. Cloud Storage
3. Dataflow
4. Firebase Cloud Messaging
<details><div>
    答え：1
説明
正しい選択肢は A. Apache Kafka です。
Apache Kafkaは、データ統合のための機能を備えたメッセージングシステムを提供する分散ストリーミングプラットフォームであり、トピック内の特定のオフセットにシークする機能、数百ものトピック上でパブリッシュ／サブスクライブセマンティクスをサポートする機能、キーごとの順序付けを保持する機能などを備えています。
不正解の選択肢
オプションB. Cloud Storageは、Apache Kafkaのようなデータ統合の機能を提供していないため、不正解です。
オプションC. Dataflowは、トピック内の特定のオフセットにシークする機能、数百のトピックでのパブリッシュ/サブスクライブ・セマンティクスのサポート、およびキーごとの順序付けを保持する機能を提供しないため、不正解です。
オプション D. Firebase Cloud Messaging は、トピック内の特定のオフセットへのシーク機能、何百ものトピックでの発行/購読セマンティクスのサポート、およびキーごとの順序付けの保持を提供していないため、不正解です。
</div></details>

### Q. 5
既存のオンプレミスのApache Hadoopデプロイメントをマネージドサービスを利用してクラウドに移行する場合、長時間実行するバッチジョブに対して最大限の耐障害性とコスト効率を確保するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：1
説明
選択肢Aが正解です。Dataprocクラスタをデプロイすることが、長時間実行するバッチジョブの耐障害性とコスト効率を確保する最善の方法です。
標準的な永続ディスクと50%のプリエンプティブワーカーを使用することで、コストを低く抑えることができます。データをクラウドストレージに保存し、スクリプト内の参照をhdfs://からgs://に変更することで、データへのアクセスと管理が容易になります。
不正解の選択肢
SSD永続ディスクを使用すると、標準の永続ディスクよりも高価になるため、オプションBは正しくありません。
オプションCは、標準インスタンスで10ノードのCompute Engineインスタンスグループを使用すると、プリエンプティブインスタンスを使用するよりもコストが高くなるため、不正解です。
オプションDは、HDFSにデータを保存するとクラウドストレージに保存するよりも高くつくので、間違っています。
参考リンク
Dataproc データアクセシビリティ:- https://cloud.google.com/dataproc/docs/resources/faq#data_access_availability
</div></details>

### Q. 6
あなたのチームは現在2値分類問題に取り組んでいます．サポートベクターマシン（SVM）分類器をデフォルトのパラメータでトレーニングした後、検証中に0.87の曲線下面積（AUC）スコアを得ました。あなたの目的は、モデルのAUCを向上させることです。
どのようにこの改善を達成できますか？
1. ハイパーパラメータ・チューニングの実行
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解 A. ハイパーパラメータ・チューニングの実行
ハイパーパラメータチューニングの実行は、モデルのAUCを向上させる最良のアプローチです。これは、データへの適合を高め、モデルのパフォーマンスを向上させるために、モデルのパラメータを調整することを含みます。
不正解のオプション
不正解の選択肢 B: ディープニューラルネットワークで分類器をトレーニングしても、デフォルトのパラメータを持つSVM分類器に勝てるとは限りません。データによっては、SVM分類器がニューラルネットワーク分類器を上回る可能性もあります。
不正解選択肢 C: モデルをデプロイして実世界の AUC を測定しても、それが検証の AUC よりも高くなることは保証されません。オーバーフィッティングやその他の要因によって、モデルが実世界でより悪いパフォーマンスを示す可能性があります。
不正解選択肢 D: 予測値をスケーリングしても、モデルの AUC が向上するとは限りません。モデルの性能が、スケーリングなしよりもスケーリングありの方が悪い可能性がある。
参考リンク
https://cloud.google.com/ml-engine/docs/tensorflow/hyperparameter-tuning- 概要
</div></details>

### Q. 7
Cloud Dataprocクラスタノードはリソースを取得するためにインターネットにアクセスしてはならないという会社のセキュリティポリシーに準拠しながら、既存の初期化アクションを使用して起動時にCloud Dataprocクラスタのすべてのノードに追加の依存関係を展開するにはどうすればよいですか？
1. 
2. 
3. すべての依存関係をVPCセキュリティ境界内のクラウドストレージバケットにコピーします。
4. 
<details><div>
    答え：3
説明
Cloud Dataprocノードがインターネットにアクセスすることなく、起動時にCloud Dataprocクラスタの全ノードに追加の依存関係をデプロイするには、この方法に従います：
これが適切な理由です：
VPCセキュリティ境界内のCloud Storageバケットに依存関係を配置することで、セキュリティポリシーを遵守しながらCloud Dataprocクラスタにアクセスできるようになります。
VPC内にCloud Storageバケットを作成し、VPC Service Controlsまたはオンプレミスホスト用のPrivate Google Accessを使用してCloud Dataprocクラスタノードにアクセスすることができます。
クラウド・ストレージ・バケットを初期化アクションやクラスタの起動時に必要なリソースのソースとして指定することができます。
誤ったオプション
オプションAとDは、ノードへの依存関係のデプロイとは直接関係ありません：
A. A. Cloud DataprocマスタにCloud SQL Proxyをデプロイすることは、Cloud SQLアクセスに特有であり、一般的な依存関係のデプロイには関係ありません。
D. サービス・アカウントをネットワーク・ユーザー・ロールに追加することは、ネットワーク権限に関することであり、依存関係のデプロイメントには対応していません。
オプションB、SSHトンネルを使用してCloud Dataprocクラスタにインターネットへのアクセスを与えることは、Cloud Dataprocノードがインターネットアクセスを持ってはならないという要件に違反するので、このシナリオには適していません。
</div></details>

### Q. 8
以下の仕様の新規プロジェクトにどのデータベースを選択しますか？
1. 完全な管理機能。
2. 自動スケーラビリティ。
3. トランザクションの一貫性。
4. 最大6TBまでのスケーラビリティ。
5. SQLクエリーのサポート
このプロジェクトではどのデータベースを選択しますか？
1. Cloud SQL
2. Cloud Bigtable
3. Cloud Spanner
4. Cloud Datastore
<details><div>
    答え：3
説明
C. Cloud Spanner
Cloud Spannerは、Google Cloudが提供する、完全に管理され、グローバルに分散された、一貫性の高いデータベースサービスです。シナリオで説明した要件を満たすように設計されています：
フルマネージド： Cloud Spannerはフルマネージドであり、Google Cloudがインフラ管理、アップデート、バックアップを行うため、アプリケーションに集中することができます。
自動的なスケールアップ：Cloud Spannerは水平方向のスケーラビリティを考慮して設計されています。データとクエリの負荷が増加した場合、アプリケーションのスケーリングニーズに自動的に対応できます。
トランザクションの一貫性： Cloud Spannerは強力なトランザクション一貫性を提供します。つまり、データのACID（原子性、一貫性、分離、耐久性）特性を保証し、信頼性と一貫性のあるトランザクションを必要とするアプリケーションに適しています。
最大6 TBまで拡張可能：Cloud Spannerはより大きなデータセットを扱うことができるため、最大6 TBまで拡張可能です。
SQLでクエリ可能： Cloud SpannerはSQLクエリをサポートしているため、SQLベースのデータベースに慣れている開発者にはなじみやすい。
不適切なオプション
A. Cloud SQL： Cloud SQLはマネージド・リレーショナル・データベース・サービスですが、Cloud Spannerほど簡単には自動スケールしません。また、Cloud Spannerのように分散したグローバルに一貫性のあるデータを扱うようには設計されていない。
B. Cloud Bigtable： Cloud BigtableはNoSQLデータベースで、特に分析や時系列のユースケースで大量のデータを扱うのに優れている。しかし、このシナリオの要件である強力なトランザクション一貫性は提供しない。
D. クラウド・データストア： Cloud Datastore（データストアモードのFirestore）は、拡張可能なNoSQLドキュメントデータベースだが、Cloud Spannerと同レベルのトランザクション一貫性は提供できない。また、一般的にSQLクエリに依存する従来のリレーショナル・データベースとは異なるユースケースで使用される。
参考リンク
Cloud Spanner: https://cloud.google.com/spanner
</div></details>

### Q. 9
あなたは、オンプレミスのデータベースからGoogle Cloud Platform（GCP）へ、業務システムのトランザクションデータを移行する仕事を任されている中堅企業に雇われています。このデータベースには、20テラバイトものデータが含まれています。このような状況を踏まえて、この移行に最も適したデータベースソリューションはどれでしょうか？
1. Cloud SQL
2. Cloud Bigtable
3. Cloud Spanner
4. Cloud Datastore
<details><div>
    答え：1
説明
回答 A. クラウドSQL
Cloud SQLは、Google Cloud Platform上でリレーショナル・データベースのセットアップ、保守、管理、運用を行うことができるフルマネージドのリレーショナル・データベース・サービスであるため、正しい選択肢です。トランザクション処理、データウェアハウス、eコマースなど、リレーショナルデータベースを必要とするアプリケーションに最適です。また、Cloud SQLは、最大20TBのデータベースを含む幅広いデータベースサイズをサポートしているため、オンプレミスのデータベースをGCPに移行する際にも適しています。
不正解の選択肢
Cloud Bigtableは大規模なスケーラビリティと高いパフォーマンスを実現するために設計されたNoSQLデータベースであり、Cloud Spannerはグローバルに分散されたリレーショナル・データベース・サービスであり、Cloud Datastoreは非リレーショナル・データを格納するためのNoSQLドキュメント・データベースであるためです。これらのオプションはいずれも、オンプレミスのデータベースをGCPに移行するのには適していない。
参考リンク
クラウドSQL: https://cloud.google.com/sql
</div></details>

### Q. 10
何百万台ものコンピュータのCPUとメモリ使用量に関する時系列データを効果的に保存するデータベースの選択に関する決断に迫られていると想像してほしい。要件は、このデータを1秒間隔で取得したサンプルとして保存することです。このデータはアナリストがリアルタイムのアドホック分析に使用するため、データベースは効率的なクエリ実行をサポートする必要があります。さらに、クエリを実行するたびに料金が発生するのを防ぎ、選択したスキーマ設計が将来的なデータセットの拡張に対応できることを目的としています。これらの目的に最適なデータベースとデータモデルはどれでしょうか？
1. 
2. 
3. 
4. 
<details><div>
    答え：3
説明
正解はCです。Bigtableに、コンピュータ・エンジンのコンピュータ識別子と各秒のサンプル時間を組み合わせた行キーを持つ狭いテーブルを作成します。
こうすることで、アナリストはデータをすばやく照会できるようになり、スキーマ設計がデータセットの将来の成長を可能にします。Bigtableは、データへの高速アクセスとクエリを可能にするので、この種のデータには最適です。
不正解の選択肢
BigQueryはリアルタイムのアドホック分析をサポートしていないため、オプションAは不正解です。
BigQueryはリアルタイムのアドホック分析をサポートしておらず、各秒の間隔で行を更新するのは効率的ではないため、オプションBは不正解です。
Bigtableはワイドテーブルをサポートしておらず、各秒の値を列データとして結合するのは非効率的であるため、オプションDは不正解です。
参考リンク
https://cloud.google.com/bigtable/docs/schema-design-time-series
</div></details>

### Q. 11
クラウド・ストレージ環境内にデータをアーカイブすることを意図しており、特に機密性の高い情報の保護に注意を払っています。最大限のセキュリティと機密性を確保するため、クラウドプロバイダーの担当者であっても不正アクセスを防止する「Trust No One」（TNO）暗号化アプローチの導入を強く希望しています。
クラウドストレージにデータを保存する前に、「Trust No One」（TNO）アプローチを使ってデータを安全に暗号化するには、どのような手順を踏むべきでしょうか？
1. gcloud kms keys createを使って共通鍵を作成します。次に、gcloud kms encryptを使用して、各アーカイブファイルをキーと一意の追加認証データ（AAD）で暗号化します。gsutil cpを使用して、暗号化された各ファイルをCloud Storageバケットにアップロードし、AADをGoogle Cloud外に保管します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
選択肢Aが正解です。
このオプションでは、Trust No One（TNO）アプローチを使用してデータを暗号化し、クラウドプロバイダのスタッフがデータを復号化できないようにします。対称キーは、キーと一意の追加認証データ（AAD）で各アーカイブファイルを暗号化するために使用されます。暗号化されたファイルはCloud Storageバケットにアップロードされ、AADはGoogle Cloudの外部に保管されます。
正しくないオプション
オプションBはTNOのアプローチを使用していないため、不正解です。対称鍵は各アーカイブファイルの暗号化に使用されるが、鍵は破棄されずローテーションされる。これは、クラウド・プロバイダーのスタッフが鍵にアクセスし、データの復号化に使用できる可能性があることを意味する。
オプションCはTNOのアプローチを使用していないため、誤りである。顧客提供の暗号化キー（CSEK）は.boto設定ファイルで指定され、アーカイブ・ファイルはクラウド・ストレージ・バケットにアップロードされる。CSEKはクラウドメモリストアに保存されますが、クラウドプロバイダーのスタッフがアクセスできないようにするには十分なセキュリティではありません。
オプションDはTNOのアプローチを使用していないため、不正解です。顧客提供の暗号化キー（CSEK）は.boto設定ファイルで指定され、アーカイブファイルはクラウドストレージバケットにアップロードされます。CSEKは別のプロジェクトに保存されますが、これはクラウド・プロバイダーのスタッフがアクセスできないことを保証するものではありません。
参考リンク
https://cloud.google.com/security/encryption-at-rest/customer-supplied-encryption-keys/
</div></details>

### Q. 12
BigQuery、Dataflow、Dataprocで運用中のデータパイプラインがあり、ヘルスアセスメントやパフォーマンスの監視を行う機能が必要な場合、どのように進めればよいのでしょうか。さらに、これらのパイプラインの監督を担当するチームに障害が発生した場合にアラートを出す必要があり、さまざまなプロジェクトでシームレスに運用できなければなりません。プラットフォームが管理する製品や機能を活用したいと考えています。
このシナリオでは、どのような手順を踏むべきでしょうか？
1. 情報をCloud Monitoringにエクスポートし、アラートポリシーを設定します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。
Cloud MonitoringはGoogle Cloud Platformが提供するマネージドサービスであり、データパイプラインの監視と管理を可能にするからです。Cloud MonitoringはGoogle Cloud Platformが提供するマネージドサービスであり、データパイプラインの監視と管理を可能にする。Cloud Monitoringはアラートポリシーを提供し、パイプラインに障害が発生した場合にパイプラインを管理するチームに通知するように設定できる。さらに、Cloud Monitoringは複数のプロジェクトで使用できるため、このような状況に最も適した選択肢となる。
不適切なオプション
Compute Engine with AirflowのVirtual Machinesはマネージドサービスではないため、選択肢Bは誤りです。
オプションCは、BigQueryがアラートポリシーを提供していないため、この状況に最適なオプションではないため、不正解です。
App Engine は、GCP API 呼び出しを使用してログを消費するアプリケーションを開発する必要があり、他の選択肢よりも複雑であるため、この状況では最適な選択肢ではないため、選択肢 D は正しくありません。
参考リンク
クラウド監視に関する Google Cloud Platform のドキュメント: https://cloud.google.com/monitoring
</div></details>

### Q. 13
顧客が自社の商品を購入する確率を予測するためにBigQuery MLで線形回帰モデルを開発する際、重要な予測要因として都市名の変数がありますが、モデルの学習と展開のためにデータを列に効率的に構造化し、必要な変数を保持しながら必要なコーディング工数を最小限に抑えるにはどうすればよいでしょうか？
1. 
2. BigQueryのSQLを使用して、ワンホットエンコーディング法を使用してstateカラムを変換し、各都市をバイナリ値を持つカラムにします。
3. 
4. 
<details><div>
    答え：2
説明
正解はBです。
これは各都市に新しい列を作成し、都市名に基づいて各行にバイナリ値を割り当てるので、データを準備する最も効率的な方法です。これにより、モデルは都市名を予測変数として使用できるようになります。
不正解の選択肢
A. 都市情報の列を含まない新しいビューをBigQueryで作成しても、都市を予測変数として使用するために必要な情報をモデルに提供することはできません。
C. C. TensorFlow を使用して語彙リストを持つカテゴリ変数を作成すると、時間がかかりすぎ、必要以上のコーディングが必要になる。
D. クラウドデータフュージョンを使って、各都市を1,2,3,4,5とラベル付けされた地域に割り当て、その番号を使ってモデルで都市を表すことは、予測変数として都市を使うために必要な情報をモデルに提供しない。
</div></details>

### Q. 14
あなたは、北米で広く事業を展開する有名銀行に雇われている。あなたの仕事は、銀行口座取引を管理するために設計されたデータストレージシステムを構築することです。あなたの具体的なニーズには、ACIDコンプライアンス原則の遵守と、SQLクエリを使用してデータを取得する機能が含まれます。この目的に適したソリューションは何でしょうか？
1. トランザクションデータをCloud Spannerに格納する。ステールリードを有効にしてレイテンシを減らす。
2. トランザクションデータをCloud Spannerに格納する。ロック付き読み書きトランザクションを使用する。
3. トランザクションデータをBigQueryに保存する。クエリキャッシュを無効にして一貫性を確保する。
4. トランザクションデータをCloud SQLに格納する。分析にはBigQueryとの連携クエリを使用する。
<details><div>
    答え：2
説明
オプションB：
Cloud Spannerはグローバルに分散され、ACIDコンプライアンスを提供する一貫性の強いデータベースサービスであるため、銀行口座のトランザクションを処理するのに適している。Cloud Spannerでロック付き読み書きトランザクションを使用すると、データの一貫性と整合性を確保できます。
以下はオプションBに関する考慮事項です：
強力な一貫性： Cloud Spannerは強力な一貫性を提供します。これは銀行環境でデータの整合性を維持するために極めて重要です。
ACIDコンプライアンス： Cloud SpannerはACIDに準拠しており、トランザクション・データ・ストレージの要件を満たしています。
読み書きトランザクションのロック 読み書きトランザクションをロックすることで、データへのアクセスを制御して競合を防ぎ、データの整合性を確保できます。
不正解の選択肢
A. 
Cloud SpannerはACIDに準拠しており、トランザクション・データに適していますが、ステール・リードを有効にするとデータの一貫性が損なわれる可能性があります。ステイル・リードを有効にすると、最新ではないデータを読み込むことができるため、データの整合性が重要な銀行口座のトランザクションには適していません。
C. 
BigQueryは分析ワークロード用に設計されており、トランザクションデータベースではない。ACID コンプライアンスや強力なトランザクション一貫性は提供しません。BigQueryのクエリキャッシュを無効にしても、これらの基本的な要件には対処できません。
D. 
Cloud SQL は、ACID コンプライアンスと強力な一貫性を提供するマネージド・リレーショナル・データベースであり、トランザクション・データの保存に適しています。BigQueryとの連携クエリを分析に使用することで、トランザクション処理と分析で両方のサービスの強みを活用できます。このアプローチはバランスが取れており、指定された要件を満たすことができます。
</div></details>

### Q. 15
ある運送会社では、荷物の追跡データをApache Kafkaストリームにリアルタイムで送信しています。このデータはBigQueryにロードされます。社内のアナリストは、BigQueryで追跡データを照会して、パッケージのライフサイクルにおける地理空間的傾向を分析したいと考えています。このテーブルは当初、インジェスト・デート・パーティショニングで作成されました。時間の経過とともに、クエリの処理時間が長くなっています。あなたのタスクは、BigQueryのクエリパフォーマンスを向上させるための修正を特定することです。
どのような対策を取るべきですか？
1. 
2. パッケージ追跡ID列にクラスタリングを実装する
3. 
4. 
<details><div>
    答え：2
説明
オプションB - 
BigQueryのクラスタリングは、クラスタリング列に基づいて各パーティション内のデータを物理的に整理することで、クエリ・パフォーマンスを最適化するために使用されます。パッケージ追跡 ID 列にクラスタリングを実装すると、パッケージ追跡 ID でデータをフィルタリングまたはソートするクエリにおいて、クエリ・パフォーマンスの向上に役立つ可能性があります。
クラスタリングは、フィルタ句を使用するクエリやデータを集約するクエリなど、特定のタイプのクエリのパフォーマンスを向上させます。クエリジョブまたはロードジョブによってクラスタ化テーブルにデータが書き込まれると、BigQueryはクラスタリング列の値を使用してデータをソートします。これらの値は、BigQueryストレージ内でデータを複数のブロックに整理するために使用されます。クラスタリング列に基づいてデータをフィルタリングする句を含むクエリを送信すると、BigQueryはソートされたブロックを使用して不要なデータのスキャンを排除します。
参考リンク
BigQuery クラスタ化テーブル:- https://cloud.google.com/bigquery/docs/clustered-tables
</div></details>

### Q. 16
現在、Spark、Hive、HDFSを利用した大規模なオンプレミスクラスターをコロケーション施設で使用していますが、コスト削減を最大化しつつ、クラウドへの移行をタイムリーに行うにはどうすればよいでしょうか？このクラスタはピーク時の利用を想定して設計されていますが、多くのバッチジョブがあるため、需要が変動しています。貴社はまた、オンプレミスのオーバーヘッドとメンテナンスコストの削減を目指し、クラウドのサーバーレス・オファリングを採用することで、インフラを近代化しようとしています。コロケーション施設の契約更新まで2カ月しかありませんが、これらの目的を達成するためにどのような移行戦略をお勧めしますか？
1. 
2. ワークロードをDataproc plus Cloud Storageに移行し、後でモダナイズする。
3. 
4. 
<details><div>
    答え：2
説明
クラウドに移行してオーバーヘッドを削減し、コスト削減のメリットを享受するという貴社の目標と、最初の移行期間が2カ月という限られた期間であることを考慮すると、推奨されるアプローチは次のようになります：
B. 
このアプローチが適している理由は以下の通りです：
混乱を最小限に抑える： Googleクラウド上のマネージドSparkおよびHadoopサービスであるDataprocにワークロードを移行することで、既存のSparkおよびHiveジョブの中断を最小限に抑えることができます。DataprocはSparkとHiveのワークロードを実行するための使い慣れた環境を提供するため、迅速な移行が容易です。
コスト効率： データストレージソリューションとしてDataprocとCloud Storageを併用することで、クラウドのコスト効率の高いストレージオプションを活用することができます。クラウドストレージは拡張性が高く、競争力のある価格設定なので、オンプレミスのインフラストラクチャのオーバーヘッドなしにデータを保存できます。
時間的制約： 初期移行に2ヶ月というタイトなスケジュールを考えると、短時間で比較的簡単に移行できる戦略を優先することが重要です。Dataprocとクラウド・ストレージへの移行は、ワークロードをすぐにモダナイズするのに比べ、より直接的な方法です。
近代化： 最初の移行が完了した後に、最新化を計画することができます。ワークロードがクラウドで実行されるようになったら、BigQuery for HiveのモダナイゼーションやDataflow for Sparkのモダナイゼーションのようなサーバーレスオファリングを徐々に検討し、サーバーレスの機能とコストの最適化を活用しながら進めることができます。
オプションC（SparkワークロードをDataprocとHDFSに移行し、HiveワークロードをBigQuery用にモダナイズする）は、Hiveをすぐにモダナイズする特定のニーズがある場合に検討できます。ただし、オプションBに比べて複雑さが増し、実行に時間がかかる可能性があります。
オプションD（SparkとHiveの両方のワークロードをすぐに最新化する）は、最新化の取り組みがコード、アーキテクチャ、およびプロセスの変更を伴う可能性があるため、特に2カ月の時間枠を考えると、より長くリスクの高い経路になる可能性があります。
参考リンク
Cloud Dataproc:- https://cloud.google.com/dataproc/
</div></details>

### Q. 17
オンライン登録サービスを提供する金融機関に勤務するあなたは、新規登録された顧客のユーザデータをBigQueryに取り込む前にPub/Subに送信する際、顧客の政府発行の識別番号を隠すことでセキュリティを強化することを選択しました。一方、顧客サービス担当者が必要に応じて変更前の値にアクセスできるようにするつもりです。そのためには、どのような行動を取るべきでしょうか？
1. 
2. 
3. 
4. データをBigQueryにロードする前に、クラウドデータ損失防止（DLP）を使用して、入力値を暗号化形式保持暗号化トークンに置き換えます。
<details><div>
    答え：4
説明
正解はDです。
これは、機密データを保護するための最良のオプションです。これは、カスタマーサービス担当者が必要に応じて元の値を表示できるようにするためです。
正しくないオプション
BigQueryに組み込まれているAEAD暗号化では、カスタマーサービス担当者が元の値を見ることができないため、オプションAは正しくありません。
BigQueryの列レベルのセキュリティでは、カスタマーサービス担当者が元の値を表示することはできないため、オプションBは正しくありません。
オプションCは、クラウドデータ損失防止（DLP）により、カスタマーサービス担当者が必要に応じて元の値を見ることができないため、不正解です。
参考リンク
クラウドDLP
</div></details>

### Q. 18
テーブルをBigQueryに移行してデータモデルを決定する際、クエリのパフォーマンスを最適化するためにテーブルをどのように構造化すべきでしょうか？問題のテーブルには、複数の店舗での購入に関するデータが含まれており、トランザクションのタイムスタンプ、購入したアイテム、店舗ID、各店舗の市や州などの詳細が含まれています。定期的なクエリでは、過去30日間の個々のアイテムの売上を追跡し、州、都市、特定の店舗に基づいて購入パターンを分析します。
1. トランザクション時間でパーティショニングし、最初に州、次に市、次に店舗IDでクラスタリングします。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。
このオプションを使用すると、トランザクションの時間、州、市、および店舗IDによってテーブルをすばやくクエリできるため、正解です。これにより、探している特定の店舗、市町村、州をすばやく絞り込むことができるため、テーブルをクエリする際に最高のパフォーマンスが得られます。
不適切なオプション
最初に店舗 ID でクラスタリングすると、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション B は正しくありません。
最初に州によってトップレベル・クラスタリングを行うと、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション C は正しくありません。
最初にストア ID を指定したトップレベル・クラスタリングでは、テーブルへのクエリ時に最高のパフォーマンスは得られないため、オプション D は正しくありません。
参照リンク
https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 19
Pub/Sub フィードのサブスクライバのコードを更新しています。展開時にサブスクライバが誤ってメッセージを承認してしまい、メッセージが失われることを懸念しています。サブスクライバは確認メッセージを保持するように設定されていません。
展開後のエラーからの回復を保証するにはどうすればよいですか?
1. ローカル・マシンにPub/Subエミュレータをセットアップします。本番環境にデプロイする前に、新しいサブスクライバ・ロジックの動作を検証してください。
2. 新しいサブスクライバコードをデプロイする前に、Pub/Sub スナップショットを作成します。Seek 処理を使用して、スナップショットの作成後に利用可能になったメッセージを再配信します。
3. デプロイには Cloud Build を使用します。デプロイ後にエラーが発生した場合は、Seek オペレーションを使用して、デプロイ開始時に Cloud Build によってログに記録されたタイムスタンプを検索します。
4. Pub/Sub トピックでデッドレタリングを有効にして、正常に承認されなかったメッセージを捕捉する。展開後にエラーが発生した場合は、デッド・レター・キューでキャプチャされたメッセージをすべて再配信します。
<details><div>
    答え：2
説明
オプション B. 
新しいサブスクライバ・コードをデプロイする前に Pub/Sub スナップショットを作成することで、特定の時点のサブスクリプションの状態を取得できます。新しいサブスクライバコードの問題により、誤って承認され失われたメッセージがある場合、Seek 操作を使用して、スナップショットの作成後に利用可能になったメッセージを再送信することができます。
この方法は、誤った確認応答によって失われたメッセージを回復するのに効果的です。ただし、メッセージの回復を確実に行うには、スナップショットの作成と管理に依存します。
誤ったオプション
A. 
ローカルでのテストは開発に不可欠な要素ですが、本番環境でのサブスクライバの動作にエラーがないことを保証するものではありません。Pub/Sub エミュレータは本番環境を完全に再現しているとは限らず、動作に違いが生じる可能性があります。さらに、このオプションは、デプロイ後にエラーが発生した場合にメッセージを回復するメカニズムを提供しません。
C. 
Cloud Build はデプロイメントを管理するための貴重なツールですが、Cloud Build によってログに記録されたタイムスタンプに依存してエラーを回復することは、最も単純で効率的な方法ではない可能性があります。手作業が必要であり、メッセージ復旧に必要なメッセージ固有の詳細を取得できない可能性があります。さらに、タイムスタンプだけでは、メッセージ処理の正確な状態をピンポイントで特定するには不十分な場合があります。
D. 
デッドレターを有効にすることは、正常に処理できなかったメッセージをキャプチャするための確立された方法です。これは、処理中にエラーが発生したメッセージを回復するための体系的かつ自動化された方法を提供し、デプロイ後のメッセージ回復を確実にするための、より強固なオプションとなります。
参考リンク
Cloud Pub/Sub:- https://cloud.google.com/pubsub/
</div></details>

### Q. 20
著名な不動産会社に勤務するあなたは、機械学習用に6TBもの膨大な住宅販売データを準備する仕事を任されています。あなたの目的は、データ変換にSQLを利用し、機械学習モデルを確立するためにBigQuery MLを採用することです。このモデルは、未処理の生のデータセットに対して予測を行うことを目的としています。予測段階でスキューを効果的に回避するために、ワークフローを構成する上でどのような手順を踏むべきですか？
1. モデルを作成する際、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データに対して変換を指定しません。
2. 
3. BigQueryビューを使用して前処理ロジックを定義します。モデルを作成する際、そのビューをモデルの学習データとして使用します。予測時には、生の入力データに対して変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
4. Dataflowを使用してすべてのデータを前処理する。予測時には、入力データに対してさらなる変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
<details><div>
    答え：1
説明
オプションA. 
モデル作成時には、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。モデルの学習時には、これらの前処理ステップが学習データに適用されます。
予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データには変換を指定しません。これは、予測を行う前にモデルが内部的に生の入力データに同じ前処理ステップを適用することに依存していることを意味します。
モデルの前処理ロジックが十分に定義され、トレーニングデータと一貫している場合、オプションAは効果的に機能するかもしれませんが、予測中にモデル自身が未加工の入力データの前処理を正しく処理する必要があります。このアプローチは、モデル内部の前処理が予測の歪みを防ぐのに十分であることを前提としています。
実際には、オプション A とオプション B のどちらを選択するかは、モデル内部の前処理ロジッ クの具体的な特性と信頼性、および予測プロセスにおける透明性と制御の要件によって決まります。どちらのオプションも有効ですが、前処理と予測の一貫性に対するアプローチが異なります。
正しくないオプション
オプションC - 
BigQueryビューを使用して前処理ロジックを定義することは、学習データと予測データ間の一貫性を確保するための有効なアプローチです。しかし、このオプションには、ML.EVALUATE を使用する前の生の入力データに対する明示的な変換ステップがありません。このビューは一貫した前処理ロジックを提供しますが、スキューを防止するために、生の入力データが同じ前処理ステップを受けることを確実にすることが重要です。
オプションD - 
Dataflowを使用してすべてのデータを前処理することは、データ変換と準備のための実行可能なソリューションです。しかし、このオプションはDataflowの前処理と予測中のモデル内部の前処理が同一であることを前提としています。また、前処理ステップには必要ないかもしれないが、Dataflowによってさらなる複雑さがもたらされる。
オプションCとオプションDの両方は、ML.EVALUATEを使用する前に生の入力データを一貫して変換する必要性に明示的に対処していません。
参考リンク
BigQuery ML:- https://cloud.google.com/bigquery/docs/bigqueryml-intro
</div></details>

### Q. 21
あなたはある会社の株価を分析しています。5秒ごとに、過去30秒分のデータの移動平均を計算する必要があります。あなたはPub/Subからデータを読み込み、DataFlowを使って分析を行っています。ウィンドウ・パイプラインをどのようにセットアップしますか？
1. 
2. 
3. 
4. 継続時間30秒、周期5秒のスライディング・ウィンドウを使用します。以下のトリガーを設定して結果を出力する： AfterWatermark.pastEndOfWindow()を設定する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
30秒のスライディング・ウィンドウ： 期間30秒のスライディング・ウィンドウを使用することは、移動平均計算のために直近の30秒間のデータを考慮し続けることを意味します。これはあなたの要求と一致しています。
期間5秒： 期間5秒は、ウィンドウが5秒ごとに前方にスライドすることを示します。こ れに よ り 、 直近 30 秒のデー タ に基づいて 5 秒ご と に移動平均を計算す る こ と が保証 さ れます。この設定は、5秒ごとに移動平均を計算するという要件に合致しています。
トリガー設定： トリガーは、透かしがウィンドウの最後を通過した後に結果を出すように設定されています。これにより、ウィンドウが前方にスライドしたときに計算がトリガーされ、移動平均計算の望ましいタイミングと一致します。
誤ったオプション
オプションA（5秒間の固定ウィンドウ）は、過去30秒分のデータを取り込みません。これは、5秒間の固定ウィンドウを提供しますが、要件を満たしていません。
オプションB（継続時間30秒の固定ウィンドウ）は、30秒のウィンドウをキャプチャしますが、5秒ごとに前方にスライドしません。これは、5秒ごとに移動平均を計算するという要件に合致しません。
オプションC（継続時間5秒のスライディング・ウィンドウ）は5秒のスライディング・ウィンドウをキャプチャしますが、過去30秒のデータの移動平均を計算するために必要な30秒の継続時間を持ちません。さらに、トリガー設定は30秒後にデータを処理するように設定されており、5秒間隔の要件とは一致しません。
参考リンク
ビーム・ウィンドウの基本:https://beam.apache.org/documentation/programming-guide/#windowing-basics
</div></details>

### Q. 22
データのスケーラブルな処理とBigQueryへのロードを保証すると同時に、これらのイベントをPub/Subトピックにパブリッシュするために構築しているパイプライン内で、メッセージのシーケンシングは気にしなくても、1時間ごとにアプリケーションイベントを集約できるようにするには、どのようなテクノロジを採用すべきでしょうか？
1. 
2. 
3. 
4. Pub/Subトピックから継続的に読み取り、タンブリング・ウィンドウを使用して必要な集約を実行するストリーミングDataflowジョブを作成します。
<details><div>
    答え：4
説明
正しい選択肢はDです。
ストリーミングDataflowジョブはPub/Subトピックからのメッセージを継続的に処理し、タンブリング・ウィンドウを使用して必要な集計を実行できるため、このオプションは正しい。これにより、大量のイベントに対応しながら、タイムリーにデータが処理され、BigQueryにロードされます。
不正解の選択肢
クラウド関数は、新しいメッセージがトピックにパブリッシュされたときにのみトリガされ、1時間ごとの区切りでイベントを処理および集計できないため、オプションAは不正解です。
オプション B は、クラウド関数が Pub/Sub トピックから利用可能なすべてのメッセージをプルし、1 回の実行で必要な集計を実行できるだけであり、1 時間ごとの区切りでイベントを処理および集計することはできないため、不正解です。
バッチデータフロージョブは、Pub/Subトピックから利用可能なすべてのメッセージをプルし、1回の実行で必要な集計を実行できるだけであり、不連続な時間間隔にわたってイベントを処理および集計することはできないため、オプションCは正しくありません。
参考リンク
https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines
</div></details>

### Q. 23
大手金融機関の従業員として、Dialogflowを使用してモバイルアプリケーション内でチャットボットを作成しようとしているあなたは、過去のチャット記録を綿密に調査し、顧客がカスタマーサービスに連絡した理由と一致する意図に従って、すべての会話を分類しました。顧客からの問い合わせの約70%は率直な要求が中心で、通常、最初の10件以内に解決されます。一方、残り30％の問い合わせは複雑で、対応にかなりの時間と労力を要する。このような状況を踏まえて、最初に自動化の優先順位をつけるべきインテントはどれでしょうか？
1. 生のエージェントがより複雑なリクエストに対応できるように、リクエストの70%をカバーする10のインテントを自動化する。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正しい選択肢 A. 
顧客リクエストの70%をカバーする最も一般的な10のインテントを自動化することは、現実的なアプローチです。自動化によって、顧客からの問い合わせの大部分に効率的に対応することに重点を置いています。これらのインテントを自動化することで、一般的なリクエストに対して迅速かつ一貫したレスポンスを提供できるようになり、効率が向上するだけでなく、ユーザーエクスペリエンスも向上します。
生身のエージェントが定型的で頻繁に発生するリクエストの処理から解放されることで、より複雑で個別対応が必要な残りの30%の問い合わせに、より多くの時間と注意を割くことができます。これにより、リソースの割り当てが最適化され、複雑な問題に対する全体的なサービス品質が向上します。
誤ったオプション
オプションB（「より複雑なリクエストを最初に自動化する」）は、場合によっては合理的なアプローチですが、大半の顧客からの問い合わせの効率を最適化するという当面の問題には対処できないかもしれません。複雑なリクエストに集中するあまり、最も一般的で簡単なリクエストがおろそかになる可能性がある。
オプションC（「最も短いインテントと最も長いインテントの混合を自動化する」）は、様々なインテントタイプで自動化のバランスを取ろうとしているが、顧客リクエストの分布と一致しない可能性がある。あまり一般的でないインテントを不必要に自動化する可能性がある。
オプションD（「"payment "などの一般的な単語が一度だけ出現する場所のインテントを自動化する」）は、必ずしも頻度や複雑さではなく、特定のキーワードに基づいてインテントを優先する。このアプローチでは、最も一般的または重要なインテントを捕捉できない可能性があります。
参考リンク
AI製品： https://cloud.google.com/products/ai/
</div></details>

### Q. 24
あなたは、現在構築中のBigQueryベースのデータウェアハウスのデータモデルを作成する責任を与えられました。スター型データスキーマを使用する既存のオンプレミス販売データウェアハウスをBigQueryプラットフォームに移行することが、目下の課題です。しかし、過去30日間の履歴データに対してクエリを実行したところ、パフォーマンスのボトルネックが発生しました。Googleが推奨するベストプラクティスに従って、ストレージ費用を抑えながらクエリ速度を向上させるには、どのような対策を講じればよいでしょうか？
1. 
2. 
3. 
4. トランザクションの日付でデータをパーティショニングします。
<details><div>
    答え：4
説明
BigQueryで過去30日分のデータをクエリする際に、データウェアハウスのストレージコストを増加させずにクエリのパフォーマンスを高速化するには、次のことを考慮する必要があります：
D. 
パーティショニング： パーティショニングとは、特定の属性（この場合はトランザクション日付など）に基づいて、データをより小さく管理しやすい塊に整理することです。パーティショニングは、時間ベースのデータのクエリ・パフォーマンスを向上させる効果的な方法です。データを日付でパーティショニングすると、BigQueryは特定の日付範囲のクエリを実行する際に、無関係なパーティションを効率的に削除することができます。
時間ベースのクエリ： パーティショニングは、過去30日間のデータをクエリする要件に適しています。これにより、BigQueryは関連するパーティションに焦点を当てることができ、データセット全体をスキャンするよりも大幅に高速化されます。
コスト効率： パーティショニングはデータの論理的な整理であるため、ストレージコストを増加させることはありません。使用するストレージの代金は支払いますが、パーティショニング自体がストレージ・コストを増加させることはありません。コストに影響を与えることなく、クエリのパフォーマンスを最適化します。
誤ったオプション
オプションA（データの非正規化）は、特定のタイプのクエリには役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスの問題には特に対応していません。
オプションB（顧客IDごとにデータをシャーディングする）は、日付ベースのクエリのパフォーマンスを直接改善しない可能性があり、特定の日付範囲のデータをクエリするときに複雑さをもたらす可能性があります。
オプションC（ビューで次元データをマテリアライズする）は、クエリを単純化するのに役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスを最適化するには、パーティショニングほど効果的ではないかもしれません。
参考リンク
BigQuery パーティショニング: https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 25
5年分のログデータをクラウドストレージにアップロードしました。あるユーザーから、ログの特定のデータポイントが想定される範囲から外れており、潜在的なエラーがあることを指摘されました。あなたの目的は、この問題を解決し、コンプライアンス目的で元のデータを保持しながら、将来的にプロセスを再実行できるようにすることです。どのような手順を踏むべきでしょうか？
1. 
2. 
3. データフローワークフローを作成し、クラウドストレージからデータを読み取り、予期される範囲外の値をチェックし、値を適切なデフォルトに設定し、更新されたレコードをクラウドストレージの新しいデータセットに書き込む。
4. 
<details><div>
    答え：3
説明
コンプライアンス上の理由から元のデータを保持しながら、ログデータ内の想定範囲外のデータポイントの問題に対処するには、次のことを検討する必要があります：
C. C. 
このオプションが適切な理由は以下の通り：
データ変換： データ変換： データフローを使用することで、元のデータセットを保持したまま、期待範囲外のデータポイントを識別して修正するデータ変換ロジックを実装することができます。これにより、誤ったデータが確実に修正されます。
オリジナルデータの保持： 更新されたレコードをクラウド・ストレージの新しいデータセットに書き込むことで、コンプライアンス上の理由からオリジナル・データの整合性を維持することができます。このアプローチでは、元のデータセットがそのまま維持され、分析や使用のために修正されたクリーンなバージョンが提供されます。
誤ったオプション
オプションA（データをBigQueryにインポートし、エラーのある行をスキップする）はうまくいくかもしれませんが、コンプライアンス上の理由で必要となる可能性がある、元のデータを変更されていない状態で保持することはできません。
オプションB（Compute Engineのインスタンスを作成し、エラーのある行をスキップしながらデータをコピーする）は、手作業で複雑なプロセスになる可能性があり、Dataflowのようなデータ処理フレームワークを使用するほど効率的ではないかもしれない。
オプションD（更新されたレコードをクラウドストレージの同じデータセットに書き込む）は、元のデータを上書きする。
</div></details>

### Q. 26
サーバーレスツールとSOL構文を活用して開発を加速し、パイプラインの実行時間を短縮しながら、スピードと処理要件を満たすGoogle Cloudパイプラインを構築するにはどうすればよいでしょうか？現在のアプローチでは、大規模なデータ変換にPySparkを使用しており、実行に12時間以上かかっています。生データがクラウドストレージに転送されていることは重要です。
1. 
2. 
3. Cloud StorageからBigQueryにデータを取り込み、PySparkコマンドをBigQuery SQLクエリに変換してデータを変換し、変換結果を新しいテーブルに書き込みます。
4. 
<details><div>
    答え：3
説明
Google Cloud上の構造化データで速度と処理要件を満たしながら、開発とパイプラインの実行時間を短縮するには、次のことを検討する必要があります：
C. C. 
サーバーレスでスケーラブル： BigQueryはサーバーレスデータウェアハウスであり、インフラストラクチャを管理することなく大規模なデータ処理を行うことができます。高速処理のために設計されているため、パイプラインの実行時間を短縮できる。
SQL構文： SQL構文を使用したいので、BigQueryは完全に管理された強力なSQLエンジンを提供します。PySparkのコマンドを直接BigQueryのSQLクエリに変換できるので、移行や変換のプロセスがスムーズになります。
クラウドストレージとの統合： BigQueryはクラウドストレージとシームレスに統合されており、クラウドストレージからBigQueryにデータを取り込んで分析や変換を行うことができます。
変換の書き込み： BigQueryはSQL変換の結果を新しいテーブルに書き出すことをサポートしており、元のデータを保持したまま、さらなる分析のために変換されたデータを保存できます。
誤ったオプション
オプションA（Dataproc上でパイプラインを実行する）では、Dataprocクラスタのセットアップと管理が必要になるため、BigQueryのようなフルマネージドサービスを使用する場合と比較して、コスト効率や利便性が劣る可能性があります。
オプションB（Cloud SQLにデータを取り込み、連携クエリを使用）は、データ処理に複数のサービスを使用するため複雑さが生じ、BigQueryのようなパフォーマンスメリットが得られない可能性がある。
オプションD（Apache Beam Python SDKの使用）は有効な選択肢ですが、BigQueryのビルトインSQL機能を活用するのに比べて開発工数がかかる可能性があります。Pythonの使用を好み、データ変換プロセスをより制御する必要がある場合は、Apache Beamが適切な選択肢になる可能性があります。
</div></details>

### Q. 27
テキストファイルを取り込んで変換するDataflowパイプラインをテストしています。Dataflowジョブは、圧縮されたgzipファイル、デッドレターキューによるエラー処理、データ結合のためのSideInputsの利用により、予想よりも遅く実行されています。パイプラインの完了を加速するために、どのようなアクションを取るべきでしょうか？
1. 
2. 
3. 
4. SideInputの代わりにCoGroupByKeyを使用する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
CoGroupByKey： CoGroupByKey: CoGroupByKeyは、Apache Beam（Dataflowの基盤）の変換で、複数の入力PCollectionsからのデータを共通のキーに基づいてグループ化する。複数のソースからのデータを効率的に結合するために使用できます。SideInputsの使用に関連したパフォーマンス問題が発生している場合、CoGroupByKeyに切り替えることが有効な最適化かもしれません。SideInputsは、特に大きなデータセットを扱う場合、要素ごとのルックアップを伴うため、オーバーヘッドが発生する可能性があります。
SideInputsの代わりにCoGroupByKeyを使用するように処理戦略を変更することで、パフォーマンスの問題に対処できる可能性があります。このオプションの選択は、パイプラインの仕様と、どこでボトルネックが発生しているかに依存します。パイプラインの動作とパフォーマンス特性を分析し、十分な情報を得た上で決定することが重要です。
誤ったオプション
オプションA（圧縮Avroファイルへの切り替え）は、主にデータストレージと圧縮効率に対処しますが、特にパフォーマンスのボトルネックが圧縮ではなくデータ処理にある場合、Dataflowジョブを直接迅速化しない可能性があります。
オプションB（バッチサイズを小さくする）は、ある程度ジョブ効率を向上させることができますが、SideInputsやjoinオペレーションに関連するパフォーマンス問題に対処する最も効果的な方法ではないかもしれません。小さいバッチは並列処理に役立つが、処理戦略を根本的に変えないかもしれない。
オプションC（エラーをスローしたレコードを再試行する）は、エラー処理に重点を置いており、ジョブ実行時間の問題に直接対処していない。エラーを効果的に処理することは不可欠ですが、ジョブの完了を早める主要な方法ではありません。
参考リンク
https://beam.apache.org/documentation/transforms/python/aggregation/cogroupbykey/
</div></details>

### Q. 28
あなたは、PII（個人を特定できる情報）データを含む可能性のあるファイルをクラウドストレージにストリームし、最終的にBigQueryにストリームするリアルタイム予測エンジンを構築しています。PIIデータへの不正アクセスを防ぐために、クラウドデータ損失防止API（DLP API）を使用して、名前や電子メールなどの機密データをマスキングしながら参照整合性を維持するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. PIIデータを暗号化フォーマット保持トークンで置き換えて偽名を作成する。
<details><div>
    答え：4
説明
参照整合性を維持しながら、PII データに権限のない個人がアクセスできないようにするには、次のアプローチを検討する必要があります：
D. D. 
このオプションが適切な理由は以下のとおりです：
暗号化形式保存トークン： 暗号化トークン：暗号化トークンを使用することで、PII データの形式と参照整合性を保持したまま、PII データを仮名化することができます。これにより、名前や電子メールなどの結合キーが引き続き効果的に使用できるようになります。
機密データの保護： 暗号化トークンを使用することで、強力なデータ保護が実現し、権限のない個人による機密PIIデータへのアクセスや悪用が困難になります。
不正なオプション
オプション A（暗号化トークンを作成し、トークン化されていないデータをロックダウンされたバケツに保存する）は、PII データを仮名化するという点ではオプション D に似ていますが、フォーマットと参照整合性を維持するために不可欠な暗号化フォーマット保持トークンの使用を指定していません。
オプションB（すべてのPIIデータを再編集する）は、機密情報を永久に削除します。これは、結合キーの参照整合性を維持する必要がある場合には適していない可能性があります。
オプションC（BigQueryのすべてのテーブルをスキャンし、検出したデータをPIIでマスクする）はBigQueryに有効かもしれませんが、クラウドストレージからのPIIデータ取り込みプロセスに直接対応しておらず、暗号化トークンの使用についても言及していません。
参考リンク
クラウドDLP
</div></details>

### Q. 29
図書館の本とその詳細(著者や出版年など)をモニタリングするアプリケーションをオンプレミスのデータ ウェアハウスから BigQuery に移行する際に、借りた書籍の著者に関する情報のクエリ速度を最速にするために、Google が推奨するスキーマ設計手法に従ってデータをどのように構成しますか?既存の設定では、著者の詳細を個別のテーブルに保持し、現在のリレーショナル データベース内の共有キーを介して書籍情報にリンクします。
1. スキーマを同じに保ち、書籍と各属性の異なるテーブルを維持し、現在行っているようにクエリを実行します
2. 幅が広く、作成者の銘、性、年月日など、各属性の列を含むテーブルを作成します
3. 書籍と著者に関する情報を含むテーブルを作成しますが、著者フィールドは著者列内にネストします。
4. スキーマを同じに保ち、すべてのテーブルを結合するビューを作成し、常にビューをクエリします
<details><div>
    答え：3
説明
図書館の図書追跡アプリケーションを BigQuery に移行する際に、借りた各書籍の著者に関するクエリの速度を最適化するには、次の方法を検討する必要があります。
C. 
ネストされたデータ: BigQuery は、テーブル内のネストされたフィールドと繰り返されるフィールドをサポートしています。著者情報を著者列内に入れ子にすることで、コストのかかる結合を回避しながら、書籍と著者の関係を維持できます。これにより、各書籍の著者に関する効率的なクエリが可能になります。
結合の削減: 著者情報を同じテーブル内に保持すると、著者の詳細と書籍の詳細を照会するときに結合が不要になります。これにより、クエリの実行が高速化され、待機時間が短縮されます。
簡略化されたクエリ: 入れ子になったデータを使用すると、クエリを簡略化し、複数のテーブルを結合する複雑さを回避できます。著者情報は、書籍情報と同じ行内で直接アクセスできます。
正しくないオプション -
オプション A (書籍と属性のテーブルを分けてスキーマを同じに保つ) は、結合が必要になる可能性が高く、著者に関するクエリでは効率的ではない可能性があります。
オプション B (各属性の列を含む幅の広いテーブルを作成する) は、特に作成者に複数の属性がある場合、スキーマが非正規化され、保守性が低下する可能性があります。
オプション D(すべてのテーブルを結合するビューを作成する)では、結合が必要になるため、クエリのパフォーマンスが低下する可能性があり、ネストされたデータ構造に対する BigQuery の機能を十分に活用できない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/nested-repeated
</div></details>

### Q. 30
データ ポイントを受信して GUID を生成するサービスを通じて、新しい Web サイト ユーザーにグローバル一意識別子 (GUID) を提供するときに、バックプレッシャーの懸念を最小限に抑えるためにパイプラインを構成するにはどうすればよいでしょうか。このデータは、内部システムと外部システムの両方から発生し、パイプライン内のマイクロサービスを介してHTTP呼び出しを介してアクセスされ、システムへのバックプレッシャーを回避しながら、マルチスレッドの可能性がある毎秒数万件の大量のメッセージの影響を受けます。
1. HTTP経由でサービスを呼び出します
2. パイプラインをクラス定義で静的に作成します
3. DnFnのstartbundleメソッドで新しいオブジェクトを作成します
4. ジョブを 10 秒単位でバッチ処理します。
<details><div>
    答え：4
説明
D. 
このオプションは、メッセージを 10 秒間隔でバッチ処理することを提案します。このアプローチの理論的根拠は次のとおりです。
バックプレッシャーの低減: 処理のためにメッセージをバッチ処理すると、メッセージの取り込みと処理の速度を制限することで、バックプレッシャーを減らすことができます。これにより、パイプラインへのデータフローを制御し、処理負荷の急増を防ぐことができます。
ただし、このアプローチにはトレードオフも生じることに注意することが重要です。
待機時間: メッセージをバッチ処理すると、一部のメッセージが次のバッチ ウィンドウまで遅延する可能性があるため、処理に待機時間が発生する可能性があります。これは、リアルタイムまたは低待機時間の処理が重要なシナリオには適していない可能性があります。
複雑さ: バッチ処理を実装すると、特にマイクロサービスや HTTP 呼び出しを処理する場合に、パイプラインが複雑になる可能性があります。定期的にバッチを管理およびフラッシュするメカニズムが必要になります。
正しくないオプション -
オプション A (HTTP 経由でサービスを呼び出す): このオプションは、通常、リアルタイムまたはほぼリアルタイムの処理に適していますが、バックプレッシャーを減らすという目標に合わない場合があります。各メッセージに対して HTTP 呼び出しを行う際の高スループットと潜在的なボトルネックを考慮することが重要です。
オプション B (クラス定義でパイプラインを静的に作成する) と C (DoFn の startBundle メソッドで新しいオブジェクトを作成する): これらのオプションは、バックプレッシャーに直接対処するのではなく、パイプライン コンポーネントの設計とインスタンス化に関連しています。これらは、高スループットのシナリオにおけるバックプレッシャーの懸念を本質的に軽減するものではありません。
</div></details>

### Q. 31
データ ウェアハウスを Google Cloud に移行し、オンプレミスのデータセンターをシャットダウンしているところです。この取り組みの優先度が高いことを認識した上で、クラウドへの初期データ転送に十分な帯域幅が提供されることを期待しています。移動するファイルの量はそれほど多くありませんが、個々のファイルは 90 ギガバイトを占有します。さらに、トランザクション システムから Google Cloud ベースのウェアハウスへの更新フローをリアルタイムで一定に維持することを目指しています。
データの移行と、ウェアハウスへの中断のない書き込みの保証の両方に推奨されるツールは何ですか?
1. 
2. 
3. gsutil (移行用)Pub/Sub と Dataflow によるリアルタイム更新。
4. 
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
データ移行(gsutil):
gsutil: Google Cloud Storage Utility(gsutil)は、Google Cloud Storage との間でデータを効率的に転送するためのコマンドライン ツールです。これは、90 GB のファイルなどの大きなファイルの移行を処理するのに適しています。これは、初期データ読み込みのための簡単で効率的な選択です。
リアルタイム更新(Pub/Sub とデータフロー):
Pub/Sub: Google Cloud Pub/Sub は、トランザクション システムからダウンストリーム サービスにリアルタイムでデータをストリーミングするために使用できるスケーラブルなメッセージング サービスです。リアルタイムのデータストリーミング用に設計されており、他のGoogle Cloudサービスとうまく統合できます。
データフロー: Google Cloud Dataflow は、強力なストリームおよびバッチ データ処理サービスです。Pub/Sub からのリアルタイム データ ストリームを処理し、変換、集計、その他のデータ処理タスクを実行するために使用できます。リアルタイムのデータ更新に適しており、複雑なデータ処理シナリオを処理できます。
正しくないオプション -
オプション A (移行用のストレージ転送サービス。Pub/Sub と Cloud Data Fusion (リアルタイム更新用):
ストレージ転送サービス: ストレージ転送サービスは大規模なデータ転送に効率的ですが、主に 1 回限りまたは定期的な転送用に設計されています。リアルタイムのデータストリーミングには最適化されていません。
Cloud Data Fusion: Cloud Data Fusion はデータ統合サービスですが、通常はリアルタイムの更新ではなく、バッチ処理や ETL 処理に使用されます。リアルタイムの更新に使用すると、ソリューションが複雑になりすぎる可能性があります。
オプション B(移行用の BigQuery Data Transfer Service。Pub/Sub と Dataproc (リアルタイム更新用):
BigQuery Data Transfer Service: BigQuery Data Transfer Service は、BigQuery への自動データインポートに重点を置いているため、Google Cloud Storage への大容量ファイルの移行には適していない場合があります。
Dataproc: Google Cloud Dataproc は、主に Apache Spark と Hadoop のジョブの実行に使用されますが、リアルタイムの更新には必要ない場合があります。バッチ処理に適しています。
オプション D(移行とリアルタイム更新の両方に gsutil):
gsutil: gsutil はデータ移行には適していますが、リアルタイムのデータ ストリーミングや処理用には設計されていません。リアルタイム更新に gsutil を使用するのは現実的ではありません。
参考リンク -
https://cloud.google.com/storage/docs/gsutil
</div></details>

### Q. 32
Bigtable を使用して取引アプリケーションでこれらのインデックスの株式市場データを保存および提供する際に、すべての主要インデックスの最新の株価にアクセスするための最もシンプルなクエリを確実に行うには、Bigtable 内で行キーとテーブルをどのように構成すればよいでしょうか。
1. 
2. すべてのインデックスに対して一意のテーブルを 1 つ作成し、行キーの設計として逆タイムスタンプを使用します。
3. 
4. 
<details><div>
    答え：2
説明
B. 
このオプションが適切であると考えられる理由は次のとおりです。
すべてのインデックスに対して 1 つのテーブル: すべてのインデックスに対して 1 つのテーブルを使用することで、複数のテーブルを作成する必要がなくなり、管理が簡素化されます。インデックスの数が多い場合は、それぞれに個別のテーブルを管理するのが面倒になる可能性があるため、特に便利です。
行キーとしての逆タイムスタンプ: 行キー設計として逆タイムスタンプを使用すると、最新の株価に簡単にアクセスできます。Bigtable は行を辞書式に並べ替えるため、最新のデータがテーブルの先頭に配置され、効率的に取得できます。
オプションBは機能しますが、いくつかのトレードオフと複雑さが伴います。
複雑な範囲クエリ: 最新のデータを取得するのは効率的ですが、履歴データに対して範囲クエリを実行するとより複雑になる場合があります。古いデータを効率的に取得するために、追加のロジックを実装する必要がある場合があります。
データの分離: 1 つのテーブルを使用すると、すべてのインデックスが一緒に格納されます。特定のインデックスを含むクエリを実行したり、特定のインデックスのデータを分離したりする必要がある場合は、追加のフィルター処理や処理が必要になることがあります。
正しくないオプション -
オプション A (すべてのインデックスに対して一意のテーブルを 1 つ作成し、インデックスとタイムスタンプを行キーの設計として使用します):
この方法では、タイムスタンプを抽出するために解析を必要とする複雑な行キー設計になる可能性があります。これにより、履歴データの範囲クエリの効率が低下する可能性があります。
オプション C (インデックスごとに個別のテーブルを用意し、行キーの設計としてタイムスタンプを使用します):
各インデックスのデータへのアクセスは簡素化されますが、インデックスの数が増えると、個別のテーブルを維持する必要があるため、管理オーバーヘッドが発生する可能性があります。
オプション D (インデックスごとに個別のテーブルを用意し、行キーの設計として逆タイムスタンプを使用します):
このオプションでは、インデックスごとに分離できますが、テーブルが急増し、管理が困難になる可能性があります。
参考リンク https://cloud.google.com/bigtable/docs/schema-design
</div></details>

### Q. 33
データの取り込みやレポート作成のパフォーマンスを損なうことなく 1 つのマスター データセットを維持するには、BigQuery のストリーミング API を使用して、Google が推奨するプラクティスに従って、レポートのみのデータ ウェアハウスのデータ読み込みプロセスをどのように構築すればよいのでしょうか?
1. 
2. 
3. ステージングされたデータを運用テーブルに移動し、ステージング テーブルの内容を 3 時間ごとに削除するステージング テーブルを用意します。
4. 
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
ステージング テーブル: ステージング テーブルを使用して、受信データを最初に取り込んで格納することは、一般的なベスト プラクティスです。これは、データ インジェスト用のバッファーを提供し、インジェスト プロセスを運用データセットから分離するのに役立ちます。
定期的な ETL: ステージング テーブルから運用テーブルに定期的に (この場合は 3 時間ごと) データを移動することで、マスター データセットの更新のタイミングを制御できます。これにより、レポートクエリが進行中の取り込みの影響を受けなくなります。
データのクリーンアップ: データを移動した後にステージング テーブルの内容を削除すると、過剰なデータが蓄積されることなく、新しいデータ インジェストに引き続き使用できます。
正しくないオプション -
オプション D (ステージング テーブルの内容を 30 分ごとに削除する) は、一部のユース ケースでは頻繁すぎる可能性があり、特に監査やエラー分析にデータ保持が必要な場合に、データ管理のオーバーヘッドが増加する可能性があります。
オプション A と B (3 時間または 90 分ごとに運用テーブルを更新する) では、レポート データセットの変更の反映に遅延が発生し、レポートの適時性に影響を与える可能性があります。
参考リンク -
https://cloud.google.com/bigquery/docs/streaming-data-into-bigquery
</div></details>

### Q. 34
新しい Dataflow バッチ ジョブを開始します。ジョブは正常に開始され、いくつかの要素を処理しますが、突然失敗して終了します。Dataflow モニタリング インターフェースにアクセスすると、パイプライン内の特定の DoFn に関連するエラー メッセージが検出されます。
これらのエラーの考えられる根本原因は何ですか?
1. 
2. ワーカー コードの例外
3. 
4. 
<details><div>
    答え：2
説明
B. 
Dataflow ジョブを開始すると、しばらくの間は正常に実行され、ワーカー コードの例外やエラーが原因で失敗することがあります。これらの例外により、ジョブが突然シャットダウンする可能性があります。特定の DoFn (パイプライン内の要素を処理するために定義する関数) に関連するエラーが表示される場合は、その DoFn 内のコードに問題がある可能性があります。
正しくないオプション -
A. ジョブの検証: Dataflow は通常、ジョブを開始する前に検証し、オプションの欠落や構成ミスなどの問題をチェックします。ジョブの検証で問題が発生した場合、ジョブは最初から開始されていない可能性があります。
C. グラフまたはパイプラインの構築: Dataflow パイプラインの構築方法の問題(コンポーネントの接続の誤りやフローの設定ミスなど)に関連します。これらの問題は通常、ジョブの検証または構築中に検出されますが、発生した場合、ジョブが開始時に失敗したり、期待どおりに実行されなかったりする可能性があります。
D. アクセス許可が不十分: これはアクセス許可とアクセス制御に関連しており、ジョブの開始や必要なリソースへのアクセスを妨げる可能性があります。アクセス許可が不十分な場合、ジョブが開始されなかったり、実行前に問題が発生したりする可能性があります。
参考リンク -
https://cloud.google.com/dataflow/docs/guides/common-errors
</div></details>

### Q. 35
新規顧客向けに、Google Cloud コンピューティング リソースの純消費量を詳細に記した日次レポートを迅速かつ効果的に作成し、これらのリソースのユーザーを特定するにはどうすればよいでしょうか。
1. Cloud Logging データを BigQuery に毎日エクスポートします。プロジェクト、ログタイプ、リソース、ユーザーでフィルタリングされたビューを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Google Cloud コンピューティング リソースの正味消費量とリソースを使用したユーザーを示す日次レポートを迅速かつ効率的に生成するには、次のオプションが最も適しています。
ある。
このオプションが適切な理由は次のとおりです。
Cloud Logging から BigQuery へ: ログデータを効率的に保存、分析するための一般的な方法は、Cloud Logging のデータを BigQuery にエクスポートする方法です。これにより、BigQuery のクエリ機能とスケーラビリティを活用できます。
フィルタリング用のビュー: BigQuery でビューを作成すると、プロジェクト、ログタイプ、リソース、ユーザーなどの特定の条件に基づいてデータを事前にフィルタリングできます。この事前フィルタリングにより、レポートを生成するための関連データを操作できるようになります。
毎日のエクスポート: 毎日のエクスポートを実行すると、レポートごとに新しいデータセットを操作でき、データを最新の状態に保つことができます。
正しくないオプション -
オプション B(プロジェクト、リソース、ユーザーで Cloud Logging のデータをフィルタリングし、そのデータを CSV 形式でエクスポートする)は機能する可能性がありますが、より複雑なクエリやレポート要件に対応する BigQuery の柔軟性と拡張性に欠けます。
オプション C(Cloud Logging でデータをフィルタリングして BigQuery にインポートする)では、追加のデータ移動手順が導入されるため、直接エクスポートよりも効率が悪く、タイムリーにならない可能性があります。
オプション D(Cloud Logging データを CSV 形式で Cloud Storage にエクスポートし、Dataprep を使用してクレンジングする)は複雑さを増し、日次レポートを生成するための BigQuery の直接的なアプローチほど効率的ではない可能性があります。
参考リンク -https://cloud.google.com/logging/docs/export/bigquery
</div></details>

### Q. 36
現在、単一のアジア地域内の顧客のみに対応しているスタートアップのWebアプリケーションが、最初はコストの最適化を優先し、後にネイティブJDBCドライバーを使用する要件でグローバルなプレゼンスとパフォーマンスの向上に焦点を当てながら、グローバルな顧客サービスを可能にするための資金を求める場合、どのような手順を踏む必要がありますか?
1. 最初に Cloud Spanner を使用して単一リージョンのインスタンスを構成し、資金を確保した後に複数リージョンの Cloud Spanner インスタンスを構成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
Cloud Spanner のスケーラビリティ: Cloud Spanner は、グローバルに分散された水平方向にスケーラブルなデータベースであり、複数のリージョン間で強力な一貫性を提供できます。単一リージョンのインスタンスから開始し、マルチリージョンのインスタンスを構成することは、資金を確保した後、グローバルなプレゼンスとパフォーマンスを最適化するという目標と一致します。
強力な整合性: Cloud Spanner は、強力な整合性が保証されていることで知られており、データの一貫性が重要なグローバル アプリケーションに適しています。
ネイティブ JDBC サポート: Cloud Spanner はネイティブ JDBC ドライバをサポートし、ウェブアプリケーションの要件との互換性を確保します。
正しくないオプション -
B. 最初に Cloud SQL for PostgreSQL の高可用性インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアのレプリケーションで Bigtable を使用します。
このオプションでは、可用性の高い Cloud SQL for PostgreSQL インスタンスから始めることをお勧めしますが、これは当初必要以上にコストが高くなる可能性があります。Bigtable はグローバル レプリケーションを提供できますが、Cloud SQL を最初に選択した時点では、資金調達前の費用最適化という目標に合致していない可能性があります。
C. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアで Bigtable を使用します。
オプション B と同様に、当初の費用最適化を主な目標としている場合、Cloud SQL for PostgreSQL から始めるのは最も費用対効果の高い選択肢ではない可能性があります。また、Cloud SQL のグローバル拡張機能は、Cloud Spanner に比べて制限されています。
D. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、可用性の高い構成の Cloud SQL for PostgreSQL を使用します。
このオプションでは、Bigtable や Cloud Spanner などのグローバルに分散されたデータベースを使用しないため、グローバルなプレゼンスとパフォーマンスを最適化するという資金調達後の目標に合わない可能性があります。
要約すると、オプション B、C、D にはそれぞれメリットがありますが、オプション A は、Cloud Spanner のグローバルなスケーラビリティと強力な整合性機能を活用して、初期費用の最適化目標と資金調達後のグローバル展開とパフォーマンスの最適化の両方の目標と一致するため、シナリオに最適な選択肢です。
参照リンク - リージョン構成とマルチリージョン構成 - Cloud Spanner
</div></details>

### Q. 37
大規模なデータ転送に関する Google が推奨するベスト プラクティスを遵守しながら、わずか数時間でデータ転送を完了することを目標に、オンプレミスのデータセンターから Google Cloud に 1 PB のデータを安全かつ効率的に移行するには、どのような手順を踏む必要がありますか?
1. 
2. Transfer Appliance を使用し、エンジニアに手動でデータの暗号化、復号化、検証を依頼します。
3. 
4. 
<details><div>
    答え：2
説明
Google が推奨するプラクティスに従いながら、安全な接続を介してオンプレミスのデータセンターから Google Cloud に 1 PB のデータを効率的に移行するには、次のアプローチを検討する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
Transfer Appliance: Google の Transfer Appliance は、大量のデータを安全かつ効率的に移行できるように設計されています。これは、データをオフラインで読み込み、Google Cloud Storage に取り込むために Google に送付するために使用できる物理ストレージ アプライアンスです。
手動暗号化: Transfer Applianceの使用中に、アプライアンスにロードする前にデータを手動で暗号化できます。これにより、転送中のデータセキュリティが確保されます。
手動検証:データ転送が完了した後、エンジニアはデータを復号化して元のデータセットと比較することで、データの整合性を手動で検証できます。この検証プロセスにより、データが正確に転送されたことが保証されます。
正しくないオプション -
オプションA(Cloud Interconnect and Storage Transfer Service)は、わずか数時間で1 PBのデータを移行するために必要な速度を提供しない可能性があるため、このような大量のデータ転送には適していない可能性があります。
オプション C(Cloud VPN、並列 gcloud compute scp ジョブ、チェックサム)は、このような大量のデータを迅速かつ安全に転送するための最も効率的な方法ではない可能性があります。
オプション D(データを 3 TB のバッチに削減し、gsutil を使用し、チェックサムを実行する)は、小規模なデータセットでは実現可能ですが、大量のデータが含まれるため、わずか数時間で 1 PB の移行を行うのは現実的ではない可能性があります。
速度、セキュリティ、Google のベスト プラクティスの遵守を目標とする 1 PB のデータ移行では、手動で暗号化と検証を行う Transfer Appliance の使用をおすすめします。この方法は、大規模なデータセットを Google Cloud に転送するための安全で効率的な方法を提供します。
参考リンク -
https://cloud.google.com/products/data-transfer/
</div></details>

### Q. 38
CSV ファイルを Cloud Storage から BigQuery に読み込む際に、1 つの列に STRING や INT64 などのデータ型が混在していたり、電話番号や住所などの値の形式に一貫性がなかったりするなど、ファイルの既知のデータ品質の問題を考慮して、データ品質を維持し、必要なクレンジングと変換を実行するためのデータ パイプラインをどのように確立すればよいのでしょうか。
1. BigQuery に読み込む前に、Data Fusion を使用してデータを変換します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
変換のための Data Fusion: Google Cloud Data Fusion は、ETL(抽出、変換、読み込み)プロセスのための強力なツールです。データ品質の問題に対処するために不可欠な、データ変換、クレンジング、エンリッチメントの機能を提供します。
高度な変換: Data Fusion では、ビジュアル インターフェースやカスタム コードを使用して複雑なデータ変換を実行できるため、データ型の不一致や一貫性のない書式設定などの問題を処理するのに適しています。
BigQuery との統合: Data Fusion は BigQuery とシームレスに統合できるため、変換されたデータを BigQuery テーブルに直接読み込むことができるため、データ パイプラインが簡素化されます。
オプション A は、BigQuery に読み込む前に Google Cloud Data Fusion を使用してデータ変換を行うもので、データ品質の問題に対処し、高度な変換機能を提供する包括的なアプローチです。これは、シナリオで説明されているように、複雑なデータ クレンジングと変換タスクを処理する場合に推奨される選択肢です。
正しくないオプション -
B. データを BigQuery に読み込む前に、Data Fusion を使用して CSV ファイルを AVRO などの自己記述型データ形式に変換します。
データ形式の変換は特定のシナリオでは役立ちますが、データ型の不一致や一貫性のない書式設定など、質問に記載されているデータ品質の問題に直接対処するものではありません。
C. 目的のスキーマを使用してステージング テーブルに CSV ファイルを読み込み、SQL で変換を実行してから、結果を最終的な変換先テーブルに書き込みます。
変換に SQL を使用することは有効なアプローチですが、データ品質の問題は SQL のみを使用して効果的に処理できることを前提としていますが、複雑な問題には当てはまらない場合があります。
D. 目的のスキーマでテーブルを作成し、CSV ファイルをテーブルにロードし、SQL を使用してその場で変換を実行します。
このオプションでは、最終的な変換先テーブルにデータを直接読み込む必要がありますが、データ品質の問題に事前に対処しないと危険です。一般に、データの検証と変換にはステージング テーブルを使用する方が安全です。
参照リンク: Data Fusion の概要
</div></details>

### Q. 39
e コマース プラットフォームでの顧客の購入確率を予測することを目的とした新しいディープ ラーニング モデルの開発に取り組んでいる間、初期トレーニング データセットと新しいテスト データセットの両方を使用して、モデルのパフォーマンスの評価を実施しました。この評価の結果、モデルが提供されたデータに対して過学習の傾向を示していることが明らかになりました。目的は、新しいデータの結果を予測する際に、モデルの精度を高めることです。この目標を達成するには、どのような手順を踏む必要がありますか?
1. 
2. トレーニング データセットのサイズを大きくし、入力特徴の数を減らします。
3. 
4. 
<details><div>
    答え：2
説明
新しいデータを予測する際の過学習に対処し、深層学習モデルの精度を向上させるには、次のことを行う必要があります。
B. 
このオプションが適切な理由は次のとおりです。
トレーニング データを増やす: トレーニング データセットのサイズを大きくすると、モデルの一般化が向上し、過学習を減らすことができます。データが多いほど、基になるパターンがより広く表現され、新しいデータでのモデルのパフォーマンスが向上する可能性があります。
入力特徴量を減らす: 入力特徴量が多すぎる過度に複雑なモデルは、トレーニング データ内のノイズをキャプチャできるため、過学習する傾向があります。入力特徴の数を減らすことで、モデルを単純化し、最も関連性の高い情報に焦点を合わせることができるため、汎化を改善できます。
過学習を軽減する最も効果的な方法は、トレーニング データセットのサイズを大きくすると同時に、入力フィーチャの数を減らしてモデルを単純化することです。この組み合わせにより、モデルの汎化が向上し、新しいデータの精度が向上します。
正しくないオプション -
オプション A、C、および D は、推奨されるアプローチではありません。
オプション A (データセットのサイズを増やし、入力特徴量を増やす): データセットのサイズと入力特徴の数の両方を増やすと、過学習がさらに悪化する可能性があります。モデルがすでに複雑すぎる場合は、データが多いだけでは役に立たない可能性があります。
オプション C (データセットのサイズを小さくし、入力フィーチャを増やす): データセットのサイズを小さくすると、モデルの一般化がさらに困難になる可能性があります。入力特徴量を増やしてデータを減らすと、モデルがさらにオーバーフィットになる可能性があります。
オプション D (データセットのサイズを小さくし、入力特徴量を減らす): データセットのサイズと入力特徴の数の両方を減らしても、モデルが意味のあるパターンを学習するための十分な情報が得られない可能性があります。
</div></details>

### Q. 40
オンライン小売業者の顧客サービスを強化するためのチャットボットを効果的に作成し、テキストと音声の両方のクエリを処理できると同時に、ローコードまたはノーコードのソリューションを模索し、キーワードベースの応答のための簡単なトレーニングを確保するにはどうすればよいでしょうか?
1. 
2. 
3. 
4. Dialogflow を使用してチャットボットを実装し、収集された最も一般的なクエリに基づいてインテントを定義します。
<details><div>
    答え：4
説明
D. 
Dialogflow は、モバイルアプリ、ウェブ アプリケーション、デバイス、ボット、自動音声応答システムなどに会話型ユーザー インターフェースを簡単に設計して統合できる自然言語理解プラットフォームです。Dialogflow を使用すると、ユーザーがプロダクトと対話するための新しい魅力的な方法を提供できます。Dialogflow では、テキスト入力や音声入力(電話や音声録音など)など、顧客からの複数のタイプの入力を分析できます。また、テキストまたは合成音声のいずれかで、いくつかの方法で顧客に応答することもできます。
参考リンク -
https://cloud.google.com/dialogflow/docs
</div></details>

### Q. 41
航空宇宙企業独自の形式から BigQuery にフライトデータを最も効果的にインポートし、リソース消費を最小限に抑えながら、この新しいデータソース間の接続を確立し、BigQuery へのデータ ストリーミングを容易にするにはどうすればよいでしょうか。
1. 
2. 
3. 
4. Apache Beam カスタム コネクタを使用して、データを Avro 形式で BigQuery にストリーミングする Dataflow パイプラインを作成します。
<details><div>
    答え：4
説明
オプション D. 
このシナリオでは、特定の形式の独自のフライト データがあり、最小限のリソース消費で効率的に BigQuery にインポートする必要があります。
Apache Beam カスタム コネクタと Dataflow を併用して Avro 形式で BigQuery にデータをストリーミングすることは、いくつかの理由から最適な選択肢です。
Apache Beam は、複雑なデータ インジェストと変換タスクを処理できる強力で柔軟なデータ処理フレームワークです。
Avro はコンパクトで効率的なデータシリアル化形式であり、大量のデータのストリーミングと保存に適しています。
カスタム コネクタを使用すると、データ インジェスト プロセスを独自のデータ形式に合わせて調整し、スムーズで効率的なデータ転送を確保できます。
Dataflow は、データ量に合わせて自動的にスケーリングできるマネージド サービスであり、リソースを手動で管理してプロビジョニングする必要性を減らします。
正しくないオプション -
A. 定期的な ETL バッチ ジョブの Cloud Functions の関数をトリガーするシェル スクリプトを記述する:
このオプションは、定期的なバッチジョブの実行を示唆していますが、リアルタイムのデータストリーミングには適していない可能性があります。
また、データのストリーミングに効率的である可能性のある Avro 形式の使用についても言及していません。
B. 標準の Dataflow パイプラインを使用して BigQuery に生データを保存し、後で形式を変換する:
このアプローチでは、データが未加工の形式で BigQuery に保存されますが、これは BigQuery の機能を利用する最も効率的な方法ではない可能性があります。
これには、既に保存されているデータを変換する追加の手順が含まれますが、これは、目的の形式でデータをストリーミングするほどリソース効率が良くない可能性があります。
C. Apache Hive を使用して、データを CSV 形式で BigQuery にストリーミングする Dataproc ジョブを作成します。
Apache Hive はバッチ処理には適したツールですが、リアルタイムのデータ ストリーミングには適していない可能性があります。
CSV 形式は Avro ほどストリーミングに効率的ではなく、より多くのリソースを消費する可能性があります。
オプション D は、Apache Beam とカスタム コネクタを活用して Avro 形式で BigQuery にデータをストリーミングし、リソース消費を最小限に抑えながら効率的かつリアルタイムのデータ取り込みを実現するため、最も適切な選択肢です。
参照リンク - Apache Beam のプログラミング モデル
</div></details>

### Q. 42
オンライン証券会社には、大量の取引処理アーキテクチャが必要です。ジョブをトリガーするセキュア・キューイング・システムを作成する必要があります。ジョブはGoogle Cloudで実行され、同社のPython APIを呼び出して取引を実行します。ソリューションを効率的に実装する必要があります。あなたは何をするべきか?
1. Pub/Sub プッシュ サブスクリプションを使用して Cloud Functions の関数をトリガーし、Python API にデータを渡します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Google Cloud で実行されるジョブをトリガーし、会社の Python API を呼び出して取引を実行する安全なキューイング システムを作成するための最も効率的で適切なオプションは次のとおりです。
オプション A: 
Google Cloud Pub/Sub は、独立したアプリケーション間でリアルタイムかつ信頼性の高いメッセージングを実現するために設計されたメッセージング サービスです。
このシナリオでは、取引リクエストが発行される Pub/Sub トピックを設定できます。
Pub/Sub トピックへのプッシュ サブスクリプションを作成すると、メッセージがトピックにパブリッシュされたときに Cloud Functions の関数が呼び出されます。
その後、Cloud Functions の関数は取引データを Python API に渡して実行できます。
このアーキテクチャは効率的でスケーラブルであり、大量の取引処理に適しています。
正しくないオプション -
オプション B では、Compute Engine インスタンスでホストされるアプリケーションを作成して、Pub/Sub トピックへのプッシュ サブスクリプションを作成することを提案しています。これは機能しますが、Compute Engine インスタンスの管理とスケーリングが必要であり、Cloud Functions を使用する場合ほど効率的ではなく、サーバーレスでもない可能性があります。
オプションCは、NoSQLデータベースでのキューの作成について言及しています。NoSQL データベースはキューイングなど多くの目的に使用できますが、Google Cloud Pub/Sub などの専用のキューイング システムを設定する方が効率的で、この種のタスクに特化して構築されています。
オプション D では、Google Cloud のマネージド ワークフロー オーケストレーション サービスである Cloud Composer の使用について言及しています。Cloud Composer はさまざまなタスクに使用できますが、この特定のユースケースで Pub/Sub で Cloud Functions を直接使用する場合と比較して、単純なメッセージ キューイングと Python API 呼び出しの実行用に Cloud Composer を設定すると、不必要に複雑になる可能性があります。
参考リンク -
https://cloud.google.com/run/docs/triggering/pubsub-push
</div></details>

### Q. 43
あなたの会社は、データベースに 10 TB を超える現在のシステムから医療情報の大きな結果セットを取得し、さらにクエリを実行するためにデータを新しいテーブルに格納できるようにしたいと考えています。データベースは、メンテナンスの少ないアーキテクチャを持ち、SQL経由でアクセスできる必要があります。大規模な結果セットのデータ分析をサポートできるコスト効率の高いソリューションを実装する必要があります。あなたは何をするべきか?
1. 
2. BigQuery をデータ ウェアハウスとして使用する。大きなクエリをキャッシュするための出力先を設定します。
3. 
4. 
<details><div>
    答え：2
説明
大規模な結果セットのデータ分析をサポートしながら、メンテナンスが少なく、SQLへのアクセス性も備えている、最も費用対効果の高いソリューションは次のとおりです。
オプション B: 
説明：
Google BigQuery は、大規模なデータセットや複雑なクエリを処理するために設計された、サーバーレスで拡張性が高く、費用対効果の高いデータ ウェアハウス ソリューションです。
BigQuery は SQL に似たクエリ機能を備えており、SQL 経由でアクセスできます。
ストレージ、インデックス作成、クエリ パフォーマンスの最適化など、データの管理を自動的に処理します。
BigQuery ではクエリ結果をキャッシュできるため、大きな結果セットを複数回取得する際のパフォーマンスが大幅に向上し、クエリ費用を削減できます。
これは完全に管理されたサービスであり、手動のメンテナンスとスケーリングの必要性を排除します。
正しくないオプション -
オプション A(Cloud SQL を使用)とオプション C(Compute Engine で MySQL クラスタを使用)は、手動管理が必要で、BigQuery ほどシームレスにスケーリングできず、データ量が多い場合はコストがかかる可能性があるため、非常に大規模なデータセットや複雑な分析を処理するには最適な選択肢ではない可能性があります。
オプション D(Cloud Spanner を使用)は、グローバルに分散された可用性の高いデータベース サービスですが、大規模な結果セットの分析ではなく、トランザクション データ向けに設計されています。このユースケースでは、最も費用対効果の高いオプションではない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/cached-results
</div></details>

### Q. 44
オンプレミスのデータセンターに 15 TB のデータがあり、Google Cloud に転送したいとします。データは毎週変更され、POSIX 準拠のソースに保存されます。ネットワーク運用チームは、パブリック インターネットに 500 Mbps の帯域幅を付与しました。Google が推奨する方法に従って、週単位で Google Cloud にデータを確実に転送したい。あなたは何をするべきか?
1. 
2. 
3. データ センターにオンプレミス データ用の Storage Transfer Service をインストールし、毎週の転送ジョブを構成します。
4. 
<details><div>
    答え：3
説明
パブリック インターネットへの帯域幅が 500 Mbps の場合、オンプレミスのデータセンターから Google Cloud に 15 TB のデータを毎週確実に転送するには、Google が推奨するデータ転送方法の使用を検討する必要があります。このシナリオでは、
オプション C: 
このオプションが適している理由は次のとおりです。
Storage Transfer Service は、Google Cloud が提供するマネージド サービスで、オンプレミスのデータソースまたは別のクラウド プロバイダから Google Cloud Storage にデータを転送するのに役立ちます。これは、大規模で定期的な転送を効率的に処理するように設計されています。
データセンターに Storage Transfer Service をインストールすると、スケジュールされた自動転送ジョブを設定して、定期的に(毎週など)Google Cloud にデータを移動できます。
Storage Transfer Service は、並列処理、再開可能な転送、および効率的で信頼性の高いデータ転送を保証するその他の機能を処理して、転送プロセスを最適化できます。
正しくないオプション -
オプション A(Cloud Scheduler を使用して gsutil をトリガーする)は機能しますが、gsutil コマンドとそのスケジュールを管理する必要があります。Storage Transfer Service と同じレベルの自動化と組み込みのデータ転送の最適化は提供されません。
オプション B (Transfer Appliance を使用) は、非常に大規模なデータセットや、ネットワーク帯域幅が制限要因となる状況に適しています。ただし、データが 15 TB で帯域幅が 500 Mbps のこのシナリオでは、必要以上に複雑でコストがかかる可能性があります。
オプション D(Google Cloud 仮想マシンへの Storage Transfer Service のインストール)は、標準または推奨されるアプローチではありません。Storage Transfer Service は、データ転送の目的でオンプレミスで実行するように設計されており、仮想マシンにインストールすると、不必要な複雑さが加わります。
参考リンク -
https://cloud.google.com/storage-transfer/docs/overview
</div></details>

### Q. 45
ACID準拠のデータベースを必要とするシステムを設計しています。障害が発生した場合に、システムが必要とする人間の介入が最小限であることを確認する必要があります。あなたは何をするべきか?
1. 
2. 高可用性を有効にして Cloud SQL for PostgreSQL インスタンスを構成するを選択する必要があります。
3. 
4. 
<details><div>
    答え：2
説明
障害発生時に人的介入を最小限に抑えた ACID 準拠のデータベースを必要とするシステムを設計するには、オプション B: 
Cloud SQL for PostgreSQL は、フルマネージドで可用性が高く、ACID 準拠のリレーショナル データベース サービスを提供します。これは、信頼性とデータの整合性で知られるPostgreSQLに基づいています。
Cloud SQL インスタンスの高可用性を有効にすると、同じリージョン内の別のゾーンにスタンバイ レプリカが作成されます。プライマリ・インスタンスに障害が発生すると、スタンバイへの自動フェイルオーバーが発生し、ダウンタイムが最小限に抑えられ、データの整合性が確保されます。
PostgreSQLは一般に、ACID(原子性、一貫性、分離性、耐久性)トランザクションを強力にサポートしているため、データの整合性と信頼性を必要とするアプリケーションに適しています。
誤ったオプション-
オプション A(ポイントインタイム リカバリを使用した Cloud SQL for MySQL)は適切な選択肢ですが、ACID トランザクションをより強力にサポートする PostgreSQL が好まれることがよくあります。
オプション C(複数のクラスタを持つ Bigtable)は、ACID 準拠のリレーショナル データベース機能を提供するようには設計されていません。Bigtable は、さまざまなタイプのワークロードに使用される NoSQL データベースです。
オプション D(マルチリージョン構成の BigQuery)は、このシナリオには適用されません。BigQuery はデータ ウェアハウスおよび分析サービスであり、トランザクション リレーショナル データベースではありません。
参考リンク -
https://cloud.google.com/sql/docs/postgres
</div></details>

### Q. 46
あなたは、小売企業のeコマースWebサイトのデータストレージソリューションの設計を担当しています。同社は毎日膨大な量の取引データを生成しています。高可用性とスケーラビリティを確保しながら、待機時間を最小限に抑えたい。どのGCPサービスまたはデータベースを選択しますか?
1. 
2. 
3. 
4. Cloud Spanner
<details><div>
    答え：4
説明
小売企業のeコマースWebサイト向けのデータストレージソリューションを設計し、高可用性、スケーラビリティ、低遅延に重点を置いたデータストレージソリューションを設計し、毎日膨大な量のトランザクションデータを処理する場合、最適なGCPサービスは次のとおりです。
D. 
高可用性: Cloud Spanner は高可用性を実現するように設計されています。グローバルな分散アーキテクチャにより、複数のリージョン間でデータを複製できるため、リージョンの障害が発生した場合でもデータの可用性を維持できます。
スケーラビリティ: Cloud Spanner は水平方向にスケーラブルなデータベースであり、ビジネスの成長に合わせて増加するワークロードを自動的に処理できます。自動シャーディングと負荷分散を提供するため、大規模なアプリケーションに適しています。
低レイテンシ: Cloud Spanner は、リアルタイムのインタラクションと応答性を必要とする e コマース アプリケーションに不可欠な、データへの低レイテンシの読み取りおよび書き込みアクセスを提供します。
正しくないオプション -
A. Bigtable: Bigtable は拡張性の高い NoSQL データベースですが、e コマース Web サイトのようなトランザクション データには最適ではない可能性があります。これは通常、大規模なデータセットに対して高スループット、低遅延の読み取りと書き込みを必要とするアプリケーションに使用されますが、複雑なトランザクション クエリには最適化されない場合があります。
B. Firestore: Firestore は、モバイル アプリケーションやウェブ アプリケーションに適した NoSQL ドキュメント データベースです。特定のユースケースではうまく機能しますが、eコマースのトランザクションデータに必要なレベルのトランザクションの一貫性が得られない場合があります。
C. Cloud SQL: Cloud SQL はマネージド リレーショナル データベース サービスです。トランザクションの一貫性を提供できますが、特に大量のデータを処理する場合は、非常に高いスケーラビリティと低遅延の要件には最適ではない可能性があります。
</div></details>

### Q. 47
メディアストリーミングプラットフォームは、動画の視聴回数やクリック率などのユーザーインタラクションデータを保存して分析する必要があります。そのためには、高い読み取りと書き込みのスループットを低レイテンシーで処理できるデータベースが必要です。このシナリオに最も適した GCP サービスはどれですか?
1. 
2. 
3. Bigtable
4. 
<details><div>
    答え：3
説明
このシナリオの正しいオプションは C.  です。
Bigtable は、低レイテンシの読み取りおよび書き込み操作で大量のデータを処理できるように設計された、非常にスケーラブルで高性能な NoSQL データベースです。これは、ビデオの視聴回数やクリックスルー率などのユーザー操作データを保存および分析するためにメディア ストリーミング プラットフォームが必要とする、高い読み取りおよび書き込みスループットを低遅延で処理する必要があるシナリオに適しています。
正しくないオプション -
A. BigQuery: BigQuery は、大規模なデータセットに対して SQL のようなクエリを実行するために最適化されたデータ ウェアハウスおよび分析プラットフォームです。Bigtable と比較してクエリのレイテンシが長くなる可能性があるため、リアルタイム、高スループット、低レイテンシのデータ ストレージと取得には最適ではありません。
B. クラウドストレージ:クラウドストレージは、主にファイルやオブジェクトなどの非構造化データを保存するために設計されたオブジェクトストレージサービスです。ユーザー操作のデータ分析に必要な、リアルタイムで低遅延のデータアクセスとクエリ機能は提供されません。
D. Firestore: Firestore は、ドキュメント指向のデータ用に設計された NoSQL データベースであり、モバイル アプリケーションやウェブ アプリケーションによく使用されます。リアルタイム データを処理できますが、メディア ストリーミング プラットフォームの高スループット、低レイテンシの要件に対しては、Bigtable ほどパフォーマンスが高くない可能性があります。また、Firestore にはドキュメントとコレクションの制限があり、非常に高速なデータのスケーラビリティに影響を与える可能性があります。
</div></details>

### Q. 48
組織は、モバイル アプリから収集されたユーザーの行動データに基づいてレコメンデーション システムを構築したいと考えています。複雑なクエリを効率的に処理し、リアルタイム分析機能を提供できるデータベースが必要です。どのGCPサービスを検討すべきですか?
1. 
2. BigQuery
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は B.  です。
ここで説明するシナリオでは、モバイルアプリから収集したユーザー行動データに基づいてレコメンデーションシステムを構築する必要があります。
複雑なクエリ: レコメンデーション システムの構築には、多くの場合、ユーザーの行動を分析し、パーソナライズされたレコメンデーションを生成するための複雑なクエリが含まれます。BigQuery は、大規模なデータセットに対して複雑な SQL クエリを実行するために最適化された、フルマネージドのサーバーレス データ ウェアハウスです。分析ワークロードの処理に優れているため、このシナリオには有力な選択肢となります。
効率性: BigQuery はクエリを効率的に実行するように設計されているため、リアルタイム分析タスクに適しています。大量のデータを処理でき、クエリの応答時間が短くなります。
正しくないオプション -
A. Cloud Bigtable: Bigtable は、高スループットで低レイテンシのデータ アクセス用に最適化された NoSQL データベースです。時系列データやキー値ストレージなどの特定のユースケースには優れていますが、複雑な分析クエリやリアルタイム分析には適していません。
C. Cloud Datastore: Cloud Datastore は、ウェブ アプリケーションやモバイル アプリケーションの構造化データの保存と取得に適した NoSQL データベースです。ただし、複雑なレコメンデーションシステムやリアルタイム分析に必要なパフォーマンスとクエリ機能が提供されない場合があります。
D. Cloud SQL: Cloud SQL はマネージド リレーショナル データベース サービスです。トランザクション ワークロードや構造化データには適していますが、BigQuery の方が適している複雑な分析クエリやリアルタイム分析には適していない可能性があります。
複雑なクエリを効率的に処理し、リアルタイム分析機能を提供する必要があるレコメンデーション システムの場合、分析ワークロードと大規模なデータセットの処理に強みを持つ BigQuery は、GCP サービスとして最適です。
</div></details>

### Q. 49
ある製造会社は、生産設備からのセンサーデータをリアルタイムで監視および分析しようとしています。高速データストリームを取り込んで処理できるデータベースが必要です。どのGCPサービスが最適ですか?
1. Cloud Pub/Sub
2. 
3. 
4. 
<details><div>
    答え：1
説明
このシナリオの正しいオプションは次のとおりです。 A. 
生産設備からのセンサーデータをリアルタイムでモニタリングして分析したいと考えている製造会社にとって、Cloud Pub/Sub は次のような理由から最適な選択肢です。
高速データ ストリームの取り込みと処理: Cloud Pub/Sub は、リアルタイムの高速データ ストリームの取り込みと処理を目的として設計されています。センサーやデバイスからの大量のデータを効率的に処理できます。
リアルタイム データ: Cloud Pub/Sub では、生産設備からのデータをモニタリングして対応するために不可欠なリアルタイムのデータ ストリーミングが可能です。
スケーラビリティ: 多くの構成を行うことなく、データ負荷の増加を処理するように拡張できるため、データ量が時間の経過とともに変化する可能性がある状況に適しています。
正しくないオプション -
B. BigQuery:
BigQuery は、リアルタイムのデータ取り込みや処理よりも、分析クエリやデータのバッチ処理に適しています。
高速データストリームの処理には最適化されておらず、リアルタイム監視に使用すると、複雑さと遅延が増します。
C. クラウドデータストア:
Cloud Datastore は、構造化データの保存と取得に適した NoSQL データベースですが、高速でのリアルタイムのデータ取り込みと処理に特化して設計されているわけではありません。
D. Cloud SQL:
Cloud SQL はマネージド リレーショナル データベース サービスであり、リアルタイムのデータ ストリーミングや高速データ処理には適していません。これは通常、構造化されたトランザクションデータに使用されます。
Cloud Pub/Sub は、リアルタイムのデータ ストリームを処理するために構築されており、製造環境のセンサーからデータを効率的に取り込んで処理できるため、このシナリオに最適です。
</div></details>

### Q. 50
あなたは、車両のリアルタイムの位置データを保存および取得する必要がある物流会社のデータストレージソリューションを設計しています。このユースケースに最適なGCPサービスはどれですか?
1. 
2. Bigtable
3. 
4. 
<details><div>
    答え：2
説明
このシナリオの正しいオプションは B.  です。
Bigtable は、高スループットで低レイテンシのデータ アクセスを実現するように設計された、フルマネージドの NoSQL データベース サービスです。大量のデータを処理でき、車両のリアルタイム位置データの保存に適しているため、このユースケースに最適です。車両の位置を効率的に追跡するために必要なスケーラビリティ、パフォーマンス、およびリアルタイムのデータアクセスを提供します。
正しくないオプション -
A. Cloud SQL: Cloud SQL はフルマネージドのリレーショナル データベース サービスであり、複数の車両のリアルタイムの位置データの保存と取得には適していません。構造化データに適しており、車両のリアルタイム追跡に必要なスケーラビリティとパフォーマンスは提供されません。
C. Firestore: Firestore は、柔軟でスケーラブルなリアルタイムのデータ ストレージ用に設計された NoSQL ドキュメント データベースです。リアルタイム データを処理できますが、車両の大量の位置データを保存するのには適していない場合があります。Firestore は、モバイルアプリやウェブアプリなど、ドキュメント形式のデータ ストレージを必要とするアプリケーションでより一般的に使用されます。
D. Cloud Pub/Sub: Cloud Pub/Sub は、独立したアプリケーション間でメッセージを送受信できるメッセージング サービスです。これはデータベースではなく、データを保存しません。これは、コンポーネント間のリアルタイムのイベントストリーミングとメッセージングに使用できますが、データストレージを目的としたものではありません。
スタート
演習テスト1: Google Cloud Professional Data Engineer - Practice Test #1
スタート
演習テスト2: Google Cloud Professional Data Engineer - Practice Test #2
スタート
演習テスト3: Google Cloud Professional Data Engineer - Practice Test #3
スタート
演習テスト4: Google Cloud Professional Data Engineer - Practice Test #4
法人向けサービスのお問い合わせ
Udemyで教える
出資
規約
ヘルプとサポート
サイトマップ
アクセシビリティに関する声明
特定商取引に関する表記
</div></details>

## 2
### Q. 質問1: 未回答
株式取引記録の保存を担当するデータベースと、カスタマイズ可能な期間内に指定された会社の平均株価を計算するために使用される関連アプリケーションを管理します。これらのレコードは Cloud Bigtable に保存され、取引日時が行キーの最初の部分として機能します。追加されるストックの数が増えるにつれて、数千人の同時ユーザーが発生するアプリケーションのパフォーマンスが低下する兆候が見られます。アプリケーションのパフォーマンスを向上させるには、どのようなアクションを実行する必要がありますか?
1. Cloud Bigtable テーブルの行キー構文を、株式記号で始まるように変更します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Cloud Bigtable から調整可能な期間の平均株価を取得する際のアプリケーションのパフォーマンスを向上させるには、次の点を考慮する必要があります。
A. 
銘柄記号から始まるように行キーの構文を変更することは、特定の銘柄コードの株式データを取得する際のクエリのパフォーマンスを向上させるための適切なアプローチです。
特定の企業の平均株価を照会する場合、それに応じて行キーを構成することで、その特定の銘柄に関連するデータに効率的にアクセスできます。
このアプローチにより、特定の会社の株式データを取得するときにスキャンする必要があるデータの量を減らすことができ、クエリのパフォーマンスが向上します。
正しくないオプション -
B. Cloud Bigtable テーブルの行キー構文を、乱数/秒で始まるように変更します。
このオプションは、特定の企業の平均株価を経時的に取得するユースケースには適していません。乱数を行キーとして使用すると、非効率的で予測不可能なクエリ パターンが発生し、必要なデータへのアクセスが困難になる可能性があります。
C. 株式取引の保存に BigQuery を使用するようにデータ パイプラインを変更し、アプリケーションを更新します。
BigQuery は分析ワークロードには適していますが、特に同時実行性の高いシナリオを扱う場合は、リアルタイムのトランザクション データの保存と取得には適していない可能性があります。
BigQuery に移行するには、データ パイプラインとアプリケーションの両方に大幅な変更が必要になり、複雑で時間がかかる可能性があります。
D. Cloud Dataflow を使用して、各日の株式取引の概要を Cloud Storage の Avro ファイルに書き込みます。Cloud Storage と Cloud Bigtable から読み取ってレスポンスを計算するようにアプリケーションを更新します。
このオプションでは、Cloud Dataflow と Cloud Storage の複雑さが増すため、ユースケースでは必要ない場合があります。
また、Cloud Storage に概要を書き込んでから読み取って計算する必要があるため、平均株価の計算プロセスにレイテンシが加わります。
</div></details>

### Q. 質問2: 未回答
指定した期間内に Cloud Pub/Sub サブスクリプション ソースからのイベントを集計し、その結果の集計を Cloud Storage バケットに保存する Cloud Dataflow ストリーミング パイプラインを管理しています。ソースは、データのスループットを一定に保ちます。パイプラインのデータ処理アクティビティを継続的に監視し、問題があれば警告するには、どのような種類の Stackdriver アラートを作成する必要がありますか?
1. 
2. ソースのサブスクリプション/num_undelivered_messagesの増加と、宛先のインスタンス/ストレージ/used_bytesの変更率の減少に基づくアラート。
3. 
4. 
<details><div>
    答え：2
説明
Cloud Dataflow ストリーミング パイプラインの動作をモニタリングするための Stackdriver アラートを作成するには、ソース(Cloud Pub/Sub サブスクリプション)とデスティネーション(Cloud Storage バケット)の両方の健全性とパフォーマンスを反映する指標に重点を置く必要があります。目標は、パイプラインがデータを正しく処理していることを確認することです。これに基づいて、最も適切なアラート構成は次のとおりです。
B.
この選択の根拠は次のとおりです。
ソースのアラート (Cloud Pub/Sub サブスクリプション):
ソースのサブスクリプション/num_undelivered_messagesを監視することは不可欠です。未配信のメッセージの増加は、データの取り込みまたは処理に問題があることを示している可能性があります。
宛先(Cloud Storage バケット)のアラート:
デスティネーション(Cloud Storage バケット)のインスタンス / ストレージ / used_bytes をモニタリングすることで、データが正しく書き込まれていることが確認されます。使用バイト数の減少は、パイプラインが期待どおりに宛先にデータを書き込んでいないことを示している可能性があります。
正しくないオプション -
オプションA:ソースのサブスクリプション/num_undelivered_messagesの減少は、必ずしも問題を示しているわけではありません。これは、メッセージが処理されるにつれて正常に減少する可能性があります。宛先のインスタンス/ストレージ/used_bytesの変更率の増加を監視するだけでは、パイプラインの動作に関する分析情報が得られない場合があります。
オプションC:ソースのインスタンス/ストレージ/used_bytesの削減は、パイプラインの動作とは直接関係ありません。宛先のサブスクリプション/num_undelivered_messagesの変更率の増加を監視することは、パイプラインの問題を検出するのにそれほど意味がない場合があります。
オプションD:ソースのインスタンス/ストレージ/used_bytesを増やしても、必ずしも問題を示しているとは限りません。これは、データの取り込みによる通常の増加である可能性があります。宛先のサブスクリプション/num_undelivered_messagesの変更率の低下を監視しても、パイプラインの正常性に関する必要な分析情報が得られない場合があります。
</div></details>

### Q. 質問3: 未回答
現在、米国東部のデータセンター内で単一のオンプレミス Kafka クラスターを管理し、グローバルな IoT デバイス メッセージの取り込みを処理しています。多くのリージョンでインターネットアクセスが不十分なため、メッセージがエッジに蓄積され、同時にKafkaクラスターに急増することがあり、その結果、負荷が上昇し、コストが過剰になります。
この状況でGoogleが推奨するクラウドネイティブアーキテクチャは何ですか?
1. 
2. 
3. Cloud Pub/Sub からメッセージを読み取って処理するための Cloud Dataflow を備えた IoT ゲートウェイ。
4. 
<details><div>
    答え：3
説明
メッセージをバッチで送信する IoT デバイスがグローバルにあり、このデータ フローをより効率的かつ費用対効果の高い方法で管理したいシナリオでは、通常、Google が推奨するクラウドネイティブ アーキテクチャでは、スケーラビリティと信頼性のためにマネージド サービスを活用します。この場合、最も適切なオプションは次のとおりです。
C. 
このオプションが推奨される理由は次のとおりです。
IoT ゲートウェイ:IoT ゲートウェイは、エッジの IoT デバイスとクラウドの間の仲介役として機能するデバイスまたはソフトウェアです。特にインターネット接続が不十分なエリアでデバイスを扱う場合に、データをより効率的にバッファリング、集約、および送信できます。ゲートウェイは、メッセージをローカルでバッチ処理し、接続が使用可能になったときにクラウドに送信できます。
Cloud Pub/Sub の場合:Google Cloud Pub/Sub は、世界中の IoT デバイスからのメッセージの取り込みを処理できる、スケーラブルで信頼性の高いメッセージング サービスです。バッチ処理されたメッセージを処理するために必要な柔軟性を提供し、信頼性の高い配信を保証します。
クラウドデータフロー:Google Cloud Dataflow は、サーバーレスのフルマネージド ストリームおよびバッチ データ処理サービスです。Cloud Pub/Sub からのデータを大規模に効率的に処理および変換できます。Dataflow は、自動的にスケーリングすることでメッセージ読み込みの急増に対処し、データ処理パイプラインの費用対効果と信頼性を確保します。
正しくないオプション -
オプション A (センサー デバイスとしてのエッジ TPU):エッジ TPU は、エッジでの機械学習推論用に設計されており、メッセージの保存と送信に最も効率的なソリューションではない可能性があります。これらは通常、特定の AI タスクに使用されます。
オプション B(Kafka クラスタに接続された Cloud Dataflow):Cloud Dataflow は Kafka データを処理できますが、特にグローバルな IoT デバイスを扱う場合は、Cloud Pub/Sub をフルマネージドでスケーラブルな取り込みサービスとして使用する方が効率的です。
オプション D(Compute Engine で仮想化された Kafka クラスタ):Compute Engine インスタンスでの Kafka クラスタの管理は複雑でコストがかかる場合があり、メッセージの急増を効率的に処理するという問題には対処できません。
</div></details>

### Q. 質問4: 未回答
Cloud Datastore を利用して、車両のテレメトリ データをリアルタイムで取り込むことを選択しました。目的は、費用対効果を維持しながら、長期的なデータの増加に対応するストレージソリューションを確立することです。また、このデータのスナップショットを定期的に生成して、代替環境での Cloud Datastore のポイントインタイム リカバリ(PIT)やデータのクローン作成を容易にします。2つの異なる方法を使用して、これらの目標を達成するにはどうすればよいでしょうか。(2つ選択)
1. マネージド エクスポートを使用し、Nearline クラスまたは Coldline クラスを使用して Cloud Storage バケットにデータを保存します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
車両のテレメトリ データをリアルタイムで Cloud Datastore に取り込み、コストを抑えながら長期保存用のデータのスナップショットを作成するという目標を達成するには、次の 2 つの方法を検討できます。
A. 
説明: Cloud Datastore の管理対象エクスポート機能を使用して、データを定期的にエクスポートできます。エクスポート後、データを Cloud Storage バケットに保存します。Nearline または Coldline ストレージクラスを選択することで、コストを低く抑えながら、スナップショットを長期保存用にアーカイブできます。
B. 管理対象エクスポートを使用してから、そのエクスポート用に予約された一意の名前空間の下にある別のプロジェクトの Cloud Datastore にインポートします。
説明: データのスナップショットを作成する別の方法として、Cloud Datastore の管理対象エクスポートを使用する方法があります。エクスポート後、そのエクスポート用に特別に予約された一意の名前空間を使用して、別の Cloud Datastore プロジェクトにデータをインポートできます。これにより、別の環境にデータのコピーを別個に作成できます。
正しくないオプション -
その他のオプション(C、D、E)は、Cloud Datastore データのスナップショットを作成し、コストを最小限に抑えながら長期保存用にアーカイブするという目標に直接対応していません。オプション C と D では、BigQuery にデータをインポートするか、データを管理するアプリケーションを作成するかについて説明しますが、これはスナップショットを作成する最も効率的な方法ではありません。オプションEでは、クラウドソースリポジトリにデータを保存することについて言及していますが、これはデータスナップショットには適していません。
</div></details>

### Q. 質問5: 未回答
あなたは、データサイエンスチームによる分析のために、時系列のトランザクションデータを BigQuery にコピーするデータパイプラインを設定する任務を負っています。このデータは 1 時間ごとに新しいステータスで更新され、初期データセット サイズは 1.5 PB で、毎日 3 TB ずつ増加します。データの構造が複雑で、データ サイエンス チームはそれを使用して機械学習モデルを構築することを計画しています。目的は、データ サイエンス チームのパフォーマンスと使いやすさを最適化することです。
この目標を達成するために、どの2つの戦略を採用すべきでしょうか?(2つ選択してください。
1. 可能な限りデータを非正規化します。
2. 
3. 
4. ステータスの更新が BigQuery に更新されるのではなく、追加されるデータ パイプラインを開発します。
5. 
<details><div>
    答え：1,4
説明
A. 
データを非正規化すると、特に大規模なデータセットを処理する場合に、クエリのパフォーマンスを向上させることができます。非正規化することで、複雑な結合の必要性が減り、クエリをより簡単にすることができます。場合によっては、これにより、データ サイエンティストの使いやすさとクエリのパフォーマンスが向上する可能性があります。
D. 
時系列データに追加のみのアプローチを使用することは、ストリーミング データや頻繁に更新されるデータを処理する場合の一般的な方法です。既存のレコードを更新する代わりに、期間ごとに新しいレコードを追加します(例:毎時)。このアプローチにより、履歴データが保持され、時系列データの自然な流れに合わせることができます。
正しくないオプション -
オプション B (データの構造を可能な限り保持する) は、一般に、データの整合性を維持し、データが理解しやすい状態を維持するための優れたプラクティスです。ただし、場合によっては、クエリのパフォーマンスのために非正規化が必要になることがあります。
オプション C(BigQuery UPDATE を使用してデータセットのサイズをさらに小さくする)は、既存のレコードが頻繁に更新されることを意味するため、時系列データには適していない可能性があります。追加のみのアプローチでは、既存のレコードを更新するのではなく、時間間隔ごとに新しいレコードを追加します。
オプション E(トランザクション データの日次スナップショットを Cloud Storage にコピーし、Avro ファイルとして保存します。BigQuery の外部データソースのサポートを使用してクエリを実行する)は、スナップショットのアーカイブと維持には有効な戦略ですが、トランザクション データのリアルタイム分析には最も効率的なアプローチではない可能性があります。これは、履歴分析やバックアップの目的に適しています。
</div></details>

### Q. 質問6: 未回答
あなたは、次の基準を満たしながら履歴データを処理するためのクラウドネイティブなソリューションを考案する任務を負っています。
- 分析対象のデータが CSV、Avro、PDF 形式で存在し、Dataproc、BigQuery、Compute Engine などの複数の分析ツールがアクセスする必要がある。
- バッチ パイプラインは、毎日のデータの移動を担当します。
- このソリューションでは、パフォーマンスは主な関心事ではありません。
- ソリューションの設計では、可用性を優先する必要があります。
このソリューションのデータストレージをどのように構成しますか?
1. 
2. 
3. 
4. 複数リージョンの Cloud Storage バケットにデータを保存します。Dataproc、BigQuery、Compute Engine を使用してデータに直接アクセスします。
<details><div>
    答え：4
説明
可用性を最大化し、Dataproc、BigQuery、Compute Engine などの複数の分析ツールからアクセスできるようにする必要があるクラウドネイティブの履歴データ処理システムの場合、推奨されるアプローチは次のとおりです。
D. 
このオプションが適している理由は次のとおりです。
マルチリージョンクラウドストレージバケット:マルチリージョンの Cloud Storage バケットにデータを保存することで、高可用性と耐久性が確保されます。データは複数のリージョンにレプリケートされるため、リージョンの停止によるデータ損失のリスクが軽減されます。
直接アクセス:Cloud Storage を使用すると、Dataproc、BigQuery、Compute Engine など、さまざまな Google Cloud サービスのデータに直接アクセスできます。これにより、複雑さとレイテンシーが最小限に抑えられ、分析用のデータへの効率的なアクセスが可能になります。
正しくないオプション -
オプション A(Dataproc 上の HDFS):HDFS は Dataproc で使用できますが、より複雑なソリューションであり、マルチリージョンの Cloud Storage ほど効果的に可用性を最大化できない可能性があります。
オプション B(BigQuery):BigQuery は強力な分析ツールですが、通常は構造化データに使用され、PDF ファイルの取り込みは困難な場合があります。さまざまな形式の未加工のストレージに BigQuery を使用することは、最も効率的なアプローチではない可能性があります。
高可用性が必要な場合は、オプション C (リージョン クラウド ストレージ バケット) が実行可能な選択肢になる可能性がありますが、可用性を最大化するには、特にマルチリージョン アクセスの場合は、オプション D が推奨されます。
</div></details>

### Q. 質問7: 未回答
ペタバイト規模の分析データを管理する任務を負っており、ストレージと処理のプラットフォームが必要です。目標は、Google Cloud でデータ ウェアハウス スタイルの分析を有効にし、データセットを他のクラウド プラットフォーム上のバッチ分析ツールのファイルとして利用できるようにすることです。
これを達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. リージョンの Cloud Storage バケットにデータを保存します。Dataproc、BigQuery、Compute Engine を使用してバケットに直接アクセスします。
4. 
<details><div>
    答え：3
説明
C. 
このオプションは、耐久性とアクセス性を確保するために、リージョンの Cloud Storage バケットにデータを保存する場合に適しています。このデータには、Dataproc、BigQuery、Compute Engine など、さまざまな Google Cloud サービスを使用して直接アクセスできます。このアプローチでは、データの使用方法と処理方法に関して柔軟性があります。
誤ったオプション-
オプション A(データセット全体を BigQuery に保存して処理する):BigQuery はデータ ウェアハウスと分析には優れていますが、特にデータのかなりの部分が頻繁にアクセスされない場合は、ペタバイト規模のデータに対して最も費用対効果の高いソリューションではない可能性があります。すべてのデータを BigQuery に保存すると、コストが高くなる可能性があります。
オプション B(データセット全体を Bigtable に保存して処理する):Bigtable は、高スループットの NoSQL スタイルのワークロード向けに設計されており、従来のデータ ウェアハウス スタイルの分析には適していません。SQLクエリ機能がありません。
オプション D(ウォームデータをファイルとして Cloud Storage に保存し、アクティブデータを BigQuery に保存する):このアプローチは、アクティブなデータとアクティブでないデータを明確に分離している場合には意味があるかもしれませんが、他のクラウド プロバイダーでバッチ分析のためにデータをファイルとして公開する必要性に直接対処するものではありません。アクティブ データを BigQuery に保存することは適切な選択ですが、耐久性のためにウォーム データは引き続き Cloud Storage に保存される可能性があります。
</div></details>

### Q. 質問8: 未回答
あなたは、それぞれ独自のサプライヤーから約 750 の異なるコンポーネントを調達する製造会社の一員です。データセットには、平均して、コンポーネントごとに 1000 個のラベル付き例が含まれています。目的は、倉庫スタッフがコンポーネントの写真から入荷コンポーネントを識別するのに役立つアプリを作成することです。最初の動作バージョンを概念実証として迅速に開発することを目指しています。
どのように進めればよいですか?
1. 既存のデータセットで Cloud Vision AutoML を使用します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
Cloud Vision AutoML はカスタム画像認識タスク専用に設計された機械学習サービスであるため、これは正しいオプションです。これにより、シナリオに不可欠な既存のデータセットを使用してカスタム画像認識モデルをトレーニングできます。オプションAが最良の選択である理由は次のとおりです。
カスタマイズ：Cloud Vision AutoMLを使用すると、特定のユースケースに合わせたカスタムモデルを構築できます。シナリオでは、倉庫作業員が撮影した写真からさまざまなコンポーネントを認識するには、正確な結果を得るためにカスタマイズされたソリューションが必要です。
精度：カスタム モデルは、ドメイン固有のデータでトレーニングされるため、多くの場合、汎用モデルよりもパフォーマンスが高くなります。既存のデータセットを使用してモデルをトレーニングすることで、コンポーネントの認識精度を高めることができます。
使いやすさ:カスタム機械学習モデルのトレーニングは複雑になりがちですが、Cloud Vision AutoML を使用するとプロセスが簡素化され、機械学習の深い専門知識がなくてもアクセスできるようになります。これは、迅速な概念実証という目標とよく一致します。
正しくないオプション -
オプション B: Cloud Vision AutoML を使用しますが、データセットを 2 回削減します。
データセットを減らすと、貴重なトレーニングデータが失われ、モデルの精度に悪影響を与える可能性があります。PoC では、最良の結果を得るために、できるだけ多くの関連データを使用する必要があります。
オプション C: 認識のヒントとしてカスタム ラベルを指定して、Cloud Vision API を使用します。
Cloud Vision API はさまざまな画像分析タスクに役立ちますが、カスタム画像認識を必要とする特定のシナリオには適していない可能性があります。カスタムラベルをヒントとして指定すると認識が向上しますが、ラベル付けされた画像のデータセットが大量にある場合は、Cloud Vision AutoMLでカスタムモデルをトレーニングするほど効果的ではありません。
オプション D: 転移学習手法を活用して独自の画像認識モデルをトレーニングします。
転移学習手法を使用して独自の画像認識モデルをトレーニングすることは有効なアプローチであり、特定のシナリオでは非常に効果的ですが、画像内のコンポーネントを認識するための迅速な概念実証 (PoC) の作成を含む特定の状況には最適な選択肢ではない可能性があります。
</div></details>

### Q. 質問9: 未回答
あなたは画像認識に関連する特殊なプロジェクトに携わっており、チームは、開発したカスタム C++ TensorFlow 操作に主に依存するモデルを作成しました。これらの操作は、主要なトレーニング プロセスに不可欠であり、リソースを大量に消費する行列の乗算を伴います。現在、モデルのトレーニング プロセスが完了するまでに数日かかる場合があります。目標は、Google Cloud アクセラレータを活用して費用対効果を維持しながら、このトレーニング時間を大幅に短縮することです。
この目標を達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. CPU を使用したまま、モデルをトレーニングするクラスターのサイズを増やします。
<details><div>
    答え：4
説明
D. 
カスタム C++ TensorFlow Ops:モデルは、カスタム C++ TensorFlow 演算に大きく依存しています。TPU や GPU とシームレスに連携するようにこれらの運用を移行することは、複雑で時間のかかるプロセスであり、多くの場合、これらのアクセラレータの最適化には大幅なコード変更と専門知識が必要です。
TPUの:Cloud TPU は、特定のディープ ラーニング ワークロード向けの優れたアクセラレータですが、アーキテクチャと互換性のある TensorFlow オペレーション向けに最適化されています。カスタム演算を TPU で実行するように適応させるのは困難な場合があり、モデルが特殊なハードウェアを最大限に活用できない限り、大きなメリットが得られない可能性があります。
GPUサポート:カスタム演算に GPU カーネル サポートを実装することは、GPU の使用を計画している場合、正しい方向への一歩です。ただし、GPU と TPU はアーキテクチャが異なるため、個別の最適化が必要です。このオプションは、特にGPUアクセラレーションをターゲットとしている場合に適しています。
クラスタのスケーリング:CPU にとどまり、クラスターのサイズを増やすことで、複数の CPU ノードにワークロードを分散できます。これにより、計算負荷の高いタスクであっても、トレーニング時間を大幅に短縮できます。多くの場合、トレーニングをスピードアップするための最も簡単で費用対効果の高い方法です。
コストに関する考慮事項:TPU と GPU は、CPU ベースのクラスターと比較して、使用コストが高くなる可能性があります。CPU にとどまり、クラスターをスケーリングすることで、パフォーマンスとコスト効率のバランスを取ることができます。
カスタム C++ TensorFlow 演算を使用するシナリオと、コストを低く抑えながらトレーニング時間を最小限に抑える必要があることを考えると、CPU にとどまり、クラスターをスケーリングする (オプション D) ことが、最も実用的でコスト効率の高いアプローチです。TPU や GPU などのアクセラレータへの移行は長期的な目標かもしれませんが、これらのハードウェア プラットフォーム向けのカスタム運用の最適化に伴う複雑さとコストを慎重に検討して取り組む必要があります。
</div></details>

### Q. 発行： 未回答
自然言語処理領域内の回帰問題に取り組んでおり、1 億個のラベル付き例を含むデータセットを備えています。データをランダムにシャッフルし、90/10 の比率でトレーニング セットとテスト セットに分割しました。ニューラル ネットワークに学習させ、テスト セットでそのパフォーマンスを評価すると、トレーニング セットの二乗平均平方根誤差 (RMSE) がテスト セットの誤差の 2 倍であることがわかります。
モデルのパフォーマンスを向上させるには、どのような手順を実行する必要がありますか?
1. 
2. 
3. 正則化手法 (ドロップアウトやバッチ正規化など) を試して、過学習を回避します。
4. 
<details><div>
    答え：3
説明
モデルの二乗平均平方根誤差 (RMSE) が、トレーニング セットではテスト セットの 2 倍であるという観察結果は、過学習を示しています。過学習は、モデルが学習データに近づきすぎて、一般的なパターンではなく学習データにノイズや特異性をキャプチャすることを学習した場合に発生します。モデルのパフォーマンスを向上させるには、過学習を減らすことに重点を置く必要があります。正しいアプローチは次のとおりです。
C. 
正則化手法:ドロップアウト、バッチ正規化、L2 正則化などの手法は、過学習を軽減するように設計されています。トレーニング中にモデルのパラメーターに制約を導入し、トレーニング データに近づきすぎないようにし、目に見えないデータへの一般化を促進します。
テストセットサイズの拡大(オプションA):トレーニングとテストの分割でテスト サンプルのシェアを増やしても、過学習には直接対処できません。重要なのは、既存のテストセットの相対的なパフォーマンスであり、そのサイズではありません。
より多くのデータを収集する(オプションB):より多くのデータを収集すると、特定のケースでは役立ちますが、必ずしも過学習が解決されるとは限りません。一般に、データセットのサイズを増やすことを検討する前に、まずモデルを最適化し、正則化手法を適用することをお勧めします。
モデルの複雑性を増す(オプションD):モデルの複雑さが増すと、過学習が解決されるどころか悪化する可能性があります。複雑なモデルほどパフォーマンスが向上するというのは、よくある誤解です。適切な正則化を備えた単純なモデルは、多くの場合、過度に複雑なモデルよりも優れた性能を発揮します。
正しくないオプション -
A. トレーニングとテストの分割でテスト サンプルのシェアを増やします。
トレーニングとテストの分割でテスト サンプルの割合を増やしても、過学習の問題に直接対処できるわけではありません。トレーニングとテストの間でデータの割り当てが変更されるだけで、モデルの動作には影響しません。
問題は、テストセットのサイズではなく、モデルがトレーニングセットから未知のデータにうまく一般化できないことです。このオプションでは、過学習の根本原因には対処できません。
B. より多くのデータを収集し、データセットのサイズを大きくしてみてください。
より多くのデータを収集することは、特に意味のあるパターンを学習するための十分なデータがモデルにない場合に、場合によっては有用な戦略となる可能性があります。ただし、このシナリオでは、既にかなりのデータセット (100M の例) があります。
データセットのサイズを大きくしても、過学習の問題に直接対処できない場合があります。過学習は、多くの場合、モデルが複雑すぎるか、使用可能なデータの量に対してパラメーターが多すぎることが原因です。一般に、大規模なデータセットがある場合は、モデルの正則化に重点を置く方が効果的です。
D. 追加のレイヤーを導入したり、使用する語彙や n-gram のサイズを増やしたりするなどして、モデルの複雑さを増します。
モデルの複雑さが増すと、過学習は解決されるどころか悪化する可能性があります。より複雑なモデルでは、トレーニング データにノイズや特異性が当てはめられやすく、一般化が不十分になる可能性があります。
過学習は、通常、モデルが既に複雑すぎて使用可能なデータがない場合に発生します。複雑さを増すことは、推奨されるアプローチではありません。代わりに、モデルを単純化し、正則化手法を適用して過学習を防ぐことをお勧めします。
</div></details>

### Q. 質問11: 未回答
一元化された分析設定では、BigQuery がコア プラットフォームとして機能します。毎日データがアップロードされ、ユーザーに提示する前にデータ変換を担当するETLパイプラインを運用します。ETL パイプラインは頻繁に変更され、時折エラーが発生し、その一部は 2 週間の遅延後にのみ表面化する場合があります。これらのエラーの回復メカニズムを確立すると同時に、バックアップ ストレージのコストを最適化する必要があります。
BigQuery でデータを構造化し、バックアップ戦略を管理するには、どのようなアプローチが推奨されますか?
1. 
2. 月ごとにデータを個別のテーブルに整理し、データをエクスポート、圧縮して Cloud Storage に保存します。
3. 
4. 
<details><div>
    答え：2
説明
オプション B: 
このオプションでは、データを月ごとに個別のテーブルに整理することを提案し、データ管理の適切な方法を提供します。さらに、データをエクスポート、圧縮し、Cloud Storage に保存することをお勧めします。
これが正解である理由は次のとおりです。
月ごとに個別のテーブル:月ごとにデータを個別のテーブルに整理すると、データが分離されます。ETL プロセス中にエラーが発生した場合、またはデータが破損した場合、他の月に影響を与えることなく、影響を受けた月のデータを簡単に特定して回復できます。
エクスポートと圧縮:データをエクスポートして Cloud Storage に保存することは、バックアップの一形態として機能します。データを圧縮することで、ストレージコストを最適化できます。データの破損やエラーが発生した場合は、バックアップしたデータを Cloud Storage から取得し、BigQuery に読み込むことができます。
正しくないオプション -
オプション A: データを 1 つのテーブルに整理し、BigQuery データをエクスポートして圧縮し、Cloud Storage に保存します。
このオプションでは、すべてのデータを 1 つのテーブルに格納することを提案します。Cloud Storage にデータをエクスポートして保存することについては言及していますが、データを時間単位で整理することの利点については考慮されていません。すべてのデータを 1 つのテーブルに格納すると、エラーが発生した場合に特定の期間を分離して回復することが困難になる可能性があります。
オプション C: 月ごとにデータを別々のテーブルに整理し、BigQuery の別のデータセットにデータを複製します。
BigQuery 内の別のデータセットにデータを複製すると、ストレージ費用が大幅に増加する可能性があります。データ復旧のための効率的なバックアップ戦略は提供されません。さらに、正確なポイントインタイムリカバリを可能にするスナップショットデコレーターは利用されません。
オプション D: 月ごとにデータを個別のテーブルに整理し、スナップショット デコレーターを使用してテーブルを破損前の時点に復元します。
BigQuery のスナップショット デコレーターは、特定の時点までデータを復元するのに便利な機能ですが、いくつかの制限があり、このシナリオでは最適な選択ではない可能性があります。
</div></details>

### Q. 質問12: 未回答
組織のマーケティング チームは、顧客データセットのセグメントの更新を定期的に提供します。BigQuery で更新する必要がある 100 万件のレコードを含む CSV ファイルが作成されました。ただし、BigQuery で UPDATE ステートメントを使用しようとすると、quotaExceeded エラーが発生します。
この問題に対処するには、どのような手順を実行する必要がありますか?
1. 
2. 
3. 
4. CSV ファイルから新しい BigQuery テーブルに新しいレコードをインポートします。新しいレコードを既存のレコードとマージし、結果を新しい BigQuery テーブルに書き込む BigQuery ジョブを作成します。
<details><div>
    答え：4
説明
BigQuery で UPDATE ステートメントを使用しているときに quotaExceeded エラーが発生した場合は、通常、1 回のクエリ ジョブで実行できる更新数の上限に達していることを示しています。この問題に対処するための正しいアプローチは次のとおりです。
D. 
このアプローチが最も適している理由は次のとおりです。
拡張性:新しいレコードを別の BigQuery テーブルにインポートすることで、1 つの DML ステートメントで更新の割り当て制限に達することを回避できます。BigQuery は大規模なデータセットのクエリと処理に最適化されており、このアプローチにより、新しいレコードと既存のレコードを効率的にマージできます。
コントロール：この方法では、更新プロセスをより詳細に制御できます。マージ操作は SQL ステートメントを使用して実行できるため、特定の要件に基づいて管理およびカスタマイズしやすくなります。
データの整合性:新しいレコードを別のテーブルにインポートすると、既存のデータを誤って上書きしたり変更したりすることがなくなります。マージ操作の結果をメイン データセットにコミットする前に確認できるため、より安全なアプローチです。
パフォーマンス：BigQuery は大規模なデータセットのクエリ用に設計されており、マージクエリを使用して更新操作を実行することは、大量のデータを効率的に処理するのに適しています。
正しくないオプション -
対照的に、他のオプション(A、B、C)は quotaExceeded エラーに直接対処しないため、BigQuery で大規模なデータセットを更新するための効果的なソリューションではない可能性があります。オプション D は、更新を効率的に処理し、クォータの制限を回避するための構造化されたスケーラブルなアプローチを提供します。
</div></details>

### Q. 質問13: 未回答
組織での GCP の使用が拡大するにつれて、さまざまなチームが独自のプロジェクトを生成し、さまざまなデプロイ フェーズやオーディエンス ターゲティングにさらに拡張しています。各プロジェクトには、個別のアクセス制御設定が必要です。中央の IT 部門では、すべてのプロジェクトにわたるユニバーサル アクセスが必要です。また、Cloud Storage バケットと BigQuery データセットは、プロジェクト間で柔軟に共有する必要があります。ポリシーの数を減らすことでアクセス制御を合理化することを目指しています。
どの 2 つのアクションを追求すべきですか?(2つ選択してください。
1. 
2. アクセス コントロール ポリシーの継承を活用するためのリソース階層を導入します。
3. チームごとに個別のグループを作成し、Cloud IAM ポリシーでグループを指定します。
4. 
5. 
<details><div>
    答え：2,3
説明
アクセス制御管理を簡素化し、ポリシーの数を最小限に抑えながら、組織での GCP の使用の拡大に対応するには、次の手順を検討する必要があります。
B. 
リソース階層を使用すると、それらのプロジェクト内のプロジェクト、フォルダー、およびリソースによって継承される組織レベルのポリシーを定義できます。このアプローチにより、組織レベルで高レベルのアクセス制御ポリシーを設定しながら、プロジェクトレベルでより具体的なポリシーを管理することができます。
C. 
チームごとに個別のグループを作成し、Cloud IAM ポリシーでこれらのグループを指定することで、アクセス管理を効率化できます。ユーザーを個別に指定する代わりに、グループに権限を割り当てることができるため、複数のプロジェクトにまたがるチームのアクセス制御を簡単に管理できます。
正しくないオプション -
A. Cloud Deployment Manager を使用して、アクセスのプロビジョニングを自動化します。
Cloud Deployment Manager は、主に、Infrastructure as Code を含むクラウド リソースのプロビジョニングと管理に使用されます。リソースのプロビジョニングを自動化することはできますが、アクセス制御管理の簡素化やポリシーの最小化には直接対応していません。
D. サービス アカウントは、Cloud Storage バケットと BigQuery データセットのデータを共有する場合にのみ使用します。
サービス アカウントは、自動化されたプロセスやアプリケーションへのアクセスを許可するのに便利ですが、人間のユーザーやチームとアドホックな方法でデータを共有するのには適していない場合があります。サービス アカウントは、通常、特定のプログラムによるアクセスに使用されます。
E.Cloud Storage バケットまたは BigQuery データセットごとに、アクセスが必要なプロジェクトを決定します。これらのプロジェクトへのアクセス権を持つすべてのアクティブ メンバーを検索し、Cloud IAM ポリシーを作成して、これらのすべてのユーザーにアクセス権を付与します。
このアプローチでは、各リソースのユーザーを手動で識別してアクセス権を付与します。時間がかかり、プロジェクトやリソースの数が増えるにつれてエラーが発生しやすくなります。リソース階層とグループを使用すると、アクセス制御に対してよりスケーラブルで組織化されたアプローチを提供できます。
</div></details>

### Q. 質問14: 未回答
米国を拠点とする会社は、ユーザー操作を評価して対応するために設計されたアプリケーションを開発しました。メインデータベーステーブルのデータ量は、毎秒250,000レコードの割合で増加しています。さまざまなサードパーティエンティティが、アプリケーションのAPIを利用して、その機能をフロントエンドアプリケーションに統合します。アプリケーションの API が次の基準に準拠していることを確認する必要があります。
- 単一のグローバルエンドポイントを維持します。
- ANSI SQL のサポートを提供します。
- 最新のデータへの一貫したアクセスを保証します。
これらの要件を満たすには、どのような手順を踏む必要がありますか?
1. 
2. 北米のリーダーである Cloud Spanner と、アジアとヨーロッパで読み取り専用レプリカを実装する
3. 
4. 
<details><div>
    答え：2
説明
アプリケーションが単一のグローバル エンドポイント、ANSI SQL サポート、および最新のデータへの一貫したアクセスを必要とするこのシナリオでは、最適なオプションは次のとおりです。
オプション B: 
その理由は次のとおりです。
グローバルエンドポイント:Cloud Spanner には、アプリケーション用に 1 つのグローバル エンドポイントを作成できるグローバル分散機能が用意されています。これは、世界中のどこからでも要求を処理できる、グローバルで強力な一貫性のあるデータベースを提供するため、サードパーティが API を使用しているシナリオに最適です。
ANSI SQL サポート:Cloud Spanner は ANSI SQL をサポートしているため、標準の SQL クエリと互換性があります。これにより、前述の要件であるSQLを使用してデータを簡単に操作できます。
一貫性：Cloud Spanner は強力なグローバル整合性を備えているため、読み取り専用レプリカを含むすべてのレプリカがリーダーとの整合性が保たれます。これにより、アプリケーションとサードパーティのアプリケーションがどこにあっても、最新のデータにアクセスできるようになります。
グローバル・レプリケーション:アジアとヨーロッパに読み取り専用レプリカを持つことで、北米の主要なリーダーとの一貫性を維持しながら、これらの地域のユーザーとアプリケーションのデータへの低レイテンシーのアクセスを確保できます。
正しくないオプション -
オプション A(BigQuery):BigQuery は大規模なデータセットの分析とクエリ用に設計されていますが、トランザクション システムに必要なリアルタイムの一貫性とグローバル エンドポイント機能を提供しない場合があります。
オプション C(Cloud SQL for PostgreSQL):Cloud SQL はマネージド リレーショナル データベース サービスですが、Cloud Spanner と同じグローバルな分散とスケーラビリティを提供しない場合があり、PostgreSQL は同じレベルのグローバルな一貫性を提供しない可能性があります。
オプション D(Bigtable):Bigtable は、高スループットで大規模なデータ用に最適化された NoSQL データベースです。ANSI SQL をサポートしていない可能性があり、整合性モデルは Cloud Spanner ほど強力ではありません。
</div></details>

### Q. 質問15: 未回答
データ サイエンティストが BigQuery ML モデルを開発し、予測を配信するための ML パイプラインの構築についてサポートを求めています。REST API アプリケーションは、100 ミリ秒未満の待ち時間内に個々のユーザー ID の予測を提供するという基準を満たす必要があります。使用される予測クエリは、SELECT predicted_label、user_id FROM ML.PREDICT (MODEL 'dataset.model', table user_features) です。
この ML パイプラインの作成にはどうすればよいでしょうか。
1. 
2. 
3. 
4. BigQueryIO を使用して Dataflow パイプラインを作成し、クエリからすべてのユーザーの予測を読み取り、BigtableIO を使用して結果を Bigtable に書き込み、アプリケーションが Bigtable から個々のユーザーの予測を読み取れるように、アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与することです。
<details><div>
    答え：4
説明
REST API アプリケーションで BigQuery ML を使用して低レイテンシで予測を提供する場合、最適なオプションは、オプション D: 
その理由は次のとおりです。
レイテンシーに関する考慮事項:個々のユーザー ID のレイテンシーが 100 ミリ秒未満の予測を提供することは、困難な要件です。BigQuery への直接クエリは、この低レイテンシの要件を常に満たしているとは限りません。
データフロー パイプライン:Dataflow パイプラインを作成することで、データを効率的に処理、変換できます。Dataflow は BigQuery から予測を読み取り、低レイテンシのアクセスに最適化された別のストレージ システム(Bigtable など)に書き込むことができます。
Bigtable ストレージ:Bigtable は、低レイテンシ、高スループットのストレージを提供する NoSQL データベースです。Bigtable に予測を保存すると、個々のユーザー ID の予測をすばやく取得できます。
ロールベースのアクセス制御:アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与すると、Bigtable から予測を読み取るために必要な権限がアプリケーションに付与されます。
正しくないオプション -
オプション A (クエリへの WHERE 句の追加とデータ閲覧者ロールの付与):このオプションでは低レイテンシの要件には対応しておらず、BigQuery を直接クエリしてもレイテンシの目標を達成できない可能性があります。
オプション B (承認済みビューの作成):承認済みビューの作成は、特定のデータへのアクセスを制御するのに役立ちますが、必ずしも低レイテンシーの要件に対応できるわけではなく、低レイテンシーで予測を提供する必要があります。
オプション C(クエリから結果を読み取るための Dataflow パイプラインの作成):このオプションはデータの処理に使用できますが、低レイテンシーの要件には対応しておらず、低レイテンシーで予測を提供するソリューションが必要になります。
</div></details>

### Q. 質問 16: 未回答
金融市場データを消費者に配布するアプリケーションを開発する場合、データはリアルタイムで収集されるため、さまざまな手段でこのデータを消費者に配信するための最も適切なソリューションを決定する必要があります。
- リアルタイムイベントストリーム
- ANSI SQLによるリアルタイムストリームおよび履歴データへのアクセス
- バッチ履歴エクスポート
このタスクを効果的に実行するには、どのようなソリューションを採用する必要がありますか?
1. 
2. Cloud Pub/Sub、Cloud Storage、BigQuery
3. 
4. 
<details><div>
    答え：2
説明
金融市場データを消費者とリアルタイムで共有し、リアルタイムのストリームと履歴データへの ANSI SQL アクセスを提供し、履歴のバッチ エクスポートをサポートするアプリケーションを構築する場合、最適なソリューションはオプション B: Cloud Pub/Sub、Cloud Storage、BigQuery です。
このオプションが適している理由は次のとおりです。
Cloud Pub/Sub の場合:これは、リアルタイムのイベントストリームを処理するための優れた選択肢です。市場データを Pub/Sub トピックにパブリッシュして、消費者がリアルタイムでデータをサブスクライブして受信できるようにすることができます。
クラウドストレージ:Cloud Storage を使用して履歴データを保存し、消費者がバッチ エクスポートを通じてアクセスできるようにすることができます。これにより、耐久性、スケーラビリティ、および履歴データへの容易なアクセスが提供されます。
BigQuery の場合:BigQuery は、リアルタイムのストリーム データ(ストリーミング テーブルのクエリ)と履歴データ(保存されたテーブルのクエリによる)への ANSI SQL アクセスを提供する強力なデータ ウェアハウスです。これにより、ストリーミング データに対してリアルタイム分析を実行し、履歴データに対する複雑なクエリをサポートできます。
オプションBは、リアルタイムデータストリーミング、SQLアクセス、およびバッチ履歴エクスポートの効率的かつ費用対効果の高いすべての要件をカバーしています。
他のオプション(A、C、D)では、この特定のユースケースに必要な同じレベルの統合と機能が提供されない場合があります。
</div></details>

### Q. 質問17: 未回答
スケーラブルなデータ収集を必要とする新しいアプリケーションを開発しています。データは一日中アプリケーションから継続的にストリーミングされ、年末までに毎日約 150 GB の JSON データが出力されると予想されています。仕様には次のものが含まれます。
- 生産者と消費者の分離
- 費用対効果に重点を置いた生の取り込みデータを効率的に保存し、無期限に保持する
- ほぼリアルタイムのSQLクエリの実現
- 少なくとも2年分の履歴データを保持し、SQLクエリでアクセス可能
これらの要件を満たすには、どのようなタイプのデータパイプラインを採用する必要がありますか?
1. 
2. 
3. 
4. Cloud Pub/Sub にイベントを発行するアプリケーションを作成し、JSON イベント ペイロードを Avro に変換して Cloud Storage と BigQuery にデータを書き込む Cloud Dataflow パイプラインを作成する必要があります。
<details><div>
    答え：4
説明
所定の要件を満たすには、オプション D: 
オプションDが最良の選択である理由は次のとおりです。
プロデューサとコンシューマのデカップリング:Cloud Pub/Sub を使用すると、プロデューサー(アプリケーション)とコンシューマ(Dataflow パイプラインと BigQuery)を切り離すことができます。これにより、データの取り込みと処理が緊密に結合されなくなります。
スペースとコスト効率の高いストレージ:Avro は、生の JSON と比較して、よりスペース効率が高く、費用対効果の高い形式です。Cloud Storage に Avro 形式でデータを保存すると、ストレージ費用とクエリ パフォーマンスの両面で効率的です。
ほぼリアルタイムの SQL クエリ:Cloud Dataflow はほぼリアルタイムでデータを処理できるため、取り込み後すぐに SQL クエリでデータを利用できるようになります。
履歴データの更新:BigQuery を使用すると、少なくとも 2 年間は履歴データを効率的に保存し、クエリを実行できます。
正しくないオプション -
オプション A: API を提供するアプリケーションを作成します。API をポーリングし、データを gzip 圧縮された JSON ファイルとして Cloud Storage に書き込むツールを作成します。
このオプションには、リアルタイムのデータ インジェストがありません。API をポーリングすると、データ インジェストが遅延し、ほぼリアルタイムではなくなります。
データを gzip 圧縮された JSON ファイルとして Cloud Storage に保存すると、スペース効率が悪くなり、Avro を使用する場合と比較してストレージ コストが高くなる可能性があります。
生データを Cloud Storage に保存することはできますが、ほぼリアルタイムの SQL クエリを効率的に実行することはできません。
このアプローチでは、履歴データを維持し、SQLでクエリを実行することは困難であり、パフォーマンスが低下します。
オプション B: Cloud SQL データベースに書き込み、データを保存するアプリケーションを作成します。データベースを定期的にエクスポートして Cloud Storage に書き込み、BigQuery に読み込むように設定します。
大量の生データの保存に Cloud SQL を使用すると、コストがかかる場合があり、データ ストレージの費用対効果が高くない可能性があります。
Cloud SQL から Cloud Storage に定期的にエクスポートすると、データの可用性にレイテンシが生じる可能性があります。
この設定で SQL を使用して履歴データを効率的にクエリすることは、特に大規模なデータセットの場合、困難な場合があります。
オプション C: Cloud Pub/Sub にイベントを発行するアプリケーションを作成し、Cloud Dataproc で Spark ジョブを作成して、JSON データを Avro 形式に変換し、永続ディスク上の HDFS に保存します。
このオプションでは、Cloud Dataproc で Spark ジョブを設定して管理するため、ソリューションが複雑になります。
永続ディスク上のHDFSにデータを保存することは、長期ストレージにとって最も費用対効果が高くスケーラブルなアプローチではない可能性があります。
JSON データを Avro に変換しますが、Cloud Dataflow が提供するほぼリアルタイムの SQL クエリ機能はありません。
</div></details>

### Q. 質問 18: 未回答
Pub/Sub トピックからメッセージを取り込み、その結果を EU 内の BigQuery データセットに保存する Dataflow パイプラインを運用しています。現在、パイプラインは europe-west4 にあり、それぞれタイプ n1-standard-1 の最大 3 人のワーカーを雇用しています。ピーク時には、特に 3 つのワーカーすべてが CPU 容量をフルに稼働している場合に、パイプラインでレコードを迅速に処理するという課題が発生することがわかりました。
パイプラインのパフォーマンスを向上させるために実行できる 2 つのアクションは何ですか?(2つ選択)
1. 最大ワーカー数を増やします。
2. Dataflow ワーカーには、より大きなインスタンスタイプを使用します。
3. 
4. 
<details><div>
    答え：1,2
説明
A. 
ワーカーの数を増やすと、Dataflow パイプラインでより多くのデータを並行して処理できるようになります。ピーク時に既存のワーカーが最大 CPU 使用率に達していることが観察された場合、ワーカーを追加することで負荷をより効果的に分散し、スループットと処理速度を向上させることができます。
B. 
より大きなインスタンスタイプを使用すると、各ワーカーにより多くの CPU とメモリリソースが提供されます。これは、CPU 使用率がボトルネックになっている場合に、Dataflow パイプラインのパフォーマンスを向上させるのに特に効果的です。より大きなインスタンスにアップグレードすると、ワーカーが処理ワークロードをより効率的に処理するのに役立ちます。
正しくないオプション -
オプション C は当初、ゾーンの変更として言及されていましたが、通常、Dataflow ジョブのパフォーマンスに直接影響することはありません。地理的な配置が重要です。
オプション D の Bigtable で一時テーブルをバッファとして作成するという方法は、バッファリングのアプローチですが、複雑さとストレージ コストが増す可能性があります。これは、Dataflow のパフォーマンスを向上させるための最も簡単なソリューションではありません。
オプション E(Cloud Spanner に一時テーブルをバッファとして作成する)は有効なアプローチですが、Dataflow パイプラインの CPU 使用率の問題に対処するための主要なソリューションではない可能性があります。CPUのボトルネックに直接対処するのではなく、データのバッファリングとデータの整合性の維持に重点を置いています。
</div></details>

### Q. 質問19: 未回答
時系列指標の集計と Bigtable への書き込みを担当する Dataflow ジョブを特徴とするデータ パイプラインを管理しています。Bigtable 内でデータ更新の遅延が発生していますが、このデータは、組織内の何千人ものユーザーがアクセスするダッシュボードにとって非常に重要です。パフォーマンスを向上させ、より多くの同時ユーザーに対応し、データの書き込み時間を短縮するには、2 つの推奨アクションは何ですか?(2つ選択してください。
1. 
2. PipelineOptions で maxNumWorkers を設定して、Dataflow ワーカーの最大数を増やします。
3. Bigtable クラスタのノード数を増やします。
4. 
5. 
<details><div>
    答え：2,3
説明
Dataflow パイプラインのパフォーマンスを向上させ、Bigtable へのデータ書き込みに必要な時間を短縮しながら、追加の同時ユーザーをサポートするには、次のアクションを検討する必要があります。
B. 
Dataflow ワーカーの数を増やすと、パイプラインでデータの処理と書き込みを並行して行うことができるため、Bigtable への書き込みパフォーマンスが大幅に向上します。このアクションは、ワークロードをより効果的に分散し、データの更新を高速化するのに役立ちます。
C. 
Bigtable クラスタにノードを追加すると、容量とスループットが向上します。これにより、Bigtable は大量の書き込み操作を処理できるため、レイテンシが短縮され、データの更新がより迅速に行われるようになります。Bigtable を適切にスケーリングすることは、書き込みパフォーマンスを向上させるために重要です。
正しくないオプション -
オプション A は、ローカル実行を使用するように Dataflow パイプラインを構成するもので、通常、開発とデバッグの目的で使用されます。これは、実稼動パイプラインのパフォーマンスを向上させるための適切なアプローチではありません。
オプション D では、Bigtable への書き込み前にフラット化変換を使用すると、パイプライン内のデータ変換に役立つ可能性がありますが、Bigtable へのデータ書き込みのパフォーマンスには直接対処しません。
CoGroupByKey 変換を使用するオプション E は、通常、より複雑なシナリオでデータをグループ化して結合するために使用されます。これは、Bigtable への書き込みパフォーマンスの向上とは直接関係がない可能性があります。
</div></details>

### Q. 発行： 未回答
スケジュールに従って動作する Cloud Dataproc クラスタで、複数の Spark ジョブ(一部は順番に実行し、他は同時に実行)の実行を自動化するにはどうすればよいでしょうか。
1. 
2. 
3. Cloud Composer で有向非巡回グラフ(DAG)を作成する:
4. 
<details><div>
    答え：3
説明
オプション C: Cloud Composer で有向非巡回グラフ(DAG)を作成する:
正しいオプションの説明:Cloud Composer は、Google Cloud のマネージド Apache Airflow サービスで、複雑なワークフローを調整するために設計されています。Airflow では、有向非巡回グラフ (DAG) を作成して、ワークフローを定義およびスケジュールできます。このコンテキストでは、Spark ジョブのシーケンスと依存関係を表す DAG を作成できます。この DAG をスケジュールして、目的の順序でジョブを実行できます。
正しくないオプション -
オプション A: Cloud Dataproc ワークフロー テンプレートを作成します。
Dataproc ワークフロー テンプレートを作成して Dataproc ジョブのスケジュールを設定することはできますが、Spark ジョブ間の複雑な依存関係の管理やジョブの同時実行には適していない可能性があります。Dataproc ワークフロー テンプレートは、ジョブの順次実行をより簡単に行うことができます。
オプション B: ジョブを実行するための初期化アクションを作成します。
初期化アクションは、通常、起動時に Dataproc クラスタを構成するために使用されます。これらは、ジョブのオーケストレーションや依存関係を管理するようには設計されていません。このオプションでは、複雑なジョブ シーケンスをきれいに表現することはできません。
オプション D: Bash スクリプトを作成します。
Bash スクリプトを使用してクラスターを手動で作成し、ジョブを実行し、クラスターを破棄すると、エラーが発生しやすくなり、ジョブの依存関係とスケジュールを管理するための組み込み機能が不足しています。これは、Airflow(オプションC)のような専用のワークフローオーケストレーションツールと比較して、効率と拡張性に欠けるソリューションです。
</div></details>

### Q. 質問21: 未回答
現在、ジョブジェネレーターとジョブランナーという 2 つの異なるカテゴリのアプリケーション間でのデータ共有を容易にするデータパイプラインを構築しているところです。ソリューションには、使用量の増加に適応できるスケーラビリティがあり、既存のアプリケーションのパフォーマンスに悪影響を与えることなく、新しいアプリケーションをシームレスに統合できることが不可欠です。この目標を達成するために、どのように進めるべきでしょうか?
1. 
2. Cloud Pub/Sub トピックを使用してジョブを発行し、サブスクリプションを使用してジョブを実行します。
3. 
4. 
<details><div>
    答え：2
説明
既存のアプリケーションに悪影響を与えることなく、使用量の増加と新しいアプリケーションに対応できるスケーラブルなデータパイプラインを構築するための最も適切な選択肢は次のとおりです。
B. 
このオプションが適している理由は次のとおりです。
拡張性:Cloud Pub/Sub は、大量のメッセージや複数のサブスクライバーへの配信を処理できる、拡張性の高いメッセージング サービスです。使用量が増えると、Pub/Sub は追加の負荷をシームレスに処理できます。
コンポーネントのデカップリング:Cloud Pub/Sub では、ジョブジェネレータ(パブリッシャー)とジョブランナー(サブスクライバー)を切り離すことができます。新しいアプリケーションは、既存のトピックに影響を与えることなく、関連する Pub/Sub トピックをサブスクライブするだけで済みます。この分離により、新しいアプリケーションを追加しても、既存のアプリケーションのパフォーマンスに悪影響を与えることはありません。
柔軟性：Pub/Sub は柔軟性が高く、さまざまなメッセージ形式に対応できるため、さまざまなタイプのアプリケーションに適しています。
非同期：Pub/Sub は非同期で動作するため、システムのさまざまなコンポーネント間で効率的かつ応答性の高い通信が可能になります。
正しくないオプション -
オプション A(App Engine で API を作成する)は機能しますが、使用量の増加に応じて、エンドポイントの管理とスケーリングに関する考慮事項が必要になる場合があります。既存のアプリケーションに影響を与えずに新しいアプリケーションを追加するには、それほどシームレスではない可能性があります。
オプション C(Cloud SQL を使用)と D(Cloud Spanner を使用)にはリレーショナル データベースが含まれるため、大量のメッセージやアプリケーション間の非同期通信の処理には Pub/Sub ほど適していない可能性があります。
</div></details>

### Q. 質問22: 未回答
Cloud Spanner で、商品の販売データを保存する新しいトランザクション テーブルを作成する必要があります。主キーとして何を使用するかを決定します。パフォーマンスの観点から、どの戦略を選択する必要がありますか?
1. 
2. 
3. ランダムな汎用一意識別子番号 (バージョン 4 UUID):
4. 
<details><div>
    答え：3
説明
オプション C: 
UUID (Universally Unique Identifier) を主キーとして使用すると、一意性を強力に保証できます。UUID は分散システム間で一意になるように生成されるため、特に複数リージョンのデプロイで重要な競合を回避するのに役立ちます。
正しくないオプション -
オプション A: 現在のエポック時間:
現在のエポック時間を主キーとして使用すると、書き込み負荷の高いシナリオで問題が発生する可能性があります。複数のトランザクションが同時に発生すると、同じタイムスタンプが共有され、競合やパフォーマンスの問題が発生する可能性があります。
オプション B: 製品名と現在のエポック時間の連結:
オプション A と同様に、この選択では書き込み競合の問題が発生する可能性があります。同じ商品の複数の販売が同時に発生すると、同じキーを共有し、パフォーマンスのボトルネックにつながる可能性があります。
オプション D: 販売システムからの元の注文識別番号 (単調に増加する整数)。
単調に増加する整数は特定のシナリオに適している可能性がありますが、すべてのユース ケースに最適な選択であるとは限りません。特に書き込み集中型の状況では、ホットスポットや不均一なデータ分散につながる可能性があります。注文が必ずしも厳密な順序で到着するとは限らない販売システムでは、単調に増加する整数だけに頼ることは理想的ではない場合があります。
</div></details>

### Q. 質問23: 未回答
貴社のデータ アナリストは、プロジェクトで Cloud IAM オーナーのロールを保持し、さまざまな GCP プロダクトでの作業を円滑に進めます。会社のポリシーにより、BigQuery のデータ アクセスログを 6 か月間保持することが義務付けられています。あなたの仕事は、これらのログへのアクセスを、すべてのプロジェクトにわたって指定された監査担当者に制限することです。
これを達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 集計されたエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。エクスポートされたログを含むプロジェクトへのアクセスを制限します。
<details><div>
    答え：4
説明
社内の監査担当者のみがすべてのプロジェクトのデータアクセスログにアクセスでき、ログを 6 か月間保持できるようにするための正しいアプローチは、オプション D です。
オプション D: 
このオプションが最も適している理由は次のとおりです。
集約されたエクスポート シンク:集約されたエクスポート シンクを使用すると、複数のプロジェクトから 1 つの場所にログをエクスポートできるため、監査ログの一元的な管理とアクセスが容易になります。
クラウドストレージバケット:Cloud Storage バケットへのログのエクスポートは、ログを安全に保存するための一般的で効率的な方法です。
監査ログ用に新しく作成されたプロジェクト:監査ログ専用の別のプロジェクトを作成すると、ログを分離してセキュリティで保護するのに役立ちます。このプロジェクトにアクセスできるのは、許可された担当者のみです。
アクセスの制限:エクスポートされたログを含むプロジェクトでIAMポリシーとアクセス制御を設定することで、アクセスを監査担当者のみに制限し、許可された個人のみがログにアクセスして確認できるようにすることができます。
正しくないオプション -
オプション A: 各データ アナリストのプロジェクトでデータ アクセス ログを有効にします。Cloud IAM ロールによる Stackdriver Logging へのアクセスを制限します。
このオプションでは、各データ アナリストのプロジェクトでデータ アクセス ログを個別に有効にしてから、Stackdriver Logging へのアクセスを制限します。ただし、このオプションにはいくつかの欠点があります。
複雑さ：複数のプロジェクトでデータアクセスログを個別に有効にすることは、特にプロジェクトとデータアナリストの数が増えるにつれて、管理が複雑になる可能性があります。
限定的な中央集権化:ログは複数のプロジェクトに分散し、アクセス制御を効果的に一元化して管理することが困難になります。
潜在的なギャップ:個々のプロジェクト構成によっては、一部のログがキャプチャされず、監査にギャップが生じる可能性があります。
限定的な保持制御:すべてのプロジェクトで一貫した保持期間を管理することは困難な場合があります。
オプション B: プロジェクトレベルのエクスポート シンクを介して、データ アナリストのプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。Cloud Storage バケットへのアクセスを制限します。
このオプションでは、各データアナリストのプロジェクト内の Cloud Storage バケットにログをエクスポートし、アクセスを制限します。問題は次のとおりです。
分散ストレージ:ログは複数のプロジェクトに分散され、中央監査が複雑になる可能性があります。
限定的な制御:データアクセスログの保持とアクセス制御は、プロジェクトごとに個別に管理されるため、統一されたポリシーを適用することは困難でした。
アクセスの複雑さ:プロジェクトごとに個々の Cloud Storage バケットのアクセス制御を管理するのは面倒な場合があり、権限の一貫性を確保するのは困難です。
オプション C: プロジェクトレベルのエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータ アクセス ログをエクスポートします。エクスポートされたログでプロジェクトへのアクセスを制限します。
このオプションでは、監査ログ用の新しいプロジェクトを作成しますが、個々のプロジェクトからログをエクスポートします。このアプローチには、次のような問題があります。
散在エクスポート:監査ログ用の中央プロジェクトを作成しても、ログは個々の Data Analyst プロジェクトからエクスポートされるため、一元化されません。
アクセス制御の複雑さ:ログを含む中央プロジェクトでのアクセス制御の管理は複雑になる可能性があり、アクセスを完全に一元化するわけではありません。
保持管理:一貫した保存期間を確保することは、依然として困難な場合があります。
</div></details>

### Q. 質問24: 未回答
組織内の各分析チームが、それぞれのプロジェクト内で BigQuery ジョブを運用し、プロジェクト固有のスロットの使用状況を効果的にモニタリング、追跡できるようにするにはどうすればよいでしょうか。
1. 
2. BigQuery の指標スロット数 / allocated_for_projectに基づいて Cloud Monitoring ダッシュボードを作成する
3. 
4. 
<details><div>
    答え：2
説明
B. 
その理由は次のとおりです。
BigQuery にはスロット割り当て用のネイティブ指標が用意されており、スロット数/allocated_for_project指標はプロジェクトに割り当てられたスロット数を追跡するために特別に設計されています。このメトリックを使用すると、プロジェクト・レベルでスロットの使用状況をモニターできます。
このネイティブ指標に基づいて Cloud Monitoring ダッシュボードを作成することは、各分析チームのプロジェクトのスロットの使用状況をモニタリングする最も簡単で正確な方法です。
正しくないオプション -
A. BigQuery 指標クエリに基づいて Cloud Monitoring ダッシュボードを作成するscanned_bytes
このメトリックは、スロット割り当てではなくクエリによってスキャンされたデータに関連しており、プロジェクト レベルでのスロットの使用状況に関する直接的な分析情報は提供されません。
C. 各プロジェクトのログ エクスポートを作成し、BigQuery ジョブ実行ログをキャプチャし、totalSlotM に基づいてカスタム指標を作成し、カスタム指標に基づいて Cloud Monitoring ダッシュボードを作成します
このオプションには、ログのエクスポート、カスタムメトリックの作成、ダッシュボードの構成など、より複雑な設定が含まれます。可能ですが、より複雑で、ネイティブのスロット/allocated_for_projectメトリックと同じレベルの精度と使いやすさが得られない場合があります。
D. 組織レベルで集計ログのエクスポートを作成し、BigQuery ジョブの実行ログをキャプチャし、totalSlotMs に基づいてカスタム指標を作成し、カスタム指標に基づいて Cloud Monitoring ダッシュボードを作成します
オプションCと同様に、これには複雑なセットアップが必要であり、目的であるプロジェクトレベルでのきめ細かな監視が提供されない可能性があります。さらに、組織レベルでのログのエクスポートは、プロジェクト固有の監視に効率的でないか、必要ではない場合があります。
</div></details>

### Q. 質問25: 未回答
あなたはストリーミング Cloud Dataflow パイプラインを担当しています。エンジニアは、個別のウィンドウ処理アルゴリズムとトリガー戦略を組み込んだ新しいバージョンのパイプラインを開発しました。目的は、更新中のすべてのデータの保持を保証しながら、この新しいバージョンで既存の実行中のパイプラインをアップグレードすることです。
どうすればこれを実現できますか?
1. 
2. 
3. 
4. [ドレイン] オプションを使用して Cloud Dataflow パイプラインを停止します。更新されたコードで新しい Cloud Dataflow ジョブを作成します。
<details><div>
    答え：4
説明
D. 
正しい説明は次のとおりです。
オプション D では、既存の Cloud Dataflow パイプラインを [ドレイン] オプションで停止します。「ドレーン」オプションを使用すると、既存のジョブは停止する前に残りのデータの処理を完了できます。ドレインが完了したら、更新したコードで新しい Cloud Dataflow ジョブを作成し、開始できます。このアプローチにより、新しいジョブに移行する前にすべてのデータが古いジョブによって処理され、データ損失が最小限に抑えられ、スムーズな移行が保証されます。
誤ったオプション-
オプション A では、同じジョブ名を使用して --update オプションで既存のジョブを更新すると、更新で問題やデータ損失が発生した場合、実行中のジョブに影響を与える可能性があるため、リスクが伴う可能性があります。クリーンな移行は提供されません。
オプション B では、新しい一意のジョブ名を使用して --update オプションで既存のジョブを更新することが有効なアプローチになる場合がありますが、2 つのジョブが同時に実行される可能性があり、リソースが限られている場合は望ましくない可能性があります。
オプション C の [キャンセル] オプションを使用して Cloud Dataflow パイプラインを停止すると、既存のジョブが突然停止し、データの損失や処理の不完全な状態につながる可能性があります。スムーズな移行には適していません。
</div></details>

### Q. 質問26: 未回答
送信ネットワーク容量が 20 Mb/秒に制限されている場合、6 か月間に 2 PB の履歴データをオンプレミス ストレージ アプライアンスから Cloud Storage に転送するにはどうすればよいでしょうか?
1. Transfer Appliance を使用してデータを Cloud Storage にコピーする
2. 
3. 
4. 
<details><div>
    答え：1
説明
正しいオプションは A. Transfer Appliance を使用してデータを Cloud Storage にコピーする です。
Transfer Appliance は、大規模なデータ転送を容易にするために Google が提供する物理デバイスです。2 PB の履歴データを 6 か月以内に移行するという制約と、送信ネットワーク容量が 20 Mb/秒に制限されていることを考えると、Transfer Appliance を使用するのが最も効率的で効果的なアプローチです。Transfer Appliance を使用すると、大量のデータをアプライアンスにオフラインでコピーし、それを Google に返送して Cloud Storage に直接データを取り込むことができます。この方法では、ネットワークの制約が回避され、大規模なデータセットを高速かつ確実に転送できます。
正しくないオプション -
オプション B (コンテンツの圧縮に使用) は、ここでの主な制約は送信ネットワーク容量の制限であり、データを圧縮してもそれには対処されないため、大きな利点が得られない可能性があります。gsutil cp -J
オプション C (ストレージ転送サービスを使用) では、インターネットを使用してデータを転送しますが、ネットワーク容量が限られているため、効率的ではない可能性があります。
オプション D ( を使用、または ) は、 によって使用される帯域幅を制限することを目的としていますが、このような大量のデータをタイムリーに転送するには、最も効果的なソリューションではない可能性があります。trickleionicegsutil cpgsutil cp
参考リンク -
データ転送:- https://cloud.google.com/products/data-transfer/
</div></details>

### Q. 質問27: 未回答
サードパーティからCSV形式の月次データファイルを定期的に受信しており、データクレンジングのソリューションが必要です。ただし、ファイル スキーマは 3 か月ごとに変更されます。このトランスフォーメーションプロセスの主な要件は次のとおりです。
- 変換の実行をスケジュールする。
- 開発者以外のアナリストが変換を変更できるようにする。
- 変換を設計するためのグラフィカルツールを提供します。
これらの要件を満たすには、どのような手順またはアプローチを取る必要がありますか?
1. Dataprep by Trifacta を使用して変換レシピを構築および管理し、スケジュールに基づいて実行する
2. 
3. 
4. 
<details><div>
    答え：1
説明
要件に最適なオプションは、A. Dataprep by Trifacta を使用して変換レシピを構築および管理し、スケジュールに基づいて実行することです。
その理由は次のとおりです。
スケジュールに従った変換の実行: Dataprep by Trifacta では、変換レシピの実行をスケジュールできます。定期的なジョブを設定して、受信する月次 CSV データを自動的に処理できます。
デベロッパー以外のアナリストが変換を変更できるようにする: Dataprep は、コーディングのスキルを必要としない、使いやすいグラフィカル インターフェースを提供します。デベロッパー以外のアナリストは、Dataprep が提供するビジュアル ツールを使用して変換を設計、変更できます。
変換をデザインするためのグラフィカル ツールの提供: Dataprep は、データ変換レシピをデザインするためのビジュアル インターフェースを提供します。アナリストは、コードを記述することなく、これらの変換を簡単に作成、変更、およびテストできます。
正しくないオプション -
オプション B(BigQuery にデータを読み込み、SQL クエリを使用する)は、固定スキーマでは機能する可能性がありますが、3 か月ごとのスキーマ変更に対応できる柔軟性はありません。また、開発者以外のアナリストに必要なグラフィカル ツールも提供されません。
オプション C(Python で Dataflow パイプラインを記述する)はコーディングを伴い、特にデベロッパー以外のアナリストにとっては使い勝手が悪い場合があります。また、スキーマの変更を処理するために、かなりの開発作業が必要です。
オプション D(Dataproc で Apache Spark を使用)は、より複雑な設定が必要で、アナリストにとって使い勝手が悪い場合があります。また、グラフィカルで開発者に適していない側面も強調されていません。
</div></details>

### Q. 質問28: 未回答
オンプレミスの Hadoop セットアップを Cloud Dataproc に移行することを目指しており、Hive が主要なツールであり、Optimized Row Columnar(ORC)がデータ形式です。これで、すべての ORC ファイルが Cloud Storage コンテナに効果的に転送されました。パフォーマンスを向上させるには、特定のデータをクラスターのローカルの Hadoop Distributed File System (HDFS) に複製する必要があります。
Cloud Dataproc 内で Hive の使用を開始するには、どのような方法がありますか?(2つ選択)
1. gsutil ユーティリティを実行して、すべての ORC ファイルを Cloud Storage バケットから HDFS に転送します。Hive テーブルをローカルにマウントします。
2. 
3. 
4. Cloud Storage Connector for Hadoop を活用して、ORC ファイルを外部 Hive テーブルとしてマウントします。外部 Hive テーブルをネイティブ テーブルにレプリケートします。
<details><div>
    答え：1,4
説明
オプション A: 
このオプションでは、gsutil を使用して Cloud Storage から Dataproc クラスタ上の Hadoop Distributed File System(HDFS)に ORC ファイルをコピーします。その後、HDFSのデータの上にHiveテーブルを作成し、ローカルにマウントできます。
オプション D: 
このオプションでは、Cloud Storage Connector for Hadoop を使用して Cloud Storage 内の ORC ファイルに直接アクセスし、それらに基づいて外部 Hive テーブルを作成します。これらの外部 Hive テーブルからネイティブ Hive テーブルにデータをレプリケートできます。
パフォーマンスを最適化するためにデータをHDFSに複製する場合は、オプションAが適切な選択です。データをHDFSに複製せずに外部表を操作する場合は、オプションDが適切です。
</div></details>

### Q. 質問29: 未回答
特定の順序に従う必要があり、シェル スクリプトの実行、Hadoop ジョブの実行、BigQuery でのクエリの実行を含む、相互に依存する複数のステップを持つバッチ ジョブを管理するプロセスでは、数分から数時間の範囲で、障害が発生した場合に一定の再試行が必要になると予想されますが、ジョブの実行を監視するためにどのサービスを採用する必要がありますか?
1. 
2. 
3. 
4. Cloud Composer
<details><div>
    答え：4
説明
相互に依存するステップ、再試行、特定の注文要件を持つ複雑なバッチ ジョブの実行を管理するには、Cloud Composer(オプション D)を使用する必要があります。
Cloud Composer は、Apache Airflow 上に構築されたフルマネージドのワークフロー オーケストレーション サービスです。これにより、ワークフローを有向非巡回グラフ (DAG) として定義、スケジュール、および監視できます。タスク間の依存関係を持つ複雑なワークフローを作成したり、再試行ポリシーを指定したり、タスクの実行順序を設定したりできます。さらに、シェル スクリプトの実行、Hadoop ジョブ、BigQuery クエリなど、さまざまな GCP サービスをワークフローに統合できます。
正しくないオプション -
Cloud Scheduler(オプション A)は、主にスケジュールに従って HTTP/S エンドポイントまたは Pub/Sub トピックをトリガーするように設計されています。タスク間の依存関係を持つ複雑なワークフローの管理には適していません。
Cloud Dataflow(オプション B)は、汎用のバッチ ジョブ オーケストレーションよりも、データ処理やストリーム処理のジョブに適しています。
Cloud Functions(オプション C)は、サーバーレスのイベントドリブン関数向けに設計されているため、依存関係のある実行時間の長い複雑なバッチ ジョブの管理には適していない可能性があります。
</div></details>

### Q. 質問30: 未回答
あなたは、荷物が仕分けのために配送ラインを通過する配送センターを運営する運送会社に雇用されています。同社は、配送ラインにカメラを導入することで、荷物の取り扱いプロセスを強化することを目指しています。これらのカメラは、輸送中のパッケージの視覚的な損傷を特定して監視することを目的としています。あなたの仕事は、損傷したパッケージをリアルタイムで検出し、その後、輸送中の人間によるレビューのためにそのようなパッケージにタグを付けるための自動化システムを考案することです。このシナリオに最も適したソリューションはどれですか?
1. 
2. AutoML モデルをトレーニングする
3. 
4. 
<details><div>
    答え：2
説明
オプション B ():
カスタマイズ：AutoML (Auto Machine Learning) を使用すると、特定のデータセット (この場合は破損したパッケージの画像) に基づいてカスタム機械学習モデルをトレーニングできます。
統合：AutoML モデルを中心に API を構築できるため、パッケージ追跡アプリケーションと簡単に統合でき、リアルタイム分析が可能になります。
精度：カスタム モデルは、多くの場合、汎用モデルと比較して、特定のタスクに対してより高い精度を提供します。
正しくないオプション -
オプション C (Cloud Vision API を使用):
使いやすさ:Cloud Vision API は、一般的なユースケース向けに事前トレーニング済みのモデルを提供するマネージド サービスです。物体や一部の損傷を検出できますが、パッケージの特定の種類の損傷を特定するなど、高度に専門的なタスクでは精度が低くなる可能性があります。
カスタマイズ：これは、パッケージに固有の微妙な損傷タイプを検出するためのカスタムトレーニング済みモデルほど柔軟ではない可能性があります。
オプション D(TensorFlow と Datalab を使用):
複雑さ：カスタム TensorFlow モデルを構築して維持するには、データの前処理、モデルのトレーニング、デプロイなど、多大な開発作業が必要です。これは複雑で時間がかかる場合があります。
リアルタイム検出:リアルタイムの検出と荷物追跡アプリケーションとの統合には、追加のインフラストラクチャと開発作業が必要になります。
オプション A(BigQuery 機械学習を使用する):
バッチ処理:BigQuery の機械学習は、リアルタイムの画像分析ではなく、バッチ処理とデータ分析用に設計されています。輸送中の荷物の損傷を検出するのには適していません。
</div></details>

### Q. 質問31: 未回答
データ ウェアハウスを BigQuery に移行し、データをデータセット テーブルに統合すると、組織内のさまざまなユーザーのアクセスを制御する必要が生じます。具体的には、ユーザーがチーム メンバーシップに基づいて特定のテーブルのみを表示してアクセスできるようにします。BigQuery でこのテーブルレベルのアクセス制御を実現するためにユーザー権限を構成するには、どのような方法が推奨されますか?
1. 各テーブルのテーブル レベルでユーザー/グループのデータ閲覧者アクセス権を割り当てます
2. 
3. 
4. 
<details><div>
    答え：1
説明
正しいオプション: オプション A - 。
BigQuery では、データセット レベルとテーブル レベルの両方でアクセス制御を割り当てることができます。
テーブル レベルでのデータ閲覧者アクセス権の割り当ては、データセット内の特定のテーブルへのアクセス権をユーザーまたはグループに付与し、他のユーザーへのアクセスを制限する場合に適しています。
このオプションを使用すると、アクセス許可を微調整して、ユーザーが必要なテーブルにのみアクセスできるようにし、同じデータセット内の他のユーザーへのアクセスを拒否できるようにすることができます。
各テーブルにはアクセス制御リスト (ACL) を定義できるため、ユーザーまたはチームの要件に基づいてきめ細かく制御できます。
正しくないオプション -
オプション B (同じデータセット内の各チームの SQL ビューを作成する):
SQL ビューは、データ アクセス用の抽象化レイヤーを提供できますが、基になるテーブルへのアクセスを本質的に制限するものではありません。
ビューを含むデータセットへのアクセス権を持つユーザーは、追加のアクセス制御が適用されない限り、ベース テーブルを直接クエリできる可能性があります。
オプション C (同じデータセット内の各チームの承認済みビューを作成する):
許可されたビューは、通常、異なるテーブルへのアクセスを制御するためではなく、テーブル内の列のサブセットへのアクセスを提供する場合に使用されます。
これらは、チーム メンバーシップに基づいてテーブル レベルでアクセスを制御するようには設計されていません。
オプション D (チームごとに個別のデータセットで承認されたビューを作成する):
このオプションは非常に複雑であり、1 つのデータセット内のチーム メンバーシップに基づいてテーブルへのアクセスを制御するためには必要ありません。
複数のデータセットを作成して管理する必要があり、管理オーバーヘッドにつながる可能性があります。
</div></details>

### Q. 質問32: 未回答
マネージドHadoopシステムをデータレイクとして構築したい。データ変換プロセスは、順番に実行される一連のHadoopジョブで構成されます。ストレージとコンピューティングを分離する設計を実現するために、Cloud Storage コネクタを使用して、すべての入力データ、出力データ、中間データを保存することにしました。ただし、オンプレミスのベアメタル Hadoop 環境(100 GB の RAM を搭載した 8 コア ノード)と比較すると、Cloud Dataproc では 1 つの Hadoop ジョブの実行が非常に遅いことに気付きました。分析によると、この特定のHadoopジョブはディスクI/Oを大量に消費します。問題を解決したい。あなたは何をするべきか?
1. 
2. Hadoopクラスターに十分な永続ディスク領域を割り当て、その特定のHadoopジョブの中間データをネイティブHDFSに格納します。
3. 
4. 
<details><div>
    答え：2
説明
正しいオプションは次のとおりです。
B. 
このオプションが正しい理由は次のとおりです。
問題のHadoopジョブは、ディスクI/Oのために低速であり、ストレージとの間でのデータの読み取りと書き込みによってボトルネックになっています。
Hadoopクラスタに十分な永続ディスク容量を割り当て、中間データをネイティブHDFS(Hadoop Distributed File System)に保存することで、パフォーマンスを大幅に向上させることができます。
HDFSは分散データストレージ向けに最適化されており、オブジェクトストレージサービスであるCloud Storageと比較して、データの読み取りおよび書き込み操作が大幅に高速化されます。中間データを HDFS に保存すると、Cloud Storage のデータへのアクセスに関連するネットワーク レイテンシとオーバーヘッドが削減されます。
このアプローチでは、中間データ ストレージに HDFS の利点を活用しながら、長期ストレージに Cloud Storage を使用し、ストレージをコンピューティングから切り離します。
誤ったオプション-
A. より多くのメモリを割り当てると、ジョブのパフォーマンスの特定の側面に役立つ場合がありますが、ディスク I/O のボトルネックに直接対処できない場合があります。
C. CPU コアまたはインスタンスの割り当てを増やしても、問題は CPU バウンドの処理ではなくデータ アクセス速度に関連しているため、ディスク I/O の問題が解決する可能性は低いです。
D. ネットワークインターフェイスの追加やリンクアグリゲーションの設定は、ネットワーク帯域幅に関するものであり、Hadoopジョブが直面しているディスクI/Oの問題に直接対処するものではありません。
</div></details>

### Q. 質問33: 未回答
広告会社に勤務し、広告ブロックのクリックスルー率を予測するためのSpark MLモデルを作成しました。以前はオンプレミスのデータセンターで作業していましたが、データセンターの閉鎖が間近に迫っているため、会社は Google Cloud に移行しています。データを BigQuery に移行し、Spark ML モデルを定期的に再トレーニングするため、既存のトレーニング パイプラインを Google Cloud に迅速に移行する必要があります。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 既存の Spark ML モデルのトレーニングには Dataproc を使用しますが、BigQuery から直接データの読み取りを開始します。
4. 
<details><div>
    答え：3
説明
オプション C: 
このオプションは、Google Cloud への移行中に既存の Spark ML モデルを移行する場合に適しています。これが正しいオプションである理由は次のとおりです。
Dataproc の互換性:Google Cloud Dataproc は、Spark やその他のビッグデータ フレームワークをシームレスに実行できるように設計されています。これにより、大規模な書き換えを行うことなく、既存の Spark ML モデルを引き続き使用できます。
BigQuery との統合:Dataproc は BigQuery からデータを直接読み取ることができるため、BigQuery に保存されているデータで Spark ML モデルを効率的にトレーニングできます。この統合により、データの移動が最小限に抑えられ、複雑さと遅延が軽減されます。
正しくないオプション -
A. トレーニングに Vertex AI を使用する: Vertex AI は Google Cloud の強力な機械学習プラットフォームですが、主に TensorFlow モデルと scikit-learn モデルをサポートしています。既存の Spark ML モデルを Vertex AI に移行するには、大幅な変更が必要になる場合があり、迅速なリフト&シフト移行に対応できない場合があります。
B. TensorFlow でモデルを書き換え、Vertex AI を使用する: このオプションでは、既存の Spark ML モデルを TensorFlow で書き換える必要がありますが、これには時間がかかり、迅速な移行には適さない場合があります。
D. Compute Engine で Spark クラスタを起動する: Compute Engine で Spark を実行することもできますが、このオプションではインフラストラクチャを自分で設定して管理する必要があります。移行プロセスが複雑になる可能性があり、この特定のシナリオでは Dataproc と BigQuery の統合を使用する明確なメリットはありません。
</div></details>

### Q. 質問34: 未回答
あなたは、配送ラベルを読み取るためにハンドヘルドスキャナーを採用している配送会社に雇用されています。同社は厳格なデータプライバシー規制を遵守しており、イベントが生成されたときにのみスキャナーが追跡番号をKafkaトピックに送信することを義務付けています。最近のソフトウェアアップデートにより、これらのスキャナーは受信者の個人を特定できる情報(PII)を誤って分析システムに送信し始め、ユーザーのプライバシー規制を侵害しました。クラウドネイティブなマネージドサービスを使用してスケーラブルなソリューションを迅速に確立し、分析システムへのPIIの露出を防ぐには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. トピックを読み取り、Cloud Data Loss Prevention(Cloud DLP)API を呼び出す Cloud Functions の関数を作成します。タグ付けレベルと信頼度レベルを使用して、レビューのためにバケット内のデータを渡すか隔離します。
<details><div>
    答え：4
説明
クラウドネイティブなマネージドサービスを使用してスケーラブルなソリューションを迅速に構築し、分析システムへのPIIの公開を防ぐには、次のことを行う必要があります。
D. 
このオプションが適切な理由は次のとおりです。
Cloud Functions: Cloud Functionsはサーバーレスでイベント駆動型であるため、Kafkaトピックに到着したデータを効率的に処理できます。
Cloud Data Loss Prevention(Cloud DLP)API: Cloud DLP は、PII などの機密データを特定して保護するように設計されています。Cloud DLP API を呼び出すことで、受信データの PII をスキャンできます。
タグ付けと信頼度: Cloud DLP は、検出された機密情報のタグ付けと信頼度を提供します。これらのタグと信頼度を使用して、データを渡すか、レビューのために検疫するかを決定できます。
このソリューションにより、機密情報が分析システムに到達する前に適切に識別および処理され、データプライバシー基準への準拠を維持できます。
オプション D は、Cloud Functions と Cloud DLP API を利用して、到着したデータをスキャンして処理することで、データ プライバシー基準へのコンプライアンスを確保しながら、PII が分析システムに公開されるのを防ぐためのスケーラブルで効果的なアプローチを提供します。
正しくないオプション -
オプション A(BigQuery で承認済みビューを作成する): このオプションでは、BigQuery のデータへのアクセスを制御することに重点を置いていますが、そもそも機密データが分析システムに到達するのを防ぐことはできません。
オプション B(サードパーティのデータ検証ツールを Compute Engine 仮想マシンにインストールする): データ検証ツールは便利ですが、複雑さが増し、クラウドネイティブ ソリューションほどスケーラブルで費用対効果が高くない可能性があります。
オプション C(Cloud Logging を使用してデータを分析): Cloud Logging はログの分析に役立ちますが、データが流出したときに積極的に防止するよりも、後処理やモニタリングに適しています。
</div></details>

### Q. 質問35: 未回答
これで、3 つのデータ処理タスクが作成されました。1 つ目は、Cloud Storage に保存されているデータを変換し、その結果を BigQuery に読み込むための Cloud Dataflow パイプラインを実行します。2 つ目のタスクでは、オンプレミス サーバーからデータを取り込み、Cloud Storage にアップロードします。3 つ目のタスクは、サードパーティ プロバイダからデータを取得して Cloud Storage にアップロードする Cloud Dataflow パイプラインで構成されています。要件は、これら 3 つのワークフローのスケジューリングおよび監視システムを確立し、必要に応じて手動で実行できるようにすることです。これを達成するには、どのような手順を踏む必要がありますか?
1. Cloud Composer で直接非巡回グラフを作成し、ジョブをスケジュールしてモニタリングします。
2. 
3. 
4. 
<details><div>
    答え：1
説明
これら 3 つのデータ処理ジョブの実行をスケジュールして監視し、必要に応じて手動で実行するには、次の操作を行う必要があります。
A. 
このオプションが適切な理由は次のとおりです。
Cloud Composer: Cloud Composer は、Apache Airflow 上に構築されたフルマネージドのワークフロー オーケストレーション サービスです。これにより、複雑なワークフローを簡単に定義、スケジュール、および監視できます。
スケジュールされた実行: Cloud Composer で DAG(Direct Acyclic Graphs)を作成して、指定した間隔または時間にデータ処理ジョブの実行をスケジュールできます。
モニタリング: Cloud Composer にはモニタリング機能とロギング機能が組み込まれており、ジョブの進行状況の追跡、ログの表示、問題のトラブルシューティングを行うことができます。
手動実行: 必要に応じて Cloud Composer で DAG を手動でトリガーできるため、オンデマンドでジョブを柔軟に実行できます。
正しくないオプション -
オプション B(Stackdriver Monitoring を使用し、Webhook でアラートを設定する): Stackdriver Monitoring はモニタリング機能を提供できますが、Cloud Composer のようなワークフローのスケジュール設定機能やオーケストレーション機能は提供しません。
オプション C(App Engine アプリケーションの開発): ジョブのスケジュール設定とモニタリング用にカスタム App Engine アプリケーションを構築するには、追加の開発作業とメンテナンスが必要になります。Cloud Composer は、よりわかりやすいソリューションです。
オプション D(Compute Engine インスタンスで cron ジョブを設定する): Compute Engine での cron ジョブの使用は拡張性が低く、ジョブの実行とモニタリングに手動のスクリプトが必要になる場合がありますが、Cloud Composer はマネージドで統合されたソリューションを提供します。
Cloud Composer は、クラウドネイティブ環境でのデータ処理ジョブのスケジューリング、モニタリング、オーケストレーションに特化して構築されており、お客様の要件に最適なオプションです。
参考リンク -
https://cloud.google.com/composer/docs/how-to/using/writing-dags
</div></details>

### Q. 質問36: 未回答
Node.js で記述された Cloud Functions があり、Cloud Pub/Sub からメッセージを取得して BigQuery にデータを送信します。Pub/Sub トピックのメッセージ処理速度が予想よりも桁違いに高いことがわかりますが、Cloud Logging にはエラーは記録されません。この問題の最も可能性の高い 2 つの原因は何ですか?(2つ選択してください。
1. 
2. 
3. サブスクライバー コードでのエラー処理がランタイム エラーを適切に処理していません。
4. 
<details><div>
    答え：3
説明
C. 
このオプションは、サブスクライバー コードで適切に処理されないランタイム エラーが検出されると、メッセージ処理フローが中断される可能性があるため、正しい方法です。未処理のエラーにより、サブスクライバーがメッセージの処理を停止し、バックログが発生する可能性があります。また、エラーの詳細が正しく記録されていない場合、Cloud Logging にエラー メッセージが表示されず、トラブルシューティングが困難になる可能性があります。
E.サブスクライバー・コードは、プルするメッセージを確認しません。
Cloud Pub/Sub はメッセージが正常に処理されたかどうかをメッセージ確認に基づいて判断するため、このオプションは正しいです。処理後にサブスクライバー コードがメッセージを確認しない場合、Pub/Sub はメッセージが未処理であると見なして再配信するため、メッセージの処理速度が効果的に向上します。メッセージのフローを維持するためには、メッセージを適切に確認することが重要です。
正しくないオプション -
A. パブリッシャーのスループット クォータが小さすぎます。
このオプションは、パブリッシャーのスループット クォータがメッセージが Pub/Sub トピックにパブリッシュされるレートに関連しているため、問題の原因となる可能性は低くなります。サブスクライバーがメッセージを消費および処理できる速度には直接影響しません。パブリッシャーのスループット クォータを超えた場合、メッセージの発行に影響を与える可能性がありますが、サブスクライバー側のメッセージ処理速度が急激に増加することはありません。
B. 未処理のメッセージの合計が最大 10 MB を超えています。
また、このオプションは、観察された問題の原因である可能性も低くなります。10 MB の最大制限は、通常、個々のメッセージのサイズを指します。この制限を超えると、メッセージ サイズの問題が発生する可能性がありますが、メッセージ処理速度の大幅な増加には直接つながりません。これにより、メッセージのサイズに関連する問題が発生する可能性がありますが、メッセージの処理速度には関連しません。
D. サブスクライバ コードがメッセージに追いつかない。
Pub/Sub トピックのメッセージ処理レートが、Cloud Functions の関数サブスクライバー コードでメッセージを処理できるレートよりもはるかに高い場合、未処理のメッセージのバックログが発生します。
正しいオプションは C と E で、サブスクライバー コードの問題と、メッセージを適切に処理および確認する機能に直接関連しているため、観察された問題につながる可能性があります。
</div></details>

### Q. 質問37: 未回答
Google Cloud で新しいパイプラインを作成し、Cloud Pub/Sub から Cloud Dataflow を介して BigQuery に IoT データをストリーミングします。データをプレビューしていると、データの約 2% が破損しているように見えます。Cloud Dataflow パイプラインを変更して、この破損したデータを除外する必要があります。あなたは何をするべきか?
1. 
2. Cloud Dataflow に ParDo 変換を追加して、破損した要素を破棄します。
3. 
4. 
<details><div>
    答え：2
説明
回答: B. 
Cloud Dataflow に ParDo 変換を追加することは、破損したデータを除外するための最良の方法です。SideInput は、要素が破損している場合に Boolean を返しますが、実際には要素を破棄しません。パーティション変換では、有効なデータと破損したデータを分離できますが、破損したデータは破棄されません。GroupByKey 変換では、すべての有効なデータをグループ化できますが、破損したデータは破棄されません。
</div></details>

### Q. 質問38: 未回答
過去 3 年間の履歴データが BigQuery に保存され、毎日データ パイプラインが新しいデータにフィードされるため、データ サイエンス チームによるクエリで 30 日から 90 日分のデータの日付列をフィルタリングすると、テーブル全体がスキャンされ、費用が増加することがわかりました。目的は、SQL クエリ機能を維持しながら、この問題に効率的に対処することです。
最も費用対効果の高いソリューションは何ですか?
1. DDL を使用してテーブルを再作成します。TIMESTAMP型またはDATE型を含む列でテーブルをパーティション分割します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
BigQuery の履歴データに対して SQL クエリを実行する機能を維持しながら、クエリのパフォーマンスを最適化して費用を削減するには、パーティション分割の使用を検討する必要があります。オプション A は、TIMESTAMP または DATE 型を含む列でテーブルをパーティション分割することを推奨しており、最も適切なアプローチです。
A. 
このオプションは正しいです。BigQuery でのテーブルのパーティション分割は、クエリのパフォーマンスを最適化し、費用を削減する効果的な方法です。TIMESTAMP または DATE 列に基づいてテーブルをパーティション分割することで、データをより小さく、より管理しやすいパーティションに整理できるため、date 列をフィルター処理するクエリで、テーブル全体をスキャンするのではなく、関連するパーティションのみをスキャンできます。これにより、クエリのコストが大幅に削減され、クエリのパフォーマンスが向上します。
正しくないオプション -
テーブルを Cloud Storage の CSV ファイルにエクスポートするオプション B は、BigQuery で直接 SQL クエリを実行する機能を維持したい場合、実用的なソリューションではありません。
オプション C では、データを 2 つのテーブル (最近と履歴) に分割することを提案しており、最近のデータのクエリ コストを削減するのに役立ちますが、大規模なデータセットのパーティション分割ほど効率的ではない可能性があります。これにより、データの管理とクエリが複雑になる可能性があります。
オプション D では、1 日ごとに個別の BigQuery テーブルを作成することを提案していますが、時間の経過とともにテーブルの数が多くなり、データの効率的な管理とクエリが困難になる可能性があります。パーティション分割は、よりスケーラブルでコスト効率の高いアプローチです。
</div></details>

### Q. 質問39: 未回答
あなたは、車両ベースのセンサーからのイベント配信の信頼性を高めることを目的とした物流会社を経営しています。イベントキャプチャ用のグローバルデータセンターを維持します。ただし、イベント収集インフラストラクチャーをイベント処理インフラストラクチャーに接続する専用回線は、待ち時間が不確実であるため、一貫性がありません。
コストを最小限に抑えながら、これに対処するにはどうすればよいでしょうか。
1. 
2. データ取得デバイスで Cloud Pub/Sub にデータをパブリッシュします。
3. 
4. 
<details><div>
    答え：2
説明
正解は B.
Cloud Pub/Sub は、アプリケーションとサービス間でデータを送受信できるフルマネージドのリアルタイム メッセージング サービスです。これにより、リモート・データ・センターからイベント処理インフラストラクチャーに、確実かつコスト効率よくデータを配信できます。これは、遅延が予測できない信頼性の低い専用回線の問題に対処するための最も費用対効果の高い方法です。
正しくないオプション -
A: 小規模な Kafka クラスターをデータセンターにデプロイしてイベントをバッファリングしても、レイテンシーが予測できない信頼性の低い専用回線の問題には対処できません。
C: すべてのリモート データセンターと Google の間にクラウド インターコネクトを確立しても、遅延が予測できない信頼性の低い専用回線の問題には対処できません。
D: セッション ウィンドウ内のすべてのデータを集約する Cloud Dataflow パイプラインを作成しても、レイテンシが予測できない信頼性の低い専用回線の問題には対処できません。
</div></details>

### Q. 質問40: 未回答
Google Homeなどのさまざまな在宅アシスタントとのオンライン販売の統合を強化することを目指している小売業者として、顧客の音声コマンドを解釈し、バックエンドシステム内で注文を開始するには、どのようなソリューションを選択する必要がありますか?
1. 
2. 
3. Dialogflow Enterprise エディション
4. 
<details><div>
    答え：3
説明
Google Home などの在宅アシスタントとの統合のコンテキストで顧客の音声コマンドを解釈し、バックエンド システムに注文を発行するには、次のものを選択する必要があります。
C. 
Dialogflow は、チャットボットや音声起動アプリケーションなどの会話型インターフェースの作成に特化して設計されています。これにより、自然言語でユーザー入力を理解して応答できるため、顧客からの音声コマンドを解釈するのに適しています。
その他のオプション(A、B、D)は Google Cloud エコシステムの重要なコンポーネントですが、それぞれ目的が異なります。
Speech-to-Text API (オプション A): この API は、音声言語を書き言葉に変換するために使用されます。音声コマンド処理のコンポーネントにはなりますが、Dialogflow が提供する自然言語理解や会話管理機能は提供されません。
Cloud Natural Language API(オプション B): この API は、感情分析やエンティティ認識など、テキストから分析情報を分析および抽出するために使用されます。これは主に、リアルタイムの会話で音声コマンドを解釈するために設計されたものではありません。
AutoML Natural Language (オプション D): AutoML Natural Language を使用すると、自然言語理解タスク用のカスタム機械学習モデルを構築できます。強力ではありますが、音声コマンドの解釈に Dialogflow などの専用ツールを使用する場合と比較して、より多くの開発作業が必要になる場合があります。
音声コマンド処理と会話管理には、提供されているオプションの中から Dialogflow Enterprise Edition が最も適しています。
</div></details>

### Q. 質問41: 未回答
異なるクラウドプロバイダーサービス間のデータ移動と、これらの各プロバイダーからのサービスの利用を含む複雑なデータパイプラインを持つ企業のハイブリッドクラウドイニシアチブのコンテキストでは、パイプライン全体をオーケストレーションするのに最も適した特定のクラウドネイティブサービスはどれですか?
1. 
2. Cloud Composer
3. 
4. 
<details><div>
    答え：2
説明
正解は B. Cloud Composer です。
Cloud Composer は、複数のクラウド プロバイダにまたがる複雑なデータ パイプラインのオーケストレーションに使用されるクラウドネイティブ サービスであるため、正しい選択です。Cloud Dataflow はデータ パイプラインと ETL ジョブを作成するためのマネージド サービス、Cloud Dataprep はデータ ラングリング サービス、Cloud Dataproc はマネージド Spark および Hadoop サービス、Cloud Functions はサーバーレス コンピューティング サービスです。これらのサービスはいずれも、複数のクラウドプロバイダーにまたがる複雑なデータパイプラインをオーケストレーションするために設計されたものではありません。
参考リンク -
https://cloud.google.com/composer#
</div></details>

### Q. 質問42: 未回答
サードパーティ企業に分析のために BigQuery のデータセットへのアクセス権を付与する際に、データの鮮度を維持し、データ共有費用を最小限に抑えるには、どのソリューションを選択すればよいでしょうか?
1. Analytics Hub を使用してデータ アクセスを制御し、サードパーティ企業にデータセットへのアクセスを提供します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
Analytics Hubを使用してデータアクセスを制御することは、コストを低く抑え、データを最新の状態に保ちながら、サードパーティ企業にデータセットへのアクセスを提供できるため、最適なソリューションです。
正しくないオプション -
Cloud Scheduler はジョブとタスクのスケジュール設定に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション B は正しくありません。
BigQuery で別のデータセットを作成することは、最も費用対効果の高いソリューションではなく、データが最新であることを保証できないため、オプション C は正しくありません。
Dataflow はデータの処理と変換に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション D は正しくありません。
</div></details>

### Q. 質問43: 未回答
現在、オンプレミスのデータ ウェアハウス ソリューションを BigQuery に移行している会社では、さまざまなトランザクション データベース ソースからの更新を毎日適用するために、変更データ キャプチャ(CDC)プロセスを強化したいと考えています。この改善は、データ ウェアハウス変更アプリケーションのパフォーマンスの最適化に重点を置き、ログベースの CDC ストリームを介して BigQuery でソース システムからの変更にすばやくアクセスできるようにすることを目的としています。BigQuery レポートの表で変更を利用できるようにするためのレイテンシを最小限に抑えながら、コンピューティングのオーバーヘッドを削減するには、どの 2 つのアクションを実行すべきでしょうか。(2つ選択)
1. 
2. 新しい各 CDC レコードと対応する操作の種類をステージング テーブルにリアルタイムで挿入します。
3. 
4. DML MERGE を定期的に使用して、レポート テーブルで複数の DML INSERT、UPDATE、および DELETE 操作を同時に実行します。
5. 
<details><div>
    答え：2,4
説明
B. 
この手順は、ソース システムから変更をリアルタイムでキャプチャし、ステージング テーブルに格納するために不可欠です。ステージング テーブルは、受信 CDC データのバッファーを提供し、データをレポート表に移動する前に、必要なビジネス ロジックを検証、変換、および適用できます。このアプローチは、レポート データセットの一部になる前に、データの一貫性と正確性を確保するのに役立ちます。
D. 
定期的な MERGE 操作の使用は、累積された変更をステージング テーブルからレポート テーブルに適用するための効果的な戦略です。これにより、複数の CDC レコードを 1 つの DML 操作に統合し、個々の INSERT、UPDATE、または DELETE に関連するオーバーヘッドを削減できます。このアプローチにより、計算コストが最適化され、レポート テーブルを効率的に維持できます。
正しくないオプション -
A. DML INSERT、UPDATE、または DELETE を実行して、個々の CDC レコードをレポート テーブルに直接リアルタイムで直接レプリケートします。
このオプションを使用すると、すべての CDC レコードのレポート テーブルで個々の DML 操作が大量に発生する可能性があり、リソースを大量に消費し、最適なクエリ パフォーマンスが得られない可能性があります。
C. レポート テーブルから古いレコードを定期的に削除します。
古いレコードの削除はデータ管理に必要ですが、CDC データのほぼリアルタイムの処理要件には対応していません。このオプションは、タイムリーな更新ではなく、データ保持に重点を置いています。
E. 新しい各 CDC レコードと対応する操作の種類をレポート テーブルにリアルタイムで挿入し、具体化されたビューを使用して、一意の各レコードの最新バージョンのみを公開します。
具体化されたビューはクエリのパフォーマンスを最適化するのに役立ちますが、このアプローチでは CDC データ自体のリアルタイム処理には対応していません。具体化されたビューは、通常、集計または概要を事前に計算するために使用され、リアルタイムのデータキャプチャや変換用には設計されていません。
待機時間を最小限に抑え、コンピューティング オーバーヘッドを削減してほぼリアルタイムの CDC を実現するには、手順 B と D を組み合わせることをお勧めします。ステージング テーブル (B) で変更をリアルタイムでキャプチャし、これらの変更をレポート テーブル (D) に定期的にマージして、データセットを効率的に更新します。
</div></details>

### Q. 質問44: 未回答
負荷の増加に応じて自動的にスケーリングできるデータ処理パイプラインを設計し、メッセージが少なくとも 1 回処理されるようにし、1 時間以内に順序を維持する必要があります。このソリューションをどのように設計する必要がありますか?
1. 
2. 
3. 
4. メッセージの取り込みには Cloud Pub/Sub を使用し、ストリーミング分析には Cloud Dataflow を使用します。
<details><div>
    答え：4
説明
D. 
このオプションは、Cloud Pub/Sub と Cloud Dataflow の両方の長所を活用しているため、要件に適した選択肢となります。
Cloud Pub/Sub は、高スループットのメッセージ取り込みを処理できるマネージド メッセージング サービスです。これにより、メッセージの少なくとも 1 回分の配信が保証され、メッセージの順序を維持できるため、1 時間以内にメッセージを順序付けするという要件に合わせることができます。
Cloud Dataflow は、負荷に応じて自動的にスケーリングできるマネージド ストリームおよびバッチ データ処理サービスです。これにより、ウィンドウ処理やトリガーなどの処理パイプラインを定義して、リアルタイムまたは最小限のレイテンシーでデータを処理できます。この選択により、1 時間以内に目的のメッセージ処理を実現できます。
正しくないオプション -
A. メッセージの取り込みには Apache Kafka を使用し、ストリーミング分析には Cloud Dataproc を使用します。Apache Kafka はメッセージの取り込みに適しており、メッセージの順序を維持できますが、ストリーミング分析に Cloud Dataproc(マネージド Spark および Hadoop サービス)を使用すると、Cloud Dataflow と比較してリアルタイム処理の効率が低くなります。Cloud Dataproc は通常、バッチ処理やアドホック データ分析に使用されます。
B. メッセージの取り込みには Apache Kafka を使用し、ストリーミング分析には Cloud Dataflow を使用します。このオプションも有効な選択であり、うまく機能します。取り込みには Kafka を、ストリーミング分析には Cloud Dataflow を組み合わせています。私の以前の応答は、このオプションを誤って却下しました。見落としをお詫びします。
C. メッセージの取り込みに Cloud Pub/Sub を使用し、ストリーミング分析に Cloud Dataproc を使用します。前述したように、ストリーミング分析に Cloud Dataproc を使用することは、最も効率的な選択ではない可能性があります。Cloud Dataflow は、Google Cloud のエコシステムでのリアルタイム ストリーミング分析に適しています。
</div></details>

### Q. 質問45: 未回答
指定された条件を満たすには、BigQuery データへのアクセスを提供する必要があります。
- 各部門は、自分のデータにのみアクセスできるようにする必要があります。
- 各部門には、テーブルを作成および更新してチームに提供できる必要がある 1 人以上のリードがいます。
- 各部門にはデータアナリストがおり、データのクエリはできるが、変更はできない。
BigQuery のデータへのアクセスをどのように設定すればよいですか?
1. 
2. 部門ごとにデータセットを作成します。部門リーダーに WRITER の役割を割り当て、データ アナリストにデータセットの READER の役割を割り当てます。
3. 
4. 
<details><div>
    答え：2
説明
正解は、
B. 
部門ごとにデータセットを作成することは、データを論理的に分離し、各部門がデータ用に分離されたスペースを確保するための優れた方法です。
部門リーダーを WRITER ロールに割り当てると、データセット内のテーブルを作成および変更するアクセス許可が付与されます。これは、リードがテーブルを作成および更新できる必要があるという要件と一致しています。
データセットに対してデータアナリストにREADERのロールを割り当てると、データアナリストはデータのクエリはできますが、変更はできないため、データアナリストはデータのクエリはできますが、変更はできないという要件と一致します。
正しくないオプション -
オプションA(正しくない):
このオプションでは、部門リーダーに OWNER のロールが付与され、データセットを削除する権限など、必要以上の権限が付与されます。これは、部門リーダーがテーブルを作成および更新するための要件を超えています。
データアナリストに WRITER の役割を割り当てると、データアナリストはテーブルを作成できますが、その役割がデータを変更せずにクエリを実行する場合は、必要以上のアクセス権限が必要になります。
オプションC(正しくない):
部門ごとにテーブルを作成することは、BigQuery でアクセス制御とデータの分離を管理するのに理想的な方法ではありません。
部門をプロジェクトレベルで所有者の役割に割り当てると、プロジェクト全体にわたる幅広い権限が付与され、必要以上のアクセス権が含まれる場合があります。
オプションD(正しくない):
オプション C と同様に、部門ごとに個別のテーブルを作成することは、アクセス制御とデータ編成のために推奨される方法ではありません。
部門リーダーをプロジェクトレベルで編集者の役割に割り当てると、データセット、テーブル、その他のプロジェクトリソースを編集する機能が含まれるため、必要以上に幅広い権限が与えられます。
</div></details>

### Q. 質問46: 未回答
金融機関は、機密性の高い顧客データを安全に保管し、規制コンプライアンスを確保する必要があります。これには、暗号化、監査ログ、きめ細かなアクセス制御を備えたマネージド・データベース・サービスが必要です。どのGCPサービスを選ぶべきか?
1. Cloud SQL
2. 
3. 
4. 
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. 
Cloud SQL は、機密データを処理するように設計された Google Cloud のマネージド リレーショナル データベース サービスです。保存中および転送中の暗号化、自動バックアップ、きめ細かなアクセス制御などの機能を提供します。これは、規制コンプライアンスと機密性の高い顧客データの安全なストレージを必要とするアプリケーションに適しています。構造化されたリレーショナルデータベースの使用は、取引データやコンプライアンスの目的で金融機関で好まれることがよくあります。
正しくないオプション -
B. Bigtable は、主に高スループットでスケーラブルなワークロード向けに設計された NoSQL データベースであり、機密性の高い顧客データを安全に保存し、規制コンプライアンスを確保するには最適な選択肢ではない可能性があります。Cloud SQL と同じレベルの組み込みのセキュリティ機能やコンプライアンス機能は提供されません。
C. Firestore は、一般的に柔軟でスキーマレスのデータ ストレージに使用される NoSQL ドキュメント データベースですが、金融機関が必要とする特定のセキュリティおよびコンプライアンス機能を提供しない場合があります。Firestore は通常、より柔軟で俊敏なデータ ストレージのニーズに合わせて選択されます。
D. BigQuery は、大規模なデータセットの分析とクエリに使用される、サーバーレスで拡張性の高いデータ ウェアハウスです。データ分析には使用できますが、主にトランザクション データベースではなく、Cloud SQL と同じレベルのセキュリティとコンプライアンス機能を提供していません。
Cloud SQL は、必要なセキュリティとコンプライアンスの機能に加えて、機密性の高い顧客データを金融機関に安全に保管するために必要な構造を備えているため、最も適切な選択肢です。
</div></details>

### Q. 質問47: 未回答
あなたの会社は、投稿、コメント、いいねなどのユーザー生成コンテンツを保存するために、柔軟でスキーマレスなデータベースを必要とするソーシャルメディアプラットフォームを開発しています。このシナリオに適したGCPデータベースサービスはどれですか?
1. 
2. Firestore
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は B. Firestore です。
このシナリオの要件は、ソーシャル メディア プラットフォームの投稿、コメント、いいねなどのユーザー生成コンテンツを保存することです。時間の経過とともに変化する可能性のある、このユーザー生成コンテンツのさまざまな構造に対応するには、柔軟なスキーマレスデータベースが必要です。
Firestore は、柔軟でスキーマレスなデータ ストレージを提供する NoSQL ドキュメント データベースです。非構造化データや半構造化データを簡単に処理できるため、ユーザーが作成したコンテンツをソーシャルメディアプラットフォームに保存するための優れた選択肢となります。Firestore は、このようなアプリケーションに不可欠なリアルタイムの同期とスケーラビリティも提供します。
正しくないオプション -
A. BigQueryの場合:BigQuery は分析用のデータ ウェアハウスであり、ユーザーが生成したコンテンツを保存するための柔軟なスキーマレス データベースではありません。構造化データに対して複雑なSQLクエリを実行するように設計されているため、ソーシャルメディアの投稿やコメントなどの非構造化コンテンツや半構造化コンテンツにはあまり適していません。
C. クラウドデータストア:Cloud Datastore も Google Cloud が提供する NoSQL データベースですが、より最新の機能と優れたスケーラビリティにより、Firestore がほぼこれに取って代わりました。このシナリオでも Cloud Datastore は機能しますが、新しいプロジェクトでは一般的に Firestore をおすすめします。
D. Cloud SQL:Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。固定スキーマが適用されるため、ソーシャルメディアプラットフォームにおけるユーザー生成コンテンツの柔軟でスキーマレスな性質にはあまり適していません。Cloud SQL は、構造化データ ストレージとリレーショナル データベースのニーズに適しています。
</div></details>

### Q. 質問48: 未回答
オンラインゲーム会社は、スコア、実績、ゲームの進行状況などのプレーヤー統計をリアルタイムで保存して処理したいと考えています。頻繁な更新とクエリを処理できるデータベースが必要です。どのGCPサービスをお勧めしますか?
1. Bigtable
2. 
3. 
4. 
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. Bigtable
このシナリオでは、オンラインゲーム会社は、頻繁な更新とクエリを使用して、プレーヤーの統計をリアルタイムで保存および処理する必要があります。Bigtable は、Google Cloud Platform(GCP)上の NoSQL で拡張性が高く、低レイテンシのデータベース サービスであり、大量のデータを高い読み取りおよび書き込みスループットで処理するように設計されています。
リアルタイム データ処理: Bigtable は、リアルタイム データを低レイテンシで処理することに優れているため、ゲームプレイ中にリアルタイムで更新されるプレイヤーの統計情報を保存および処理するのに適しています。
スケーラビリティ: Bigtable は、多数のプレイヤーと広範な統計を扱うゲーム会社にとって不可欠な、大量のデータに対応するために簡単に拡張できます。
頻繁な更新とクエリ: Bigtable の設計は、高頻度の読み取りおよび書き込み操作に最適化されているため、プレイヤーの統計情報の記録と取得に適しています。
正しくないオプション -
B. クラウドデータストア:
Cloud Datastore も NoSQL データベースですが、一般的には、より構造化されたトランザクション データ ストレージを必要とするアプリケーションに適しています。頻繁な更新とクエリを伴うリアルタイムのゲーム統計については、Bigtable ほどパフォーマンスが高くない可能性があります。
C. BigQueryの場合:
BigQuery は、大規模なデータセットの分析とクエリ用に設計されたデータ ウェアハウス サービスです。これは、このシナリオの主要な要件であるリアルタイムのデータストレージと処理にはあまり適していません。
D. Cloud SQL:
Cloud SQL は、マネージド リレーショナル データベース サービスです。構造化データやトランザクションデータには適していますが、頻繁な更新やクエリを伴うリアルタイムのゲーム統計に必要なパフォーマンスとスケーラビリティを提供しない場合があります。
Bigtable は、リアルタイム処理機能、スケーラビリティ、頻繁な更新やクエリを処理する能力など、ゲーム会社のプレイヤー統計の要件に合致しているため、最も適切な選択肢です。
</div></details>

### Q. 質問49: 未回答
組織はニュース Web サイトを運営しており、ユーザーの行動データを分析してコンテンツのレコメンデーションをパーソナライズする必要があります。リアルタイムのデータストリーミングと複雑な分析を効率的に処理できるGCPデータベースサービスはどれですか?
1. 
2. 
3. 
4. BigQuery
<details><div>
    答え：4
説明
質問の正しいオプションは D. BigQuery です。
BigQuery は、フルマネージドのサーバーレス データ ウェアハウスであり、リアルタイムのデータ ストリーミングや複雑な分析の処理に適しています。BigQuery は、大規模なデータセットの複雑な分析に優れたデータ ウェアハウスおよび分析プラットフォームです。ストリーミング挿入などの機能を通じてリアルタイムのデータストリーミングを効率的に処理でき、強力な分析のためのSQLのようなクエリ言語を提供します。これは、ユーザーの行動データに対して複雑なクエリを実行してコンテンツのレコメンデーションをパーソナライズするのに適しており、このシナリオに最も適した選択肢です。
コンテンツのレコメンデーションをパーソナライズするためにユーザーの行動データを分析する必要がある場合や、リアルタイムのデータ ストリーミングと複雑な分析が必要な場合、BigQuery は要件に最適な GCP データベース サービスです。
正しくないオプション -
A. Cloud Pub/Sub の場合: Cloud Pub/Sub は、イベントドリブン システムの構築とデータのストリーミングのためのメッセージング サービスです。データのストリーミングには便利ですが、BigQuery のようなデータベース サービスではなく、複雑な分析は実行しません。これは通常、メッセージ キューイングとイベント ドリブン アーキテクチャに使用されます。
B. Bigtable の場合: Bigtable は、高スループット、低レイテンシ、スケーラビリティを実現するように設計された NoSQL データベースです。大量のデータへの高速な読み取りおよび書き込みアクセスを必要とするアプリケーションには適していますが、複雑な分析には最適化されていません。Bigtable は、時系列データやキー値ストレージなどのユースケースに適しています。
C. Firestore: Firestore は、モバイル アプリケーションやウェブ アプリケーション向けに設計された NoSQL データベースです。リアルタイム データを処理できますが、主にトランザクション データに使用され、複雑な分析には使用されません。これはドキュメントベースのストレージ用に設計されており、クライアント間でデータをリアルタイムで同期する必要があるアプリケーションに適しています。
</div></details>

### Q. 質問50: 未回答
ある医療企業は、患者記録管理システムを構築しています。そのためには、強力な一貫性と自動シャーディングを備えた、可用性の高いグローバルに分散されたデータベースが必要です。これらの要件に当てはまる GCP サービスはどれですか?
1. 
2. Cloud Spanner
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しいオプションは B. Cloud Spanner です。
Cloud Spanner:
Cloud Spanner は、グローバルに分散され、水平方向にスケーラブルで、強力な一貫性を持つデータベース サービスです。これは、質問に記載されている要件を満たすように特別に設計されています。自動シャーディングを提供し、グローバルな分散を提供することで、複数のリージョン間でデータの可用性と一貫性を確保します。
Cloud Spanner は、医療における患者記録管理システムなど、データの整合性、強力な一貫性、グローバルな可用性が重要なアプリケーションに最適です。
正しくないオプション -
クラウドデータストア:
Cloud Datastore は NoSQL データベースですが、グローバルに分散した患者記録管理システムに必要な強力な整合性と自動シャーディングは提供されません。
高可用性を実現するように設計されていますが、医療データに必要なレベルのグローバル分散と強力な一貫性は提供されない場合があります。
Bigtable の場合:
Bigtable は、大規模な分析および運用ワークロード向けに最適化された NoSQL データベースですが、医療アプリケーションの重要な要件である強力な一貫性をすぐに提供することはできません。
大量のデータを処理でき、高可用性を提供しますが、強力な一貫性を必要とするアプリケーションには最適ではありません。
クラウド SQL:
Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。自動シャーディングは提供されておらず、医療患者記録管理システムに必要なレベルのグローバル分散と強力な一貫性を提供しない可能性があります。
従来のリレーショナルデータベースのユースケースには適していますが、このシナリオには最適ではありません。
</div></details>

## 3
### Q. 質問1: 未回答
会社がキャンペーンのデータ パイプラインを確立する際、Google Cloud Pub/Sub ストリーミング データの重要なビジネス要件は、キャンペーン中に入力とそれに関連するタイミングを定期的に追跡することです。これを実現するために、エンジニアは Google Cloud Dataflow によるウィンドウ処理と変換を採用することを選択しました。ただし、テスト中に、ストリーミング挿入を処理するときに Cloud Dataflow ジョブの一貫したエラーが発生します。この問題の考えられる根本原因は何ですか?
1. 
2. 
3. 
4. 非グローバル ウィンドウ関数を適用していないため、パイプラインの作成時にジョブが失敗します。
<details><div>
    答え：4
説明
正解はDです。
Google Cloud Dataflow を使用したストリーミング データ処理では、集計と分析のためにデータをウィンドウに分割する方法を定義する必要があります。グローバル・ウィンドウ・ウィンドウと非グローバル (固定) ウィンドウ・ウィンドウのどちらかを選択できます。非グローバル ウィンドウは、データを有限の重複しない時間間隔にグループ化するために使用されます。
ストリーミング データを処理する場合は、ウィンドウ関数を定義して、データを処理用のより小さく管理しやすいチャンクに分割するのが一般的です。
ユースケースで必要なときに非グローバルウィンドウ関数を適用しないと、特にパイプラインがデータがウィンドウ化されることを想定しているのにそうでない場合、ジョブが失敗する可能性があります。
正しくないオプション -
ある。タイムスタンプが割り当てられていないため、ジョブが失敗します。
データへのタイムスタンプの割り当ては、イベント時の処理とウィンドウ処理にとって重要ですが、タイムスタンプがないだけでは必ずしもジョブが失敗するとは限りません。その結果、処理時間が使用される可能性があり、イベント時間ベースのウィンドウ処理には適していない可能性がありますが、ジョブの失敗の原因として最も可能性の高いものではありません。
B.遅れて入ってくるデータに対応するトリガーを設定していないため、ジョブが失敗します。
遅延データに対するトリガーの設定は、順不同または遅延到着のデータを処理するために重要です。ただし、トリガー設定がない場合でも、ジョブが直接失敗するとは限りません。代わりに、結果の正確性に影響を与える可能性があります。
C. グローバル ウィンドウ関数を適用していないため、パイプラインの作成時にジョブが失敗します。
特定のユースケースでグローバルウィンドウを使用することは完全に有効です。グローバルウィンドウを使用すると、データを固定ウィンドウに分割することなく、イベント時間全体のデータを処理できます。すべてのシナリオに最適な選択ではないかもしれませんが、通常、それだけを使用してもジョブの失敗にはつながりません。
</div></details>

### Q. 質問2: 未回答
地震データを解析するシステムを設計します。抽出、変換、読み込み (ETL) プロセスは、Apache Hadoop クラスターで一連の MapReduce ジョブとして実行されます。ETLプロセスでは、一部のステップで計算コストがかかるため、データセットの処理に数日かかります。次に、センサーのキャリブレーション手順が省略されていることがわかります。今後、センサーのキャリブレーションを体系的に実施するために、ETLプロセスをどのように変更する必要がありますか?
1. 
2. 新しい MapReduce ジョブを導入して、センサーのキャリブレーションを生データに適用し、この後、他のすべての MapReduce ジョブがチェーンされるようにします。
3. 
4. 
<details><div>
    答え：2
説明
正しいアプローチは B です。 
オプションBでは、センサーキャリブレーション専用のMapReduceジョブを導入し、すべてのデータがこの重要なステップを経てからさらに処理されるようにします。センサーキャリブレーションの省略に対処するための体系的かつ組織的な方法を提供し、ETLパイプラインで処理されるすべてのデータが将来一貫してキャリブレーションされることを保証します。
正しくないオプション -
A. 変換 MapReduce ジョブを変更して、他の処理を行う前にセンサーのキャリブレーションを適用します。
このオプションは、既存の変換ジョブを変更するだけなので、過去のセンサー調整の省略の問題には対処しません。今後のデータはキャリブレーションされますが、キャリブレーションされていないデータを遡及的に修正することはありません。
C. ETL プロセスの出力にセンサー キャリブレーション データを追加し、すべてのユーザーがセンサー キャリブレーションを自分で適用する必要があることを文書化します。
このオプションでは、センサのキャリブレーションの責任がエンドユーザーに移るため、体系的で信頼性の高いプロセスには理想的ではありません。ユーザーはキャリブレーションを忘れたり、誤って適用したりして、不整合につながる可能性があります。
D. シミュレーションを通じてアルゴリズムを開発し、キャリブレーション係数に基づいて最後の MapReduce ジョブから出力されたデータ出力の分散を予測し、その補正をすべてのデータに適用します。
このアプローチは洗練されているように聞こえますが、シミュレーションと予測に依存しているため、信頼性の高いセンサーのキャリブレーションには十分な精度が得られない可能性があります。また、複雑で、ある程度の不確実性が生じます。
</div></details>

### Q. 質問3: 未回答
オンライン小売業者の既存のアプリケーションは、Google App Engine でホストされています。新しい会社のイニシアチブでは、顧客との直接取引を可能にするためにアプリケーションを拡張しる必要があります。ビジネス インテリジェンス(BI)ツールを使用してショッピング トランザクションを効果的に管理し、複数のソースからのデータを分析するために、単一の Google Cloud データベースを活用することを目指しています。この要件には、どの Google Cloud データベースを選択すればよいでしょうか?
1. 
2. Cloud SQL
3. 
4. 
<details><div>
    答え：2
説明
オンライン小売業者がショッピング トランザクションを管理する必要があるこのシナリオでは、データベース ソリューションとして Cloud SQL(オプション B)を選択するのが適切です。
Cloud SQL が適している理由は次のとおりです。
トランザクション データ: Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。これは、トランザクション データの保存と管理用に設計されており、ショッピング トランザクションを管理する要件と一致しています。
ACIDコンプライアンス: Cloud SQLデータベースは、ACID(原子性、一貫性、分離性、耐久性)に準拠し、トランザクションの信頼性と一貫性を確保します。
互換性: 小売業者の既存のアプリケーションがすでに Google App Engine で実行されている場合、Cloud SQL は App Engine とシームレスに統合されるため、自然な選択です。
BIツールの統合:Cloud SQLは、さまざまなBIツールのデータソースとして使用でき、小売業者は必要に応じてデータ分析を実行できます。
構造化データ: Cloud SQL は構造化データに適していますが、これは通常、トランザクション システムの場合です。
正しくないオプション -
BigQuery(オプション A): BigQuery は分析ワークロードや大規模なデータセットのクエリには優れていますが、通常、トランザクション データのプライマリ データベースとしては使用されません。これは、履歴データまたは集計データの保存と分析に適しています。
Cloud Bigtable(オプション C): Cloud Bigtable は、高スループット、低レイテンシの読み取り/書き込みオペレーション用に最適化された NoSQL データベースです。これは、大規模なリアルタイムのデータアクセスを必要とするアプリケーションに適していますが、従来のトランザクションデータには最適な選択ではない可能性があります。
Cloud Datastore(オプション D):Cloud Datastore は、高可用性とスケーラビリティを必要とするアプリケーションに適した NoSQL データベースです。ただし、一般的には非構造化データまたは半構造化データに使用され、トランザクション データ管理には適していない場合があります。
</div></details>

### Q. 質問4: 未回答
約 1 年前に新しいゲーム アプリをローンチしました。前日のログファイルを、テーブル名の形式が LOGS_yyyymmdd の別の Google BigQuery テーブルにアップロードしています。テーブル ワイルドカード関数を使用して、すべての時間範囲の日次および月次レポートを生成しています。最近、長い日付範囲をカバーする一部のクエリが 000,<> テーブルの制限を超え、失敗していることを発見しました。
どうすればこの問題を解決できますか?
1. 
2. シャード テーブルを 1 つのパーティション テーブルに変換する
3. 
4. 
<details><div>
    答え：2
説明
B. 
テーブル数の削減: シャード テーブルは、通常、類似した構造を持つ複数のテーブルを参照し、多くの場合、日付などの条件で分割されます。これらのシャード テーブルを 1 つのパーティション テーブルに変換することで、クエリでスキャンする必要があるテーブルの数を大幅に減らすことができます。
パーティション テーブル: パーティション テーブルは時間ベースのデータ用に設計されており、Google BigQuery はそれらを操作する際のクエリ パフォーマンスを最適化します。各パーティションは特定の期間を表すため、長い日付範囲のデータをより効率的にクエリできます。
正しくないオプション -
A. すべての日次ログ テーブルを日付パーティション テーブルに変換します。
日次ログ テーブルを日付パーティション テーブルに変換することは、時間ベースのデータに対するクエリを最適化するための優れたプラクティスですが、1,000 テーブルの制限を超えるという問題に直接対処するものではありません。パーティション テーブルへの変換は便利ですが、毎日のパーティションがまだ多数ある場合は、本質的にテーブル数が減るわけではありません。
C. クエリ キャッシュを有効にして、前月のデータをキャッシュできるようにします。
クエリ キャッシュは、結果を再利用することでクエリのパフォーマンスを向上させることができますが、1,000 テーブルの制限を超えるという問題に直接対処するものではありません。また、クエリのキャッシュは、非常に大きなデータセットや、新しいデータを必要とするクエリを保証するものではありません。
D. 各月をカバーする個別のビューを作成し、次のビューからクエリを実行します。
月ごとに個別のビューを作成しても、テーブル数が直接減るわけではありません。ビューはテーブルの上に論理レイヤーを提供し、クエリの編成に役立ちますが、基になるテーブルの数は減りません。各ビューが異なる日次ログ テーブルに対応している場合、1,000 テーブルの制限を超えるという問題が残ります。
</div></details>

### Q. 質問5: 未回答
分析チームは、さまざまな指標を利用して、会社と再び関わる可能性が高い顧客を特定するための基本的な統計モデルを作成しようとしています。このモデルは Apache Spark を使用して実行し、データは Google Cloud Storage に保存される予定で、このタスクに Google Cloud Dataproc を利用することを提案しました。初期テストでは、このジョブは 30 ノード クラスタで約 15 分で完了し、結果は Google BigQuery に保存されることが示されています。目的は、このタスクを毎週実行することです。コスト効率を高めるためにクラスタ構成を最適化するにはどうすればよいでしょうか。
1. ワークロードを Google Cloud Dataflow に移行します。
2. クラスターにプリエンプティブル仮想マシン (VM) を使用します。
3. メモリの大きいノードを使用して、ジョブの実行を高速化します。
4. ワーカー ノードで SSD を使用して、ジョブの実行を高速化します。
<details><div>
    答え：2
説明
Google Cloud Dataproc の Apache Spark で週単位のワークロードを実行する際に、クラスタのコストを最適化するための正しいオプションは次のとおりです。
B. 
プリエンプティブル VM: プリエンプティブル VM は、標準のオンデマンド VM よりも大幅に安価であるため、Google Cloud の費用対効果の高いオプションです。ただし、Google Cloud によっていつでもプリエンプト(終了)される可能性があり、通常は短期間(最大 24 時間)でプリエンプト(終了)される可能性があります。週単位の統計モデルの実行など、長期的なアップタイムを必要としないワークロードでは、プリエンプティブル VM を使用すると、かなりのコストを節約できます。
正しくないオプション -
A. 
Google Cloud Dataflow への移行はオプションかもしれませんが、これは別のテクノロジーであり、既存の Apache Spark ベースのワークロードに大幅な変更が必要になる場合があります。これにより、複雑さが増し、開発作業が増える可能性があります。また、Dataflow と Dataproc のコストへの影響は、特定のユースケースによって異なります。
C. 
メモリの大きいノードを使用すると、ジョブのパフォーマンスが向上する可能性がありますが、コストが大幅に増加する可能性もあります。コストを最適化するこのシナリオでは、特にジョブが小さなプリエンプティブル ノードで効率的に実行される場合、より大きなノードを選択することは最も効率的なアプローチではない可能性があります。
D. 
ワーカー ノードに SSD を追加すると、データの読み取り/書き込みパフォーマンスが向上する可能性がありますが、必ずしもコスト最適化戦略ではありません。SSD はインフラストラクチャ コストを増加させる可能性があり、30 ノード クラスターで既に 15 分で実行されているジョブのパフォーマンス向上は大きくない可能性があります。コストの最適化が主な目的である場合、このオプションは最適な選択ではない可能性があります。
</div></details>

### Q. 質問6: 未回答
会社は、バッチベースとストリームベースのイベントデータの両方を受信します。Google Cloud Dataflow を使用して、予測可能な期間にわたってデータを処理したい。ただし、場合によっては、データが遅れたり、順序どおりに届かなかったりすることがあります。
遅延したデータや順序が正しくないデータを処理するために、Cloud Dataflow パイプラインをどのように設計すればよいですか?
1. 
2. 
3. 透かしとタイムスタンプを使用して、時間差データをキャプチャします。
4. 
<details><div>
    答え：3
説明
Google Cloud Dataflow パイプラインで遅延または順序が正しくないデータを処理するには、次のことを行う必要があります。
C. 
ウォーターマークとタイムスタンプ: Google Cloud Dataflow のようなストリーム処理パイプラインでは、ウォーターマークとタイムスタンプは、遅延データや順不同のデータを処理するために不可欠な概念です。ウォーターマークはイベント時間の進行状況を表し、特定の期間にデータが完了したと見なすのが安全である時期を Dataflow が理解するのに役立ちます。タイムスタンプは、イベントがいつ発生したかを示します。
ウォーターマークとタイムスタンプを使用すると、次のことができます。
処理時間ではなくイベント時間に基づいてウィンドウを定義します。これにより、遅れて到着しても、関連する時間枠に属するデータを取得できます。
イベントが到着したときにタイムスタンプを割り当て、ウォーターマークを使用してイベント時間の進行状況を追跡することで、順不同のデータを処理します。Dataflow は、イベントのタイムスタンプに基づいて、適切なウィンドウにイベントを正しく配置できます。
正しくないオプション -
A. すべてのデータを取得するために 1 つのグローバル ウィンドウを設定します。
このアプローチでは、データの遅延や順序の乱れの問題には対処できません。すべてのデータが 1 つのウィンドウにあるかのように扱われ、指定された時間枠の後に到着したイベントを正しく処理するために必要な柔軟性は提供されません。
B. スライディング ウィンドウを設定して、すべての時間差データをキャプチャします。
スライディング ウィンドウは、一定の間隔でデータをキャプチャする場合に便利ですが、本質的に遅延データや順序が正しくないデータは処理されません。遅延データはスライディング ウィンドウの範囲外にある可能性があり、スライディング ウィンドウのみを使用してそのようなデータを処理するのに十分ではない可能性があります。
D. すべてのデータソースの種類 (ストリームまたはバッチ) にタイムスタンプがあることを確認し、タイムスタンプを使用して時間差データのロジックを定義します。
データソースにタイムスタンプを付けることはおすすめの方法ですが、Dataflow パイプライン内で遅延したデータや順序が正しくないデータを処理するという主要な問題には対処できません。タイムスタンプだけでは、イベント時間処理の複雑さを処理し、遅延データが処理ウィンドウで正しく考慮されるようにするには不十分です。
</div></details>

### Q. 質問7: 未回答
社内の IT アプリケーションの 1 つを Google BigQuery と統合し、ユーザーがアプリケーションのインターフェースから BigQuery クエリを実行できるようにしています。目的は、個々のユーザーが BigQuery で直接認証する必要がないようにすることであり、データセットへのアクセス権を付与したくありません。このような状況で、IT アプリケーションから BigQuery へのアクセスを安全に有効にするにはどうすればよいでしょうか。
1. 
2. 
3. サービスアカウントを作成し、そのアカウントへのデータセットアクセス権を付与します。サービスアカウントの秘密鍵を使用してデータセットにアクセスします。
4. 
<details><div>
    答え：3
説明
個々のユーザーが BigQuery に対して認証を行ったり、データセットへのアクセス権を付与したりすることなく、IT アプリケーションから Google BigQuery に安全にアクセスするための最も安全で推奨されるアプローチは次のとおりです。
C. 
サービス アカウント: サービス アカウントは、個々のユーザーではなく、アプリケーションを表す特殊なタイプの Google アカウントです。これは、サーバー間の対話用に設計されています。サービス アカウントを作成し、そのアカウントを使用して BigQuery にアクセスすることで、ユーザーが BigQuery に直接アクセスする必要がなく、サービス アカウントがアクセスできるリソースを完全に制御できます。
秘密鍵: サービス アカウントには秘密鍵が付属しており、この秘密鍵を安全に保存して、BigQuery などの Google Cloud サービスでの認証にアプリケーションで使用できます。この秘密キーにより、アプリケーションはユーザーレベルの認証を必要とせずに、サービスアカウントの代わりに動作できます。
正しくないオプション -
A. ユーザーのグループを作成し、それらのグループにデータセットへのアクセス権を付与します。
このオプションでは、ユーザーにデータセットのアクセス権が付与されますが、これは実行したくないこととして明示的に言及されています。個々のユーザーにデータセットへのアクセス権を付与しないという要件には対応していません。
B. シングル サインオン (SSO) プラットフォームと統合し、各ユーザーの資格情報をクエリ要求と共に渡します。
SSO 統合はユーザー認証に役立ちますが、通常、BigQuery 内の特定のデータセットへのアクセスを制限するメカニズムは提供されません。クエリ要求と共にユーザー資格情報を渡すと、個々のユーザーの認証が必要になる可能性が高くなりますが、これは避けたいことです。
D. ダミーユーザーを作成し、そのユーザーにデータセットアクセス権を付与します。そのユーザーのユーザー名とパスワードをファイル システム上のファイルに保存し、それらの認証情報を使用して BigQuery データセットにアクセスします。
このオプションでは、ダミーユーザーを作成し、その資格情報をファイルシステムに保存する必要がありますが、これは安全ではないため、推奨されません。この方法で認証情報を保存すると、セキュリティ上のリスクが生じるため、Google Cloud サービスにアクセスするためのベスト プラクティスにはなりません。
</div></details>

### Q. 質問8: 未回答
Google Cloud でデータ パイプラインを構築しています。機械学習プロセスでは、カジュアルな方法を使用してデータを準備する必要があります。ロジスティック回帰モデルをサポートする場合。また、null 値を監視して調整する必要もありますが、null 値は実数値のままで、削除することはできません。あなたは何をするべきか?
1. 
2. Cloud Dataprep を使用して、サンプルソースデータ内の null 値を見つけます。Cloud Dataprep ジョブを使用して、すべての null を 0 に変換します。
3. 
4. 
<details><div>
    答え：2
説明
ロジスティック回帰モデル用のデータを準備しながら、実数値を維持する必要がある NULL 値を監視および処理するには、次のオプションを検討する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
Cloud Dataprep: Cloud Dataprep は、データを視覚的に探索、クリーニング、変換できるデータ準備サービスです。null 値を 0 などの特定の値に置き換える機能など、null 値を処理するための使いやすいツールを提供します。
Null 値の処理: 機械学習では、特に実数値の特徴を操作する場合、null 値を 0 などの特定の数値に置き換えるのが一般的です。このアプローチにより、データが実数値のままになり、ロジスティック回帰モデルで効果的に使用できます。
正しくないオプション -
A. Cloud Dataprep を使用して、サンプルのソースデータから null 値を見つけます。Cloud Dataprep ジョブを使用して、すべての null を「none」に変換します。
null を 'none' に変換すると、数値以外の値がデータに導入され、ロジスティック回帰には適していません。ロジスティック回帰には数値入力特徴が必要です。
C. Cloud Dataflow を使用して、サンプル ソース データ内の null 値を検索します。Cloud Dataprep ジョブを使用して、すべての null を「none」に変換します。
Cloud Dataflow は強力なデータ処理サービスですが、通常、単純な null 値の置換タスクには使用されません。さらに、null を 'none' に変換することは、ロジスティック回帰モデルには適していない場合があります。
D. Cloud Dataflow を使用して、サンプルのソースデータで null 値を見つけます。カスタムスクリプトを使用してすべてのnullを0に変換します。
Cloud Dataflow はデータの前処理タスクに使用できますが、カスタム スクリプトを使用して null を 0 に置き換えると、不必要に複雑になる可能性があります。Cloud Dataprep は、このようなデータ準備タスクをよりユーザーフレンドリーで効率的に処理する方法を提供します。
</div></details>

### Q. 質問9: 未回答
Kafka クラスタを介して Redis クラスタに挿入されるストリーミング データの保存データを暗号化し、どちらも Compute Engine インスタンスでホストされ、必要に応じて暗号鍵を作成、ローテーション、削除する機能を備えているには、どのような手順を実行する必要がありますか?
1. 
2. Cloud Key Management Service で暗号化キーを作成します。これらの鍵を使用して、すべての Compute Engine クラスタ インスタンスのデータを暗号化します。
3. 
4. 
<details><div>
    答え：2
説明
Compute Engine インスタンスで実行されている Redis クラスタと Kafka クラスタの両方の保存データを暗号化し、暗号鍵の制御を維持するには、次のことを行う必要があります。
B. 
Cloud Key Management Service(Cloud KMS): Cloud KMS は、暗号鍵を作成、管理、ローテーションできるマネージド サービスです。キーに強力なセキュリティとアクセス制御を提供します。
データの暗号化: Cloud KMS で暗号鍵を作成し、その鍵を使用して Compute Engine インスタンス内のデータを暗号化することで、保存データが確実に暗号化されます。この暗号化はシームレスで透過的であり、必要に応じてキーのローテーションや破棄など、キー管理を制御できます。
正しくないオプション -
A. 専用のサービス アカウントを作成し、保存時の暗号化を使用して、API サービス呼び出しの一部として Compute Engine クラスタ インスタンスに保存されているデータを参照します。
このオプションでは、データ自体の暗号化には対応していません。保存時の暗号化とは、通常、転送中(APIサービス呼び出しの一部として)ではなく、ストレージメディア(ディスクなど)上のデータを暗号化することを指します。また、Cloud KMS と同じレベルの鍵管理制御も提供されません。
C. 暗号化キーをローカルで作成します。暗号化鍵を Cloud Key Management Service にアップロードします。これらのキーを使用して、すべての Compute Engine クラスタ インスタンスのデータを暗号化します。
鍵をローカルで作成して Cloud KMS にアップロードすることもできますが、複雑さが増し、Cloud KMS などのマネージド鍵サービスを使用するメリットが失われます。キーをローカルで直接管理すると、キーが漏洩するリスクも高まります。
D. Cloud Key Management Service で暗号化キーを作成します。これらのキーは、Compute Engine クラスタ インスタンスのデータにアクセスするときに、API サービス呼び出しで参照します。
このオプションは、転送中の暗号化に重点を置き、保存データには対応しません。包括的なセキュリティを提供するために、保存データを暗号化することが重要です。
</div></details>

### Q. 質問10: 未回答
Google Cloud で動画レコメンデーション アプリケーションを開発しています。アプリケーションは、顧客が以前に視聴したビデオに基づいて、新しいビデオを顧客に表示する必要があります。また、アプリケーションは、顧客が視聴したビデオ内のエンティティ(俳優、監督、ジャンルなど)のラベルを生成する必要があります。アプリケーションの設計では、数テラバイトのデータに対する他の顧客の好みからのデータに基づいて、非常に高速なフィルタリングの提案を提供できる必要があります。このアプリケーションを実装するには、どのような手順を実行する必要がありますか?
1. 
2. 
3. Cloud Video Intelligence API を呼び出してラベルを生成するアプリケーションを構築します。Cloud Bigtable にデータを保存し、予測ラベルをフィルタリングしてユーザーの視聴履歴と一致させ、設定を生成します。
4. 
<details><div>
    答え：3
説明
C. 
Cloud Video Intelligence API: Cloud Video Intelligence API は、動画コンテンツの分析に特化して設計されています。ビデオからラベルやその他の洞察を生成できるため、ビデオコンテンツから情報を抽出するタスクに適しています。
Cloud Bigtable: Cloud Bigtable は、大量のデータを効率的に処理できるスケーラブルな NoSQL データベースです。Cloud Bigtable にデータを保存すると、設定のフィルタリングと生成に必要なデータに高速にアクセスできます。
データのフィルタリング: このオプションでは、パーソナライズされたレコメンデーションを作成するために不可欠な、ユーザーの視聴履歴と一致するように予測ラベルをフィルタリングすることを提案します。Cloud Bigtable はこれを効率的に処理できます。
正しくないオプション -
A. Spark MLlib を使用して複雑な分類モデルを構築してトレーニングし、ラベルを生成し、結果をフィルター処理します。Cloud Dataproc を使用してモデルをデプロイします。アプリケーションからモデルを呼び出します。
Spark MLlib と Cloud Dataproc は機械学習のタスクには強力ですが、このタスクに複雑な分類モデルを使用すると、過剰に設計されたソリューションになる可能性があります。Cloud Video Intelligence API などの特殊な API を使用するよりも、リソースを大量に消費し、時間がかかる場合があります。
B. Spark MLlib を使用して分類モデルを構築してトレーニングし、ラベルを生成します。Spark MLlib を使用して 2 番目の分類モデルを構築してトレーニングし、顧客の好みに合わせて結果をフィルター処理します。Cloud Dataproc を使用してモデルをデプロイします。アプリケーションからモデルを呼び出します。
オプション A と同様に、このアプローチでは複雑な分類モデルを使用するため、ビデオ ラベルとレコメンデーションを生成するタスクには必要ない場合があります。これにより、複雑さが増し、メンテナンスのオーバーヘッドが発生します。
D. Cloud Video Intelligence API を呼び出してラベルを生成するアプリケーションを構築します。Cloud SQL にデータを保存し、予測されたラベルを結合してフィルタリングし、ユーザーの視聴履歴と一致させて設定を生成します。
ラベルの生成には Cloud Video Intelligence API の使用が適していますが、大規模なデータの保存とフィルタリングには Cloud SQL が適していない可能性があります。通常、Cloud Bigtable は大量のデータを効率的に処理するのに適しています。
</div></details>

### Q. 質問11: 未回答
現在、Google Cloud 上のデータ パイプライン用に JSON メッセージを作成し、Cloud Pub/Sub から BigQuery に変換するためのサービスを選択しています。目的は、サービスコストを削減し、最小限の手動介入で変動する入力データ量に簡単に適応できるシステムを確立することです。これを達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. Cloud Dataflow を使用して変換を実行します。ジョブ システムの遅延を Stackdriver でモニタリングします。ワーカーインスタンスのデフォルトの自動スケーリング設定を使用します。
4. 
<details><div>
    答え：3
説明
Cloud Pub/Sub から BigQuery への JSON メッセージの書き込みや変換を行う際に、サービス費用を最小限に抑え、手動による介入を最小限に抑えてさまざまな入力データ量を処理するには、次のオプションが最適です。
C. 
Cloud Dataflow: Cloud Dataflow は、Cloud Pub/Sub から BigQuery へのデータを効率的に処理して変換できる、マネージド ストリームおよびバッチ データ処理サービスです。入力データ量に基づいてワーカーインスタンスの数を自動的に調整する自動スケーリング機能を提供し、費用対効果とパフォーマンスの最適化を保証します。
ジョブ システムの遅延をモニタリングする: Stackdriver を使用してジョブ システムの遅延を監視すると、Dataflow ジョブがデータを処理する速度と、データの到着速度を比較できます。これにより、ボトルネックを特定し、必要に応じてリソースを調整できます。
正しくないオプション -
A. Cloud Dataproc を使用して変換を実行します。クラスタの CPU 使用率を監視します。コマンドラインを使用して、クラスタ内のワーカーノードの数のサイズを変更します。
Cloud Dataproc はバッチ処理用に設計されているため、Cloud Dataflow のようなストリーミング データには費用対効果と効率性が劣る場合があります。コマンドラインを使用してワーカーノードを手動でサイズ変更しても、データ量の変化に必要なレベルの自動化が得られない場合があります。
B. Cloud Dataproc を使用して変換を実行します。diagnose コマンドを使用して、操作出力アーカイブを生成します。ボトルネックを特定し、クラスター リソースを調整します。
Cloud Dataproc はバッチ処理を処理できますが、リアルタイムのストリーム処理には最適ではありません。diagnose コマンドを使用してボトルネックを特定し、リソースを手動で調整すると、Cloud Dataflow に比べて時間がかかり、自動化も容易ではない場合があります。
D. Cloud Dataflow を使用して変換を実行します。ジョブのサンプリングの合計実行時間を監視します。必要に応じて、デフォルト以外の Compute Engine マシンタイプを使用するようにジョブを設定します。
Cloud Dataflow は正しい選択ですが、合計実行時間をモニタリングしてマシンタイプを手動で構成すると、デフォルトの自動スケーリング設定に付属する自動スケーリングのメリットが得られず、さまざまなデータ量を処理する際の効率が低下する可能性があります。
</div></details>

### Q. 質問12: 未回答
インフラストラクチャには、一連の YouTube チャンネルが含まれています。あなたは、分析のために YouTube チャンネルのデータを Google Cloud に送信するプロセスを作成する任務を負っています。世界中のマーケティングチームが、最新の YouTube チャンネルのログデータに対して ANSI SQL やその他の種類の分析を実行できるソリューションを設計したいと考えています。Google Cloud へのログデータ転送はどのように設定すればよいですか?
1. Storage Transfer Service を使用して、オフサイトのバックアップ ファイルを最終的な宛先として Cloud Storage Multi-Regional Storage バケットに転送します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
Storage Transfer Service: Google Cloud の Storage Transfer Service は、さまざまなソースから Cloud Storage にデータを効率的に転送できるように設計されています。オフサイトのバックアップファイルの転送を確実に処理できます。
マルチリージョンストレージ: マルチリージョンストレージバケットを使用すると、複数のリージョン間でデータの可用性と耐久性が確保されます。この冗長性は、高可用性とディザスター リカバリーのシナリオで重要になる場合があります。
正しくないオプション -
B. Storage Transfer Service を使用して、オフサイトのバックアップ ファイルを最終宛先として Cloud Storage リージョン バケットに転送します。
リージョナルバケットの使用は有効な選択肢ですが、マルチリージョナルバケットと同じレベルの冗長性が得られない場合があります。世界中のマーケティングチームがこのデータに依存している場合、複数のリージョンで利用できるようにすることで(オプションA)、さまざまな場所のユーザーのアクセスパフォーマンスを向上させることができます。
C. BigQuery Data Transfer Service を使用して、オフサイトのバックアップ ファイルを最終的な宛先として Cloud Storage Multi-Regional Storage バケットに転送します。
このオプションでは、不必要な複雑さが生じます。BigQuery Data Transfer Service を使用して BigQuery にデータを取り込むことはできますが、オフサイトのバックアップ ファイルの Cloud Storage への転送は効率的に処理されません。初期転送にストレージ転送サービスを使用する方が、より簡単な方法です。
D. BigQuery Data Transfer Service を使用して、オフサイトのバックアップ ファイルを最終的な宛先として Cloud Storage リージョン ストレージ バケットに転送します。
オプション C と同様に、このアプローチは複雑になり、BigQuery Data Transfer Service の主な目的である、分析のためにデータを直接取り込むという目的に沿うものではありません。初期データ転送に Storage Transfer Service を使用すると、より効率的になります。
</div></details>

### Q. 質問13: 未回答
あなたは、Google Cloud のデータ パイプラインに大量のテキスト ファイル用のストレージを作成する任務を負っています。目的は、ANSI SQL クエリを有効にし、圧縮を実装し、Google のベスト プラクティスに準拠しながら、入力場所からの並列読み込みを容易にすることです。これらの目標を達成するには、どのような手順を踏む必要がありますか?
1. 
2. Cloud Dataflow を使用して、テキスト ファイルを圧縮された Avro に変換します。クエリには Cloud Storage と BigQuery の永続的なリンク テーブルを使用します。
3. 
4. 
<details><div>
    答え：2
説明
Google Cloud 上のデータ パイプライン用に非常に大きなテキスト ファイルのストレージを設計し、ANSI SQL クエリをサポートし、Google が推奨するプラクティスに従って入力場所からの圧縮と並列読み込みをサポートするには、次のオプションを検討する必要があります。
B. 
Cloud Dataflow: Cloud Dataflow を使用すると、並列読み込みをサポートしながら、テキスト ファイルを Avro 形式に変換できます。データ変換機能を提供し、大規模なデータセットを効率的に処理できます。
Cloud Storage: 変換されたデータを Cloud Storage に保存することは、効率的なデータ ストレージの一般的な方法です。Cloud Storage は、大量のデータを処理するように設計されており、データの耐久性と可用性を提供します。
BigQuery: データのクエリに BigQuery を使用すると、ANSI SQL を分析に活用できます。Cloud Storage のデータを参照する永続的なリンク テーブルを BigQuery で作成することで、データをクエリするための便利でパフォーマンスの高い方法が提供されます。
正しくないオプション -
A. Cloud Dataflow を使用して、テキスト ファイルを圧縮された Avro に変換します。ストレージとクエリに BigQuery を使用する:
BigQuery は Avro ファイルを保存できますが、Cloud Storage と比較して最も効率的なストレージ形式ではありません。さらに、Cloud Storage を参照する BigQuery でリンク テーブルを使用すると、柔軟性と制御性が向上します。
C. Grid Computing Tools を使用してテキスト ファイルを gzip に圧縮します。ストレージとクエリに BigQuery を使用する:
BigQuery は gzip 圧縮データを処理できますが、このオプションでは、クエリ最適化のためのより構造化された効率的なストレージを提供できる Avro 形式へのテキスト ファイルの変換には対応していません。
D. Grid Computing Tools を使用してテキストファイルを gzip に圧縮します。Cloud Storage を使用し、クエリのために Cloud Bigtable にインポートします。
Cloud Bigtable は、BigQuery のような ANSI SQL クエリの実行ではなく、高スループットで低レイテンシの NoSQL データ向けに設計されています。このオプションは、ANSI SQL クエリをサポートするための要件には適合しておらず、NoSQL ワークロードに適しています。
</div></details>

### Q. 質問14: 未回答
ユーザーのブログ投稿の件名ラベルを自動的に生成するアプリケーションを Google Cloud で開発しています。この機能を迅速に追加しなければならないという競争上のプレッシャーにさらされており、追加の開発者リソースはありません。チームには機械学習の経験がある人がいません。あなたは何をするべきか?
1. アプリケーションから Cloud Natural Language API を呼び出します。生成されたエンティティ分析をラベルとして処理します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
Cloud Natural Language API: Google の Cloud Natural Language API は、フルマネージドで事前トレーニング済みの機械学習サービスです。広範な機械学習の専門知識を必要とせずに、テキスト データからエンティティ、センチメント、その他の貴重な分析情報を抽出できます。
エンティティ分析: エンティティ分析では、ブログ投稿から重要な主題、エンティティ、およびキーワードを識別して抽出できます。これらのエンティティは、投稿のラベルとして使用できます。
このオプションを使用すると、最小限の開発労力と時間で、必要な機能をアプリケーションにすばやく追加できます。Cloud Natural Language API は、機械学習の複雑さを抽象化し、機械学習の専門知識がなくてもアクセスできるようにします。
正しくないオプション -
B. アプリケーションから Cloud Natural Language API を呼び出します。生成された感情分析をラベルとして処理します。
センチメント分析は、テキストの感情的なトーンに関する洞察を提供できますが、ブログ投稿の件名ラベルとして直接機能しない場合があります。この目的には、エンティティ分析の方が適しています。
C. TensorFlow を使用してテキスト分類モデルを構築してトレーニングします。Cloud Machine Learning Engine を使用してモデルをデプロイします。アプリケーションからモデルを呼び出し、結果をラベルとして処理します。
このオプションには、モデルの作成、トレーニング、デプロイなど、機械学習の開発作業が伴います。機械学習の経験がなく、開発者のリソースが限られている場合、それは実用的ではありません。
D. TensorFlow を使用してテキスト分類モデルを構築してトレーニングします。Kubernetes Engine クラスターを使用してモデルをデプロイします。アプリケーションからモデルを呼び出し、結果をラベルとして処理します。
オプションCと同様に、このアプローチには、モデルのトレーニングやKubernetesクラスターの管理など、機械学習に関する十分な専門知識が必要です。機械学習の経験がなく、リソースが限られている場合は適していません。
</div></details>

### Q. 質問15: 未回答
入力データが CSV 形式である Google Cloud 上のデータ パイプライン デプロイ用に 20 TB のテキスト ファイルのストレージを計画する場合、目的は、さまざまなエンジンを介して Cloud Storage のデータにアクセスする複数のユーザーの集計値をクエリするコストを削減することです。この目標を達成するには、どのようなストレージ サービスとスキーマの設計を選択する必要がありますか?
1. 
2. 
3. ストレージには Cloud Storage を使用します。クエリ用に BigQuery の永続的なテーブルとしてリンクします。
4. 
<details><div>
    答え：3
説明
複数のエンジンを使用して Cloud Storage 内のデータをクエリする複数のユーザーの集計値をクエリするコストを最小限に抑えるには、次のオプションを検討する必要があります。
C. 
クラウドストレージ: 20 TB のテキストファイルを Cloud Storage に保存することは、大量のデータを処理するための費用対効果が高く効率的なオプションです。
BigQuery: BigQuery でデータを永続的なテーブルとしてリンクすると、データに対して SQL クエリを効率的に実行できます。BigQuery は分析用に設計されており、複雑なクエリをサポートし、大規模なデータセットを処理できます。
正しくないオプション -
A. ストレージには Cloud Bigtable を使用します。Compute Engine インスタンスに HBase シェルをインストールして、Cloud Bigtable データをクエリします。
Cloud Bigtable は、BigQuery のような ANSI SQL クエリの実行ではなく、高スループットの NoSQL ワークロード向けに設計されています。HBase をインストールして Compute Engine インスタンスを使用すると、複雑さが増し、ユースケースの費用対効果が高くない可能性があります。
B. ストレージに Cloud Bigtable を使用する。クエリ用に BigQuery の永続的なテーブルとしてリンクする:
BigQuery で Cloud Bigtable データをリンクすることは可能ですが、通常は NoSQL ストレージに特定の要件があり、BigQuery のデータに対して SQL のようなクエリを実行する必要がある場合に使用されます。ただし、CSV テキストデータを処理するには、Cloud Storage の方が費用対効果が高く、わかりやすいオプションです。
D. ストレージには Cloud Storage を使用します。クエリ用に BigQuery の一時テーブルとしてリンクする:
BigQuery でデータを一時テーブルとしてリンクすることは、一時データや永続化する必要のないデータのためのオプションです。20 TB のデータがあるため、効率的なクエリには永続的なテーブルを使用する方が適切です。
</div></details>

### Q. 質問16: 未回答
Google Cloud 上の 10 TB データベースの一部である <> つのリレーショナル テーブルのストレージを設計しています。水平方向にスケーリングするトランザクションをサポートする必要があります。また、非キー列に対する範囲クエリのデータを最適化する必要もあります。あなたは何をするべきか?
1. 
2. 
3. ストレージに Cloud Spanner を使用します。セカンダリインデックスを追加して、クエリパターンをサポートします。
4. 
<details><div>
    答え：3
説明
C. 
Cloud Spanner: Cloud Spanner は、グローバルに分散され、水平方向にスケーラブルで、強力な一貫性を持つリレーショナル データベース サービスです。大規模なデータベースを処理でき、水平方向のスケーラビリティを備えているため、10 TB のデータベースに適しています。
セカンダリ インデックス: Cloud Spanner ではセカンダリ インデックスを作成できるため、特定のクエリ パターンに対するクエリのパフォーマンスを大幅に向上させることができます。非キー列にセカンダリインデックスを追加すると、効率的な範囲クエリが可能になります。
正しくないオプション -
A. ストレージには Cloud SQL を使用します。セカンダリインデックスを追加して、クエリパターンをサポートします。
Cloud SQL はリレーショナル データをサポートできますが、10 TB のデータベースを Cloud Spanner ほど効率的に処理できない場合があります。また、Cloud SQL で大規模なデータセットにセカンダリ インデックスを追加すると、パフォーマンスに影響し、同じスケーラビリティが得られない可能性があります。
B. ストレージに Cloud SQL を使用します。Cloud Dataflow を使用してデータを変換し、クエリ パターンをサポートします。
Cloud SQL は、スケーラビリティ要件のある 10 TB のデータベースには適していない可能性があります。Cloud Dataflow はデータ変換に役立ちますが、水平方向のスケーラビリティのニーズには対応しておらず、複雑さが生じる可能性があります。
D. ストレージに Cloud Spanner を使用します。Cloud Dataflow を使用してデータを変換し、クエリ パターンをサポートします。
ストレージに Cloud Spanner を使用するのは適切な選択ですが、Cloud Dataflow は通常、セカンダリ インデックスなどのクエリ パターンに合わせてデータを最適化するためではなく、前処理と変換のタスクに使用されます。Cloud Spanner はすでにセカンダリ インデックスをサポートしているため、この追加のデータ変換手順はあまり必要ありません。
</div></details>

### Q. 質問17: 未回答
金融サービス組織は、クラウドテクノロジーに移行し、50TBの金融時系列データをクラウド環境に保存することを目指しています。このデータは頻繁に更新され、新しい情報が継続的にストリーミングされます。同時に、同社は現在のApache Hadoopジョブをクラウドに移行し、このデータから洞察を引き出す予定です。このデータを効果的に保存し、目的のクラウドベースの運用をサポートするには、どの特定の製品を採用する必要がありますか?
1. Cloud Bigtable
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
Cloud Bigtable が正しい選択と見なされる理由は次のとおりです。
スケーラビリティ: Cloud Bigtable は、高スループットで水平方向にスケーラブルなワークロード向けに設計された NoSQL データベースです。大量のデータを処理でき、頻繁な更新やデータのストリーミングを行うシナリオに適しています。
低レイテンシー: 特にリアルタイムの洞察が必要な場合に、金融時系列データに不可欠なデータへの低レイテンシーアクセスを提供します。
Apache Hadoop の統合: Cloud Bigtable は HBase API を介して Apache Hadoop と統合されているため、既存の Apache Hadoop ジョブをクラウドに移行して、大幅な変更を行うことなく Bigtable に保存されているデータを分析できます。
正しくないオプション -
B. Google BigQuery:
BigQuery は、大規模なデータセットに対して SQL のようなクエリを実行するのに最適ですが、主要なストレージ ソリューションではありません。これは、生の時系列データを格納するよりも、分析ワークロードに適しています。BigQuery にデータを読み込んで分析することはできますが、特にリアルタイムの更新と低レイテンシのアクセスが不可欠な場合は、50 TB の金融時系列データのプライマリ ストレージには最適ではない可能性があります。
C. Google Cloud Storage:
Cloud Storage はオブジェクト ストレージ サービスであり、Cloud Bigtable のようなデータベース システムと同じリアルタイムのデータ アクセス機能やクエリ機能を提供しない場合があります。Cloud Storage にデータを保存することもできますが、通常は耐久性のあるストレージ レイヤとして使用され、追加の処理を行わないとトランザクションや分析のワークロードには適さない場合があります。
D. Google Cloud データストア:
Cloud Datastore は、特定のユースケースに適した NoSQL データベースですが、大量の財務時系列データを処理し、Apache Hadoop ジョブをサポートするには、Cloud Bigtable と同じレベルのパフォーマンスとスケーラビリティを備えていない可能性があります。
</div></details>

### Q. 質問18: 未回答
組織は、ユーザーレベルのデータを含むテーブルを含む Google BigQuery データセットを維持しています。このデータの集計を他の Google Cloud プロジェクトに公開しながら、ユーザーレベルのデータへのアクセスを制御したいと考えています。さらに、全体的なストレージ コストを最小限に抑え、他のプロジェクトの分析コストがそれらのプロジェクトに割り当てられるようにする必要があります。彼らは何をすべきか?
1. 
2. 集計結果を提供する新しいデータセットとビューを作成して共有します。
3. 
4. 
<details><div>
    答え：2
説明
ユーザーレベルのデータへのアクセスを制御し、ストレージ コストを最小限に抑え、他のプロジェクトの分析コストがそれらのプロジェクトに割り当てられるようにしながら、Google BigQuery データセットのユーザーレベルのデータの集計を他の Google Cloud プロジェクトに公開するには、組織は次のオプションを検討する必要があります。
B. 
新しいデータセット: 集計結果専用の新しいデータセットを作成することで、集計データをユーザーレベルのデータから分離し、アクセス制御と権限を分離することができます。これは、生のユーザーレベルデータへのアクセスを制御するのに役立ちます。
ビュー: 新しいデータセット内にビューを作成すると、ユーザーレベルのデータから必要な集計を生成するSQLクエリを定義できます。ビューは仮想テーブルとして機能し、データのフィルター処理および集計されたパースペクティブを提供します。
共有: その後、新しいデータセットとそれに関連するビューを他の Google Cloud プロジェクトと共有して、元のデータセット内のユーザーレベルのデータを安全に保ちながら、それらのプロジェクトが集計データにアクセスできるようにすることができます。
コスト管理: データセットとビューを分離することで、コストをより適切に管理および割り当てることができます。新しいデータセットとビューのクエリを実行するときに他のプロジェクトによって発生する分析コストは、それらのプロジェクトに関連付けられ、組織の全体的なコストが最小限に抑えられます。
正しくないオプション -
オプション A の、集計結果を提供する許可済みビューを作成して共有することも有効なアプローチです。ただし、新しいデータセットとビューを作成すると、集計されたデータがユーザーレベルのデータからより適切に分離され、長期的にはよりクリーンでスケーラブルなソリューションになる可能性があります。
オプション C では、集計結果を含む新しいデータセットとテーブルを作成して共有できますが、特にストレージ コストが懸念される場合は、集計を個別のテーブルに具体化するよりも、集計のビューを作成する方が一般的に効率的です。
オプション D は、データセットに dataViewer Identity and Access Management (IAM) ロールを作成して共有を有効にすることですが、それだけでは十分ではありません。それでも、ユーザーレベルのデータへのアクセスを制御しながら、特定の集計結果を提供するために、新しいデータセットまたはビューを作成する必要があります。
</div></details>

### Q. 質問19: 未回答
特定のデータ型へのアクセスに関する監査可能な記録の維持が義務付けられている業界の政府規制により、期限切れになるすべてのログが適切にアーカイブされることを前提として、この規制要件に該当するデータをどこに保存する必要がありますか?
1. 
2. 許可された担当者のみが表示できる BigQuery データセットで、データアクセスログを使用して監査機能を提供します。
3. 
4. 
<details><div>
    答え：2
説明
監査可能なアクセス記録の維持を義務付ける政府規制の対象となるデータを保存するには、次のオプションが最も適しています。
B.
監査: BigQuery は、データアクセスログなどの堅牢な監査機能を提供します。これらのログには、誰が、いつ、どのようなアクションが実行されたかに関する詳細情報が記録されます。これは、監査可能なアクセス記録を維持するための要件を満たしています。
アクセス制御: BigQuery ではきめ細かなアクセス制御が可能で、許可された担当者のみにアクセスを制限できます。権限とユーザーロールを管理して、適切な個人のみがデータを表示できるようにすることができます。
データの可視性: 権限のある担当者は、BigQuery を介してデータのクエリと表示を行い、制御と監査可能性を維持しながら分析にアクセスできるようにします。
正しくないオプション -
オプション A(ユーザー指定の暗号鍵を使用して Cloud Storage 上のデータを暗号化する)は、データを保護するための優れた方法ですが、BigQuery のデータアクセスログと同じレベルの組み込み監査機能は提供されません。
オプション C(個別のデータベース ユーザー名で Cloud SQL にデータを保存する)は、データを保護するための有効なアプローチですが、監査可能性は主に Cloud SQL 管理者のアクティビティ ログに基づいているため、BigQuery のデータアクセスログと同じレベルの詳細と粒度が得られない可能性があります。
オプション D(AppEngine サービスからのみアクセス可能な Cloud Storage 上のバケットにデータを保存する)には、実装と管理が複雑になる可能性があるカスタム ソリューションが含まれます。データ分析と監査追跡用に設計された BigQuery と同じレベルの監査可能性とアクセス制御は提供されない場合があります。
</div></details>

### Q. 質問20: 未回答
ニューラルネットワークモデルのトレーニングに数日かかっています。トレーニング速度を上げたい。その他のオプション
1. 
2. トレーニングデータセットをサブサンプリングします。
3. 
4. 
<details><div>
    答え：2
説明
B. 
説明: トレーニングデータセットのサブサンプリングでは、ニューラルネットワークのトレーニングに、より小さく代表的なデータのサブセットを使用します。このアプローチが効果的な理由はいくつかあります。
計算の高速化: トレーニング データセットが小さいほど、各トレーニング イテレーションで必要な計算とメモリが少なくなり、トレーニング時間が短縮されます。
ノイズの低減: サブサンプリングは、トレーニング データのノイズと分散を減らすのに役立ち、収束の高速化と汎化の向上につながる可能性があります。
仮説の検証: 機械学習では、多くの場合、さまざまなモデル アーキテクチャとハイパーパラメーターを試す必要があります。最初の実験に小さなデータセットを使用すると、モデルの可能性を検証しながら時間を節約できます。
正しくないオプション -
A. テストデータセットをサブサンプリングします。
説明: テスト データセットのサブサンプリングは、トレーニング速度を上げるための一般的な方法ではありません。テスト データセットは、トレーニング後のモデルのパフォーマンスを評価するために使用されます。テストデータセットのサイズを変更すると、評価結果に影響を与える可能性があり、トレーニングプロセスは高速化されません。モデルの汎化パフォーマンスを正確に評価するには、代表的なテスト データセットを維持することが不可欠です。
C. モデルへの入力特徴の数を増やします。
説明: 通常、入力特徴の数を増やすと、モデルが複雑になり、その結果、トレーニング時間が長くなります。機能を追加すると、モデルの次元が増加する可能性があり、トレーニングにより多くの計算リソースと時間が必要になる場合があります。このオプションは、トレーニングを高速化するよりも遅くする可能性が高くなります。
D. ニューラルネットワークの層数を増やします。
説明: ニューラルネットワークに層を追加すると、ニューラルネットワークが深くなり、複雑になる可能性があります。ディープ ネットワークはデータの複雑なパターンをキャプチャできますが、特に多くのパラメーターが含まれている場合は、トレーニングに時間がかかることがよくあります。レイヤー数を増やすことは、トレーニングを高速化するための推奨される戦略ではありません。これにより、トレーニング時間が長くなり、追加の計算リソースが必要になる場合があります。
</div></details>

### Q. 質問21: 未回答
あなたの役割は、会社がApache Hadoopクラスター内で運用するためのETLパイプラインを開発する任務を負っています。これらのパイプラインには、チェックポイント機能と分割機能の両方の実装が含まれます。これらのパイプラインを効果的に作成するには、どのようなアプローチを採用する必要がありますか?
1. Pig を使った PigLatin
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
Pig は、Hadoop エコシステムの高レベルのデータ処理フレームワークであり、PigLatin と呼ばれる言語を使用して ETL パイプラインを記述できます。PigLatin は複雑なデータ処理タスクを簡素化し、特に ETL ワークロードに適しています。
シンプルさと抽象化: PigLatin は、Java MapReduce などの低水準言語と比較して、より抽象的でユーザーフレンドリーな方法でデータ変換を表現できます。この抽象化により、ETL パイプラインの開発が迅速化され、メンテナンスが容易になります。
データフローモデル:Pigはデータフローモデルで動作するため、データ変換と依存関係を順番に表現しやすくなります。これは、ETL パイプラインでのタスクのチェックポイント設定と分割に役立ちます。
最適化: Pig は、クエリ プランを自動的に最適化するように設計されているため、ETL タスクの実行がより効率的になります。
正しくないオプション -
B. Hive を使用した HiveQL:
Hive は、主に SQL に似たクエリを使用して Hadoop に格納されているデータをクエリするために使用されます。大規模なデータセットのクエリと処理には適していますが、複雑な変換、チェックポイント処理、パイプラインの分割を伴う ETL タスクにはあまり適していません。
C. MapReduceを使用したJava:
Java MapReduceは、ETL、特に複雑なデータ処理タスクのための強力で柔軟なオプションです。ただし、PigLatin と比較して、より多くの開発作業とコードが必要です。Java MapReduceでのチェックポイント設定と分割タスクの実装は、より複雑で時間がかかる場合があります。
D. MapReduceを使用したPython:
Python は Hadoop MapReduce で使用できますが、この目的では Java ほど一般的ではありません。Python MapReduceは通常、Hadoop Streamingなどの外部ライブラリを使用する必要があるため、複雑さが増す可能性があります。Java と同様に、チェックポイント処理と分割の実装は、Python MapReduce では Pig よりも難しい場合があります。
</div></details>

### Q. 質問22: 未回答
会社では、GCP とのハイブリッド デプロイを維持しており、匿名化された顧客データに対して分析が実行されます。データは、GCP で実行されているデータ転送サーバーへの並列アップロードを通じて、データセンターから Cloud Storage にインポートされます。経営陣は、毎日の転送に時間がかかりすぎることを通知し、問題を解決するように求めました。転送速度を最大にしたい。どのアクションを実行する必要がありますか?
1. 
2. 
3. データセンターから GCP へのネットワーク帯域幅を増やします。
4. 
<details><div>
    答え：3
説明
データセンターから Google Cloud Storage への毎日のアップロードの転送速度を最大化するには、次の点を考慮する必要があります。
C. 
ネットワーク帯域幅: データセンターと Google Cloud 間のデータ転送速度は、利用可能なネットワーク帯域幅に大きく依存します。データセンターから GCP へのネットワーク帯域幅を増やすことで、Cloud Storage へのデータのアップロード速度を向上させることができます。
ボトルネック:多くの場合、データ転送が遅いのは、クラウドインフラストラクチャ内ではなく、データセンター側の帯域幅の制限が原因です。データセンターの帯域幅を増やすことで、このボトルネックを軽減できます。
正しくないオプション -
オプション A と B(CPU サイズまたはサーバー上の Google Persistent Disk のサイズを増やす)は、主にサーバーの処理能力とストレージ能力に影響します。これらのアップグレードは、サーバーがボトルネックになっている場合は役立つ可能性がありますが、ネットワーク帯域幅が主な制限要因である場合、データ転送速度を大幅に向上させることはできません。
オプション D(Compute Engine から Cloud Storage へのネットワーク帯域幅の増加)は、Google Cloud インフラストラクチャ自体でボトルネックが発生した場合に役立ちます。ただし、この質問はデータセンターからの毎日のアップロードを改善することに焦点を当てているため、最も効果的なアクションは、データセンターからGCPへのネットワーク帯域幅に対処することです(オプションC)。
</div></details>

### Q. 質問23: 未回答
BigQuery で実行するために ETL ジョブを移行した後は、移行したジョブの出力が元のジョブの出力と一致するようにする必要があります。元のジョブの出力を保持するテーブルを正常にロードしたので、その内容を移行されたジョブからの出力と比較して、それらの性質が同一であることを示す必要があります。残念ながら、テーブルには、比較のための直接結合を容易にする主キー列がありません。この状況では、どのような手順を踏む必要がありますか?
1. 
2. 
3. Dataproc クラスタと BigQuery Hadoop コネクタを使用して、各テーブルからデータを読み取り、並べ替え後にテーブルのタイムスタンプ以外の列からハッシュを計算します。各テーブルのハッシュを比較します。
4. 
<details><div>
    答え：3
説明
直接結合用の主キー列がない場合に BigQuery で 2 つのテーブルの内容を比較するには、次の点を考慮する必要があります。
C. 
Dataproc Cluster: Dataproc は、Google Cloud のマネージド Apache Spark および Hadoop サービスです。Dataproc を使用してクラスタを作成すると、大規模なデータセットを効率的に処理、比較するための分散コンピューティング機能が提供されます。
BigQuery Hadoop コネクタ: BigQuery Hadoop コネクタを使用すると、BigQuery テーブルから Dataproc クラスタにデータを直接読み取ることができるため、分散処理環境で BigQuery データを簡単に操作できます。
ハッシュ比較: 並べ替え後に各テーブルのタイムスタンプ以外の列からハッシュを計算することで、各行に一意の識別子を作成できます。次に、これらのハッシュを 2 つのテーブル間で比較して、同じ行を確認できます。
正しくないオプション -
オプションA(RAND()関数を使用してランダムサンプルを選択)およびオプションB(HASH()関数を使用してランダムサンプルを選択)は、データセット全体の包括的な比較を保証しない場合があります。これらのオプションはランダム サンプリングに依存しており、大規模なデータセットで不一致を検出する可能性は限られている可能性があります。
オプションD(OVER()関数を使用して層化ランダムサンプルを作成する)は、より高度でデータのサンプリングに適していますが、データセット全体の完全な比較を保証するものではありません。
</div></details>

### Q. 質問24: 未回答
あなたは、それぞれ異なる優先順位と予算を持つ複数の事業部門を持つ大企業のBI責任者です。オンデマンドを使用する BigQuery の料金(プロジェクトあたり 2K の同時オンデマンド スロットの割り当てあり)。組織のユーザーは、クエリを実行するためのスロットを取得しない場合があり、これを修正する必要があります。アカウントに新しいプロジェクトを導入しないようにしたい。あなたは何をするべきか?
1. 
2. 
3. 定額価格に切り替え、プロジェクトの階層的な優先順位モデルを確立します。
4. 
<details><div>
    答え：3
説明
プロジェクトごとに 2K のオンデマンド同時スロットの割り当てがあり、新しいプロジェクトの導入を避けたい場合に、ユーザーが BigQuery でクエリを実行するスロットを取得できないという問題に対処するには、次の点を考慮する必要があります。
C. 
定額料金: BigQuery で定額料金に切り替えると、割り当て制限のあるオンデマンド スロットに頼るのではなく、組織専用の固定数のスロットを購入できます。これにより、より予測可能で一貫性のあるクエリパフォーマンスが実現します。
階層型優先度モデル: 定額価格設定では、プロジェクトの階層型優先度モデルを確立できます。組織内の各部署またはプロジェクトに、優先順位と予算に基づいて特定の数のスロットを割り当てることができます。これにより、重要な事業部門は、リソース割り当ての制御を維持しながら、必要なリソースを確実に取得できます。
正しくないオプション -
オプション A (バッチ クエリを対話型クエリに変換する) は、クエリの実行を最適化することである程度役立つ場合がありますが、根本的なリソース割り当ての問題には対処しません。
オプション B (追加のプロジェクトの作成) は複雑さを増すため、既存のプロジェクト内でリソース割り当てを効果的に管理できる場合、最も効率的なソリューションではない可能性があります。
オプション D([割り当て] ページでプロジェクトごとの同時スロット数を増やす)は、Google Cloud の割り当てポリシーの対象となるため実現できない可能性があり、定額料金と階層的な優先度モデルが提供するレベルのリソース管理と制御が提供されない可能性があります。
</div></details>

### Q. 質問25: 未回答
Web アプリケーションログを含むトピックをホストするオンプレミスの Apache Kafka クラスターを運用しています。目的は、このデータを Google Cloud に複製して、BigQuery と Cloud Storage で分析することです。ミラーリングの推奨レプリケーション方法に従い、Kafka Connect プラグインのデプロイを回避しながらこれを実現するには、どのような手順を実行する必要がありますか?
1. GCE VM インスタンスに Kafka クラスタをデプロイします。GCE で実行されているクラスターにトピックをミラーリングするようにオンプレミス クラスターを構成します。Dataproc クラスタまたは Dataflow ジョブを使用して、Kafka からの読み取りと GCS への書き込みを行います。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
GCE VM 上の Kafka クラスタ: Google Compute Engine(GCE)VM インスタンスに Kafka クラスタをデプロイすると、オンプレミスの Kafka クラスタからミラーリングされたデータを直接受信できる Google Cloud でホストされる Kafka クラスタを使用できます。
Google Cloud へのミラーリング: GCE でホストされる Kafka クラスタにトピックをミラーリングするようにオンプレミスの Kafka クラスタを構成することで、追加のコネクタを必要とせずに、オンプレミスからクラウドへのデータ レプリケーションを実現できます。
Dataproc または Dataflow: Google Cloud サービスである Dataproc または Dataflow を使用して、GCE でホストされる Kafka クラスタからデータを読み取り、Google Cloud Storage(GCS)に書き込むことができます。このアプローチにより、Google Cloud 環境内でのデータの一貫性と統合が確保されます。
正しくないオプション -
B. Kafka Kafka コネクタをシンクコネクタとして設定した状態で、GCE VM インスタンスに Kafka クラスタをデプロイします。Dataproc クラスタまたは Dataflow ジョブを使用して Kafka から読み取り、GCS に書き込みます。
このオプションでは、中間ステップとして Pub/Sub Kafka コネクタが導入されます。これは有効なアプローチですが、追加のサービス(Pub/Sub)と構成手順が必要になるため、複雑さが増します。
C. Pub/Sub Kafka コネクタをオンプレミスの Kafka クラスターにデプロイし、Pub/Sub をソースコネクタとして構成します。Dataflow ジョブを使用して Pub/Sub から読み取り、GCS に書き込みます。
このオプションでは、オンプレミスの Kafka クラスターに直接コネクターをデプロイして構成します。実現可能ですが、Google Cloud に Kafka クラスタをデプロイしてミラーリングを構成するほど簡単ではないかもしれません。
D. Pub/Sub Kafka コネクタをオンプレミスの Kafka クラスターにデプロイし、Pub/Sub をシンク コネクタとして構成します。Dataflow ジョブを使用して Pub/Sub から読み取り、GCS に書き込みます。
オプション C と同様に、このアプローチでは、オンプレミス クラスターにコネクタをデプロイし、Pub/Sub をシンクとして構成することで複雑さが生じます。これは、Google Cloud でホストされている Kafka クラスタのデプロイほど合理的ではない可能性があります。
</div></details>

### Q. 質問26: 未回答
Hadoop ジョブをオンプレミス クラスタから dataproc と GCS に移行しました。Spark ジョブは、多くのシャッフル操作で構成される複雑な分析ワークロードであり、初期データは Parquet ファイル (それぞれ平均 200 から 400 MB のサイズ) です。Dataproc への移行後にパフォーマンスが低下したため、最適化する必要があります。組織はコストに敏感な組織であるため、このワークロードではプリエンプティブル(2 つの非プリエンプティブル ワーカーのみ)で Dataproc を引き続き使用する必要があります。あなたは何をするべきか?
1. 
2. 
3. 
4. HDD から SSD に切り替え、プリエンプティブル VM 構成をオーバーライドして、ブート ディスク サイズを増やします。
<details><div>
    答え：4
説明
D. 
SSD への切り替え: HDD を SSD に交換すると、I/O パフォーマンスが大幅に向上します。SSD は HDD と比較して読み取りと書き込みの速度が速いため、シャッフル操作やデータ集約型のワークロードを伴う Spark ジョブに役立ちます。
ブート ディスク サイズの増加: プリエンプティブル VM のブート ディスク サイズを増やすことで、オペレーティング システムと Spark によって生成される一時データの両方により多くのストレージ容量を提供します。これにより、潜在的なストレージのボトルネックを回避し、Sparkジョブに十分な一時ストレージを確保できます。
正しくないオプション -
A. Parquet ファイルのサイズを増やして、最小 1 GB になるようにします。
Parquet ファイルのサイズを大きくしても、HDD の使用によって引き起こされる I/O パフォーマンスの問題に直接対処できない場合があります。 ファイル サイズが大きくなると、HDD の読み取り/書き込み速度の低下に関連するパフォーマンスの低下を完全に軽減できない場合があります。
B. Parquet ファイルではなく、TFRecords 形式 (ファイルあたり約 200 MB) に切り替えます。
ファイル形式を変更すると、ストレージのオーバーヘッドを削減できる場合がありますが、基になる HDD 関連の I/O パフォーマンスの問題に直接対処するわけではありません。
C. HDD から SSD に切り替え、GCS から HDFS に初期データをコピーし、Spark ジョブを実行して、結果を GCS にコピーします。
SSDに切り替えてHDFSを使用すると、ストレージとデータの局所性に役立ちますが、コスト削減のために引き続き使用したいとおっしゃった既存のプリエンプティブルVMは活用されません。
</div></details>

### Q. 質問27: 未回答
社内で ETL の開発とメンテナンスを担当するチームとして、入力データのエラーが原因で Dataflow ジョブの 1 つが失敗する状況に遭遇しました。失敗したすべてのデータを再処理する機能など、パイプラインの信頼性を高めるには、どのような手順を実行する必要がありますか?
1. 
2. 
3. 
4. try...catch ブロックをデータを変換する DoFn に追加し、sideOutput を使用して、後で Pub/Sub に保存できる PCollection を作成します。
<details><div>
    答え：4
説明
Dataflow パイプラインの信頼性(失敗したすべてのデータを再処理する機能など)を向上させるには、次の点を考慮する必要があります。
D. 
try...catch ブロック:トライを追加しています...DoFn 内の catch ブロックを使用すると、データ変換中のエラーを適切に処理できます。エラーが発生した場合は、それをキャッチして特定のアクションを実行できます。
サイド出力: Dataflow で sideOutput を使用すると、別の PCollection を作成して、エラーのあるデータ レコードをキャプチャできます。エラーが発生した場合は、問題のあるレコードをこちら側の出力に出力して、メインのデータ処理フローを中断しないようにすることができます。
Pub/Sub への保存: エラーのあるレコードを PCollection に保存し、後で Pub/Sub に送信できるようにすることで、データを再処理することができます。Pub/Sub は、再処理や詳細な分析が必要なデータの信頼性の高いメッセージ ブローカーとして機能します。
正しくないオプション -
オプション A (エラーをスキップするフィルター処理ステップの追加) は、エラーによるパイプラインの中断を防ぐ可能性がありますが、信頼性とトラブルシューティングに不可欠な潜在的な再処理のためにエラーのあるデータをキャプチャして保存することはありません。
オプション B (try...catch ブロックを side 出力なしで使用) を使用すると、エラーを処理できますが、エラーのあるデータを格納して再処理するメカニズムは提供されません。データが失われる可能性があります。
オプション C(DoFn から Pub/Sub に誤った行を直接書き込む)は機能しますが、DoFn ロジックが複雑になる可能性があり、サイド出力を使用するほど単純ではない可能性があります。
</div></details>

### Q. 質問28: 未回答
不動産物件を含む利用可能なデータセットに基づいて住宅価格を予測するモデルをトレーニングしています。計画では、完全に接続されたニューラル ネットワークをトレーニングし、データセットにプロパティの緯度と経度が含まれていることを発見しました。不動産の専門家は、物件の立地が価格に大きく影響すると聞いているため、この物理的な依存性を組み込んだ機能を設計したいと考えています。あなたは何をするべきか?
1. 
2. 
3. 緯度と経度のフィーチャクロスを作成し、分単位でバケット化し、最適化中に L1 正則化を使用します。
4. 
<details><div>
    答え：3
説明
C. 
特徴交差: 緯度と経度の間に特徴交差 (相互作用) を作成すると、モデルはこれらの地理的特徴の複合的な影響をキャプチャでき、住宅価格の予測に重要になる可能性があります。
バケット化: 分レベルでフィーチャクロスをバケット化することは、位置情報を特定の範囲に離散化することを意味します。これにより、モデルは住宅価格と場所パターンの関係をより細かい粒度で学習できます。
L1 正則化: L1 正則化 (なげなわ正則化) は、モデル係数の絶対値にペナルティを課すことで、モデルのスパース性を促進する手法です。これは、多くの特徴があり、特徴選択を実行する場合に便利です。このコンテキストでは、住宅価格の予測に最も関連する分単位のロケーションの相互作用をモデルが特定するのに役立ちます。
正しくないオプション -
A. 緯度と経度をニューラル ネットワークへの入力ベクトルとして指定します。
この方法では、緯度と経度が別々の入力フィーチャとして扱われるため、それらの間の相互作用を効果的に取得できない可能性があります。地理フィーチャを離散化または正規化する方法は提供されません。
B. 緯度と経度の特徴の十字から数値列を作成します。
特徴クロスから数値列を作成することは有効な手法ですが、分レベルのバケット化または正則化の特定の要件には対応していません。きめ細かな位置パターンをキャプチャできない場合があります。
D. 緯度と経度の特徴クロスを作成し、分単位でバケット化し、最適化中に L2 正則化を使用します。
L2 正則化 (リッジ正則化) の使用は、モデル係数の 2 乗にペナルティを課す手法であり、過学習を防ぎ、外れ値の影響を軽減します。L1 正則化は有用ですが、特徴の選択や関連する分単位の位置操作の特定には、L<> 正則化ほど効果的ではない可能性があります。
</div></details>

### Q. 質問29: 未回答
MariaDB SQL データベースを GCE VM インスタンスにデプロイ中であり、監視とアラートの設定が必要です。目標は、最小限の開発作業でネットワーク接続、ディスク IO、レプリケーション ステータスなどの指標を MariaDB から収集し、StackDriver を利用してダッシュボードとアラートを作成することです。この構成をどのように実現できますか?
1. 
2. 
3. 
4. StackDriver Agent をインストールし、MySQL プラグインを設定します。
<details><div>
    答え：4
説明
最小限の開発労力で MariaDB から指標を収集し、ダッシュボードとアラートに StackDriver を使用するには、次の点を考慮する必要があります。
D. 
StackDriver エージェント: StackDriver Agent は、最小限の労力で VM インスタンスからシステムとアプリケーションの指標を収集するように設計されています。これにより、指標を収集して StackDriver にエクスポートするプロセスが簡素化されます。
MySQLプラグイン:StackDriver Agentには、MariaDBなどのMySQL互換データベースからデータベース関連の指標を収集するために特別に設計されたMySQLプラグインが含まれています。このプラグインは、ネットワーク接続、ディスク I/O、レプリケーション ステータスなどの重要なメトリックをキャプチャできます。
正しくないオプション -
オプション A(OpenCensus Agent をインストールし、カスタム指標収集アプリケーションを作成する)では、MariaDB 指標を収集して StackDriver にエクスポートするために、より多くの開発作業とカスタム コーディングが必要になります。これは、StackDriver エージェントが提供する組み込みの MySQL プラグインを使用する場合と比較して、より複雑なソリューションです。
オプション B(ヘルスチェックを使用して MariaDB インスタンスをインスタンス グループに配置する)は、主にインスタンスの可用性に対応しますが、データベース固有の指標を直接収集して StackDriver にエクスポートすることはありません。
オプション C(StackDriver Logging Agent をインストールし、MariaDB ログを読み取るための fluentd in_tail プラグインの構成)は、ログの収集に重点を置いており、データベースから詳細なパフォーマンスと正常性の指標を収集するのには適していません。
</div></details>

### Q. 質問30: 未回答
あなたは銀行に勤めるデータサイエンティストです。既に承認されているローン申請のデータセットと、借り手がローンの債務不履行に陥ったかどうかに関する情報が与えられています。ここでのタスクは、新規ローン申請者の債務不履行の可能性を予測できるモデルをトレーニングすることです。
1. 
2. 線形回帰をトレーニングしてクレジット デフォルト リスク スコアを予測する
3. 
4. 
<details><div>
    答え：2
説明
手法の適切性: 線形回帰は、入力特徴量の組み合わせに基づいて数値ターゲット変数 (この場合はクレジット デフォルト リスク スコア) を予測するのに適した手法です。信用リスク評価のコンテキストでは、回帰モデルを使用して、債務不履行の確率または信用リスク スコアを推定するのが一般的です。
正しくないオプション -
A. 追加のデータを収集して、データセットのサイズを増やします。
データセットのサイズを大きくするとモデルのパフォーマンスが向上する場合がありますが、この場合は必要ない場合があります。データセットには、承認済みのローン申請がすでに含まれており、目標はデフォルトを予測することです。承認済みの申請をより多く集めることは、却下されたローン申請を収集したり、機能の選択やエンジニアリングに集中したりすることほど役に立たない場合があります。
C. データからバイアスを取り除き、ローンを拒否されたアプリケーションを収集します。
データの偏りに対処し、却下されたローン申請を収集することは、より代表的なデータセットを作成するために重要です。ただし、この手順だけでは、モデリングのアプローチは定義されません。これは、データセットの品質と公平性を向上させるためのデータの前処理手順であり、モデリング戦略自体ではありません。
D. ローン申請者をソーシャル プロファイルと照合して、特徴エンジニアリングを有効にします。
ローン申請者とソーシャル プロファイルのリンクは、追加機能の潜在的なソースになる可能性がありますが、これは最初のモデリング戦略ではなく、特徴エンジニアリングの手順です。特徴量エンジニアリングは、モデリング手法を選択する前ではなく、選択した後に実行する必要があります。
オプションBは、クレジット・デフォルト・リスクを予測するモデルをトレーニングするタスクに直接対処するため、正しい選択です。オプション A、C、D は、データ準備と特徴エンジニアリング プロセスにおける重要なステップですが、モデリング アプローチはオプション B ほど明確に定義されていません。
</div></details>

### Q. 質問31: 未回答
2 TB のリレーショナル データベースを Google Cloud Platform に移行するという課題があり、アプリケーションのリファクタリングに制限があり、費用対効果に重点が置かれています。このシナリオでは、データの保存と提供にどの Google Cloud サービスを選択すればよいですか?
1. 
2. 
3. 
4. Cloud SQL
<details><div>
    答え：4
説明
2 TB のリレーショナル データベースを Google Cloud Platform に移行する要件を考えると、コストを主な懸念事項とし、アプリケーションの大幅なリファクタリングを行わずに、次のオプションを検討する必要があります。
D. クラウド SQL
リレーショナル データベースの互換性: Cloud SQL は、MySQL、PostgreSQL、SQL Server などの一般的なデータベース エンジンと互換性のあるマネージド リレーショナル データベース サービスを提供します。既存のデータベースがリレーショナルの場合、Cloud SQL はアプリケーション コードへの変更を最小限に抑えた簡単な移行パスを提供します。
費用対効果: Cloud SQL にはさまざまな料金階層と柔軟なスケーリング オプションが用意されているため、ワークロードと予算に適した構成を選択できます。ニーズに合わせて適切なマシンタイプとストレージ容量を選択できるため、コストを管理できます。
正しくないオプション -
オプション A、B、および C は、2 TB のリレーショナル データベースの単純な移行には適していない場合があります。
A. Cloud Spanner: Cloud Spanner は拡張性が高く、グローバルに分散されたデータベース サービスですが、トランザクション ワークロードの高可用性とスケーラビリティを実現するように設計されています。2TBのリレーショナルデータベースは、通常、ミッションクリティカルなグローバルに分散されたアプリケーションに使用されるため、コストが主な懸念事項である場合、やり過ぎになる可能性があります。
B. Cloud Bigtable: Cloud Bigtable は、通常、分析データや時系列データに使用される大規模な NoSQL データを保存および提供するために設計されています。これはリレーショナルデータベースではないため、従来の2TBリレーショナルデータベースの移行には適していない可能性があります。
C. Cloud Firestore: Cloud Firestore は、主にモバイルおよびウェブ アプリケーション向けに設計された NoSQL ドキュメント データベースです。通常、従来のリレーショナル データベースの移行には使用されず、大幅なアプリケーション リファクタリングが必要になる場合があります。
</div></details>

### Q. 質問32: 未回答
リアルタイム アプリケーションに Bigtable を使用しており、読み取りと書き込みが混在する負荷が高い。最近、追加のユース ケースを特定し、データベース全体の特定の統計を計算するために分析ジョブを時間単位で実行する必要があります。本番アプリケーションの信頼性と分析ワークロードの両方を確保する必要があります。あなたは何をするべきか?
1. 
2. 
3. 単一クラスタ ルーティングで 2 番目のクラスタを追加する
4. 
<details><div>
    答え：3
説明
オプション C: 
このオプションでは、分析ワークロードを処理するために、Bigtable インスタンスに別のクラスタを追加します。この分離により、運用アプリケーションのリアルタイム トラフィックと分析ジョブが異なるクラスターで実行されることが保証され、分離レベルが提供されます。
単一クラスター ルーティングを使用すると、アプリ プロファイル (運用環境の場合はライブ トラフィック、分析の場合はバッチ分析) に基づいて、どのクラスターがどのタイプのトラフィックを処理するかを指定できます。このアプローチにより、トラフィック ルーティングを効果的に管理できます。
主な利点は、ワークロードを同じインスタンス内に保持しながら、ワークロードをある程度分離できるため、費用対効果と運用効率が高いことです。
正しくないオプション -
オプション A(Bigtable ダンプを GCS にエクスポート):Bigtable データを Google Cloud Storage(GCS)にエクスポートし、エクスポートしたファイルに対して分析を実行するのはバッチ指向のアプローチであり、リアルタイム分析や本番アプリケーションとのシームレスな統合はできません。また、分析プロセスの複雑さと遅延も増します。
オプション B(マルチクラスタ ルーティング):マルチクラスター ルーティングはワークロードの分離に適していますが、このオプションでは、運用環境にライブ トラフィック アプリ プロファイルを使用し、分析にバッチ分析プロファイルを使用することをお勧めします。ただし、ライブ トラフィック プロファイルはリアルタイム トラフィック用に設計されており、分析に使用すると、運用アプリケーションの信頼性に影響を与える可能性があります。
オプション D (既存のクラスターのサイズを 2 回増やす):既存のクラスターのサイズを増やすと、スケーリングに役立つ場合がありますが、リアルタイムのワークロードと分析のワークロードを明確に分離することはできません。このオプションは、リソースの競合につながる可能性があり、信頼性の問題に効果的に対処できない可能性があります。
</div></details>

### Q. 質問33: 未回答
Apache Beam パイプラインを設計して Cloud Pub/Sub データを BigQuery の静的な参照データで強化し、参照データを 1 人のワーカーのメモリに格納し、分析のためにエンリッチメントされた結果を BigQuery に書き込むことを目標とする場合、このパイプラインではどのジョブタイプと変換を使用する必要がありますか?
1. 
2. 
3. ストリーミング ジョブ、PubSubIO、BigQueryIO、サイドインプット
4. 
<details><div>
    答え：3
説明
オプション C: 
このオプションには、次のコンポーネントが含まれます。
ストリーミングジョブ:データは Cloud Pub/Sub から送信されるため、リアルタイム データを処理するにはストリーミング ジョブが適切な選択肢です。
PubSubIO の場合:PubSubIO は、ストリーミング コンテキストで Cloud Pub/Sub からデータを読み取って処理するために使用され、データのリアルタイム性に合わせて調整されます。
BigQueryIO に追加します。BigQueryIO は、BigQuery からの参照データの読み取りと、エンリッチメントされた結果を BigQuery に書き戻すために使用できます。これは、分析のためにエンリッチメント プロセスを BigQuery とシームレスに統合する場合に便利です。
サイド入力:サイドインプットを使用すると、BigQuery の静的な参照データでストリーミング データを強化できます。これは、リアルタイム データの処理中に静的データセットから情報を検索する必要がある場合に特に役立ちます。
オプションCが正しい理由:
オプション C では、ストリーミング データの取り込みに PubSubIO、BigQuery へのデータの読み取りと書き込みに BigQueryIO、BigQuery からの静的参照データでストリーミング データをエンリッチメントするためのサイドインプットの長所を活用します。これは、シナリオの要件とよく一致しています。
データフローのユースケースパターン:- https://cloud.google.com/blog/products/gcp/guide-to-common-cloud-dataflow-use-case-patterns-part-1
正しくないオプション -
オプション A (バッチ ジョブ、PubSubIO、サイド入力):
このオプションでは、Cloud Pub/Sub からのリアルタイム データの処理には適さないバッチ ジョブの使用が推奨されます。
エンリッチメントのためのサイドインプットについて言及していますが、バッチ処理はリアルタイムデータには適していません。
オプション B (ストリーミング ジョブ、PubSubIO、JdbcIO、サイド出力):
BigQuery データの統合には BigQueryIO の方が自然にフィットするため、JdbcIO を使用して BigQuery からのデータをエンリッチすることは最適な選択ではない可能性があります。
サイドアウトプットは、1 つの処理ステップから複数のアウトプットを生成するために使用されますが、この特定のエンリッチメント シナリオでは必要ありません。
オプション D: ストリーミング ジョブ、PubSubIO、BigQueryIO、サイド出力
オプション D にはいくつかの関連コンポーネントが含まれていますが、次の理由により、このシナリオには最適な選択肢ではありません。
サイド出力:サイドアウトプットは、通常、Apache Beam パイプラインで 1 つの処理ステップから複数のアウトプットを生成するために使用されます。これらは、パイプライン内でデータを複数のストリームまたはカテゴリに分割する必要があるシナリオで役立ちます。このシナリオでは、BigQuery からメインのデータストリームにデータを追加する簡単なエンリッチメント タスクがあります。サイドアウトプットは、このユースケースに不必要な複雑さをもたらします。
BigQuery によるエンリッチメント:このパイプラインの主な目的は、Cloud Pub/Sub からのストリーミング データを BigQuery の静的参照データで強化することです。BigQueryIO は BigQuery からの読み取りと書き込みの両方を処理できますが、このエンリッチメントを実現するためにサイドアウトプットは必要ありません。より簡単なアプローチは、メインのデータ処理フロー内で読み取りと書き込みの両方に BigQueryIO を使用することです。
可読性と複雑さ:比較的単純なデータエンリッチメントタスクにサイドアウトプットを導入すると、パイプラインが必要以上に複雑になる可能性があります。一般に、パイプラインをできるだけシンプルで読みやすい状態に保つことをお勧めします (特に、サイドアウトプットなしでタスクを実行できる場合)。
</div></details>

### Q. 質問34: 未回答
適切に設計された行キーを使用して Cloud Bigtable にデータを書き込むデータ パイプラインがあります。パイプラインをモニタリングして、Cloud Bigtable クラスタのサイズをいつ増やすかを判断します。これを達成するために、どのような 2 つのアクションを実行できますか?(2つ選択してください。
1. 
2. 
3. 書き込み操作の待機時間を監視します。書き込みレイテンシが持続的に増加する場合は、Cloud Bigtable クラスタのサイズを増やします。
4. ストレージ使用率を監視します。使用率が最大容量の 70% を超えたら、Cloud Bigtable クラスタのサイズを増やします。
5. 
<details><div>
    答え：3,4
説明
C. 
このオプションは確かに正しいです。書き込み操作のレイテンシは、書き込みワークロードを処理する際の Cloud Bigtable クラスタのパフォーマンスを直接反映するため、非常に重要です。書き込みレイテンシーは、時間の経過に伴う書き込みレイテンシーの増加は、クラスターが受信書き込みの効率的な処理に苦労している可能性があることを示唆しているため、監視すべき重要なメトリックです。書き込みレイテンシが持続的に増加している場合は、増大する書き込み負荷をより効果的に処理するために Cloud Bigtable クラスタをスケールアップする必要があることを示しています。
D. 
このオプションも正しいです。ストレージ使用率のモニタリングは、Cloud Bigtable インスタンスを効果的に管理するために不可欠です。ストレージ使用率が最大容量の 70% に近づくか、それを超えると、インスタンスの領域が不足していることを示します。通常はノードを追加して Cloud Bigtable クラスタのサイズを増やすと、データ量の増加に対応し、ストレージの制限によるパフォーマンスの低下を防ぐことができます。
正しくないオプション -
A. キー ビジュアライザーのメトリックを確認します。Cloud Bigtable クラスタのサイズを増やすには、読み取りプレッシャー インデックスが 100 を超えます。
Key Visualizer の読み取り圧力インデックスは、書き込みワークロードではなく、読み取りワークロードに関連しています。読み取りプレッシャーの監視は、読み取りパフォーマンスを最適化するために不可欠ですが、書き込み負荷の高いワークロードのクラスター サイズをいつ増やすかを決定することには直接関係ありません。
B. キービジュアライザーの指標を確認します。Cloud Bigtable クラスタのサイズを増やすには、書き込みプレッシャー インデックスが 100 を超えます。
書き込みプレッシャー インデックスは書き込みワークロードに関連していますが、クラスター サイズの調整を決定するために使用される一般的なメトリックではありません。書き込みレイテンシーとストレージ使用率は、書き込みワークロードに応じてスケーリングを決定するための、より一般的で実用的なメトリックです。
E. 読み取り操作の待機時間を監視します。読み取り操作に 100 ミリ秒以上かかる場合は、Cloud Bigtable クラスタのサイズを増やします。
読み取り待機時間の監視は、応答性の高いクエリのパフォーマンスを確保するために不可欠ですが、書き込みワークロードの問題や、書き込み要求に応じてクラスター サイズを増やすタイミングに関する直接的な分析情報は提供されません。
</div></details>

### Q. 質問35: 未回答
次の要件を効率的かつ費用対効果の高い方法で満たすにはどうすればよいでしょうか。
- 毎日何十万ものソーシャルメディア投稿を分析します。
- Cloud Natural Language API を使用して投稿を毎日一括読み込みします。
- 投稿からトピックとセンチメントを抽出します。
- 履歴のために生の投稿をアーカイブします。
- 社内外の関係者向けに共有可能なダッシュボードを作成する。
- APIから抽出されたデータと、分析とアーカイブの目的で生のソーシャルメディア投稿の両方を確実に保存しますか?
1. 
2. 
3. 生のソーシャル メディア投稿を Cloud Storage に保存し、API から抽出したデータを BigQuery に書き込みます。
4. 
<details><div>
    答え：3
説明
ソーシャルメディアの投稿を毎日分析し、アーカイブと再処理のために生の投稿と抽出されたデータの両方を保存するという要件を満たすには、オプションCを選択する必要があります。
C. 
費用対効果の高いストレージ:生のソーシャル メディアの投稿を Cloud Storage に保存することは、費用対効果の高いソリューションです。Cloud Storage は、大量のデータに対してスケーラブルでコスト効率の高いストレージを提供し、アーカイブ目的に最適です。
データ抽出:Cloud Natural Language API を使用して、ソーシャル メディアの投稿からトピックやセンチメントを抽出できます。このデータを抽出したら、分析とレポート作成のために BigQuery に書き込むことができます。
ヒストリカルアーカイブ:生のソーシャル メディア投稿を Cloud Storage に保存すると、元のデータの履歴アーカイブを保持できます。これは、いつでも元のコンテンツを参照できるため、再処理や監査の目的で重要です。
Analytics との統合:抽出したデータを BigQuery に書き込むことで、分析の実行、ダッシュボードの作成、組織内外のユーザーとの分析情報の共有を簡単に行うことができます。BigQuery は、構造化データの保存と分析に適しています。
正しくないオプション -
オプション A(未加工の投稿と抽出したデータの両方を BigQuery に保存する)は、生のソーシャル メディア投稿を保存するのにコストがかかる可能性があり、最も費用対効果の高いソリューションではない可能性があります。
オプション B(Cloud SQL へのデータの保存)は、ソーシャル メディアの投稿などの大量の非構造化データを保存する場合に最適な選択肢ではありません。Cloud SQL は、構造化されたリレーショナル データに適しています。
オプションDは、技術的には実現可能ですが、ソースからソーシャルメディアの投稿をAPIに直接フィードする必要があるため、最も効率的なアプローチではない可能性があります。これにより、ソース データの可用性に対する複雑さと依存関係がさらに高くなる可能性があります。未加工の投稿を Cloud Storage に保存し、1 日に 1 回バッチで処理することは、より堅牢で費用対効果の高いアプローチです。
</div></details>

### Q. 質問36: 未回答
履歴データは Cloud Storage に保存します。履歴データに対して分析を実行する必要があります。ソリューションを使用して無効なデータエントリを検出し、プログラミングや SQL の知識を必要としないデータ変換を実行したい。あなたは何をするべきか?
1. 
2. Cloud Dataprep とレシピを使用して、エラーを検出し、変換を実行します。
3. 
4. 
<details><div>
    答え：2
説明
プログラミングや SQL の知識を必要とせずに、Cloud Storage に保存された履歴データに対してエラーを検出し、データ変換を実行するには、次のオプションが最適です。
B. 
このオプションが最良の選択である理由は次のとおりです。
ユーザーフレンドリーなインターフェース:Cloud Dataprep は、データの準備と変換のためのユーザーフレンドリーで視覚的なインターフェースを提供します。データクリーニングと変換のレシピは、コードやSQL問合せを記述せずに作成できます。これにより、さまざまなレベルの技術的専門知識を持つユーザーがアクセスできるようになります。
データ品質チェック:Cloud Dataprep には、欠損値、外れ値、データ形式のエラーなどのデータ品質の問題を検出する機能が含まれています。ルールと変換を視覚的に定義して、データをクリーンアップおよび修正できます。
拡張性:Cloud Dataprep は大規模なデータセットを処理できるため、Cloud Storage に保存されている履歴データの分析に適しています。
統合：Cloud Dataprep は他の Google Cloud サービスとシームレスに統合されるため、Cloud Storage からデータを取り込み、変換を実行してから、クリーニングしたデータを BigQuery やその他の分析ツールに読み込むことができます。
正しくないオプション -
オプション A(Cloud Dataflow と Beam)とオプション C(Cloud Dataproc と Hadoop ジョブ)は、よりプログラム的なソリューションであり、コーディングとデータ処理フレームワークの知識が必要です。
オプション D(クエリを使用した BigQuery のフェデレーション テーブル)では、SQL クエリを記述する必要があるため、特に SQL コードやプログラミング コードを記述したくない場合は、データのクリーニングと変換のタスクを Cloud Dataprep ほど簡単に行えない可能性があります。
</div></details>

### Q. 質問37: 未回答
会社は、履歴データを Cloud Storage に安全にアップロードする必要があります。セキュリティ・ルールでは、内部IPアドレスからオンプレミス・リソースへのアクセスのみが許可されます。最初のアップロード後、既存のオンプレミス アプリケーションから新しいデータが毎日追加されます。これを達成するための最良の方法は何ですか?
1. オンプレミス サーバーから gsutil rsync を実行します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
このオプションでは、gsutil rsync コマンドを使用して、オンプレミス サーバーから Cloud Storage にデータを同期します。これは、最初のアップロードとその後の毎日の更新の両方で機能しますが、Dataflow と同じレベルのデータ変換と処理機能を提供しない場合があります。ただし、これはデータ転送の簡単な方法であり、適切なアクセス制御と認証が実施されていれば安全です。
正しくないオプション -
オプション B: Dataflow を使用して Cloud Storage にデータを書き込む。
Dataflow は堅牢なデータ処理および変換ツールであり、特に重要なデータ変換が不要な場合は、単純なデータ転送タスク用に過剰に設計されたソリューションになる可能性があります。これは、データ転送プロセスの一部として複雑なデータ変換を実行する必要がある場合に適しています。
オプション C: Dataproc でジョブ テンプレートを作成して、データ転送を実行します。
Dataproc は、分散データ処理ジョブ(通常はバッチ処理やリアルタイム データ分析)を実行するために設計されています。単純なデータ転送タスクに Dataproc を使用すると、不必要に複雑になる可能性があります。
オプション D: Compute Engine VM に FTP サーバーをインストールしてファイルを受信し、Cloud Storage に移動します。
このオプションでは、Compute Engine VM での FTP サーバーのセットアップとメンテナンスを行います。データ転送には機能しますが、VM の管理とセキュリティ構成に関して追加のオーバーヘッドが発生します。
オプションAとオプションBのどちらを選択するかは、特定の要件によって異なります。オプション A(gsutil rsync)は、よりシンプルでわかりやすいデータ転送方法であり、オプション B(データフロー)は、データの変換と処理の柔軟性を高めます。ユースケースで基本的なデータ転送のみが必要で、セキュリティが懸念される場合は、オプションAの方が簡単な選択肢になる可能性があります。ただし、今後、より複雑なデータ処理が必要になることが予想される場合や、転送中にデータ変換を実行する必要がある場合は、オプション B (データフロー) の方が適している可能性があります。
</div></details>

### Q. 質問38: 未回答
タイムスタンプ列と ID 列の WHERE 句を使用して BigQuery テーブルをフィルタリングするクエリがあります。bq query '"-dry_run を使用すると、タイムスタンプと ID のフィルターによってデータ全体のごく一部が選択されている場合でも、クエリによってテーブルのフル スキャンがトリガーされることがわかります。既存の SQL クエリへの変更を最小限に抑えて、BigQuery でスキャンされるデータの量を減らしたい。あなたは何をするべきか?
1. 
2. 
3. パーティション列とクラスタリング列を含むテーブルを再作成します。
4. 
<details><div>
    答え：3
説明
既存の SQL クエリへの変更を最小限に抑えて BigQuery でスキャンされるデータの量を減らすには、オプション C を検討する必要があります。
C. 
このオプションが適切な選択である理由は次のとおりです。
パーティション 分割：タイムスタンプ列に基づいてテーブルをパーティション分割することで(日付またはタイムスタンプ タイプの場合)、BigQuery は関連データを含まないパーティションのスキャンをスキップできます。これにより、タイムスタンプに基づいてクエリを実行するときにスキャンされるデータの量が削減されます。
クラスタ リング：クラスタリングカラムは、クエリのパフォーマンスをさらに向上させることができます。ID 列に基づいてテーブルをクラスタリングすることで、同じ ID 値を持つデータがディスクにまとめて格納され、ID でフィルタリングするときにスキャンされるデータの量が削減されます。
最小限のクエリ変更:このオプションでは、既存の SQL クエリに対する変更が最小限で済みます。同じ SQL クエリを引き続き使用でき、BigQuery の最適化が有効になり、スキャンされるデータの量が削減されます。
正しくないオプション -
オプション A (ID ごとに個別のテーブルを作成する) では、データ構造とクエリが大幅に変更され、多くの ID 値を処理するときに管理上の課題が発生する可能性があります。
オプション B (LIMIT キーワードを使用) では、返される行数を制限できますが、スキャンされるデータの量が必ずしも減るわけではなく、コストの最適化に不可欠です。
オプション D (--maximum_bytes_billed フラグを使用) は、データ・スキャンの最適化というよりは、照会コストの制御に関するものです。不要なデータのスキャンの問題には対処していません。
</div></details>

### Q. 質問39: 未回答
50,000 個のセンサーから BigQuery テーブルに分単位のデータを挿入する必要があります。データ量の大幅な増加が予想され、集計された傾向をリアルタイムで分析するために、取り込みから 1 分以内にデータを利用できるようにする必要があります。どのような手順を踏む必要がありますか?
1. 
2. Cloud Dataflow パイプラインを使用して、BigQuery テーブルにデータをストリーミングします。
3. 
4. 
<details><div>
    答え：2
説明
50,000 個のセンサーから分単位のデータを BigQuery テーブルに挿入し、リアルタイムで分析できるようにするという要件を満たすには、オプション B を選択する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
リアルタイムのデータ取り込み:Cloud Dataflow を使用すると、リアルタイムのデータ パイプラインを構築できます。Dataflow を使用して BigQuery にデータをストリーミングすると、取り込みから数秒以内にデータを分析できるようになり、リアルタイム分析の要件を満たすことができます。
拡張性:Dataflow は、多数のセンサー(この場合は 50,000 個)からのデータの取り込みを処理でき、データ量の増加に合わせてスケーリングできます。
BigQuery との統合:Dataflow は BigQuery とシームレスに統合されているため、BigQuery テーブルにデータを簡単にストリーミングできます。
分単位のデータを挿入する:これは、データを1分に1回の頻度で記録する必要があることを意味します。
50,000個のセンサー:これは、データを生成するセンサーが多数あることを意味します。
BigQuery テーブル:これは、データの保存と分析に使用される BigQuery のデータ構造です。
データ量の大幅な増加:これは、生成されるデータの量が急速に増加すると予想されることを意味します。
1分間の摂取:つまり、データは生成後 1 分以内に BigQuery で利用できるようになる必要があります。
集計された傾向のリアルタイム分析:つまり、傾向を特定するためにデータをリアルタイムで分析する必要があります。
正しくないオプション -
オプション A (bq load を使用して 60 秒ごとにバッチを読み込む) は、バッチ処理に適しており、必要なリアルタイム機能は提供されません。
オプション C (INSERT ステートメントを使用して 60 秒ごとにバッチを挿入する) では、手動のスクリプト作成とスケジュール設定が必要であり、リアルタイム要件を効果的に満たさない可能性があります。
オプション D (MERGE ステートメントを使用して 60 秒ごとにバッチで更新を適用する) は、主に既存のデータを更新するためのものであり、リアルタイムのデータ インジェスト要件には対応していません。
</div></details>

### Q. 質問40: 未回答
あなたは、何百万もの機密性の高い患者記録をリレーショナル データベースから BigQuery にコピーする任務を負っています。データベースの合計サイズは 10 TB です。ソリューションは、安全で時間効率が良いものでなければなりません。あなたは何をするべきか?
1. 
2. データベースからレコードを Avro ファイルとしてエクスポートします。ファイルを Transfer Appliance にコピーし、Google に送信します。次に、GCP Console の BigQuery ウェブ UI を使用して Avro ファイルを BigQuery に読み込みます。
3. 
4. 
<details><div>
    答え：2
説明
B. 
このオプションでは、大規模なデータセットを Google Cloud に安全かつ効率的に転送するために Google が提供する物理デバイスである Transfer Appliance を使用します。このオプションが適切な理由は次のとおりです。
安全：Transfer Appliance は、機密データを安全に転送するように設計されています。転送中のデータを保護するための暗号化およびセキュリティ機能が組み込まれています。
効率：非常に大規模なデータセットの場合、Transfer Appliance を使用すると、インターネット経由でデータをアップロードするよりも大幅に高速になります。これにより、データ転送に必要な時間が短縮されます。
確実：Transfer Appliance は、ネットワークの中断などのデータ転送の課題を処理するように構築されており、データの安全な到着を保証します。
正しくないオプション -
A. Avro としてエクスポートし、gsutil 経由でアップロードする:このオプションでは、Transfer Appliance を使用するセキュリティと効率性に欠けます。暗号化については言及しておらず、大規模なデータセットに対して同じレベルの信頼性を提供していません。
C. CSV としてエクスポートし、Storage Transfer Service を使用する:Storage Transfer Service は便利ですが、機密データに対して CSV ファイルのパブリック URL を作成することはお勧めしません。これにより、データが潜在的なセキュリティリスクにさらされます。
D. パブリック URL を使用して Avro としてエクスポートする:オプション C と同様に、機密データのパブリック URL を作成することは、Storage Transfer Service を使用している場合でも、セキュリティ上のリスクとなります。これは、機密情報の取り扱いには推奨されません。
</div></details>

### Q. 質問41: 未回答
ここでは、BigQuery データ ウェアハウスのメイン インベントリ テーブルを読み取る、ほぼリアルタイムのインベントリ ダッシュボードを作成します。履歴在庫データは、品目および場所ごとの在庫残高として保存されます。毎時間、数千件のインベントリーの更新があります。ダッシュボードのパフォーマンスを可能な限り向上させ、データが正確であることを確認する必要があります。どのような手順を踏む必要がありますか?
1. 
2. 
3. BigQuery ストリーミングを使用して、日次在庫移動テーブルに変更をストリーミングします。履歴在庫残高テーブルに結合するビューで残高を計算します。在庫残高表を毎晩更新します。
4. 
<details><div>
    答え：3
説明
C. 
オプション C が推奨される理由は次のとおりです。
ほぼリアルタイムのデータ:BigQuery ストリーミングを使用すると、在庫の変更が発生したときにキャプチャできるため、在庫移動表をほぼリアルタイムで最新の状態に保つことができます。これは、インベントリ ダッシュボードにとって非常に重要です。
パフォーマンス：履歴在庫残高テーブルを在庫移動テーブルから分離することで、移動データを照会するときにスキャンされるデータの量を減らすことができます。これにより、クエリのパフォーマンスが大幅に向上します。
精度：ビューでの残高の日次計算により、在庫残高テーブルに最も正確なデータが反映されます。このプロセス中に、必要なデータクレンジングと検証を実行する機会があります。
効率：在庫残高テーブルを毎晩更新することで、データを統合して最適化し、クエリのパフォーマンスにより適したものにすることができます。これは、ダッシュボードの速度を維持するのに役立ちます。
キーポイント -
ほぼリアルタイムのインベントリ ダッシュボードを作成する必要があります。
ダッシュボードは、BigQuery データ ウェアハウスのメイン インベントリ テーブルを読み取ります。
履歴在庫データは、品目および場所ごとの在庫残高として保存されます。
毎時間、数千件のインベントリーの更新があります。
ダッシュボードのパフォーマンスを可能な限り向上させ、データが正確であることを確認する必要があります。
正しくないオプション -
オプション A(BigQuery UPDATE ステートメントを使用)は、同時実行の問題が発生する可能性があるため、リアルタイム更新に適しておらず、クエリのパフォーマンスに影響を与える可能性があります。オプション B (在庫残高テーブルのパーティション分割) では、クエリのパフォーマンスは向上しますが、リアルタイムの更新やデータの正確性はオプション C ほど効果的には対応できません。
オプション D(BigQuery バルクローダーを使用)は、バッチ読み込みのシナリオに適しており、インベントリ ダッシュボードに必要なほぼリアルタイムのデータ更新を提供できない場合があります。したがって、このコンテキストでは最適な選択ではありません。
</div></details>

### Q. 質問42: 未回答
BigQuery にデータが保存されている。BigQuery データセットのデータは、高可用性を備えている必要があります。このデータのストレージ、バックアップ、およびリカバリ戦略を定義して、コストを最小限に抑える必要があります。目標復旧時点(RPO)が 30 日の BigQuery テーブルをどのように構成すればよいですか?
1. 
2. 
3. BigQuery データセットをマルチリージョンに設定します。緊急時には、特定の時点のスナップショットを使用してデータを回復します。
4. 
<details><div>
    答え：3
説明
C. 
このオプションは、いくつかの理由で正しいです。
マルチリージョンデータセット:複数リージョンの BigQuery データセットを作成すると、データが複数の地理的リージョンに複製され、高可用性と冗長性が確保されます。このアプローチは、リージョンの障害によるデータ損失を防ぐのに役立ちます。
ポイント・イン・タイム・スナップショット:BigQuery のポイントインタイム スナップショット機能を使用すると、過去 30 日以内の特定の時点にデータを復元できます。これは、目標復旧時点 (RPO) の目標値である 30 日と一致します。
正しくないオプション -
A. BigQuery データセットをリージョンに設定します。緊急時には、特定の時点のスナップショットを使用してデータを回復します。
このオプションでは、特定の時点のスナップショットの使用が推奨されますが、リージョンの冗長性しか提供されないため、高可用性とディザスター リカバリーには十分ではない可能性があります。リージョン データセットは、マルチリージョン データセットと同じレベルのリージョン停止に対する保護を提供しません。
B. BigQuery データセットをリージョンに設定します。スケジュールされたクエリを作成して、バックアップの時刻のサフィックスが付いたテーブルにデータのコピーを作成します。緊急の場合は、テーブルのバックアップコピーを使用してください。
このオプションでは、スケジュールされたクエリ バックアップを作成する必要がありますが、これはデータ復旧の効果的な戦略です。ただし、特にデータセットが大きい場合は、バックアップの管理と保守が複雑になり、追加コストが発生します。BigQuery にはすでにネイティブのバックアップと復元機能が用意されているため、スケジュールされたクエリのコピーは不要になります。
D. BigQuery データセットをマルチリージョンに設定します。スケジュールされたクエリを作成して、バックアップの時刻のサフィックスが付いたテーブルにデータのコピーを作成します。緊急の場合は、テーブルのバックアップコピーを使用してください。
オプション B と同様に、このアプローチでは、マルチリージョン ストレージとスケジュールされたクエリ バックアップが組み合わされます。マルチリージョン ストレージによる冗長性は提供されますが、スケジュールされたクエリを使用してデータのバックアップ コピーを維持することに関連する複雑さと不要なコストも発生する可能性があります。BigQuery のリカバリとポイントインタイム スナップショットのネイティブ機能は、より効率的で費用対効果が高く、目的の RPO を達成します。
</div></details>

### Q. 質問43: 未回答
BigQuery テーブル内のデータのサンプルで Dataprep レシピを作成しました。このレシピを使用して、ロード・ジョブの実行が完了した後、同じスキーマを持つデータの新しい日次アップロードをクリーンアップおよび変換します。どのように進めればよいですか?
1. 
2. 
3. 
4. Dataprep ジョブを Dataflow テンプレートとしてエクスポートし、Composer ジョブに組み込むことです。
<details><div>
    答え：4
説明
正しいオプションは D. 
データフローテンプレートとしてエクスポートする:Dataprep ジョブを Dataflow テンプレートとしてエクスポートすると、受信データに対して実行できる再利用可能なデータ変換ワークフローが作成されます。
Composerジョブに組み込む:Google Cloud Composer は、複雑なワークフローをオーケストレーションできるマネージド Apache Airflow サービスです。Dataflow テンプレートを Composer ジョブに組み込むことで、大規模なデータ処理パイプラインの一部として Dataprep ベースのデータ変換の実行をスケジュールし、管理することができます。
正しくないオプション -
A. Dataprep で cron スケジュールを作成します。Dataprep ではジョブの実行をスケジュールできますが、これらのスケジュールは通常、Dataprep 環境内で Dataprep ジョブを実行するためのものであり、このシナリオで必要な外部でのオーケストレーションのためのものではありません。
B. App Engine の cron ジョブを作成します。App Engine の cron ジョブは、HTTP エンドポイントのトリガーなど、App Engine 環境に固有のタスクには適していますが、データ変換ワークフローやその他の外部プロセスのオーケストレーションを目的としたものではありません。
C. レシピを Dataprep テンプレートとしてエクスポートし、Cloud Scheduler でジョブを作成します。Cloud Scheduler を使用してジョブをトリガーすることもできますが、Dataprep ジョブは通常、Dataprep 環境内で実行されます。このオプションでは、Dataprep ジョブの実行を大規模なデータ パイプラインにシームレスに組み込むことはできません。
参考リンク -
クラウドコンポーザー:- https://cloud.google.com/composer/
</div></details>

### Q. 質問44: 未回答
Google Cloud で実行されているマルチステップ データ パイプラインの実行を自動化したい。パイプラインには、相互に複数の依存関係を持つ Dataproc ジョブと Dataflow ジョブが含まれています。可能な場合はマネージド サービスを使用し、パイプラインは毎日実行されます。どのツールを使うべきですか?
1. 
2. Cloud Composer
3. 
4. 
<details><div>
    答え：2
説明
正しいオプションは B. Cloud Composer です。
Cloud Composer の場合:Cloud Composer は、Google Cloud 上のマネージド Apache Airflow サービスです。これは、データパイプラインなどの複雑なワークフローを調整するために設計されています。これにより、有向非巡回グラフ (DAG) を使用してワークフローを定義、スケジュール、および管理できます。Cloud Composer 内の Dataproc、Dataflow、その他のサービスに依存するマルチステップ データ パイプラインを簡単に作成、実行、モニタリングできます。パイプラインには複数の依存関係を持つ Dataproc ジョブと Dataflow ジョブが含まれるため、Cloud Composer はこれらのタスクをスケジュールしてオーケストレーションするための堅牢なソリューションを提供します。さらに、柔軟性、スケーラビリティ、さまざまな Google Cloud サービスとの統合機能も備えています。
正しくないオプション -
A. cron:cron は個々のタスクやジョブのスケジュール設定に使用できますが、データ パイプラインで通常必要とされる依存関係、再試行、および監視を含む複雑なワークフローを処理する機能がありません。
C. クラウドスケジューラ:Cloud Scheduler は、特定の時間または間隔で HTTP リクエストや Pub/Sub メッセージをトリガーするのに適しています。オーケストレーションされたパイプラインの一部にすることもできますが、主にジョブのスケジューリングに重点が置かれており、複雑な複数ステップのパイプラインに必要なワークフロー管理機能を提供しない場合があります。
D. Dataproc のワークフロー テンプレート:Dataproc のワークフロー テンプレートは、Dataproc クラスタとジョブに固有です。これらは、Dataproc 内で定期的なワークフロー テンプレートを定義、管理するために使用されます。Dataproc 固有のタスクには便利ですが、依存関係のある Dataproc ジョブと Dataflow ジョブの両方を含む複数ステップのパイプラインをオーケストレーションするには適していない場合があります。この目的には Cloud Composer の方が適しています。
参考リンク -
クラウドコンポーザー:- https://cloud.google.com/composer/
</div></details>

### Q. 質問45: 未回答
Cloud Dataproc クラスタの管理者である。クラスターで進行中の作業を失うことなく、コストを最小限に抑えながら、実行時間の長いジョブをより高速に実行する必要があります。具体的にどのようなステップを踏むべきでしょうか?
1. 
2. 
3. 
4. プリエンプティブルワーカーノードでクラスタサイズを増やし、グレースフルデコミッションを使用するように構成します。
<details><div>
    答え：4
説明
正しいオプションは D です。 
プリエンプティブル・ワーカー・ノード:プリエンプティブル VM は、Google Cloud 上の有効期間が短く、費用対効果の高いコンピューティング インスタンスです。通常の VM よりも安価ですが、必要な容量が増加したときに Google がプリエンプト(終了)できます。コスト削減にはなりますが、いつでもプリエンプトされる可能性があるため、信頼性が低下する可能性もあります。
グレースフルデコミッショニング:グレースフルデコミッションを使用するようにプリエンプティブルワーカーノードを構成すると、プリエンプションノードで現在実行中のワークロードをプリエンプションされる前に、クラスタで終了できます。これにより、進行中の作業が失われるリスクが最小限に抑えられ、プリエンプティブルノードが停止した場合でもジョブが正常に完了します。
プリエンプティブルワーカーノードでクラスターサイズを拡大し、グレースフルデコミッションを使用することで、プリエンプティブルインスタンスのコスト削減を効果的に活用しながら、ジョブが中断することなく作業を完了できるようにし、ジョブの実行を高速化し、コストを最小限に抑えることができます。
正しくないオプション -
A. プリエンプティブルでないワーカーを増やしてクラスタサイズを増やします。クラスター サイズを大きくするとジョブのパフォーマンスが向上しますが、プリエンプティブルでないワーカーを追加すると、プリエンプティブル ノードが終了するという問題に直接対処せずにコストが増加します。
B. プリエンプティブルワーカーノードでクラスタサイズを増やし、強制的に使用停止するように構成します。プリエンプティブル・ワーカー・ノードを強制的に使用停止にすると、進行中の作業が失われる可能性があり、データを失うことなくジョブをより高速に実行するためには望ましくありません。
C. プリエンプティブル ワーカー ノードでクラスタ サイズを増やし、Cloud Stackdriver を使用してスクリプトをトリガーして作業を保持します。モニタリングとアラートに Stackdriver を使用することは重要ですが、グレースフルな廃止の必要性に直接対処することはできません。グレースフル デコミッションは、プリエンプティブル ノードの終了をより効率的に処理するための Dataproc の組み込みメカニズムです。
</div></details>

### Q. 質問46: 未回答
ある小売チェーンは、さまざまな地域の店舗で顧客の購入パターンを分析したいと考えています。複雑なSQLクエリをサポートし、大量のデータを処理できるデータウェアハウスソリューションが必要です。どのGCPサービスを使用すべきか?
1. 
2. BigQuery
3. 
4. 
<details><div>
    答え：2
説明
質問の正しいオプションは次のとおりです。 B. BigQuery
このシナリオでは、小売チェーンは、異なる地域の店舗間で顧客の購入パターンを分析する必要があります。これには、複雑な SQL クエリのサポートと大量のデータを処理する機能という 2 つの主要な要件があります。
BigQuery は、SQL クエリを使用して大規模なデータセットを分析するために設計された、フルマネージドのサーバーレス データ ウェアハウス ソリューションです。複雑な分析クエリの処理に優れており、大量のデータを効率的に処理できます。また、パーティション分割やクラスタリングなどの機能も提供して、クエリのパフォーマンスを最適化します。したがって、店舗全体の顧客の購入パターンを分析するという小売チェーンのニーズと完全に一致しています。
正しくないオプション -
A. Cloud Bigtable の場合: Cloud Bigtable は、大規模で高スループットのワークロード向けに設計された NoSQL データベースです。複雑な SQL クエリには適しておらず、複雑なデータ ウェアハウスやクエリ タスクではなく、主にリアルタイムの運用分析と時系列データに使用されます。
C. Firestore: Firestore は、主にモバイルおよびウェブ アプリケーション開発向けに設計された、柔軟でスケーラブルな NoSQL データベースです。リアルタイムのデータ同期や低レイテンシのクエリには適していますが、複雑な SQL クエリや大規模なデータ ウェアハウスを BigQuery ほど効率的に処理できない場合があります。
D. クラウドデータストア: Cloud Datastore は、運用アプリケーションやリアルタイム データに適した NoSQL データベースでもありますが、複雑なデータ ウェアハウス タスクに必要な堅牢なクエリ機能やパフォーマンスは提供されない場合があります。
</div></details>

### Q. 質問47: 未回答
研究機関は、世界中で行われている実験から大規模な科学データを収集し、処理します。そのためには、ペタバイト規模のデータを低遅延で効率的に管理できるストレージソリューションが必要です。このシナリオにはどのGCPサービスが適していますか?
1. 
2. 
3. Google クラウドストレージ
4. 
<details><div>
    答え：3
説明
研究機関が大規模な科学データを効率的に収集して処理し、ペタバイト規模のデータを低遅延で管理する必要があるシナリオに適したオプションは次のとおりです。
C. Google クラウドストレージ
Google Cloud Storage(オプション C): Google Cloud Storage は、ペタバイト規模のデータを含む大量のデータを保存および取得するように設計されています。オブジェクトへの低遅延アクセスを提供し、大規模なデータを効率的に格納および管理する必要があるシナリオに適しています。耐久性、スケーラビリティ、高可用性を提供し、データストレージの信頼できる選択肢となっています。
正しくないオプション -
A. Cloud Pub/Sub(オプション A):
Cloud Pub/Sub は、イベントドリブン システム向けのメッセージング サービスです。リアルタイムのメッセージングとイベントの取り込みに使用されますが、大規模なデータストレージ用には設計されていません。
B. Bigtable(オプション B):
Bigtable は、高スループットで低レイテンシのワークロード向けに設計された NoSQL データベースですが、大規模な科学データの保存と管理には適していない可能性があります。これは、大規模なデータセットの長期保存ではなく、高速でリアルタイムのデータアクセスと分析に適しています。
D. クラウドデータストア(オプション D):
Cloud Datastore は NoSQL データベース サービスであり、ウェブやモバイル アプリケーションのデータ ストレージには適していますが、ペタバイト規模の科学データの管理には適していない可能性があります。トランザクション データに重点を置いており、この特定のユースケースでは Google Cloud Storage と同じスケーラビリティと費用対効果を提供できない場合があります。
</div></details>

### Q. 質問48: 未回答
eラーニングプラットフォームは、生徒の進捗状況とクイズの結果をリアルタイムで追跡する必要があります。また、レポートと分析を生成する必要もあります。このユースケースに適したデータベースを提供するGCPサービスはどれですか?
1. 
2. 
3. BigQuery
4. 
<details><div>
    答え：3
説明
生徒の進捗状況や小テストの結果をリアルタイムで追跡したり、eラーニングプラットフォームでレポートや分析を生成したりするには、BigQuery(オプションC)が最適なGCPサービスです。その理由は次のとおりです。
正しいオプションは C. BigQuery -
BigQuery は、大規模なデータセットの処理と複雑な SQL クエリの迅速な実行を専門とする、フルマネージドでサーバーレスかつ拡張性の高いデータ ウェアハウスです。
リアルタイム分析用に設計されており、データ分析とレポート作成タスクに優れたパフォーマンスを提供します。
データをリアルタイムで取り込んで分析できるため、生徒の進捗状況やクイズの結果をその都度追跡するのに適しています。
大量のデータを処理できるため、レポートや分析の生成に適しています。
正しくないオプション -
A. Firestore:
Firestore は、クライアント(モバイル アプリケーションやウェブ アプリケーションなど)間での柔軟なリアルタイムのデータ ストレージと同期に適した NoSQL ドキュメント データベースです。Firestore はリアルタイムのデータ更新を処理でき、学生関連のデータの管理には適していますが、BigQuery と比較すると、複雑な分析やレポート作成のタスクには適していない可能性があります。
B. Cloud SQL:
Cloud SQL はマネージド リレーショナル データベース サービスですが、従来のリレーショナル データベースの制限により、リアルタイムの分析やレポート作成には適していない場合があります。構造化データやトランザクション ワークロード向けに設計されているため、複雑な分析クエリでは BigQuery ほど効率的に実行できない場合があります。
D. クラウドデータストア:
Cloud Datastore は、半構造化データの保存とクエリに適した NoSQL データベースです。リアルタイムのウェブスケール アプリケーション向けに設計されていますが、BigQuery が提供する詳細なレポートと分析に必要な堅牢な分析機能は提供されない場合があります。
</div></details>

### Q. 質問49: 未回答
スマートシティに展開されたIoTデバイスからセンサーデータを収集して分析するプロジェクトに取り組んでいます。膨大な量の受信データを処理し、リアルタイム分析をサポートできるGCPサービスはどれですか?
1. 
2. Bigtable
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は、B. Bigtable です。
このシナリオでは、スマート シティに展開されたデバイスからの IoT センサー データを処理しており、通常は大量の受信データが生成されます。また、リアルタイム分析のサポートも必要です。
Bigtable は、大量のデータを低レイテンシと高スループットで処理するために設計された NoSQL データベースです。大量のセンサー データの取り込みと保存に適しています。Bigtable はリアルタイムのデータ取り込みを処理でき、効率的なクエリをサポートしているため、大規模なデータセットのリアルタイム分析に適しています。センサーの読み取り値などの時系列データに最適化されているため、このユースケースに適しています。
正しくないオプション -
A. Cloud Pub/Sub の場合:
Cloud Pub/Sub は、リアルタイムのイベントの取り込みと配信のために設計されたメッセージング サービスです。リアルタイム データの取り込みには適していますが、分析に必要なストレージとクエリ機能は提供されません。大規模なデータの処理と分析の実行に必要なストレージとクエリ機能が不足しています。
C. BigQueryの場合:
BigQuery は、大規模なデータセットに対して SQL に似たクエリを実行するために設計されたデータ ウェアハウスですが、リアルタイムのデータ取り込みには最適化されていません。BigQuery は分析クエリやバッチ処理には優れていますが、大量のリアルタイム データ インジェストを処理するには最適な選択肢ではない可能性があります。
D. Firestore:
Firestore は柔軟な NoSQL データベースですが、ドキュメントベースのデータの管理に適しており、一般的にモバイル アプリケーションやウェブ アプリケーションに使用されます。IoTセンサーからの大量の時系列データを処理し、リアルタイム分析を実行するには最適な選択ではない可能性があります。
</div></details>

### Q. 質問50: 未回答
マーケティング会社は、Web、モバイルアプリ、メールキャンペーンなど、さまざまなソースからの顧客データを保存して分析したいと考えています。複数のチャネルからのデータを統合して分析できるデータベースが必要です。どのGCPサービスを検討すべきでしょうか?
1. BigQuery
2. 
3. 
4. 
<details><div>
    答え：1
説明
さまざまなソースからの顧客データを保存および分析し、複数のチャネルからのデータを統合および分析することを検討しているマーケティング会社にとって、検討すべき最適なGCPサービスはA.BigQueryです。
BigQuery は、大規模なデータセットを処理し、分析とデータ ウェアハウスのために複雑な SQL クエリを実行するように設計されています。複数のソースとチャネルからのデータの統合と分析を効率的に処理できます。
正しくないオプション -
B. Firestore は、主にモバイルおよび Web アプリケーションの開発に使用される NoSQL ドキュメント データベースです。アプリケーションの構造化データの管理には適していますが、複数のチャネルにまたがる複雑なデータ分析には適していない可能性があります。
C. Cloud Datastore は、ウェブおよびモバイル アプリケーション用に設計された NoSQL データベースでもあります。Firestore と同様に、アプリケーションの構造化データの保存には適していますが、BigQuery のような分析機能やクエリ パフォーマンスには欠けています。
D. Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。トランザクションデータベースには最適ですが、さまざまなソースやチャネルからのデータを扱うマーケティング会社が必要とする複雑な分析やデータ統合には最適化されていません。
</div></details>

## 4
### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>

### Q. 
1. 
2. 
3. 
4. 
<details><div>
    答え：
</div></details>
