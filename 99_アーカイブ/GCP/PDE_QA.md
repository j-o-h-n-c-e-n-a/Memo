## 1
### Q. 1
あなたは世界的な海運会社の一員です。あなたの目的は、40TBのデータを使用して予測モデルを構築し、様々な地域内の船舶による配送遅延の可能性を毎日予測することです。このモデルは、様々な情報源から収集された数多くの属性に依存しています。各船舶からの GeoJSON 位置情報を含むテレメトリーデータが 1 時間ごとに収集されます。あなたは、予測および地理空間処理のための組み込み機能を提供するストレージソリューションを求めています。 この目的のために、どのようなストレージ・ソリューションを選択すべきでしょうか？
1. 　BigQuery
2. Cloud Bigtable
3. Cloud Datastore
4. Cloud SQL for PostgreSQL
<details><div>
    答え：1
説明
BigQueryはアナリティクスに最適化されたクラウドベースのストレージソリューションで、予測や地理空間処理のためのネイティブ機能を備えています。モデルのトレーニングに使用したい40TBのデータのような大規模なデータセットに適しています。また、ダッシュボード機能もあり、地域内で遅延が発生しそうな船舶の数や船舶を表示することができる。
不正確なオプション
Cloud Bigtableは、低レイテンシのルックアップに最適化され、大量のデータを格納できるNoSQLデータベースソリューションです。予測や地理空間処理のためのネイティブ機能がないため、このユースケースには最適ではない。
Cloud Datastoreは、スケーラビリティに最適化され、大量のデータを保存できるNoSQLデータベースソリューションです。予測や地理空間処理のためのネイティブ機能を備えていないため、このユースケースには最適な選択肢ではありません。
Cloud SQL for PostgreSQLは、トランザクションに最適化され、大量のデータを保存できるリレーショナルデータベースソリューションです。予測や地理空間処理のためのネイティブ機能を備えていないため、このユースケースには最適ではない。
参考リンク
Google BigQuery: https://cloud.google.com/bigquery
</div></details>

### Q. 2
あなたはApache Kafkaを利用したIoTパイプラインを管理しており、通常毎秒約5000メッセージを受信しています。あなたの目標は、Google Cloud Platformを採用して、1時間移動平均が毎秒4000メッセージを下回ったときにアラートを生成することです。
どのような手順を踏むべきですか？
1. 　Kafka IOを使用してDataflowでデータのストリームを使用する。1分ごとに5時間のスライディング・タイム・ウィンドウを設定する。ウィンドウが閉じたら平均を計算し、平均が4000メッセージ未満ならアラートを送信する。
2. Kafka IOを使用してDataflowでデータのストリームを使用する。1時間のスライディング・タイム・ウィンドウを設定する。ウィンドウが閉じたら平均を計算し、平均が4000メッセージ未満ならアラートを送信する。
3. 
4. 
<details><div>
    答え：1
説明
IoTパイプラインの1時間の移動平均が毎秒4000メッセージを下回るとすぐにアラートを作成するには、以下の方法を取る必要があります：
このアプローチが適している理由は以下の通り：
Kafka IOを使ったデータフローでは、入力されるデータのストリームを効率的に処理できます。
5分ごとに1時間のスライディングタイムウィンドウを使用することで、移動平均を継続的に計算することができます。
ウィンドウが閉じたときに平均を計算することで、移動平均をチェックする間隔が一定になります。
計算された平均が4000メッセージを下回ると簡単にアラートを送ることができ、リアルタイムのアラート・メカニズムになります。
誤ったオプション
オプションB、C、およびDは、1時間にわたって移動平均を計算し、それが特定のしきい値を下回ったときにアラートを生成するという要件に直接対応していません：
B. 1時間の固定時間ウィンドウを使用すると、移動平均は得られず、むしろ1時間の静的平均が得られる。
C. このアプローチは、BigtableとCloud Schedulerを使用しますが、移動平均を直接計算しません。
D. このアプローチもBigQueryとCloud Schedulerを使用しますが、移動平均の計算がありません。
</div></details>

### Q. 4
データの取り込みと配信を一元化するために、貴社はどのシステムを選ぶべきか。
- トピック内の特定のオフセットへのシーク機能
-多数のトピックにおけるパブリッシュ/サブスクライブ・セマンティクスのサポート
- キーごとの順序付けを維持するか？
1. 　Apache Kafka
2. Cloud Storage
3. Dataflow
4. Firebase Cloud Messaging
<details><div>
    答え：1
説明
正しい選択肢は A. Apache Kafka です。
Apache Kafkaは、データ統合のための機能を備えたメッセージングシステムを提供する分散ストリーミングプラットフォームであり、トピック内の特定のオフセットにシークする機能、数百ものトピック上でパブリッシュ／サブスクライブセマンティクスをサポートする機能、キーごとの順序付けを保持する機能などを備えています。
不正解の選択肢
オプションB. Cloud Storageは、Apache Kafkaのようなデータ統合の機能を提供していないため、不正解です。
オプションC. Dataflowは、トピック内の特定のオフセットにシークする機能、数百のトピックでのパブリッシュ/サブスクライブ・セマンティクスのサポート、およびキーごとの順序付けを保持する機能を提供しないため、不正解です。
オプション D. Firebase Cloud Messaging は、トピック内の特定のオフセットへのシーク機能、何百ものトピックでの発行/購読セマンティクスのサポート、およびキーごとの順序付けの保持を提供していないため、不正解です。
</div></details>

### Q. 8
以下の仕様の新規プロジェクトにどのデータベースを選択しますか？
1. 　完全な管理機能。
2. 自動スケーラビリティ。
3. トランザクションの一貫性。
4. 最大6TBまでのスケーラビリティ。
5. SQLクエリーのサポート
このプロジェクトではどのデータベースを選択しますか？
1. 　Cloud SQL
2. Cloud Bigtable
3. Cloud Spanner
4. Cloud Datastore
<details><div>
    答え：3
説明
C. Cloud Spanner
Cloud Spannerは、Google Cloudが提供する、完全に管理され、グローバルに分散された、一貫性の高いデータベースサービスです。シナリオで説明した要件を満たすように設計されています：
フルマネージド： Cloud Spannerはフルマネージドであり、Google Cloudがインフラ管理、アップデート、バックアップを行うため、アプリケーションに集中することができます。
自動的なスケールアップ：Cloud Spannerは水平方向のスケーラビリティを考慮して設計されています。データとクエリの負荷が増加した場合、アプリケーションのスケーリングニーズに自動的に対応できます。
トランザクションの一貫性： Cloud Spannerは強力なトランザクション一貫性を提供します。つまり、データのACID（原子性、一貫性、分離、耐久性）特性を保証し、信頼性と一貫性のあるトランザクションを必要とするアプリケーションに適しています。
最大6 TBまで拡張可能：Cloud Spannerはより大きなデータセットを扱うことができるため、最大6 TBまで拡張可能です。
SQLでクエリ可能： Cloud SpannerはSQLクエリをサポートしているため、SQLベースのデータベースに慣れている開発者にはなじみやすい。
不適切なオプション
A. Cloud SQL： Cloud SQLはマネージド・リレーショナル・データベース・サービスですが、Cloud Spannerほど簡単には自動スケールしません。また、Cloud Spannerのように分散したグローバルに一貫性のあるデータを扱うようには設計されていない。
B. Cloud Bigtable： Cloud BigtableはNoSQLデータベースで、特に分析や時系列のユースケースで大量のデータを扱うのに優れている。しかし、このシナリオの要件である強力なトランザクション一貫性は提供しない。
D. クラウド・データストア： Cloud Datastore（データストアモードのFirestore）は、拡張可能なNoSQLドキュメントデータベースだが、Cloud Spannerと同レベルのトランザクション一貫性は提供できない。また、一般的にSQLクエリに依存する従来のリレーショナル・データベースとは異なるユースケースで使用される。
参考リンク
Cloud Spanner: https://cloud.google.com/spanner
</div></details>

### Q. 10
何百万台ものコンピュータのCPUとメモリ使用量に関する時系列データを効果的に保存するデータベースの選択に関する決断に迫られていると想像してほしい。要件は、このデータを1秒間隔で取得したサンプルとして保存することです。このデータはアナリストがリアルタイムのアドホック分析に使用するため、データベースは効率的なクエリ実行をサポートする必要があります。さらに、クエリを実行するたびに料金が発生するのを防ぎ、選択したスキーマ設計が将来的なデータセットの拡張に対応できることを目的としています。これらの目的に最適なデータベースとデータモデルはどれでしょうか？
1. 　
2. 
3. コンピューター エンジンのコンピューター識別子と各秒のサンプル時間を組み合わせた行キーを使用して、Bigtable で幅の狭いテーブルを作成します。
4. 
<details><div>
    答え：3
説明
正解はCです。Bigtableに、コンピュータ・エンジンのコンピュータ識別子と各秒のサンプル時間を組み合わせた行キーを持つ狭いテーブルを作成します。
こうすることで、アナリストはデータをすばやく照会できるようになり、スキーマ設計がデータセットの将来の成長を可能にします。Bigtableは、データへの高速アクセスとクエリを可能にするので、この種のデータには最適です。
不正解の選択肢
BigQueryはリアルタイムのアドホック分析をサポートしていないため、オプションAは不正解です。
BigQueryはリアルタイムのアドホック分析をサポートしておらず、各秒の間隔で行を更新するのは効率的ではないため、オプションBは不正解です。
Bigtableはワイドテーブルをサポートしておらず、各秒の値を列データとして結合するのは非効率的であるため、オプションDは不正解です。
参考リンク
https://cloud.google.com/bigtable/docs/schema-design-time-series
</div></details>

### Q. 13
顧客が自社の商品を購入する確率を予測するためにBigQuery MLで線形回帰モデルを開発する際、重要な予測要因として都市名の変数がありますが、モデルの学習と展開のためにデータを列に効率的に構造化し、必要な変数を保持しながら必要なコーディング工数を最小限に抑えるにはどうすればよいでしょうか？
1. 　
2. BigQueryのSQLを使用して、ワンホットエンコーディング法を使用してstateカラムを変換し、各都市をバイナリ値を持つカラムにします。
3. 
4. 
<details><div>
    答え：2
説明
正解はBです。
これは各都市に新しい列を作成し、都市名に基づいて各行にバイナリ値を割り当てるので、データを準備する最も効率的な方法です。これにより、モデルは都市名を予測変数として使用できるようになります。
不正解の選択肢
A. 都市情報の列を含まない新しいビューをBigQueryで作成しても、都市を予測変数として使用するために必要な情報をモデルに提供することはできません。
C. C. TensorFlow を使用して語彙リストを持つカテゴリ変数を作成すると、時間がかかりすぎ、必要以上のコーディングが必要になる。
D. クラウドデータフュージョンを使って、各都市を1,2,3,4,5とラベル付けされた地域に割り当て、その番号を使ってモデルで都市を表すことは、予測変数として都市を使うために必要な情報をモデルに提供しない。
</div></details>

### Q. 14
あなたは、北米で広く事業を展開する有名銀行に雇われている。あなたの仕事は、銀行口座取引を管理するために設計されたデータストレージシステムを構築することです。あなたの具体的なニーズには、ACIDコンプライアンス原則の遵守と、SQLクエリを使用してデータを取得する機能が含まれます。この目的に適したソリューションは何でしょうか？
1. 　トランザクションデータをCloud Spannerに格納する。ステールリードを有効にしてレイテンシを減らす。
2. トランザクションデータをCloud Spannerに格納する。ロック付き読み書きトランザクションを使用する。
3. トランザクションデータをBigQueryに保存する。クエリキャッシュを無効にして一貫性を確保する。
4. トランザクションデータをCloud SQLに格納する。分析にはBigQueryとの連携クエリを使用する。
<details><div>
    答え：2
説明
オプションB：
Cloud Spannerはグローバルに分散され、ACIDコンプライアンスを提供する一貫性の強いデータベースサービスであるため、銀行口座のトランザクションを処理するのに適している。Cloud Spannerでロック付き読み書きトランザクションを使用すると、データの一貫性と整合性を確保できます。
以下はオプションBに関する考慮事項です：
強力な一貫性： Cloud Spannerは強力な一貫性を提供します。これは銀行環境でデータの整合性を維持するために極めて重要です。
ACIDコンプライアンス： Cloud SpannerはACIDに準拠しており、トランザクション・データ・ストレージの要件を満たしています。
読み書きトランザクションのロック 読み書きトランザクションをロックすることで、データへのアクセスを制御して競合を防ぎ、データの整合性を確保できます。
不正解の選択肢
A. 
Cloud SpannerはACIDに準拠しており、トランザクション・データに適していますが、ステール・リードを有効にするとデータの一貫性が損なわれる可能性があります。ステイル・リードを有効にすると、最新ではないデータを読み込むことができるため、データの整合性が重要な銀行口座のトランザクションには適していません。
C. 
BigQueryは分析ワークロード用に設計されており、トランザクションデータベースではない。ACID コンプライアンスや強力なトランザクション一貫性は提供しません。BigQueryのクエリキャッシュを無効にしても、これらの基本的な要件には対処できません。
D. 
Cloud SQL は、ACID コンプライアンスと強力な一貫性を提供するマネージド・リレーショナル・データベースであり、トランザクション・データの保存に適しています。BigQueryとの連携クエリを分析に使用することで、トランザクション処理と分析で両方のサービスの強みを活用できます。このアプローチはバランスが取れており、指定された要件を満たすことができます。
</div></details>

### Q. 16
現在、Spark、Hive、HDFSを利用した大規模なオンプレミスクラスターをコロケーション施設で使用していますが、コスト削減を最大化しつつ、クラウドへの移行をタイムリーに行うにはどうすればよいでしょうか？このクラスタはピーク時の利用を想定して設計されていますが、多くのバッチジョブがあるため、需要が変動しています。貴社はまた、オンプレミスのオーバーヘッドとメンテナンスコストの削減を目指し、クラウドのサーバーレス・オファリングを採用することで、インフラを近代化しようとしています。コロケーション施設の契約更新まで2カ月しかありませんが、これらの目的を達成するためにどのような移行戦略をお勧めしますか？
1. 　
2. ワークロードをDataproc plus Cloud Storageに移行し、後でモダナイズする。
3. 
4. 
<details><div>
    答え：2
説明
クラウドに移行してオーバーヘッドを削減し、コスト削減のメリットを享受するという貴社の目標と、最初の移行期間が2カ月という限られた期間であることを考慮すると、推奨されるアプローチは次のようになります：
B. 
このアプローチが適している理由は以下の通りです：
混乱を最小限に抑える： Googleクラウド上のマネージドSparkおよびHadoopサービスであるDataprocにワークロードを移行することで、既存のSparkおよびHiveジョブの中断を最小限に抑えることができます。DataprocはSparkとHiveのワークロードを実行するための使い慣れた環境を提供するため、迅速な移行が容易です。
コスト効率： データストレージソリューションとしてDataprocとCloud Storageを併用することで、クラウドのコスト効率の高いストレージオプションを活用することができます。クラウドストレージは拡張性が高く、競争力のある価格設定なので、オンプレミスのインフラストラクチャのオーバーヘッドなしにデータを保存できます。
時間的制約： 初期移行に2ヶ月というタイトなスケジュールを考えると、短時間で比較的簡単に移行できる戦略を優先することが重要です。Dataprocとクラウド・ストレージへの移行は、ワークロードをすぐにモダナイズするのに比べ、より直接的な方法です。
近代化： 最初の移行が完了した後に、最新化を計画することができます。ワークロードがクラウドで実行されるようになったら、BigQuery for HiveのモダナイゼーションやDataflow for Sparkのモダナイゼーションのようなサーバーレスオファリングを徐々に検討し、サーバーレスの機能とコストの最適化を活用しながら進めることができます。
オプションC（SparkワークロードをDataprocとHDFSに移行し、HiveワークロードをBigQuery用にモダナイズする）は、Hiveをすぐにモダナイズする特定のニーズがある場合に検討できます。ただし、オプションBに比べて複雑さが増し、実行に時間がかかる可能性があります。
オプションD（SparkとHiveの両方のワークロードをすぐに最新化する）は、最新化の取り組みがコード、アーキテクチャ、およびプロセスの変更を伴う可能性があるため、特に2カ月の時間枠を考えると、より長くリスクの高い経路になる可能性があります。
参考リンク
Cloud Dataproc:- https://cloud.google.com/dataproc/
</div></details>

### Q. 18
テーブルをBigQueryに移行してデータモデルを決定する際、クエリのパフォーマンスを最適化するためにテーブルをどのように構造化すべきでしょうか？問題のテーブルには、複数の店舗での購入に関するデータが含まれており、トランザクションのタイムスタンプ、購入したアイテム、店舗ID、各店舗の市や州などの詳細が含まれています。定期的なクエリでは、過去30日間の個々のアイテムの売上を追跡し、州、都市、特定の店舗に基づいて購入パターンを分析します。
1. 　トランザクション時間でパーティショニングし、最初に州、次に市、次に店舗IDでクラスタリングします。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。
このオプションを使用すると、トランザクションの時間、州、市、および店舗IDによってテーブルをすばやくクエリできるため、正解です。これにより、探している特定の店舗、市町村、州をすばやく絞り込むことができるため、テーブルをクエリする際に最高のパフォーマンスが得られます。
不適切なオプション
最初に店舗 ID でクラスタリングすると、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション B は正しくありません。
最初に州によってトップレベル・クラスタリングを行うと、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション C は正しくありません。
最初にストア ID を指定したトップレベル・クラスタリングでは、テーブルへのクエリ時に最高のパフォーマンスは得られないため、オプション D は正しくありません。
参照リンク
https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 19
Pub/Sub フィードのサブスクライバのコードを更新しています。展開時にサブスクライバが誤ってメッセージを承認してしまい、メッセージが失われることを懸念しています。サブスクライバは確認メッセージを保持するように設定されていません。
展開後のエラーからの回復を保証するにはどうすればよいですか?
1. 　ローカル・マシンにPub/Subエミュレータをセットアップします。本番環境にデプロイする前に、新しいサブスクライバ・ロジックの動作を検証してください。
2. 新しいサブスクライバコードをデプロイする前に、Pub/Sub スナップショットを作成します。Seek 処理を使用して、スナップショットの作成後に利用可能になったメッセージを再配信します。
3. デプロイには Cloud Build を使用します。デプロイ後にエラーが発生した場合は、Seek オペレーションを使用して、デプロイ開始時に Cloud Build によってログに記録されたタイムスタンプを検索します。
4. Pub/Sub トピックでデッドレタリングを有効にして、正常に承認されなかったメッセージを捕捉する。展開後にエラーが発生した場合は、デッド・レター・キューでキャプチャされたメッセージをすべて再配信します。
<details><div>
    答え：2
説明
オプション B. 
新しいサブスクライバ・コードをデプロイする前に Pub/Sub スナップショットを作成することで、特定の時点のサブスクリプションの状態を取得できます。新しいサブスクライバコードの問題により、誤って承認され失われたメッセージがある場合、Seek 操作を使用して、スナップショットの作成後に利用可能になったメッセージを再送信することができます。
この方法は、誤った確認応答によって失われたメッセージを回復するのに効果的です。ただし、メッセージの回復を確実に行うには、スナップショットの作成と管理に依存します。
誤ったオプション
A. 
ローカルでのテストは開発に不可欠な要素ですが、本番環境でのサブスクライバの動作にエラーがないことを保証するものではありません。Pub/Sub エミュレータは本番環境を完全に再現しているとは限らず、動作に違いが生じる可能性があります。さらに、このオプションは、デプロイ後にエラーが発生した場合にメッセージを回復するメカニズムを提供しません。
C. 
Cloud Build はデプロイメントを管理するための貴重なツールですが、Cloud Build によってログに記録されたタイムスタンプに依存してエラーを回復することは、最も単純で効率的な方法ではない可能性があります。手作業が必要であり、メッセージ復旧に必要なメッセージ固有の詳細を取得できない可能性があります。さらに、タイムスタンプだけでは、メッセージ処理の正確な状態をピンポイントで特定するには不十分な場合があります。
D. 
デッドレターを有効にすることは、正常に処理できなかったメッセージをキャプチャするための確立された方法です。これは、処理中にエラーが発生したメッセージを回復するための体系的かつ自動化された方法を提供し、デプロイ後のメッセージ回復を確実にするための、より強固なオプションとなります。
参考リンク
Cloud Pub/Sub:- https://cloud.google.com/pubsub/
</div></details>

### Q. 20
著名な不動産会社に勤務するあなたは、機械学習用に6TBもの膨大な住宅販売データを準備する仕事を任されています。あなたの目的は、データ変換にSQLを利用し、機械学習モデルを確立するためにBigQuery MLを採用することです。このモデルは、未処理の生のデータセットに対して予測を行うことを目的としています。予測段階でスキューを効果的に回避するために、ワークフローを構成する上でどのような手順を踏むべきですか？
1. 　モデルを作成する際、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データに対して変換を指定しません。
2. 
3. BigQueryビューを使用して前処理ロジックを定義します。モデルを作成する際、そのビューをモデルの学習データとして使用します。予測時には、生の入力データに対して変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
4. Dataflowを使用してすべてのデータを前処理する。予測時には、入力データに対してさらなる変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
<details><div>
    答え：1
説明
オプションA. 
モデル作成時には、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。モデルの学習時には、これらの前処理ステップが学習データに適用されます。
予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データには変換を指定しません。これは、予測を行う前にモデルが内部的に生の入力データに同じ前処理ステップを適用することに依存していることを意味します。
モデルの前処理ロジックが十分に定義され、トレーニングデータと一貫している場合、オプションAは効果的に機能するかもしれませんが、予測中にモデル自身が未加工の入力データの前処理を正しく処理する必要があります。このアプローチは、モデル内部の前処理が予測の歪みを防ぐのに十分であることを前提としています。
実際には、オプション A とオプション B のどちらを選択するかは、モデル内部の前処理ロジッ クの具体的な特性と信頼性、および予測プロセスにおける透明性と制御の要件によって決まります。どちらのオプションも有効ですが、前処理と予測の一貫性に対するアプローチが異なります。
正しくないオプション
オプションC - 
BigQueryビューを使用して前処理ロジックを定義することは、学習データと予測データ間の一貫性を確保するための有効なアプローチです。しかし、このオプションには、ML.EVALUATE を使用する前の生の入力データに対する明示的な変換ステップがありません。このビューは一貫した前処理ロジックを提供しますが、スキューを防止するために、生の入力データが同じ前処理ステップを受けることを確実にすることが重要です。
オプションD - 
Dataflowを使用してすべてのデータを前処理することは、データ変換と準備のための実行可能なソリューションです。しかし、このオプションはDataflowの前処理と予測中のモデル内部の前処理が同一であることを前提としています。また、前処理ステップには必要ないかもしれないが、Dataflowによってさらなる複雑さがもたらされる。
オプションCとオプションDの両方は、ML.EVALUATEを使用する前に生の入力データを一貫して変換する必要性に明示的に対処していません。
参考リンク
BigQuery ML:- https://cloud.google.com/bigquery/docs/bigqueryml-intro
</div></details>

### Q. 21
あなたはある会社の株価を分析しています。5秒ごとに、過去30秒分のデータの移動平均を計算する必要があります。あなたはPub/Subからデータを読み込み、DataFlowを使って分析を行っています。ウィンドウ・パイプラインをどのようにセットアップしますか？
1. 　5秒間の固定ウィンドウ
2. 継続時間30秒の固定ウィンドウ
3. 継続時間5秒のスライディング・ウィンドウ
4. 継続時間30秒、周期5秒のスライディング・ウィンドウを使用します。以下のトリガーを設定して結果を出力する： AfterWatermark.pastEndOfWindow()を設定する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
30秒のスライディング・ウィンドウ： 期間30秒のスライディング・ウィンドウを使用することは、移動平均計算のために直近の30秒間のデータを考慮し続けることを意味します。これはあなたの要求と一致しています。
期間5秒： 期間5秒は、ウィンドウが5秒ごとに前方にスライドすることを示します。こ れに よ り 、 直近 30 秒のデー タ に基づいて 5 秒ご と に移動平均を計算す る こ と が保証 さ れます。この設定は、5秒ごとに移動平均を計算するという要件に合致しています。
トリガー設定： トリガーは、透かしがウィンドウの最後を通過した後に結果を出すように設定されています。これにより、ウィンドウが前方にスライドしたときに計算がトリガーされ、移動平均計算の望ましいタイミングと一致します。
誤ったオプション
オプションA（5秒間の固定ウィンドウ）は、過去30秒分のデータを取り込みません。これは、5秒間の固定ウィンドウを提供しますが、要件を満たしていません。
オプションB（継続時間30秒の固定ウィンドウ）は、30秒のウィンドウをキャプチャしますが、5秒ごとに前方にスライドしません。これは、5秒ごとに移動平均を計算するという要件に合致しません。
オプションC（継続時間5秒のスライディング・ウィンドウ）は5秒のスライディング・ウィンドウをキャプチャしますが、過去30秒のデータの移動平均を計算するために必要な30秒の継続時間を持ちません。さらに、トリガー設定は30秒後にデータを処理するように設定されており、5秒間隔の要件とは一致しません。
参考リンク
ビーム・ウィンドウの基本:https://beam.apache.org/documentation/programming-guide/#windowing-basics
</div></details>

### Q. 22
データのスケーラブルな処理とBigQueryへのロードを保証すると同時に、これらのイベントをPub/Subトピックにパブリッシュするために構築しているパイプライン内で、メッセージのシーケンシングは気にしなくても、1時間ごとにアプリケーションイベントを集約できるようにするには、どのようなテクノロジを採用すべきでしょうか？
1. 　
2. 
3. 
4. Pub/Subトピックから継続的に読み取り、タンブリング・ウィンドウを使用して必要な集約を実行するストリーミングDataflowジョブを作成します。
<details><div>
    答え：4
説明
正しい選択肢はDです。
ストリーミングDataflowジョブはPub/Subトピックからのメッセージを継続的に処理し、タンブリング・ウィンドウを使用して必要な集計を実行できるため、このオプションは正しい。これにより、大量のイベントに対応しながら、タイムリーにデータが処理され、BigQueryにロードされます。
不正解の選択肢
クラウド関数は、新しいメッセージがトピックにパブリッシュされたときにのみトリガされ、1時間ごとの区切りでイベントを処理および集計できないため、オプションAは不正解です。
オプション B は、クラウド関数が Pub/Sub トピックから利用可能なすべてのメッセージをプルし、1 回の実行で必要な集計を実行できるだけであり、1 時間ごとの区切りでイベントを処理および集計することはできないため、不正解です。
バッチデータフロージョブは、Pub/Subトピックから利用可能なすべてのメッセージをプルし、1回の実行で必要な集計を実行できるだけであり、不連続な時間間隔にわたってイベントを処理および集計することはできないため、オプションCは正しくありません。
参考リンク
https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines
</div></details>

### Q. 23
大手金融機関の従業員として、Dialogflowを使用してモバイルアプリケーション内でチャットボットを作成しようとしているあなたは、過去のチャット記録を綿密に調査し、顧客がカスタマーサービスに連絡した理由と一致する意図に従って、すべての会話を分類しました。顧客からの問い合わせの約70%は率直な要求が中心で、通常、最初の10件以内に解決されます。一方、残り30％の問い合わせは複雑で、対応にかなりの時間と労力を要する。このような状況を踏まえて、最初に自動化の優先順位をつけるべきインテントはどれでしょうか？
1. 　生のエージェントがより複雑なリクエストに対応できるように、リクエストの70%をカバーする10のインテントを自動化する。
2. より複雑な要求を最初に自動化する
3. 最短インテントと最長インテントのブレンドを自動化する
4. 「支払い」などの一般的な単語が一度しか表示されない場所でインテントを自動化する
<details><div>
    答え：1
説明
正しい選択肢 A. 
顧客リクエストの70%をカバーする最も一般的な10のインテントを自動化することは、現実的なアプローチです。自動化によって、顧客からの問い合わせの大部分に効率的に対応することに重点を置いています。これらのインテントを自動化することで、一般的なリクエストに対して迅速かつ一貫したレスポンスを提供できるようになり、効率が向上するだけでなく、ユーザーエクスペリエンスも向上します。
生身のエージェントが定型的で頻繁に発生するリクエストの処理から解放されることで、より複雑で個別対応が必要な残りの30%の問い合わせに、より多くの時間と注意を割くことができます。これにより、リソースの割り当てが最適化され、複雑な問題に対する全体的なサービス品質が向上します。
誤ったオプション
オプションB（「より複雑なリクエストを最初に自動化する」）は、場合によっては合理的なアプローチですが、大半の顧客からの問い合わせの効率を最適化するという当面の問題には対処できないかもしれません。複雑なリクエストに集中するあまり、最も一般的で簡単なリクエストがおろそかになる可能性がある。
オプションC（「最も短いインテントと最も長いインテントの混合を自動化する」）は、様々なインテントタイプで自動化のバランスを取ろうとしているが、顧客リクエストの分布と一致しない可能性がある。あまり一般的でないインテントを不必要に自動化する可能性がある。
オプションD（「"payment "などの一般的な単語が一度だけ出現する場所のインテントを自動化する」）は、必ずしも頻度や複雑さではなく、特定のキーワードに基づいてインテントを優先する。このアプローチでは、最も一般的または重要なインテントを捕捉できない可能性があります。
参考リンク
AI製品： https://cloud.google.com/products/ai/
</div></details>

### Q. 24
あなたは、現在構築中のBigQueryベースのデータウェアハウスのデータモデルを作成する責任を与えられました。スター型データスキーマを使用する既存のオンプレミス販売データウェアハウスをBigQueryプラットフォームに移行することが、目下の課題です。しかし、過去30日間の履歴データに対してクエリを実行したところ、パフォーマンスのボトルネックが発生しました。Googleが推奨するベストプラクティスに従って、ストレージ費用を抑えながらクエリ速度を向上させるには、どのような対策を講じればよいでしょうか？
1. 　データの非正規化
2. 顧客IDごとにデータをシャーディングする
3. ビューで次元データをマテリアライズする
4. トランザクションの日付でデータをパーティショニングします。
<details><div>
    答え：4
説明
BigQueryで過去30日分のデータをクエリする際に、データウェアハウスのストレージコストを増加させずにクエリのパフォーマンスを高速化するには、次のことを考慮する必要があります：
D. 
パーティショニング： パーティショニングとは、特定の属性（この場合はトランザクション日付など）に基づいて、データをより小さく管理しやすい塊に整理することです。パーティショニングは、時間ベースのデータのクエリ・パフォーマンスを向上させる効果的な方法です。データを日付でパーティショニングすると、BigQueryは特定の日付範囲のクエリを実行する際に、無関係なパーティションを効率的に削除することができます。
時間ベースのクエリ： パーティショニングは、過去30日間のデータをクエリする要件に適しています。これにより、BigQueryは関連するパーティションに焦点を当てることができ、データセット全体をスキャンするよりも大幅に高速化されます。
コスト効率： パーティショニングはデータの論理的な整理であるため、ストレージコストを増加させることはありません。使用するストレージの代金は支払いますが、パーティショニング自体がストレージ・コストを増加させることはありません。コストに影響を与えることなく、クエリのパフォーマンスを最適化します。
誤ったオプション
オプションA（データの非正規化）は、特定のタイプのクエリには役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスの問題には特に対応していません。
オプションB（顧客IDごとにデータをシャーディングする）は、日付ベースのクエリのパフォーマンスを直接改善しない可能性があり、特定の日付範囲のデータをクエリするときに複雑さをもたらす可能性があります。
オプションC（ビューで次元データをマテリアライズする）は、クエリを単純化するのに役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスを最適化するには、パーティショニングほど効果的ではないかもしれません。
参考リンク
BigQuery パーティショニング: https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 25
5年分のログデータをクラウドストレージにアップロードしました。あるユーザーから、ログの特定のデータポイントが想定される範囲から外れており、潜在的なエラーがあることを指摘されました。あなたの目的は、この問題を解決し、コンプライアンス目的で元のデータを保持しながら、将来的にプロセスを再実行できるようにすることです。どのような手順を踏むべきでしょうか？
1. 　データをBigQueryにインポートし、エラーのある行をスキップする
2. Compute Engineのインスタンスを作成し、エラーのある行をスキップしながらデータをコピーする
3. データフローワークフローを作成し、クラウドストレージからデータを読み取り、予期される範囲外の値をチェックし、値を適切なデフォルトに設定し、更新されたレコードをクラウドストレージの新しいデータセットに書き込む。
4. 更新されたレコードをクラウドストレージの同じデータセットに書き込む
<details><div>
    答え：3
説明
コンプライアンス上の理由から元のデータを保持しながら、ログデータ内の想定範囲外のデータポイントの問題に対処するには、次のことを検討する必要があります：
C. C. 
このオプションが適切な理由は以下の通り：
データ変換： データ変換： データフローを使用することで、元のデータセットを保持したまま、期待範囲外のデータポイントを識別して修正するデータ変換ロジックを実装することができます。これにより、誤ったデータが確実に修正されます。
オリジナルデータの保持： 更新されたレコードをクラウド・ストレージの新しいデータセットに書き込むことで、コンプライアンス上の理由からオリジナル・データの整合性を維持することができます。このアプローチでは、元のデータセットがそのまま維持され、分析や使用のために修正されたクリーンなバージョンが提供されます。
誤ったオプション
オプションA（データをBigQueryにインポートし、エラーのある行をスキップする）はうまくいくかもしれませんが、コンプライアンス上の理由で必要となる可能性がある、元のデータを変更されていない状態で保持することはできません。
オプションB（Compute Engineのインスタンスを作成し、エラーのある行をスキップしながらデータをコピーする）は、手作業で複雑なプロセスになる可能性があり、Dataflowのようなデータ処理フレームワークを使用するほど効率的ではないかもしれない。
オプションD（更新されたレコードをクラウドストレージの同じデータセットに書き込む）は、元のデータを上書きする。
</div></details>

### Q. 26
サーバーレスツールとSOL構文を活用して開発を加速し、パイプラインの実行時間を短縮しながら、スピードと処理要件を満たすGoogle Cloudパイプラインを構築するにはどうすればよいでしょうか？現在のアプローチでは、大規模なデータ変換にPySparkを使用しており、実行に12時間以上かかっています。生データがクラウドストレージに転送されていることは重要です。
1. 　Dataproc上でパイプラインを実行する
2. Cloud SQLにデータを取り込み、連携クエリを使用
3. Cloud StorageからBigQueryにデータを取り込み、PySparkコマンドをBigQuery SQLクエリに変換してデータを変換し、変換結果を新しいテーブルに書き込みます。
4. Apache Beam Python SDKの使用
<details><div>
    答え：3
説明
Google Cloud上の構造化データで速度と処理要件を満たしながら、開発とパイプラインの実行時間を短縮するには、次のことを検討する必要があります：
C. C. 
サーバーレスでスケーラブル： BigQueryはサーバーレスデータウェアハウスであり、インフラストラクチャを管理することなく大規模なデータ処理を行うことができます。高速処理のために設計されているため、パイプラインの実行時間を短縮できる。
SQL構文： SQL構文を使用したいので、BigQueryは完全に管理された強力なSQLエンジンを提供します。PySparkのコマンドを直接BigQueryのSQLクエリに変換できるので、移行や変換のプロセスがスムーズになります。
クラウドストレージとの統合： BigQueryはクラウドストレージとシームレスに統合されており、クラウドストレージからBigQueryにデータを取り込んで分析や変換を行うことができます。
変換の書き込み： BigQueryはSQL変換の結果を新しいテーブルに書き出すことをサポートしており、元のデータを保持したまま、さらなる分析のために変換されたデータを保存できます。
誤ったオプション
オプションA（Dataproc上でパイプラインを実行する）では、Dataprocクラスタのセットアップと管理が必要になるため、BigQueryのようなフルマネージドサービスを使用する場合と比較して、コスト効率や利便性が劣る可能性があります。
オプションB（Cloud SQLにデータを取り込み、連携クエリを使用）は、データ処理に複数のサービスを使用するため複雑さが生じ、BigQueryのようなパフォーマンスメリットが得られない可能性がある。
オプションD（Apache Beam Python SDKの使用）は有効な選択肢ですが、BigQueryのビルトインSQL機能を活用するのに比べて開発工数がかかる可能性があります。Pythonの使用を好み、データ変換プロセスをより制御する必要がある場合は、Apache Beamが適切な選択肢になる可能性があります。
</div></details>

### Q. 27
テキストファイルを取り込んで変換するDataflowパイプラインをテストしています。Dataflowジョブは、圧縮されたgzipファイル、デッドレターキューによるエラー処理、データ結合のためのSideInputsの利用により、予想よりも遅く実行されています。パイプラインの完了を加速するために、どのようなアクションを取るべきでしょうか？
1. 　圧縮Avroファイルへの切り替え
2. バッチサイズを小さくする
3. エラーをスローしたレコードを再試行する
4. SideInputの代わりにCoGroupByKeyを使用する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
CoGroupByKey： CoGroupByKey: CoGroupByKeyは、Apache Beam（Dataflowの基盤）の変換で、複数の入力PCollectionsからのデータを共通のキーに基づいてグループ化する。複数のソースからのデータを効率的に結合するために使用できます。SideInputsの使用に関連したパフォーマンス問題が発生している場合、CoGroupByKeyに切り替えることが有効な最適化かもしれません。SideInputsは、特に大きなデータセットを扱う場合、要素ごとのルックアップを伴うため、オーバーヘッドが発生する可能性があります。
SideInputsの代わりにCoGroupByKeyを使用するように処理戦略を変更することで、パフォーマンスの問題に対処できる可能性があります。このオプションの選択は、パイプラインの仕様と、どこでボトルネックが発生しているかに依存します。パイプラインの動作とパフォーマンス特性を分析し、十分な情報を得た上で決定することが重要です。
誤ったオプション
オプションA（圧縮Avroファイルへの切り替え）は、主にデータストレージと圧縮効率に対処しますが、特にパフォーマンスのボトルネックが圧縮ではなくデータ処理にある場合、Dataflowジョブを直接迅速化しない可能性があります。
オプションB（バッチサイズを小さくする）は、ある程度ジョブ効率を向上させることができますが、SideInputsやjoinオペレーションに関連するパフォーマンス問題に対処する最も効果的な方法ではないかもしれません。小さいバッチは並列処理に役立つが、処理戦略を根本的に変えないかもしれない。
オプションC（エラーをスローしたレコードを再試行する）は、エラー処理に重点を置いており、ジョブ実行時間の問題に直接対処していない。エラーを効果的に処理することは不可欠ですが、ジョブの完了を早める主要な方法ではありません。
参考リンク
https://beam.apache.org/documentation/transforms/python/aggregation/cogroupbykey/
</div></details>

### Q. 28
あなたは、PII（個人を特定できる情報）データを含む可能性のあるファイルをクラウドストレージにストリームし、最終的にBigQueryにストリームするリアルタイム予測エンジンを構築しています。PIIデータへの不正アクセスを防ぐために、クラウドデータ損失防止API（DLP API）を使用して、名前や電子メールなどの機密データをマスキングしながら参照整合性を維持するにはどうすればよいでしょうか。
1. 　暗号化トークンを作成し、トークン化されていないデータをロックダウンされたバケツに保存する
2. すべてのPIIデータを再編集する
3. BigQueryのすべてのテーブルをスキャンし、検出したデータをPIIでマスクする
4. PIIデータを暗号化フォーマット保持トークンで置き換えて偽名を作成する。
<details><div>
    答え：4
説明
参照整合性を維持しながら、PII データに権限のない個人がアクセスできないようにするには、次のアプローチを検討する必要があります：
D. D. 
このオプションが適切な理由は以下のとおりです：
暗号化形式保存トークン： 暗号化トークン：暗号化トークンを使用することで、PII データの形式と参照整合性を保持したまま、PII データを仮名化することができます。これにより、名前や電子メールなどの結合キーが引き続き効果的に使用できるようになります。
機密データの保護： 暗号化トークンを使用することで、強力なデータ保護が実現し、権限のない個人による機密PIIデータへのアクセスや悪用が困難になります。
不正なオプション
オプション A（暗号化トークンを作成し、トークン化されていないデータをロックダウンされたバケツに保存する）は、PII データを仮名化するという点ではオプション D に似ていますが、フォーマットと参照整合性を維持するために不可欠な暗号化フォーマット保持トークンの使用を指定していません。
オプションB（すべてのPIIデータを再編集する）は、機密情報を永久に削除します。これは、結合キーの参照整合性を維持する必要がある場合には適していない可能性があります。
オプションC（BigQueryのすべてのテーブルをスキャンし、検出したデータをPIIでマスクする）はBigQueryに有効かもしれませんが、クラウドストレージからのPIIデータ取り込みプロセスに直接対応しておらず、暗号化トークンの使用についても言及していません。
参考リンク
クラウドDLP
</div></details>

### Q. 29
図書館の本とその詳細(著者や出版年など)をモニタリングするアプリケーションをオンプレミスのデータ ウェアハウスから BigQuery に移行する際に、借りた書籍の著者に関する情報のクエリ速度を最速にするために、Google が推奨するスキーマ設計手法に従ってデータをどのように構成しますか?既存の設定では、著者の詳細を個別のテーブルに保持し、現在のリレーショナル データベース内の共有キーを介して書籍情報にリンクします。
1. 　スキーマを同じに保ち、書籍と各属性の異なるテーブルを維持し、現在行っているようにクエリを実行します
2. 幅が広く、作成者の銘、性、年月日など、各属性の列を含むテーブルを作成します
3. 書籍と著者に関する情報を含むテーブルを作成しますが、著者フィールドは著者列内にネストします。
4. スキーマを同じに保ち、すべてのテーブルを結合するビューを作成し、常にビューをクエリします
<details><div>
    答え：3
説明
図書館の図書追跡アプリケーションを BigQuery に移行する際に、借りた各書籍の著者に関するクエリの速度を最適化するには、次の方法を検討する必要があります。
C. 
ネストされたデータ: BigQuery は、テーブル内のネストされたフィールドと繰り返されるフィールドをサポートしています。著者情報を著者列内に入れ子にすることで、コストのかかる結合を回避しながら、書籍と著者の関係を維持できます。これにより、各書籍の著者に関する効率的なクエリが可能になります。
結合の削減: 著者情報を同じテーブル内に保持すると、著者の詳細と書籍の詳細を照会するときに結合が不要になります。これにより、クエリの実行が高速化され、待機時間が短縮されます。
簡略化されたクエリ: 入れ子になったデータを使用すると、クエリを簡略化し、複数のテーブルを結合する複雑さを回避できます。著者情報は、書籍情報と同じ行内で直接アクセスできます。
正しくないオプション -
オプション A (書籍と属性のテーブルを分けてスキーマを同じに保つ) は、結合が必要になる可能性が高く、著者に関するクエリでは効率的ではない可能性があります。
オプション B (各属性の列を含む幅の広いテーブルを作成する) は、特に作成者に複数の属性がある場合、スキーマが非正規化され、保守性が低下する可能性があります。
オプション D(すべてのテーブルを結合するビューを作成する)では、結合が必要になるため、クエリのパフォーマンスが低下する可能性があり、ネストされたデータ構造に対する BigQuery の機能を十分に活用できない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/nested-repeated
</div></details>

### Q. 30
データ ポイントを受信して GUID を生成するサービスを通じて、新しい Web サイト ユーザーにグローバル一意識別子 (GUID) を提供するときに、バックプレッシャーの懸念を最小限に抑えるためにパイプラインを構成するにはどうすればよいでしょうか。このデータは、内部システムと外部システムの両方から発生し、パイプライン内のマイクロサービスを介してHTTP呼び出しを介してアクセスされ、システムへのバックプレッシャーを回避しながら、マルチスレッドの可能性がある毎秒数万件の大量のメッセージの影響を受けます。
1. 　HTTP経由でサービスを呼び出します
2. パイプラインをクラス定義で静的に作成します
3. DnFnのstartbundleメソッドで新しいオブジェクトを作成します
4. ジョブを 10 秒単位でバッチ処理します。
<details><div>
    答え：4
説明
D. 
このオプションは、メッセージを 10 秒間隔でバッチ処理することを提案します。このアプローチの理論的根拠は次のとおりです。
バックプレッシャーの低減: 処理のためにメッセージをバッチ処理すると、メッセージの取り込みと処理の速度を制限することで、バックプレッシャーを減らすことができます。これにより、パイプラインへのデータフローを制御し、処理負荷の急増を防ぐことができます。
ただし、このアプローチにはトレードオフも生じることに注意することが重要です。
待機時間: メッセージをバッチ処理すると、一部のメッセージが次のバッチ ウィンドウまで遅延する可能性があるため、処理に待機時間が発生する可能性があります。これは、リアルタイムまたは低待機時間の処理が重要なシナリオには適していない可能性があります。
複雑さ: バッチ処理を実装すると、特にマイクロサービスや HTTP 呼び出しを処理する場合に、パイプラインが複雑になる可能性があります。定期的にバッチを管理およびフラッシュするメカニズムが必要になります。
正しくないオプション -
オプション A (HTTP 経由でサービスを呼び出す): このオプションは、通常、リアルタイムまたはほぼリアルタイムの処理に適していますが、バックプレッシャーを減らすという目標に合わない場合があります。各メッセージに対して HTTP 呼び出しを行う際の高スループットと潜在的なボトルネックを考慮することが重要です。
オプション B (クラス定義でパイプラインを静的に作成する) と C (DoFn の startBundle メソッドで新しいオブジェクトを作成する): これらのオプションは、バックプレッシャーに直接対処するのではなく、パイプライン コンポーネントの設計とインスタンス化に関連しています。これらは、高スループットのシナリオにおけるバックプレッシャーの懸念を本質的に軽減するものではありません。
</div></details>

### Q. 31
データ ウェアハウスを Google Cloud に移行し、オンプレミスのデータセンターをシャットダウンしているところです。この取り組みの優先度が高いことを認識した上で、クラウドへの初期データ転送に十分な帯域幅が提供されることを期待しています。移動するファイルの量はそれほど多くありませんが、個々のファイルは 90 ギガバイトを占有します。さらに、トランザクション システムから Google Cloud ベースのウェアハウスへの更新フローをリアルタイムで一定に維持することを目指しています。
データの移行と、ウェアハウスへの中断のない書き込みの保証の両方に推奨されるツールは何ですか?
1. 　移行用のストレージ転送サービス。Pub/Sub と Cloud Data Fusion
2. 移行用の BigQuery Data Transfer Service。Pub/Sub と Dataproc
3. gsutil (移行用)Pub/Sub と Dataflow によるリアルタイム更新。
4. 移行とリアルタイム更新の両方に gsutil
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
データ移行(gsutil):
gsutil: Google Cloud Storage Utility(gsutil)は、Google Cloud Storage との間でデータを効率的に転送するためのコマンドライン ツールです。これは、90 GB のファイルなどの大きなファイルの移行を処理するのに適しています。これは、初期データ読み込みのための簡単で効率的な選択です。
リアルタイム更新(Pub/Sub とデータフロー):
Pub/Sub: Google Cloud Pub/Sub は、トランザクション システムからダウンストリーム サービスにリアルタイムでデータをストリーミングするために使用できるスケーラブルなメッセージング サービスです。リアルタイムのデータストリーミング用に設計されており、他のGoogle Cloudサービスとうまく統合できます。
データフロー: Google Cloud Dataflow は、強力なストリームおよびバッチ データ処理サービスです。Pub/Sub からのリアルタイム データ ストリームを処理し、変換、集計、その他のデータ処理タスクを実行するために使用できます。リアルタイムのデータ更新に適しており、複雑なデータ処理シナリオを処理できます。
正しくないオプション -
オプション A (移行用のストレージ転送サービス。Pub/Sub と Cloud Data Fusion (リアルタイム更新用):
ストレージ転送サービス: ストレージ転送サービスは大規模なデータ転送に効率的ですが、主に 1 回限りまたは定期的な転送用に設計されています。リアルタイムのデータストリーミングには最適化されていません。
Cloud Data Fusion: Cloud Data Fusion はデータ統合サービスですが、通常はリアルタイムの更新ではなく、バッチ処理や ETL 処理に使用されます。リアルタイムの更新に使用すると、ソリューションが複雑になりすぎる可能性があります。
オプション B(移行用の BigQuery Data Transfer Service。Pub/Sub と Dataproc (リアルタイム更新用):
BigQuery Data Transfer Service: BigQuery Data Transfer Service は、BigQuery への自動データインポートに重点を置いているため、Google Cloud Storage への大容量ファイルの移行には適していない場合があります。
Dataproc: Google Cloud Dataproc は、主に Apache Spark と Hadoop のジョブの実行に使用されますが、リアルタイムの更新には必要ない場合があります。バッチ処理に適しています。
オプション D(移行とリアルタイム更新の両方に gsutil):
gsutil: gsutil はデータ移行には適していますが、リアルタイムのデータ ストリーミングや処理用には設計されていません。リアルタイム更新に gsutil を使用するのは現実的ではありません。
参考リンク -
https://cloud.google.com/storage/docs/gsutil
</div></details>

### Q. 32
Bigtable を使用して取引アプリケーションでこれらのインデックスの株式市場データを保存および提供する際に、すべての主要インデックスの最新の株価にアクセスするための最もシンプルなクエリを確実に行うには、Bigtable 内で行キーとテーブルをどのように構成すればよいでしょうか。
1. 　すべてのインデックスに対して一意のテーブルを 1 つ作成し、インデックスとタイムスタンプを行キーの設計として使用します
2. すべてのインデックスに対して一意のテーブルを 1 つ作成し、行キーの設計として逆タイムスタンプを使用します。
3. インデックスごとに個別のテーブルを用意し、行キーの設計としてタイムスタンプを使用します
4. インデックスごとに個別のテーブルを用意し、行キーの設計として逆タイムスタンプを使用します
<details><div>
    答え：2
説明
B. 
このオプションが適切であると考えられる理由は次のとおりです。
すべてのインデックスに対して 1 つのテーブル: すべてのインデックスに対して 1 つのテーブルを使用することで、複数のテーブルを作成する必要がなくなり、管理が簡素化されます。インデックスの数が多い場合は、それぞれに個別のテーブルを管理するのが面倒になる可能性があるため、特に便利です。
行キーとしての逆タイムスタンプ: 行キー設計として逆タイムスタンプを使用すると、最新の株価に簡単にアクセスできます。Bigtable は行を辞書式に並べ替えるため、最新のデータがテーブルの先頭に配置され、効率的に取得できます。
オプションBは機能しますが、いくつかのトレードオフと複雑さが伴います。
複雑な範囲クエリ: 最新のデータを取得するのは効率的ですが、履歴データに対して範囲クエリを実行するとより複雑になる場合があります。古いデータを効率的に取得するために、追加のロジックを実装する必要がある場合があります。
データの分離: 1 つのテーブルを使用すると、すべてのインデックスが一緒に格納されます。特定のインデックスを含むクエリを実行したり、特定のインデックスのデータを分離したりする必要がある場合は、追加のフィルター処理や処理が必要になることがあります。
正しくないオプション -
オプション A (すべてのインデックスに対して一意のテーブルを 1 つ作成し、インデックスとタイムスタンプを行キーの設計として使用します):
この方法では、タイムスタンプを抽出するために解析を必要とする複雑な行キー設計になる可能性があります。これにより、履歴データの範囲クエリの効率が低下する可能性があります。
オプション C (インデックスごとに個別のテーブルを用意し、行キーの設計としてタイムスタンプを使用します):
各インデックスのデータへのアクセスは簡素化されますが、インデックスの数が増えると、個別のテーブルを維持する必要があるため、管理オーバーヘッドが発生する可能性があります。
オプション D (インデックスごとに個別のテーブルを用意し、行キーの設計として逆タイムスタンプを使用します):
このオプションでは、インデックスごとに分離できますが、テーブルが急増し、管理が困難になる可能性があります。
参考リンク https://cloud.google.com/bigtable/docs/schema-design
</div></details>

### Q. 33
データの取り込みやレポート作成のパフォーマンスを損なうことなく 1 つのマスター データセットを維持するには、BigQuery のストリーミング API を使用して、Google が推奨するプラクティスに従って、レポートのみのデータ ウェアハウスのデータ読み込みプロセスをどのように構築すればよいのでしょうか?
1. 　3 時間ごとに運用テーブルを更新する
2. 90 分ごとに運用テーブルを更新する
3. ステージングされたデータを運用テーブルに移動し、ステージング テーブルの内容を 3 時間ごとに削除するステージング テーブルを用意します。
4. ステージング テーブルの内容を 30 分ごとに削除する
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
ステージング テーブル: ステージング テーブルを使用して、受信データを最初に取り込んで格納することは、一般的なベスト プラクティスです。これは、データ インジェスト用のバッファーを提供し、インジェスト プロセスを運用データセットから分離するのに役立ちます。
定期的な ETL: ステージング テーブルから運用テーブルに定期的に (この場合は 3 時間ごと) データを移動することで、マスター データセットの更新のタイミングを制御できます。これにより、レポートクエリが進行中の取り込みの影響を受けなくなります。
データのクリーンアップ: データを移動した後にステージング テーブルの内容を削除すると、過剰なデータが蓄積されることなく、新しいデータ インジェストに引き続き使用できます。
正しくないオプション -
オプション D (ステージング テーブルの内容を 30 分ごとに削除する) は、一部のユース ケースでは頻繁すぎる可能性があり、特に監査やエラー分析にデータ保持が必要な場合に、データ管理のオーバーヘッドが増加する可能性があります。
オプション A と B (3 時間または 90 分ごとに運用テーブルを更新する) では、レポート データセットの変更の反映に遅延が発生し、レポートの適時性に影響を与える可能性があります。
参考リンク -
https://cloud.google.com/bigquery/docs/streaming-data-into-bigquery
</div></details>

### Q. 34
新しい Dataflow バッチ ジョブを開始します。ジョブは正常に開始され、いくつかの要素を処理しますが、突然失敗して終了します。Dataflow モニタリング インターフェースにアクセスすると、パイプライン内の特定の DoFn に関連するエラー メッセージが検出されます。
これらのエラーの考えられる根本原因は何ですか?
1. 　ジョブの検証
2. ワーカー コードの例外
3. グラフまたはパイプラインの構築
4. アクセス許可が不十分
<details><div>
    答え：2
説明
B. 
Dataflow ジョブを開始すると、しばらくの間は正常に実行され、ワーカー コードの例外やエラーが原因で失敗することがあります。これらの例外により、ジョブが突然シャットダウンする可能性があります。特定の DoFn (パイプライン内の要素を処理するために定義する関数) に関連するエラーが表示される場合は、その DoFn 内のコードに問題がある可能性があります。
正しくないオプション -
A. ジョブの検証: Dataflow は通常、ジョブを開始する前に検証し、オプションの欠落や構成ミスなどの問題をチェックします。ジョブの検証で問題が発生した場合、ジョブは最初から開始されていない可能性があります。
C. グラフまたはパイプラインの構築: Dataflow パイプラインの構築方法の問題(コンポーネントの接続の誤りやフローの設定ミスなど)に関連します。これらの問題は通常、ジョブの検証または構築中に検出されますが、発生した場合、ジョブが開始時に失敗したり、期待どおりに実行されなかったりする可能性があります。
D. アクセス許可が不十分: これはアクセス許可とアクセス制御に関連しており、ジョブの開始や必要なリソースへのアクセスを妨げる可能性があります。アクセス許可が不十分な場合、ジョブが開始されなかったり、実行前に問題が発生したりする可能性があります。
参考リンク -
https://cloud.google.com/dataflow/docs/guides/common-errors
</div></details>

### Q. 35
新規顧客向けに、Google Cloud コンピューティング リソースの純消費量を詳細に記した日次レポートを迅速かつ効果的に作成し、これらのリソースのユーザーを特定するにはどうすればよいでしょうか。
1. 　Cloud Logging データを BigQuery に毎日エクスポートします。プロジェクト、ログタイプ、リソース、ユーザーでフィルタリングされたビューを作成します。
2. プロジェクト、リソース、ユーザーで Cloud Logging のデータをフィルタリングし、そのデータを CSV 形式でエクスポートする
3. Cloud Logging でデータをフィルタリングして BigQuery にインポートする
4. Cloud Logging データを CSV 形式で Cloud Storage にエクスポートし、Dataprep を使用してクレンジングする
<details><div>
    答え：1
説明
Google Cloud コンピューティング リソースの正味消費量とリソースを使用したユーザーを示す日次レポートを迅速かつ効率的に生成するには、次のオプションが最も適しています。
ある。
このオプションが適切な理由は次のとおりです。
Cloud Logging から BigQuery へ: ログデータを効率的に保存、分析するための一般的な方法は、Cloud Logging のデータを BigQuery にエクスポートする方法です。これにより、BigQuery のクエリ機能とスケーラビリティを活用できます。
フィルタリング用のビュー: BigQuery でビューを作成すると、プロジェクト、ログタイプ、リソース、ユーザーなどの特定の条件に基づいてデータを事前にフィルタリングできます。この事前フィルタリングにより、レポートを生成するための関連データを操作できるようになります。
毎日のエクスポート: 毎日のエクスポートを実行すると、レポートごとに新しいデータセットを操作でき、データを最新の状態に保つことができます。
正しくないオプション -
オプション B(プロジェクト、リソース、ユーザーで Cloud Logging のデータをフィルタリングし、そのデータを CSV 形式でエクスポートする)は機能する可能性がありますが、より複雑なクエリやレポート要件に対応する BigQuery の柔軟性と拡張性に欠けます。
オプション C(Cloud Logging でデータをフィルタリングして BigQuery にインポートする)では、追加のデータ移動手順が導入されるため、直接エクスポートよりも効率が悪く、タイムリーにならない可能性があります。
オプション D(Cloud Logging データを CSV 形式で Cloud Storage にエクスポートし、Dataprep を使用してクレンジングする)は複雑さを増し、日次レポートを生成するための BigQuery の直接的なアプローチほど効率的ではない可能性があります。
参考リンク -https://cloud.google.com/logging/docs/export/bigquery
</div></details>

### Q. 36
現在、単一のアジア地域内の顧客のみに対応しているスタートアップのWebアプリケーションが、最初はコストの最適化を優先し、後にネイティブJDBCドライバーを使用する要件でグローバルなプレゼンスとパフォーマンスの向上に焦点を当てながら、グローバルな顧客サービスを可能にするための資金を求める場合、どのような手順を踏む必要がありますか?
1. 　最初に Cloud Spanner を使用して単一リージョンのインスタンスを構成し、資金を確保した後に複数リージョンの Cloud Spanner インスタンスを構成します。
2. 最初に Cloud SQL for PostgreSQL の高可用性インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアのレプリケーションで Bigtable を使用します。
3. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアで Bigtable を使用します。
4. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、可用性の高い構成の Cloud SQL for PostgreSQL を使用します。
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
Cloud Spanner のスケーラビリティ: Cloud Spanner は、グローバルに分散された水平方向にスケーラブルなデータベースであり、複数のリージョン間で強力な一貫性を提供できます。単一リージョンのインスタンスから開始し、マルチリージョンのインスタンスを構成することは、資金を確保した後、グローバルなプレゼンスとパフォーマンスを最適化するという目標と一致します。
強力な整合性: Cloud Spanner は、強力な整合性が保証されていることで知られており、データの一貫性が重要なグローバル アプリケーションに適しています。
ネイティブ JDBC サポート: Cloud Spanner はネイティブ JDBC ドライバをサポートし、ウェブアプリケーションの要件との互換性を確保します。
正しくないオプション -
B. 最初に Cloud SQL for PostgreSQL の高可用性インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアのレプリケーションで Bigtable を使用します。
このオプションでは、可用性の高い Cloud SQL for PostgreSQL インスタンスから始めることをお勧めしますが、これは当初必要以上にコストが高くなる可能性があります。Bigtable はグローバル レプリケーションを提供できますが、Cloud SQL を最初に選択した時点では、資金調達前の費用最適化という目標に合致していない可能性があります。
C. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアで Bigtable を使用します。
オプション B と同様に、当初の費用最適化を主な目標としている場合、Cloud SQL for PostgreSQL から始めるのは最も費用対効果の高い選択肢ではない可能性があります。また、Cloud SQL のグローバル拡張機能は、Cloud Spanner に比べて制限されています。
D. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、可用性の高い構成の Cloud SQL for PostgreSQL を使用します。
このオプションでは、Bigtable や Cloud Spanner などのグローバルに分散されたデータベースを使用しないため、グローバルなプレゼンスとパフォーマンスを最適化するという資金調達後の目標に合わない可能性があります。
要約すると、オプション B、C、D にはそれぞれメリットがありますが、オプション A は、Cloud Spanner のグローバルなスケーラビリティと強力な整合性機能を活用して、初期費用の最適化目標と資金調達後のグローバル展開とパフォーマンスの最適化の両方の目標と一致するため、シナリオに最適な選択肢です。
参照リンク - リージョン構成とマルチリージョン構成 - Cloud Spanner
</div></details>

### Q. 37
大規模なデータ転送に関する Google が推奨するベスト プラクティスを遵守しながら、わずか数時間でデータ転送を完了することを目標に、オンプレミスのデータセンターから Google Cloud に 1 PB のデータを安全かつ効率的に移行するには、どのような手順を踏む必要がありますか?
1. 　Cloud Interconnect and Storage Transfer Service
2. Transfer Appliance を使用し、エンジニアに手動でデータの暗号化、復号化、検証を依頼します。
3. loud VPN、並列 gcloud compute scp ジョブ、チェックサム
4. データを 3 TB のバッチに削減し、gsutil を使用し、チェックサムを実行する
<details><div>
    答え：2
説明
Google が推奨するプラクティスに従いながら、安全な接続を介してオンプレミスのデータセンターから Google Cloud に 1 PB のデータを効率的に移行するには、次のアプローチを検討する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
Transfer Appliance: Google の Transfer Appliance は、大量のデータを安全かつ効率的に移行できるように設計されています。これは、データをオフラインで読み込み、Google Cloud Storage に取り込むために Google に送付するために使用できる物理ストレージ アプライアンスです。
手動暗号化: Transfer Applianceの使用中に、アプライアンスにロードする前にデータを手動で暗号化できます。これにより、転送中のデータセキュリティが確保されます。
手動検証:データ転送が完了した後、エンジニアはデータを復号化して元のデータセットと比較することで、データの整合性を手動で検証できます。この検証プロセスにより、データが正確に転送されたことが保証されます。
正しくないオプション -
オプションA(Cloud Interconnect and Storage Transfer Service)は、わずか数時間で1 PBのデータを移行するために必要な速度を提供しない可能性があるため、このような大量のデータ転送には適していない可能性があります。
オプション C(Cloud VPN、並列 gcloud compute scp ジョブ、チェックサム)は、このような大量のデータを迅速かつ安全に転送するための最も効率的な方法ではない可能性があります。
オプション D(データを 3 TB のバッチに削減し、gsutil を使用し、チェックサムを実行する)は、小規模なデータセットでは実現可能ですが、大量のデータが含まれるため、わずか数時間で 1 PB の移行を行うのは現実的ではない可能性があります。
速度、セキュリティ、Google のベスト プラクティスの遵守を目標とする 1 PB のデータ移行では、手動で暗号化と検証を行う Transfer Appliance の使用をおすすめします。この方法は、大規模なデータセットを Google Cloud に転送するための安全で効率的な方法を提供します。
参考リンク -
https://cloud.google.com/products/data-transfer/
</div></details>

### Q. 38
CSV ファイルを Cloud Storage から BigQuery に読み込む際に、1 つの列に STRING や INT64 などのデータ型が混在していたり、電話番号や住所などの値の形式に一貫性がなかったりするなど、ファイルの既知のデータ品質の問題を考慮して、データ品質を維持し、必要なクレンジングと変換を実行するためのデータ パイプラインをどのように確立すればよいのでしょうか。
1. 　BigQuery に読み込む前に、Data Fusion を使用してデータを変換します。
2. データを BigQuery に読み込む前に、Data Fusion を使用して CSV ファイルを AVRO などの自己記述型データ形式に変換します。
3. 目的のスキーマを使用してステージング テーブルに CSV ファイルを読み込み、SQL で変換を実行してから、結果を最終的な変換先テーブルに書き込みます。
4. 目的のスキーマでテーブルを作成し、CSV ファイルをテーブルにロードし、SQL を使用してその場で変換を実行します。
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
変換のための Data Fusion: Google Cloud Data Fusion は、ETL(抽出、変換、読み込み)プロセスのための強力なツールです。データ品質の問題に対処するために不可欠な、データ変換、クレンジング、エンリッチメントの機能を提供します。
高度な変換: Data Fusion では、ビジュアル インターフェースやカスタム コードを使用して複雑なデータ変換を実行できるため、データ型の不一致や一貫性のない書式設定などの問題を処理するのに適しています。
BigQuery との統合: Data Fusion は BigQuery とシームレスに統合できるため、変換されたデータを BigQuery テーブルに直接読み込むことができるため、データ パイプラインが簡素化されます。
オプション A は、BigQuery に読み込む前に Google Cloud Data Fusion を使用してデータ変換を行うもので、データ品質の問題に対処し、高度な変換機能を提供する包括的なアプローチです。これは、シナリオで説明されているように、複雑なデータ クレンジングと変換タスクを処理する場合に推奨される選択肢です。
正しくないオプション -
B. データを BigQuery に読み込む前に、Data Fusion を使用して CSV ファイルを AVRO などの自己記述型データ形式に変換します。
データ形式の変換は特定のシナリオでは役立ちますが、データ型の不一致や一貫性のない書式設定など、質問に記載されているデータ品質の問題に直接対処するものではありません。
C. 目的のスキーマを使用してステージング テーブルに CSV ファイルを読み込み、SQL で変換を実行してから、結果を最終的な変換先テーブルに書き込みます。
変換に SQL を使用することは有効なアプローチですが、データ品質の問題は SQL のみを使用して効果的に処理できることを前提としていますが、複雑な問題には当てはまらない場合があります。
D. 目的のスキーマでテーブルを作成し、CSV ファイルをテーブルにロードし、SQL を使用してその場で変換を実行します。
このオプションでは、最終的な変換先テーブルにデータを直接読み込む必要がありますが、データ品質の問題に事前に対処しないと危険です。一般に、データの検証と変換にはステージング テーブルを使用する方が安全です。
参照リンク: Data Fusion の概要
</div></details>

### Q. 39
e コマース プラットフォームでの顧客の購入確率を予測することを目的とした新しいディープ ラーニング モデルの開発に取り組んでいる間、初期トレーニング データセットと新しいテスト データセットの両方を使用して、モデルのパフォーマンスの評価を実施しました。この評価の結果、モデルが提供されたデータに対して過学習の傾向を示していることが明らかになりました。目的は、新しいデータの結果を予測する際に、モデルの精度を高めることです。この目標を達成するには、どのような手順を踏む必要がありますか?
1. 　データセットのサイズを増やし、入力特徴量を増やす
2. トレーニング データセットのサイズを大きくし、入力特徴の数を減らします。
3. データセットのサイズを小さくし、入力フィーチャを増やす
4. データセットのサイズを小さくし、入力特徴量を減らす
<details><div>
    答え：2
説明
新しいデータを予測する際の過学習に対処し、深層学習モデルの精度を向上させるには、次のことを行う必要があります。
B. 
このオプションが適切な理由は次のとおりです。
トレーニング データを増やす: トレーニング データセットのサイズを大きくすると、モデルの一般化が向上し、過学習を減らすことができます。データが多いほど、基になるパターンがより広く表現され、新しいデータでのモデルのパフォーマンスが向上する可能性があります。
入力特徴量を減らす: 入力特徴量が多すぎる過度に複雑なモデルは、トレーニング データ内のノイズをキャプチャできるため、過学習する傾向があります。入力特徴の数を減らすことで、モデルを単純化し、最も関連性の高い情報に焦点を合わせることができるため、汎化を改善できます。
過学習を軽減する最も効果的な方法は、トレーニング データセットのサイズを大きくすると同時に、入力フィーチャの数を減らしてモデルを単純化することです。この組み合わせにより、モデルの汎化が向上し、新しいデータの精度が向上します。
正しくないオプション -
オプション A、C、および D は、推奨されるアプローチではありません。
オプション A (データセットのサイズを増やし、入力特徴量を増やす): データセットのサイズと入力特徴の数の両方を増やすと、過学習がさらに悪化する可能性があります。モデルがすでに複雑すぎる場合は、データが多いだけでは役に立たない可能性があります。
オプション C (データセットのサイズを小さくし、入力フィーチャを増やす): データセットのサイズを小さくすると、モデルの一般化がさらに困難になる可能性があります。入力特徴量を増やしてデータを減らすと、モデルがさらにオーバーフィットになる可能性があります。
オプション D (データセットのサイズを小さくし、入力特徴量を減らす): データセットのサイズと入力特徴の数の両方を減らしても、モデルが意味のあるパターンを学習するための十分な情報が得られない可能性があります。
</div></details>

### Q. 40
オンライン小売業者の顧客サービスを強化するためのチャットボットを効果的に作成し、テキストと音声の両方のクエリを処理できると同時に、ローコードまたはノーコードのソリューションを模索し、キーワードベースの応答のための簡単なトレーニングを確保するにはどうすればよいでしょうか?
1. 　
2. 
3. 
4. Dialogflow を使用してチャットボットを実装し、収集された最も一般的なクエリに基づいてインテントを定義します。
<details><div>
    答え：4
説明
D. 
Dialogflow は、モバイルアプリ、ウェブ アプリケーション、デバイス、ボット、自動音声応答システムなどに会話型ユーザー インターフェースを簡単に設計して統合できる自然言語理解プラットフォームです。Dialogflow を使用すると、ユーザーがプロダクトと対話するための新しい魅力的な方法を提供できます。Dialogflow では、テキスト入力や音声入力(電話や音声録音など)など、顧客からの複数のタイプの入力を分析できます。また、テキストまたは合成音声のいずれかで、いくつかの方法で顧客に応答することもできます。
参考リンク -
https://cloud.google.com/dialogflow/docs
</div></details>

### Q. 41
航空宇宙企業独自の形式から BigQuery にフライトデータを最も効果的にインポートし、リソース消費を最小限に抑えながら、この新しいデータソース間の接続を確立し、BigQuery へのデータ ストリーミングを容易にするにはどうすればよいでしょうか。
1. 　定期的な ETL バッチ ジョブの Cloud Functions の関数をトリガーするシェル スクリプトを記述する
2. 標準の Dataflow パイプラインを使用して BigQuery に生データを保存し、後で形式を変換する
3. Apache Hive を使用して、データを CSV 形式で BigQuery にストリーミングする Dataproc ジョブを作成します。
4. Apache Beam カスタム コネクタを使用して、データを Avro 形式で BigQuery にストリーミングする Dataflow パイプラインを作成します。
<details><div>
    答え：4
説明
オプション D. 
このシナリオでは、特定の形式の独自のフライト データがあり、最小限のリソース消費で効率的に BigQuery にインポートする必要があります。
Apache Beam カスタム コネクタと Dataflow を併用して Avro 形式で BigQuery にデータをストリーミングすることは、いくつかの理由から最適な選択肢です。
Apache Beam は、複雑なデータ インジェストと変換タスクを処理できる強力で柔軟なデータ処理フレームワークです。
Avro はコンパクトで効率的なデータシリアル化形式であり、大量のデータのストリーミングと保存に適しています。
カスタム コネクタを使用すると、データ インジェスト プロセスを独自のデータ形式に合わせて調整し、スムーズで効率的なデータ転送を確保できます。
Dataflow は、データ量に合わせて自動的にスケーリングできるマネージド サービスであり、リソースを手動で管理してプロビジョニングする必要性を減らします。
正しくないオプション -
A. 定期的な ETL バッチ ジョブの Cloud Functions の関数をトリガーするシェル スクリプトを記述する:
このオプションは、定期的なバッチジョブの実行を示唆していますが、リアルタイムのデータストリーミングには適していない可能性があります。
また、データのストリーミングに効率的である可能性のある Avro 形式の使用についても言及していません。
B. 標準の Dataflow パイプラインを使用して BigQuery に生データを保存し、後で形式を変換する:
このアプローチでは、データが未加工の形式で BigQuery に保存されますが、これは BigQuery の機能を利用する最も効率的な方法ではない可能性があります。
これには、既に保存されているデータを変換する追加の手順が含まれますが、これは、目的の形式でデータをストリーミングするほどリソース効率が良くない可能性があります。
C. Apache Hive を使用して、データを CSV 形式で BigQuery にストリーミングする Dataproc ジョブを作成します。
Apache Hive はバッチ処理には適したツールですが、リアルタイムのデータ ストリーミングには適していない可能性があります。
CSV 形式は Avro ほどストリーミングに効率的ではなく、より多くのリソースを消費する可能性があります。
オプション D は、Apache Beam とカスタム コネクタを活用して Avro 形式で BigQuery にデータをストリーミングし、リソース消費を最小限に抑えながら効率的かつリアルタイムのデータ取り込みを実現するため、最も適切な選択肢です。
参照リンク - Apache Beam のプログラミング モデル
</div></details>

### Q. 42
オンライン証券会社には、大量の取引処理アーキテクチャが必要です。ジョブをトリガーするセキュア・キューイング・システムを作成する必要があります。ジョブはGoogle Cloudで実行され、同社のPython APIを呼び出して取引を実行します。ソリューションを効率的に実装する必要があります。あなたは何をするべきか?
1. 　Pub/Sub プッシュ サブスクリプションを使用して Cloud Functions の関数をトリガーし、Python API にデータを渡します。
2. Compute Engine インスタンスでホストされるアプリケーションを作成して、Pub/Sub トピックへのプッシュ サブスクリプションを作成する
3. NoSQLデータベースでのキューの作成
4. Cloud Composer の使用
<details><div>
    答え：1
説明
Google Cloud で実行されるジョブをトリガーし、会社の Python API を呼び出して取引を実行する安全なキューイング システムを作成するための最も効率的で適切なオプションは次のとおりです。
オプション A: 
Google Cloud Pub/Sub は、独立したアプリケーション間でリアルタイムかつ信頼性の高いメッセージングを実現するために設計されたメッセージング サービスです。
このシナリオでは、取引リクエストが発行される Pub/Sub トピックを設定できます。
Pub/Sub トピックへのプッシュ サブスクリプションを作成すると、メッセージがトピックにパブリッシュされたときに Cloud Functions の関数が呼び出されます。
その後、Cloud Functions の関数は取引データを Python API に渡して実行できます。
このアーキテクチャは効率的でスケーラブルであり、大量の取引処理に適しています。
正しくないオプション -
オプション B では、Compute Engine インスタンスでホストされるアプリケーションを作成して、Pub/Sub トピックへのプッシュ サブスクリプションを作成することを提案しています。これは機能しますが、Compute Engine インスタンスの管理とスケーリングが必要であり、Cloud Functions を使用する場合ほど効率的ではなく、サーバーレスでもない可能性があります。
オプションCは、NoSQLデータベースでのキューの作成について言及しています。NoSQL データベースはキューイングなど多くの目的に使用できますが、Google Cloud Pub/Sub などの専用のキューイング システムを設定する方が効率的で、この種のタスクに特化して構築されています。
オプション D では、Google Cloud のマネージド ワークフロー オーケストレーション サービスである Cloud Composer の使用について言及しています。Cloud Composer はさまざまなタスクに使用できますが、この特定のユースケースで Pub/Sub で Cloud Functions を直接使用する場合と比較して、単純なメッセージ キューイングと Python API 呼び出しの実行用に Cloud Composer を設定すると、不必要に複雑になる可能性があります。
参考リンク -
https://cloud.google.com/run/docs/triggering/pubsub-push
</div></details>

### Q. 43
あなたの会社は、データベースに 10 TB を超える現在のシステムから医療情報の大きな結果セットを取得し、さらにクエリを実行するためにデータを新しいテーブルに格納できるようにしたいと考えています。データベースは、メンテナンスの少ないアーキテクチャを持ち、SQL経由でアクセスできる必要があります。大規模な結果セットのデータ分析をサポートできるコスト効率の高いソリューションを実装する必要があります。あなたは何をするべきか?
1. 　Cloud SQL を使用
2. BigQuery をデータ ウェアハウスとして使用する。大きなクエリをキャッシュするための出力先を設定します。
3. Compute Engine で MySQL クラスタを使用
4. Cloud Spanner を使用
<details><div>
    答え：2
説明
大規模な結果セットのデータ分析をサポートしながら、メンテナンスが少なく、SQLへのアクセス性も備えている、最も費用対効果の高いソリューションは次のとおりです。
オプション B: 
説明：
Google BigQuery は、大規模なデータセットや複雑なクエリを処理するために設計された、サーバーレスで拡張性が高く、費用対効果の高いデータ ウェアハウス ソリューションです。
BigQuery は SQL に似たクエリ機能を備えており、SQL 経由でアクセスできます。
ストレージ、インデックス作成、クエリ パフォーマンスの最適化など、データの管理を自動的に処理します。
BigQuery ではクエリ結果をキャッシュできるため、大きな結果セットを複数回取得する際のパフォーマンスが大幅に向上し、クエリ費用を削減できます。
これは完全に管理されたサービスであり、手動のメンテナンスとスケーリングの必要性を排除します。
正しくないオプション -
オプション A(Cloud SQL を使用)とオプション C(Compute Engine で MySQL クラスタを使用)は、手動管理が必要で、BigQuery ほどシームレスにスケーリングできず、データ量が多い場合はコストがかかる可能性があるため、非常に大規模なデータセットや複雑な分析を処理するには最適な選択肢ではない可能性があります。
オプション D(Cloud Spanner を使用)は、グローバルに分散された可用性の高いデータベース サービスですが、大規模な結果セットの分析ではなく、トランザクション データ向けに設計されています。このユースケースでは、最も費用対効果の高いオプションではない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/cached-results
</div></details>

### Q. 44
オンプレミスのデータセンターに 15 TB のデータがあり、Google Cloud に転送したいとします。データは毎週変更され、POSIX 準拠のソースに保存されます。ネットワーク運用チームは、パブリック インターネットに 500 Mbps の帯域幅を付与しました。Google が推奨する方法に従って、週単位で Google Cloud にデータを確実に転送したい。あなたは何をするべきか?
1. 　Cloud Scheduler を使用して gsutil をトリガーする
2. Transfer Appliance を使用
3. データ センターにオンプレミス データ用の Storage Transfer Service をインストールし、毎週の転送ジョブを構成します。
4. Google Cloud 仮想マシンへの Storage Transfer Service のインストール
<details><div>
    答え：3
説明
パブリック インターネットへの帯域幅が 500 Mbps の場合、オンプレミスのデータセンターから Google Cloud に 15 TB のデータを毎週確実に転送するには、Google が推奨するデータ転送方法の使用を検討する必要があります。このシナリオでは、
オプション C: 
このオプションが適している理由は次のとおりです。
Storage Transfer Service は、Google Cloud が提供するマネージド サービスで、オンプレミスのデータソースまたは別のクラウド プロバイダから Google Cloud Storage にデータを転送するのに役立ちます。これは、大規模で定期的な転送を効率的に処理するように設計されています。
データセンターに Storage Transfer Service をインストールすると、スケジュールされた自動転送ジョブを設定して、定期的に(毎週など)Google Cloud にデータを移動できます。
Storage Transfer Service は、並列処理、再開可能な転送、および効率的で信頼性の高いデータ転送を保証するその他の機能を処理して、転送プロセスを最適化できます。
正しくないオプション -
オプション A(Cloud Scheduler を使用して gsutil をトリガーする)は機能しますが、gsutil コマンドとそのスケジュールを管理する必要があります。Storage Transfer Service と同じレベルの自動化と組み込みのデータ転送の最適化は提供されません。
オプション B (Transfer Appliance を使用) は、非常に大規模なデータセットや、ネットワーク帯域幅が制限要因となる状況に適しています。ただし、データが 15 TB で帯域幅が 500 Mbps のこのシナリオでは、必要以上に複雑でコストがかかる可能性があります。
オプション D(Google Cloud 仮想マシンへの Storage Transfer Service のインストール)は、標準または推奨されるアプローチではありません。Storage Transfer Service は、データ転送の目的でオンプレミスで実行するように設計されており、仮想マシンにインストールすると、不必要な複雑さが加わります。
参考リンク -
https://cloud.google.com/storage-transfer/docs/overview
</div></details>

### Q. 45
ACID準拠のデータベースを必要とするシステムを設計しています。障害が発生した場合に、システムが必要とする人間の介入が最小限であることを確認する必要があります。あなたは何をするべきか?
1. 　ポイントインタイム リカバリを使用した Cloud SQL for MySQL
2. 高可用性を有効にして Cloud SQL for PostgreSQL インスタンスを構成するを選択する必要があります。
3. 複数のクラスタを持つ Bigtable
4. マルチリージョン構成の BigQuery
<details><div>
    答え：2
説明
障害発生時に人的介入を最小限に抑えた ACID 準拠のデータベースを必要とするシステムを設計するには、オプション B: 
Cloud SQL for PostgreSQL は、フルマネージドで可用性が高く、ACID 準拠のリレーショナル データベース サービスを提供します。これは、信頼性とデータの整合性で知られるPostgreSQLに基づいています。
Cloud SQL インスタンスの高可用性を有効にすると、同じリージョン内の別のゾーンにスタンバイ レプリカが作成されます。プライマリ・インスタンスに障害が発生すると、スタンバイへの自動フェイルオーバーが発生し、ダウンタイムが最小限に抑えられ、データの整合性が確保されます。
PostgreSQLは一般に、ACID(原子性、一貫性、分離性、耐久性)トランザクションを強力にサポートしているため、データの整合性と信頼性を必要とするアプリケーションに適しています。
誤ったオプション-
オプション A(ポイントインタイム リカバリを使用した Cloud SQL for MySQL)は適切な選択肢ですが、ACID トランザクションをより強力にサポートする PostgreSQL が好まれることがよくあります。
オプション C(複数のクラスタを持つ Bigtable)は、ACID 準拠のリレーショナル データベース機能を提供するようには設計されていません。Bigtable は、さまざまなタイプのワークロードに使用される NoSQL データベースです。
オプション D(マルチリージョン構成の BigQuery)は、このシナリオには適用されません。BigQuery はデータ ウェアハウスおよび分析サービスであり、トランザクション リレーショナル データベースではありません。
参考リンク -
https://cloud.google.com/sql/docs/postgres
</div></details>

### Q. 47
メディアストリーミングプラットフォームは、動画の視聴回数やクリック率などのユーザーインタラクションデータを保存して分析する必要があります。そのためには、高い読み取りと書き込みのスループットを低レイテンシーで処理できるデータベースが必要です。このシナリオに最も適した GCP サービスはどれですか?
1. 　BigQuery
2. クラウドストレージ
3. Bigtable
4. Firestore
<details><div>
    答え：3
説明
このシナリオの正しいオプションは C.  です。
Bigtable は、低レイテンシの読み取りおよび書き込み操作で大量のデータを処理できるように設計された、非常にスケーラブルで高性能な NoSQL データベースです。これは、ビデオの視聴回数やクリックスルー率などのユーザー操作データを保存および分析するためにメディア ストリーミング プラットフォームが必要とする、高い読み取りおよび書き込みスループットを低遅延で処理する必要があるシナリオに適しています。
正しくないオプション -
A. BigQuery: BigQuery は、大規模なデータセットに対して SQL のようなクエリを実行するために最適化されたデータ ウェアハウスおよび分析プラットフォームです。Bigtable と比較してクエリのレイテンシが長くなる可能性があるため、リアルタイム、高スループット、低レイテンシのデータ ストレージと取得には最適ではありません。
B. クラウドストレージ:クラウドストレージは、主にファイルやオブジェクトなどの非構造化データを保存するために設計されたオブジェクトストレージサービスです。ユーザー操作のデータ分析に必要な、リアルタイムで低遅延のデータアクセスとクエリ機能は提供されません。
D. Firestore: Firestore は、ドキュメント指向のデータ用に設計された NoSQL データベースであり、モバイル アプリケーションやウェブ アプリケーションによく使用されます。リアルタイム データを処理できますが、メディア ストリーミング プラットフォームの高スループット、低レイテンシの要件に対しては、Bigtable ほどパフォーマンスが高くない可能性があります。また、Firestore にはドキュメントとコレクションの制限があり、非常に高速なデータのスケーラビリティに影響を与える可能性があります。
</div></details>

### Q. 48
組織は、モバイル アプリから収集されたユーザーの行動データに基づいてレコメンデーション システムを構築したいと考えています。複雑なクエリを効率的に処理し、リアルタイム分析機能を提供できるデータベースが必要です。どのGCPサービスを検討すべきですか?
1. 　Cloud Bigtable
2. BigQuery
3. Cloud Datastore
4. Cloud SQL
<details><div>
    答え：2
説明
この質問の正しい選択肢は B.  です。
ここで説明するシナリオでは、モバイルアプリから収集したユーザー行動データに基づいてレコメンデーションシステムを構築する必要があります。
複雑なクエリ: レコメンデーション システムの構築には、多くの場合、ユーザーの行動を分析し、パーソナライズされたレコメンデーションを生成するための複雑なクエリが含まれます。BigQuery は、大規模なデータセットに対して複雑な SQL クエリを実行するために最適化された、フルマネージドのサーバーレス データ ウェアハウスです。分析ワークロードの処理に優れているため、このシナリオには有力な選択肢となります。
効率性: BigQuery はクエリを効率的に実行するように設計されているため、リアルタイム分析タスクに適しています。大量のデータを処理でき、クエリの応答時間が短くなります。
正しくないオプション -
A. Cloud Bigtable: Bigtable は、高スループットで低レイテンシのデータ アクセス用に最適化された NoSQL データベースです。時系列データやキー値ストレージなどの特定のユースケースには優れていますが、複雑な分析クエリやリアルタイム分析には適していません。
C. Cloud Datastore: Cloud Datastore は、ウェブ アプリケーションやモバイル アプリケーションの構造化データの保存と取得に適した NoSQL データベースです。ただし、複雑なレコメンデーションシステムやリアルタイム分析に必要なパフォーマンスとクエリ機能が提供されない場合があります。
D. Cloud SQL: Cloud SQL はマネージド リレーショナル データベース サービスです。トランザクション ワークロードや構造化データには適していますが、BigQuery の方が適している複雑な分析クエリやリアルタイム分析には適していない可能性があります。
複雑なクエリを効率的に処理し、リアルタイム分析機能を提供する必要があるレコメンデーション システムの場合、分析ワークロードと大規模なデータセットの処理に強みを持つ BigQuery は、GCP サービスとして最適です。
</div></details>

### Q. 50
あなたは、車両のリアルタイムの位置データを保存および取得する必要がある物流会社のデータストレージソリューションを設計しています。このユースケースに最適なGCPサービスはどれですか?
1. 　Cloud SQL
2. Bigtable
3. Firestore
4. Cloud Pub/Sub
<details><div>
    答え：2
説明
このシナリオの正しいオプションは B.  です。
Bigtable は、高スループットで低レイテンシのデータ アクセスを実現するように設計された、フルマネージドの NoSQL データベース サービスです。大量のデータを処理でき、車両のリアルタイム位置データの保存に適しているため、このユースケースに最適です。車両の位置を効率的に追跡するために必要なスケーラビリティ、パフォーマンス、およびリアルタイムのデータアクセスを提供します。
正しくないオプション -
A. Cloud SQL: Cloud SQL はフルマネージドのリレーショナル データベース サービスであり、複数の車両のリアルタイムの位置データの保存と取得には適していません。構造化データに適しており、車両のリアルタイム追跡に必要なスケーラビリティとパフォーマンスは提供されません。
C. Firestore: Firestore は、柔軟でスケーラブルなリアルタイムのデータ ストレージ用に設計された NoSQL ドキュメント データベースです。リアルタイム データを処理できますが、車両の大量の位置データを保存するのには適していない場合があります。Firestore は、モバイルアプリやウェブアプリなど、ドキュメント形式のデータ ストレージを必要とするアプリケーションでより一般的に使用されます。
D. Cloud Pub/Sub: Cloud Pub/Sub は、独立したアプリケーション間でメッセージを送受信できるメッセージング サービスです。これはデータベースではなく、データを保存しません。これは、コンポーネント間のリアルタイムのイベントストリーミングとメッセージングに使用できますが、データストレージを目的としたものではありません。
スタート
演習テスト1: Google Cloud Professional Data Engineer - Practice Test #1
スタート
演習テスト2: Google Cloud Professional Data Engineer - Practice Test #2
スタート
演習テスト3: Google Cloud Professional Data Engineer - Practice Test #3
スタート
演習テスト4: Google Cloud Professional Data Engineer - Practice Test #4
法人向けサービスのお問い合わせ
Udemyで教える
出資
規約
ヘルプとサポート
サイトマップ
アクセシビリティに関する声明
特定商取引に関する表記
</div></details>

## 2
### Q. 質問4: 未回答
Cloud Datastore を利用して、車両のテレメトリ データをリアルタイムで取り込むことを選択しました。目的は、費用対効果を維持しながら、長期的なデータの増加に対応するストレージソリューションを確立することです。また、このデータのスナップショットを定期的に生成して、代替環境での Cloud Datastore のポイントインタイム リカバリ(PIT)やデータのクローン作成を容易にします。2つの異なる方法を使用して、これらの目標を達成するにはどうすればよいでしょうか。(2つ選択)
1. 　マネージド エクスポートを使用し、Nearline クラスまたは Coldline クラスを使用して Cloud Storage バケットにデータを保存します。
2. 管理対象エクスポートを使用してから、そのエクスポート用に予約された一意の名前空間の下にある別のプロジェクトの Cloud Datastore にインポートします。
3. 
4. 
<details><div>
    答え：1,2
説明
車両のテレメトリ データをリアルタイムで Cloud Datastore に取り込み、コストを抑えながら長期保存用のデータのスナップショットを作成するという目標を達成するには、次の 2 つの方法を検討できます。
A. 
説明: Cloud Datastore の管理対象エクスポート機能を使用して、データを定期的にエクスポートできます。エクスポート後、データを Cloud Storage バケットに保存します。Nearline または Coldline ストレージクラスを選択することで、コストを低く抑えながら、スナップショットを長期保存用にアーカイブできます。
B. 管理対象エクスポートを使用してから、そのエクスポート用に予約された一意の名前空間の下にある別のプロジェクトの Cloud Datastore にインポートします。
説明: データのスナップショットを作成する別の方法として、Cloud Datastore の管理対象エクスポートを使用する方法があります。エクスポート後、そのエクスポート用に特別に予約された一意の名前空間を使用して、別の Cloud Datastore プロジェクトにデータをインポートできます。これにより、別の環境にデータのコピーを別個に作成できます。
正しくないオプション -
その他のオプション(C、D、E)は、Cloud Datastore データのスナップショットを作成し、コストを最小限に抑えながら長期保存用にアーカイブするという目標に直接対応していません。オプション C と D では、BigQuery にデータをインポートするか、データを管理するアプリケーションを作成するかについて説明しますが、これはスナップショットを作成する最も効率的な方法ではありません。オプションEでは、クラウドソースリポジトリにデータを保存することについて言及していますが、これはデータスナップショットには適していません。
</div></details>

### Q. 質問5: 未回答
あなたは、データサイエンスチームによる分析のために、時系列のトランザクションデータを BigQuery にコピーするデータパイプラインを設定する任務を負っています。このデータは 1 時間ごとに新しいステータスで更新され、初期データセット サイズは 1.5 PB で、毎日 3 TB ずつ増加します。データの構造が複雑で、データ サイエンス チームはそれを使用して機械学習モデルを構築することを計画しています。目的は、データ サイエンス チームのパフォーマンスと使いやすさを最適化することです。
この目標を達成するために、どの2つの戦略を採用すべきでしょうか?(2つ選択してください。)
1. 　可能な限りデータを非正規化します。
2. データの構造を可能な限り保持する
3. BigQuery UPDATE を使用してデータセットのサイズをさらに小さくする
4. ステータスの更新が BigQuery に更新されるのではなく、追加されるデータ パイプラインを開発します。
5. トランザクション データの日次スナップショットを Cloud Storage にコピーし、Avro ファイルとして保存します。BigQuery の外部データソースのサポートを使用してクエリを実行する)
<details><div>
    答え：1,4
説明
A. 
データを非正規化すると、特に大規模なデータセットを処理する場合に、クエリのパフォーマンスを向上させることができます。非正規化することで、複雑な結合の必要性が減り、クエリをより簡単にすることができます。場合によっては、これにより、データ サイエンティストの使いやすさとクエリのパフォーマンスが向上する可能性があります。
D. 
時系列データに追加のみのアプローチを使用することは、ストリーミング データや頻繁に更新されるデータを処理する場合の一般的な方法です。既存のレコードを更新する代わりに、期間ごとに新しいレコードを追加します(例:毎時)。このアプローチにより、履歴データが保持され、時系列データの自然な流れに合わせることができます。
正しくないオプション -
オプション B (データの構造を可能な限り保持する) は、一般に、データの整合性を維持し、データが理解しやすい状態を維持するための優れたプラクティスです。ただし、場合によっては、クエリのパフォーマンスのために非正規化が必要になることがあります。
オプション C(BigQuery UPDATE を使用してデータセットのサイズをさらに小さくする)は、既存のレコードが頻繁に更新されることを意味するため、時系列データには適していない可能性があります。追加のみのアプローチでは、既存のレコードを更新するのではなく、時間間隔ごとに新しいレコードを追加します。
オプション E(トランザクション データの日次スナップショットを Cloud Storage にコピーし、Avro ファイルとして保存します。BigQuery の外部データソースのサポートを使用してクエリを実行する)は、スナップショットのアーカイブと維持には有効な戦略ですが、トランザクション データのリアルタイム分析には最も効率的なアプローチではない可能性があります。これは、履歴分析やバックアップの目的に適しています。
</div></details>

### Q. 質問8: 未回答
あなたは、それぞれ独自のサプライヤーから約 750 の異なるコンポーネントを調達する製造会社の一員です。データセットには、平均して、コンポーネントごとに 1000 個のラベル付き例が含まれています。目的は、倉庫スタッフがコンポーネントの写真から入荷コンポーネントを識別するのに役立つアプリを作成することです。最初の動作バージョンを概念実証として迅速に開発することを目指しています。
どのように進めればよいですか?
1. 既存のデータセットで Cloud Vision AutoML を使用します。
2. Cloud Vision AutoML を使用しますが、データセットを 2 回削減します。
3. 認識のヒントとしてカスタム ラベルを指定して、Cloud Vision API を使用します。
4. 転移学習手法を活用して独自の画像認識モデルをトレーニングします。
<details><div>
    答え：1
説明
オプション A: 
Cloud Vision AutoML はカスタム画像認識タスク専用に設計された機械学習サービスであるため、これは正しいオプションです。これにより、シナリオに不可欠な既存のデータセットを使用してカスタム画像認識モデルをトレーニングできます。オプションAが最良の選択である理由は次のとおりです。
カスタマイズ：Cloud Vision AutoMLを使用すると、特定のユースケースに合わせたカスタムモデルを構築できます。シナリオでは、倉庫作業員が撮影した写真からさまざまなコンポーネントを認識するには、正確な結果を得るためにカスタマイズされたソリューションが必要です。
精度：カスタム モデルは、ドメイン固有のデータでトレーニングされるため、多くの場合、汎用モデルよりもパフォーマンスが高くなります。既存のデータセットを使用してモデルをトレーニングすることで、コンポーネントの認識精度を高めることができます。
使いやすさ:カスタム機械学習モデルのトレーニングは複雑になりがちですが、Cloud Vision AutoML を使用するとプロセスが簡素化され、機械学習の深い専門知識がなくてもアクセスできるようになります。これは、迅速な概念実証という目標とよく一致します。
正しくないオプション -
オプション B: Cloud Vision AutoML を使用しますが、データセットを 2 回削減します。
データセットを減らすと、貴重なトレーニングデータが失われ、モデルの精度に悪影響を与える可能性があります。PoC では、最良の結果を得るために、できるだけ多くの関連データを使用する必要があります。
オプション C: 認識のヒントとしてカスタム ラベルを指定して、Cloud Vision API を使用します。
Cloud Vision API はさまざまな画像分析タスクに役立ちますが、カスタム画像認識を必要とする特定のシナリオには適していない可能性があります。カスタムラベルをヒントとして指定すると認識が向上しますが、ラベル付けされた画像のデータセットが大量にある場合は、Cloud Vision AutoMLでカスタムモデルをトレーニングするほど効果的ではありません。
オプション D: 転移学習手法を活用して独自の画像認識モデルをトレーニングします。
転移学習手法を使用して独自の画像認識モデルをトレーニングすることは有効なアプローチであり、特定のシナリオでは非常に効果的ですが、画像内のコンポーネントを認識するための迅速な概念実証 (PoC) の作成を含む特定の状況には最適な選択肢ではない可能性があります。
</div></details>

### Q. 質問9: 未回答
あなたは画像認識に関連する特殊なプロジェクトに携わっており、チームは、開発したカスタム C++ TensorFlow 操作に主に依存するモデルを作成しました。これらの操作は、主要なトレーニング プロセスに不可欠であり、リソースを大量に消費する行列の乗算を伴います。現在、モデルのトレーニング プロセスが完了するまでに数日かかる場合があります。目標は、Google Cloud アクセラレータを活用して費用対効果を維持しながら、このトレーニング時間を大幅に短縮することです。
この目標を達成するには、どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. CPU を使用したまま、モデルをトレーニングするクラスターのサイズを増やします。
<details><div>
    答え：4
説明
D. 
カスタム C++ TensorFlow Ops:モデルは、カスタム C++ TensorFlow 演算に大きく依存しています。TPU や GPU とシームレスに連携するようにこれらの運用を移行することは、複雑で時間のかかるプロセスであり、多くの場合、これらのアクセラレータの最適化には大幅なコード変更と専門知識が必要です。
TPUの:Cloud TPU は、特定のディープ ラーニング ワークロード向けの優れたアクセラレータですが、アーキテクチャと互換性のある TensorFlow オペレーション向けに最適化されています。カスタム演算を TPU で実行するように適応させるのは困難な場合があり、モデルが特殊なハードウェアを最大限に活用できない限り、大きなメリットが得られない可能性があります。
GPUサポート:カスタム演算に GPU カーネル サポートを実装することは、GPU の使用を計画している場合、正しい方向への一歩です。ただし、GPU と TPU はアーキテクチャが異なるため、個別の最適化が必要です。このオプションは、特にGPUアクセラレーションをターゲットとしている場合に適しています。
クラスタのスケーリング:CPU にとどまり、クラスターのサイズを増やすことで、複数の CPU ノードにワークロードを分散できます。これにより、計算負荷の高いタスクであっても、トレーニング時間を大幅に短縮できます。多くの場合、トレーニングをスピードアップするための最も簡単で費用対効果の高い方法です。
コストに関する考慮事項:TPU と GPU は、CPU ベースのクラスターと比較して、使用コストが高くなる可能性があります。CPU にとどまり、クラスターをスケーリングすることで、パフォーマンスとコスト効率のバランスを取ることができます。
カスタム C++ TensorFlow 演算を使用するシナリオと、コストを低く抑えながらトレーニング時間を最小限に抑える必要があることを考えると、CPU にとどまり、クラスターをスケーリングする (オプション D) ことが、最も実用的でコスト効率の高いアプローチです。TPU や GPU などのアクセラレータへの移行は長期的な目標かもしれませんが、これらのハードウェア プラットフォーム向けのカスタム運用の最適化に伴う複雑さとコストを慎重に検討して取り組む必要があります。
</div></details>

### Q. 発行： 未回答
自然言語処理領域内の回帰問題に取り組んでおり、1 億個のラベル付き例を含むデータセットを備えています。データをランダムにシャッフルし、90/10 の比率でトレーニング セットとテスト セットに分割しました。ニューラル ネットワークに学習させ、テスト セットでそのパフォーマンスを評価すると、トレーニング セットの二乗平均平方根誤差 (RMSE) がテスト セットの誤差の 2 倍であることがわかります。
モデルのパフォーマンスを向上させるには、どのような手順を実行する必要がありますか?
1. 　トレーニングとテストの分割でテスト サンプルのシェアを増やします。
2. より多くのデータを収集し、データセットのサイズを大きくしてみてください。
3. 正則化手法 (ドロップアウトやバッチ正規化など) を試して、過学習を回避します。
4. 追加のレイヤーを導入したり、使用する語彙や n-gram のサイズを増やしたりするなどして、モデルの複雑さを増します。
<details><div>
    答え：3
説明
モデルの二乗平均平方根誤差 (RMSE) が、トレーニング セットではテスト セットの 2 倍であるという観察結果は、過学習を示しています。過学習は、モデルが学習データに近づきすぎて、一般的なパターンではなく学習データにノイズや特異性をキャプチャすることを学習した場合に発生します。モデルのパフォーマンスを向上させるには、過学習を減らすことに重点を置く必要があります。正しいアプローチは次のとおりです。
C. 
正則化手法:ドロップアウト、バッチ正規化、L2 正則化などの手法は、過学習を軽減するように設計されています。トレーニング中にモデルのパラメーターに制約を導入し、トレーニング データに近づきすぎないようにし、目に見えないデータへの一般化を促進します。
テストセットサイズの拡大(オプションA):トレーニングとテストの分割でテスト サンプルのシェアを増やしても、過学習には直接対処できません。重要なのは、既存のテストセットの相対的なパフォーマンスであり、そのサイズではありません。
より多くのデータを収集する(オプションB):より多くのデータを収集すると、特定のケースでは役立ちますが、必ずしも過学習が解決されるとは限りません。一般に、データセットのサイズを増やすことを検討する前に、まずモデルを最適化し、正則化手法を適用することをお勧めします。
モデルの複雑性を増す(オプションD):モデルの複雑さが増すと、過学習が解決されるどころか悪化する可能性があります。複雑なモデルほどパフォーマンスが向上するというのは、よくある誤解です。適切な正則化を備えた単純なモデルは、多くの場合、過度に複雑なモデルよりも優れた性能を発揮します。
正しくないオプション -
A. トレーニングとテストの分割でテスト サンプルのシェアを増やします。
トレーニングとテストの分割でテスト サンプルの割合を増やしても、過学習の問題に直接対処できるわけではありません。トレーニングとテストの間でデータの割り当てが変更されるだけで、モデルの動作には影響しません。
問題は、テストセットのサイズではなく、モデルがトレーニングセットから未知のデータにうまく一般化できないことです。このオプションでは、過学習の根本原因には対処できません。
B. より多くのデータを収集し、データセットのサイズを大きくしてみてください。
より多くのデータを収集することは、特に意味のあるパターンを学習するための十分なデータがモデルにない場合に、場合によっては有用な戦略となる可能性があります。ただし、このシナリオでは、既にかなりのデータセット (100M の例) があります。
データセットのサイズを大きくしても、過学習の問題に直接対処できない場合があります。過学習は、多くの場合、モデルが複雑すぎるか、使用可能なデータの量に対してパラメーターが多すぎることが原因です。一般に、大規模なデータセットがある場合は、モデルの正則化に重点を置く方が効果的です。
D. 追加のレイヤーを導入したり、使用する語彙や n-gram のサイズを増やしたりするなどして、モデルの複雑さを増します。
モデルの複雑さが増すと、過学習は解決されるどころか悪化する可能性があります。より複雑なモデルでは、トレーニング データにノイズや特異性が当てはめられやすく、一般化が不十分になる可能性があります。
過学習は、通常、モデルが既に複雑すぎて使用可能なデータがない場合に発生します。複雑さを増すことは、推奨されるアプローチではありません。代わりに、モデルを単純化し、正則化手法を適用して過学習を防ぐことをお勧めします。
</div></details>

### Q. 質問15: 未回答
データ サイエンティストが BigQuery ML モデルを開発し、予測を配信するための ML パイプラインの構築についてサポートを求めています。REST API アプリケーションは、100 ミリ秒未満の待ち時間内に個々のユーザー ID の予測を提供するという基準を満たす必要があります。使用される予測クエリは、SELECT predicted_label、user_id FROM ML.PREDICT (MODEL 'dataset.model', table user_features) です。
この ML パイプラインの作成にはどうすればよいでしょうか。
1. 　クエリへの WHERE 句の追加とデータ閲覧者ロールの付与
2. 承認済みビューの作成
3. クエリから結果を読み取るための Dataflow パイプラインの作成
4. BigQueryIO を使用して Dataflow パイプラインを作成し、クエリからすべてのユーザーの予測を読み取り、BigtableIO を使用して結果を Bigtable に書き込み、アプリケーションが Bigtable から個々のユーザーの予測を読み取れるように、アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与することです。
<details><div>
    答え：4
説明
REST API アプリケーションで BigQuery ML を使用して低レイテンシで予測を提供する場合、最適なオプションは、オプション D: 
その理由は次のとおりです。
レイテンシーに関する考慮事項:個々のユーザー ID のレイテンシーが 100 ミリ秒未満の予測を提供することは、困難な要件です。BigQuery への直接クエリは、この低レイテンシの要件を常に満たしているとは限りません。
データフロー パイプライン:Dataflow パイプラインを作成することで、データを効率的に処理、変換できます。Dataflow は BigQuery から予測を読み取り、低レイテンシのアクセスに最適化された別のストレージ システム(Bigtable など)に書き込むことができます。
Bigtable ストレージ:Bigtable は、低レイテンシ、高スループットのストレージを提供する NoSQL データベースです。Bigtable に予測を保存すると、個々のユーザー ID の予測をすばやく取得できます。
ロールベースのアクセス制御:アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与すると、Bigtable から予測を読み取るために必要な権限がアプリケーションに付与されます。
正しくないオプション -
オプション A (クエリへの WHERE 句の追加とデータ閲覧者ロールの付与):このオプションでは低レイテンシの要件には対応しておらず、BigQuery を直接クエリしてもレイテンシの目標を達成できない可能性があります。
オプション B (承認済みビューの作成):承認済みビューの作成は、特定のデータへのアクセスを制御するのに役立ちますが、必ずしも低レイテンシーの要件に対応できるわけではなく、低レイテンシーで予測を提供する必要があります。
オプション C(クエリから結果を読み取るための Dataflow パイプラインの作成):このオプションはデータの処理に使用できますが、低レイテンシーの要件には対応しておらず、低レイテンシーで予測を提供するソリューションが必要になります。
</div></details>

### Q. 質問23: 未回答
貴社のデータ アナリストは、プロジェクトで Cloud IAM オーナーのロールを保持し、さまざまな GCP プロダクトでの作業を円滑に進めます。会社のポリシーにより、BigQuery のデータ アクセスログを 6 か月間保持することが義務付けられています。あなたの仕事は、これらのログへのアクセスを、すべてのプロジェクトにわたって指定された監査担当者に制限することです。
これを達成するには、どのような手順を踏む必要がありますか?
1. 　
2. 
3. 
4. 集計されたエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。エクスポートされたログを含むプロジェクトへのアクセスを制限します。
<details><div>
    答え：4
説明
社内の監査担当者のみがすべてのプロジェクトのデータアクセスログにアクセスでき、ログを 6 か月間保持できるようにするための正しいアプローチは、オプション D です。
オプション D: 
このオプションが最も適している理由は次のとおりです。
集約されたエクスポート シンク:集約されたエクスポート シンクを使用すると、複数のプロジェクトから 1 つの場所にログをエクスポートできるため、監査ログの一元的な管理とアクセスが容易になります。
クラウドストレージバケット:Cloud Storage バケットへのログのエクスポートは、ログを安全に保存するための一般的で効率的な方法です。
監査ログ用に新しく作成されたプロジェクト:監査ログ専用の別のプロジェクトを作成すると、ログを分離してセキュリティで保護するのに役立ちます。このプロジェクトにアクセスできるのは、許可された担当者のみです。
アクセスの制限:エクスポートされたログを含むプロジェクトでIAMポリシーとアクセス制御を設定することで、アクセスを監査担当者のみに制限し、許可された個人のみがログにアクセスして確認できるようにすることができます。
正しくないオプション -
オプション A: 各データ アナリストのプロジェクトでデータ アクセス ログを有効にします。Cloud IAM ロールによる Stackdriver Logging へのアクセスを制限します。
このオプションでは、各データ アナリストのプロジェクトでデータ アクセス ログを個別に有効にしてから、Stackdriver Logging へのアクセスを制限します。ただし、このオプションにはいくつかの欠点があります。
複雑さ：複数のプロジェクトでデータアクセスログを個別に有効にすることは、特にプロジェクトとデータアナリストの数が増えるにつれて、管理が複雑になる可能性があります。
限定的な中央集権化:ログは複数のプロジェクトに分散し、アクセス制御を効果的に一元化して管理することが困難になります。
潜在的なギャップ:個々のプロジェクト構成によっては、一部のログがキャプチャされず、監査にギャップが生じる可能性があります。
限定的な保持制御:すべてのプロジェクトで一貫した保持期間を管理することは困難な場合があります。
オプション B: プロジェクトレベルのエクスポート シンクを介して、データ アナリストのプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。Cloud Storage バケットへのアクセスを制限します。
このオプションでは、各データアナリストのプロジェクト内の Cloud Storage バケットにログをエクスポートし、アクセスを制限します。問題は次のとおりです。
分散ストレージ:ログは複数のプロジェクトに分散され、中央監査が複雑になる可能性があります。
限定的な制御:データアクセスログの保持とアクセス制御は、プロジェクトごとに個別に管理されるため、統一されたポリシーを適用することは困難でした。
アクセスの複雑さ:プロジェクトごとに個々の Cloud Storage バケットのアクセス制御を管理するのは面倒な場合があり、権限の一貫性を確保するのは困難です。
オプション C: プロジェクトレベルのエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータ アクセス ログをエクスポートします。エクスポートされたログでプロジェクトへのアクセスを制限します。
このオプションでは、監査ログ用の新しいプロジェクトを作成しますが、個々のプロジェクトからログをエクスポートします。このアプローチには、次のような問題があります。
散在エクスポート:監査ログ用の中央プロジェクトを作成しても、ログは個々の Data Analyst プロジェクトからエクスポートされるため、一元化されません。
アクセス制御の複雑さ:ログを含む中央プロジェクトでのアクセス制御の管理は複雑になる可能性があり、アクセスを完全に一元化するわけではありません。
保持管理:一貫した保存期間を確保することは、依然として困難な場合があります。
</div></details>

### Q. 質問42: 未回答
サードパーティ企業に分析のために BigQuery のデータセットへのアクセス権を付与する際に、データの鮮度を維持し、データ共有費用を最小限に抑えるには、どのソリューションを選択すればよいでしょうか?
1. 　Analytics Hub を使用してデータ アクセスを制御し、サードパーティ企業にデータセットへのアクセスを提供します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
Analytics Hubを使用してデータアクセスを制御することは、コストを低く抑え、データを最新の状態に保ちながら、サードパーティ企業にデータセットへのアクセスを提供できるため、最適なソリューションです。
正しくないオプション -
Cloud Scheduler はジョブとタスクのスケジュール設定に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション B は正しくありません。
BigQuery で別のデータセットを作成することは、最も費用対効果の高いソリューションではなく、データが最新であることを保証できないため、オプション C は正しくありません。
Dataflow はデータの処理と変換に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション D は正しくありません。
</div></details>

### Q. 質問43: 未回答
現在、オンプレミスのデータ ウェアハウス ソリューションを BigQuery に移行している会社では、さまざまなトランザクション データベース ソースからの更新を毎日適用するために、変更データ キャプチャ(CDC)プロセスを強化したいと考えています。この改善は、データ ウェアハウス変更アプリケーションのパフォーマンスの最適化に重点を置き、ログベースの CDC ストリームを介して BigQuery でソース システムからの変更にすばやくアクセスできるようにすることを目的としています。BigQuery レポートの表で変更を利用できるようにするためのレイテンシを最小限に抑えながら、コンピューティングのオーバーヘッドを削減するには、どの 2 つのアクションを実行すべきでしょうか。(2つ選択)
1. 　DML INSERT、UPDATE、または DELETE を実行して、個々の CDC レコードをレポート テーブルに直接リアルタイムで直接レプリケートします。
2. 新しい各 CDC レコードと対応する操作の種類をステージング テーブルにリアルタイムで挿入します。
3. レポート テーブルから古いレコードを定期的に削除します。
4. DML MERGE を定期的に使用して、レポート テーブルで複数の DML INSERT、UPDATE、および DELETE 操作を同時に実行します。
5. 新しい各 CDC レコードと対応する操作の種類をレポート テーブルにリアルタイムで挿入し、具体化されたビューを使用して、一意の各レコードの最新バージョンのみを公開します。
<details><div>
    答え：2,4
説明
B. 
この手順は、ソース システムから変更をリアルタイムでキャプチャし、ステージング テーブルに格納するために不可欠です。ステージング テーブルは、受信 CDC データのバッファーを提供し、データをレポート表に移動する前に、必要なビジネス ロジックを検証、変換、および適用できます。このアプローチは、レポート データセットの一部になる前に、データの一貫性と正確性を確保するのに役立ちます。
D. 
定期的な MERGE 操作の使用は、累積された変更をステージング テーブルからレポート テーブルに適用するための効果的な戦略です。これにより、複数の CDC レコードを 1 つの DML 操作に統合し、個々の INSERT、UPDATE、または DELETE に関連するオーバーヘッドを削減できます。このアプローチにより、計算コストが最適化され、レポート テーブルを効率的に維持できます。
正しくないオプション -
A. DML INSERT、UPDATE、または DELETE を実行して、個々の CDC レコードをレポート テーブルに直接リアルタイムで直接レプリケートします。
このオプションを使用すると、すべての CDC レコードのレポート テーブルで個々の DML 操作が大量に発生する可能性があり、リソースを大量に消費し、最適なクエリ パフォーマンスが得られない可能性があります。
C. レポート テーブルから古いレコードを定期的に削除します。
古いレコードの削除はデータ管理に必要ですが、CDC データのほぼリアルタイムの処理要件には対応していません。このオプションは、タイムリーな更新ではなく、データ保持に重点を置いています。
E. 新しい各 CDC レコードと対応する操作の種類をレポート テーブルにリアルタイムで挿入し、具体化されたビューを使用して、一意の各レコードの最新バージョンのみを公開します。
具体化されたビューはクエリのパフォーマンスを最適化するのに役立ちますが、このアプローチでは CDC データ自体のリアルタイム処理には対応していません。具体化されたビューは、通常、集計または概要を事前に計算するために使用され、リアルタイムのデータキャプチャや変換用には設計されていません。
待機時間を最小限に抑え、コンピューティング オーバーヘッドを削減してほぼリアルタイムの CDC を実現するには、手順 B と D を組み合わせることをお勧めします。ステージング テーブル (B) で変更をリアルタイムでキャプチャし、これらの変更をレポート テーブル (D) に定期的にマージして、データセットを効率的に更新します。
</div></details>

### Q. 質問46: 未回答
金融機関は、機密性の高い顧客データを安全に保管し、規制コンプライアンスを確保する必要があります。これには、暗号化、監査ログ、きめ細かなアクセス制御を備えたマネージド・データベース・サービスが必要です。どのGCPサービスを選ぶべきか?
1. 　Cloud SQL
2. Bigtable
3. Firestore
4. BigQuery
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. 
Cloud SQL は、機密データを処理するように設計された Google Cloud のマネージド リレーショナル データベース サービスです。保存中および転送中の暗号化、自動バックアップ、きめ細かなアクセス制御などの機能を提供します。これは、規制コンプライアンスと機密性の高い顧客データの安全なストレージを必要とするアプリケーションに適しています。構造化されたリレーショナルデータベースの使用は、取引データやコンプライアンスの目的で金融機関で好まれることがよくあります。
正しくないオプション -
B. Bigtable は、主に高スループットでスケーラブルなワークロード向けに設計された NoSQL データベースであり、機密性の高い顧客データを安全に保存し、規制コンプライアンスを確保するには最適な選択肢ではない可能性があります。Cloud SQL と同じレベルの組み込みのセキュリティ機能やコンプライアンス機能は提供されません。
C. Firestore は、一般的に柔軟でスキーマレスのデータ ストレージに使用される NoSQL ドキュメント データベースですが、金融機関が必要とする特定のセキュリティおよびコンプライアンス機能を提供しない場合があります。Firestore は通常、より柔軟で俊敏なデータ ストレージのニーズに合わせて選択されます。
D. BigQuery は、大規模なデータセットの分析とクエリに使用される、サーバーレスで拡張性の高いデータ ウェアハウスです。データ分析には使用できますが、主にトランザクション データベースではなく、Cloud SQL と同じレベルのセキュリティとコンプライアンス機能を提供していません。
Cloud SQL は、必要なセキュリティとコンプライアンスの機能に加えて、機密性の高い顧客データを金融機関に安全に保管するために必要な構造を備えているため、最も適切な選択肢です。
</div></details>

### Q. 質問47: 未回答
あなたの会社は、投稿、コメント、いいねなどのユーザー生成コンテンツを保存するために、柔軟でスキーマレスなデータベースを必要とするソーシャルメディアプラットフォームを開発しています。このシナリオに適したGCPデータベースサービスはどれですか?
1. 　BigQuery
2. Firestore
3. Cloud Datastore
4. Cloud SQL
<details><div>
    答え：2
説明
この質問の正しい選択肢は B. Firestore です。
このシナリオの要件は、ソーシャル メディア プラットフォームの投稿、コメント、いいねなどのユーザー生成コンテンツを保存することです。時間の経過とともに変化する可能性のある、このユーザー生成コンテンツのさまざまな構造に対応するには、柔軟なスキーマレスデータベースが必要です。
Firestore は、柔軟でスキーマレスなデータ ストレージを提供する NoSQL ドキュメント データベースです。非構造化データや半構造化データを簡単に処理できるため、ユーザーが作成したコンテンツをソーシャルメディアプラットフォームに保存するための優れた選択肢となります。Firestore は、このようなアプリケーションに不可欠なリアルタイムの同期とスケーラビリティも提供します。
正しくないオプション -
A. BigQueryの場合:BigQuery は分析用のデータ ウェアハウスであり、ユーザーが生成したコンテンツを保存するための柔軟なスキーマレス データベースではありません。構造化データに対して複雑なSQLクエリを実行するように設計されているため、ソーシャルメディアの投稿やコメントなどの非構造化コンテンツや半構造化コンテンツにはあまり適していません。
C. クラウドデータストア:Cloud Datastore も Google Cloud が提供する NoSQL データベースですが、より最新の機能と優れたスケーラビリティにより、Firestore がほぼこれに取って代わりました。このシナリオでも Cloud Datastore は機能しますが、新しいプロジェクトでは一般的に Firestore をおすすめします。
D. Cloud SQL:Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。固定スキーマが適用されるため、ソーシャルメディアプラットフォームにおけるユーザー生成コンテンツの柔軟でスキーマレスな性質にはあまり適していません。Cloud SQL は、構造化データ ストレージとリレーショナル データベースのニーズに適しています。
</div></details>

### Q. 質問48: 未回答
オンラインゲーム会社は、スコア、実績、ゲームの進行状況などのプレーヤー統計をリアルタイムで保存して処理したいと考えています。頻繁な更新とクエリを処理できるデータベースが必要です。どのGCPサービスをお勧めしますか?
1. 　Bigtable
2. Cloud Datastore
3. BigQuery
4. Cloud SQL
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. Bigtable
このシナリオでは、オンラインゲーム会社は、頻繁な更新とクエリを使用して、プレーヤーの統計をリアルタイムで保存および処理する必要があります。Bigtable は、Google Cloud Platform(GCP)上の NoSQL で拡張性が高く、低レイテンシのデータベース サービスであり、大量のデータを高い読み取りおよび書き込みスループットで処理するように設計されています。
リアルタイム データ処理: Bigtable は、リアルタイム データを低レイテンシで処理することに優れているため、ゲームプレイ中にリアルタイムで更新されるプレイヤーの統計情報を保存および処理するのに適しています。
スケーラビリティ: Bigtable は、多数のプレイヤーと広範な統計を扱うゲーム会社にとって不可欠な、大量のデータに対応するために簡単に拡張できます。
頻繁な更新とクエリ: Bigtable の設計は、高頻度の読み取りおよび書き込み操作に最適化されているため、プレイヤーの統計情報の記録と取得に適しています。
正しくないオプション -
B. クラウドデータストア:
Cloud Datastore も NoSQL データベースですが、一般的には、より構造化されたトランザクション データ ストレージを必要とするアプリケーションに適しています。頻繁な更新とクエリを伴うリアルタイムのゲーム統計については、Bigtable ほどパフォーマンスが高くない可能性があります。
C. BigQueryの場合:
BigQuery は、大規模なデータセットの分析とクエリ用に設計されたデータ ウェアハウス サービスです。これは、このシナリオの主要な要件であるリアルタイムのデータストレージと処理にはあまり適していません。
D. Cloud SQL:
Cloud SQL は、マネージド リレーショナル データベース サービスです。構造化データやトランザクションデータには適していますが、頻繁な更新やクエリを伴うリアルタイムのゲーム統計に必要なパフォーマンスとスケーラビリティを提供しない場合があります。
Bigtable は、リアルタイム処理機能、スケーラビリティ、頻繁な更新やクエリを処理する能力など、ゲーム会社のプレイヤー統計の要件に合致しているため、最も適切な選択肢です。
</div></details>

### Q. 質問49: 未回答
組織はニュース Web サイトを運営しており、ユーザーの行動データを分析してコンテンツのレコメンデーションをパーソナライズする必要があります。リアルタイムのデータストリーミングと複雑な分析を効率的に処理できるGCPデータベースサービスはどれですか?
1. 　Cloud Pub/Sub
2. Bigtable
3. Firestore
4. BigQuery
<details><div>
    答え：4
説明
質問の正しいオプションは D. BigQuery です。
BigQuery は、フルマネージドのサーバーレス データ ウェアハウスであり、リアルタイムのデータ ストリーミングや複雑な分析の処理に適しています。BigQuery は、大規模なデータセットの複雑な分析に優れたデータ ウェアハウスおよび分析プラットフォームです。ストリーミング挿入などの機能を通じてリアルタイムのデータストリーミングを効率的に処理でき、強力な分析のためのSQLのようなクエリ言語を提供します。これは、ユーザーの行動データに対して複雑なクエリを実行してコンテンツのレコメンデーションをパーソナライズするのに適しており、このシナリオに最も適した選択肢です。
コンテンツのレコメンデーションをパーソナライズするためにユーザーの行動データを分析する必要がある場合や、リアルタイムのデータ ストリーミングと複雑な分析が必要な場合、BigQuery は要件に最適な GCP データベース サービスです。
正しくないオプション -
A. Cloud Pub/Sub の場合: Cloud Pub/Sub は、イベントドリブン システムの構築とデータのストリーミングのためのメッセージング サービスです。データのストリーミングには便利ですが、BigQuery のようなデータベース サービスではなく、複雑な分析は実行しません。これは通常、メッセージ キューイングとイベント ドリブン アーキテクチャに使用されます。
B. Bigtable の場合: Bigtable は、高スループット、低レイテンシ、スケーラビリティを実現するように設計された NoSQL データベースです。大量のデータへの高速な読み取りおよび書き込みアクセスを必要とするアプリケーションには適していますが、複雑な分析には最適化されていません。Bigtable は、時系列データやキー値ストレージなどのユースケースに適しています。
C. Firestore: Firestore は、モバイル アプリケーションやウェブ アプリケーション向けに設計された NoSQL データベースです。リアルタイム データを処理できますが、主にトランザクション データに使用され、複雑な分析には使用されません。これはドキュメントベースのストレージ用に設計されており、クライアント間でデータをリアルタイムで同期する必要があるアプリケーションに適しています。
</div></details>

## 3
### Q. 質問2: 未回答
地震データを解析するシステムを設計します。抽出、変換、読み込み (ETL) プロセスは、Apache Hadoop クラスターで一連の MapReduce ジョブとして実行されます。ETLプロセスでは、一部のステップで計算コストがかかるため、データセットの処理に数日かかります。次に、センサーのキャリブレーション手順が省略されていることがわかります。今後、センサーのキャリブレーションを体系的に実施するために、ETLプロセスをどのように変更する必要がありますか?
1. 　
2. 新しい MapReduce ジョブを導入して、センサーのキャリブレーションを生データに適用し、この後、他のすべての MapReduce ジョブがチェーンされるようにします。
3. 
4. 
<details><div>
    答え：2
説明
正しいアプローチは B です。 
オプションBでは、センサーキャリブレーション専用のMapReduceジョブを導入し、すべてのデータがこの重要なステップを経てからさらに処理されるようにします。センサーキャリブレーションの省略に対処するための体系的かつ組織的な方法を提供し、ETLパイプラインで処理されるすべてのデータが将来一貫してキャリブレーションされることを保証します。
正しくないオプション -
A. 変換 MapReduce ジョブを変更して、他の処理を行う前にセンサーのキャリブレーションを適用します。
このオプションは、既存の変換ジョブを変更するだけなので、過去のセンサー調整の省略の問題には対処しません。今後のデータはキャリブレーションされますが、キャリブレーションされていないデータを遡及的に修正することはありません。
C. ETL プロセスの出力にセンサー キャリブレーション データを追加し、すべてのユーザーがセンサー キャリブレーションを自分で適用する必要があることを文書化します。
このオプションでは、センサのキャリブレーションの責任がエンドユーザーに移るため、体系的で信頼性の高いプロセスには理想的ではありません。ユーザーはキャリブレーションを忘れたり、誤って適用したりして、不整合につながる可能性があります。
D. シミュレーションを通じてアルゴリズムを開発し、キャリブレーション係数に基づいて最後の MapReduce ジョブから出力されたデータ出力の分散を予測し、その補正をすべてのデータに適用します。
このアプローチは洗練されているように聞こえますが、シミュレーションと予測に依存しているため、信頼性の高いセンサーのキャリブレーションには十分な精度が得られない可能性があります。また、複雑で、ある程度の不確実性が生じます。
</div></details>

### Q. 質問3: 未回答
オンライン小売業者の既存のアプリケーションは、Google App Engine でホストされています。新しい会社のイニシアチブでは、顧客との直接取引を可能にするためにアプリケーションを拡張しる必要があります。ビジネス インテリジェンス(BI)ツールを使用してショッピング トランザクションを効果的に管理し、複数のソースからのデータを分析するために、単一の Google Cloud データベースを活用することを目指しています。この要件には、どの Google Cloud データベースを選択すればよいでしょうか?
1. 　
2. Cloud SQL
3. 
4. 
<details><div>
    答え：2
説明
オンライン小売業者がショッピング トランザクションを管理する必要があるこのシナリオでは、データベース ソリューションとして Cloud SQL(オプション B)を選択するのが適切です。
Cloud SQL が適している理由は次のとおりです。
トランザクション データ: Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。これは、トランザクション データの保存と管理用に設計されており、ショッピング トランザクションを管理する要件と一致しています。
ACIDコンプライアンス: Cloud SQLデータベースは、ACID(原子性、一貫性、分離性、耐久性)に準拠し、トランザクションの信頼性と一貫性を確保します。
互換性: 小売業者の既存のアプリケーションがすでに Google App Engine で実行されている場合、Cloud SQL は App Engine とシームレスに統合されるため、自然な選択です。
BIツールの統合:Cloud SQLは、さまざまなBIツールのデータソースとして使用でき、小売業者は必要に応じてデータ分析を実行できます。
構造化データ: Cloud SQL は構造化データに適していますが、これは通常、トランザクション システムの場合です。
正しくないオプション -
BigQuery(オプション A): BigQuery は分析ワークロードや大規模なデータセットのクエリには優れていますが、通常、トランザクション データのプライマリ データベースとしては使用されません。これは、履歴データまたは集計データの保存と分析に適しています。
Cloud Bigtable(オプション C): Cloud Bigtable は、高スループット、低レイテンシの読み取り/書き込みオペレーション用に最適化された NoSQL データベースです。これは、大規模なリアルタイムのデータアクセスを必要とするアプリケーションに適していますが、従来のトランザクションデータには最適な選択ではない可能性があります。
Cloud Datastore(オプション D):Cloud Datastore は、高可用性とスケーラビリティを必要とするアプリケーションに適した NoSQL データベースです。ただし、一般的には非構造化データまたは半構造化データに使用され、トランザクション データ管理には適していない場合があります。
</div></details>

### Q. 質問5: 未回答
分析チームは、さまざまな指標を利用して、会社と再び関わる可能性が高い顧客を特定するための基本的な統計モデルを作成しようとしています。このモデルは Apache Spark を使用して実行し、データは Google Cloud Storage に保存される予定で、このタスクに Google Cloud Dataproc を利用することを提案しました。初期テストでは、このジョブは 30 ノード クラスタで約 15 分で完了し、結果は Google BigQuery に保存されることが示されています。目的は、このタスクを毎週実行することです。コスト効率を高めるためにクラスタ構成を最適化するにはどうすればよいでしょうか。
1. 　ワークロードを Google Cloud Dataflow に移行します。
2. クラスターにプリエンプティブル仮想マシン (VM) を使用します。
3. メモリの大きいノードを使用して、ジョブの実行を高速化します。
4. ワーカー ノードで SSD を使用して、ジョブの実行を高速化します。
<details><div>
    答え：2
説明
Google Cloud Dataproc の Apache Spark で週単位のワークロードを実行する際に、クラスタのコストを最適化するための正しいオプションは次のとおりです。
B. 
プリエンプティブル VM: プリエンプティブル VM は、標準のオンデマンド VM よりも大幅に安価であるため、Google Cloud の費用対効果の高いオプションです。ただし、Google Cloud によっていつでもプリエンプト(終了)される可能性があり、通常は短期間(最大 24 時間)でプリエンプト(終了)される可能性があります。週単位の統計モデルの実行など、長期的なアップタイムを必要としないワークロードでは、プリエンプティブル VM を使用すると、かなりのコストを節約できます。
正しくないオプション -
A. 
Google Cloud Dataflow への移行はオプションかもしれませんが、これは別のテクノロジーであり、既存の Apache Spark ベースのワークロードに大幅な変更が必要になる場合があります。これにより、複雑さが増し、開発作業が増える可能性があります。また、Dataflow と Dataproc のコストへの影響は、特定のユースケースによって異なります。
C. 
メモリの大きいノードを使用すると、ジョブのパフォーマンスが向上する可能性がありますが、コストが大幅に増加する可能性もあります。コストを最適化するこのシナリオでは、特にジョブが小さなプリエンプティブル ノードで効率的に実行される場合、より大きなノードを選択することは最も効率的なアプローチではない可能性があります。
D. 
ワーカー ノードに SSD を追加すると、データの読み取り/書き込みパフォーマンスが向上する可能性がありますが、必ずしもコスト最適化戦略ではありません。SSD はインフラストラクチャ コストを増加させる可能性があり、30 ノード クラスターで既に 15 分で実行されているジョブのパフォーマンス向上は大きくない可能性があります。コストの最適化が主な目的である場合、このオプションは最適な選択ではない可能性があります。
</div></details>

### Q. 質問6: 未回答
会社は、バッチベースとストリームベースのイベントデータの両方を受信します。Google Cloud Dataflow を使用して、予測可能な期間にわたってデータを処理したい。ただし、場合によっては、データが遅れたり、順序どおりに届かなかったりすることがあります。
遅延したデータや順序が正しくないデータを処理するために、Cloud Dataflow パイプラインをどのように設計すればよいですか?
1. 　
2. 
3. 透かしとタイムスタンプを使用して、時間差データをキャプチャします。
4. 
<details><div>
    答え：3
説明
Google Cloud Dataflow パイプラインで遅延または順序が正しくないデータを処理するには、次のことを行う必要があります。
C. 
ウォーターマークとタイムスタンプ: Google Cloud Dataflow のようなストリーム処理パイプラインでは、ウォーターマークとタイムスタンプは、遅延データや順不同のデータを処理するために不可欠な概念です。ウォーターマークはイベント時間の進行状況を表し、特定の期間にデータが完了したと見なすのが安全である時期を Dataflow が理解するのに役立ちます。タイムスタンプは、イベントがいつ発生したかを示します。
ウォーターマークとタイムスタンプを使用すると、次のことができます。
処理時間ではなくイベント時間に基づいてウィンドウを定義します。これにより、遅れて到着しても、関連する時間枠に属するデータを取得できます。
イベントが到着したときにタイムスタンプを割り当て、ウォーターマークを使用してイベント時間の進行状況を追跡することで、順不同のデータを処理します。Dataflow は、イベントのタイムスタンプに基づいて、適切なウィンドウにイベントを正しく配置できます。
正しくないオプション -
A. すべてのデータを取得するために 1 つのグローバル ウィンドウを設定します。
このアプローチでは、データの遅延や順序の乱れの問題には対処できません。すべてのデータが 1 つのウィンドウにあるかのように扱われ、指定された時間枠の後に到着したイベントを正しく処理するために必要な柔軟性は提供されません。
B. スライディング ウィンドウを設定して、すべての時間差データをキャプチャします。
スライディング ウィンドウは、一定の間隔でデータをキャプチャする場合に便利ですが、本質的に遅延データや順序が正しくないデータは処理されません。遅延データはスライディング ウィンドウの範囲外にある可能性があり、スライディング ウィンドウのみを使用してそのようなデータを処理するのに十分ではない可能性があります。
D. すべてのデータソースの種類 (ストリームまたはバッチ) にタイムスタンプがあることを確認し、タイムスタンプを使用して時間差データのロジックを定義します。
データソースにタイムスタンプを付けることはおすすめの方法ですが、Dataflow パイプライン内で遅延したデータや順序が正しくないデータを処理するという主要な問題には対処できません。タイムスタンプだけでは、イベント時間処理の複雑さを処理し、遅延データが処理ウィンドウで正しく考慮されるようにするには不十分です。
</div></details>

### Q. 質問8: 未回答
Google Cloud でデータ パイプラインを構築しています。機械学習プロセスでは、カジュアルな方法を使用してデータを準備する必要があります。ロジスティック回帰モデルをサポートする場合。また、null 値を監視して調整する必要もありますが、null 値は実数値のままで、削除することはできません。あなたは何をするべきか?
1. 　
2. Cloud Dataprep を使用して、サンプルソースデータ内の null 値を見つけます。Cloud Dataprep ジョブを使用して、すべての null を 0 に変換します。
3. 
4. 
<details><div>
    答え：2
説明
ロジスティック回帰モデル用のデータを準備しながら、実数値を維持する必要がある NULL 値を監視および処理するには、次のオプションを検討する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
Cloud Dataprep: Cloud Dataprep は、データを視覚的に探索、クリーニング、変換できるデータ準備サービスです。null 値を 0 などの特定の値に置き換える機能など、null 値を処理するための使いやすいツールを提供します。
Null 値の処理: 機械学習では、特に実数値の特徴を操作する場合、null 値を 0 などの特定の数値に置き換えるのが一般的です。このアプローチにより、データが実数値のままになり、ロジスティック回帰モデルで効果的に使用できます。
正しくないオプション -
A. Cloud Dataprep を使用して、サンプルのソースデータから null 値を見つけます。Cloud Dataprep ジョブを使用して、すべての null を「none」に変換します。
null を 'none' に変換すると、数値以外の値がデータに導入され、ロジスティック回帰には適していません。ロジスティック回帰には数値入力特徴が必要です。
C. Cloud Dataflow を使用して、サンプル ソース データ内の null 値を検索します。Cloud Dataprep ジョブを使用して、すべての null を「none」に変換します。
Cloud Dataflow は強力なデータ処理サービスですが、通常、単純な null 値の置換タスクには使用されません。さらに、null を 'none' に変換することは、ロジスティック回帰モデルには適していない場合があります。
D. Cloud Dataflow を使用して、サンプルのソースデータで null 値を見つけます。カスタムスクリプトを使用してすべてのnullを0に変換します。
Cloud Dataflow はデータの前処理タスクに使用できますが、カスタム スクリプトを使用して null を 0 に置き換えると、不必要に複雑になる可能性があります。Cloud Dataprep は、このようなデータ準備タスクをよりユーザーフレンドリーで効率的に処理する方法を提供します。
</div></details>

### Q. 質問10: 未回答
Google Cloud で動画レコメンデーション アプリケーションを開発しています。アプリケーションは、顧客が以前に視聴したビデオに基づいて、新しいビデオを顧客に表示する必要があります。また、アプリケーションは、顧客が視聴したビデオ内のエンティティ(俳優、監督、ジャンルなど)のラベルを生成する必要があります。アプリケーションの設計では、数テラバイトのデータに対する他の顧客の好みからのデータに基づいて、非常に高速なフィルタリングの提案を提供できる必要があります。このアプリケーションを実装するには、どのような手順を実行する必要がありますか?
1. 　
2. 
3. Cloud Video Intelligence API を呼び出してラベルを生成するアプリケーションを構築します。Cloud Bigtable にデータを保存し、予測ラベルをフィルタリングしてユーザーの視聴履歴と一致させ、設定を生成します。
4. 
<details><div>
    答え：3
説明
C. 
Cloud Video Intelligence API: Cloud Video Intelligence API は、動画コンテンツの分析に特化して設計されています。ビデオからラベルやその他の洞察を生成できるため、ビデオコンテンツから情報を抽出するタスクに適しています。
Cloud Bigtable: Cloud Bigtable は、大量のデータを効率的に処理できるスケーラブルな NoSQL データベースです。Cloud Bigtable にデータを保存すると、設定のフィルタリングと生成に必要なデータに高速にアクセスできます。
データのフィルタリング: このオプションでは、パーソナライズされたレコメンデーションを作成するために不可欠な、ユーザーの視聴履歴と一致するように予測ラベルをフィルタリングすることを提案します。Cloud Bigtable はこれを効率的に処理できます。
正しくないオプション -
A. Spark MLlib を使用して複雑な分類モデルを構築してトレーニングし、ラベルを生成し、結果をフィルター処理します。Cloud Dataproc を使用してモデルをデプロイします。アプリケーションからモデルを呼び出します。
Spark MLlib と Cloud Dataproc は機械学習のタスクには強力ですが、このタスクに複雑な分類モデルを使用すると、過剰に設計されたソリューションになる可能性があります。Cloud Video Intelligence API などの特殊な API を使用するよりも、リソースを大量に消費し、時間がかかる場合があります。
B. Spark MLlib を使用して分類モデルを構築してトレーニングし、ラベルを生成します。Spark MLlib を使用して 2 番目の分類モデルを構築してトレーニングし、顧客の好みに合わせて結果をフィルター処理します。Cloud Dataproc を使用してモデルをデプロイします。アプリケーションからモデルを呼び出します。
オプション A と同様に、このアプローチでは複雑な分類モデルを使用するため、ビデオ ラベルとレコメンデーションを生成するタスクには必要ない場合があります。これにより、複雑さが増し、メンテナンスのオーバーヘッドが発生します。
D. Cloud Video Intelligence API を呼び出してラベルを生成するアプリケーションを構築します。Cloud SQL にデータを保存し、予測されたラベルを結合してフィルタリングし、ユーザーの視聴履歴と一致させて設定を生成します。
ラベルの生成には Cloud Video Intelligence API の使用が適していますが、大規模なデータの保存とフィルタリングには Cloud SQL が適していない可能性があります。通常、Cloud Bigtable は大量のデータを効率的に処理するのに適しています。
</div></details>

### Q. 質問13: 未回答
あなたは、Google Cloud のデータ パイプラインに大量のテキスト ファイル用のストレージを作成する任務を負っています。目的は、ANSI SQL クエリを有効にし、圧縮を実装し、Google のベスト プラクティスに準拠しながら、入力場所からの並列読み込みを容易にすることです。これらの目標を達成するには、どのような手順を踏む必要がありますか?
1. 　
2. Cloud Dataflow を使用して、テキスト ファイルを圧縮された Avro に変換します。クエリには Cloud Storage と BigQuery の永続的なリンク テーブルを使用します。
3. 
4. 
<details><div>
    答え：2
説明
Google Cloud 上のデータ パイプライン用に非常に大きなテキスト ファイルのストレージを設計し、ANSI SQL クエリをサポートし、Google が推奨するプラクティスに従って入力場所からの圧縮と並列読み込みをサポートするには、次のオプションを検討する必要があります。
B. 
Cloud Dataflow: Cloud Dataflow を使用すると、並列読み込みをサポートしながら、テキスト ファイルを Avro 形式に変換できます。データ変換機能を提供し、大規模なデータセットを効率的に処理できます。
Cloud Storage: 変換されたデータを Cloud Storage に保存することは、効率的なデータ ストレージの一般的な方法です。Cloud Storage は、大量のデータを処理するように設計されており、データの耐久性と可用性を提供します。
BigQuery: データのクエリに BigQuery を使用すると、ANSI SQL を分析に活用できます。Cloud Storage のデータを参照する永続的なリンク テーブルを BigQuery で作成することで、データをクエリするための便利でパフォーマンスの高い方法が提供されます。
正しくないオプション -
A. Cloud Dataflow を使用して、テキスト ファイルを圧縮された Avro に変換します。ストレージとクエリに BigQuery を使用する:
BigQuery は Avro ファイルを保存できますが、Cloud Storage と比較して最も効率的なストレージ形式ではありません。さらに、Cloud Storage を参照する BigQuery でリンク テーブルを使用すると、柔軟性と制御性が向上します。
C. Grid Computing Tools を使用してテキスト ファイルを gzip に圧縮します。ストレージとクエリに BigQuery を使用する:
BigQuery は gzip 圧縮データを処理できますが、このオプションでは、クエリ最適化のためのより構造化された効率的なストレージを提供できる Avro 形式へのテキスト ファイルの変換には対応していません。
D. Grid Computing Tools を使用してテキストファイルを gzip に圧縮します。Cloud Storage を使用し、クエリのために Cloud Bigtable にインポートします。
Cloud Bigtable は、BigQuery のような ANSI SQL クエリの実行ではなく、高スループットで低レイテンシの NoSQL データ向けに設計されています。このオプションは、ANSI SQL クエリをサポートするための要件には適合しておらず、NoSQL ワークロードに適しています。
</div></details>

### Q. 質問15: 未回答
入力データが CSV 形式である Google Cloud 上のデータ パイプライン デプロイ用に 20 TB のテキスト ファイルのストレージを計画する場合、目的は、さまざまなエンジンを介して Cloud Storage のデータにアクセスする複数のユーザーの集計値をクエリするコストを削減することです。この目標を達成するには、どのようなストレージ サービスとスキーマの設計を選択する必要がありますか?
1. 　
2. 
3. ストレージには Cloud Storage を使用します。クエリ用に BigQuery の永続的なテーブルとしてリンクします。
4. 
<details><div>
    答え：3
説明
複数のエンジンを使用して Cloud Storage 内のデータをクエリする複数のユーザーの集計値をクエリするコストを最小限に抑えるには、次のオプションを検討する必要があります。
C. 
クラウドストレージ: 20 TB のテキストファイルを Cloud Storage に保存することは、大量のデータを処理するための費用対効果が高く効率的なオプションです。
BigQuery: BigQuery でデータを永続的なテーブルとしてリンクすると、データに対して SQL クエリを効率的に実行できます。BigQuery は分析用に設計されており、複雑なクエリをサポートし、大規模なデータセットを処理できます。
正しくないオプション -
A. ストレージには Cloud Bigtable を使用します。Compute Engine インスタンスに HBase シェルをインストールして、Cloud Bigtable データをクエリします。
Cloud Bigtable は、BigQuery のような ANSI SQL クエリの実行ではなく、高スループットの NoSQL ワークロード向けに設計されています。HBase をインストールして Compute Engine インスタンスを使用すると、複雑さが増し、ユースケースの費用対効果が高くない可能性があります。
B. ストレージに Cloud Bigtable を使用する。クエリ用に BigQuery の永続的なテーブルとしてリンクする:
BigQuery で Cloud Bigtable データをリンクすることは可能ですが、通常は NoSQL ストレージに特定の要件があり、BigQuery のデータに対して SQL のようなクエリを実行する必要がある場合に使用されます。ただし、CSV テキストデータを処理するには、Cloud Storage の方が費用対効果が高く、わかりやすいオプションです。
D. ストレージには Cloud Storage を使用します。クエリ用に BigQuery の一時テーブルとしてリンクする:
BigQuery でデータを一時テーブルとしてリンクすることは、一時データや永続化する必要のないデータのためのオプションです。20 TB のデータがあるため、効率的なクエリには永続的なテーブルを使用する方が適切です。
</div></details>

### Q. 質問17: 未回答
金融サービス組織は、クラウドテクノロジーに移行し、50TBの金融時系列データをクラウド環境に保存することを目指しています。このデータは頻繁に更新され、新しい情報が継続的にストリーミングされます。同時に、同社は現在のApache Hadoopジョブをクラウドに移行し、このデータから洞察を引き出す予定です。このデータを効果的に保存し、目的のクラウドベースの運用をサポートするには、どの特定の製品を採用する必要がありますか?
1. 　Cloud Bigtable
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
Cloud Bigtable が正しい選択と見なされる理由は次のとおりです。
スケーラビリティ: Cloud Bigtable は、高スループットで水平方向にスケーラブルなワークロード向けに設計された NoSQL データベースです。大量のデータを処理でき、頻繁な更新やデータのストリーミングを行うシナリオに適しています。
低レイテンシー: 特にリアルタイムの洞察が必要な場合に、金融時系列データに不可欠なデータへの低レイテンシーアクセスを提供します。
Apache Hadoop の統合: Cloud Bigtable は HBase API を介して Apache Hadoop と統合されているため、既存の Apache Hadoop ジョブをクラウドに移行して、大幅な変更を行うことなく Bigtable に保存されているデータを分析できます。
正しくないオプション -
B. Google BigQuery:
BigQuery は、大規模なデータセットに対して SQL のようなクエリを実行するのに最適ですが、主要なストレージ ソリューションではありません。これは、生の時系列データを格納するよりも、分析ワークロードに適しています。BigQuery にデータを読み込んで分析することはできますが、特にリアルタイムの更新と低レイテンシのアクセスが不可欠な場合は、50 TB の金融時系列データのプライマリ ストレージには最適ではない可能性があります。
C. Google Cloud Storage:
Cloud Storage はオブジェクト ストレージ サービスであり、Cloud Bigtable のようなデータベース システムと同じリアルタイムのデータ アクセス機能やクエリ機能を提供しない場合があります。Cloud Storage にデータを保存することもできますが、通常は耐久性のあるストレージ レイヤとして使用され、追加の処理を行わないとトランザクションや分析のワークロードには適さない場合があります。
D. Google Cloud データストア:
Cloud Datastore は、特定のユースケースに適した NoSQL データベースですが、大量の財務時系列データを処理し、Apache Hadoop ジョブをサポートするには、Cloud Bigtable と同じレベルのパフォーマンスとスケーラビリティを備えていない可能性があります。
</div></details>

### Q. 質問18: 未回答
組織は、ユーザーレベルのデータを含むテーブルを含む Google BigQuery データセットを維持しています。このデータの集計を他の Google Cloud プロジェクトに公開しながら、ユーザーレベルのデータへのアクセスを制御したいと考えています。さらに、全体的なストレージ コストを最小限に抑え、他のプロジェクトの分析コストがそれらのプロジェクトに割り当てられるようにする必要があります。彼らは何をすべきか?
1. 　
2. 集計結果を提供する新しいデータセットとビューを作成して共有します。
3. 
4. 
<details><div>
    答え：2
説明
ユーザーレベルのデータへのアクセスを制御し、ストレージ コストを最小限に抑え、他のプロジェクトの分析コストがそれらのプロジェクトに割り当てられるようにしながら、Google BigQuery データセットのユーザーレベルのデータの集計を他の Google Cloud プロジェクトに公開するには、組織は次のオプションを検討する必要があります。
B. 
新しいデータセット: 集計結果専用の新しいデータセットを作成することで、集計データをユーザーレベルのデータから分離し、アクセス制御と権限を分離することができます。これは、生のユーザーレベルデータへのアクセスを制御するのに役立ちます。
ビュー: 新しいデータセット内にビューを作成すると、ユーザーレベルのデータから必要な集計を生成するSQLクエリを定義できます。ビューは仮想テーブルとして機能し、データのフィルター処理および集計されたパースペクティブを提供します。
共有: その後、新しいデータセットとそれに関連するビューを他の Google Cloud プロジェクトと共有して、元のデータセット内のユーザーレベルのデータを安全に保ちながら、それらのプロジェクトが集計データにアクセスできるようにすることができます。
コスト管理: データセットとビューを分離することで、コストをより適切に管理および割り当てることができます。新しいデータセットとビューのクエリを実行するときに他のプロジェクトによって発生する分析コストは、それらのプロジェクトに関連付けられ、組織の全体的なコストが最小限に抑えられます。
正しくないオプション -
オプション A の、集計結果を提供する許可済みビューを作成して共有することも有効なアプローチです。ただし、新しいデータセットとビューを作成すると、集計されたデータがユーザーレベルのデータからより適切に分離され、長期的にはよりクリーンでスケーラブルなソリューションになる可能性があります。
オプション C では、集計結果を含む新しいデータセットとテーブルを作成して共有できますが、特にストレージ コストが懸念される場合は、集計を個別のテーブルに具体化するよりも、集計のビューを作成する方が一般的に効率的です。
オプション D は、データセットに dataViewer Identity and Access Management (IAM) ロールを作成して共有を有効にすることですが、それだけでは十分ではありません。それでも、ユーザーレベルのデータへのアクセスを制御しながら、特定の集計結果を提供するために、新しいデータセットまたはビューを作成する必要があります。
</div></details>

### Q. 質問20: 未回答
ニューラルネットワークモデルのトレーニングに数日かかっています。トレーニング速度を上げたい。その他のオプション
1. 　
2. トレーニングデータセットをサブサンプリングします。
3. 
4. 
<details><div>
    答え：2
説明
B. 
説明: トレーニングデータセットのサブサンプリングでは、ニューラルネットワークのトレーニングに、より小さく代表的なデータのサブセットを使用します。このアプローチが効果的な理由はいくつかあります。
計算の高速化: トレーニング データセットが小さいほど、各トレーニング イテレーションで必要な計算とメモリが少なくなり、トレーニング時間が短縮されます。
ノイズの低減: サブサンプリングは、トレーニング データのノイズと分散を減らすのに役立ち、収束の高速化と汎化の向上につながる可能性があります。
仮説の検証: 機械学習では、多くの場合、さまざまなモデル アーキテクチャとハイパーパラメーターを試す必要があります。最初の実験に小さなデータセットを使用すると、モデルの可能性を検証しながら時間を節約できます。
正しくないオプション -
A. テストデータセットをサブサンプリングします。
説明: テスト データセットのサブサンプリングは、トレーニング速度を上げるための一般的な方法ではありません。テスト データセットは、トレーニング後のモデルのパフォーマンスを評価するために使用されます。テストデータセットのサイズを変更すると、評価結果に影響を与える可能性があり、トレーニングプロセスは高速化されません。モデルの汎化パフォーマンスを正確に評価するには、代表的なテスト データセットを維持することが不可欠です。
C. モデルへの入力特徴の数を増やします。
説明: 通常、入力特徴の数を増やすと、モデルが複雑になり、その結果、トレーニング時間が長くなります。機能を追加すると、モデルの次元が増加する可能性があり、トレーニングにより多くの計算リソースと時間が必要になる場合があります。このオプションは、トレーニングを高速化するよりも遅くする可能性が高くなります。
D. ニューラルネットワークの層数を増やします。
説明: ニューラルネットワークに層を追加すると、ニューラルネットワークが深くなり、複雑になる可能性があります。ディープ ネットワークはデータの複雑なパターンをキャプチャできますが、特に多くのパラメーターが含まれている場合は、トレーニングに時間がかかることがよくあります。レイヤー数を増やすことは、トレーニングを高速化するための推奨される戦略ではありません。これにより、トレーニング時間が長くなり、追加の計算リソースが必要になる場合があります。
</div></details>

### Q. 質問22: 未回答
会社では、GCP とのハイブリッド デプロイを維持しており、匿名化された顧客データに対して分析が実行されます。データは、GCP で実行されているデータ転送サーバーへの並列アップロードを通じて、データセンターから Cloud Storage にインポートされます。経営陣は、毎日の転送に時間がかかりすぎることを通知し、問題を解決するように求めました。転送速度を最大にしたい。どのアクションを実行する必要がありますか?
1. 　
2. 
3. データセンターから GCP へのネットワーク帯域幅を増やします。
4. 
<details><div>
    答え：3
説明
データセンターから Google Cloud Storage への毎日のアップロードの転送速度を最大化するには、次の点を考慮する必要があります。
C. 
ネットワーク帯域幅: データセンターと Google Cloud 間のデータ転送速度は、利用可能なネットワーク帯域幅に大きく依存します。データセンターから GCP へのネットワーク帯域幅を増やすことで、Cloud Storage へのデータのアップロード速度を向上させることができます。
ボトルネック:多くの場合、データ転送が遅いのは、クラウドインフラストラクチャ内ではなく、データセンター側の帯域幅の制限が原因です。データセンターの帯域幅を増やすことで、このボトルネックを軽減できます。
正しくないオプション -
オプション A と B(CPU サイズまたはサーバー上の Google Persistent Disk のサイズを増やす)は、主にサーバーの処理能力とストレージ能力に影響します。これらのアップグレードは、サーバーがボトルネックになっている場合は役立つ可能性がありますが、ネットワーク帯域幅が主な制限要因である場合、データ転送速度を大幅に向上させることはできません。
オプション D(Compute Engine から Cloud Storage へのネットワーク帯域幅の増加)は、Google Cloud インフラストラクチャ自体でボトルネックが発生した場合に役立ちます。ただし、この質問はデータセンターからの毎日のアップロードを改善することに焦点を当てているため、最も効果的なアクションは、データセンターからGCPへのネットワーク帯域幅に対処することです(オプションC)。
</div></details>

### Q. 質問24: 未回答
あなたは、それぞれ異なる優先順位と予算を持つ複数の事業部門を持つ大企業のBI責任者です。オンデマンドを使用する BigQuery の料金(プロジェクトあたり 2K の同時オンデマンド スロットの割り当てあり)。組織のユーザーは、クエリを実行するためのスロットを取得しない場合があり、これを修正する必要があります。アカウントに新しいプロジェクトを導入しないようにしたい。あなたは何をするべきか?
1. 　
2. 
3. 定額価格に切り替え、プロジェクトの階層的な優先順位モデルを確立します。
4. 
<details><div>
    答え：3
説明
プロジェクトごとに 2K のオンデマンド同時スロットの割り当てがあり、新しいプロジェクトの導入を避けたい場合に、ユーザーが BigQuery でクエリを実行するスロットを取得できないという問題に対処するには、次の点を考慮する必要があります。
C. 
定額料金: BigQuery で定額料金に切り替えると、割り当て制限のあるオンデマンド スロットに頼るのではなく、組織専用の固定数のスロットを購入できます。これにより、より予測可能で一貫性のあるクエリパフォーマンスが実現します。
階層型優先度モデル: 定額価格設定では、プロジェクトの階層型優先度モデルを確立できます。組織内の各部署またはプロジェクトに、優先順位と予算に基づいて特定の数のスロットを割り当てることができます。これにより、重要な事業部門は、リソース割り当ての制御を維持しながら、必要なリソースを確実に取得できます。
正しくないオプション -
オプション A (バッチ クエリを対話型クエリに変換する) は、クエリの実行を最適化することである程度役立つ場合がありますが、根本的なリソース割り当ての問題には対処しません。
オプション B (追加のプロジェクトの作成) は複雑さを増すため、既存のプロジェクト内でリソース割り当てを効果的に管理できる場合、最も効率的なソリューションではない可能性があります。
オプション D([割り当て] ページでプロジェクトごとの同時スロット数を増やす)は、Google Cloud の割り当てポリシーの対象となるため実現できない可能性があり、定額料金と階層的な優先度モデルが提供するレベルのリソース管理と制御が提供されない可能性があります。
</div></details>

### Q. 質問26: 未回答
Hadoop ジョブをオンプレミス クラスタから dataproc と GCS に移行しました。Spark ジョブは、多くのシャッフル操作で構成される複雑な分析ワークロードであり、初期データは Parquet ファイル (それぞれ平均 200 から 400 MB のサイズ) です。Dataproc への移行後にパフォーマンスが低下したため、最適化する必要があります。組織はコストに敏感な組織であるため、このワークロードではプリエンプティブル(2 つの非プリエンプティブル ワーカーのみ)で Dataproc を引き続き使用する必要があります。あなたは何をするべきか?
1. 　Parquetファイルのサイズを大きくして、最小1GBになるようにする
2. 
3. 
4. HDD から SSD に切り替え、プリエンプティブル VM 構成をオーバーライドして、ブート ディスク サイズを増やします。
<details><div>
    答え：1
説明
既存にプロセスをコスト増に繋がらない形でチューニングする必要があります。
従って、プロセスで使用しているコンピューティングリソース自体の最適化は避けるべきです。
Parquet は効率的なカラム型ファイル形式であり、Spark でアプリケーションの実行に必要なデータのみを読み取ることができます。
SparkジョブでParquetファイルを使用する場合、ファイルサイズの目安は1GBと言われています。
今回のケースでは、Parquetサイズが200~400MBと小さいため、この点は改善の余地がある点になります。
したがって、正解は「Parquetファイルのサイズを大きくして、最小1GBになるようにする」です。
参照：
https://cloud.google.com/dataproc/docs/support/spark-job-tuning
https://cloud.google.com/architecture/hadoop/hadoop-gcp-migration-jobs
https://community.databricks.com/s/question/0D53f00001HKHWDCA5/what-is-an-optimal-size-for-file-partitions-using-parquet

誤り説明
D. 
SSD への切り替え: HDD を SSD に交換すると、I/O パフォーマンスが大幅に向上します。SSD は HDD と比較して読み取りと書き込みの速度が速いため、シャッフル操作やデータ集約型のワークロードを伴う Spark ジョブに役立ちます。
ブート ディスク サイズの増加: プリエンプティブル VM のブート ディスク サイズを増やすことで、オペレーティング システムと Spark によって生成される一時データの両方により多くのストレージ容量を提供します。これにより、潜在的なストレージのボトルネックを回避し、Sparkジョブに十分な一時ストレージを確保できます。
正しくないオプション -
A. Parquet ファイルのサイズを増やして、最小 1 GB になるようにします。
Parquet ファイルのサイズを大きくしても、HDD の使用によって引き起こされる I/O パフォーマンスの問題に直接対処できない場合があります。 ファイル サイズが大きくなると、HDD の読み取り/書き込み速度の低下に関連するパフォーマンスの低下を完全に軽減できない場合があります。
B. Parquet ファイルではなく、TFRecords 形式 (ファイルあたり約 200 MB) に切り替えます。
ファイル形式を変更すると、ストレージのオーバーヘッドを削減できる場合がありますが、基になる HDD 関連の I/O パフォーマンスの問題に直接対処するわけではありません。
C. HDD から SSD に切り替え、GCS から HDFS に初期データをコピーし、Spark ジョブを実行して、結果を GCS にコピーします。
SSDに切り替えてHDFSを使用すると、ストレージとデータの局所性に役立ちますが、コスト削減のために引き続き使用したいとおっしゃった既存のプリエンプティブルVMは活用されません。
</div></details>

### Q. 質問27: 未回答
社内で ETL の開発とメンテナンスを担当するチームとして、入力データのエラーが原因で Dataflow ジョブの 1 つが失敗する状況に遭遇しました。失敗したすべてのデータを再処理する機能など、パイプラインの信頼性を高めるには、どのような手順を実行する必要がありますか?
1. 　
2. 
3. 
4. try...catch ブロックをデータを変換する DoFn に追加し、sideOutput を使用して、後で Pub/Sub に保存できる PCollection を作成します。
<details><div>
    答え：4
説明
Dataflow パイプラインの信頼性(失敗したすべてのデータを再処理する機能など)を向上させるには、次の点を考慮する必要があります。
D. 
try...catch ブロック:トライを追加しています...DoFn 内の catch ブロックを使用すると、データ変換中のエラーを適切に処理できます。エラーが発生した場合は、それをキャッチして特定のアクションを実行できます。
サイド出力: Dataflow で sideOutput を使用すると、別の PCollection を作成して、エラーのあるデータ レコードをキャプチャできます。エラーが発生した場合は、問題のあるレコードをこちら側の出力に出力して、メインのデータ処理フローを中断しないようにすることができます。
Pub/Sub への保存: エラーのあるレコードを PCollection に保存し、後で Pub/Sub に送信できるようにすることで、データを再処理することができます。Pub/Sub は、再処理や詳細な分析が必要なデータの信頼性の高いメッセージ ブローカーとして機能します。
正しくないオプション -
オプション A (エラーをスキップするフィルター処理ステップの追加) は、エラーによるパイプラインの中断を防ぐ可能性がありますが、信頼性とトラブルシューティングに不可欠な潜在的な再処理のためにエラーのあるデータをキャプチャして保存することはありません。
オプション B (try...catch ブロックを side 出力なしで使用) を使用すると、エラーを処理できますが、エラーのあるデータを格納して再処理するメカニズムは提供されません。データが失われる可能性があります。
オプション C(DoFn から Pub/Sub に誤った行を直接書き込む)は機能しますが、DoFn ロジックが複雑になる可能性があり、サイド出力を使用するほど単純ではない可能性があります。
</div></details>

### Q. 質問29: 未回答
MariaDB SQL データベースを GCE VM インスタンスにデプロイ中であり、監視とアラートの設定が必要です。目標は、最小限の開発作業でネットワーク接続、ディスク IO、レプリケーション ステータスなどの指標を MariaDB から収集し、StackDriver を利用してダッシュボードとアラートを作成することです。この構成をどのように実現できますか?
1. 　
2. 
3. 
4. Ops Agent をインストールし、MySQL プラグインを設定します。
<details><div>
    答え：4
説明
最小限の開発労力で MariaDB から指標を収集し、ダッシュボードとアラートに StackDriver を使用するには、次の点を考慮する必要があります。
D. 
StackDriver エージェント: StackDriver Agent は、最小限の労力で VM インスタンスからシステムとアプリケーションの指標を収集するように設計されています。これにより、指標を収集して StackDriver にエクスポートするプロセスが簡素化されます。
MySQLプラグイン:StackDriver Agentには、MariaDBなどのMySQL互換データベースからデータベース関連の指標を収集するために特別に設計されたMySQLプラグインが含まれています。このプラグインは、ネットワーク接続、ディスク I/O、レプリケーション ステータスなどの重要なメトリックをキャプチャできます。
正しくないオプション -
オプション A(OpenCensus Agent をインストールし、カスタム指標収集アプリケーションを作成する)では、MariaDB 指標を収集して StackDriver にエクスポートするために、より多くの開発作業とカスタム コーディングが必要になります。これは、StackDriver エージェントが提供する組み込みの MySQL プラグインを使用する場合と比較して、より複雑なソリューションです。
オプション B(ヘルスチェックを使用して MariaDB インスタンスをインスタンス グループに配置する)は、主にインスタンスの可用性に対応しますが、データベース固有の指標を直接収集して StackDriver にエクスポートすることはありません。
オプション C(StackDriver Logging Agent をインストールし、MariaDB ログを読み取るための fluentd in_tail プラグインの構成)は、ログの収集に重点を置いており、データベースから詳細なパフォーマンスと正常性の指標を収集するのには適していません。
参照：
https://cloud.google.com/monitoring/custom-metrics/open-census
</div></details>

### Q. 質問31: 未回答
2 TB のリレーショナル データベースを Google Cloud Platform に移行するという課題があり、アプリケーションのリファクタリングに制限があり、費用対効果に重点が置かれています。このシナリオでは、データの保存と提供にどの Google Cloud サービスを選択すればよいですか?
1. 　
2. 
3. 
4. Cloud SQL
<details><div>
    答え：4
説明
2 TB のリレーショナル データベースを Google Cloud Platform に移行する要件を考えると、コストを主な懸念事項とし、アプリケーションの大幅なリファクタリングを行わずに、次のオプションを検討する必要があります。
D. クラウド SQL
リレーショナル データベースの互換性: Cloud SQL は、MySQL、PostgreSQL、SQL Server などの一般的なデータベース エンジンと互換性のあるマネージド リレーショナル データベース サービスを提供します。既存のデータベースがリレーショナルの場合、Cloud SQL はアプリケーション コードへの変更を最小限に抑えた簡単な移行パスを提供します。
費用対効果: Cloud SQL にはさまざまな料金階層と柔軟なスケーリング オプションが用意されているため、ワークロードと予算に適した構成を選択できます。ニーズに合わせて適切なマシンタイプとストレージ容量を選択できるため、コストを管理できます。
正しくないオプション -
オプション A、B、および C は、2 TB のリレーショナル データベースの単純な移行には適していない場合があります。
A. Cloud Spanner: Cloud Spanner は拡張性が高く、グローバルに分散されたデータベース サービスですが、トランザクション ワークロードの高可用性とスケーラビリティを実現するように設計されています。2TBのリレーショナルデータベースは、通常、ミッションクリティカルなグローバルに分散されたアプリケーションに使用されるため、コストが主な懸念事項である場合、やり過ぎになる可能性があります。
B. Cloud Bigtable: Cloud Bigtable は、通常、分析データや時系列データに使用される大規模な NoSQL データを保存および提供するために設計されています。これはリレーショナルデータベースではないため、従来の2TBリレーショナルデータベースの移行には適していない可能性があります。
C. Cloud Firestore: Cloud Firestore は、主にモバイルおよびウェブ アプリケーション向けに設計された NoSQL ドキュメント データベースです。通常、従来のリレーショナル データベースの移行には使用されず、大幅なアプリケーション リファクタリングが必要になる場合があります。
</div></details>

### Q. 質問32: 未回答
リアルタイム アプリケーションに Bigtable を使用しており、読み取りと書き込みが混在する負荷が高い。最近、追加のユース ケースを特定し、データベース全体の特定の統計を計算するために分析ジョブを時間単位で実行する必要があります。本番アプリケーションの信頼性と分析ワークロードの両方を確保する必要があります。あなたは何をするべきか?
1. 　
2. 
3. 単一クラスタ ルーティングで 2 番目のクラスタを追加する
4. 
<details><div>
    答え：3
説明
オプション C: 
このオプションでは、分析ワークロードを処理するために、Bigtable インスタンスに別のクラスタを追加します。この分離により、運用アプリケーションのリアルタイム トラフィックと分析ジョブが異なるクラスターで実行されることが保証され、分離レベルが提供されます。
単一クラスター ルーティングを使用すると、アプリ プロファイル (運用環境の場合はライブ トラフィック、分析の場合はバッチ分析) に基づいて、どのクラスターがどのタイプのトラフィックを処理するかを指定できます。このアプローチにより、トラフィック ルーティングを効果的に管理できます。
主な利点は、ワークロードを同じインスタンス内に保持しながら、ワークロードをある程度分離できるため、費用対効果と運用効率が高いことです。
正しくないオプション -
オプション A(Bigtable ダンプを GCS にエクスポート):Bigtable データを Google Cloud Storage(GCS)にエクスポートし、エクスポートしたファイルに対して分析を実行するのはバッチ指向のアプローチであり、リアルタイム分析や本番アプリケーションとのシームレスな統合はできません。また、分析プロセスの複雑さと遅延も増します。
オプション B(マルチクラスタ ルーティング):マルチクラスター ルーティングはワークロードの分離に適していますが、このオプションでは、運用環境にライブ トラフィック アプリ プロファイルを使用し、分析にバッチ分析プロファイルを使用することをお勧めします。ただし、ライブ トラフィック プロファイルはリアルタイム トラフィック用に設計されており、分析に使用すると、運用アプリケーションの信頼性に影響を与える可能性があります。
オプション D (既存のクラスターのサイズを 2 回増やす):既存のクラスターのサイズを増やすと、スケーリングに役立つ場合がありますが、リアルタイムのワークロードと分析のワークロードを明確に分離することはできません。このオプションは、リソースの競合につながる可能性があり、信頼性の問題に効果的に対処できない可能性があります。
</div></details>

### Q. 質問34: 未回答
適切に設計された行キーを使用して Cloud Bigtable にデータを書き込むデータ パイプラインがあります。パイプラインをモニタリングして、Cloud Bigtable クラスタのサイズをいつ増やすかを判断します。これを達成するために、どのような 2 つのアクションを実行できますか?(2つ選択してください。
1. 　
2. 
3. 書き込み操作の待機時間を監視します。書き込みレイテンシが持続的に増加する場合は、Cloud Bigtable クラスタのサイズを増やします。
4. ストレージ使用率を監視します。使用率が最大容量の 70% を超えたら、Cloud Bigtable クラスタのサイズを増やします。
5. 
<details><div>
    答え：3,4
説明
C. 
このオプションは確かに正しいです。書き込み操作のレイテンシは、書き込みワークロードを処理する際の Cloud Bigtable クラスタのパフォーマンスを直接反映するため、非常に重要です。書き込みレイテンシーは、時間の経過に伴う書き込みレイテンシーの増加は、クラスターが受信書き込みの効率的な処理に苦労している可能性があることを示唆しているため、監視すべき重要なメトリックです。書き込みレイテンシが持続的に増加している場合は、増大する書き込み負荷をより効果的に処理するために Cloud Bigtable クラスタをスケールアップする必要があることを示しています。
D. 
このオプションも正しいです。ストレージ使用率のモニタリングは、Cloud Bigtable インスタンスを効果的に管理するために不可欠です。ストレージ使用率が最大容量の 70% に近づくか、それを超えると、インスタンスの領域が不足していることを示します。通常はノードを追加して Cloud Bigtable クラスタのサイズを増やすと、データ量の増加に対応し、ストレージの制限によるパフォーマンスの低下を防ぐことができます。
正しくないオプション -
A. キー ビジュアライザーのメトリックを確認します。Cloud Bigtable クラスタのサイズを増やすには、読み取りプレッシャー インデックスが 100 を超えます。
Key Visualizer の読み取り圧力インデックスは、書き込みワークロードではなく、読み取りワークロードに関連しています。読み取りプレッシャーの監視は、読み取りパフォーマンスを最適化するために不可欠ですが、書き込み負荷の高いワークロードのクラスター サイズをいつ増やすかを決定することには直接関係ありません。
B. キービジュアライザーの指標を確認します。Cloud Bigtable クラスタのサイズを増やすには、書き込みプレッシャー インデックスが 100 を超えます。
書き込みプレッシャー インデックスは書き込みワークロードに関連していますが、クラスター サイズの調整を決定するために使用される一般的なメトリックではありません。書き込みレイテンシーとストレージ使用率は、書き込みワークロードに応じてスケーリングを決定するための、より一般的で実用的なメトリックです。
E. 読み取り操作の待機時間を監視します。読み取り操作に 100 ミリ秒以上かかる場合は、Cloud Bigtable クラスタのサイズを増やします。
読み取り待機時間の監視は、応答性の高いクエリのパフォーマンスを確保するために不可欠ですが、書き込みワークロードの問題や、書き込み要求に応じてクラスター サイズを増やすタイミングに関する直接的な分析情報は提供されません。
</div></details>

### Q. 質問36: 未回答
履歴データは Cloud Storage に保存します。履歴データに対して分析を実行する必要があります。ソリューションを使用して無効なデータエントリを検出し、プログラミングや SQL の知識を必要としないデータ変換を実行したい。あなたは何をするべきか?
1. 　
2. Cloud Dataprep とレシピを使用して、エラーを検出し、変換を実行します。
3. 
4. 
<details><div>
    答え：2
説明
プログラミングや SQL の知識を必要とせずに、Cloud Storage に保存された履歴データに対してエラーを検出し、データ変換を実行するには、次のオプションが最適です。
B. 
このオプションが最良の選択である理由は次のとおりです。
ユーザーフレンドリーなインターフェース:Cloud Dataprep は、データの準備と変換のためのユーザーフレンドリーで視覚的なインターフェースを提供します。データクリーニングと変換のレシピは、コードやSQL問合せを記述せずに作成できます。これにより、さまざまなレベルの技術的専門知識を持つユーザーがアクセスできるようになります。
データ品質チェック:Cloud Dataprep には、欠損値、外れ値、データ形式のエラーなどのデータ品質の問題を検出する機能が含まれています。ルールと変換を視覚的に定義して、データをクリーンアップおよび修正できます。
拡張性:Cloud Dataprep は大規模なデータセットを処理できるため、Cloud Storage に保存されている履歴データの分析に適しています。
統合：Cloud Dataprep は他の Google Cloud サービスとシームレスに統合されるため、Cloud Storage からデータを取り込み、変換を実行してから、クリーニングしたデータを BigQuery やその他の分析ツールに読み込むことができます。
正しくないオプション -
オプション A(Cloud Dataflow と Beam)とオプション C(Cloud Dataproc と Hadoop ジョブ)は、よりプログラム的なソリューションであり、コーディングとデータ処理フレームワークの知識が必要です。
オプション D(クエリを使用した BigQuery のフェデレーション テーブル)では、SQL クエリを記述する必要があるため、特に SQL コードやプログラミング コードを記述したくない場合は、データのクリーニングと変換のタスクを Cloud Dataprep ほど簡単に行えない可能性があります。
</div></details>

### Q. 質問37: 未回答
会社は、履歴データを Cloud Storage に安全にアップロードする必要があります。セキュリティ・ルールでは、内部IPアドレスからオンプレミス・リソースへのアクセスのみが許可されます。最初のアップロード後、既存のオンプレミス アプリケーションから新しいデータが毎日追加されます。これを達成するための最良の方法は何ですか?
1. 　オンプレミス サーバーから gsutil rsync を実行します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
このオプションでは、gsutil rsync コマンドを使用して、オンプレミス サーバーから Cloud Storage にデータを同期します。これは、最初のアップロードとその後の毎日の更新の両方で機能しますが、Dataflow と同じレベルのデータ変換と処理機能を提供しない場合があります。ただし、これはデータ転送の簡単な方法であり、適切なアクセス制御と認証が実施されていれば安全です。
正しくないオプション -
オプション B: Dataflow を使用して Cloud Storage にデータを書き込む。
Dataflow は堅牢なデータ処理および変換ツールであり、特に重要なデータ変換が不要な場合は、単純なデータ転送タスク用に過剰に設計されたソリューションになる可能性があります。これは、データ転送プロセスの一部として複雑なデータ変換を実行する必要がある場合に適しています。
オプション C: Dataproc でジョブ テンプレートを作成して、データ転送を実行します。
Dataproc は、分散データ処理ジョブ(通常はバッチ処理やリアルタイム データ分析)を実行するために設計されています。単純なデータ転送タスクに Dataproc を使用すると、不必要に複雑になる可能性があります。
オプション D: Compute Engine VM に FTP サーバーをインストールしてファイルを受信し、Cloud Storage に移動します。
このオプションでは、Compute Engine VM での FTP サーバーのセットアップとメンテナンスを行います。データ転送には機能しますが、VM の管理とセキュリティ構成に関して追加のオーバーヘッドが発生します。
オプションAとオプションBのどちらを選択するかは、特定の要件によって異なります。オプション A(gsutil rsync)は、よりシンプルでわかりやすいデータ転送方法であり、オプション B(データフロー)は、データの変換と処理の柔軟性を高めます。ユースケースで基本的なデータ転送のみが必要で、セキュリティが懸念される場合は、オプションAの方が簡単な選択肢になる可能性があります。ただし、今後、より複雑なデータ処理が必要になることが予想される場合や、転送中にデータ変換を実行する必要がある場合は、オプション B (データフロー) の方が適している可能性があります。
</div></details>

### Q. 質問38: 未回答
タイムスタンプ列と ID 列の WHERE 句を使用して BigQuery テーブルをフィルタリングするクエリがあります。bq query '"-dry_run を使用すると、タイムスタンプと ID のフィルターによってデータ全体のごく一部が選択されている場合でも、クエリによってテーブルのフル スキャンがトリガーされることがわかります。既存の SQL クエリへの変更を最小限に抑えて、BigQuery でスキャンされるデータの量を減らしたい。あなたは何をするべきか?
1. 　
2. 
3. パーティション列とクラスタリング列を含むテーブルを再作成します。
4. 
<details><div>
    答え：3
説明
既存の SQL クエリへの変更を最小限に抑えて BigQuery でスキャンされるデータの量を減らすには、オプション C を検討する必要があります。
C. 
このオプションが適切な選択である理由は次のとおりです。
パーティション 分割：タイムスタンプ列に基づいてテーブルをパーティション分割することで(日付またはタイムスタンプ タイプの場合)、BigQuery は関連データを含まないパーティションのスキャンをスキップできます。これにより、タイムスタンプに基づいてクエリを実行するときにスキャンされるデータの量が削減されます。
クラスタ リング：クラスタリングカラムは、クエリのパフォーマンスをさらに向上させることができます。ID 列に基づいてテーブルをクラスタリングすることで、同じ ID 値を持つデータがディスクにまとめて格納され、ID でフィルタリングするときにスキャンされるデータの量が削減されます。
最小限のクエリ変更:このオプションでは、既存の SQL クエリに対する変更が最小限で済みます。同じ SQL クエリを引き続き使用でき、BigQuery の最適化が有効になり、スキャンされるデータの量が削減されます。
正しくないオプション -
オプション A (ID ごとに個別のテーブルを作成する) では、データ構造とクエリが大幅に変更され、多くの ID 値を処理するときに管理上の課題が発生する可能性があります。
オプション B (LIMIT キーワードを使用) では、返される行数を制限できますが、スキャンされるデータの量が必ずしも減るわけではなく、コストの最適化に不可欠です。
オプション D (--maximum_bytes_billed フラグを使用) は、データ・スキャンの最適化というよりは、照会コストの制御に関するものです。不要なデータのスキャンの問題には対処していません。
</div></details>

### Q. 質問39: 未回答
50,000 個のセンサーから BigQuery テーブルに分単位のデータを挿入する必要があります。データ量の大幅な増加が予想され、集計された傾向をリアルタイムで分析するために、取り込みから 1 分以内にデータを利用できるようにする必要があります。どのような手順を踏む必要がありますか?
1. 　
2. Cloud Dataflow パイプラインを使用して、BigQuery テーブルにデータをストリーミングします。
3. 
4. 
<details><div>
    答え：2
説明
50,000 個のセンサーから分単位のデータを BigQuery テーブルに挿入し、リアルタイムで分析できるようにするという要件を満たすには、オプション B を選択する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
リアルタイムのデータ取り込み:Cloud Dataflow を使用すると、リアルタイムのデータ パイプラインを構築できます。Dataflow を使用して BigQuery にデータをストリーミングすると、取り込みから数秒以内にデータを分析できるようになり、リアルタイム分析の要件を満たすことができます。
拡張性:Dataflow は、多数のセンサー(この場合は 50,000 個)からのデータの取り込みを処理でき、データ量の増加に合わせてスケーリングできます。
BigQuery との統合:Dataflow は BigQuery とシームレスに統合されているため、BigQuery テーブルにデータを簡単にストリーミングできます。
分単位のデータを挿入する:これは、データを1分に1回の頻度で記録する必要があることを意味します。
50,000個のセンサー:これは、データを生成するセンサーが多数あることを意味します。
BigQuery テーブル:これは、データの保存と分析に使用される BigQuery のデータ構造です。
データ量の大幅な増加:これは、生成されるデータの量が急速に増加すると予想されることを意味します。
1分間の摂取:つまり、データは生成後 1 分以内に BigQuery で利用できるようになる必要があります。
集計された傾向のリアルタイム分析:つまり、傾向を特定するためにデータをリアルタイムで分析する必要があります。
正しくないオプション -
オプション A (bq load を使用して 60 秒ごとにバッチを読み込む) は、バッチ処理に適しており、必要なリアルタイム機能は提供されません。
オプション C (INSERT ステートメントを使用して 60 秒ごとにバッチを挿入する) では、手動のスクリプト作成とスケジュール設定が必要であり、リアルタイム要件を効果的に満たさない可能性があります。
オプション D (MERGE ステートメントを使用して 60 秒ごとにバッチで更新を適用する) は、主に既存のデータを更新するためのものであり、リアルタイムのデータ インジェスト要件には対応していません。
</div></details>

### Q. 質問41: 未回答
ここでは、BigQuery データ ウェアハウスのメイン インベントリ テーブルを読み取る、ほぼリアルタイムのインベントリ ダッシュボードを作成します。履歴在庫データは、品目および場所ごとの在庫残高として保存されます。毎時間、数千件のインベントリーの更新があります。ダッシュボードのパフォーマンスを可能な限り向上させ、データが正確であることを確認する必要があります。どのような手順を踏む必要がありますか?
1. 　
2. 
3. BigQuery ストリーミングを使用して、日次在庫移動テーブルに変更をストリーミングします。履歴在庫残高テーブルに結合するビューで残高を計算します。在庫残高表を毎晩更新します。
4. 
<details><div>
    答え：3
説明
C. 
オプション C が推奨される理由は次のとおりです。
ほぼリアルタイムのデータ:BigQuery ストリーミングを使用すると、在庫の変更が発生したときにキャプチャできるため、在庫移動表をほぼリアルタイムで最新の状態に保つことができます。これは、インベントリ ダッシュボードにとって非常に重要です。
パフォーマンス：履歴在庫残高テーブルを在庫移動テーブルから分離することで、移動データを照会するときにスキャンされるデータの量を減らすことができます。これにより、クエリのパフォーマンスが大幅に向上します。
精度：ビューでの残高の日次計算により、在庫残高テーブルに最も正確なデータが反映されます。このプロセス中に、必要なデータクレンジングと検証を実行する機会があります。
効率：在庫残高テーブルを毎晩更新することで、データを統合して最適化し、クエリのパフォーマンスにより適したものにすることができます。これは、ダッシュボードの速度を維持するのに役立ちます。
キーポイント -
ほぼリアルタイムのインベントリ ダッシュボードを作成する必要があります。
ダッシュボードは、BigQuery データ ウェアハウスのメイン インベントリ テーブルを読み取ります。
履歴在庫データは、品目および場所ごとの在庫残高として保存されます。
毎時間、数千件のインベントリーの更新があります。
ダッシュボードのパフォーマンスを可能な限り向上させ、データが正確であることを確認する必要があります。
正しくないオプション -
オプション A(BigQuery UPDATE ステートメントを使用)は、同時実行の問題が発生する可能性があるため、リアルタイム更新に適しておらず、クエリのパフォーマンスに影響を与える可能性があります。オプション B (在庫残高テーブルのパーティション分割) では、クエリのパフォーマンスは向上しますが、リアルタイムの更新やデータの正確性はオプション C ほど効果的には対応できません。
オプション D(BigQuery バルクローダーを使用)は、バッチ読み込みのシナリオに適しており、インベントリ ダッシュボードに必要なほぼリアルタイムのデータ更新を提供できない場合があります。したがって、このコンテキストでは最適な選択ではありません。
</div></details>

### Q. 質問42: 未回答
BigQuery にデータが保存されている。BigQuery データセットのデータは、高可用性を備えている必要があります。このデータのストレージ、バックアップ、およびリカバリ戦略を定義して、コストを最小限に抑える必要があります。目標復旧時点(RPO)が 30 日の BigQuery テーブルをどのように構成すればよいですか?
1. 　
2. 
3. BigQuery データセットをマルチリージョンに設定します。緊急時には、特定の時点のスナップショットを使用してデータを回復します。
4. 
<details><div>
    答え：3
説明
C. 
このオプションは、いくつかの理由で正しいです。
マルチリージョンデータセット:複数リージョンの BigQuery データセットを作成すると、データが複数の地理的リージョンに複製され、高可用性と冗長性が確保されます。このアプローチは、リージョンの障害によるデータ損失を防ぐのに役立ちます。
ポイント・イン・タイム・スナップショット:BigQuery のポイントインタイム スナップショット機能を使用すると、過去 30 日以内の特定の時点にデータを復元できます。これは、目標復旧時点 (RPO) の目標値である 30 日と一致します。
正しくないオプション -
A. BigQuery データセットをリージョンに設定します。緊急時には、特定の時点のスナップショットを使用してデータを回復します。
このオプションでは、特定の時点のスナップショットの使用が推奨されますが、リージョンの冗長性しか提供されないため、高可用性とディザスター リカバリーには十分ではない可能性があります。リージョン データセットは、マルチリージョン データセットと同じレベルのリージョン停止に対する保護を提供しません。
B. BigQuery データセットをリージョンに設定します。スケジュールされたクエリを作成して、バックアップの時刻のサフィックスが付いたテーブルにデータのコピーを作成します。緊急の場合は、テーブルのバックアップコピーを使用してください。
このオプションでは、スケジュールされたクエリ バックアップを作成する必要がありますが、これはデータ復旧の効果的な戦略です。ただし、特にデータセットが大きい場合は、バックアップの管理と保守が複雑になり、追加コストが発生します。BigQuery にはすでにネイティブのバックアップと復元機能が用意されているため、スケジュールされたクエリのコピーは不要になります。
D. BigQuery データセットをマルチリージョンに設定します。スケジュールされたクエリを作成して、バックアップの時刻のサフィックスが付いたテーブルにデータのコピーを作成します。緊急の場合は、テーブルのバックアップコピーを使用してください。
オプション B と同様に、このアプローチでは、マルチリージョン ストレージとスケジュールされたクエリ バックアップが組み合わされます。マルチリージョン ストレージによる冗長性は提供されますが、スケジュールされたクエリを使用してデータのバックアップ コピーを維持することに関連する複雑さと不要なコストも発生する可能性があります。BigQuery のリカバリとポイントインタイム スナップショットのネイティブ機能は、より効率的で費用対効果が高く、目的の RPO を達成します。
</div></details>

### Q. 質問43: 未回答
BigQuery テーブル内のデータのサンプルで Dataprep レシピを作成しました。このレシピを使用して、ロード・ジョブの実行が完了した後、同じスキーマを持つデータの新しい日次アップロードをクリーンアップおよび変換します。どのように進めればよいですか?
1. 　
2. 
3. 
4. Dataprep ジョブを Dataflow テンプレートとしてエクスポートし、Composer ジョブに組み込むことです。
<details><div>
    答え：4
説明
正しいオプションは D. 
データフローテンプレートとしてエクスポートする:Dataprep ジョブを Dataflow テンプレートとしてエクスポートすると、受信データに対して実行できる再利用可能なデータ変換ワークフローが作成されます。
Composerジョブに組み込む:Google Cloud Composer は、複雑なワークフローをオーケストレーションできるマネージド Apache Airflow サービスです。Dataflow テンプレートを Composer ジョブに組み込むことで、大規模なデータ処理パイプラインの一部として Dataprep ベースのデータ変換の実行をスケジュールし、管理することができます。
正しくないオプション -
A. Dataprep で cron スケジュールを作成します。Dataprep ではジョブの実行をスケジュールできますが、これらのスケジュールは通常、Dataprep 環境内で Dataprep ジョブを実行するためのものであり、このシナリオで必要な外部でのオーケストレーションのためのものではありません。
B. App Engine の cron ジョブを作成します。App Engine の cron ジョブは、HTTP エンドポイントのトリガーなど、App Engine 環境に固有のタスクには適していますが、データ変換ワークフローやその他の外部プロセスのオーケストレーションを目的としたものではありません。
C. レシピを Dataprep テンプレートとしてエクスポートし、Cloud Scheduler でジョブを作成します。Cloud Scheduler を使用してジョブをトリガーすることもできますが、Dataprep ジョブは通常、Dataprep 環境内で実行されます。このオプションでは、Dataprep ジョブの実行を大規模なデータ パイプラインにシームレスに組み込むことはできません。
参考リンク -
クラウドコンポーザー:- https://cloud.google.com/composer/
</div></details>

### Q. 質問45: 未回答
Cloud Dataproc クラスタの管理者である。クラスターで進行中の作業を失うことなく、コストを最小限に抑えながら、実行時間の長いジョブをより高速に実行する必要があります。具体的にどのようなステップを踏むべきでしょうか?
1. 　
2. 
3. 
4. プリエンプティブルワーカーノードでクラスタサイズを増やし、グレースフルデコミッションを使用するように構成します。
<details><div>
    答え：4
説明
正しいオプションは D です。 
プリエンプティブル・ワーカー・ノード:プリエンプティブル VM は、Google Cloud 上の有効期間が短く、費用対効果の高いコンピューティング インスタンスです。通常の VM よりも安価ですが、必要な容量が増加したときに Google がプリエンプト(終了)できます。コスト削減にはなりますが、いつでもプリエンプトされる可能性があるため、信頼性が低下する可能性もあります。
グレースフルデコミッショニング:グレースフルデコミッションを使用するようにプリエンプティブルワーカーノードを構成すると、プリエンプションノードで現在実行中のワークロードをプリエンプションされる前に、クラスタで終了できます。これにより、進行中の作業が失われるリスクが最小限に抑えられ、プリエンプティブルノードが停止した場合でもジョブが正常に完了します。
プリエンプティブルワーカーノードでクラスターサイズを拡大し、グレースフルデコミッションを使用することで、プリエンプティブルインスタンスのコスト削減を効果的に活用しながら、ジョブが中断することなく作業を完了できるようにし、ジョブの実行を高速化し、コストを最小限に抑えることができます。
正しくないオプション -
A. プリエンプティブルでないワーカーを増やしてクラスタサイズを増やします。クラスター サイズを大きくするとジョブのパフォーマンスが向上しますが、プリエンプティブルでないワーカーを追加すると、プリエンプティブル ノードが終了するという問題に直接対処せずにコストが増加します。
B. プリエンプティブルワーカーノードでクラスタサイズを増やし、強制的に使用停止するように構成します。プリエンプティブル・ワーカー・ノードを強制的に使用停止にすると、進行中の作業が失われる可能性があり、データを失うことなくジョブをより高速に実行するためには望ましくありません。
C. プリエンプティブル ワーカー ノードでクラスタ サイズを増やし、Cloud Stackdriver を使用してスクリプトをトリガーして作業を保持します。モニタリングとアラートに Stackdriver を使用することは重要ですが、グレースフルな廃止の必要性に直接対処することはできません。グレースフル デコミッションは、プリエンプティブル ノードの終了をより効率的に処理するための Dataproc の組み込みメカニズムです。
</div></details>

### Q. 質問46: 未回答
ある小売チェーンは、さまざまな地域の店舗で顧客の購入パターンを分析したいと考えています。複雑なSQLクエリをサポートし、大量のデータを処理できるデータウェアハウスソリューションが必要です。どのGCPサービスを使用すべきか?
1. 　
2. BigQuery
3. 
4. 
<details><div>
    答え：2
説明
質問の正しいオプションは次のとおりです。 B. BigQuery
このシナリオでは、小売チェーンは、異なる地域の店舗間で顧客の購入パターンを分析する必要があります。これには、複雑な SQL クエリのサポートと大量のデータを処理する機能という 2 つの主要な要件があります。
BigQuery は、SQL クエリを使用して大規模なデータセットを分析するために設計された、フルマネージドのサーバーレス データ ウェアハウス ソリューションです。複雑な分析クエリの処理に優れており、大量のデータを効率的に処理できます。また、パーティション分割やクラスタリングなどの機能も提供して、クエリのパフォーマンスを最適化します。したがって、店舗全体の顧客の購入パターンを分析するという小売チェーンのニーズと完全に一致しています。
正しくないオプション -
A. Cloud Bigtable の場合: Cloud Bigtable は、大規模で高スループットのワークロード向けに設計された NoSQL データベースです。複雑な SQL クエリには適しておらず、複雑なデータ ウェアハウスやクエリ タスクではなく、主にリアルタイムの運用分析と時系列データに使用されます。
C. Firestore: Firestore は、主にモバイルおよびウェブ アプリケーション開発向けに設計された、柔軟でスケーラブルな NoSQL データベースです。リアルタイムのデータ同期や低レイテンシのクエリには適していますが、複雑な SQL クエリや大規模なデータ ウェアハウスを BigQuery ほど効率的に処理できない場合があります。
D. クラウドデータストア: Cloud Datastore は、運用アプリケーションやリアルタイム データに適した NoSQL データベースでもありますが、複雑なデータ ウェアハウス タスクに必要な堅牢なクエリ機能やパフォーマンスは提供されない場合があります。
</div></details>

### Q. 質問47: 未回答
研究機関は、世界中で行われている実験から大規模な科学データを収集し、処理します。そのためには、ペタバイト規模のデータを低遅延で効率的に管理できるストレージソリューションが必要です。このシナリオにはどのGCPサービスが適していますか?
1. 　
2. 
3. Google クラウドストレージ
4. 
<details><div>
    答え：3
説明
研究機関が大規模な科学データを効率的に収集して処理し、ペタバイト規模のデータを低遅延で管理する必要があるシナリオに適したオプションは次のとおりです。
C. Google クラウドストレージ
Google Cloud Storage(オプション C): Google Cloud Storage は、ペタバイト規模のデータを含む大量のデータを保存および取得するように設計されています。オブジェクトへの低遅延アクセスを提供し、大規模なデータを効率的に格納および管理する必要があるシナリオに適しています。耐久性、スケーラビリティ、高可用性を提供し、データストレージの信頼できる選択肢となっています。
正しくないオプション -
A. Cloud Pub/Sub(オプション A):
Cloud Pub/Sub は、イベントドリブン システム向けのメッセージング サービスです。リアルタイムのメッセージングとイベントの取り込みに使用されますが、大規模なデータストレージ用には設計されていません。
B. Bigtable(オプション B):
Bigtable は、高スループットで低レイテンシのワークロード向けに設計された NoSQL データベースですが、大規模な科学データの保存と管理には適していない可能性があります。これは、大規模なデータセットの長期保存ではなく、高速でリアルタイムのデータアクセスと分析に適しています。
D. クラウドデータストア(オプション D):
Cloud Datastore は NoSQL データベース サービスであり、ウェブやモバイル アプリケーションのデータ ストレージには適していますが、ペタバイト規模の科学データの管理には適していない可能性があります。トランザクション データに重点を置いており、この特定のユースケースでは Google Cloud Storage と同じスケーラビリティと費用対効果を提供できない場合があります。
</div></details>

### Q. 質問48: 未回答
eラーニングプラットフォームは、生徒の進捗状況とクイズの結果をリアルタイムで追跡する必要があります。また、レポートと分析を生成する必要もあります。このユースケースに適したデータベースを提供するGCPサービスはどれですか?
1. 　
2. 
3. BigQuery
4. 
<details><div>
    答え：3
説明
生徒の進捗状況や小テストの結果をリアルタイムで追跡したり、eラーニングプラットフォームでレポートや分析を生成したりするには、BigQuery(オプションC)が最適なGCPサービスです。その理由は次のとおりです。
正しいオプションは C. BigQuery -
BigQuery は、大規模なデータセットの処理と複雑な SQL クエリの迅速な実行を専門とする、フルマネージドでサーバーレスかつ拡張性の高いデータ ウェアハウスです。
リアルタイム分析用に設計されており、データ分析とレポート作成タスクに優れたパフォーマンスを提供します。
データをリアルタイムで取り込んで分析できるため、生徒の進捗状況やクイズの結果をその都度追跡するのに適しています。
大量のデータを処理できるため、レポートや分析の生成に適しています。
正しくないオプション -
A. Firestore:
Firestore は、クライアント(モバイル アプリケーションやウェブ アプリケーションなど)間での柔軟なリアルタイムのデータ ストレージと同期に適した NoSQL ドキュメント データベースです。Firestore はリアルタイムのデータ更新を処理でき、学生関連のデータの管理には適していますが、BigQuery と比較すると、複雑な分析やレポート作成のタスクには適していない可能性があります。
B. Cloud SQL:
Cloud SQL はマネージド リレーショナル データベース サービスですが、従来のリレーショナル データベースの制限により、リアルタイムの分析やレポート作成には適していない場合があります。構造化データやトランザクション ワークロード向けに設計されているため、複雑な分析クエリでは BigQuery ほど効率的に実行できない場合があります。
D. クラウドデータストア:
Cloud Datastore は、半構造化データの保存とクエリに適した NoSQL データベースです。リアルタイムのウェブスケール アプリケーション向けに設計されていますが、BigQuery が提供する詳細なレポートと分析に必要な堅牢な分析機能は提供されない場合があります。
</div></details>

### Q. 質問49: 未回答
スマートシティに展開されたIoTデバイスからセンサーデータを収集して分析するプロジェクトに取り組んでいます。膨大な量の受信データを処理し、リアルタイム分析をサポートできるGCPサービスはどれですか?
1. 　
2. Bigtable
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は、B. Bigtable です。
このシナリオでは、スマート シティに展開されたデバイスからの IoT センサー データを処理しており、通常は大量の受信データが生成されます。また、リアルタイム分析のサポートも必要です。
Bigtable は、大量のデータを低レイテンシと高スループットで処理するために設計された NoSQL データベースです。大量のセンサー データの取り込みと保存に適しています。Bigtable はリアルタイムのデータ取り込みを処理でき、効率的なクエリをサポートしているため、大規模なデータセットのリアルタイム分析に適しています。センサーの読み取り値などの時系列データに最適化されているため、このユースケースに適しています。
正しくないオプション -
A. Cloud Pub/Sub の場合:
Cloud Pub/Sub は、リアルタイムのイベントの取り込みと配信のために設計されたメッセージング サービスです。リアルタイム データの取り込みには適していますが、分析に必要なストレージとクエリ機能は提供されません。大規模なデータの処理と分析の実行に必要なストレージとクエリ機能が不足しています。
C. BigQueryの場合:
BigQuery は、大規模なデータセットに対して SQL に似たクエリを実行するために設計されたデータ ウェアハウスですが、リアルタイムのデータ取り込みには最適化されていません。BigQuery は分析クエリやバッチ処理には優れていますが、大量のリアルタイム データ インジェストを処理するには最適な選択肢ではない可能性があります。
D. Firestore:
Firestore は柔軟な NoSQL データベースですが、ドキュメントベースのデータの管理に適しており、一般的にモバイル アプリケーションやウェブ アプリケーションに使用されます。IoTセンサーからの大量の時系列データを処理し、リアルタイム分析を実行するには最適な選択ではない可能性があります。
</div></details>

### Q. 質問50: 未回答
マーケティング会社は、Web、モバイルアプリ、メールキャンペーンなど、さまざまなソースからの顧客データを保存して分析したいと考えています。複数のチャネルからのデータを統合して分析できるデータベースが必要です。どのGCPサービスを検討すべきでしょうか?
1. 　BigQuery
2. 
3. 
4. 
<details><div>
    答え：1
説明
さまざまなソースからの顧客データを保存および分析し、複数のチャネルからのデータを統合および分析することを検討しているマーケティング会社にとって、検討すべき最適なGCPサービスはA.BigQueryです。
BigQuery は、大規模なデータセットを処理し、分析とデータ ウェアハウスのために複雑な SQL クエリを実行するように設計されています。複数のソースとチャネルからのデータの統合と分析を効率的に処理できます。
正しくないオプション -
B. Firestore は、主にモバイルおよび Web アプリケーションの開発に使用される NoSQL ドキュメント データベースです。アプリケーションの構造化データの管理には適していますが、複数のチャネルにまたがる複雑なデータ分析には適していない可能性があります。
C. Cloud Datastore は、ウェブおよびモバイル アプリケーション用に設計された NoSQL データベースでもあります。Firestore と同様に、アプリケーションの構造化データの保存には適していますが、BigQuery のような分析機能やクエリ パフォーマンスには欠けています。
D. Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。トランザクションデータベースには最適ですが、さまざまなソースやチャネルからのデータを扱うマーケティング会社が必要とする複雑な分析やデータ統合には最適化されていません。
</div></details>

## 4
### Q. 質問1: 未回答
Google データポータル 360 で、Google BigQuery をデータソースとして使用するレポートを作成します。レポートの視覚化には、1 時間未満のデータが表示されていません。
これを修正するにはどうすればよいですか?
1. 　レポート設定を編集して、キャッシュを無効にします。
2. 
3. 
4. 
<details><div>
    答え：1
説明
Google BigQuery をデータソースとして使用している場合に、1 時間未満のデータが Google データポータルのレポートに表示されるようにするには、次のことを行う必要があります。
A. レポート設定を編集して、キャッシュを無効にします。
このオプションが正しい選択である理由は次のとおりです。
キャッシュ: Google データポータルでは、パフォーマンス向上のためにデータをキャッシュすることがあります。このキャッシュ メカニズムにより、キャッシュされたデータが使用されているために、視覚化に最新のデータが表示されない状況が発生する場合があります。
キャッシュの無効化: レポート設定でキャッシュを無効にすると、レポートにアクセスするたびにデータソース(この場合は Google BigQuery)からデータを直接取得するように Google データポータルに指示できます。これにより、ビジュアライゼーションには常に最新のデータが反映されます。
正しくないオプション -
オプション B の「テーブルの詳細を編集して BigQuery のキャッシュを無効にする」は、Google データポータルのキャッシュ設定には適用されません。キャッシュ設定は、通常、データソース自体ではなく、レポートツール内で制御されます。
オプション C と D の [視覚化を表示するブラウザー タブを更新する] と [過去 1 時間のブラウザー履歴を消去してから、視覚化を表示するタブを再読み込みする] は、ブラウザーに表示されるデータを更新するのに役立つ場合があります。ただし、これらのオプションでは Google データポータルのキャッシュ設定には対応していないため、レポートに常に <> 時間未満のデータが表示されるようにするために必要な調整を行う必要があります。
</div></details>

### Q. 質問2: 未回答
外部顧客から、データベースからのデータのダンプが毎日提供されます。データはカンマ区切り値(CSV)ファイルとして Google Cloud Storage GCS に送られます。このデータを Google BigQuery で分析したいが、データに誤った形式または破損した行が含まれている可能性があります。
このパイプラインをどのように構築する必要がありますか?
1. 　
2. 
3. 
4. Google Cloud Dataflow バッチ パイプラインを実行してデータを BigQuery にインポートし、分析のために別の配信不能テーブルにエラーをプッシュします。
<details><div>
    答え：4
説明
Google BigQuery の Google Cloud Storage(GCS)にある日次 CSV ファイルのデータを分析しながら、破損または形式が正しくない可能性のある行を処理するパイプラインを構築するには、次の方法をお勧めします。
D. Google Cloud Dataflow バッチ パイプラインを実行してデータを BigQuery にインポートし、分析のために別の配信不能テーブルにエラーをプッシュします。
このアプローチが適切な理由は次のとおりです。
データの変換と検証: Google Cloud Dataflow は、データの変換と検証のための強力なツールです。Dataflow を使用して GCS から CSV ファイルを取り込み、データの検証と変換ロジックを適用してから、クリーンなデータを BigQuery に読み込むことができます。これにより、BigQuery に挿入する前に、必要に応じてデータのクリーニング、エンリッチメント、修正を行うことができます。
エラー処理: Dataflow は堅牢なエラー処理機能を提供します。正しく書式設定されていない行や破損している行は、配信不能テーブルにリダイレクトされ、そこで問題を個別に分析およびデバッグできます。これにより、不良データによって BigQuery への正常なデータの読み込みが妨げられることがなくなります。
バッチ処理: 毎日のデータ ダンプを処理するため、Dataflow などのバッチ処理アプローチがこのシナリオに適しています。これにより、データを継続的に監視するのではなく、より大きなチャンクでデータを処理できます。
正しくないオプション -
オプション A(フェデレーション データ ソースを使用)は、単純なケースでは機能する可能性がありますが、Dataflow と同じレベルの制御とエラー処理は提供されません。SQL クエリでのデータ品質の問題の処理は、複雑で効率が低下する可能性があります。
オプション B(Google Stackdriver で BigQuery モニタリングを有効にしてアラートを作成する)は、BigQuery 自体のパフォーマンスと運用上の問題のモニタリングとアラートに重点が置かれており、データ品質やデータのインポートの問題には直接対処していません。
オプション C(gcloud CLI を使用して BigQuery にデータをインポートし、max_bad_records を 0 に設定する)では、BigQuery にデータが読み込まれますが、破損した行や形式が正しくない行を処理するための堅牢なメカニズムは提供されません。max_bad_records を 0 に設定すると、エラーのある行が拒否され、データが失われる可能性があります。
</div></details>

### Q. 質問6: 未回答
あなたの会社は規制の厳しい業界に属しており、個々のユーザーが業務に必要な最小限の情報にのみアクセスできるようにするデータセキュリティポリシーを実装する必要があります。Google BigQuery を使用してこのポリシーを適用します。次の 3 つのアプローチのうち、どれを選びますか?(3つ選択してください。
1. 　
2. テーブルへのアクセスをロールで制限します。
3. 
4. BigQuery API へのアクセスを承認済みのユーザーに制限する
5. 複数のテーブルまたはデータベース間でデータを分離します。
6. 
<details><div>
    答え：2,4,5
説明
個々のユーザーが Google BigQuery で業務を行うために必要な最小限の情報にのみアクセスできるようにするという要件を適用するには、次の方法を使用できます。
B. テーブルへのアクセスをロールで制限します。さまざまなレベルのアクセス権限を持つさまざまなロールをユーザーまたはグループに割り当てます。これにより、特定のテーブルまたはデータセットをクエリまたは変更できるユーザーを制御できます。
D. BigQuery API へのアクセスを承認済みのユーザーに制限する:API アクセスを管理することで、BigQuery API を使用してデータを操作できるユーザーを制限できます。承認されたユーザーまたはアプリケーションのみがアクセスできるようにする必要があります。
E. 複数のテーブルまたはデータベース間でデータを分離します。アクセス要件に基づいてデータを異なるテーブルまたはデータセットに分割して整理します。これにより、ユーザーは自分のロールに関連するデータにのみアクセスできます。
これらのアプローチは、規制の厳しい業界におけるデータアクセス制御と規制へのコンプライアンスを確保するのに役立ちます。オプション A、C、および F は、全体的なデータ セキュリティとガバナンスにも役割を果たす可能性がありますが、ユーザー固有のデータ アクセス制限を適用するための直接的なメカニズムではありません。
</div></details>

### Q. 質問7: 未回答
eコマース企業向けにバスケット放棄システムを設計しています。システムは、次の条件が満たされた場合にユーザーにメッセージを送信します。
ユーザーが 1 時間 Web サイトを操作していない。
ユーザーは、30ドル相当の製品をカートに追加しました。
ユーザーはトランザクションを完了していません。
Google Cloud Dataflow を使用してデータを処理し、メッセージを送信するかどうかを決定します。パイプラインをどのように設計すべきか?
1. 　
2. 
3. ギャップ期間が 60 分のセッション ウィンドウを使用
4. 
<details><div>
    答え：3
説明
正しいオプション - C (ギャップ期間が 60 分のセッション ウィンドウを使用):
このシナリオでは、30 ドル相当の商品をカートに追加し、サイトを 1 時間操作していないユーザーを特定します。
ギャップ期間が 60 分のセッション ウィンドウを使用すると、セッション内のユーザー アクティビティをキャプチャし、アクティビティ間に 60 分以上のギャップがある場合に検出できるため、適切な選択です。
セッション・ウィンドウを定義して、この時間枠内のユーザー・アクティビティーをグループ化できます。セッションが終了すると (つまり、60 分間アクティビティがない場合)、セッションの内容を分析し、ユーザーにメッセージを送信するための条件を満たしているかどうかを判断できます。
正しくないオプション -
オプション A (期間が 60 分の固定時間枠を使用):
期間が 60 分の固定時間枠を使用することは、ユーザー セッションやユーザー アクティビティのギャップを考慮しないため、適切ではありません。60 分間隔の重複しないウィンドウが作成されるだけで、ユーザーの動作と一致しない可能性があります。
オプション B (期間が 60 分のスライディング タイム ウィンドウを使用):
スライディング タイム ウィンドウはデータを継続的に移動し、ユーザーが 60 分間非アクティブになったときに、関心のある特定のセッションをキャプチャできない場合があります。スライディング ウィンドウは、連続的なリアルタイム処理に適しています。
オプション D (60 分の遅延を持つ時間ベースのトリガーを持つグローバル ウィンドウを使用):
グローバルウィンドウでは、セッションの境界やユーザーアクティビティは考慮されません。すべてのデータを 1 つの連続したストリームとして扱うため、ユーザー セッションや非アクティブな期間の特定には役立たない場合があります。
参考リンク -
ビームウィンドウの基本:- https://beam.apache.org/documentation/programming-guide/#windowing-basics
</div></details>

### Q. 質問8: 未回答
あなたの会社は、さまざまなクライアントのデータ処理を処理しています。各クライアントは独自の分析ツールスイートを使用することを好み、Google BigQueryを介して直接クエリにアクセスできるものもあります。クライアントが互いのデータを見ることができないように、データをセキュリティで保護する必要があります。データへの適切なアクセスを確保する必要があります。どの3つのステップを踏むべきですか?(3つ選択してください。
1. 　
2. クライアントごとに異なるデータセットにデータを読み込みます。
3. 
4. クライアントのデータセットを承認されたユーザーに制限します。
5. 
6. 各クライアントのユーザーに適切な Identity and Access Management (IAM) ロールを使用します。
<details><div>
    答え：2,4,6
説明
データをセキュリティで保護し、適切なアクセスを許可しながら、クライアントが互いのデータを表示できないようにするには、次の 3 つの手順を実行する必要があります。
B. クライアントごとに異なるデータセットにデータを読み込みます。
クライアントごとにデータを個別のデータセットに整理します。これにより、データセットレベルでのデータ分離が保証され、各クライアントのデータに対するアクセスとアクセス許可の管理が容易になります。
D. クライアントのデータセットを承認されたユーザーに制限します。
データセットへのアクセスを許可するユーザーまたはグループを指定することで、データセットレベルでアクセス制御を実装します。これにより、許可された個人のみが特定のクライアントのデータセット内のデータを表示およびクエリできるようになります。
F. 各クライアントのユーザーに適切な Identity and Access Management (IAM) ロールを使用します。
各クライアントのユーザーまたはグループに固有の IAM ロールを割り当てます。IAM ロールは、データセット内で実行できるアクションを制御し、各クライアントが自分のデータに適切なレベルのアクセス権を持ち、他のクライアントのデータへのアクセスが制限されるようにします。
これらの手順をまとめて、Google BigQuery 内の各クライアントのデータにデータの分離、アクセス制御、セキュリティを提供し、クライアントデータを安全かつ独立して管理できるようにします。
</div></details>

### Q. 質問9: 未回答
Google Cloud Platform で実行される POS アプリケーションを開発しています。アプリケーションは支払いトランザクションを処理し、ユーザーベースが指数関数的に増加すると予想されます。データベースのインフラストラクチャのスケーリングを管理したくないため、スケーラブルで信頼性が高く、安全な Google データベース サービスを選択する必要があります。
どのGoogleデータベースサービスを使用する必要がありますか?
1. 　Cloud SQL
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解 - A. Cloud SQL
ユーザーベースが急激に増加する可能性があると予想される POS アプリケーションで支払いトランザクションを処理する場合、インフラストラクチャのスケーリングの管理を避けたい場合は、Cloud SQL が適しています。その理由は次のとおりです。
1. 　Cloud SQL はフルマネージドのリレーショナル データベース サービスです: スケーリングやメンテナンスなどのインフラストラクチャ管理を行うため、アプリケーションの開発とビジネス ロジックに集中できます。
2. ACID コンプライアンス: Cloud SQL は、支払いトランザクションを処理し、データの一貫性と信頼性を確保するために不可欠な強力な ACID(Atomicity、Consistency、Isolation、Durability)コンプライアンスを提供します。
3. 一般的なデータベースエンジンとの互換性: Cloud SQL は、MySQL、PostgreSQL、SQL Server など、複数のデータベースエンジンをサポートしているため、アプリケーション固有の要件に柔軟に対応できます。
正しくないオプション -
BigQuery(オプション B)、Cloud Bigtable(オプション C)、Cloud Datastore(オプション D)は価値ある Google Cloud データベース サービスですが、ユースケースは異なります。
- BigQuery は、フルマネージドでサーバーレス、かつ拡張性の高いデータ ウェアハウス サービスであり、支払いトランザクションなどのトランザクション処理ではなく、主に分析やビジネス インテリジェンスのワークロードに使用されます。
- Cloud Bigtable は、高スループット、低レイテンシ、スケーラビリティを実現するように設計された NoSQL データベース サービスで、通常、大規模な高速な読み取りおよび書き込み操作を必要とするアプリケーションに使用されます。トランザクション処理には最適ではない可能性があります。
- Cloud Datastore は、ウェブ アプリケーションやモバイル アプリケーションの構築に適した NoSQL ドキュメント データベース サービスですが、特定の ACID 要件により、支払いトランザクションの処理には最適ではない場合があります。
</div></details>

### Q. 質問10: 未回答
組織サンプルに関する情報のデータベースを使用して、将来の組織サンプルを正常または変異のいずれかに分類します。組織サンプルを分類するための教師なし異常検出方法を評価しています。この方法をサポートする 2 つの特性はどれですか?(2つ選択してください。
1. 　正常なサンプルと比較して突然変異の発生はほとんどありません。
2. 
3. 将来の突然変異は、データベース内の突然変異したサンプルとは異なる特徴を持つと予想されます。
4. 
<details><div>
    答え：1,3
説明
組織サンプルを正常または変異として分類するための教師なし異常検出法をサポートする2つの特性は次のとおりです。
ある。正常なサンプルと比較して突然変異の発生はほとんどありません。
- 教師なし異常検出では、この方法は通常、異常(この場合は変異した組織サンプル)を、標準(正常組織サンプル)からの逸脱に基づいて識別します。正常なサンプルと比較して変異の発生が非常に少ない場合は、異常がまれで目立つため、異常検出がより効果的になります。
C. 将来の突然変異は、データベース内の突然変異したサンプルとは異なる特徴を持つと予想されます。
- 教師なし異常検出法は、異常が大部分のデータ(正常サンプル)と比較して明確な特徴または特性を持っているという考えに基づいて異常を検出することを目的としています。将来の変異が、データベースにすでに存在する変異したサンプルとは異なる特徴を持つことが予想される場合、これは特徴の違いに基づいて異常を特定するという前提と一致します。
正しくないオプション -
オプションBは、正常サンプルと変異サンプルの両方がほぼ等しい発生であっても、異常の効果的な識別に必ずしも役立つとは限らないため、通常、教師なし異常検出をサポートする特性ではありません。
また、オプションDは、教師なし異常検出を直接サポートする特性ではありません。将来の突然変異がデータベース内の突然変異したサンプルと類似した特徴を持っている場合、特徴ベースの方法を使用してそれらを異常として区別することは困難である可能性があります。
オプションEは、どのサンプルが変異し、どのサンプルが正常であるかを示すラベルを持つことに言及しており、教師なしアプローチではなく教師ありアプローチを示唆しています。教師なし異常検出は、トレーニング用のラベル付きデータがないが、標準からの逸脱に基づいてデータセット内の異常を検出する場合に使用されます。
</div></details>

### Q. 質問11: 未回答
あなたは、毎分 10,000 メッセージの割合で Google BigQuery にソーシャル メディアの投稿を保存および分析するアプリケーションを設計する任務を負っています。このアプリケーションでは、ストリーミング挿入を使用して、個々の投稿をほぼリアルタイムで BigQuery に挿入します。アプリケーションは、ストリーミング挿入の直後にデータ集計も実行します。ただし、ストリーミング挿入後のクエリは厳密な一貫性を示さず、クエリからのレポートで処理中のデータが失われる可能性があることがわかります。
アプリケーションの設計を調整して、クエリの一貫性が保たれ、レポートが処理中のデータを見逃さないようにするにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. ストリーミング挿入後のデータ可用性の平均待機時間を推定し、常に 2 倍の待機時間後にクエリを実行します。
<details><div>
    答え：4
説明
D. ストリーミング挿入後のデータ可用性の平均待機時間を推定し、常に 2 倍の待機時間後にクエリを実行します。
ストリーミング挿入後に BigQuery でデータが使用可能になるまでの平均レイテンシを計算します。このレイテンシーは変動する可能性があるため、正確に見積もるには監視と分析が必要です。
レイテンシーを見積もった後、推定レイテンシーよりも長い期間待機した後に実行するようにクエリを設定します。たとえば、平均待機時間が 1 分の場合、クエリを 3 分ごとに実行するようにスケジュールできます。
予想されるデータ可用性の待機時間よりも長く待機することで、クエリは、最近挿入されたデータと、すぐには使用できなかった可能性のある処理中のデータの両方を確実にキャプチャします。
このアプローチにより、クエリの一貫性を確保し、処理中のデータを見逃すことなくすべての関連データをキャプチャできます。これは、ほぼリアルタイムの分析を維持しながら、データの可用性の変動に対処するための実用的な方法です。
正しくないオプション -
A. 蓄積されたデータを 2 分ごとにロードするようにアプリケーションを書き直します。
このアプローチでは、BigQuery に読み込む前に 2 分間データを蓄積することを提案します。これにより、データの読み込み頻度は減る可能性がありますが、転送中のデータの一貫性の問題には対処できません。それでも、この 2 分間の間にデータが欠落する可能性があるという同じ問題に直面します。
B. ストリーミング挿入コードを個々のメッセージのバッチ読み込みに変換します。
ストリーミング挿入からバッチ読み込みに切り替えると、強力な一貫性が得られる場合がありますが、ほぼリアルタイムの処理という目標に大きな影響を与えます。通常、バッチ読み込みは遅く、ほぼリアルタイムで到着するデータを分析するための要件には適合しません。
C. 元のメッセージを Google Cloud SQL に読み込み、ストリーミング挿入を使用してテーブルを 1 時間ごとに BigQuery にエクスポートします。
このアプローチでは、Google Cloud SQL と BigQuery への時間単位のエクスポートが関係するため、複雑さが増します。時間間隔内では強力な一貫性が提供される場合がありますが、ほぼリアルタイムで毎分 10,000 メッセージの速度でデータを処理するのには適していません。
</div></details>

### Q. 質問12: 未回答
スタートアップが正式なセキュリティポリシーを実装していない。現在、社内の全員が Google BigQuery に保存されているデータセットにアクセスできます。チームは、適切と思われるサービスを自由に使用できますが、ユースケースを文書化していません。データウェアハウスをセキュリティで保護するように求められました。みんなが何をしているのかを知る必要があります。最初に何をすべきですか?
1. 　Google Stackdriver 監査ログを使用して、データアクセスを確認します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
データウェアハウスを保護し、全員が何をしているかを理解するために取るべき最初のステップは次のとおりです。
A. Google Stackdriver 監査ログを使用して、データアクセスを確認します。
Google Stackdriver 監査ログは、Google Cloud 環境で誰が、どこで、いつ、何をしたかに関する詳細情報を提供します。これらのログを確認することで、BigQuery データセットにアクセスしているユーザーや、そのユーザーが実行しているアクションを把握できます。これは、データアクセスの現状を把握し、潜在的なセキュリティリスクや不正アクセスを特定するための重要な最初のステップです。
正しくないオプション -
B. 各テーブルの ID およびアクセス管理 (IAM) ポリシーを取得することは、アクセス制御ポリシーの定義と適用に役立ちますが、継続的なデータ アクセスの全体像を把握できない場合があります。
C. Stackdriver Monitoring を使用して BigQuery クエリスロットの使用状況を確認する方法は、データアクセスの監査ではなく、クエリのパフォーマンスとリソース使用率のモニタリングに重点が置かれています。
D. Google Cloud Billing API を使用してウェアハウスがどのアカウントに請求されているかを確認することは、請求とコスト追跡に関連しており、これは重要ですが、データ アクセスを理解して保護する必要性に直接対処するものではありません。
</div></details>

### Q. 質問13: 未回答
会社には、オンプレミスに 30 ノードの Apache Hadoop クラスターがあります。このクラスタを Google Cloud Platform(GCP)に移行しながら、既存の Hadoop ジョブを再利用できるようにしたいと考えています。また、クラスターの管理を可能な限り最小限に抑え、クラスターの存続期間を超えてデータを保持できるようにしたいと考えています。
このクラスタを GCP に移行するには、どのような手順が必要ですか?
1. 　
2. 
3. 
4. Google Cloud Storage コネクタを使用する Cloud Dataproc クラスタを作成します。
<details><div>
    答え：4
説明
D. Google Cloud Storage コネクタを使用する Cloud Dataproc クラスタを作成します。
オプションDは、Hadoopクラスタをクラウドに移行しながら、管理を最小限に抑え、データの永続性を有効にするための有効な選択肢です。その理由は次のとおりです。
Google Cloud Dataproc: Dataproc は Google Cloud 上のマネージド Hadoop および Spark サービスであり、クラスタ管理の複雑さの多くを抽象化します。
Google Cloud Storage Connector: Google Cloud Storage コネクタを使用すると、Hadoop データに耐久性と拡張性に優れたストレージを提供する Google Cloud Storage にデータを保存できます。
Hadoop ジョブの再利用: Dataproc は Apache Hadoop と完全に互換性があり、大幅な変更なしで既存の Hadoop ジョブを再利用できます。
管理の最小化: Dataproc は、クラスタのプロビジョニング、サイズ変更、管理タスクを簡素化し、運用上のオーバーヘッドを削減します。
データの永続性: Google Cloud Storage はデータの永続性を重視して設計されているため、データはクラスタのライフサイクルとは無関係に保存されます。
この設定では、Hadoop ジョブは Google Cloud Storage に対してデータの読み取りと書き込みを行うことができるため、クラスタの寿命が尽きるまでデータの耐久性を確保できます。
Dataproc に関するよくある質問: https://cloud.google.com/dataproc/docs/resources/faq
オプション B(HDFS 用の永続ディスクを含む Dataproc クラスタを作成する)も有効なアプローチであり、HDFS によるデータの永続性を提供します。オプションBとオプションDのどちらを選択するかは、特定の要件と、HadoopデータのストレージレイヤーとしてHDFSとGoogle Cloud Storageのどちらを使用するかによって異なります。どちらのオプションも、ユースケースに応じて効果的に機能します。
参考リンク -
Google Cloud Dataproc: https://cloud.google.com/dataproc
Hadoop から Cloud Dataproc への移行: https://cloud.google.com/dataproc/docs/tutorials/migrating-hadoop
</div></details>

### Q. 質問14: 未回答
あなたの会社の事業主は、銀行取引のデータベースをあなたに与えました。各行には、ユーザー ID、トランザクション・タイプ、トランザクション・ロケーション、およびトランザクション金額が含まれます。データに適用できる機械学習の種類を調査するように求められます。使用できる機械学習アプリケーションを 3 つ選ぶのはどれですか?(3つ選択してください。
1. 　
2. どの取引が不正である可能性が最も高いかを判断するための教師なし学習。
3. 特徴の類似性に基づいてトランザクションを N 個のカテゴリに分割するクラスタリング。
4. トランザクションの場所を予測するための教師あり学習。
<details><div>
    答え：2,3,4
説明
正解は -
B. どの取引が不正である可能性が最も高いかを判断するための教師なし学習。
異常検出やクラスタリングなどの教師なし学習は、ラベル付けされた例を必要とせずに、トランザクションデータのパターンや異常を特定するために使用できます。これは、通常の動作からの逸脱に基づいて、不正の可能性があるトランザクションを検出するのに役立ちます。
C. 特徴の類似性に基づいてトランザクションを N 個のカテゴリに分割するクラスタリング。
クラスタリングは、特徴の類似性に基づいてトランザクションをカテゴリまたはクラスターにグループ化できる教師なし学習手法です。これは、データ内のパターンやグループを特定するのに役立ち、一般的なトランザクションの動作や特性を明らかにすることができます。
D. トランザクションの場所を予測するための教師あり学習。
教師あり学習は、場所がターゲット変数である履歴データに基づいてトランザクションの場所を予測するためにも使用できます。モデルをトレーニングして、他の特徴量からトランザクションの場所を予測することができ、これはロケーションベースのサービスや分析に役立ちます。
</div></details>

### Q. 質問16: 未回答
自動車メーカーに勤務し、Google Cloud Pub/Sub を使用してデータ パイプラインを設定し、異常なセンサー イベントをキャプチャしました。Cloud Pub/Sub でプッシュ サブスクリプションを使用していて、作成したカスタム HTTPS エンドポイントを呼び出して、これらの異常なイベントが発生したときにアクションを実行しています。カスタム HTTPS エンドポイントで、重複するメッセージが大量に受信され続けます。これらの重複メッセージの最も可能性の高い原因は何ですか?
1. 　
2. 
3. 
4. カスタム エンドポイントが、受信確認の期限内にメッセージを確認していません。
<details><div>
    答え：4
説明
D. カスタム エンドポイントが、受信確認の期限内にメッセージを確認していません。
このシナリオで重複するメッセージを受信する原因として最も可能性が高いのは、カスタム HTTPS エンドポイントが確認の期限内に Cloud Pub/Sub からのメッセージを認識していないことです。
Cloud Pub/Sub では、メッセージがサブスクライバー(この場合はカスタム HTTPS エンドポイント)に配信されると、サブスクライバーはメッセージの受信を確認する必要があります。確認の期限内に確認応答が受信されなかった場合、Cloud Pub/Sub はメッセージがサブスクライバーによって正常に処理されなかったと見なし、再配信します。
重複したメッセージを受信しないようにするには、カスタム HTTPS エンドポイントがメッセージを正常に処理したら、すぐに確認応答するようにする必要があります。これにより、メッセージが処理されたことが Cloud Pub/Sub に通知され、再配信されません。
カスタム エンドポイントのロジックを確認して、重複を防ぐために、予想される期間内にメッセージを確認するようにします。
</div></details>

### Q. 質問17: 未回答
会社では、独自のシステムを使用して、6 時間ごとにクラウドベースのデータ インジェスト サービスにインベントリ データを送信しています。データには、在庫品目 ID、名前、数量、場所など、いくつかのフィールドのペイロードが含まれます。送信のタイムスタンプも含まれます。送信に懸念がある場合は、システムによってデータが再送信されます。データの重複排除を最も効率的に行うにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. 各データエントリのハッシュ値とその他のメタデータを格納するデータベーステーブルを維持します。
<details><div>
    答え：4
説明
D. 各データエントリのハッシュ値とその他のメタデータを格納するデータベーステーブルを維持します。
送信されたデータの重複排除を行う最も効率的な方法は、各データエントリのハッシュ値とその他のメタデータを格納するデータベーステーブルを維持することです。このアプローチが効率的である理由は次のとおりです。
1.ハッシュ:各データエントリのハッシュ値の計算は、高速で効率的なプロセスです。ハッシュ関数は、データの内容に基づいて固定サイズのハッシュコードを生成し、比較的迅速に計算できます。
2.ストレージ:ハッシュ値やその他のメタデータをデータベーステーブルに格納することで、効率的なインデックス作成とクエリが可能になります。ハッシュ値を主キーとして使用したり、インデックス付き列で使用して高速検索を行ったりすることができます。
3.重複排除:新しいデータを受信すると、そのハッシュ値を計算し、データベースにすでに保存されているハッシュ値と比較できます。一致するハッシュ値が見つかった場合は、データが重複していることをすばやく判断し、適切なアクションを実行できます。
4.タイムスタンプ:データには送信のタイムスタンプが含まれます。このタイムスタンプをハッシュ値とともに使用して、再送信の場合に特定のデータエントリの最新バージョンを識別できます。
ハッシュ値とメタデータを使用してデータベーステーブルを維持することは、特に再送信やその他の問題のためにデータ転送に重複が含まれる可能性がある場合に、データの重複を排除するためのスケーラブルで効率的な方法です。このアプローチにより、受信データの迅速かつ信頼性の高い重複排除が可能になります。
</div></details>

### Q. 質問18: 未回答
あなたの会社は、Google Cloud に保存されている非常に大規模なデータセットに対して複雑な分析を実行したいと考えている新しいデータ サイエンティストを採用しました ストレージと Google Compute Engine の Cassandra クラスタ内。サイエンティストは、主に機械学習プロジェクト用のラベル付きデータセットと、いくつかの視覚化タスクを作成したいと考えています。彼女は、ラップトップがタスクを実行するのに十分なパワーがなく、速度が低下していると報告しています。あなたは彼女がタスクを実行するのを手伝いたいです。 あなたは何をするべきか?
1. 　
2. 
3. 
4. Google Compute Engine 上の仮想マシン(VM)に Google Cloud Datalab をデプロイします。
<details><div>
    答え：4
説明
Datalab は廃止され、Datalab create コマンドを使用して新しい Datalab インスタンスを作成することはできません。詳細については、以下の参照リンクを参照してください。
D. Google Compute Engine 上の仮想マシン(VM)に Google Cloud Datalab をデプロイします。
Google Cloud Datalab は、データの探索、分析、可視化のための強力なインタラクティブ ツールです。これは、データ サイエンスと機械学習のタスクに合わせて調整された Jupyter Notebook 環境を提供します。このシナリオでは、いくつかの理由から、Google Compute Engine 上の VM に Google Cloud Datalab をデプロイするのが最適なオプションです。
1. 　パフォーマンス: Google Cloud Datalab は、十分なコンピューティング リソースを備えた VM にデプロイできるため、データ サイエンティストは、大規模なデータセットを操作したり、複雑な分析を実行したりするための強力なコンピューティング環境にアクセスできます。
2. スケーラビリティ: Google Compute Engine 上の VM は、データ サイエンティストの特定の要件を満たすために、さまざまなレベルの CPU およびメモリ リソースでプロビジョニングできます。このスケーラビリティにより、より大きなデータセットを効率的に操作できます。
3. 統合: Google Cloud Datalab は、Google Cloud Storage、Cassandra、およびその他の Google Cloud Platform サービスとシームレスに統合されます。これにより、データサイエンティストは、単一の環境内で複数のソースからのデータに簡単にアクセスして分析できます。
4. コラボレーション: Google Cloud Datalab はチーム メンバーと共同で共有できるため、データ分析や機械学習プロジェクトでの効果的なコラボレーションが可能になります。
5. バージョン管理: Datalab ノートブックは、Git などのツールを使用してバージョン管理でき、データ分析コードとドキュメントを管理するための構造化された整理されたアプローチを提供します。
Google Cloud Datalab を Google Compute Engine にデプロイすることで、データ サイエンティストはデータ分析、可視化、機械学習のタスクに堅牢で柔軟な環境を提供し、ノートパソコンの限界に関する懸念に対処できます。
参考リンク -
https://cloud.google.com/vertex-ai/docs/workbench/introduction
</div></details>

### Q. 質問19: 未回答
10,000 台の新しい IoT デバイスを導入して、世界中の倉庫の温度データを収集しています。これらのデバイスからのデータは非常に高い速度で生成され、リアルタイムで処理、保存、分析する必要があります。
このプロセスに関連する主な考慮事項と手順は何ですか?
1. 　
2. Google Cloud Pub/Sub にデータを送信し、Cloud Pub/Sub を Google Cloud Dataflow にストリーミングして、Google BigQuery にデータを保存します。
3. 
4. 
<details><div>
    答え：2
説明
正しいオプション: B. Google Cloud Pub/Sub にデータを送信し、Cloud Pub/Sub を Google Cloud Dataflow にストリーミングして、Google BigQuery にデータを保存します。
このオプションは、次の理由により、モノのインターネット (IoT) デバイスからの非常に大きなデータセットをリアルタイムで処理、保存、分析する場合に最も適しています。
Google Cloud Pub/Sub の場合:Google Cloud Pub/Sub は、高スループットのリアルタイム データ インジェスト向けに設計されています。これは、IoTデバイスからの受信データストリームを効率的に処理できるメッセージングサービスとして機能します。
Google Cloud データフロー:Google Cloud Dataflow は、フルマネージドのストリームおよびバッチ データ処理サービスです。Cloud Pub/Sub からの受信データをリアルタイムで処理し、必要に応じて変換や集計を適用してから、処理したデータを目的の宛先(Google BigQuery など)に送信できます。
Google BigQueryの場合:Google BigQuery は、大規模なデータセットの高速クエリ用に設計されたサーバーレス データ ウェアハウスおよび分析プラットフォームです。IoTデータをBigQueryに保存することで、データのリアルタイムなクエリと分析が可能になり、倉庫の温度データの監視と分析に適しています。
主な考慮事項は次のとおりです。
データ量:10,000台のIoTデバイスによって生成されるデータは非常に大きくなります。このデータを保存および処理するために必要なインフラストラクチャが整っていることを確認する必要があります。
データ処理の速度: データを迅速に処理できるように、データをリアルタイムで処理する必要があります。大量のデータを処理できるプラットフォームを使用する必要があります。
データのセキュリティ:IoTデバイスによって収集されるデータは機密性が高く、保護する必要があります。不正アクセスからデータを保護できる安全なプラットフォームを使用する必要があります。
ソリューションのスケーラビリティ: 倉庫内の IoT デバイスの数は、将来的に増加する可能性があります。選択したソリューションがスケーラブルであることを確認して、デバイスを簡単に追加できるようにする必要があります。
正しくないオプション -
A. Google Cloud Datastore にデータを送信し、BigQuery にエクスポートします。
Google Cloud Datastore は、よりシンプルなクエリのニーズで構造化データを保存するのに適しています。大規模なIoTデータストレージやリアルタイム分析には理想的な選択肢ではないかもしれません。
Datastore から BigQuery にデータをエクスポートすると、レイテンシが発生する可能性があり、リアルタイム分析に適していない可能性があります。
C. データを Cloud Storage に送信し、分析が必要なときはいつでも、必要に応じて Google Cloud Dataproc で Apache Hadoop クラスタを起動します。
オブジェクト ストレージには Cloud Storage が適していますが、Hadoop クラスタをオンデマンドでスピンアップすると複雑さが増し、リアルタイムの IoT データ処理のための Cloud Dataflow や BigQuery などのマネージド サービスほど費用対効果や拡張性に欠ける可能性があります。
このアプローチは、リアルタイム分析よりもバッチ処理に適しています。
D. ログを Google Cloud Storage にバッチでエクスポートし、Google Cloud SQL インスタンスを起動し、Cloud Storage からデータをインポートして、必要に応じて分析を実行します。
Google Cloud SQLはリレーショナルデータベースサービスであり、大規模なIoTデータの処理には適していない可能性があります。
Cloud SQL でバッチ処理を実行することは、IoT データのリアルタイム分析を実行する最も効率的な方法ではありません。
このアプローチでは、より合理化された Cloud Pub/Sub、Cloud Dataflow、BigQuery パイプラインと比較して、複雑さとレイテンシが生じる可能性があります。
</div></details>

### Q. 質問20: 未回答
CSV ファイルから Google BigQuery テーブル CLICK_STREAMにデータをロードしました。列 DT には、クリック イベントのエポック タイムが格納されます。最初に、すべてのフィールドが STRING 型として扱われる単純なスキーマを選択しました。次に、サイトを訪問するユーザーの Web セッション時間を計算し、DT のデータ型を TIMESTAMP 型に変更します。移行の労力を最小限に抑え、将来のクエリの計算コストが高くならないようにする必要があります。
あなたは何をするべきか?
1. 　
2. 
3. 
4. 
5. 組み込み関数を使用して列 DT の文字列を TIMESTAMP 値にキャストしながら、テーブルCLICK_STREAMのすべての行を返すクエリを作成します。列 TS が TIMESTAMP 型である宛先テーブル NEW_CLICK_STREAMに対してクエリを実行します。今後は、表CLICK_STREAMの代わりに表NEW_CLICK_STREAM参照します。今後、新しいデータがテーブルNEW_CLICK_STREAMにロードされます。
<details><div>
    答え：5
説明
E. 組み込み関数を使用して列 DT の文字列を TIMESTAMP 値にキャストしながら、テーブルCLICK_STREAMのすべての行を返すクエリを作成します。列 TS が TIMESTAMP 型である宛先テーブル NEW_CLICK_STREAMに対してクエリを実行します。今後は、表CLICK_STREAMの代わりに表NEW_CLICK_STREAM参照します。今後、新しいデータがテーブルNEW_CLICK_STREAMにロードされます。
データ変換: オプション E では、DT 列の文字列を TIMESTAMP 値にキャストするクエリを使用して、既存のテーブル (CLICK_STREAM) 内のデータを変換します。この変換はクエリの実行中に行われるため、元のテーブル スキーマは変更されません。
新しいテーブル: このクエリの結果は、DT 列が TIMESTAMP に変換され、TS という名前が付けられた新しいテーブル (NEW_CLICK_STREAM) に保存されます。このテーブルには、目的のデータ型のデータが含まれます。
最小限の移行作業: データの移動を伴う元のテーブルを削除または再作成する必要はありません。代わりに、適切なスキーマを使用して新しいテーブルを作成します。これにより、移行の労力が最小限に抑えられます。
下位互換性: CLICK_STREAM テーブルを参照する既存のクエリは、変更なしで引き続き機能します。必要に応じて、新しいテーブルを参照するようにクエリを段階的に更新できます。
将来のデータに効率的: 新しいデータをNEW_CLICK_STREAMテーブルに直接ロードできるため、挿入時のデータ変換が不要になります。これにより、将来のデータを効率的に処理できます。
正しくないオプション -
A. テーブルの削除と再作成 (オプション A) は、すべてのデータを再読み込みする必要があるため、時間がかかり、テーブルを参照するクエリの変更が必要になる場合があります。
B. 既存の列 (DT) と並行して新しい列 (TS) を追加し、データを移行する (オプション B) とすると、テーブルが複雑になり、冗長になり、メンテナンスが困難になる可能性があります。
C. ビュー (オプション C) を作成すると、データ型の表示が変更される可能性がありますが、基になるデータ型は実際には変更されず、クエリのパフォーマンスに影響を与える可能性があります。
D. 列 (TS と IS_NEW) を追加し、IS_NEW フラグ (オプション D) に基づいてデータを管理すると、スキーマが不必要に複雑になり、ユース ケースの効率的なソリューションではない可能性があります。
</div></details>

### Q. 質問21: 未回答
Google Stackdriver Logging を使用して Google BigQuery の使用状況をモニタリングしたい。挿入ジョブを使用して特定のテーブルに新しいデータが追加されたときに即座に通知を受け取る必要がありますが、他のテーブルの通知は受け取りたくない。
どうすればこれを実現できますか?
1. 　
2. 
3. 
4. Stackdriver API を使用して、Pub/Sub にエクスポートする高度なログ フィルタを含むプロジェクト シンクを作成し、モニタリング ツールからトピックをサブスクライブします。
<details><div>
    答え：4
説明
D. Stackdriver API を使用して、Pub/Sub にエクスポートする高度なログ フィルタを含むプロジェクト シンクを作成し、モニタリング ツールからトピックをサブスクライブします。
このオプションでは、Stackdriver API を使用して、特定のログエントリを Google Cloud Pub/Sub にエクスポートするカスタムログシンクを作成します。
高度なログフィルタを使用すると、Pub/Sub トピックにエクスポートするログエントリを正確に定義できます。この場合、BigQuery の挿入ジョブを使用して特定のテーブルに新しいデータが追加されたときに通知を受け取り、それに応じてフィルタを設定できます。
Stackdriver API は、ログのエクスポートをきめ細かく制御できるため、特定の要件に合わせてログのエクスポートを調整する必要がある、より複雑なユースケースに適しています。
モニタリング ツールから Pub/Sub トピックをサブスクライブすると、フィルタ条件に一致する新しいログエントリがパブリッシュされたときにリアルタイムで通知を受け取ることができます。
正しくないオプション -
A. Stackdriver API を呼び出してすべてのログを一覧表示し、高度なフィルタを適用します。
このオプションでは、Stackdriver API を使用してすべてのログを手動で一覧表示し、高度なフィルタを適用することを提案します。この方法でログをフィルタリングすることはできますが、ログが多数ある場合や、リアルタイムの通知が必要な場合は、実用的なアプローチではありません。
B.Stackdriver のログ管理インターフェースで、BigQuery へのログシンクのエクスポートを有効にします。
このオプションでは、ログシンクを使用してログを BigQuery にエクスポートし、分析と保存に役立てることができます。ただし、求めているリアルタイム通知機能は提供されません。これは、長期的なログ ストレージとクエリに重点を置いています。
C. Stackdriver のログ管理インターフェースで、Google Cloud Pub/Sub へのログシンクのエクスポートを有効にし、モニタリング ツールからトピックをサブスクライブします。
このオプションは、リアルタイムのイベントドリブン ワークフローで一般的に使用される Pub/Sub の使用に言及することで、正しい方向に進んでいます。ただし、BigQuery で特定のテーブルの挿入ジョブの通知のみを受信するという特定の要件は考慮されていません。高度なフィルタを使用しない場合、すべてのログが Pub/Sub に送信されます。
</div></details>

### Q. 質問22: 未回答
プライベートなユーザーデータを含む機密性の高いプロジェクトに取り組んでいる。Google Cloud Platform にプロジェクトを設定し、社内で作業を格納しました。外部コンサルタントが、プロジェクトの Google Cloud Dataflow パイプラインでの複雑な変換のコーディングを支援します。ユーザーのプライバシーをどのように保護する必要がありますか?
1. 　
2. 
3. 
4. コンサルタントが別のプロジェクトで作業するためのデータの匿名化されたサンプルを作成することです。
<details><div>
    答え：4
説明
正解は、オプション D: コンサルタントが別のプロジェクトで作業するためのデータの匿名化されたサンプルを作成することです。
オプションDは、データのプライバシーとセキュリティを優先するため、正しい選択です。これには、次の手順が含まれます。
1. 　データの匿名化: 外部コンサルタントとデータを共有する前に、機密性の高いユーザーデータのサニタイズまたは匿名化されたサンプルを作成します。これは、プライバシーを確保するために、個人を特定できる情報(PII)や機密情報を削除または難読化することを意味します。
2. 別のプロジェクト: コンサルタントが作業する別のプロジェクトまたは環境を設定します。このプロジェクトには、匿名化されたデータセットと、Dataflow パイプラインの開発に必要なツールが含まれています。
3. コラボレーション: コンサルタントは、実際の機密データにアクセスすることなく、この制御された環境内でコラボレーションを行うことができます。匿名化されたデータセットを使用して Dataflow パイプラインを開発、テスト、最適化できます。
正しくないオプション -
A. オプション A では、コンサルタントにプロジェクトの閲覧者ロールを付与することを提案します。これにより、すべてのリソースへの読み取り専用アクセスが許可されますが、データのプライバシーや分離には対処されません。
B. オプション B では、コンサルタントにプロジェクトの Cloud Dataflow デベロッパー ロールを付与することをおすすめします。Dataflow パイプラインの開発は可能ですが、データのプライバシーを確保したり、コンサルタントの作業を機密データから分離したりすることはできません。
C. オプション C では、アクセスを管理する方法であるサービス アカウントの作成について言及していますが、データのプライバシーと分離を維持する方法は指定されていません。通常、サービス アカウントは認証と承認に使用されますが、データ アクセスを制御するには慎重に構成する必要があります。
</div></details>

### Q. 質問25: 未回答
あなたの会社は、工場の現場から Bigtable にリアルタイムのセンサー データをストリーミングしています。このデータは、リアルタイムのダッシュボードに入力するために使用されています。ただし、ダッシュボードに入力するクエリのパフォーマンスは低下します。クエリのパフォーマンスを向上させるために、行キーをどのように再設計する必要がありますか?
1. 　
2. 
3. 
4. #<sensorid>#<timestamp>
<details><div>
    答え：4
説明
D. >#<sensorid>#<timestamp> という形式の行キーを使用します。
Bigtable では、行キーの選択は、データへのアクセス方法やクエリ方法など、さまざまな要因によって異なります。行キーとして #<sensorid>#<timestamp> を使用すると、リアルタイム ダッシュボード クエリのパフォーマンスが向上する場合は、それが正しい選択です。この形式は、特にクエリにセンサー ID とタイムスタンプによるフィルター処理が頻繁に含まれる場合に、データの分散とアクセス パターンに役立つ可能性があります。
参考リンク -
https://cloud.google.com/bigtable/docs/schema-design
</div></details>

### Q. 質問26: 未回答
多くの場合、会社の顧客データベースと注文データベースには大きな負荷がかかっています。これにより、運用に支障をきたすことなく分析を実行することが困難になります。データベースはMySQLクラスタ内にあり、mysqldumpを使用して夜間バックアップが取得されます。運用への影響を最小限に抑えて分析を実行したい。あなたは何をするべきか?
1. 　
2. ETL ツールを使用して、MySQL から Google BigQuery にデータをロードします。
3. 
4. 
<details><div>
    答え：2
説明
B. ETL ツールを使用して、MySQL から Google BigQuery にデータをロードします。
その理由は次のとおりです。
最小限の影響:ETL(抽出、変換、ロード)ツールを使用してGoogle BigQueryにデータをロードすると、運用中のMySQLクラスタに大きな影響を与えることなく分析を実行できます。ETLプロセスは、中断を最小限に抑えるために、オフピーク時にスケジュールできます。
スケーラビリティ: Google BigQuery は、大規模なデータ分析を処理するように設計されています。大規模なデータセットを効率的に処理およびクエリできるため、ソースMySQLクラスタに過負荷をかけることなく分析タスクに適しています。
懸念事項の分離: データを BigQuery に移動することで、分析ワークロードをオペレーショナル データベースから分離します。この分離は、分析タスクが顧客データベースと注文データベースのパフォーマンスと可用性に影響を与えないようにするためのベストプラクティスです。
リアルタイム分析: Google BigQuery はリアルタイムのデータストリーミングをサポートしているため、データが利用可能になったときにデータを取り込むことができます。これは、夜間のバックアップを待たずにほぼリアルタイムの分析を行うのに役立ちます。
正しくないオプション -
MySQL クラスターにノードを追加する (オプション A) やオンプレミスの Apache Hadoop クラスターに接続する (オプション C) などのオプションは分析に役立つ可能性がありますが、ソース データベースに追加の負荷がかかる可能性があります。Google Cloud Dataproc とバックアップを含むオプション D も機能しますが、分析に BigQuery を直接使用するほど簡単で効率的ではない可能性があります。したがって、ETLプロセスでGoogle BigQueryを使用することが、このユースケースに推奨されるアプローチです。
</div></details>

### Q. 質問27: 未回答
Google Cloud Dataflow ストリーミング パイプラインが実行されており、Google Cloud Pub/Sub サブスクリプションからデータを受信している。このパイプラインのコードを更新する必要がありますが、この更新により、新しいパイプラインは現在のパイプラインと互換性がなくなります。この更新を行うときにデータが失われないようにします。
データが失われないようにするには、どのような手順を踏む必要がありますか?
1. 　現在のパイプラインを更新し、"drain" フラグを使用します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解: A. 現在のパイプラインを更新し、"drain" フラグを使用します。
Google Cloud Pub/Sub サブスクリプションをソースとして Google Cloud Dataflow ストリーミング パイプラインを実行している場合、その過程でデータを失うことなくパイプラインを更新することが不可欠です。「drain」フラグは、この目的のために Dataflow が提供する機能です。その仕組みは次のとおりです。
現在のパイプライン コードを更新して「drain」フラグを使用すると、すでに転送中または処理中の既存のデータの処理を続行するように Dataflow に指示されます。
同時に、Dataflow は Pub/Sub サブスクリプションから新しいデータを受け付けません。これにより、移行中にデータが失われることはありません。
既存のデータは、完全に処理されるまでパイプラインを通過し続け、データが取り残されないようにします。
正しくないオプション -
B. 現在のパイプラインを更新し、変換マッピング JSON オブジェクトを指定します。
このオプションでは、更新中のデータの継続性の問題には対処されません。変換マッピング JSON オブジェクトを提供するだけでは、データが中断されることなく処理されるとは限りません。
C. 同じ Cloud Pub/Sub サブスクリプションを持つ新しいパイプラインを作成し、古いパイプラインをキャンセルします。
新しいパイプラインを作成し、古いパイプラインを取り消すと、データ処理が中断されます。更新中のデータ損失を回避する必要がある場合は、適切なソリューションではありません。
D. 新しい Cloud Pub/Sub サブスクリプションを持つ新しいパイプラインを作成し、古いパイプラインをキャンセルします。
同様に、新しいサブスクリプションで新しいパイプラインを作成し、古いパイプラインを取り消すと、データが失われ、データ処理が中断されます。
参考リンク -
https://cloud.google.com/dataflow/docs/guides/stopping-a-pipeline
</div></details>

### Q. 質問28: 未回答
あなたの会社は、ホリデーシーズン中にリアルタイムデータを分析して様々なオファーを提供する、最初の動的キャンペーンを実施しています。データサイエンティストは、30日間のキャンペーン期間中、毎時間急速に増加するテラバイトのデータを収集しています。Google Cloud Dataflow を使用してデータを前処理し、Google Cloud Bigtable の機械学習モデルに必要な特徴量(シグナル)データを収集しています。チームは、10 TB のデータの初期読み込みの読み取りと書き込みで、最適ではないパフォーマンスを観察しています。彼らは、コストを最小限に抑えながら、このパフォーマンスを向上させたいと考えています。彼らは何をすべきか?
1. 　表の行スペースに読み取りと書き込みを均等に分散して、スキーマを再定義します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解は:
A. 表の行スペースに読み取りと書き込みを均等に分散して、スキーマを再定義します。
この回答は、Google Cloud Bigtable のパフォーマンスを向上させるには、読み取りと書き込みがテーブルの行スペース全体に均等に分散されるようにスキーマを慎重に設計する必要があることを示唆しています。つまり、特定の行が不釣り合いに多くの操作 (読み取りまたは書き込み) を受け取るデータ内のホットスポットを防ぐことを目的としています。アクセス パターンを均等に分散することで、Bigtable のスケーラビリティと並列処理を効果的に活用できます。
正しくないオプション -
B.パフォーマンスの問題は、Bigtable クラスタのサイズが大きくなるにつれて、時間の経過とともに解決されるはずです。
Bigtable クラスタのサイズを大きくすると、大量のデータのスケーリングと処理に役立ちますが、基盤となるスキーマが最適でない場合は、パフォーマンスの問題に直接対処できない可能性があります。スキーマ設計を改善すると、多くの場合、パフォーマンスの問題に対処する方が効果的です。
C. 1 つの行キーを使用して、クラスター内で頻繁に更新する必要がある値を識別するようにスキーマを再設計します。
頻繁に更新される値に 1 つの行キーを使用すると、特定のユースケースでは役立ちますが、Bigtable の全体的なパフォーマンスの問題に対する主要な解決策にはならない場合があります。読み取りと書き込みを均等に分散するという問題に必ずしも対処できるわけではありません。
D. オファーを表示するユーザーごとに順番に増加する数値 ID に基づく行キーを使用するようにスキーマを再設計します。
行キーで連続した数値 ID を使用すると、一部のシナリオでは有益な場合がありますが、Bigtable の全体的なパフォーマンスの問題に対処するには十分ではない場合があります。これは、操作の均等な分散を確保することよりも、データ編成に重点を置いています。
参考リンク -
ビッグテーブルパフォーマンス
</div></details>

### Q. 質問29: 未回答
すべてのメッセージに単純な JSON 形式を使用するソフトウェア アプリケーションを開発しています。これらのメッセージは Google Cloud Pub/Sub に公開され、Google Cloud Dataflow で処理されて CFO 向けのリアルタイム ダッシュボードが作成されます。テスト中に、ダッシュボードに一部のメッセージが表示されないことに気付きました。ログを確認すると、すべてのメッセージが Cloud Pub/Sub に正常にパブリッシュされています。
問題のトラブルシューティングを行うには、次に何をする必要がありますか?
1. 　
2. Cloud Dataflow パイプラインで固定データセットを実行し、出力を分析します。
3. 
4. 
<details><div>
    答え：2
説明
B. Cloud Dataflow パイプラインで固定データセットを実行し、出力を分析します。
これにより、問題がパイプラインにあるのか、ダッシュボードアプリケーションにあるのかを判断できます。出力を分析することで、メッセージが正しく処理されているかどうかを確認し、不一致や欠落しているメッセージがあるかどうかを判断できます。問題がパイプラインにある場合は、デバッグして必要な更新を行い、すべてのメッセージが正しく処理されるようにすることができます。ダッシュボード アプリケーションに問題がある場合は、その問題の解決に集中できます。
このアプローチにより、制御された効率的な方法で、欠落しているメッセージの根本原因を分離して特定できます。
</div></details>

### Q. 質問30: 未回答
あなたの会社は最近急速に成長し、以前よりも大幅に高い速度でデータを取り込んでいます。毎日のバッチ MapReduce 分析ジョブは、Apache Hadoop で管理します。しかし、最近のデータの増加により、バッチジョブは遅れをとっています。開発チームがコストを増やさずに分析の応答性を向上させる方法を推奨するように求められました。あなたは彼らに何をすることを勧めるべきですか?
1. 　
2. Apache Spark でジョブを書き換える
3. 
4. 
<details><div>
    答え：2
説明
正解 - オプション B. Apache Spark でジョブを書き換える
Apache Spark は、既存の Hadoop インフラストラクチャを考慮すると、コストを大幅に増やすことなく分析ジョブの応答性を向上させるのに非常に適した選択肢です。これが正解である理由は次のとおりです。
パフォーマンスの向上:Apache Spark はインメモリ処理用に設計されているため、従来の Hadoop MapReduce と比較して、分析ジョブの実行が大幅に高速化されます。これは、バッチ ジョブをより迅速に完了できることを意味します。
使いやすさ:Sparkは、Scala、Python、Javaなどの言語で高レベルのAPIを提供し、開発者にとってより使いやすいものになっています。これにより、開発が迅速化され、分析ジョブのメンテナンスが容易になります。
資源効率:データをメモリにキャッシュする Spark の機能により、Hadoop 分散ファイル システム (HDFS) からの反復読み取りの必要性を減らすことができます。これにより、Hadoopクラスターへの負担が軽減され、データ取り込み速度の増加に追いつくことができる可能性があります。
互換性：SparkはHadoopとシームレスに統合できるため、既存のHadoopデータとインフラストラクチャを再利用できます。つまり、エコシステムを完全に見直すことなくSparkに移行できます。
正しくないオプション -
オプションA:Pigでジョブを書き換える
Pig は MapReduce プログラムを作成するための高レベルのプラットフォームですが、Apache Spark と同じレベルのパフォーマンス向上は提供されない可能性があります。Pig 自体は MapReduce フレームワークに依存しているため、データ インジェスト レートの増加に効果的に対処する能力が制限される可能性があります。
オプション C: Hadoop クラスターのサイズを増やす
ノードを追加してHadoopクラスタをスケールアップすると、パフォーマンスが向上する可能性がありますが、インフラストラクチャのコストも増加します。さらに、スケールアップでは、特に分析ジョブが現在クラスター サイズではなく処理速度によってボトルネックになっている場合は、応答性の問題に完全に対処しない可能性があります。
オプション D: Hadoop クラスターのサイズを小さくするが、Hive のジョブも書き換える
クラスターのサイズを小さくすると、コストが削減される可能性がありますが、パフォーマンスは向上しない可能性があります。さらに、Hadoop の別のクエリ言語である Hive でジョブを書き換えても、Hive のバッチ指向処理の性質上、Spark と同じパフォーマンス上の利点が得られない可能性があります。
</div></details>

### Q. 質問31: 未回答
あなたは製造工場のデータエンジニアです。プラントは、毎日午前 2:00 に、プラントのすべてのマシンからのアプリケーション ログを含む <> つのログ ファイルを生成します。このログファイルを処理する Google Cloud Dataflow ジョブを作成しました。ログ ファイルは <> 日に <> 回、できるだけ安価に処理する必要があります。
あなたは何をするべきか?
1. 　
2. 
3. Google App Engine Cron サービスを使用して cron ジョブを作成し、Cloud Dataflow ジョブを実行します。
4. 
<details><div>
    答え：3
説明
正解 - オプション C: Google App Engine Cron サービスを使用して cron ジョブを作成し、Cloud Dataflow ジョブを実行します。
Google App Engine Cron Service では、毎日午前 2:00 など、指定した間隔でタスクをスケジュールでき、ログファイルを <> 日に <> 回処理するという要件に合わせることができます。
このアプローチにより自動化が実現し、手動による介入なしに Dataflow ジョブが目的の時間に実行されるようになります。
これは、ジョブの実行時にのみコストが発生し、ログ ファイルのバッチ処理に合わせてスケジュールできるため、費用対効果の高いソリューションです。
正しくないオプション -
オプション A: 代わりに Google Cloud Dataproc を使用するように処理ジョブを変更します。
Google Cloud Dataproc は、Hadoop や Spark ジョブなどの分散データ処理タスクの実行には適していますが、毎日のログファイルを処理するだけではやり過ぎかもしれません。
Dataproc に移行するには、既存の Dataflow ジョブを書き直して調整する必要があるため、複雑さが増し、コストが高くなる可能性があります。
オプション B: 毎朝オフィスに出社したら、Cloud Dataflow ジョブを手動で開始します。
このアプローチでは、高レベルの手動介入と人間の操作への依存が導入され、エラー、遅延、信頼性の欠如につながる可能性があります。
これは、午前 2:00 に実行される自動化された毎日のプロセスの要件とうまく一致しません。
オプション D: Cloud Dataflow ジョブをストリーミング ジョブとして構成し、ログデータをすぐに処理します。
バッチ ジョブをストリーミング ジョブに変換すると、データの処理方法が根本的に変わります。ストリーミング ジョブは、特定の時間に毎日バッチ処理を行うのではなく、リアルタイムのデータ処理用に設計されています。
このオプションでは、リアルタイム処理が必要でない場合、不必要な複雑さとコストが発生する可能性があります。
</div></details>

### Q. 質問32: 未回答
あなたは経済コンサルティング会社のデータエンジニアです。あなたの仕事は、顧客データを最も一般的な 100 の商品の平均価格と関連付けることにより、企業が経済動向を特定できるように支援することです。これらの商品の平均価格は30分ごとに更新されます。このデータを常に最新の状態に保ち、BigQuery の他のデータとできるだけ安価に組み合わせられるようにする必要があります。
あなたは何をするべきか?
1. 　
2. リージョンの Google Cloud Storage バケットにデータを保存して更新し、BigQuery でフェデレーテッドデータソースを作成します。
3. 
4. 
<details><div>
    答え：2
説明
正しいオプションは次のとおりです。
B. リージョンの Google Cloud Storage バケットにデータを保存して更新し、BigQuery でフェデレーテッドデータソースを作成します。
Google Cloud Storage バケット:リージョンの Google Cloud Storage バケットにデータを保存して更新することは、費用対効果が高く効率的なアプローチです。バケット内のデータは、必要な頻度 (この場合は 30 分ごと) に更新できます。
BigQuery のフェデレーテッド データソース:BigQuery でフェデレーション データソースを作成すると、Google Cloud Storage などの外部の場所に保存されているデータを、BigQuery テーブルに読み込まなくてもクエリできます。これにより、BigQuery 内で追加のストレージ コストが発生しないため、コストが低く抑えられます。
正しくないオプション -
A. BigQuery の新しいパーティション テーブルに 30 分ごとにデータを読み込みます。
30 分ごとに BigQuery テーブルにデータを読み込むと、蓄積される履歴データが増えるため、ストレージ費用が増加する可能性があります。
パーティション分割はクエリのパフォーマンス向上に役立ちますが、長期的にはコストが高くなるため、BigQuery テーブルにデータを読み込む必要がなくなるわけではありません。
C. Google Cloud Datastore にデータを保存します。Google Cloud Dataflow を使用して BigQuery をクエリし、Cloud Datastore に保存されているデータとプログラムでデータを結合します。
このアプローチでは、不必要な複雑さと追加サービス(Cloud Datastore と Dataflow)が導入されます。
Datastore は主に NoSQL データベースであり、商品の平均価格などの時系列データには理想的なストレージ ソリューションではない可能性があります。
外部データのクエリを簡素化できる BigQuery のフェデレーション データソース機能は利用されません。
D. リージョンの Google Cloud Storage バケット内のファイルにデータを格納します。Cloud Dataflow を使用して BigQuery をクエリし、Google Cloud Storage に保存されているデータとプログラムでデータを結合します。
Dataflow を使用して BigQuery をクエリし、プログラムでデータを結合することは、フェデレーション データソースのアプローチと比較して、より複雑でコストがかかる可能性があります。
また、BigQuery から直接データをクエリする場合と比較して、追加の処理オーバーヘッドが必要になります。
</div></details>

### Q. 質問34: 未回答
あなたの会社では、毎時 20,000 個のファイルが作成されています。各データ ファイルは、4 KB 未満のカンマ区切り値 (CSV) ファイルとして書式設定されます。すべてのファイルは、処理する前に Google Cloud Platform に取り込む必要があります。会社のサイトから Google Cloud へのレイテンシは 200 ミリ秒で、インターネット接続帯域幅は 50 Mbps に制限されています。現在、Google Compute Engine の仮想マシンにセキュアな FTP(SFTP)サーバーをデータ インジェスト ポイントとしてデプロイしています。ローカルのSFTPクライアントは、CSVファイルをそのまま送信するために専用マシン上で実行されます。目標は、毎日午前 10:00 までに前日のデータを含むレポートをエグゼクティブが利用できるようにすることです。この設計は、帯域幅の使用率がかなり低いにもかかわらず、現在のボリュームにほとんど追いつくことができません。季節性により、今後 <> か月間にファイル数が <> 倍になると予想されているとします。どの <> つのアクションを実行する必要がありますか?(<>つ選択してください。
1. 　
2. 
3. gsutil ツールを使用して CSV ファイルをストレージ バケットに並行して送信するように、データ インジェスト プロセスを再設計します。
4. 1,000 個のファイルをテープ アーカイブ (TAR) ファイルにアセンブルします。代わりにTARファイルを送信し、受信時にクラウド内のCSVファイルを逆アセンブルします。
<details><div>
    答え：3,4
説明
C. gsutil ツールを使用して CSV ファイルをストレージ バケットに並行して送信するように、データ インジェスト プロセスを再設計します。
gsutil を使用して CSV ファイルを Google Cloud Storage バケットに並行して送信することは、利用可能な帯域幅を活用し、増加したデータ量を効率的に処理するための効果的な方法です。
D. 1,000 個のファイルをテープ アーカイブ (TAR) ファイルにアセンブルします。代わりにTARファイルを送信し、受信時にクラウド内のCSVファイルを逆アセンブルします。
TAR ファイルは、複数のファイルを 1 つのアーカイブにバンドルするためによく使用され、多数の小さなファイルを転送するオーバーヘッドを削減できます。TARファイルの送信は、特にファイルが小さくて数が多い場合に、データ転送を最適化する効果的な方法です。転送後にクラウドで分解すると、データ処理に役立ちます。
</div></details>

### Q. 質問35: 未回答
あなたは、何百万ものIoTデバイスからのテレメトリデータを格納するためのNoSQLデータベースを選択する任務を負っています。データ量は年間 100 TB で増加しており、各データ エントリには約 100 個の属性があります。データ処理パイプラインは ACID 準拠を必要としませんが、高可用性と低待機時間が必要です。また、個々のフィールドに対してクエリを実行してデータを分析できる必要もあります。
これらの要件を満たす 3 つの NoSQL データベースはどれですか?
1. 　
2. HBase
3. 
4. MongoDB
5. Cassandra
<details><div>
    答え：2,4,5
説明
正解-
B. HBase: HBase は、高可用性と低遅延で大量のデータを処理するのに適した分散 NoSQL データベースです。大規模なデータセットを格納して管理するように設計されているため、IoT テレメトリ データに適しています。
D. MongoDB:MongoDBは、スキーマ設計に柔軟性を提供し、大量のデータを処理できるNoSQLデータベースです。スケーラビリティに定評があり、リアルタイムのデータ分析とクエリに使用できます。
E. Cassandra: Cassandra は、高可用性、低遅延、スケーラビリティを提供する分散型 NoSQL データベースです。大規模なデータセットを処理するように設計されており、リアルタイム分析に使用できるため、IoT データ処理に適しています。
正しくないオプション -
A. Redis: Redis は、主にキャッシュとキー値ストアとして使用されるインメモリ データ ストアです。低遅延の点では優れていますが、メモリ内の性質上、容量が制限され、大規模なデータセットの保存にコストがかかる可能性があるため、大量の IoT テレメトリ データの保存とクエリには理想的な選択肢ではない可能性があります。
C. MySQL:MySQLは、ACID準拠とデータの一貫性で知られるリレーショナルデータベース管理システム(RDBMS)です。ただし、個々のフィールドの取り込みとクエリの速度が高い大量の IoT データの場合は、柔軟性とスケーラビリティが高いため、MongoDB、Cassandra、HBase などの NoSQL データベースの方が適している場合があります。
F. HDFS と Hive: Hive と組み合わせた HDFS (Hadoop Distributed File System) は、Hadoop エコシステムを使用したビッグ データの保存とクエリの一般的なソリューションです。ただし、バッチ処理と分析に特化しているため、IoT データ処理に必要な低遅延のリアルタイム クエリ機能は提供されない場合があります。
</div></details>

### Q. 質問36: 未回答
スパム分類子をトレーニングしています。学習データを過剰適合していることに気付きます。この問題を解決するために実行できる 3 つのアクションはどれですか?(3つ選択してください。
1. 　より多くのトレーニング例を取得する
2. 
3. より小さな特徴セットを使用する
4. 
5. 正則化パラメーターを増やす
6. 
<details><div>
    答え：1,3,5
説明
正解-
A. より多くのトレーニング例を取得する: より多くのトレーニング例を取得することは、モデルの一般化に役立つため、過学習を減らすための一般的な方法です。
C. より小さな特徴セットを使用する: 特徴の数を減らすと、モデルが単純化され、過学習を減らすことができます。このアクションは効果的です。
E. 正則化パラメーターを増やす: L1 または L2 正則化の強度などの正則化パラメーターを増やすと、複雑なモデルにペナルティを課すことで過学習を減らすことができます。したがって、このアクションも有効なアプローチです。
正しくないオプション -
B. 学習例の数を減らす: 学習例の数を減らすと、通常、過学習の問題が悪化します。一般に、トレーニング例が多いと、モデルが一般化をより適切に学習するのに役立ちます。これらを減らすと、モデルがさらに過剰適合する可能性があります。
D. より多くの特徴セットを使用する: 特徴の数を増やすと、モデルが複雑になるため、過学習が悪化する可能性があります。新しい特徴が適切でなかったり、ノイズが発生したりすると、モデルがトレーニング データに近づきすぎて、過学習が発生する可能性があります。
F. 正則化パラメーターを減らす: L1 または L2 正則化の強度を下げるなど、正則化パラメーターを減らすと、過学習が増加する傾向があります。正則化は、モデルがトレーニング データに近づきすぎないようにするために使用されます。これらのパラメーターを減らすと、モデルがより複雑になり、データが過剰適合する可能性があります。
</div></details>

### Q. 質問41: 未回答
あなたの会社は、多数のニューロンと層を持つ TensorFlow ニューラルネットワークモデルを構築しました。モデルはトレーニング データによく適合しますが、新しいデータに対してテストするとパフォーマンスが低下します。
この問題に対処するためにどのような方法を採用できますか?
1. 　
2. 
3. ドロップアウト方法
4. 
<details><div>
    答え：3
説明
TensorFlow ニューラル ネットワーク モデルがトレーニング データではうまく機能し、新しいデータではパフォーマンスが低いという問題に対処するには、以下を使用できます。
C. ドロップアウト方法
ドロップアウトは、深層学習で過学習を防ぐために一般的に使用される正則化手法です。過学習は、モデルがトレーニング データから一般化するのではなく、トレーニング データを記憶することを学習するときに発生し、新しい未知のデータのパフォーマンスが低下する可能性があります。ドロップアウトは、学習中にニューロンの一部をランダムに「ドロップアウト」することで過学習を軽減し、ネットワークに、よりロバストで一般化された特徴を学習させるのに役立ちます。
ドロップアウトの仕組みは次のとおりです。
1.トレーニング中、フォワードパスとバックワードパスごとに、ニューロンのランダムなサブセットが特定の確率(ドロップアウト率)で非アクティブ化(ゼロに設定)されます。これは、一部のニューロンがその特定の反復の計算から「ドロップアウト」されることを意味します。
2.ニューロンをドロップアウトすることで、モデルは個々のニューロンや特徴への依存度が低くなり、より堅牢になり、過剰適合する可能性が低くなります。
3.推論(テストまたは予測)中、ドロップアウトは通常オフになり、すべてのニューロンが予測に使用されます。
TensorFlow ニューラルネットワークでドロップアウト法を使用することで、トレーニングデータから新しい未知のデータに一般化する機能を向上させ、テストデータのパフォーマンス低下の問題に対処できる可能性があります。
正しくないオプション -
スレッド化 (オプション A) とシリアル化 (オプション B) は、ニューラル ネットワーク モデルの過学習の軽減や一般化の改善には直接関係しません。
次元削減 (オプション D) は、データセット内の特徴の数を減らすために使用される手法であり、特定の状況でモデルの複雑さを軽減し、汎化を改善するのに役立ちます。ただし、ドロップアウト法は、モデルがトレーニング データにうまく適合するが、新しいデータではパフォーマンスが低い場合に一般的な問題であるディープ ニューラル ネットワークの過学習に対処するのにより直接的に適しています。
参考リンク -
ドロップアウト方式
</div></details>

### Q. 質問42: 未回答
衣料品のレコメンデーションを行うモデルを構築しています。ユーザーのファッションの好みは時間の経過とともに変化する可能性が高いことがわかっているので、新しいデータが利用可能になったときにモデルにストリーミングするデータ パイプラインを構築します。
このデータを使用してモデルをトレーニングするにはどうすればよいでしょうか。
1. 　
2. 既存のデータと新しいデータの組み合わせでモデルを継続的に再トレーニングします。
3. 
4. 
<details><div>
    答え：2
説明
衣料品のレコメンデーションを目的としており、ユーザーのファッションの好みが時間の経過と共に変化する可能性が高いモデルの場合、モデルのトレーニングに新しいデータを使用する最適なアプローチは次のとおりです。
B. 既存のデータと新しいデータの組み合わせでモデルを継続的に再トレーニングします。
履歴ナレッジの保持: 既存のデータと新しいデータの組み合わせでモデルを継続的に再トレーニングすることで、モデルがユーザーの好みに関する知識を長期にわたって保持できるようにします。ファッションのトレンドやユーザーの嗜好は進化しますが、過去の嗜好やトレンドに関する貴重な情報も履歴データに含まれています。既存のデータと新しいデータを組み合わせることで、モデルは古いパターンと最近のパターンの両方から学習できます。
コンセプトのずれを防ぐ:ユーザーの嗜好は徐々に変化し、特定のファッションの嗜好が安定している期間があるかもしれません。新しいデータのみで継続的に再トレーニングを行うと (オプション A)、モデルが最近の傾向に過剰適合し、過去の好みに基づいて推奨事項を提供する機能が失われる可能性があります。古いデータと新しいデータの組み合わせで再トレーニングを行うことで、概念のずれを防ぐことができます。
評価と検証: 既存のデータをトレーニング データセットの一部として使用すると、履歴データに対するモデルのパフォーマンスを検証でき、モデルが好みの変化にどの程度適応できるかの尺度として機能します。その後、新しいデータに対するモデルのパフォーマンスも評価できます。
バランスの取れたトレーニング: 古いデータと新しいデータを組み合わせることで、時間の経過に伴うさまざまなユーザーの好みや傾向を反映したバランスの取れたデータセットを作成できます。これにより、モデルをより適切に一般化し、最近のデータに偏らないレコメンデーションを行うことができます。
正しくないオプション -
オプション C (新しいデータをテスト セットとして使用しながら既存のデータでトレーニングする) とオプション D (既存のデータをテスト セットとして使用しながら新しいデータでトレーニングする) は、トレーニングに完全なデータセットを利用しないため、通常、このシナリオには適していません。モデルが履歴データと新しいデータの両方から学習して、最も正確で適応性の高いレコメンデーションを提供する必要があります。
</div></details>

### Q. 質問44: 未回答
Google Kubernetes Engine(GKE)上で動作するデータ処理アプリケーションがあります。コンテナーは、コンテナー レジストリから使用可能な最新の構成で起動する必要があります。GKE ノードには、GPU、ローカル SSD、8 Gbps の帯域幅が必要です。データ処理インフラストラクチャを効率的にプロビジョニングし、デプロイ プロセスを管理する必要があります。
あなたは何をするべきか?
1. 　
2. Cloud Build を使用して Terraform ビルドを使用してジョブをスケジュールし、インフラストラクチャをプロビジョニングし、最新のコンテナ イメージで起動します。
3. 
4. 
<details><div>
    答え：2
説明
GPU、ローカル SSD、および 8 Gbps 帯域幅を使用してデータ処理インフラストラクチャを効率的にプロビジョニングし、展開プロセスを管理するには、オプション B が最適です。
B. Cloud Build を使用して Terraform ビルドを使用してジョブをスケジュールし、インフラストラクチャをプロビジョニングし、最新のコンテナ イメージで起動します。
Cloud Build: Cloud Build は、アプリケーションをビルド、テスト、デプロイできるマネージド CI / CD サービスです。これを使用して、コンテナー イメージをビルドおよびデプロイするための自動化されたワークフローを作成できます。Cloud Build でジョブをスケジュールすることで、インフラストラクチャとコンテナを常に最新の状態に保つことができます。
Terraform: Terraform は、宣言的な方法でインフラストラクチャを定義およびプロビジョニングできる一般的なコードとしてのインフラストラクチャ (IaC) ツールです。Terraform を使用して、GPU、ローカル SSD、ネットワーク構成など、必要な仕様で GKE クラスタを作成、管理できます。
コンテナ イメージ: Cloud Build は、ソースコードやコンテナ構成に変更があった場合に、最新のコンテナ イメージをビルドしてコンテナ レジストリにプッシュするように設定できます。これにより、コンテナーで常に最新のイメージが使用されるようになります。
効率性: Terraform と Cloud Build を使用することで、インフラストラクチャのプロビジョニングとコンテナのデプロイ プロセスを自動化し、効率性と一貫性を高めることができます。
正しくないオプション -
オプション A(Compute Engine スタートアップ スクリプトを使用)とオプション C(GKE を使用してコンテナを自動スケーリング)は、GPU やローカル SSD などの特定の要件を持つ GKE クラスタのプロビジョニングと管理には適していません。
オプション D(Dataflow と Cloud Scheduler を使用)は、GPU、ローカル SSD、8 Gbps 帯域幅を使用して GKE クラスタをプロビジョニングする要件とは無関係のようです。データフローは通常、インフラストラクチャのプロビジョニングではなく、データ処理に使用されます。
</div></details>

### Q. 質問45: 未回答
複数のベンダーからの連続ストリーミング データをほぼリアルタイムで処理できる機械学習モデルを作成したいと考えています。データに無効な値が含まれている可能性があります。BigQuery ML と Vertex AI を使用してこのモデルを作成するには、どのような手順を踏む必要がありますか?
1. 　
2. 
3. 
4. Pub/Sub トピックを作成し、すべてのベンダー データをそのトピックに送信します。Dataflow を使用して Pub/Sub データを処理およびサニタイズし、BigQuery にストリーミングします。
<details><div>
    答え：4
説明
BigQuery ML を使用して機械学習モデルを作成し、Vertex AI を使用してモデルをホストするためのエンドポイントを作成し、無効な値の可能性がある連続ストリーミング データを処理するには、次の方法が最適です。
D. Pub/Sub トピックを作成し、すべてのベンダー データをそのトピックに送信します。Dataflow を使用して Pub/Sub データを処理およびサニタイズし、BigQuery にストリーミングします。
Pub/Sub によるデータ インジェスト: Pub/Sub を使用すると、複数のベンダーからデータを効率的に収集できます。これはメッセージキューとして機能し、データの取り込みと配布を処理します。
データ処理のための Dataflow: Google Cloud Dataflow は、リアルタイムモードとバッチモードでデータを処理できるように設計されています。Dataflow を使用して Pub/Sub からデータを取り込み、データの前処理とサニタイズを実行してから、クリーニングしたデータを BigQuery にストリーミングできます。
サニタイズ: データに無効な値が含まれている可能性があるため、Dataflow を使用して受信データのクリーニング、検証、変換を行い、分析に適した形式にすることができます。これは、モデルのトレーニングと予測の精度にとって重要です。
BigQuery 統合: 処理されたデータを BigQuery にストリーミングすると、分析や機械学習モデルのトレーニングに利用できるようになります。このデータを使用して BigQuery ML モデルを作成し、トレーニングできます。
正しくないオプション -
オプション C では、Cloud Functions を使用してデータを処理しますが、Dataflow と同じレベルのデータ変換機能は提供されません。Dataflow は、複雑なデータ処理タスク、特に無効な可能性のあるデータを処理する場合に適しています。
オプション A では、データの取り込みに BigQuery ML を使用することを提案していますが、これは主なユースケースではありません。BigQuery ML は、データの取り込みやデータの前処理ではなく、機械学習モデルの構築を目的として設計されています。
オプション B では、BigQuery ストリーミング挿入を直接使用することを提案していますが、その場合、必要なデータの前処理とサニタイズを行うことができません。
</div></details>

### Q. 質問46: 未回答
あなたは大手eコマース企業のデータエンジニアです。現在、会社では Cloud Dataproc を使用して、顧客の購入履歴の大規模なデータセットを処理しています。しかし、Cloud Dataproc ではスケーラビリティとパフォーマンスの面でニーズを満たしていないことがわかりました。顧客の購入履歴の大規模なデータセットを処理するために Cloud Dataproc を置き換えるために、次の GCP サービスのうちどれを会社にお勧めしますか?
1. 　
2. 
3. BigQuery
4. 
<details><div>
    答え：3
説明
正解はBigQueryです。BigQuery は、大規模なデータセットを簡単に処理できる、ペタバイト規模のフルマネージド分析データ ウェアハウスです。また、拡張性とパフォーマンスも高いため、顧客の購入履歴の大規模なデータセットを処理するのに最適です。
正しくないオプション -
A. Cloud Data Fusion は、フルマネージドのクラウドネイティブ データ統合サービスです。大規模なデータセットを処理するようには設計されていません。
B. Cloud Dataflow は、フルマネージドのストリーミング データ処理サービスです。顧客の購入履歴の大規模なデータセットを処理するようには設計されていません。
D. Cloud Dataproc は、Hadoop と Spark のマネージド サービスです。大規模なデータセットを処理するための BigQuery ほどスケーラブルでもパフォーマンスも高くありません。
</div></details>

### Q. 質問47: 未回答
IoT デバイスからリアルタイム データを取り込んで処理するためのデータ パイプラインを設計しています。このデータは、リアルタイムのダッシュボードと分析を強化するために使用されます。
このパイプラインを設計する最適な方法は、次のうちどれですか?
1. 　Cloud Pub/Sub を使用してデータを取り込み、BigQuery に保存します。Dataflow を使用して BigQuery のデータを処理し、リアルタイムの指標を生成します。Cloud Data Studio を使用して、リアルタイムのダッシュボードを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. Cloud Pub/Sub を使用してデータを取り込み、BigQuery に保存します。Dataflow を使用して BigQuery のデータを処理し、リアルタイムの指標を生成します。Cloud Data Studio を使用して、リアルタイムのダッシュボードを作成します。
IoT デバイスからリアルタイム データを取り込んで処理するデータ パイプラインを設計する最善の方法は、Cloud Pub/Sub、BigQuery、Dataflow、Cloud Data Studio を使用することです。
Cloud Pub/Sub は、IoT デバイスからデータを取り込むために使用できるフルマネージドのリアルタイム メッセージング サービスです。BigQuery は、データの保存と処理に使用できるペタバイト規模のフルマネージド分析データ ウェアハウスです。Dataflow は、ストリーミング パイプラインとバッチ データ処理パイプラインを構築して実行するためのフルマネージド サービスです。Cloud Data Studio は、リアルタイムのダッシュボードの作成に使用できるデータ可視化ツールです。
このパイプラインを実装するには、まず、IoT デバイスから取り込むデータの種類ごとに Cloud Pub/Sub トピックを作成する必要があります。次に、これらのトピックにデータを発行するように IoT デバイスを構成する必要があります。
次に、データを保存するための BigQuery データセットを作成する必要があります。次に、Dataflow パイプラインを作成して、Cloud Pub/Sub トピックからデータを読み取り、BigQuery データセットに書き込む必要があります。
最後に、Cloud Data Studio のレポートを作成して、データをリアルタイムで可視化する必要があります。
このパイプラインは、大量のリアルタイム データを処理でき、増大するニーズに合わせてスケーラブルになります。
</div></details>

### Q. 質問48: 未回答
あなたの会社は、グローバルに展開する大規模なeコマース企業です。購入履歴、製品レビュー、人口統計など、顧客データの膨大なデータセットがあります。このデータを使用して、顧客離反を予測する機械学習モデルを構築します。データセットは非常に大きく、複雑です。また、複数のGCPリージョンに分散されています。スケーラブルで効率的な方法でデータをクリーニング、変換し、機械学習プラットフォームに読み込むためのデータ処理パイプラインを設計する必要があります。
データ処理パイプラインのオーケストレーションに最適なGCPサービスは、次のうちどれですか?
1. 　
2. 
3. Google Cloud Composer
4. 
<details><div>
    答え：3
説明
C. Google Cloud Composer
Google Cloud Composer は、Apache Airflow のマネージド サービスです。Airflowは、複雑なデータパイプラインを作成および管理できる、人気のあるオープンソースのワークフローオーケストレーションプラットフォームです。Airflow ワークフローは Python で記述されているため、開発と保守が容易です。
Google Cloud Composer には、データ処理パイプラインのオーケストレーションに最適な次のような機能が多数用意されています。
ワークフローを作成および管理するための Web ベースの UI
一般的なデータ処理タスク用の事前構築済み演算子のライブラリ
スケジュールに従ってワークフローを実行するための組み込みスケジューラ
他の GCP サービス(Cloud Dataproc、Cloud Dataflow、Cloud Storage など)との統合
正しくないオプション -
A. Google Cloud Dataproc は、Apache Spark と Hadoop のマネージド サービスです。バッチ データ処理ジョブの実行には適していますが、複雑なデータ パイプラインを調整するようには設計されていません。
B. Google Cloud Dataflow は、ストリーミング データ処理のためのマネージド サービスです。リアルタイムのデータストリームを処理するには適していますが、複雑なデータパイプラインを調整するようには設計されていません。
D. Google Cloud Data Fusion は、フルマネージドのクラウドネイティブなデータ統合サービスです。データ統合パイプラインの構築と管理には適していますが、Google Cloud Composer と同じレベルのワークフロー オーケストレーション機能は提供されません。
</div></details>

### Q. 質問49: 未回答
あなたは大手eコマース企業のデータエンジニアです。お客様は、BigQuery 上に構築された会社のデータ ウェアハウスの設計と管理を担当します。同社には、数十億行のデータを含む大規模で複雑なデータセットがあります。
同社のマーケティングチームは、複数のセッションにわたる顧客の行動を分析する新しいタイプのクエリを実行したいと考えています。このクエリは非常に複雑で、複数のテーブルを結合する必要があります。クエリが遅すぎて、他のユーザーのデータウェアハウスのパフォーマンスに影響を与えることが懸念されます。
クエリのパフォーマンスを最適化し、他のユーザーへの影響を最小限に抑える最善の方法は何ですか?
1. 　必要なデータのマテリアライズドビューを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。 必要なデータのマテリアライズドビューを作成します。
クエリのパフォーマンスを最適化し、他のユーザーへの影響を最小限に抑える最善の方法は、具体化されたビューを作成することです。マテリアライズドビューは、複雑なクエリの結果を含む事前計算されたテーブルです。
具体化されたビューを作成するには、まず、マーケティング チームが必要とするクエリの最も重要な部分を特定する必要があります。次に、クエリのこれらの部分の結果を含む具体化されたビューを作成します。
具体化されたビューが作成されると、マーケティング チームは元のテーブルではなく、具体化されたビューに対してクエリを実行できます。これにより、クエリのパフォーマンスが向上し、他のユーザーへの影響が最小限に抑えられます。
正しくないオプション -
B. クエリに割り当てるスロットの数を増やします。これにより、クエリのパフォーマンスは向上しますが、データ ウェアハウスで実行されている他のクエリのパフォーマンスにも影響します。
C. オフピーク時にクエリを実行します。これにより、他のユーザーへの影響は最小限に抑えられますが、マーケティング チームがクエリの結果を迅速に必要とする場合は、実用的ではない可能性があります。
D. 別のデータベース エンジンを使用します。BigQuery は、大規模で複雑なクエリを処理するために設計された、拡張性の高いデータベース エンジンです。別のデータベース エンジンを使用しても、クエリのパフォーマンスが大幅に向上することはほとんどありません。
</div></details>

### Q. 質問50: 未回答
あなたは大手eコマース企業のデータエンジニアです。お客様は、数十億行の顧客データを含む BigQuery データセットの管理を担当します。過去 10 日間に購入した顧客の間で最も人気のある上位 30 個の製品を特定するクエリを記述する必要があります。
このクエリを記述する最も効率的な方法は何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：2
説明
正解はオプションBです。
SELECT product_id, COUNT(*) AS num_orders
FROM `my_dataset.my_table`
WHERE purchase_date >= CURRENT_DATE() - INTERVAL 30 DAY
GROUP BY product_id
ORDER BY num_orders DESC
LIMIT 10;
このクエリは、次の理由で効率的です。
WHERE 句を使用してデータをフィルター処理し、購入日が過去 30 日以内の行のみを含めます。
GROUP BY 句を使用して、製品を製品 ID でグループ化し、各製品 ID の注文数をカウントします。
ORDER BY 句を使用して、注文数でデータを降順に並べ替えます。
LIMIT句を使用して、最も人気のある上位10個の製品に結果を限定します。
正しくないオプション -
オプション A.
SELECT * FROM `my_dataset.my_table`
WHERE purchase_date >= CURRENT_DATE() - INTERVAL 30 DAY
ORDER BY num_orders DESC
LIMIT 10;
このクエリは、クエリに必要な product_id 列と purchase_date 列のみであっても、テーブルからすべての列を選択するため、非効率的です。すべての列を選択すると、特にテーブルが非常に大きい場合に、クエリのコストが大幅に増加する可能性があります。
オプションC:
SELECT product_id, COUNT(*) AS num_orders
FROM `my_dataset.my_table`
WHERE purchase_date >= CURRENT_DATE() - INTERVAL 30 DAY
GROUP BY product_id
HAVING num_orders > 10;
このクエリは、HAVING 句を使用してデータをフィルター処理し、注文数が 10 を超える行のみを含めるため、非効率的です。LIMIT句は、すでに結果を最も人気のある上位10個の製品に制限しているため、これは不要です。
オプションD:
SELECT product_id, COUNT(*) AS num_orders
FROM `my_dataset.my_table`
WHERE purchase_date >= CURRENT_DATE() - INTERVAL 30 DAY
GROUP BY product_id
ORDER BY num_orders DESC;
このクエリは LIMIT 句を使用しないため、非効率的です。つまり、クエリは、行数が 10 より大きい場合でも、すべてのデータ行を返します。これにより、クエリのコストが増加し、実行が遅くなる可能性があります。
</div></details>

## 5
### Q. 問題28: 正解
Google Cloud上のデータパイプラインのために、Cloud Pub/SubからBigQueryへのJSONメッセージの書き込みと変換を行うサービスを選択しています。サービスのコストは最小限に抑えたいと考えています。また、サイズが変化する入力データ量を監視し、最小限の手動操作で対応したいと考えています。
要件を達成するためにするべきことは何ですか？
1. 　
2. 
3. Cloud Dataflowを使用して変換を実行する。Cloud Monitoringでジョブシステムの遅延を監視する。ワーカーインスタンスにデフォルトのオートスケーリング設定を使用する
4. 
<details><div>
    答え：3
説明
Pub/Subのデータを処理するスケーラブルなサービスを選択する必要があります。
また、データ量の監視も自動的に行えるようにする必要があります。
Pub/Sub は、スケーラブルで耐久性のあるイベントの取り込みおよび配信システムです。
Dataflow は、メッセージの重複排除、1 回限りの処理、タイムスタンプ付きイベントからのデータ ウォーターマークの生成により、Pub/Sub のスケーラブルな「最低 1 回」配信モデルを補完する。
Dataflow を使用するには、Apache Beam SDK でパイプラインを記述し、Dataflow サービスでパイプライン コードを実行する。
データ量監視についてはCloud Monitoring（Cloud Monitoring）が有効です。
Cloud Monitoring は、Google Cloud、Amazon Web Services（AWS）、ホストされた稼働時間プローブ、アプリケーション インストゥルメンテーションから指標、イベント、メタデータを収集する。
BindPlane サービスを使用して、150 以上の共通のアプリケーション コンポーネント、オンプレミス システム、ハイブリッド クラウド システムからデータを収集することもできます。
データを取り込むと、Google Cloud のオペレーション スイートはダッシュボード、グラフ、アラートを介して分析情報を提供する。
したがって、正解は「Cloud Dataflowを使用して変換を実行する。Cloud Monitoringでジョブシステムの遅延を監視する。ワーカーインスタンスにデフォルトのオートスケーリング設定を使用する」です。
参照：
https://cloud.google.com/Pub/Sub/docs/Pub/Sub-dataflow
https://cloud.google.com/migrate/compute-engine/docs/4.8/how-to/monitoring/using-Cloud Monitoring-monitoring
</div></details>

## 6
### Q. 問題18: 不正解
あなたは、企業が経済動向を把握することを支援する経済コンサルティング会社に勤務しています。分析の一環として、Google BigQuery を使用して、パン、ガソリン、牛乳など、最も一般的に販売されている 100 種類の商品の平均価格と顧客データを関連付けています。これらの商品の平均価格は30分ごとに更新されます。このデータが常に最新であることを確認し、BigQueryの他のデータとできるだけ低コストで組み合わせられるようにしたいと考えています。
要件を達成するためにするべきことは何ですか？
1. 　
2. データをリージョンの Google Cloud Storage バケットに保存して更新し、BigQuery で連携データソースを作成する
3. 
4. 
<details><div>
    答え：2
説明
BigQueryは巨大なデータセットのためのフルマネージドクエリサービスですが、データをBigQueryのデータセットに移動しなくても、BigQueryのデータアクセスレイヤーを使用してデータ連携をすることが可能です。
これは、BigQueryは連携型のデータアクセスモデルを備えており、Bigtable、Cloud Storage、Google Driveから直接、永続テーブルと一時テーブルを使ってデータを照会することができるからです。
複数のGoogle Cloud Platformサービスにデータがあり、データレイクやデータウェアハウス戦略を構築している場合、この機能がコスト最適化の観点からも有用になる場合があります。
今回の例であれば、BigQueryにインポート処理をする場合よりも、Cloud Storageのストレージコストの方が安くなるためコスト最適なソリューションを実現できます。
したがって、正解は「データをリージョンの Google Cloud Storage バケットに保存して更新し、BigQuery で連携データソースを作成する」です。
参照：
https://cloud.google.com/blog/products/gcp/accessing-external-federated-data-sources-with-bigquerys-data-access-layer
</div></details>

### Q. 問題32: 不正解
Cloud Dataprep を使用して、BigQuery テーブル内のデータのサンプルにレシピを作成しました。このレシピを、実行時間が変動するロードジョブが完了した後、同じスキーマのデータを毎日アップロードする際に再利用したいと考えています。
要件を達成するためにするべきことは何ですか？
1. 　
2. 
3. 
4. Cloud Dataprep ジョブを Cloud Dataflow テンプレートとしてエクスポートし、Cloud Composer ジョブに組み込む
<details><div>
    答え：4
説明
Dataprepの機能を利用して、スキーマのデータを再利用する方法を選択する必要があります。
Dataprepは、オーケストレーションAPIを公開しているため、スケジューラーやCloud Composerなどのオーケストレーションソリューション内でCloud Dataprepを統合することができます。
これにより、他のツールに直接統合することで、Cloud Dataflowテンプレート以外の自動化を拡大し、分析やAI/MLイニシアティブのための反復可能なデータパイプラインを作成し、時間の節約と信頼性を高めることができます。
さらに、このAPIでは、Cloud Dataflowテンプレートでは利用できないCloud Dataprep変数またはパラメータを使用して、動的な入出力を使用できます。
その結果、1つのCloud Dataprepフローを再利用して、実行時に評価されるさまざまな入出力値で実行することができます。
したがって、正解は「Cloud Dataprep ジョブを Cloud Dataflow テンプレートとしてエクスポートし、Cloud Composer ジョブに組み込む」です。
参照：
https://cloud.google.com/blog/products/data-analytics/how-to-orchestrate-cloud-dataprep-jobs-using-cloud-composer
</div></details>

### Q. 問題39: 不正解
あなたは現在ニューラルネットワークモデルの学習を行なっていますが、完了するまでに何日もかかっています。そのため、あなたは学習速度を上げたいと思っています。
要件を達成するためにするべきことは何ですか？
1. 　
2. トレーニングデータセットのサブサンプルを作成する
3. 
4. 
<details><div>
    答え：2
説明
学習にはトレーニングデータが使用されているため、トレーニングデータに関する処理を行う必要があります。
サブサンプリングとは主に不均衡データに対して用いられるデータ処理手法で、特定のクラスのデータから新しいサブセットを生成する処理です。
これによって、特定のクラスのデータセットが減少し、学習パフォーマンスが向上する。
したがって、正解は「トレーニングデータセットのサブサンプルを作成する」です。
参照：
https://qiita.com/msekino/items/390069cad04595107ee4
https://ichi.pro/tokeiteki-gakushu-de-ta-no-sanpuringu-to-risanpuringu-162315950189496
</div></details>

## 7
### Q. 問題26: 未回答
あなたは、サードパーティから毎月CSV形式のデータファイルを受け取っています。このデータをクレンジングする必要がありますが、3ヶ月に一度、ファイルのスキーマが変更されます。これらの変換を実行するための要件は以下の通りです。
- 変換をスケジュール通りに実行すること
- 開発者ではないアナリストが変換を修正できるようにすること
- トランスフォームを設計するためのグラフィカルなツールを提供すること
要件を達成するためにするべきことは何ですか？
1. 　Cloud Dataprep を使用して変換レシピを構築・維持し、スケジュールに基づいて実行する
2. 
3. 
4. 
<details><div>
    答え：1
説明
変換レシピの定期的な変更が可能でありかつ、定期実行可能なサービスを選択する必要があります。
また、開発者ではないアナリストのためにノーコードによるデータ変換をサポートする必要があります。
Cloud Dataprep by Trifacta は、分析、レポート、機械学習に使用する構造化データと非構造化データを視覚的に探索、クリーニング、準備できるインテリジェント データ サービスです。
Dataprep はサーバーレスで、規模に関係なく稼働します。
デプロイや管理が必要なインフラストラクチャはなく、素早くデータ変換ロジックを構築し定期実行も行うことが可能です。
Dataprep は、最適なデータ変換操作を UI で操作を行うたびに自動で提案、予測します。
変換のシーケンスを定義しておけば、Dataprep は内部的に Dataflow または BigQuery を使用し、あらゆるサイズの構造化データセットまたは非構造化データセットをわずか数回のクリックで処理できるようにします。
そのため、コードを記述する必要がなくなります。
したがって、正解は「Cloud Dataprep を使用して変換レシピを構築・維持し、スケジュールに基づいて実行する」です。
参照：
https://cloud.google.com/dataprep/
https://cloud.google.com/dataprep/docs/html/Overview-of-RapidTarget_136155049
</div></details>

### Q. 問題33: 未回答
あなたは、スケジュール通りに実行しなければならない複数のバッチジョブを実装しています。これらのジョブには、特定の順序で実行しなければならない多くの相互に依存するステップがあります。ジョブの一部には、シェルスクリプトの実行、Hadoopジョブの実行、BigQueryでのクエリの実行が含まれています。ジョブの実行時間は数分から数時間を想定しています。手順が失敗した場合は、一定の回数を再試行する必要があります。
これらのジョブの実行を管理するために、どのサービスを使用しますか？
1. 　
2. 
3. 
4. Cloud Composer
<details><div>
    答え：4
説明
ジョブの依存関係をコントロールしつつ実行を自動化するマネージドサービスを選択する必要があります。
Cloud ComposerはApache Airflow で構築された、フルマネージドのワークフロー オーケストレーション サービスです。
DAG（Direct Acyclic Graph）と呼ばれるデータ形式でジョブ同士の関係性を定義し、実行します。
Cloud Composer はフルマネージド サービスであり、Apache Airflow は互換性に優れているため、リソースのプロビジョニングに気をとられず、ワークフローの作成、スケジューリング、モニタリングに専念できます。
BigQuery、Dataflow、Dataproc、Datastore、Cloud Storage、Pub/Sub、AI Platform などの Google Cloud プロダクトとのエンドツーエンドの統合により、ユーザーはパイプラインを自由かつ完全にオーケストレートできます。
これによって、複数の依存関係のあるジョブを、少ないオーバーヘッドで実行することが可能になります。
したがって、正解は「Cloud Composer」です。
参照：
https://cloud.google.com/composer/docs/how-to/using/writing-dags
https://cloud.google.com/composer/?hl=en
</div></details>

### Q. 問題34: 未回答
Cloud Dataflowジョブでデータパイプラインを構築し、時系列メトリクスを集約してCloud Bigtableに書き出します。このデータは、組織全体で何千人ものユーザーが使用するダッシュボードに供給されます。同時接続ユーザーの増加に対応し、データの書き込みに必要な時間を短縮する必要があります。
あなたが取るべきアクションはどれですか？（2つ選択）
1. 　
2. PipelineOptionsでmaxNumWorkersを設定して、Cloud Dataflowのワーカーの最大数を増やす
3. Cloud Bigtableクラスターのノード数を増やす
4. 
<details><div>
    答え：2,3
説明
接続ユーザーが増加すると、メトリクスの集約をする処理の負荷が増加します。
これはDataflow、Bigtableそれぞれに対しての負荷となるため、それぞれのコンピューティングリソースを増強するための対策が必要です。
Cloud Dataflowでは、ワーカーという単位でデータの処理を行います。
このワーカーは、スケールアップとスケールアウトに対応しているため、ワーカーインスタンスのサイズを大きくすること、ワーカー数を増やすことで、処理をスムーズに行うことができます。
ワーカー数を増やす際は、maxNumWorkersを設定することで実現することができます。
Bigtableでは、クラスタにノードを追加することで、スループットを高めることができます。
例えば3つのノードからなるクラスタにさらに3つのノードを追加することで、書き込みスループットは2倍になります。
したがって、正解は以下の通りです。
- PipelineOptionsでmaxNumWorkersを設定して、Cloud Dataflowのワーカーの最大数を増やす
- Cloud Bigtableクラスターのノード数を増やす
参照：
https://cloud.google.com/bigtable/docs/performance#performance-write-throughput
https://cloud.google.com/dataflow/docs/guides/specifying-exec-params#setting-other-cloud-pipeline-options
</div></details>

### Q. 問題37: 未回答
あなたはCloud Dataprocのクラスターを管理しています。あなたは、クラスター上で進行中の作業を失うことなく、コストを最小限に抑えながらジョブを高速に実行する必要があります。
要件を達成するためにするべきことは何ですか？
1. 　
2. 
3. 
4. プリエンプティブルなワーカーノードのクラスタサイズを大きくし、グレースフルデコミッショニングを使用するように設定する
<details><div>
    答え：4
説明
コスト最適化された方法でジョブを高速に実行する方法を選択する必要があります。
Dataproc クラスタを作成した後、クラスタ内のプライマリ ワーカーノードまたはセカンダリ ワーカーノードの数を増減することで（水平方向のスケーリング）、クラスタを調整（「スケール」）できます。
Dataproc クラスタは、クラスタでジョブを実行している場合も含めいつでもスケールできます。
既存のクラスタのマシンタイプは変更できません（垂直方向のスケーリング）。
垂直方向のスケーリングを行うには、サポートされているマシンタイプを使用してクラスタを作成してから、その新しいクラスタにジョブを移行します。
Dataprocのようなバッチの場合は、コンピューティングリソースが時間課金という特性を活かして、水平スケーリングを積極的に活用するべきです。
つまり、一つのコンピューティングリソースでワークロードを処理する場合も、複数のリソースでワークロードを処理する場合も原理的には変わらないという性質を利用します。
また、ワーカーノードには、プリエンプティブルなインスタンスを用いることで、コスト削減も実現できます。
したがって、正解は「プリエンプティブルなワーカーノードのクラスタサイズを大きくし、グレースフルデコミッショニングを使用するように設定する」です。
参照：
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/scaling-clusters
</div></details>

### Q. 問題48: 未回答
Google Cloudにデータパイプラインを導入するにあたり、20TBのテキストファイルのストレージを設計しています。入力データはCSV形式です。複数のユーザーが複数のエンジンでCloud Storageのデータを照会する場合、集約値の照会コストを最小化したいと考えています。
どのストレージサービスとスキーマデザインを使用すべきでしょうか？
1. 　
2. 
3. ストレージにはCloud Storageを使用する。問い合わせ用にBigQueryのパーマネントテーブルとしてリンクする
4. 
<details><div>
    答え：3
説明
適切なストレージを選択しつつ、参照のためのコスト最適なテーブルを設計する必要があります。
Cloud StorageはCSVデータを低コストで大量に保存する際に最適なストレージです。
また、Cloud Storageに保存されたCSVファイルは、BigQueryによるクエリがネイティブにサポートされているので、データ照会を容易に行うことができます。
BigQueryのテーブル設計について注意が必要な点は、照会コストを最小にするという要件です。
一時テーブルを利用する場合は、BigQuery データセットの 1 つにテーブルを作成するわけではありません。
つまり、テーブルはデータセットに恒久的に保存されないので、クエリを行うたびにコストがかかります。
永続的なテーブルは、データセットに作成され、外部データソースにリンクされます。
テーブルが永続的であるため、データセットレベルのアクセス制御を使用して、基礎となる外部データソースへのアクセス権を持つ他の人とテーブルを共有し、低コストでテーブルを照会することが可能になります。
したがって、正解は「ストレージにはCloud Storageを使用する。問い合わせ用にBigQueryのパーマネントテーブルとしてリンクする」です。
参照：
https://cloud.google.com/blog/products/gcp/accessing-external-federated-data-sources-with-bigquerys-data-access-layer
https://cloud.google.com/bigquery/external-data-cloud-storage
</div></details>

### Q. 問題49: 未回答
細胞組織に関するデータベースに格納されているデータを使用して、特定の細胞組織サンプルが将来悪性腫瘍になるかどうかの分類したいと考えています。細胞組織サンプルを分類するために、教師なしの異常検出法を評価しています。
この方法をサポートするデータ特性はなんですか？（2つ選択）
1. 　正常なサンプルと比較して、変異の発生が非常に少ない
2. 
3. 
4. 将来の変異は、データベース内の変異したサンプルと類似した特徴を持つと予想される
<details><div>
    答え：1,4
説明
教師なし学習によって行う異常検知は、異常データが正常データの集団と比較して分離ができる（＝外れ値である）という前提に立っています。
これは言い換えると、異常データの発生確率は正常データの発生確率に比べて少なく、正常データと比較して既存の観測されている異常データと新たな異常データが近しい特徴を持つ、ということになります。
一方で、教師あり学習を行うことができるデータは、すでに正常/異常のラベルがついており、モデル作成可能な比率で正常/異常のデータが一定数存在しています。
したがって、正解は以下の通りです。
- 正常なサンプルと比較して、変異の発生が非常に少ない
- 将来の変異は、データベース内の変異したサンプルと類似した特徴を持つと予想される
参照：
https://products.sint.co.jp/aisia-ad/blog/possible-to-detect-anomalies-without-teacher-data
https://dev.classmethod.jp/articles/yoshim-sagemaker-rcf/#sec2
</div></details>

### Q. 問題50: 未回答
あなたは、ユーザーの注文する料理を予測する機械学習ベースの食品注文サービスのデータベーススキーマを設計しています。以下は、あなたが保存する必要のある情報の一部です。
- ユーザーのプロフィール。ユーザーが好きなもの、嫌いなもの
- ユーザーのアカウント情報。名前、住所、好みの食事時間
- 注文情報。いつ、どこから、どのお店に注文するか
データベースは、サービスのすべてのトランザクションデータを格納するために使用されます。あなたはデータスキーマを最適化したいと考えています。
どのGoogle Cloud Platformサービスを使うべきでしょうか？
1. 　
2. 
3. 
4. Cloud Datastore
<details><div>
    答え：4
説明
ユーザープロファイルは、ユーザーの過去の活動や嗜好に基づいて、ユーザーの体験をカスタマイズするためのものです。
そのため、リレーショナルデータベースよりも柔軟なスキーマ構造を保持する必要があります。
Datastoreの柔軟なスキーマにより、アプリケーションの新機能をサポートするために新しいプロパティを追加するなど、時間の経過とともにユーザプロファイルの構造を変化させることができます。
スキーマの変更はダウンタイムなしで行われ、ユーザー数が増加してもパフォーマンスが低下することはありません。
したがって、正解は「Cloud Datastore」です。
参照：
https://cloud.google.com/architecture/building-scalable-web-apps-with-cloud-datastore
https://cloud.google.com/architecture/building-scalable-web-apps-with-cloud-datastore#integration-with-other-gcp-products</div></details>

## 8
### Q. 
あなたは、単一のテーブルで繰り返し実行されるクエリについて、BigQuery の最適化に取り組んでいます。クエリされるデータは約 1 GB で、一部の行は 1 時間に約 10 回変更されることが予想されます。SQL ステートメントは可能な限りの最適化が済んでおり、クエリのパフォーマンスをさらに最適化したいと考えています。どうすればよいですか。
1. 　テーブルに基づくマテリアライズド ビューを作成して、そのビューをクエリします。
2. クエリデータのキャッシュ保存を有効にして、後続のクエリを高速化します。
3. スケジュール設定済みクエリを作成して、レポート作成の数分前にそのクエリを実行します。
4. 多数のスロットを事前に予約して、クエリの実行のためのコンピューティング能力を最大化します。
<details><div>
正解
1. 　テーブルに基づくマテリアライズド ビューを作成して、そのビューをクエリします。
フィードバック
A: 選択肢 A は正解です。マテリアライズド ビューは、パフォーマンスを向上させるためにクエリの結果を定期的にキャッシュ保存します。マテリアライズド ビューは、頻繁にクエリされる小さなデータセットに適しています。基盤となるテーブルデータが変更されると、影響を受ける部分をマテリアライズド ビューが無効化して再度読み込みます。
B: 選択肢 B は不正解です。キャッシュ保存は自動的に有効化されますが、基盤となるデータが変更されるとパフォーマンスを発揮できません。
C: 選択肢 C は不正解です。スケジュール設定済みクエリにより定期的なクエリをスケジュールできますが、パフォーマンスは特に最適化されません。また、クエリを早く実行しすぎると古いデータが使用される場合があります。
D: 選択肢 D は不正解です。多くのスロットを予約すると、BigQuery スロットの可用性は確保されますがパフォーマンスは向上しません。
 
https://cloud.google.com/bigquery/docs/materialized-views-intro
 
https://cloud.google.com/bigquery/docs/materialized-views-best-practices
 
https://cloud.google.com/bigquery/docs/materialized-views
</div></details>

### Q. 
Cloud Spanner データベースには、マーケティング チームが頻繁にアクセスするお客様のアドレス情報が保存されています。お客様が居住する国と州を入力すると、この情報は、外部キーで接続されている別のテーブルに保存されます。現在のアーキテクチャにはパフォーマンスの問題があり、あなたは Google の推奨手法に従ってパフォーマンスを改善したいと考えています。どうすればよいですか。
1. 　インターリーブされたテーブルを作成して、国の下に州を保存します。
2. データを非正規化して、対応する国とともに各州ごとの行を作成します。
3. 既存のアーキテクチャを維持しながら、国と州に短い 2 文字のコードを使用します。
4. 国を 1 つのセルのテキストに結合します。たとえば、「country:state1,state2, …」などです。必要な場合はデータを分割します。
<details><div>
正解
1. 　インターリーブされたテーブルを作成して、国の下に州を保存します。
フィードバック
A: 選択肢 A は正解です。Cloud Spanner はインターリーブをサポートしており、同じスプリットにデータが保存されるようにします。これにより、強いデータ局所性関係が必要なときのパフォーマンスが向上します。
B: 選択肢 B は不正解です。リレーショナル データベースでは、非正規化は好ましい手法ではありません。繰り返しデータにより複数の行が発生するためです。
C: 選択肢 C は不正解です。フィールドの大きさを略称で小さくしても、あまり違いは生じません。データのアクセスと結合がパフォーマンスのさらに大きな問題となるためです。
D: 選択肢 D は不正解です。複数の種類のデータを同じセルに詰め込むことは、リレーショナル データベースでは推奨されません。
 
https://cloud.google.com/spanner/docs/schema-and-data-model#creating-interleaved-tables
</div></details>

### Q. 
あなたの会社はビジネス クリティカルなシステムを PostgreSQL で実行しています。このシステムは、数百万ものユーザーに対応しており、世界中の多くの場所から同時にアクセスされます。データベース管理チームは冗長性とスケーリングを手動で管理しており、あなたは、データベースを Google Cloud に移行したいと考えています。グローバル スケールと可用性を提供する一方でメンテンナンスが最少のソリューションが必要です。どうすればよいですか。
1. 　BigQuery に移行します。
2. Cloud Spanner に移行します。
3. Cloud SQL for PostgreSQL インスタンスに移行します。
4. PostgreSQL がインストールされているベアメタル マシンに移行します。
<details><div>
正解
2. Cloud Spanner に移行します。
フィードバック
A: 選択肢 A は不正解です。BigQuery はグローバル スケールをサポートしていません。また、BigQuery は、PostgreSQL のようなトランザクション データベースの移行にはあまり適していません。分析に重点が置かれているためです。
B: 選択肢 B は正解です。Cloud Spanner は、リレーショナル データをサポートする、グローバル スケールで高可用性のデータベースを提供します。
C: 選択肢 C は不正解です。Cloud SQL のオプションはリージョナルで、Cloud Spanner に比べてスケーラビリティが小さくなります。
D: 選択肢 D は不正解です。ベアメタル マシンで PostgreSQL を実行すると、必要なメンテナンスが増えます。
 
https://cloud.google.com/spanner/docs/migrating-postgres-spanner
</div></details>

### Q. 
あなたの会社は、BigQuery の知識がないビジネス アナリストを数人雇用していますが、今後、彼らは BigQuery を使用して大量のデータを分析する予定です。あなたは、BigQuery でのコスト管理を行い、クエリ結果の品質を維持しつつ予算が超過しないようにする必要があります。どうすればよいですか。
1. 　プロジェクト レベルまたはユーザーレベルでカスタマイズした 1 日の割り当てを許容できる値に設定します。
2. BigQuery テーブルのデータを減らしてアナリストがクエリするデータ量を減らしてから、残りのデータをアーカイブします。
3. クエリ検証ツールまたは --dry_run を使用して費用を見積もれるようにアナリストをトレーニングし、アナリストが使用量を自身で制御できるようにします。
4. 各アナリストに対し BigQuery の 1 日あたりの費用をエクスポートして Looker でデータを可視化し、アナリストが使用量を自身で制御できるようにします。
<details><div>
正解
1. 　プロジェクト レベルまたはユーザーレベルでカスタマイズした 1 日の割り当てを許容できる値に設定します。
フィードバック
A: 選択肢 A は正解です。BigQuery プロジェクトとユーザーが複数ある場合は、1 日あたりに処理されるクエリデータの量に上限を指定するカスタム割り当てをリクエストして、コストを管理できます。
B: 選択肢 B は不正解です。部分的なデータのみをアナリストに渡しても、正確なクエリ結果が得られません。
C: 選択肢 C は不正解です。費用が予算を超過する可能性が残ります。この手法は、アナリストがガイドラインを常に遵守することが前提となります。
D: 選択肢 D は不正解です。費用が予算を超過する可能性が残ります。また、この手法は、アナリストが毎日チャートを確認してそれに応じて行動を調整することが前提となります。
 
https://cloud.google.com/bigquery/docs/custom-quotas
</div></details>

### Q. 
あなたのチームは Dataproc ワークロードを実行しており、ワーカーノードは処理に約 45 分かかります。費用の面から、ワーカーノードを積極的にシャットダウンすることも含めてシステムを最適化するさまざまな選択肢を検討してきましたが、指標ではジョブ全体がさらに長くなってしまいます。費用を抑えながらジョブ完了までの時間を延長せずにシステムを最適化するには、どうすればよいですか。
1. 　正常なデコミッションのタイムアウトを 45 分より大きく設定します。
2. Cloud Data Fusion での処理を書き換えて、ジョブを自動で実行します。
3. Dataflow での処理を書き換えて、同一データのストリーム処理を使用します。
4. 各ワーカーノードの vCPU の数を増やして処理完了までの時間を短縮します。
<details><div>
正解
1. 　正常なデコミッションのタイムアウトを 45 分より大きく設定します。
フィードバック
A: 選択肢 A は正解です。正常なデコミッションにより、ワーカーノードで進行中の作業が Dataproc クラスタから削除される前に終了します。
B: 選択肢 B は不正解です。Cloud Data Fusion でのデータ パイプラインの再構築は、労力、費用、時間が増大します。
C: 選択肢 C は不正解です。Dataflow のコードの書き換えは、労力、費用、時間が増大します。
D: 選択肢 D は不正解です。vCPU の数の増加により費用が大幅に増大します。
 
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/scaling-clusters
 
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/autoscaling#choosing_a_graceful_decommissioning_timeout
</div></details>

### Q. 
IT チームは構造化データの保存に BigQuery を使用しています。財務チームは、最近、スタンドアロンのデスクトップ版スプレッドシート プロセッサから Google Workspace Enterprise エディションに移行しました。財務チームがデータ分析情報を必要なとき、IT チームは BigQuery でクエリを実行してデータを CSV ファイルにエクスポートし、メールの添付ファイルとして財務チームメンバーに送信します。財務チームが慣れているデータ分析方法を変えずにこのプロセスを改善するには、どうすればよいですか。
1. 　BigQuery でクエリを実行して、分析可能な結果ビューへのアクセスを財務チームに許可します。
2. BigQuery でクエリを実行して、Google データポータルのデータ ビジュアリゼーションへのアクセスを財務チームに許可します。
3. BigQuery でクエリを実行して、データを CSV にエクスポートし、そのファイルを Cloud Storage バケットにアップロードして財務チームと共有します。
4. BigQuery でクエリを実行して、財務チームがアクセスして分析できる Google スプレッドシートの共有スプレッドシートに結果を保存します。
<details><div>
正解
4. BigQuery でクエリを実行して、財務チームがアクセスして分析できる Google スプレッドシートの共有スプレッドシートに結果を保存します。
フィードバック
A: 選択肢 A は不正解です。財務チームは Google Cloud へのアクセス権が必要なことに加えて、BigQuery の使用に関するトレーニングも必要となります。財務チームにとって BigQuery はなじみのある方法ではありません。
B: 選択肢 B は不正解です。データポータルでビジュアリゼーションへのアクセスを許可するだけでは、財務チームはデータを分析できません。
C: 選択肢 C は不正解です。財務チームは Google Cloud へのアクセス権が必要なことに加え、Cloud Storage の使用に関するトレーニングも必要となります。財務チームにとって Google Cloud はなじみのある方法ではありません。
D: 選択肢 D は正解です。コネクテッド シートにより、Google スプレッドシートを通じて BigQuery データを簡単に共有できます。
 
https://cloud.google.com/bigquery/docs/connected-sheets
 
https://cloud.google.com/bigquery/docs/writing-results#saving-query-results-to-sheets
 
https://www.youtube.com/watch?v=rkimIhnLKGI
</div></details>

### Q. 
あなたの暗号通貨取引会社では、価格を可視化してお客様の取引の意思決定をサポートしています。さまざまな取引がリアルタイムで行われるため、価格データは、処理に Dataflow を使用するデータ パイプラインに提供されます。移動平均を計算するにはどうすればよいですか。
1. 　Dataflow でホッピング ウィンドウを使用します。
2. Dataflow でセッション ウィンドウを使用します。
3. Dataflow でタンブリング ウィンドウを使用します。
4. Dataflow SQL を使用して、時間でグループ化された平均を計算します。
<details><div>
正解
1. 　Dataflow でホッピング ウィンドウを使用します。
フィードバック
A: 選択肢 A は正解です。ホッピング ウィンドウを使用して移動平均を計算できます。
B: 選択肢 B は不正解です。セッション ウィンドウは移動平均の計算には使用されません。
C: 選択肢 C は不正解です。タンブリング ウィンドウは移動平均の計算には使用されません。
D: 選択肢 D は不正解です。時間によるグループ化だけでは移動平均を計算できません。
 
https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines
</div></details>

### Q. 
あなたは、数百万人のトレーダーがいる証券取引所用の取引プラットフォームを構築しています。取引データは迅速に書き込まれます。あなたは、特定の株式の経時的な価格変動などのデータを迅速に取得して、可視化データをトレーダーに表示する必要があります。そのために Google Cloud のストレージ ソリューションを選択しなくてはなりません。どうすればよいですか。
1. 　Bigtable を使用します。
2. Firestore を使用します。
3. Cloud SQL を使用します。
4. Memorystore を使用します。
<details><div>
正解
1. 　Bigtable を使用します。
フィードバック
A: 選択肢 A は正解です。Bigtable は、高スループットの読み取りと書き込みを必要とする時系列データに推奨されるデータベースです。
B: 選択肢 B は不正解です。Firestore には、時系列データに最適な高スループット機能がありません。
C: 選択肢 C は不正解です。Cloud SQL には、時系列データに最適な高スループット機能がありません。
D: 選択肢 D は不正解です。Memorystore は高速インメモリ データベースで、大量のデータの永続的な保存には向いていません。
 
https://cloud.google.com/bigtable/docs/overview#what-its-good-for
</div></details>

### Q. 
あなたは BigQuery で作業するアナリスト チームのメンバーで、すでに SQL に精通しています。チームは、BigQuery のデータを使用する、マルチラベルの機械学習分類モデルを構築する必要があります。トレーニング データセットには 6,000 行のデータがあります。推論は 200 のラベルの可能性の内の一つとなると考えられます。高精度のモデルを作成するにはどうすればよいですか。
1. 　BigQuery ML を使用してモデルを作成します。
2. データを CSV ファイルにエクスポートします。TensorFlow を使用してモデルを構築します。
3. BigQuery のデータを AutoML に接続し、AutoML でモデルを構築します。
4. AI Notebooks を使用してデータに接続して、モデルをインタラクティブに構築します。
<details><div>
正解
3. BigQuery のデータを AutoML に接続し、AutoML でモデルを構築します。
フィードバック
A: 選択肢 A は不正解です。高精度のモデルを構築するには BigQuery ML は多くのデータを必要としますが、手元にあるデータは多くありません。
B: 選択肢 B は不正解です。TensorFlow でカスタムモデルを構築するには十分なデータがありません。
C: 選択肢 C は正解です。データ量が比較的少なく多様なため、このデータのみでは構築されたモデルの精度は低くなります。AutoML は他の類似データに基づく転移学習を使用するため、適切です。
D: 選択肢 D は不正解です。AI Notebooks でカスタムモデルを構築するには十分なデータがありません。
 
https://cloud.google.com/vertex-ai/docs/start/automl-model-types#tabular
</div></details>

### Q. 
あなたは、財務チームが費用請求をもっと迅速に処理できるように支援するツールを構築しています。従業員は、レシートの画像が添付された、説明が最小限の費用請求を提出します。監査と分析のために、レシートの詳細をキャプチャするにはどうすればよいですか。
1. 　Document AI をワークフローに統合し、レシート画像の情報をキャプチャしてデータベースに追加します。
2. AutoML Vision を使用してレシート画像の情報をキャプチャし、データベースに追加します。
3. Pandas と SciPy を使用してレシート画像から情報を抽出できるモデルを構築して、情報をデータベースに追加します。
4. Cloud Natural Language API を使用してレシート画像からテキストを抽出し、データベースに追加します。
<details><div>
正解
1. 　Document AI をワークフローに統合し、レシート画像の情報をキャプチャしてデータベースに追加します。
フィードバック
A: 選択肢 A は正解です。Document AI では、請求書の画像を読み込んでテキスト情報を抽出する事前パッケージ ソリューションが提供されます。
B: 選択肢 B は不正解です。AutoML Vision には、レシートと請求書の画像から情報を抽出する既製のモデルがありません。
C: 選択肢 C は不正解です。適切なデータの収集と高品質の ML モデルの構築には、時間と労力がさらにかかります。
D: 選択肢 D は不正解です。Cloud Natural Language API には、レシートと請求書の画像から情報を抽出する既製のモデルがありません。Cloud Natural Language API は、非構造化テキストの分析情報を引き出す際に使用されます。
 
https://cloud.google.com/document-ai
 
https://cloud.google.com/document-ai/docs/processors-list#processor_expense-parser
</div></details>

### Q. 
機械学習モデルの構築に使用するデータセットがあります。そのデータセットはあなたにはなじみのないものですが、社内の他のユーザーはそれで作業しておりよく知っています。あなたは、ML モデルを反復的に構築しつつ、データを自身で確認したいと考えています。また、インタラクティブに協力してチーム環境で ML モデルを構築することも考えています。  どうすればよいですか。
1. 　Vertex AI Workbench ノートブックを使用して、ノートブックを同僚と共有します。
2. Google ドキュメントを使用して、ドキュメントを同僚と共有します。
3. BigQuery テーブルを使用して同僚にビューを提供します。
4. BigQuery を使用して、データを Looker で可視化します。ダッシュボードを同僚と共有します。
<details><div>
正解
1. 　Vertex AI Workbench ノートブックを使用して、ノートブックを同僚と共有します。
フィードバック
A: 選択肢 A は正解です。Vertex AI Workbench ノートブックでは、他のユーザーと協力して、インタラクティブかつ反復的に機械学習モデルを構築できます。
B: 選択肢 B は不正解です。Google ドキュメントはコラボレーション機能を提供しますが、他の ML モデル構築ツールと直接統合されていません。
C: 選択肢 C は不正解です。BigQuery ビューの共有ではデータが共有されるだけで、モデル構築作業の残りの部分はサイロ化された状態となります。
D: 選択肢 D は不正解です。データのビジュアリゼーションのみを共有するだけでは、目的の達成には不十分です。他の ML モデル構築機能も必要です。
 
https://cloud.google.com/vertex-ai-workbench
 
https://cloud.google.com/vertex-ai/docs/workbench/introduction
</div></details>

### Q. 
あなたの会社は Cloud SQL を 2 つのリージョンで実行しています。1 つ目のリージョンである us-central1 はエンドユーザーに近く、本番環境での使用頻度は多く、予測可能です。もう一つのリージョンである europe-west1 は開発チームに近く、使用は断続的です。労力、レイテンシ、パフォーマンス面で妥協することなく費用を削減するには、どうすればよいですか。
1. 　米国リージョンの確約利用割引（CUD）を利用します。開発チームの割り当て方法をそのまま保持します
2. 米国リージョンの確約利用割引（CUD）を利用します。開発チームの割り当てを米国リージョンに移動し、低い費用のメリットを利用します。
3. 希望する費用の削減の程度に応じて、VM に割り当てられている仮想 CPU の数を 1% 単位で減らします。
4. カスタムのより低コストの VM を Compute Engine にプロビジョニングして、必要に応じてデータベースをインストールします。
その他:
<details><div>
正解
1. 　米国リージョンの確約利用割引（CUD）を利用します。開発チームの割り当て方法をそのまま保持します
フィードバック
A: 選択肢 A は正解です。使用が予測可能な場合、Cloud SQL の確約利用割引を利用できます。
B: 選択肢 B は不正解です。すべてのシステムを米国に移動して確約利用割引を利用すると費用の面でメリットがありますが、レイテンシの面でデメリットがあります。
C: 選択肢 C は不正解です。vCPU を減らすとパフォーマンスが低下します。
D: 選択肢 D は不正解です。データベース管理のローリングは、労力が余計にかかります。
 
https://cloud.google.com/sql/cud
 
https://cloud.google.com/blog/products/databases/reduce-cloud-sql-costs-with-optimizations-by-active-assist/
</div></details>


## 9
## 10
## 11