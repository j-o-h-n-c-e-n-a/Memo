## 1

### Q.質問1: 回答
データ処理アプリケーションを Google Kubernetes Engine(GKE)に効率的にデプロイし、コンテナがコンテナ レジストリから利用可能な最新の構成で起動されるようにすると同時に、GKE ノードに GPU、ローカル SSD、8 Gbps 帯域幅を確保し、デプロイ プロセスを管理できるようにするにはどうすればよいでしょうか
1. 　
2. Cloud Build と Terraform Build を使用してインフラストラクチャをプロビジョニングし、コンテナ レジストリから利用可能な最新の構成でコンテナを起動します
3. 
4. 
<details><div>
    答え：
説明
正解はBです。
Cloud Build と Terraform Build を使用してインフラストラクチャをプロビジョニングし、コンテナ レジストリから利用可能な最新の構成でコンテナを起動します。
Cloud Build と Terraform Build の併用は、インフラストラクチャのデプロイを再現可能な方法で自動化するためのベスト プラクティスです。
Terraform を使用してインフラストラクチャをコードとして定義することで、GKE ノードに GPU、ローカル SSD、8 Gbps の帯域幅を確保し、利用可能な最新のコンテナ イメージが使用されていることを確認できます。その後、Cloud Build を使用して、インフラストラクチャをプロビジョニングし、コンテナを起動するジョブをスケジュールし、効率的なデプロイ プロセスが可能になります。
Compute Engine のスタートアップ スクリプトは GKE でインフラストラクチャをプロビジョニングする最適な方法ではないため、オプション A は正しくありません。
オプション C は、Terraform と Cloud Build を使用するメリットを活用していないため、正しくありません。
オプション D は、Dataflow が GKE でインフラストラクチャをプロビジョニングするための適切なツールではないため、正しくありません。
</div></details>

### Q.質問2: 回答
BigQuery ML を使用して機械学習モデルを構築し、Vertex AI エンドポイントを作成して、複数のベンダーからのストリーミング データをほぼリアルタイムで処理します。データに無効な値が含まれている可能性があります。この状況に対処するための最善のアプローチは何ですか?
1. 　
2. 
3. 
4. ベンダーデータをPub/Subトピックに送信し、Dataflowを使用してデータを処理、サニタイズしてからBigQueryにストリーミングします
<details><div>
    答え：
説明
BigQuery ML を使用して機械学習モデルを作成し、複数のベンダーからの連続ストリーミング データをほぼリアルタイムで処理できる Vertex AI を使用してモデルをホストするためのエンドポイントを作成する場合、データに無効な値が含まれている可能性があるため、Pub/Sub を使用してデータを取り込み、Dataflow を使用してデータを処理およびサニタイズしてから BigQuery にストリーミングするのが最善の方法です。
したがって、オプションDが正解です。Pub/Sub は、複数のベンダーからの大量のデータを処理できる、スケーラブルで信頼性の高いメッセージング サービスです。Dataflow は、ストリーミング データをリアルタイムで変換およびサニタイズするために使用できるサーバーレス データ処理サービスです。Pub/Sub と Dataflow を使用すると、データ内の無効な値を処理できるスケーラブルでフォールトトレラントなデータ処理パイプラインを作成できます。
BigQuery ストリーミング挿入を使用して、複数のベンダーのデータをオプション B に取り込むことは実行可能なオプションですが、データに無効な値が含まれている可能性があるため、最適なアプローチではない可能性があります。
オプションAは複雑さを増す可能性があり、望ましい結果を達成するために必要ない場合があります。
オプション C は機能しますが、連続ストリーミング データをほぼリアルタイムで処理するためのスケーラブルでフォールト トレラントなデータ処理パイプラインは提供されません。
</div></details>

### Q.質問3: 回答
Compute Engine 仮想マシン(n2-standard-32)でトレーニングされた TensorFlow 機械学習モデルがあり、完了するまでに <> 日かかります。このモデルには、部分的に CPU 上で実行する必要があるカスタム TensorFlow 操作が必要です。費用対効果の高い方法でトレーニング時間を短縮するために何ができますか
1. 　
2. 
3. GPU ハードウェア アクセラレータを搭載した VM を使用して TensorFlow モデルをトレーニングします
4. 
<details><div>
    答え：
説明
TensorFlow モデルには、部分的に CPU 上で実行する必要があるカスタム TensorFlow 操作がある場合、コスト効率の高い方法でトレーニング時間を短縮する最適なオプションは、GPU ハードウェア アクセラレータを備えた VM を使用してモデルをトレーニングすることです。
したがって、オプションCが正解です。
GPU アクセラレータは、特に実行する計算が多数ある場合に、仮想マシンでの TensorFlow トレーニングを大幅に高速化できます。n2-highmem-32 と e2-standard-32 の仮想マシンタイプには、それぞれより多くのメモリと CPU リソースがありますが、GPU や TPU などの TensorFlow トレーニングを高速化するために必要な特殊なハードウェアはありません。
TPU は TensorFlow 用に設計された特殊なハードウェア アクセラレータですが、GPU ベースの VM よりも高価になる可能性があるため、このシナリオでは費用対効果が高くない可能性があります。
したがって、GPU ハードウェア アクセラレータを搭載した VM を使用して TensorFlow モデルをトレーニングすることは、トレーニング時間を短縮するための最も費用対効果の高いオプションです。
ワークロードに基づいて適切なGPUタイプを選択することも、最高のパフォーマンスと費用対効果を実現するために重要であることに注意してください。
</div></details>

### Q.質問4: 未回答
BigQuery を使用して会社の売上データにデータ ウェアハウスを設計しているとします。スター スキーマを使用してオンプレミスの販売データ ウェアハウスを BigQuery に移行しましたが、過去 30 日間のデータをクエリするとパフォーマンスの問題が発生しています。ストレージ コストを増やさずにクエリを高速化するために採用すべき Google 推奨のプラクティスは、次のうちどれですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
これは非正規化モデルであり、ファクト テーブルは、注文金額、割引、数量などのメトリックをキーのグループと共に収集します。これらのキーは、顧客、仕入先、地域などのディメンション テーブルに属します。グラフィカルには、モデルは星形に似ており、中央のファクト テーブルはディメンション テーブルに囲まれています。
スタースキーマはすでに非正規化されているので、パーティションはDを使用する方が理にかなっています
参照:https://cloud.google.com/bigquery/docs/migration/schema-data-overview#migrating_data_and_schema_from_on-premises_to_bigquery
</div></details>

### Q.質問5: 回答
ある金融機関は、Dialogflow を使用してモバイルアプリ用のチャットボットを作成することを計画しています。チャットログがレビューされ、顧客のリクエストに意図のタグが付けられました。リクエストの70%は単純で、必要なインテントは10個以下ですが、残りの30%はより複雑なリクエストが必要です。会社は、どのインテントを最初に自動化する必要があるかを知りたいと考えています。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
顧客のリクエストの大部分をカバーするインテントを自動化することで、ライブエージェントの作業負荷が軽減され、より複雑なリクエストに集中できるようになります。これらの単純なリクエストを最初に自動化することで、チャットボットは全体的により効率的なカスタマーサービス体験を提供できます。
</div></details>

### Q.質問6: 未回答
Pub/Sub トピックにパブリッシュされたアプリケーション イベントを効率的に処理して BigQuery に読み込み、大量のイベントのスケーラビリティを確保し、時間間隔で集約するにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. Pub/Sub トピックから継続的に読み取り、サンプリングウィンドウを使用して必要な集計を実行するストリーミングDataflowジョブを使用します
<details><div>
    答え：
説明
参照:https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines#tumbling-windows
</div></details>

### Q.質問7: 未回答
Pub/Sub の過去 5 秒分のデータを使用して、企業の株価の移動平均を 30 秒ごとに計算するには、DataFlow でウィンドウ パイプラインをどのように設定すればよいでしょうか?
1. 　
2. 
3. 
4. 期間が30秒、期間が5秒のスライディングウィンドウを使用し、AfterWatermark.pastEndOfWindow()のトリガーを使用して結果を出力します
<details><div>
    答え：
説明
次のウィンドウは、Apache Beam SDK または Dataflow SQL ストリーミング拡張機能で設定します。
ホッピング ウィンドウ (Apache Beam ではスライディング ウィンドウと呼ばれます) ホッピング ウィンドウは、データ ストリーム内の一貫した時間間隔を表します。
ホッピング ウィンドウは重なり合うことができますが、タンブリング ウィンドウはバラバラです。
たとえば、ホッピング ウィンドウは 30 秒ごとに開始され、1 分間のデータをキャプチャできます。ホッピング ウィンドウが開始する頻度は、期間と呼ばれます。この例では、1 分のウィンドウと 30 秒の期間があります。
参照:https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines#hopping-windows
</div></details>

### Q.質問8: 未回答
大手不動産会社の従業員は、SQL と BigQuery ML を使用して機械学習用に 6 TB の住宅販売データを準備する必要があります。結果のモデルを生データセットに対する予測に使用する予定です。予測時のスキューを防ぐには、どのワークフローに従う必要がありますか?
1. BigQueryのTransform句を使用して、モデル作成時の前処理ステップを定義します。次に、予測時に、生の入力データに変換を指定せずにBigQueryのML.EVALUATE句を使用します
2. 
3. 
4. 
<details><div>
    答え：
説明
Aが答えです。https://cloud.google.com/bigquery-ml/docs/bigqueryml-transform
TRANSFORM 句を使用すると、モデル作成時にすべての前処理を指定できます。
前処理は、機械学習の予測フェーズと評価フェーズで自動的に適用されます
</div></details>

### Q.質問9: 未回答
サブスクライバーのコードを Pub/Sub フィードに更新し、デプロイ後に誤ったメッセージ確認によってメッセージが失われないようにする必要があります。次のオプションのうち、どれを選択する必要がありますか?
1. 　
2. 新しいサブスクライバー コードをデプロイする前に、Pub/Sub スナップショットを作成します。Seek 操作を使用して、スナップショットの作成後に使用可能になったメッセージを再配信します。
3. 
4. 
<details><div>
    答え：
説明
新しいサブスクライバー コードをデプロイする前に、Pub/Sub スナップショットを作成します。Seek 操作を使用して、スナップショットの作成後に使用可能になったメッセージを再配信します。
以下のリストの 2 番目の参照 (以下の 2 番目のリンクを参照) によると、新しいサブスクライバー コードをデプロイする際の懸念事項は、新しい実行可能ファイルが誤ってメッセージを確認し、メッセージの損失につながる可能性があることです。スナップショットをデプロイメント・プロセスに組み込むと、新しいサブスクライバー・コードのバグから回復できます。
タイムスタンプをシークするには、まず retain-acked-messages を使用して確認応答メッセージを保持するようにサブスクリプションを構成する必要があるため、回答を C にすることはできません。retain-acked-messages が設定されている場合、Pub/Sub は確認済みのメッセージを 7 日間保持します
参照：
https://cloud.google.com/pubsub/docs/replay-message
https://cloud.google.com/pubsub/docs/replay-overview#seek_use_cases
</div></details>

### Q.質問10: 未回答
BigQuery のテーブルには、複数の店舗で行われた購入に関する情報が含まれています。
最適なクエリパフォーマンスを得るには、最適なデータモデルを選択する必要があります。
このテーブルには、トランザクションの時間、購入したアイテム、店舗 ID、店舗が所在する市区町村や都道府県などの情報が含まれています。
多くの場合、クエリを実行して、過去 30 日間の各品目の売上を表示し、州、市区町村、および個々の店舗ごとの購入傾向を分析します。
クエリのパフォーマンスを最大にするために、このテーブルをどのようにモデル化しますか?
1. 　トランザクション時間でテーブルをパーティション分割し、都道府県、市区町村、店舗IDでクラスタ化します
2. 
3. 
4. 
<details><div>
    答え：
説明
トランザクション時間によるパーティション分割は、一般的なユースケースであるトランザクションの日付によるデータのフィルタリングに役立ちます。
都道府県、市区町村、店舗 ID でこの順序でクラスタリングすると、地理的な地域ごとにデータをグループ化し、効率的なフィルタリングと集約が可能になります。
このアプローチは、州、都市、店舗ごとの傾向を分析したり、地域ごとにどの製品がよく売れているかを特定したりするのにも役立ちます
したがって、パーティショニングは明らかです:クラスタリングはオプションAですでに言及されています。そのため、最高のパフォーマンスを実現するには、両方が必要です。
</div></details>

### Q.質問11: 未回答
金融機関は顧客がオンラインで登録することを許可しており、ユーザーデータは BigQuery に取り込まれる前に Pub/Sub に送信されます。ただし、セキュリティ上の理由から、顧客の政府発行の識別番号 (GIIN) を編集し、必要に応じてカスタマー サービス担当者が元の値を表示できるようにする必要があります。これを実現するには、どのオプションを選択する必要がありますか?
1. 　
2. BigQueryの列レベルのセキュリティを使用し、CustomerServiceユーザーグループのメンバーのみがGIIN列を表示できるようにテーブル権限を設定します
3. 
4. 
<details><div>
    答え：
説明
要件は、権限のある担当者がIDを表示できるようにすることですが、オプションDには明示的に言及されていません。
</div></details>

### Q.質問12: 未回答
同社は現在、Spark、Hive、HDFSを使用して大規模なオンプレミスクラスターを運用しており、コスト削減の恩恵を受け、インフラストラクチャを最新化するためにクラウドに移行することを計画しています。コロケーション施設との契約更新のタイミングにより、最初の移行には2か月しかありません。コスト削減を最大化し、移行を予定どおりに完了するには、どの移行戦略を採用すべきですか?
1. 　
2. ワークロードを Dataproc と Cloud Storage に移行する。後でモダナイズする：このオプションでは、モダナイズせずにワークロードをワークロードを Dataproc と Cloud Storage に移行し、あとで、モダナイズすることを提案します。
3. 
4. 
<details><div>
    答え：
説明
最適なアプローチは、ワークロードを Dataproc と Cloud Storage に移行することで、コストを削減しながら、後でワークロードをモダナイズできるようにすることです。また、このソリューションにより、移行が 2 か月以内に完了するようになります。
オプション A と C は最新化に対応しておらず、後回しにすることを提案しており、追加コストにつながる可能性があります。
オプション D は、2 か月の期間とワークロードをクラウドに移行する必要があることを考えると、野心的すぎる可能性があります。
</div></details>

### Q.質問13: 回答
最初に Apache Kafka ストリームに送信された取り込み日のパーティショニングを使用してパッケージ追跡データテーブルの地理空間傾向を分析するために、BigQuery でクエリのパフォーマンスを向上させるにはどうすればよいでしょうか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
クラスタリングは、1 つ以上の列の値に基づいてテーブル内のデータを整理することで、BigQuery のクエリのパフォーマンスを向上させます。テーブルには ingest-date パーティション分割があるため、tracking-id 列でクラスタリングするとデータがグループ化され、クエリの実行時にスキャンする必要があるデータの量を減らすことができます。
オプション B では、パッケージ追跡 ID に依存するクエリのパフォーマンスが向上する可能性があります
オプション C は、古いデータを階層化してストレージ コストを削減するのに役立ちますが、必ずしもクエリのパフォーマンスが向上するとは限りません。
オプション D では、パッケージの配信日にデータ パーティションを使用してテーブルを再作成し、パフォーマンスを向上させることができますが、新しいテーブルにデータを再取り込む必要があり、実用的ではない可能性があります。
</div></details>

### Q.質問14: 未回答
あなたは、北米で事業を展開する大手銀行の取引データの保存と管理を担当しています。ACIDコンプライアンスを確保し、データへのSQLアクセスを提供できるデータストレージソリューションが必要です。次のうち、適切なオプションはどれですか?
1. 　
2. Cloud Spanner を使用してトランザクションデータを保存し、読み取り・書き込みトランザクションのロックを利用する
3. 
4. 
<details><div>
    答え：
説明
このユースケースに適したソリューションは、Cloud Spanner を使用してトランザクション データを保存し、読み取り/書き込みトランザクションのロックを利用することです。Cloud Spanner はフルマネージドのリレーショナル データベースであり、NoSQL データベースのスケーラビリティとパフォーマンスの利点を提供すると同時に、ACID コンプライアンスとデータへの SQL アクセスも提供します。さらに、読み取り/書き込みトランザクションをロックすることで、一貫性が確保され、書き込み操作中のデータ破損から保護されます。
</div></details>

### Q.質問15: 未回答
BigQuery ML で線形回帰モデルを開発し、顧客が自社の商品を購入する可能性を予測しています。このモデルでは、主要な予測コンポーネントとして都市名が必要ですが、モデルをトレーニングして提供するために、データを列に整理する必要があります。データを準備する最も効率的な方法はどれですか?
1. 　
2. BigQuery の SQL を使用して、都道府県列にワンホット エンコーディングを適用し、各市区町村をバイナリ値列に変換する
3. 
4. 
<details><div>
    答え：
説明
都市名を主要な予測要素として BigQuery ML で線形回帰モデルのデータを準備する最も効率的な方法は、BigQuery の SQL を使用して都道府県列にワンホット エンコーディングを適用し、各市区町村をバイナリ値列に変換することです。
選択肢Bが正解です。ワンホット エンコードは、線形回帰モデルでカテゴリ変数を処理するための標準的な方法です。各都市のダミー変数を作成し、モデルが都市情報を予測変数として取り込むことを可能にします。
このアプローチは、オプション C や D に比べてコーディングが少なくて済み、実装も簡単です。
したがって、正解はオプション B: BigQuery で SQL を使用して one-hot エンコーディングを state 列に適用し、各都市をバイナリ値の列に変換することです
</div></details>

### Q.質問16: 回答
BigQuery、Dataflow、Dataproc でデータ パイプラインを管理している。目標は、ユーザーの行動を監視し、ヘルスチェックを実行して、障害が発生した場合にチームに通知することです。さらに、複数のプロジェクトにまたがって作業できる必要があります。管理対象のプロダクトや GCP プラットフォームの機能を使用するソリューションのうち、どれを選びますか?
1. データを Stackdriver にエクスポートし、アラート ポリシーを設定する
2. 
3. 
4. 
<details><div>
    答え：
説明
データを Stackdriver にエクスポートし、アラート ポリシーを設定することは、BigQuery、Dataflow、Dataproc で実行されているデータ パイプラインの動作を監視するのに最適なソリューションです。
Stackdriver は Cloud Monitoring と呼ばれるようになり、GCP 上のクラウド リソースとアプリケーションを監視するためのマネージド ソリューションになりました。
データを Cloud Monitoring にエクスポートすることで、パイプラインの健全性をモニタリングし、障害が発生した場合に通知を受け取り、複数のプロジェクトにまたがるアラート ポリシーを設定できます。
このソリューションでは、セットアップや管理があまり必要ないため、必要に応じて保守や拡張が容易になります
</div></details>

### Q.質問17: 回答
クラウド プロバイダのスタッフがデータを復号できないようにするために、「Trust No One」(TNO)アプローチを使用して Cloud Storage にアーカイブするデータを暗号化するおすすめの方法は何ですか?
1. 　
2. 
3. 
4. 顧客提供の暗号化キー
<details><div>
    答え：
説明
A と B は、KMS で生成されたキーが CSP によってアクセス可能であると見なされるため、すぐに削除できます。
C は、メモリ ストアが本質的にキャッシュ サービスであるため、正しくありません。追加の認証済みデータ (AAD) は "ソルト" として機能し、暗号ではありません。
</div></details>

### Q.質問18: 未回答
何百万台ものコンピューターの時系列の CPU とメモリ使用量の 1 秒間隔のサンプルを保存し、リアルタイムのアドホック分析を可能にし、スケーラビリティを確保し、実行されるすべてのクエリに対して課金されないようにするのに最適なデータベースとデータ モデルは何ですか?
1. 　
2. 
3. ComputeEngine のコンピュータ識別子と各秒のサンプル時間を組み合わせた行キーを使用して、Bigtableで幅の狭いテーブルを作成します
4. 
<details><div>
    答え：
説明
何百万台ものパソコンの CPU とメモリの使用量を 1 秒間隔のサンプルで時系列で保存し、リアルタイムのアドホック分析とスケーラビリティを実現し、クエリを実行するたびに課金されないようにする最適なデータベースとデータモデルは、コンピューター エンジンのコンピューター識別子と各秒のサンプル時間を組み合わせた行キーを使用して、Bigtable で幅の狭いテーブルを作成することです。
このモデルでは、効率的かつ高速なデータ取得が保証され、クエリのパフォーマンスを低下させることなく大量のデータを処理できます。
BigQuery は時系列データの保存には適しておらず、BigQuery と Bigtable のワイド テーブル モデルは、効率的なクエリ パフォーマンスと将来のスケーラビリティには適していません。
参照:https://cloud.google.com/bigtable/docs/schema-design-time-series
</div></details>

### Q.質問19: 回答
20 TB のオンプレミス オペレーショナル システム トランザクション データを GCP に移動するのに最適な GCP データベースは何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
参照:https://cloud.google.com/sql/docs/quotas#:~:text=Cloud%20SQL%20storage%20limits&text=Up%20to%2030%2C720%20GB%2C%20depending,for%20PostgreSQL%20or%20SQL%20Server
</div></details>

### Q.質問20: 回答
自動的にスケールアップし、トランザクションの一貫性を提供し、最大 6 TB までスケールアップでき、SQL を使用してクエリを実行する必要がある新しいプロジェクトに最適なフル マネージド データベースはどれですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Cloud SQL は、リレーショナル データベース機能が必要だが、10 TB を超えるストレージ容量や 4000,<> を超える同時接続は必要ない場合に適したオプションです。また、オンプレミス管理のスキルも必要です。
Cloud Spanner: Cloud Spanner は、大量のデータ(10 TB 以上)を使用する予定で、トランザクションの一貫性が必要な場合に適したオプションです。
Cloud SQL から開始し、最終的に Cloud Spanner に移行する必要がある場合は、データベースの移行に加えて、アプリケーションを書き直す準備をしてください。
</div></details>

### Q.質問21: 回答
Cloud Dataproc クラスタがあり、起動時にそのすべてのノードに追加の依存関係をデプロイする必要があるが、会社のセキュリティ ポリシーにより、Cloud Dataproc ノードがインターネットにアクセスすることが禁止されている。この目的のための既存の初期化アクションがあります。これらの依存関係をデプロイするにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
インターネットにアクセスできなくても、限定公開の Google アクセスを有効にして、ジョブの依存関係を Cloud Storage に配置できます。クラスタ ノードは、内部 IP アドレスから Cloud Storage から依存関係をダウンロードできます。
参照:https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/network#create_a_cloud_dataproc_cluster_with_internal_ip_address_only
</div></details>

### Q.質問22: 未回答
二項分類問題の既定のパラメーターを使用してサポート ベクター マシン (SVM) 分類器に学習させ、検証セットで曲線下面積 (AUC) 0.87 を達成しました。モデルの AUC を改善したい。どのオプションを選択する必要がありますか?
1. SVM分類器でハイパーパラメータ調整を実行する
2. 
3. 
4. 
<details><div>
    答え：
説明
ハイパーパラメーターの調整では、モデルのパラメーターを最適化してパフォーマンスを向上させます。SVMモデルはデフォルトのパラメータで学習されているため、改善の余地がある可能性があります。
ハイパーパラメーター調整を実行することで、SVM 分類器のパフォーマンスが向上し、AUC が高くなる可能性があります。
オプションBは、ディープニューラルネットワークのパフォーマンスがデータの性質と問題に依存するため、必ずしも当てはまるとは限りません。
オプション C は、モデルの実際のパフォーマンスがコンテキストによって大きく異なる可能性があるため、信頼できるアプローチではありません。
オプション D は、モデルのパフォーマンスを向上させるための一般的なアプローチではなく、二項分類の問題には適していない可能性があります。
</div></details>

### Q.質問23: 回答
オンプレミスのApache Hadoopデプロイメントをクラウドに移行して長時間実行されるバッチジョブを実現するための、最もフォールトトレラントで費用対効果の高いマネージドサービスは何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Dataproc は Spark と Hadoop のマネージド サービスで、オープンソースのデータ ツールを活用してバッチ処理、クエリ、ストリーミング、機械学習を行うことができます。
Dataproc の自動化により、クラスタをすばやく作成して簡単に管理し、不要なときにクラスタをオフにすることで費用を節約できます。管理に費やす時間とコストが削減されるため、ジョブとデータに集中できます
</div></details>

### Q.質問には「費用対効果が高い」と記載されています。そのため、クラウドストレージとPremptible Workersを考慮する必要があります
参照:https://cloud.google.com/dataproc/docs/concepts/overview
</div></details>

### Q.質問24: 回答
データの取り込みと配信を一元化し、キーごとの順序を維持し、トピック内の特定のオフセットをシークし、何百ものトピックのセマンティクスをパブリッシュ/サブスクライブする機能をサポートするには、どのシステムを選択する必要がありますか?
1. Apache Kafka
2. 
3. 
4. 
<details><div>
    答え：
説明
キーワードは「取り込みと配送」です。したがって、Apache Kafkaを選択する必要があります。
トピックのオフセットは、「トピックのパーティション分割とトピックの特定の部分の再処理、1つのトピックの行き来用に設計されているため、pub / subでは不可能」と説明しています。
「キーごとの順序付け」は、同じキーを持つメッセージを処理したり、kafka でユーザーに割り当てることができることを示します。
</div></details>

### Q.質問25: 回答
MySQL を使用して Cloud SQL をデプロイする際に、ゾーンに障害が発生した場合に高可用性を確保するための推奨される方法は何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
MySQL を使用して Cloud SQL をデプロイする際に、ゾーン障害が発生した場合に高可用性を確保するための推奨される方法は、1 つのゾーンに Cloud SQL インスタンスを作成し、同じリージョン内の別のゾーンにフェイルオーバー レプリカを作成することです(オプション A)。T
HISは、プライマリ・ゾーンで障害が発生した場合にレプリカ・インスタンスへの自動フェイルオーバーを提供し、ダウンタイムを最小限に抑え、データの高可用性を確保します。
さらに、このセットアップは、リージョン全体の停止から保護するためのリージョン冗長性も提供します。
</div></details>

### Q.質問26: 回答
オンプレミス環境には、毎日合計 100 GB の数百万の構造化された JSON テキスト ファイルを生成するプラットフォームがあります。ただし、オンプレミス環境にはパブリック インターネットからアクセスできません。Google Cloud プロダクトを使用してプラットフォーム データを探索し、クエリを実行したい。推奨される解決策は何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
オンプレミス データ用の Transfer Service は、オンプレミス環境から Google Cloud Storage に大量のデータを安全に転送するために特別に設計されています。
オンプレミス環境はパブリックインターネットからアクセスできないため、このサービスを使用して安全な接続を確立し、データを転送できます。
データを Cloud Storage に転送した後、BigQuery Data Transfer Service を使用して BigQuery にデータをインポートできます。このサービスでは、さまざまなソースから BigQuery へのデータのインポートを簡単にスケジュール設定し、自動化できます。
オプション A では、Cloud Scheduler を使用してオンプレミス環境から Cloud Storage にデータをコピーしますが、インターネットにアクセスできないため、実現可能なソリューションではない可能性があります。
オプション B では、毎日 100 GB のデータを転送するためには必要ない Transfer Appliance を使用します。
オプション D では、すべてのデータを BigQuery に直接転送しますが、大量のデータに対しては効率的ではなく、実用的ではない可能性があります
</div></details>

### Q.質問27: 未回答
Google が推奨する方法に従い、費用、時間、労力を最小限に抑えながら、オンプレミスのデータセンターから Memorystore for Redis インスタンスに Redis データベースを移行するにはどうすればよいでしょうか。どのオプションが最適ですか?
1. RedisデータベースをRDBファイルとしてバックアップし、gsutilを使用してCloudStorageバケットにコピーし、そのファイルをMemorystoreforRedisインスタンスにインポートする
2. 
3. 
4. 
<details><div>
    答え：
説明
オプションAが最良の選択です。Redis データベースを Memorystore for Redis に移行する場合は、データベースの RDB バックアップを作成し、RDB ファイルを Cloud Storage にコピーしてから、Memorystore インスタンスにインポートすることをおすすめします。この方法は、迅速かつ簡単に実装でき、ダウンタイムも最小限に抑えられます。
オプション B は、Compute Engine インスタンス上に Redis データベースのセカンダリ インスタンスを作成し、ライブ カットオーバーを実行する必要があるため、推奨されません。この方法は複雑になる可能性があり、データの損失やダウンタイムの延長につながる可能性があります。
オプション C では、オンプレミスのデータセンターから Redis データベースを読み取り、そのデータを Memorystore for Redis インスタンスに書き込む Dataflow ジョブを作成します。この方法は複雑になる可能性があり、コストと時間が増加する可能性があります。
オプション D では、シェル スクリプトを記述して Redis データを移行し、新しい Memorystore for Redis インスタンスを作成します。この方法ではエラーが発生しやすく、データの損失やダウンタイムの延長につながる可能性があります。したがって、推奨されるアプローチではありません。
</div></details>

### Q.質問28: 未回答
Cloud Data Loss Prevention(Cloud DLP)と Google が推奨するサービス アカウントを使用しながら、銀行業界の政府規制で義務付けられ、会社のデータ保護基準で義務付けられている、顧客の個人を特定できる情報(PII)へのアクセスを制御するには、どのオプションに従う必要がありますか?
1. 必要なIAMロールをすべての従業員に割り当て、プロジェクトリソースにアクセスするための１つのサービスアカウントを作成します。
2. 
3. 
4. 
<details><div>
    答え：
説明
オプション A では、必要な Identity and Access Management (IAM) ロールをすべての従業員に割り当て、プロジェクト リソースにアクセスするための 1 つのサービス アカウントを作成することを提案します。このアプローチにより、アクセス制御をより一元的に管理でき、各従業員の特定のアクセスニーズに基づいてIAMロールを割り当てることができます
</div></details>

### Q.質問29: 未回答
大量の集計データを表示し、BigQuery とデータポータルを使用して多数の同時ユーザーがいることが予想される顧客向けダッシュボードを最適化して、最小限のレイテンシで迅速な可視化を実現するにはどうすればよいでしょうか。
1. BigQuery BI Engine とマテリアルズビューの併用
2. 
3. 
4. 
<details><div>
    答え：
説明
BigQuery BI Engine は、BigQuery 向けのフルマネージドのインメモリ分析サービスであり、ユーザーは大規模で複雑なデータセットを、秒未満のクエリ応答時間と高い同時実行性でインタラクティブに分析できます。
具体化されたビューと共に使用すると、一般的に使用される分析クエリのクエリ処理を高速化できます。マテリアライズドビューは、クエリの結果をテーブルに格納し、ビューがクエリされるたびに結果を再計算するのではなく、そのテーブルをクエリします。
これにより、特に大規模で複雑なクエリの場合、クエリの応答時間を大幅に短縮できます。
マテリアライズドビューで BigQuery BI Engine を使用することは、大量の同時ユーザーを含む大量の集計データを表示する顧客向けダッシュボードのパフォーマンスを最適化するための推奨されるアプローチです。
</div></details>

### Q.質問30: 未回答
オープンソース ツールと Google Kubernetes Engine(GKE)を使用してワークフロー パイプラインのスケジューリングを実装する必要があります。タスクを簡素化して自動化するには、共有 VPC のネットワークに関する考慮事項にも対応する Google マネージド サービスを使用します。どのオプションを選択する必要がありますか?
1. 　
2. 
3. 
4. 共有VPC構成でCloudComposerを使用し、サービスプロジェクトにCloudComposerリソースを配置する
<details><div>
    答え：
説明
Cloud Composer は、Apache Airflow 上に構築されたマネージド ワークフロー オーケストレーション サービスであり、ワークフローを作成、スケジュール、モニタリングできます。
BigQuery、Cloud Storage、Dataflow など、他の Google Cloud サービスと統合できます。共有 VPC ネットワークに関する考慮事項に対応するには、Cloud Composer リソースをサービス プロジェクトに配置する必要があります。
これは、共有 VPC セットアップでは、サービス プロジェクトには複数のプロジェクト間で共有されるリソースが含まれ、ホスト プロジェクトには共有 VPC 構成が含まれているためです。
Cloud Composer リソースをサービス プロジェクトに配置することで、ネットワーク構成を簡素化し、ワークフローがホスト プロジェクトで必要なリソースにアクセスできるようにすることができます。また、このアプローチにより、アクセス制御と監視を一元化できるため、セキュリティとコンプライアンスの維持に役立ちます
</div></details>

### Q.質問31: 未回答
障害発生時に人間の介入を最小限にとどめるACID準拠のデータベースシステムをどのように設計すればよいのでしょうか。以下から 1 つのオプションを選択します。
1. 　
2. 高可用性を有効にしてCloudSQLforPostgreSQLインスタンスを構成します
3. 
4. 
<details><div>
    答え：
説明
Cloud SQL for PostgreSQL インスタンスを高可用性で構成すると、別のゾーンのスタンバイ レプリカ インスタンスに自動的にフェイルオーバーされるため、障害発生時の人的介入が最小限に抑えられます。
また、このオプションにより、データベースが ACID に準拠していることも保証されます。
他のオプションでは自動フェールオーバーは提供されず、障害が発生した場合に人間の介入が必要になる場合があります。
オプションAは、高可用性のためのクロスゾーンレプリケーションを提供しません。
オプション C では自動フェールオーバーは提供されません。
オプションDはデータウェアハウスであるため、ACID準拠のデータベースではありません。
</div></details>

### Q.質問32: 未回答
組織には、オンプレミスのデータセンターの POSIX 準拠のソースに保存されている 15 TB のデータがあり、Google Cloud に転送する必要があります。データは毎週変更され、ネットワーク運用チームはパブリック インターネットに 500 Mbps の帯域幅を許可しています。Google が推奨する方法に従って、信頼性の高い週次データ転送を行う必要がある。あなたは何をするべきか?
1. 　
2. 
3. Storage Transfer Service エージェントをオンプレミスのデータセンターにインストールし、毎週の転送ジョブを構成します
4. 
<details><div>
    答え：
説明
Storage Transfer Service エージェント (データ センター内のオンプレミス データ用) をインストールし、毎週の転送ジョブを構成します。Storage Transfer Service は、オンプレミスのデータセンターから Google Cloud への大量のデータの転送を処理できる、フルマネージドで費用対効果の高いサービスです。
毎週の転送ジョブを構成する機能により、限られた帯域幅ネットワークを介して大量のデータを定期的に転送するための信頼性の高い自動化されたソリューションを提供します
パフォーマンスを向上させるためにオンプレミスにエージェントをインストールする理由。
参照:https://cloud.google.com/storage-transfer/docs/managing-on-prem-agents#file_system_transfer_details
参照:https://cloud.google.com/storage-transfer/docs/managing-on-prem-agents
</div></details>

### Q.質問33: 未回答
10 TB を超えるデータを含むデータベースから医療情報の大規模な結果セットを取得し、さらにクエリを実行するために新しいテーブルに格納するには、費用対効果の高いソリューションを見つける必要があります。データベースは、メンテナンスの少ないアーキテクチャを持ち、SQL経由でアクセスできる必要があります。どのオプションを選択する必要がありますか?
1. 　
2. BigQueryをデータウェアハウスとして使用し、大きなクエリをキャッシュするための出力先を設定する
3. 
4. 
<details><div>
    答え：
説明
医療情報の大規模な結果セットを取得したい企業にとって、BigQuery のようなデータ ウェアハウス ソリューションは理想的です。
BigQuery は、大量のデータを迅速かつ費用対効果の高い方法で保存およびクエリできる、フルマネージドのサーバーレス データ ウェアハウスです。また、データへのSQLベースの容易なアクセスを提供し、アナリストやデータサイエンティストがデータにアクセスできるようにします。大きなクエリをキャッシュするための出力先を設定すると、クエリの繰り返しを回避することで、パフォーマンスの向上とコストの削減にも役立ちます。
オプション A(Cloud SQL を使用)は、このような大規模なデータベースには適していない可能性があります。
オプションC(MySQLクラスタを使用)では、より多くのメンテナンスと管理が必要です。
オプション D(Cloud Spanner を使用)は、このような大規模なデータセットでは費用対効果が高くないため、高いスケーラビリティと強力な整合性が重要な要件でない限り、必要ない場合があります
</div></details>

### Q.質問34: 未回答
Google Cloud でオンライン証券会社の大量の取引処理アーキテクチャの安全なキューイング システムを作成し、リソース使用量を最小限に抑えながら、ジョブがトリガーされ、会社の Python API を介して実行されるようにするにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Pub/Sub プッシュ サブスクリプションを実装して、Python API にデータを渡す Cloud Functions の関数をトリガーします。このオプションを使用すると、ジョブをトリガーする安全で効率的なキューイング システムが可能になり、Pub/Sub プッシュ サブスクリプションがトリガーとして機能します。
その後、Cloud Functions の関数はデータを Python API に渡して取引を実行できます。
このアプローチにより、Compute Engine インスタンスでアプリケーションを作成してホストする必要がなくなり、複雑さとコストが増す可能性のある NoSQL データベースを使用する必要がなくなります。
また、Cloud Composer を使用して Pub/Sub トピックをサブスクライブすることは、主に複雑なワークフローの管理に使用されるツールであるため、このシナリオではやり過ぎかもしれません。
</div></details>

### Q.質問35: 回答
航空宇宙産業の企業は、フライトデータを独自の形式で保存しています。このデータを BigQuery にインポートし、最小限のリソース消費で効率的にストリーミングする必要があります。どのオプションが最適ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
最小限のリソース消費で独自のフライトデータを BigQuery に効率的にインポートするには、オプション D - Apache Beam でカスタム コネクタを使用して、データを Avro 形式で BigQuery にストリーミングする Dataflow パイプラインを作成するのが最適です。オプション D では、Apache Beam でカスタム コネクタを使用して、データを Avro 形式で BigQuery にストリーミングする Dataflow パイプラインを作成します。このオプションは、BigQuery にデータをストリーミングするための高いレベルの柔軟性、効率性、最適化を提供するため、最適です。Apache Beam は、データ パイプラインを構築するための柔軟で強力なフレームワークを提供し、Avro 形式はストリーミング データ用に最適化されており、リソース消費を最小限に抑えるのに役立ちます。
オプション A では、シェル スクリプトを使用して、新しいデータソースで定期的な ETL バッチ ジョブの Cloud Functions の関数をトリガーします。このオプションは、バッチ ジョブがリソースを大量に消費する可能性があり、ETL プロセスの定期的な実行ではフライト データのリアルタイム性に追いつくのに十分ではない可能性があるため、効率が低下し、リソースを大量に消費する可能性があります。
オプション B では、標準の Dataflow パイプラインを使用して生データを BigQuery に保存し、後でデータを使用するときに形式を変換します。このオプションは機能しますが、生データを格納するためにより多くのリソースが必要になる場合があり、データのリアルタイムストリーミングに対してはそれほど効率的ではない可能性があります。
オプション C では、Apache Hive を使用して Dataproc ジョブを作成し、データを CSV 形式で BigQuery にストリーミングします。このオプションは機能しますが、Apache Beam でカスタム コネクタを使用するほど効率的ではなく、CSV 形式がストリーミング用に最適化されていない可能性があります。
</div></details>

### Q.質問36: 回答
あるオンライン小売業者は、顧客サービスを改善するためにチャットボットを実装したいと考えています。チャットボットは、テキストと音声の両方の問い合わせを処理できる必要があり、ローコードまたはノーコードのオプションを使用して、キーワードに基づいて回答を提供するように簡単にトレーニングする必要があります。次のオプションのうち、どれを選択する必要がありますか?
1. 　
2. 
3. 
4. Dialogflowを使用してチャットボットを実装し、もっとも一般的なクエリに基づいてインテントを定義します。
<details><div>
    答え：
説明
Dialogflow は、モバイルアプリ、ウェブ アプリケーション、デバイス、ボット、自動音声応答システムなどに会話型ユーザー インターフェースを簡単に設計して統合できる自然言語理解プラットフォームです。
Dialogflow を使用すると、ユーザーがプロダクトと対話するための新しい魅力的な方法を提供できます。
Dialogflow では、テキスト入力や音声入力(電話や音声録音など)など、顧客からの複数のタイプの入力を分析できます。
また、テキストまたは合成音声のいずれかで、いくつかの方法で顧客に応答することもできます。
参照:https://cloud.google.com/dialogflow/docs
</div></details>

### Q.質問37: 回答
ディープラーニングモデルを使用して、eコマースサイトでの顧客の購買行動を予測しています。評価の結果、モデルが過剰適合していることが示されており、新しいデータで精度を向上させたいと考えています。次のうち、どのアクションを実行する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
参照:https://machinelearningmastery.com/impact-of-dataset-size-on-deep-learning-model-skill-and-performance-estimates/
</div></details>

### Q.質問38: 回答
データ パイプラインの一環として、CSV ファイルを Cloud Storage から BigQuery に読み込みます。ただし、これらのファイルには、データ型の不一致や一貫性のない形式など、既知のデータ品質の問題があります。データ品質が維持され、必要なクレンジングと変換を実行する必要があります。どのアプローチを取るべきですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Data Fusion は、データ パイプラインを迅速に構築して管理するための、フルマネージドのクラウドネイティブなエンタープライズ データ統合サービスです。Cloud Data Fusion ウェブ UI を使用すると、インフラストラクチャを管理することなく、データのクリーニング、準備、ブレンド、転送、変換を行うスケーラブルなデータ統合ソリューションを構築できます
https://cloud.google.com/data-fusion/docs/concepts/overview
GCPに要件を自動化するサービスがある場合、他のオプションを検討することはできません。
</div></details>

### Q.質問39: 未回答
お客様は、転送時間を最小限に抑え、安全な接続のために Google が推奨するベスト プラクティスに従うことを目標に、オンプレミスのデータセンターから Google Cloud に 1 PB のデータを移行する任務を負っています。どのオプションを選択する必要がありますか?
1. Storage Transfer Service は、オンプレミスのデータセンターとGoogleCloudの間にCloudInterconnect接続を確立した後に使用します
2. 
3. 
4. 
<details><div>
    答え：
説明
大量のデータ(1 PB)を数時間で転送するには、パブリック インターネットを使用するよりも高い帯域幅と低遅延を提供できる Cloud Interconnect などの専用ネットワーク接続を使用することをお勧めします。
Storage Transfer Service は、オンプレミスとクラウドストレージ間でデータを転送するために使用でき、Cloud Interconnect をサポートします。このアプローチにより、データ転送が高速、安全、かつ信頼性の高いものになります。
Transfer Appliance を使用するオプション B では、データを手動で処理する必要があり、時間がかかる場合があります。
gcloud compute scp ジョブを使用するオプション C も、時間がかかり、信頼性が低くなる可能性があります。
オプション D では、データを小さなバッチに減らすと、移行プロセスの複雑さが増し、数時間以内にデータを転送するという要件を満たせない可能性があります
</div></details>

### Q.質問40: 未回答
現在、アジアの 1 つの地域の顧客にサービスを提供する Web アプリケーションを実行しています。サービスをグローバルに展開する計画を立てているが、当初はコストを最適化したい。資金を確保したら、ネイティブのJDBCドライバを使用して、グローバルなプレゼンスとパフォーマンスを最適化することを計画しています。どのオプションを選択する必要がありますか?
1. 最初にCloudSpannerの単一リージョンインスタンスを構成し、資金を確保した後に複数リージョンのCloudSpannerインスタンスを構成します
2. 
3. 
4. 
<details><div>
    答え：
説明
このシナリオでは、最初に 1 つのリージョン インスタンスで Cloud Spanner を使用し、資金を確保した後に複数リージョンの Cloud Spanner インスタンスを構成するのが最も費用対効果が高くスケーラブルなオプションです。
Cloud Spanner は、強力な一貫性とスケーラビリティを備えたグローバル分散型リレーショナル データベースです。
単一リージョンのインスタンスから開始し、資金を確保した後に複数リージョンのインスタンスに移行すると、短期的にはコストを最適化しながら、長期的にはグローバルなプレゼンスとパフォーマンスが可能になります。
ネイティブの JDBC ドライバを使用することは、Cloud Spanner でも可能です
</div></details>

### Q.質問41: 未回答
顧客の Google Cloud コンピューティング リソースの正味消費量と、そのリソースを使用したユーザーを示す日次レポートを迅速かつ効率的に生成する必要があります。あなたは何をするべきか?
1. CloudLoggingのデータをBigQueryに毎日エクスポートし、プロジェクト、ログタイプ、リソース、ユーザーでフィルタリングするビューを作成します
2. 
3. 
4. 
<details><div>
    答え：
説明
お客様の Google Cloud コンピューティング リソースの正味消費量とリソースを使用したユーザーを示す日次レポートを生成する最善の方法は、Cloud Logging データを BigQuery に毎日エクスポートし、プロジェクト、ログタイプ、リソース、ユーザーでフィルタリングされたビューを作成することです。
このアプローチでは、データがすでに BigQuery に保存されており、顧客のレポート固有の要件を満たすために簡単にクエリやフィルタリングを行うことができるため、レポートを迅速かつ効率的に生成できます。
さらに、このアプローチにより、Cloud Scheduler や Cloud Functions などのツールを使用して、レポート生成プロセスを簡単に自動化できます。
</div></details>

### Q.質問42: 未回答
Dataflow でバッチ ジョブを開始し、いくつかの要素を処理した後、突然失敗してシャットダウンしました。Dataflow モニタリング インターフェースを調査し、パイプライン内の特定の DoFn に関連するエラーを見つけます。これらのエラーの原因として最も可能性の高いものは次のうちどれですか?
1. 　
2. ワーカーコードのエラー
3. 
4. 
<details><div>
    答え：
説明
いくつかの要素を処理した後、失敗した Dataflow バッチ ジョブの特定の DoFn に関連するエラーの原因として最も可能性が高いのは、
B: ワーカー コードのエラー/例外。
これは、DoFn に記述されたコードに問題があり、例外がスローされて失敗する原因になっていることを意味します。
入力/出力の型が正しくないか、null ポインター例外、またはその他のコーディング エラーが原因である可能性があります。
Dataflow モニタリング インターフェースのエラー メッセージには、エラーの具体的な原因に関する詳細情報が記載されており、問題のデバッグに役立ちます
</div></details>

### Q.質問43: 未回答
BigQuery のストリーミング API を使用するレポート専用データ ウェアハウスで、ステージング テーブルと本番テーブルの両方を使用してデータの読み込みを設計し、マスター データセットを 1 つだけにし、取り込みやレポートのパフォーマンスに影響を与えないようにする最善の方法は何ですか?
1. 　
2. 
3. ステージングされたデータを運用テーブルに移動し、ステージングテーブルの内容を3時間ごとに削除します
4. 
<details><div>
    答え：
説明
最適なアプローチは、ステージングされたデータを運用テーブルに移動し、ステージング テーブルの内容を 3 時間ごとに削除することです (オプション C)。
参照:https://cloud.google.com/blog/products/data-analytics/moving-a-publishing-workflow-to-bigquery-for-new-data-insights
</div></details>

### Q.質問44: 未回答
データ ウェアハウスを Google Cloud に移行し、トランザクション システムからウェアハウスをリアルタイムで更新するためのツールをお勧めできますか?転送されるファイルの数は多くありませんが、各ファイルのサイズは 90 GB です
1. 　
2. 
3. 移行にはgsutilを使用します。Pub/SubとDataflowによるリアルタイム更新
4. 
<details><div>
    答え：
説明
gsutil ツールは、プライベート データセンターから Google Cloud への一般的なエンタープライズ規模のネットワークを介した中小規模の転送(1 TB 未満)のための標準ツールです。
Gsutil は、1 TB 未満のデータについてプロジェクトの期限に間に合うだけの十分な帯域幅がある場合に使用します。
Storage Transfer Service は、移行用のはるかに大きなボリューム用です。
さらに、Cloud Data Fusion と Dataproc はリアルタイムの更新には適していません。BigQuery Data Transfer Service は、すべてのオンプレミス ソースをサポートしているわけではありません。
https://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets#gsutil_for_smaller_transfers_of_on-premises_data
</div></details>

### Q.質問45: 未回答
データ ポイントを受信して GUID を返すサービスを使用して、新しい Web サイト ユーザー向けにグローバル一意識別子 (GUID) を生成するパイプラインを設計する最も効果的な方法は何ですか?パイプラインは、毎秒数万件のメッセージを処理し、システムへのバックプレッシャーを最小限に抑えるためにマルチスレッドにする必要があります。
1. 　
2. 
3. 
4. ジョブを10秒単位でバッチ処理します
<details><div>
    答え：
説明
たとえば、定常状態で毎秒数万件のメッセージを処理するパイプラインを想像してみてください。
要素ごとにコールアウトを行った場合、システムは毎秒同じ数の API 呼び出しを処理する必要があります。
また、呼び出しに平均 1 秒かかると、パイプラインに大きなバックプレッシャーがかかります。
このような状況では、代わりにこれらの要求のバッチ処理を検討する必要があります。
参照:https://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1
</div></details>

### Q.質問46: 未回答
図書館の本や各書籍に関する情報(著者や出版年など)を追跡するアプリケーションをオンプレミスのデータ ウェアハウスから BigQuery に移行する場合、Google が推奨するスキーマ設計のプラクティスに従いながら、借りた各書籍の著者に関するクエリの速度を最適化するには、データをどのように構成すればよいでしょうか。
1. 　
2. 
3. 書籍と著者に関する情報を含むテーブルを作成しますが、著者フィールドは著者列内に入れ子にします
4. 
<details><div>
    答え：
説明
ベスト プラクティス: 入れ子になったフィールドと繰り返しフィールドを使用して、データ ストレージを非正規化し、クエリのパフォーマンスを向上させます。非正規化は、以前に正規化されたリレーショナル データセットの読み取りパフォーマンスを向上させるための一般的な戦略です。
BigQuery でデータを非正規化するには、ネストされたフィールドと繰り返しフィールドを使用することをおすすめします。
この戦略は、リレーションシップが階層的であり、親子関係など、頻繁に一緒にクエリを実行する場合に使用するのが最適です。
参照:https://cloud.google.com/bigquery/docs/best-practices-performance-nested
</div></details>

### Q.質問47: 未回答
Cloud Data Loss Prevention API(DLP API)を使用して、参照整合性を維持しながらリアルタイム ストリーミング ファイルの PII データをマスクするには、どうすればよいでしょうか。
1. 　
2. 
3. 
4. PIIデータを暗号化形式保持トークンに置き換えてかなを作成し、参照整合性を維持します
<details><div>
    答え：
説明
PII データをマスキングしながら参照整合性を維持するために、暗号化形式保持トークンを使用して機密情報を置き換えることができます。この方法では、同じキー値を使用してデータを結合しながら、機密データを権限のない個人から隠すことができます
</div></details>

### Q.質問48: 未回答
圧縮された gzip テキスト ファイルを取り込んで変換し、SideInputs を使用してデータを結合し、配信不能キューにエラーを書き込む Dataflow パイプラインを高速化するにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. パフォーマンスを向上させるには、SideInput をCoGropuByKeyに置き換えます
<details><div>
    答え：
説明
CoGroupByKey トランスフォームは、複数の PCollection オブジェクトをマージ(フラット化)し、共通のキーを持つエレメントをグループ化するコア ビーム トランスフォームです。
サイド入力データ全体を各ワーカーが使用できるようにするサイド入力とは異なり、CoGroupByKey はシャッフル (グループ化) 操作を実行してワーカー間でデータを分散します。
したがって、CoGroupByKey は、結合する PCollection オブジェクトが非常に大きく、ワーカー メモリに収まらない場合に最適です。
CoGroupByKey は、ワーカー メモリを大幅に超える PCollection オブジェクトの大部分をフェッチする必要がある場合に使用します
参照:https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-developing-and-testing#choose_correctly_between_side_inputs_or_cogroupbykey_for_joins
</div></details>

### Q.質問49: 未回答
組織は、Google Cloud で構造化データを処理するためのバッチ パイプラインの最適化を検討しています。現在、データ変換に PySpark を使用していますが、パイプラインの実行に 12 時間以上かかっています。開発とパイプラインの実行時間を短縮するために、SQL 構文をサポートできるサーバーレス ソリューションが必要です。生データはすでに Cloud Storage に保存されています。パフォーマンスと処理の要件を満たしながら Google Cloud でパイプラインを構築するには、どのアプローチを取るべきか
1. 　
2. 
3. CloudStorageからBigQueryにデータを取り込み、PySparkコマンドをBigQuerySQLクエリに変換してデータを変換し、その変換を新しいテーブルに書き込みます
4. 
<details><div>
    答え：
説明
BigQuery は、パフォーマンスと処理の要件を満たすオプションです。
参照:https://medium.com/paypal-tech/comparing-bigquery-processing-and-spark-dataproc-4c90c10e31ac
</div></details>

### Q.質問50: 未回答
5 年分のログデータを Cloud Storage にアップロードしました。ユーザーから、ログデータ内の一部のデータポイントが想定範囲外であり、エラーを示していると報告されました。この問題を修正し、コンプライアンス上の理由から元のデータが保持されるようにする必要があります。あなたは何をするべきか?
1. 　
2. 
3. Dataflowワークフローを使用して、CloudStorageからデータを読み取り、想定される範囲外の値を特定して修正し、更新されたデータをCloudstorageの新しいデータセットに書き込みます
4. 
<details><div>
    答え：
説明
コンプライアンス上の理由から元のデータを保持したままこの問題を解決する最善の方法は、Cloud Storage からデータを読み取り、想定される範囲外の値を特定して修正し、更新されたデータを Cloud Storage の新しいデータセットに書き込む Dataflow ワークフローを使用することです。このアプローチにより、元のデータは保持され、修正されたデータは別々に保存されます。
オプションAは、エラーのある行が削除され、元のデータが失われるため、適切な解決策ではありません。
オプション B は、データが重複し、ストレージ コストが増加するため、お勧めしません。
オプションDは、元のデータセットを上書きすると元のデータが失われることを意味するため、コンプライアンス上の理由から理想的ではないため、適切なアプローチではありません
</div></details>

## 2

### Q. 質問1: 未回答
Cloud Pub/Sub サブスクリプション ソースからのイベントをウィンドウ内で集計し、その結果の集計を Cloud Storage バケットにシンクする Cloud Dataflow ストリーミング パイプラインをモニタリングするように Stackdriver アラートを設定するには、どうすればよいですか?次のアラートのうち、作成する必要があるのはどれですか、また、他のオプションが無効であるのはなぜですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
オプション B は、ソースのサブスクリプション/num_undelivered_messagesの増加は、メッセージがパイプラインによって処理されていないことを示し、目的の動作とは逆であるため、オプション A よりも優れています。
送信先のインスタンス/ストレージ/used_bytesの変更率の低下は、送信先バケットがデータを受信せず、サイズが小さくなっていることを示しており、パイプラインがデータを処理していることを示す良い兆候です。
オプション C は、ソースのインスタンス/ストレージ/used_bytesの減少は、パイプラインがデータを処理しているかどうかを判断するための関連するメトリックではないため、正しくありません。
宛先のサブスクリプション/num_undelivered_messagesの変更率の増加は、メッセージがパイプラインによって処理されていないことを示しており、これは望ましい動作とは逆です。
オプション D は、ソースのインスタンス/ストレージ/used_bytesの増加は、パイプラインがデータを処理しているかどうかを判断するための関連するメトリックではないため、正しくありません。
宛先のサブスクリプション/num_undelivered_messagesの変更率の低下も、パイプラインがデータを処理していないことを示します。
</div></details>

 ### Q. 質問2: 未回答
あなたは、調整可能な期間における特定の会社の平均株価を取得する株式取引データベースとアプリケーションを運用しています。データベースは Cloud Bigtable に保存され、株式取引の日時が行キーの先頭になります。アプリケーションのパフォーマンスは、ストックが追加され、同時ユーザー数が増えるにつれて低下しています。アプリケーションのパフォーマンスを向上させるにはどうすればいいですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
調整可能な期間の平均株価を取得するアプリケーションのパフォーマンスを向上させるには、オプション A を検討する必要があります。
A. Cloud Bigtable テーブルの行キー構文を、株式記号で始まるように変更します。
このオプションが適切な選択である理由は次のとおりです。
データ編成: 行キーの先頭に株式記号を付けてデータを格納することは、特定の株式に関連するデータをクエリする必要がある場合によく使用されます。これにより、特定の銘柄コードのデータを効率的に取得できます。
クエリの最適化: 行キーの先頭に銘柄記号を配置すると、特定の銘柄コードのデータを簡単にフィルタリングして取得できるため、範囲スキャンを効率的に実行できます。
ホットスポットの回避: オプション B では、行キーとして乱数/秒を使用することが提案されています。これにより、データをより均等に分散できますが、特定の株式のデータを取得する必要があるため、ユースケースでは効率的ではない可能性があります。行キーをランダム化すると、ホットスポットが発生し、特定の銘柄コードのデータを効率的に取得することがより困難になる可能性があります。
オプション C と D: これらのオプションでは、それぞれ BigQuery と Cloud Dataflow を使用してデータを保存、処理することを提案しています。これらは特定のユースケースでは強力ですが、複雑さが増すため、Cloud Bigtable が適切に設計された行キーを使用してワークロードを効率的に処理できる場合は、必要ない場合があります。
要約すると、行キーの先頭に株式記号を付けて Cloud Bigtable でデータを整理すると、特に特定の株式のデータを取得する必要がある場合に、アプリケーションのパフォーマンスを向上させるのに役立ちます。
</div></details>

 ### Q. 質問3: 未回答
毎秒 5000,4000 件のメッセージを受信する Apache Kafka ベースの IoT パイプラインを管理しています。<> 時間の移動平均が <> 秒あたり <> メッセージを超えた場合に通知するアラートを設定する必要があります。Google Cloud Platformを使用してどのアプローチを取るべきですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
このシナリオでは、オプション A が最適なアプローチです。
Dataflow と Kafka IO を併用すると、データのストリームを消費し、1 分ごとに 5 時間のスライディング タイムウィンドウを設定して移動平均を計算できます。
ウィンドウが閉じるときに、平均が毎秒 4000 メッセージ未満の場合は、アラートを送信できます。
このアプローチは、受信メッセージレートの変動を検出するのに効率的かつ効果的です。
オプション B、C、D は、より多くのステップを含み、スライディング タイム ウィンドウでの移動平均の計算に最適化されていないため、適していません。
</div></details>

 ### Q. 質問4: 未回答
グローバルな海運会社の従業員は、40 TB のデータでモデルをトレーニングし、各地域のどの船が配送遅延を引き起こす可能性があるかを予測する必要があります。このモデルでは、<> 時間ごとに更新される GeoJSON 形式の位置情報などのテレメトリ データなど、複数のソースから収集されたさまざまな属性が使用されます。予測と地理空間処理のネイティブ機能を備えたストレージソリューションが必要であり、特定の地域で遅延を引き起こす可能性のある船舶を表示するダッシュボードも必要です。ニーズに最適なストレージソリューションはどれですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
BigQuery のようなデータ ウェアハウスでは、位置情報が非常に一般的です。多くの重要なビジネス上の意思決定は、位置データを中心に展開されます。たとえば、配送車両や荷物の緯度と経度を経時的に記録できます。
また、顧客のトランザクションを記録し、店舗の場所データを含む別のテーブルにデータを結合することもできます。
このタイプのロケーションデータを使用して、パッケージがいつ到着する可能性が高いかを判断したり、特定の店舗の場所のメーラーを受け取る顧客を決定したりできます。
地理空間分析では、geography データ型と Google 標準 SQL の geography 関数を使用して、BigQuery の地理空間データを分析、可視化できます。
参照:https://cloud.google.com/bigquery/docs/geospatial-intro
</div></details>

 ### Q. 質問5: 未回答
広告会社の従業員は、広告のクリックスルー率を予測する Spark ML モデルを開発しました。会社が Google Cloud に移行し、データが BigQuery に移行されます。Spark ML モデルは定期的に再トレーニングされるため、既存のトレーニング パイプラインを Google Cloud に移行する必要があります。そのための最善のアプローチは何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
データは BigQuery に移動されているため、Compute Engine の Spark クラスタにデータをエクスポートするのではなく、BigQuery から直接読み取ることをおすすめします。
オプションAは良い選択ですが、従業員はすでにSpark MLを使用しているため、TensorFlowに切り替えるのではなく、それを使い続ける方が良いでしょう。
オプション C では、BigQuery の利点を活用しながら、既存の Spark ML モデルをトレーニングできます。
</div></details>

 ### Q. 質問6: 未回答
入力、出力、中間データの保存に Cloud Storage コネクタを使用するマネージド Hadoop システムで、Cloud Dataproc を使用してディスク I/O を大量に消費する Hadoop ジョブの実行速度が遅い場合、どのように対処すればよいでしょうか。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Hadoopクラスターに十分な永続ディスク領域を割り当て、その特定のHadoopジョブの中間データをネイティブHDFSに保存します。
このオプションは、問題が Cloud Storage コネクタの速度が遅いことや、特定のワークロードに対して最適化されていないことに関連している場合に機能する可能性があります。
中間データをネイティブHDFSに格納することで、ディスクI/Oが削減されるため、ジョブの実行が速くなる可能性があります。
参照:https://cloud.google.com/compute/docs/disks/performance#optimize_disk_performance。https://cloud.google.com/solutions/migration/hadoop/hadoop-gcp-migration-jobs
</div></details>

 ### Q. 質問7: 未回答
複数のユーザーがいる BigQuery データ ウェアハウスで、各チームがチーム メンバーシップに基づいて特定のテーブルのみを表示する場合、ユーザー権限をどのように管理すればよいですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
要件オプションAを達成した場合、私の見解は、オプションDはオプションAよりも絶対確実な方法です。
参照:https://cloud.google.com/bigquery/docs/authorized-views
</div></details>

 ### Q. 質問8: 未回答
運送会社の配送ラインに設置されたカメラを使用して、輸送中の破損した荷物の検出を自動化し、リアルタイムで人間によるレビューのためにフラグを立てるための最良のソリューションは何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
AutoML は、モデルのトレーニングと損傷検出に使用されます
Auto Visionは、画像内のオブジェクトを検出するために使用される事前トレーニング済みのモデルです
</div></details>

 ### Q. 質問9: 未回答
特定の順序で実行される相互依存ステップを持ち、シェル スクリプト、Hadoop ジョブ、BigQuery クエリの実行を伴う複数のバッチ ジョブを管理するには、どのサービスを使用する必要がありますか?これらのジョブは、数分から数時間まで実行されることが予想され、手順が失敗した場合は、一定回数再試行する必要があります。正しいオプションを選択してください
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
オプション D(Cloud Composer)は、
依存関係と再試行を持つ複数のタスクで構成される複雑なワークフローを定義、スケジュール、および監視できる、完全に管理されたワークフロー オーケストレーション サービス。
これは、シェル スクリプト、Hadoop ジョブ、BigQuery クエリの実行を含む多くの相互依存ステップを含むバッチ ジョブの実行を管理するのに適したオプションであり、失敗したタスクを一定回数再試行できます
オプション A(Cloud Scheduler)は、Cloud Pub/Sub、Cloud Functions、または HTTP ターゲットを使用してバッチ ジョブをスケジュールして実行できる、フルマネージドの cron ジョブ サービスです。ただし、バッチ・ジョブ内の相互依存ステップの依存関係と順序を管理する機能は提供されません。
オプション B(Cloud Dataflow)は、大規模なデータセットの処理を並列化する ETL およびデータ処理パイプラインを実行するためのフルマネージド サービスです。再試行はサポートされていますが、相互依存するステップの依存関係と順序を管理する方法は提供されません。
オプション C(Cloud Functions)は、Cloud Storage 内のデータの変更や Pub/Sub 内のメッセージなどのイベントに応答してコードを実行することができるサーバーレス コンピューティング プラットフォームです。これは、相互に依存する複雑な一連のステップの管理には適していません。
</div></details>

 ### Q. 質問10: 未回答
ORC データ形式とプライマリ ツールとして Hive を使用するオンプレミスの Hadoop システムを Cloud Dataproc に移行します。すべての ORC ファイルを Cloud Storage バケットに正常にコピーしたので、パフォーマンスを向上させるために、一部のデータをクラスタのローカルの Hadoop Distributed File System(HDFS)に複製する必要があります。
Cloud Dataproc で Hive を使い始めるには、次の 2 つの方法のうちどれですか?2つ選択してください
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
オプションCは有効な解決策ですが、ファイルを手動でHDFSにコピーするなど、回避できる追加の手順が必要です。
オプション D は、Cloud Storage Connector for Hadoop を利用して ORC ファイルを外部 Hive テーブルとしてマウントし、外部 Hive テーブルをネイティブ Hive テーブルに複製して、効率的なデータ アクセスとレプリケーションを可能にするため、有効なソリューションです。
オプションAは、すべてのORCファイルをHDFSにコピーすることを提案しているため、最も効率的なソリューションではない可能性があるため、正しくありません。また、Hive テーブルをローカルにマウントすることは、Dataproc の分散性を活かさないため、最適な選択肢ではない可能性があります。
オプション B は、すべての ORC ファイルをクラスター内の任意のノードにコピーすると、データ スキューやネットワークの輻輳が発生する可能性があるため、理想的ではありません。また、HDFSにデータをレプリケートする方法についても説明していません。
オプション E は BigQuery に ORC ファイルを読み込むため、この問題の直接的な解決策にはなりませんが、このユースケースでは望ましいデータ ストレージ ソリューションではない可能性があります。
</div></details>

 ### Q. 質問11: 未回答
サードパーティから受け取った毎月のCSVデータファイルのスキーマが3か月ごとに変更される場合、どのようにクレンジングできますか?これらの変換を実装するための要件には、開発者以外のアナリストが変換を変更できるようにすること、変換を設計するためのグラフィカル ツールを提供すること、およびスケジュールに従って変換を実行することが含まれます
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Dataprep by Trifacta を使用して、変換レシピを構築および管理し、スケジュールに基づいて実行します。
Dataprep by Trifacta は、変換を設計するためのグラフィカル ツールを提供し、開発者以外のアナリストが変換を変更できるようにします。また、スケジュールに従って変換を実行することもできます
</div></details>

 ### Q. 質問12: 未回答
2 PB の履歴データをオンプレミスのストレージ アプライアンスから Cloud Storage に 20 か月以内に移行する必要があります。送信ネットワーク容量は <> Mb/秒に制限されています。この移行をどのように実行する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Transfer Appliance を使用して Cloud Storage にデータをコピーする
</div></details>

 ### Q. 質問13: 未回答
実行中の Cloud Dataflow パイプラインを新しいバージョンに更新し、データが失われないようにするには、どのような対策を講じる必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
このシナリオでは、パイプラインはウィンドウ処理アルゴリズムを使用してストリーミングパイプラインであり、データを失うことなく新しいアルゴリズムへの戦略変更をトリガーするため、シナリオで説明されているすべての前提条件を満たすため、ドレインオプションを使用することをお勧めします。
1.ストリーミング
2.ウィンドウアルゴリズムとトリガー戦略によるコードの変更を新しい方法に
3.更新中にデータが失われない
参照:https://cloud.google.com/dataflow/docs/guides/stopping-a-pipeline#drain
</div></details>

 ### Q. 質問14: 未回答
各分析チームがそれぞれのプロジェクト内の BigQuery スロットの使用状況をモニタリングできるようにするには、どうすればよいでしょうか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
正解はBです。
BigQuery のスロット数 / allocated_for_projectに基づいて Cloud Monitoring ダッシュボードを作成します。
このオプションを使用すると、各チームはプロジェクトに割り当てられたスロットの数と、現在使用されているスロットの数を監視して、現在および過去の使用状況を可視化できます。
参照:https://cloud.google.com/bigquery/docs/reservations-monitoring#viewing-slot-usage
オプションAは、スロットの使用状況ではなくデータ量を監視するため、正しくありません。
オプション C は、プロジェクトごとにカスタム メトリックを作成する必要があり、メトリックの数が多くなる可能性があるため、非効率的です。
また、オプション D は非効率的であり、大量のログがエクスポートされる可能性があるため、各プロジェクトのスロット使用量を個別に監視することが困難になります
</div></details>

 ### Q. 質問15: 未回答
組織では、すべての BigQuery データアクセスログを 6 か月間保持する必要があります。社内のデータアナリストには、プロジェクト内で Cloud IAM オーナーのロールが割り当てられており、プロジェクト内で複数の GCP プロダクトを操作できます。社内の監査担当者のみがすべてのプロジェクトのデータアクセスログにアクセスできるようにする必要があります。次のオプションのうち、どれを選択する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
集約されたログシンクは、すべてのプロジェクトに対して 1 つのシンクを作成し、宛先は Google Cloud Storage、Pub/Sub トピック、BigQuery テーブル、または Cloud Logging バケットにすることができます。
集約シンクがないと、これはプロジェクトごとに個別に行う必要があり、面倒になります
参照:https://cloud.google.com/logging/docs/export/aggregated_sinks
</div></details>

 ### Q. 質問16: 未回答
商品の売上データを格納する Cloud Spanner の新しいトランザクション テーブルで、パフォーマンスを考慮して最適な主キー戦略は何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
参照:https://cloud.google.com/spanner/docs/schema-design
</div></details>

 ### Q. 質問17: 未回答
既存のアプリケーションに悪影響を与えることなく、ジョブジェネレーターとジョブランナーの間でデータを共有するスケーラブルなデータパイプラインを構築するのに最適なソリューションはどれですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Cloud Pub/Sub トピックの使用は、ジョブジェネレーターとジョブランナー間のデータを管理するためのスケーラビリティを必要とするデータ パイプラインにとって、より適切なソリューションです。
Cloud Pub/Sub は、高スループットのデータを処理できるメッセージング サービスであり、幅広い公開方法とサブスクリプション方法をサポートしています。
Cloud Pub/Sub トピックを使用すると、既存のアプリケーションに悪影響を与えることなく、ジョブ情報を公開し、サブスクライバーが必要に応じてジョブ情報を実行できます。
オプション A は有効な解決策である可能性がありますが、App Engine には一定の制限があるため、スケーリングに関しては最適な選択ではない可能性があります。
オプション C は、Cloud SQL テーブルで大量のデータを処理できず、既存のアプリケーションに悪影響を及ぼす可能性があるため、おすすめしません。
オプション D は実行可能なオプションですが、この特定のユースケースでは Cloud Spanner のようなグローバルに分散されたデータベースを使用する必要がない場合があります。
</div></details>

 ### Q. 質問18: 未回答
特定のスケジュールで Cloud Dataproc クラスタで実行される複数の Spark ジョブがある。順番に実行されるジョブもあれば、同時に実行されるジョブもあります。このプロセスを自動化する必要があります。これを実現するには、どのオプションが最適ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
1)Spark PI ジョブを実行する Dataproc ワークフロー テンプレートを作成する
2)Cloud Composer が特定の時間にワークフローを開始するために使用する Apache Airflow DAG を作成します。
参照:https://cloud.google.com/dataproc/docs/tutorials/workflow-composer
</div></details>

 ### Q. 質問19: 未回答
時系列指標を Bigtable に書き込む Dataflow パイプラインがあります。ただし、数千人の同時ユーザーを含むダッシュボードにフィードするために使用される Bigtable では、データの更新に時間がかかることに気付きました。データの書き込みにかかる時間を短縮しながら、より多くの同時ユーザーをサポートする必要があります。取るべき2つの行動とは?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
パイプラインのパフォーマンスを向上させ、Bigtable へのデータ書き込みにかかる時間を短縮するために実行する 2 つのアクションは、B と C です。
PipelineOptions で maxNumWorkers を設定してワーカーの最大数を増やすと、より多くのワーカーにワークロードを分散することで、パイプラインでデータをより高速に処理できます。
Bigtable クラスタのノード数を増やすと、より多くの同時ユーザーを処理し、データの保存と取得の容量を増やすことができます。
ローカル実行の使用はパイプラインをローカルでテストする場合にのみ役立ちますが、大量のデータを処理するためのパフォーマンスは向上しないため、A は正しくありません。
D と E は、Flatten 変換と CoGroupByKey 変換が Bigtable へのデータ書き込みのパフォーマンスを向上させるように設計されていないため、正しくありません。
</div></details>

 ### Q. 質問20: 未回答
Dataflow を使用して Pub/Sub トピックのデータを処理し、EU にある BigQuery データセットに書き込みます。ただし、ピーク時には、1 つの n1-standard-<> ワーカーすべてが最大 CPU 使用率に達しているため、パイプラインで遅延が発生します。パイプラインのパフォーマンスを向上させるために実行できる <> つのアクションはどれですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
A: ワーカーの最大数を増やすと、ワークロードを分散し、CPU 使用率がボトルネックになるのを防ぐことができます。
B: Dataflow ワーカーにより大きなインスタンスタイプを使用すると、増加したワークロードを処理するために、より多くの CPU とメモリ リソースを提供することもできます。
C: Dataflow パイプラインのゾーンを us-central1 に変更すると、ネットワーク レイテンシが増加し、オーバーヘッドが増える可能性があるため、効果的でない場合があります。
D と E: Bigtable または Cloud Spanner で一時バッファ テーブルを作成すると、パイプラインのパフォーマンスが向上する可能性がありますが、複雑さとオーバーヘッドが増す可能性もあります。これらのオプションは、ワーカーを増やしたり、より大きなインスタンスタイプを使用しても十分な改善が得られない場合は、検討する必要があります
</div></details>

 ### Q. 質問21: 未回答
あなたは、年末までに 150 日あたり約 2 GB の JSON データを生成すると予想され、継続的に到着するデータのスケーラブルなコレクションを必要とする新しいアプリケーションを構築する任務を負っています。要件には、プロデューサーとコンシューマーの分離、無期限に保存する必要がある生の取り込みデータのコスト効率の高いストレージ、ほぼリアルタイムの SQL クエリ機能、SQL でクエリされる少なくとも <> 年間の履歴データの維持が含まれます。これらの要件を満たすには、どのパイプラインを使用する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Cloud Pub/Sub にイベントを発行するアプリケーションを作成し、JSON イベント ペイロードを Avro に変換して Cloud Storage と BigQuery にデータを書き込む Cloud Dataflow パイプラインを作成します。
このオプションでは、Cloud Pub/Sub を使用してプロデューサーをコンシューマから切り離し、ダウンストリーム プロセスを中断することなく、アプリケーションが継続的にデータを生成できるようにします。
その後、JSON データは Cloud Dataflow パイプラインを使用して Avro に変換され、ほぼリアルタイムでデータを処理できます。
変換されたデータは Cloud Storage と BigQuery の両方に書き込まれるため、データはコスト効率よく保存され、SQL でクエリできるようになります。
また、Cloud Storage と BigQuery はどちらも大量のデータを長期間処理するように設計されているため、このパイプラインは少なくとも 2 年分の履歴データを保持するという要件を満たしています。
</div></details>

 ### Q. 質問22: 未回答
アプリケーションは、リアルタイムのイベントストリーム、ANSI SQLを介したリアルタイムデータと履歴データへのアクセス、およびバッチ履歴エクスポートを受信する消費者と金融市場データを共有する必要があります。データは市場からリアルタイムで収集されます。どのソリューションを使用する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
アプリケーションの要件を満たすには、3つの異なるサービスの組み合わせが必要です。
まず、リアルタイム イベント ストリームは、大量のデータ ストリームを低レイテンシで処理できる Cloud Pub/Sub などのサービスで処理する必要があります。
第 2 に、ANSI SQL からリアルタイム ストリームや履歴データへのアクセスを提供するには、ユーザーが ANSI SQL を使用してリアルタイムでデータをクエリできるため、BigQuery のようなサービスが理想的です。
最後に、履歴の一括エクスポートを提供するには、ユーザーが履歴データにバッチでアクセスできる Cloud Storage などのストレージ サービスが必要です
</div></details>

 ### Q. 質問23: 未回答
データ サイエンティストが BigQuery ML モデルを作成し、REST API アプリケーションに予測を提供する ML パイプラインを構築したいと考えています。APIは、100ミリ秒未満のレイテンシーで個々のユーザーIDの予測を提供する必要があります。次のクエリは、予測を生成します: SELECT predicted_label、user_id FROM ML.PREDICT (MODEL 'dataset.model', table user_features)。ML パイプラインを構築するには、どのアプローチを取る必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
正しいアプローチは、クエリに WHERE 句を追加してユーザー ID で結果をフィルタリングし、アプリケーション サービス アカウントに BigQuery データ閲覧者ロールを付与することです。このアプローチにより、REST API アプリケーションは必要な予測のみを受信し、待機時間の要件を満たすことができます。
その他のオプションは、次の理由で無効です。
B. 指定されたクエリを使用して承認済みビューを作成し、そのビューを含むデータセットをアプリケーション サービス アカウントと共有することは、ビューへのアクセスのオーバーヘッドにより待機時間が 100 ミリ秒を超える可能性があるため、最適なソリューションではありません。
C. BigQueryIO を使用して Dataflow パイプラインを作成し、クエリから結果を読み取り、Dataflow Worker ロールをアプリケーション サービス アカウントに付与する場合は、クエリ結果を操作または変換する必要がないため、必要ありません。
D. BigQueryIO を使用して Dataflow パイプラインを作成し、クエリからすべてのユーザーの予測を読み取り、BigtableIO を使用して結果を Bigtable に書き込み、アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与することは、個々のユーザーの予測を Bigtable に保存する必要がなく、この方法では不要なレイテンシが追加される可能性があるため、必要ありません。
</div></details>

 ### Q. 質問24: 未回答
米国に拠点を置く会社は、ユーザーのアクションを分析して応答するためのアプリケーションを開発しました。アプリケーションのプライマリテーブルには、毎秒 200,000 レコードずつ増加するデータ量があります。多くのサードパーティ開発者は、アプリケーションの API を使用して、その機能を独自のフロントエンド アプリケーションに統合します。API は、1)単一のグローバル エンドポイントを提供する (2)ANSI SQL をサポートする (3)最新のデータへの一貫したアクセスを確保するという要件を満たす必要があります。次のオプションのうち、どれを選択する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
プライマリ テーブルのデータ量が毎秒 250,000 レコード増加することを考えると、アプリケーションにはスケーラブルで分散されたデータベース ソリューションが必要です。
Cloud Spanner は、このようなワークロードを処理できる、グローバルに分散され、水平方向にスケーラブルで、強力な一貫性を持つリレーショナル データベース サービスです。
また、単一のグローバル エンドポイントを提供し、ANSI SQL をサポートし、最新のデータへの一貫したアクセスを保証します。
さらに、読み取り専用レプリカがアジアとヨーロッパにあるため、APIユーザーは低遅延でデータにアクセスできます
</div></details>

 ### Q. 質問25: 未回答
組織では Google Cloud Platform の利用が拡大しており、多くのチームがデプロイのさまざまな段階や対象ユーザー向けに独自のプロジェクトを作成しています。各プロジェクトには固有のアクセス制御構成が必要であり、中央の IT チームはすべてのプロジェクトにアクセスする必要があります。また、Cloud Storage と BigQuery のデータは、必要に応じてプロジェクト間で共有する必要があります。アクセス制御管理を簡素化し、ポリシーの数を最小限に抑えるには、どのような手順を実行する必要がありますか?2つ選んでください。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
オプション B では、アクセス制御の継承を提供し、必要なポリシーの数を減らすリソース階層を実装できます。
オプション E では、特定の Cloud Storage バケットまたは BigQuery データセットへのアクセスを必要とするプロジェクトごとに Cloud IAM ポリシーを作成することで、ポリシーの管理が簡素化され、必要なプロジェクトのみがデータにアクセスできるようになります。
無効なオプション:-
オプション A は、アクセス プロビジョニングを自動化し、必ずしもポリシーの数を減らすわけではないため、アクセス制御管理を簡素化し、ポリシーの数を最小限に抑えるための有効なソリューションではありません。
オプション C では、チームごとにポリシーが作成され、アクセス コントロール ポリシーの管理は簡素化されません。
オプションDは、プロジェクト間のデータ共有をサービスアカウントのみに制限しますが、これは過度に制限される可能性があり、データ共有が必要なすべてのユースケースに対応できない可能性があります。
</div></details>

 ### Q. 質問26: 未回答
BigQuery で 1 万件のレコードを含む CSV を更新するときに quotaExceeded エラーを解決するには、どうすればよいですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
オプション D は有効なアプローチです。
新しいレコードを新しい BigQuery テーブルにインポートし、レコードをマージするジョブを作成すると、 quotaExceeded エラーを回避し、更新プロセスをより詳細に制御できます。
これは、更新を頻繁に実行する必要があり、プロセスをより柔軟に制御する必要がある場合に適したソリューションです
</div></details>

 ### Q. 質問27: 未回答
分析プラットフォーム用のデータ パイプラインを BigQuery で管理し、新しいデータを毎日読み込み、ETL パイプラインを使用して変換します。ETL パイプラインは頻繁に更新され、最大 2 週間検出されないエラーが発生する可能性があります。このようなエラーから回復し、バックアップのストレージコストを最適化できるようにする必要があります。どのアプローチを取るべきですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
月ごとに個別のテーブルを作成することで、エラーが発生した場合に特定の期間のデータを簡単に識別して回復できます。
Cloud Storage でデータをエクスポート、圧縮、保存することで、ストレージ費用を最適化できます。
データを別のデータセットに複製したり、すべてのデータを 1 つのテーブルに格納したりすると、ストレージ コストがすぐに増加し、エラーが発生した場所を特定するのが困難になる可能性があります。
スナップショット デコレーターを使用すると、テーブルを以前の状態に復元できますが、コストがかかる場合があり、通常は長期的なバックアップではなく短期的な回復に使用されます
</div></details>

 ### Q. 質問28: 未回答
自然言語処理領域の回帰問題に取り組んでおり、100 億個のラベル付き例のデータセットを使用しています。データセットをトレーニング サンプルとテスト サンプル (90/10) にランダムに分割し、ニューラル ネットワークをトレーニングし、モデルを評価した後、トレーニング セットの二乗平均平方根誤差 (RMSE) がテスト セットと比較して <> 倍高いことに気付きます。モデルのパフォーマンスを向上させる最善の方法は何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
ドロップアウトやバッチ正規化などの正則化手法は、テスト セットと比較してトレーニング セットの RMSE が高くなる原因となる可能性のある過学習の防止に役立ちます。
ドロップアウト、バッチ正規化、またはその他の正則化手法をモデルに導入することで、モデルがトレーニング データを記憶して過学習するのを防ぐことができます。
トレーニングとテストの分割 (オプション A) でテスト サンプルの割合を増やすと、トレーニング セットが小さくなり、学習不足につながる可能性があるため、効果的ではない可能性があります。
より多くのデータを収集すること(オプションB)は役に立ちますが、多くの場合、コストと時間がかかります。
モデルの複雑さを増すと (オプション D)、過学習がさらに悪化し、トレーニング時間が長くなる可能性があります。
したがって、正則化手法 (オプション C) は、このシナリオで最も効果的なソリューションです。
</div></details>

 ### Q. 質問29: 未回答
あなたは、画像認識領域のニッチな製品に取り組んでいるチームの一員です。あなたのチームは、かさばる行列の乗算を実行するためにカスタム C++ TensorFlow 演算に大きく依存するモデルを開発しました。その結果、モデルのトレーニングに数日かかるため、Google Cloud でアクセラレータを使用することで、この時間を短縮し、コストを低く抑えたいと考えています。あなたは何をするべきか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
参照:https://cloud.google.com/tpu/docs/tpus#when_to_use_tpus
</div></details>

 ### Q. 質問30: 未回答
750 のサプライヤーから 750 種類のコンポーネントを調達する製造会社の従業員は、各固有のコンポーネントの約 1000 個の例を含むラベル付きデータセットを持っています。チームは、倉庫作業員が入荷したコンポーネントの写真を分析して識別するのに役立つアプリを作成したいと考えています。このアプリの概念実証は、数営業日以内に作成する必要があります。どのアプローチを取るべきですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
同社には多数の一意のコンポーネント(750)と各コンポーネントの1000,<>個の例があり、アプリの実用的な概念実証を数日で作成することが目標であることを考えると、既存のデータセットでCloud Vision AutoMLを使用するのが最も実用的で効率的なオプションです。
Cloud Vision AutoMLは、Google Cloudが提供する機械学習ツールで、ユーザーは画像認識用のカスタムモデルをトレーニングできます。
既存のラベル付きデータセットがあれば、Cloud Vision AutoMLを使用して画像認識モデルを迅速にトレーニングできます。
オプション B は、データセットのサイズを小さくすると、モデルをトレーニングするデータが少なくなり、精度が低下する可能性があるため、理想的なアプローチではありません。
オプション C は、認識のヒントとしてカスタム ラベルに依存しており、すべてのコンポーネントに正確または関連性がない可能性があるため、最適なアプローチではありません。
オプションDでは、転移学習技術を使用してモデルをトレーニングするのにより多くの時間が必要であり、数営業日以内に実用的な概念実証を作成することは不可能です。
</div></details>

 ### Q. 質問31: 未回答
Google Cloud でペタバイト規模の分析データ用のストレージと処理プラットフォームを設計し、データに対してデータ ウェアハウス スタイルの分析を実行し、データセットを他のクラウド プロバイダのバッチ分析ツール用のファイルとして公開するには、どうすればよいでしょうか。次の中から最適なオプションを選択してください。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
このシナリオに最適なオプションは、オプション C: データセット全体を BigQuery に保存し、データの圧縮コピーを Cloud Storage バケットに保存することです。このオプションを使用すると、大規模なデータセットの処理や複雑なクエリの実行に最適化された BigQuery のデータセット全体に対して、データ ウェアハウス スタイルの分析が可能になります。さらに、バッチ分析ツールを他のクラウドプロバイダーに保存します。
オプション A(データセット全体を BigQuery に保存して処理する)は、小規模なデータセットでは実現可能ですが、ペタバイト規模のデータでは、BigQuery だけですべてを処理するのは費用対効果が高くなく、実用的ではない可能性があります。
オプション B(データセット全体を Bigtable に保存して処理する)は、リアルタイムのデータ処理に適している可能性がありますが、複雑な分析クエリには最適化されていません。
オプション D(ウォームデータをファイルとして Cloud Storage に保存し、アクティブデータを BigQuery に保存する)は、アクティビティのレベルが異なるデータセットには適していますが、データセット全体に対してデータ ウェアハウス スタイルの分析を実行する必要性には対応していません。
</div></details>

 ### Q. 質問32: 未回答
CSV、Avro、PDF 形式のデータに対して、Dataproc、BigQuery、Compute Engine などの複数の分析ツールからアクセスできる必要があるクラウドネイティブの履歴データ処理システムのデータ ストレージをどのように設計すればよいでしょうか?ソリューションでは可用性を最大化する必要がありますが、パフォーマンスは要因ではなく、バッチ パイプラインは毎日のデータを移動します。データストレージにはどのオプションを選択する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
マルチリージョンの Cloud Storage バケットにデータを保存し、Dataproc、BigQuery、Compute Engine を使用して直接アクセスします。このオプションは、可用性を最大化し、必要なすべての解析ツールから直接アクセスできるため、最良の選択です。
マルチリージョンの Cloud Storage バケットにデータを保存することで、高可用性が確保され、複数のリージョン間でデータの冗長性が確保されます。
オプション A は、高可用性を備えた Dataproc クラスタを作成し、データを HDFS に保存するものですが、複数リージョンの Cloud Storage バケットにデータを保存する場合に比べてコストがかかり、セットアップが複雑になるため、最適な選択ではありません。
オプション B の BigQuery にデータを保存し、Dataproc と Compute Engine の BigQuery コネクタを使用してアクセスする方法は、PDF 形式の非構造化データの処理には適していない可能性があるため、最適な選択ではありません。
オプション C は、データをリージョンの Cloud Storage バケットに保存し、Dataproc、BigQuery、Compute Engine を使用して直接アクセスする方法ですが、複数のリージョン間でデータの冗長性が得られず、リージョンの障害が発生した場合に可用性に影響を与える可能性があるため、最適な選択肢ではありません
</div></details>

 ### Q. 質問33: 未回答
1 日あたり 5 TB ずつ増加する 3.<> PB の時系列トランザクション・データ・セット用のデータ・パイプラインを作成する任務を負っています。目標は、データを BigQuery にコピーして、データ サイエンス チームが分析し、このデータに基づいて機械学習モデルを構築することです。データは構造化され、毎時新しいステータスで更新されます。データサイエンスチームのパフォーマンスとユーザビリティを最大化するには、どの<>つの戦略を採用する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
A: 大規模なテーブルで JOIN を実行すると BigQuery のパフォーマンスが低下するため、非正規化により数十億行のテーブルのクエリ速度が向上しますが、非正規化されたデータ構造では、すべてのデータが 1 つのテーブルに結合されているため、JOIN を使用する必要はありません。また、非正規化により、JOIN 句を使用する必要がないため、クエリが簡単になります。
https://cloud.google.com/solutions/bigquery-data-warehouse#denormalizing_data
D: BigQuery の追加
</div></details>

 ### Q. 質問34: 未回答
お客様は、Cloud Datastore を使用して車両のテレメトリ データをリアルタイムで取り込むストレージ システムを構築すると同時に、システムが長期的なデータ増加に対応し、費用対効果が高いことを確認する必要があります。さらに、データのスナップショットを定期的に作成して、ポイントインタイムリカバリやデータのコピーを別の環境に複製できるようにする必要があります。これらのスナップショットを長期間アーカイブする場合。これを実現できる2つの方法はどれですか?次のオプションから 2 つ選択します。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
費用を低く抑えながら、Cloud Datastore を使用して車両のテレメトリ データをリアルタイムで取り込み、アーカイブし、ポイントインタイム リカバリやクローン作成のための定期的なスナップショットを作成できる 2 つの方法は、A と B です
</div></details>

 ### Q. 質問35: 未回答
あなたは、IoTデバイスからグローバルにメッセージを取り込むシステムを担当しています。現在、すべてのメッセージは、us-east リージョンにある 1 つのオンプレミス Kafka クラスターによって取り込まれます。ただし、バッチ処理されたメッセージによってメッセージ量が散発的に急増するため、管理が困難になり、コストがかかるようになりました。このシナリオでは、どの Google Cloud アーキテクチャが推奨されますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
オプション C: メッセージ量の散発的な急増によって引き起こされる課題を回避しながら、IoT デバイスからメッセージをグローバルに取り込むために推奨される Google Cloud アーキテクチャは、オプション C: IoT ゲートウェイを Cloud Pub/Sub に接続し、Cloud Dataflow を使用してメッセージを処理することです。
このアーキテクチャにより、IoT ゲートウェイは IoT デバイスからのメッセージをバッチ処理して Cloud Pub/Sub に送信し、Cloud Pub/Sub は受信負荷を処理するようにスケーリングできます。その後、Cloud Dataflow は Cloud Pub/Sub からのメッセージを処理できるため、受信メッセージを処理するためのスケーラブルなマネージド ソリューションが提供されます。
オプション A では、メッセージを保存および送信するためのセンサー デバイスとしてエッジ TPU を使用しますが、エッジにデータを格納する必要があり、長期的には適切にスケーリングされない可能性があるため、お勧めしません。
オプション B の Cloud Dataflow を Kafka クラスタに接続してメッセージ処理をスケーリングしても、Kafka クラスタはメッセージ量の処理に苦労する可能性があるため、メッセージ量の急増によって引き起こされる問題は解決しない可能性があります。
オプション D の米国東部の Compute Engine で Kafka クラスタを仮想化し、Cloud Load Balancing を使用して世界中の IoT デバイスに接続する方法は、Cloud Pub/Sub や Cloud Dataflow を使用する場合ほどスケーラブルで費用対効果が高くない可能性があります。
さらに、Kafkaクラスターはメッセージ量の処理に引き続き問題に直面する可能性があるため、メッセージ量の急増によって引き起こされる問題は解決されない可能性があります。
</div></details>

 ### Q. 質問36: 未回答
次の要件を遵守しながら、社内のさまざまな部門に対して BigQuery データへのアクセスを設定するにはどうすればよいでしょうか?
1.各部門は、自分のデータにのみアクセスできるようにする必要があります。
2.各部門には、チームのテーブルを作成および更新できる <> 人以上のリードがいます。
3.各部門にはデータアナリストがおり、データのクエリはできますが、変更することはできません。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
「OWNER」、「WRITER」、「READER」は、IAMロールが登場する前のGoogleの「プリミティブロール」であり、Big Queryの「データセット」レベルで適用できます。
Big Query は、「プロジェクト」レベルでの IAM ロール (VIEWER、EDITER、OWNER) をサポートするようになりました。
質問は「部門レベル」での権限を求めているため、オプションCとDは「テーブル」レベルに付与されているため除外されます。
オプションAとBの間では、データセットレベルでプリミティブロールを付与していると仮定して、Bが正しいように見えます。
参考:https://cloud.google.com/bigquery/docs/access-control-basic-roles#dataset-primitive-roles
</div></details>

 ### Q. 質問37: 未回答
負荷の増加に応じて自動的にスケーリングし、メッセージを少なくとも 1 回処理し、<> 時間以内にメッセージの順序を維持するデータ処理パイプラインをどのように設計しますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Cloud Dataproc はストリーミング分析には適しておらず、バッチ処理に適しているため、オプション A は正しくありません。
メッセージの取り込みには Apache Kafka を使用できるため、オプション B も考えられますが、自動的にスケーリングできる Cloud Dataflow の方がストリーミング分析に適しています。
Cloud Pub/Sub はメッセージの取り込みに使用できますが、Cloud Dataproc はストリーミング分析には適していないため、オプション C は正しくありません。
オプション D: Cloud Pub/Sub は、メッセージの取り込みを可能にするマネージド メッセージング サービスです。
高スループットを処理するように自動的にスケーリングされ、メッセージは順序どおりに配信できます。これは、少なくとも 1 回、<> 時間以内にメッセージを処理するという要件を満たしています。
Cloud Dataflow は、バッチ処理パイプラインとストリーミング データ処理パイプラインを実行するためのフルマネージド サービスです。大量のデータのリアルタイム処理を処理でき、自動的にスケールアップまたはスケールダウンできます
</div></details>

 ### Q. 質問38: 未回答
オンプレミスのデータウェアハウス ソリューションを BigQuery に移行して CDC のパフォーマンスを最適化し、コンピューティングのオーバーヘッドを削減しながら、ソース システムへの変更を BigQuery レポートの表でほぼリアルタイムで利用できるようにするための 2 つの推奨手順は何ですか?(2つ選択してください。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
差分テーブルには、初期読み込み以降の特定のテーブルのすべての変更イベントが含まれます。すべての変更イベントを使用可能にしておくと、傾向、特定の瞬間にテーブルが表すエンティティの状態、または変更頻度を特定するのに役立ちます。
データを頻繁かつ一貫してマージする最善の方法は、複数の INSERT、UPDATE、および DELETE ステートメントを 1 つのアトミック操作に結合できる MERGE ステートメントを使用することです
参照:https://cloud.google.com/architecture/database-replication-to-bigquery-using-change-data-capture#overview_of_cdc_data_replication
</div></details>

 ### Q. 質問39: 未回答
BigQuery データセットを費用対効果の高い方法でサードパーティ企業と共有しながら、データを常に最新の状態に保つにはどうすればよいでしょうか。次のオプションを検討してください。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Analytics Hub では、BigQuery の特定のデータセット、ビュー、テーブルに対するアクセス ポリシーと権限を定義できます。
これにより、特定のユーザーまたはグループへのアクセスを制限し、IPアドレスやユーザーIDなどの要因に基づいてきめ細かなアクセス制御を設定できます。
Analytics Hub を使用することで、サードパーティ企業が必要な特定のデータにのみアクセスできるようにし、データアクセスを監視および監査して、規制やセキュリティのベストプラクティスへのコンプライアンスを維持することもできます。
参照:https://cloud.google.com/bigquery/docs/analytics-hub-introduction
</div></details>

 ### Q. 質問40: 未回答
企業がハイブリッドクラウド戦略と、異なるクラウドプロバイダー間でデータを移動し、そのサービスを活用する複雑なデータパイプラインを持っている場合、パイプライン全体を調整するには、どのクラウドネイティブサービスが最適なオプションでしょうか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
与えられた4つのオプションのうち、
Cloud Composer は、パイプライン全体を調整するのに最も適したクラウドネイティブ サービスです。
Cloud Composer は、ユーザーがさまざまなクラウド サービスやオンプレミス リソースでワークフローを作成、スケジュール、監視できる、フルマネージドのワークフロー オーケストレーション サービスです。
Amazon Web Services、Google Cloud Platform、Microsoft Azureなど、さまざまなクラウドプロバイダーへの幅広い事前構築済みコネクタを提供するため、ハイブリッドクラウド戦略を持つ企業にとって理想的な選択肢となります。
さらに、ワークフローを構築および監視するためのユーザーフレンドリーなインターフェイスを提供し、Apache AirflowとKubernetesの両方をサポートしているため、ユーザーは好みのワークフロー管理ツールを柔軟に選択できます。
一方、Cloud Dataflow はバッチおよびストリーミング データ処理パイプラインを実行するためのフルマネージド サービスであり、Cloud Dataproc はクラスタで Apache Hadoop と Apache Spark のジョブを実行するためのフルマネージド サービスです。
一方、Cloud Dataprep は、ユーザーがデータを探索、クリーニング、変換できるデータ準備サービスです。
これらのサービスは特定のシナリオでは役立ちますが、複数のクラウド サービスとオンプレミス リソースを含むデータ パイプライン全体を調整するようには設計されていません。
</div></details>

 ### Q. 質問41: 未回答
小売業者として、Google Homeなどのさまざまな在宅アシスタントと統合することで、オンライン販売を拡大したいと考えています。顧客の音声コマンドを処理し、バックエンドシステムで注文するには、どのようなソリューションが適切でしょうか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Dialogflow は、チャットボットや音声アシスタントなどの会話型インターフェースを作成および管理するためのツールを提供する会話型 AI プラットフォームです。
Dialogflow Enterprise Edition は、高可用性、セキュリティ、スケーラビリティを必要とする大規模でミッションクリティカルなデプロイ向けに特別に設計されています。
Speech-to-Text API(オプション A)は、音声をテキストに変換する Google Cloud サービスです。これは音声コマンドの処理には便利ですが、フル機能の音声アシスタントの構築に必要な会話フロー管理や意図認識機能は提供されません。
Cloud Natural Language API(オプション B)は、感情分析やエンティティ認識などの自然言語処理機能を提供する別の Google Cloud サービスです。
これは、顧客の音声コマンドのテキストを分析するのに役立ちますが、フル機能の音声アシスタントを構築するために必要な会話フロー管理や意図認識機能は提供されません。
AutoML Natural Language(オプション D)は、感情分析やエンティティ認識などの自然言語処理タスク用のカスタム機械学習モデルを作成できる Google Cloud サービスです。
これは、音声アシスタントの自然言語処理機能をカスタマイズする場合には便利ですが、フル機能の音声アシスタントを構築するために必要な会話フロー管理や意図認識機能は提供されません。
したがって、Dialogflow Enterprise Edition(オプション C)は、フル機能の音声アシスタントを構築するために必要な会話フロー管理と意図認識機能を提供するため、オンライン販売機能と在宅アシスタントを統合するための最適なソリューションです
</div></details>

 ### Q. 質問42: 未回答
物流会社のオペレーターとして、車両ベースのセンサーのイベント配信の信頼性を向上させようとしています。現在、これらのイベントをキャプチャするために、世界のさまざまな場所に小規模なデータセンターがあります。ただし、イベント収集インフラストラクチャーをイベント処理インフラストラクチャーに接続する専用回線は信頼性が低いため、予測不能な待機時間が発生します。この問題に対処するには、費用対効果の高いソリューションを見つける必要があります。次のうち、どのオプションが最善の行動ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
オプションAでは、小規模なKafkaクラスターをデータセンターにデプロイして、イベントをバッファリングすることを提案しています。Kafkaはイベントのバッファリングと信頼性の向上に役立ちますが、追加のインフラストラクチャとメンテナンスコストが必要であり、最も費用対効果の高いソリューションではない可能性があります。
オプション C では、すべてのリモート データセンターと Google の間に Cloud Interconnect を確立することを提案しています。これにより接続性は向上しますが、予測不可能な遅延の問題に必ずしも対処できるとは限らず、追加のコストとメンテナンスが必要になる場合があります。
オプション D では、セッション ウィンドウ内のすべてのデータを集約する Cloud Dataflow パイプラインを作成することを提案しています。これはデータ処理の管理に役立ちますが、必ずしも信頼性の低い専用回線の問題に対処できるとは限らず、追加のインフラストラクチャとメンテナンスのコストが必要になる場合があります。
したがって、シナリオで説明した特定の問題と、最も費用対効果の高い方法で対処するための要件に基づいて、最も適切なソリューションは、Cloud Pub/Sub にデータをパブリッシュするようにデータ収集デバイスを構成することです。
</div></details>

 ### Q. 質問43: 未回答
BigQuery には大量の履歴データがあり、新しいデータをテーブルに継続的に追加する毎日のデータ パイプラインがあります。データ サイエンス チームは、このデータに対して SQL クエリを実行しますが、日付列でフィルター処理され、30 日から 90 日間のデータに制限されたクエリがテーブル全体をスキャンしていることに気付きました。さらに、請求額が予想よりも急速に増加していることがわかりました。SQLクエリを実行する機能を維持しながらこの問題を解決するための最も費用対効果の高いソリューションは何ですか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
正解は、オプションA:DDLを使用して新しいテーブルを作成し、TIMESTAMPまたはDATE型を含む列でパーティション分割することです。
BigQuery でテーブルをパーティション分割すると、日付やタイムスタンプなどの特定の列に基づいて、より小さく管理しやすいセクションに整理することで、大量のデータを効率的に処理できます。
パーティション分割により、クエリはテーブル全体ではなく関連するパーティションのみをスキャンできるため、コストが削減され、クエリのパフォーマンスが向上します。
オプション B(テーブルを Cloud Storage の CSV ファイルにエクスポートし、Cloud Datalab を使用)は、プロセスに手順と複雑さが加わり、テーブルを分割するほど効率的ではない可能性があるため、理想的ではありません。
オプション C (データを 2 つの別々のテーブルに分割する) も機能しますが、管理が難しく、パーティション分割ほど効率的ではない可能性があります。オプション D (毎日新しいテーブルを作成する) では、テーブルの数が多くなり、管理が難しくなり、コストやクエリのパフォーマンスの点で効率的ではない可能性があります
</div></details>

 ### Q. 質問44: 未回答
Cloud Dataflow を介して Cloud Pub/Sub から BigQuery に IoT データをストリーミングする新しい Google Cloud パイプラインに取り組んでいます。データをプレビューしているときに、データの約 2% が破損していることに気付きました。この破損したデータを除外するには、Cloud Dataflow パイプラインにどのような変更を加える必要がありますか?次のオプションを検討してください。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Cloud Dataflow の ParDo 変換を使用すると、各要素をチェックして破損した要素を除外する DoFn を追加することで、破損した要素を除外できます。これは、パイプラインが有効なデータのみの処理を続行できるため、データ ストリームから破損した要素を削除する最も効率的な方法です。
オプション A (SideInput を組み込む) も使用できますが、追加の入力を追加し、追加の処理時間を必要とするため、最も効率的なソリューションではない可能性があります。
オプション C (パーティション変換の実装) は、破損したデータを有効なデータから分離しますが、実際にはパイプラインから削除されないため、最適なソリューションではない可能性があります。
オプション D (GroupByKey 変換の追加) では、すべての有効なデータがグループ化されますが、実際には破損したデータがパイプラインから削除されないため、正しいオプションではありません。
</div></details>

 ### Q. 質問45: 未回答
Node.js で記述された Cloud Functions は、Cloud Pub/Sub からメッセージを取得し、そのデータを BigQuery に転送します。Pub/Sub トピックのメッセージ処理速度が予想よりもはるかに高く、Cloud Logging でエラーが報告されていないことに気付きました。この問題の原因として最も可能性の高いのは、次の 2 つですか?(2つ選択してください。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
ある。パブリッシャーのスループット クォータが小さすぎる: スループット クォータが低いと、メッセージのサブスクライブではなくメッセージの発行で問題が発生するため、このオプションが問題の原因である可能性は低いです。したがって、これは問題の 2 つの最も可能性の高い原因の 1 つではありません。
B.未処理のメッセージの合計数が 10 MB の制限を超えている: 10 MB の制限は、メッセージ処理速度ではなく、<> つの要求内のメッセージの合計サイズに適用されるため、このオプションが問題の原因である可能性も低くなります。したがって、これは問題の <> つの最も可能性の高い原因の <> つではありません。
C. サブスクライバー コードがランタイム エラーを適切に処理しない: このオプションは、サブスクライバー コードがエラーを適切に処理していない場合、エラーをログに記録する代わりにサイレントに失敗する可能性があるため、問題の原因である可能性があります。これにより、メッセージ処理速度が予想よりも高くなり、Cloud Logging でエラーが報告されない可能性があります。
D. サブスクライバー コードがメッセージの量に追いつかない: このオプションも、メッセージ処理速度が高いとサブスクライバー コードが過負荷になり、サブスクライバー コードが遅れてメッセージを見逃す可能性があるため、問題の原因である可能性があります。サブスクライバー コードが大量のメッセージ用に最適化されていない場合、受信メッセージに追いつかない可能性があります。
E.サブスクライバー コードがプルするメッセージを確認しない: このオプションも、メッセージの確認応答に失敗するとメッセージが再配信され、メッセージ処理速度が予想よりも高くなる可能性があるため、問題の原因として考えられます。サブスクライバー コードがメッセージを正しく確認していない場合、メッセージ処理速度が予想以上に増加している可能性があります。
したがって、この問題の最も可能性の高い原因は、オプション C (サブスクライバー コードがランタイム エラーを適切に処理しない) とオプション E (サブスクライバー コードがプルしたメッセージを認識しない) の 2 つです
</div></details>

 ### Q. 質問46: 未回答
Google Cloud Platform で 3 つのデータ処理ジョブを作成しました。1 つのジョブは、Cloud Storage にアップロードされたデータを変換し、その結果を BigQuery に書き込みます。2 つ目のジョブは、オンプレミス サーバーからデータを取り込み、Cloud Storage にアップロードします。3 番目のジョブは、サードパーティのデータプロバイダから情報を取得し、Cloud Storage にアップロードします。これら 3 つのワークフローの実行をスケジュールして監視し、必要に応じて手動で実行できる必要があります。どのオプションを選択する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
オプション A は、ワークフローの自動化と管理のためのプラットフォームを提供する Cloud Composer で DAG(Direct Acyclic Graph)を作成できるため、有効な選択肢です。これにより、ワークフローの実行をスケジュールおよび監視し、必要に応じて手動で実行できます。このオプションは、3 つのワークフローを管理する方法を提供するため、特定のシナリオに適しています。
Stackdriver Monitoring は GCP 上のアプリケーションやインフラストラクチャの健全性とパフォーマンスをモニタリングできますが、ワークフローの自動化や管理用には設計されていないため、オプション B は最適な選択ではありません。
ワークフローのスケジュール設定とモニタリングのための App Engine アプリケーションの開発は最も簡単なソリューションではないため、オプション C は最適な選択ではありません。これには多大な開発作業が必要であり、リソースの最適な使用ではない可能性があります。
Compute Engine インスタンスで cron ジョブを設定すると、管理に多大な労力がかかり、最も効率的なソリューションではない可能性があるため、オプション D は最適な選択ではありません。また、ワークフローを監視する機能も提供されません。
全体として、オプションAは、GCPでワークフローをスケジュールおよび監視するための効率的で簡単なソリューションを提供するため、最良の選択です
</div></details>

 ### Q. 質問47: 未回答
運送会社の従業員は、クラウドネイティブのマネージドサービスを使用してスケーラブルなソリューションを構築し、ハンドヘルドスキャナーから分析システムへの個人識別情報(PII)の送信を防ぐ必要があります。あなたは何をするべきか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
最良のオプションはDです。
トピックを読み取り、Cloud Data Loss Prevention(Cloud DLP)API を呼び出す Cloud Functions の関数を構築することは、PII の送信を防ぐ最も効率的な方法です。
この関数は、データを分析し、タグ付けと信頼度レベルを使用して、レビューのためにバケット内のデータを渡すか隔離することができます。
このアプローチはスケーラブルでクラウドネイティブであり、Google Cloud が提供するマネージド サービスを利用します。
オプションAは、機密データを含むテーブルへのアクセスを制限するだけで、データの送信を妨げないため、最良の選択ではありません。
オプションBは、サードパーティのツールをインストールする必要があり、時間がかかり、他のクラウドサービスとうまく統合されない可能性があるため、最良の選択ではありません。
オプションCは、パイプライン全体を通過した後にデータを分析し、PIIの送信を妨げないため、最良の選択ではありません
</div></details>

 ### Q. 質問48: 未回答
進行中の作業を失うことなく Cloud Dataproc クラスタでジョブを実行するコストを削減し、実行を高速化するにはどうすればよいでしょうか。以下から最適なオプションを選択してください。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Cloud Dataproc クラスタは、Google Compute Engine VM インスタンスをワーカーとして使用します。
プリエンプティブル VM は、バッチ ジョブとフォールト トレラントなワークロードを実行するための低コストのオプションです。
ただし、プリエンプティブル VM が Google によってシャットダウンされると、その VM で実行されているすべての作業が失われます。
グレースフルデコミッションは、この問題を最小限に抑えるのに役立ちます。
プリエンプティブル ワーカー ノードを Cloud Dataproc クラスタに追加し、グレースフル デコミッションを使用するように構成することで、ノードが終了する前に、進行中の作業を安定したストレージに安全に保存できます。
これにより、作業が失われないようにしながら、コストを削減できます。
</div></details>

 ### Q. 質問49: 未回答
相互依存関係を持つ複数の Dataproc ジョブと Dataflow ジョブを含む Google Cloud 上の複雑なデータ パイプラインの実行を自動化する必要があります。パイプラインは毎日実行する必要があり、可能な限りマネージド サービスを使用することをお勧めします。パイプラインを自動化するには、どのツールを使用する必要がありますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Cloud Composer は、Google Cloud 上で複雑なワークフローを作成、スケジュール設定、モニタリングできるフルマネージドのワークフロー オーケストレーション サービスです。
パイプラインの DAG (有向非巡回グラフ) の作成と管理を容易にするマネージド Apache Airflow サービスを提供します。
Cloud Composer を使用すると、パイプラインを簡単に定義してスケジュール設定し、毎日実行しながら、Dataproc や Dataflow などのマネージド サービスを処理に活用できます。
また、組み込みの監視、アラート、ログ記録などの高度な機能も提供され、パイプラインのデバッグと最適化に役立ちます。
</div></details>

 ### Q. 質問50: 未回答
BigQuery テーブル内のデータのサンプルに基づいて作成された Dataprep レシピがあります。変数ロードジョブが完了した後、同じスキーマを持つ新しいデータに対して、このレシピを毎日再利用するにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Dataprep ジョブを Dataflow テンプレートとしてエクスポートすると、レシピを Dataflow パイプラインに統合し、Cloud Composer でスケジュール設定して実行できます。
Cloud Composer は、データ パイプラインのスケジュール設定、モニタリング、再試行のための高度な機能を提供する、フルマネージドのワークフロー オーケストレーション サービスです。
このオプションを使用すると、単純な cron スケジュールや App Engine の cron ジョブを使用するよりも、スケジュールの柔軟性と制御性が向上します。
レシピを Dataprep テンプレートとしてエクスポートし、Cloud Scheduler(オプション C)でジョブをスケジュールすることもできますが、Cloud Composer で Dataflow を使用すると、パイプラインを管理およびモニタリングするためのより高度な機能を利用できます。
</div></details>

## 3
