 
# セクション 1: Google Cloud ネットワークの設計、計画、プロトタイピング（試験内容の約 26%）

## 1.1 全体的なネットワーク アーキテクチャを設計する。 以下のような点を考慮します。

### 高可用性、フェイルオーバー、障害復旧の戦略

ネットワークアーキテクチャを設計する際には、高可用性、フェイルオーバー、障害復旧の戦略を考慮することが非常に重要です。これらの戦略は、ネットワークの安定性と継続的なサービス提供を確保するために不可欠です。以下に、具体的な検討点と対策について詳しく解説します。

#### 1. 高可用性を実現するための戦略

高可用性とは、システムが常に利用可能な状態を維持できる能力のことです。

* **冗長化:**
    * **ハードウェア:** サーバー、ネットワーク機器、ストレージなどを二重化または多重化することで、単一の機器故障による影響を最小限に抑えます。
    * **ソフトウェア:** アプリケーションやサービスを複数のサーバーに分散配置し、負荷分散を行うことで、特定のサーバーの障害によるサービス停止を防ぎます。
* **負荷分散:**
    * 複数のサーバーにトラフィックを分散することで、単一のサーバーへの負荷を軽減し、パフォーマンスの低下を防ぎます。
* **自動化:**
    * 障害検知、復旧処理を自動化することで、人的ミスによる遅延を防ぎ、復旧時間を短縮します。

#### 2. フェイルオーバー戦略

フェイルオーバーとは、障害が発生した際に、別のシステムやコンポーネントに処理を自動的に切り替えることです。

* **フェイルオーバーグループ:**
    * 複数のサーバーをグループ化し、あるサーバーが故障した場合に、他のサーバーが自動的にその役割を引き継ぐように設定します。
* **ハートビート:**
    * 各サーバーが互いに状態を確認し合うことで、障害を早期に検知し、フェイルオーバーをトリガーします。
* **フェイルバック:**
    * フェイルオーバーしたサーバーが復旧した場合に、元のサーバーに処理を戻す仕組みです。

#### 3. 障害復旧戦略

障害復旧とは、大規模な障害が発生した場合に、システム全体を復旧させるための戦略です。

* **バックアップ:**
    * 定期的にデータのバックアップを作成し、障害発生時に復元できるようにします。
* **オフサイトバックアップ:**
    * バックアップデータを社外に保管することで、災害などの大規模な障害にも対応できます。
* **ディザスタリカバリ:**
    * 災害発生時に、別のデータセンターやクラウド環境にシステムを復旧させる計画を策定します。

#### 具体的な検討事項と対策

* **ネットワークトポロジー:**
    * 星型、メッシュ型、リング型など、ネットワークの構成によって可用性が大きく変わります。冗長な経路を確保し、単一障害点を減らすことが重要です。
* **ルーティングプロトコル:**
    * OSPF、BGPなどのルーティングプロトコルは、ネットワークの可用性に大きく影響します。冗長なルーティング経路を確保し、障害発生時に自動的に経路を切り替える必要があります。
* **DNS:**
    * DNSサーバーの冗長化、Anycast DNSの導入などにより、DNSサービスの可用性を高めます。
* **セキュリティ:**
    * DDoS攻撃などのサイバー攻撃への対策を講じることで、ネットワークの安定性を確保します。
* **監視:**
    * ネットワーク機器、サーバー、アプリケーションの状態を常時監視し、異常を早期に検知します。
* **テスト:**
    * 定期的に障害発生を想定したテストを実施し、復旧手順の有効性を確認します。


### DNS 戦略（例: オンプレミス、Cloud DNS、GSLB）
#### GSLB（Global Server Load Balancing）
* 特徴:
    - 複数のデータセンターに分散されたサーバーへの負荷分散を実現する。
    - ネットワークの遅延やユーザーの地理的な位置に基づいて最適なサーバーに接続。
* メリット:
    - グローバルなサービスのパフォーマンス向上。
    - 災害時のフェイルオーバー。
* デメリット:
    - 複雑な構成が必要となる場合がある。
    - 高度なネットワーク知識が必要。

### セキュリティとデータの引き出しの要件：✔

ネットワークアーキテクチャを設計する上で、セキュリティとデータの引き出しは非常に重要な要素です。これらの要件を満たすためには、以下のような点を考慮した設計が必要です。

#### セキュリティ対策

##### 1. アクセス制御
* **認証・認可:** ネットワークへのアクセスを、ユーザーIDとパスワード、または多要素認証を用いて厳密に管理します。
* **アクセス権限:** 各ユーザーやデバイスに、必要な最小限のアクセス権限を付与します。
* **ロールベースアクセス制御 (RBAC):** ユーザーの役割に基づいてアクセス権限を管理することで、権限の委譲を効率的に行えます。

##### 2. 暗号化
* **データの暗号化:** データの保存時、伝送時ともに、暗号化することで、不正アクセスによるデータ漏洩を防ぎます。
* **通信の暗号化:** VPNやSSL/TLSを用いて、ネットワーク通信を暗号化します。

##### 3. ファイアウォール
* **パケットフィルタリング:** 不必要なトラフィックを遮断し、攻撃の入口を減らします。
* **侵入検知・侵入防止システム (IDS/IPS):** ネットワークトラフィックを監視し、異常な通信を検知・阻止します。

##### 4. セキュリティ対策ソフトウェア
* **ウイルス対策ソフトウェア:** マルウェア感染を防ぎます。
* **脆弱性スキャナ:** システムの脆弱性を定期的にスキャンし、パッチを適用します。

##### 5. セキュリティポリシー
* **明確なセキュリティポリシー:** セキュリティに関する規則を明確化し、全従業員に周知徹底させます。
* **定期的な見直し:** セキュリティ脅威は常に変化するため、定期的にセキュリティポリシーを見直す必要があります。

#### データの引き出し対策

##### 1. データ漏洩防止
* **データ分類:** データの重要度に応じて、異なるレベルのセキュリティ対策を適用します。
* **データ損失防止 (DLP):** 機密情報の外部への持ち出しを防止します。
* **ログの記録と分析:** ネットワーク上の活動を記録し、異常な活動を検知します。

##### 2. バックアップ
* **定期的なバックアップ:** データの損失に備え、定期的にデータをバックアップします。
* **オフサイトバックアップ:** 災害や火災などのリスクに備え、バックアップデータを社外に保管します。

##### 3. 災害復旧計画
* **災害発生時の対応:** 災害発生時に迅速にシステムを復旧させるための計画を策定します。

##### 設計時の考慮事項

* **ゼロトラストアーキテクチャ:** ネットワーク内のすべてのデバイスを信頼せず、厳格な認証と認可を行うアーキテクチャです。
* **マイクロセグメンテーション:** ネットワークを小さなセグメントに分割し、攻撃の影響範囲を限定します。
* **クラウドセキュリティ:** クラウドサービスを利用する場合は、クラウドプロバイダーのセキュリティ機能を最大限に活用し、自社のセキュリティポリシーとの整合性を確保します。

##### 具体的な検討例

* **データセンターの配置:** 複数のデータセンターに分散配置することで、単一の拠点の障害による影響を最小限に抑えます。
* **ネットワーク分割:** DMZ (Demilitarized Zone) を設置し、外部ネットワークとの間を分離します。
* **VPNの利用:** リモートアクセスにVPNを利用することで、安全な接続を確保します。
* **多要素認証の導入:** パスワードに加えて、生体認証やワンタイムパスワードなどを組み合わせることで、認証の強度を高めます。

##### 設計のポイント

* **リスクアセスメント:** ネットワークに潜むリスクを特定し、優先順位付けを行います。
* **層状防御:** 複数のセキュリティ対策を組み合わせることで、防御の堅牢性を高めます。
* **継続的な改善:** セキュリティ脅威は常に変化するため、常に最新のセキュリティ対策を導入し、システムを改善していく必要があります。

### 負荷分散：✔

ネットワークアーキテクチャ設計において、負荷分散は、システムの可用性、パフォーマンス、スケーラビリティを向上させる上で非常に重要な要素です。負荷分散によって、複数のサーバーにトラフィックを分散することで、単一のサーバーへの負荷を軽減し、システム全体の安定性を高めることができます。

#### 負荷分散の目的

* **高可用性:** 一つのサーバーが故障した場合でも、他のサーバーが処理を引き継ぎ、サービスの中断を最小限に抑えます。
* **パフォーマンス向上:** 複数のサーバーで処理を分散することで、処理能力を向上させ、応答時間を短縮します。
* **スケーラビリティ:** 負荷が増加した場合に、簡単にサーバーを追加することで、システムの処理能力を拡張できます。

#### 負荷分散の方式

* **ハードウェア型負荷分散:** 専用の負荷分散装置を使用する方式です。高性能で、大規模なネットワークに適しています。
* **ソフトウェア型負荷分散:** サーバーに負荷分散ソフトウェアをインストールする方式です。柔軟性が高く、コストを抑えられるのが特徴です。
* **クラウド型負荷分散:** クラウドサービスが提供する負荷分散機能を利用する方式です。手軽に導入でき、スケーラビリティが高いのが特徴です。

#### 負荷分散アルゴリズム

* **ラウンドロビン:** 各リクエストを順番にサーバーに割り当てる方式です。
* **最小接続:** 接続数が最も少ないサーバーにリクエストを割り当てる方式です。
* **最速応答:** 応答時間が最も短いサーバーにリクエストを割り当てる方式です。
* **重み付けラウンドロビン:** 各サーバーに重みを設定し、重みに応じてリクエストを割り当てる方式です。
* **IPハッシュ:** クライアントのIPアドレスに基づいて、常に同じサーバーにリクエストを割り当てる方式です。

#### 負荷分散の検討事項

* **アプリケーションの種類:** 状態を持たないステートレスなアプリケーションと、状態を持つステートフルなアプリケーションでは、負荷分散の方式が異なります。
* **セッション管理:** ステートフルなアプリケーションでは、セッション情報を保持する必要があります。
* **健康状態チェック:** サーバーの稼働状況を監視し、故障したサーバーを自動的に除外する必要があります。
* **ネットワーク構成:** 負荷分散装置の設置場所、ネットワーク帯域幅、遅延などを考慮する必要があります。
* **コスト:** ハードウェア、ソフトウェア、運用コストなどを総合的に評価する必要があります。

#### 具体的な検討例

* **Webサーバーの負荷分散:** HTTPリクエストを複数のWebサーバーに分散することで、Webサイトのアクセス集中によるダウンを防ぎます。
* **データベースサーバーの負荷分散:** 読み込み処理を複数のデータベースサーバーに分散することで、データベースサーバーの負荷を軽減します。
* **アプリケーションサーバーの負荷分散:** アプリケーション処理を複数のアプリケーションサーバーに分散することで、システム全体の処理能力を向上させます。

#### 設計のポイント

* **負荷分散の目的を明確にする:** 高可用性、パフォーマンス向上、スケーラビリティなど、どのような目的で負荷分散を行うのかを明確にすることが重要です。
* **適切な負荷分散方式を選択する:** アプリケーションの種類、ネットワーク環境、コストなどを考慮して、最適な負荷分散方式を選択します。
* **健康状態チェックを徹底する:** サーバーの故障を早期に検知し、迅速に復旧させることが重要です。
* **定期的な見直し:** システムの状況に合わせて、負荷分散の設定を見直す必要があります。

#### まとめ

負荷分散は、ネットワークアーキテクチャ設計において、システムの信頼性とパフォーマンスを向上させるために不可欠な要素です。適切な負荷分散の設計を行うことで、システムの可用性を高め、ユーザーに安定したサービスを提供することができます。


### プロジェクトごとおよび VPC ごとの割り当ての適用：✔
#### 割り当ての具体的な例
* 開発環境と本番環境の分離: 開発環境と本番環境を異なるプロジェクトに割り当てることで、誤って本番環境のデータを変更してしまうリスクを軽減できます。
* アプリケーションごとの分離: 各アプリケーションを別のプロジェクトに割り当てることで、アプリケーション間の影響を最小限に抑え、障害発生時の影響範囲を限定できます。
* 地域ごとの分離: 地域ごとにプロジェクトを分けることで、データ主権や規制への対応を容易にします。
#### 割り当ての検討時の注意点
* 過度な分割: プロジェクトを細かく分割しすぎると、管理が複雑になる可能性があります。
* 柔軟性: 将来的にプロジェクトの構成を変更できるよう、柔軟な設計を心掛けましょう。
* コスト: プロジェクトの作成や管理には、一定のコストがかかります。コストとメリットを比較検討し、最適な割り当てを決定しましょう。


### ハイブリッド接続（例: 限定公開の Google アクセスを使用したハイブリッド接続）
ハイブリッド接続は、オンプレミス環境とクラウド環境を連携させることで、それぞれの強みを活かしたシステムを構築する手法です。特に、限定公開の Google アクセスを利用したハイブリッド接続は、セキュリティを確保しつつ、オンプレミス環境からGoogle Cloud Platform (GCP) のサービスへ安全にアクセスするための有効な手段となります。

#### ハイブリッド接続設計における検討事項
1. 接続方法の選択
* VPN: 仮想プライベートネットワークは、最も一般的な接続方法です。IPsec VPNやSSL VPNなど、さまざまな種類があります。
* Interconnect: 専用線を利用した高帯域幅、低遅延の接続方法です。大規模なデータ転送や高可用性が求められる場合に適しています。
* 限定公開の Google アクセス: オンプレミスからGCPへのプライベートなアクセスを提供します。インターネットを経由しないため、セキュリティが向上します。
2. ネットワーク設計
* DMZ: デミリタライズドゾーンを設置し、オンプレミスネットワークとGCPネットワークを分離することで、セキュリティを強化します。
* サブネット設計: 各サブネットの役割を明確にし、アクセス制御リスト (ACL) を設定することで、ネットワークトラフィックを制御します。
* ルーティング: 静的ルーティングと動的ルーティングを適切に組み合わせ、パケットが確実に目的地に到達するようにします。
3. セキュリティ
* 認証・認可: 認証方式（ID/パスワード、多要素認証など）と認可方式（ロールベースアクセス制御など）を適切に設定します。
* 暗号化: 通信データを暗号化することで、データ漏洩を防ぎます。
* ファイアウォール: ファイアウォールルールを厳密に設定し、不要なトラフィックを遮断します。
* IDS/IPS: 侵入検知・侵入防止システムを導入し、セキュリティインシデントを早期に検知し対応します。
4. パフォーマンス
* 帯域幅: 必要な帯域幅を確保し、ネットワーク遅延を最小限に抑えます。
* QoS: Quality of Serviceを設定し、重要なトラフィックを優先的に処理します。
5. 可用性
* 冗長化: 複数の接続経路を確保し、障害発生時の影響を最小限に抑えます。
* フェイルオーバー: 障害が発生した場合に、自動的に別の経路に切り替える仕組みを構築します。
6. コスト

#### 限定公開の Google アクセスを利用したハイブリッド接続の設計ポイント
* プライベートIPアドレス: オンプレミスとGCPの間にプライベートIPアドレス空間を構築することで、インターネットを経由しないセキュアな通信を実現します。
* Cloud Router: Cloud Routerを使用して、オンプレミスとGCP間のルーティングを管理します。
* VPNトンネル: Cloud VPNトンネルを確立し、両環境を接続します。
* ファイアウォールルール: ファイアウォールルールを厳密に設定することで、許可されたトラフィックのみを通過させます。

### コンテナ ネットワーキング
コンテナネットワーキングは、コンテナ化されたアプリケーションが互いに通信し、また外部ネットワークと通信するための仕組みです。従来の仮想化ネットワークと比較して、より軽量で柔軟なネットワーク環境を提供します。

#### コンテナネットワーキングの設計における考慮事項
1. ネットワークモデルの選択
* Overlay Network: 物理ネットワークとは別に、仮想的なネットワークを構築する方式です。
    - メリット: 柔軟性が高く、複雑なネットワーク構成に対応しやすい。
    - デメリット: パフォーマンスが物理ネットワークに比べて低下する可能性がある。
* Underlay Network: 物理ネットワーク上に直接コンテナを配置する方式です。
    - メリット: パフォーマンスが高く、シンプルな構成で済む。
    - デメリット: 柔軟性が低い。
2. ネットワークプラグインの選択
* CNI (Container Network Interface): コンテナとネットワークを接続するための標準インターフェースです。
    - Flannel: シンプルで使いやすいプラグイン。
    - Calico: 大規模なネットワークに適しており、セキュリティ機能が充実している。
    - Weave Net: 高度なネットワーク機能を提供するプラグイン。
3. サービス発見
* Service Discovery: コンテナのIPアドレスやポート番号を動的に管理し、他のコンテナからサービスを検出できるようにする仕組みです。
    - Kubernetes Service: Kubernetesクラスタ内のサービスを自動的に検出します。
    - Consul: 分散型のサービス発見ツールです。
4. セキュリティ
* ネットワークポリシー: 各コンテナへのアクセスを制限するネットワークポリシーを設定します。
* TLS: コンテナ間の通信を暗号化します。
* アイデンティティ管理: 各コンテナに固有のアイデンティティを付与し、認証・認可を行います。
5. パフォーマンス
* ネットワーク帯域幅: コンテナ間の通信に十分な帯域幅を確保します。
* 遅延: ネットワーク遅延を最小限に抑えるために、適切なネットワーク設計を行います。


#### コンテナネットワーキングの設計例
* マイクロサービスアーキテクチャ: 各マイクロサービスを別のコンテナに配置し、サービスメッシュを用いて通信を管理します。
* Kubernetesクラスタ: Kubernetesクラスタ内に複数の名前空間を作成し、各名前空間に異なるアプリケーションを配置します。
* サーバーレスアーキテクチャ: サーバーレス関数を実行するためのコンテナを動的に作成し、イベントドリブンな処理を実現します。

### IAM ロール

### SaaS、PaaS、IaaS サービス

### セキュリティ目的でのマイクロセグメンテーション（例: メタデータ、タグ、サービス アカウントの使用）

#### マイクロセグメンテーションとは？

マイクロセグメンテーションは、従来のネットワークセグメンテーションをさらに細分化し、個々のワークロード（サーバー、コンテナなど）単位でセキュリティポリシーを適用する技術です。これにより、ネットワーク内の攻撃範囲を最小限に抑え、セキュリティを大幅に強化することができます。

#### マイクロセグメンテーションにおけるメタデータ、タグ、サービスアカウントの活用

##### メタデータ
* **ワークロードの識別:** 各ワークロードに固有のメタデータを付与することで、そのワークロードがどのような役割を果たしているのかを明確にします。
* **ポリシーの適用:** メタデータに基づいて、ワークロード間の通信を許可または禁止するポリシーを定義します。
* **例:**
    * 環境（開発、本番）
    * アプリケーションの種類（Webサーバー、データベース）
    * 所有者（部署、チーム）

##### タグ
* **柔軟な分類:** ワークロードに複数のタグを付与することで、より詳細な分類が可能になります。
* **動的なポリシー:** タグに基づいて、ポリシーを動的に変更することができます。
* **例:**
    * Tier（Tier1、Tier2）
    * リージョン（東京、大阪）
    * プロジェクト名

##### サービスアカウント
* **権限の管理:** 各ワークロードに専用のサービスアカウントを割り当てることで、最小権限の原則に基づいたアクセス制御を実現します。
* **ロールベースアクセス制御 (RBAC):** サービスアカウントに特定のロールを付与し、そのロールに紐づいた権限を付与します。
* **例:**
    * リードオンリーアクセス
    * 書き込みアクセス
    * 管理者権限

#### マイクロセグメンテーションの設計における検討事項

##### 1. **セグメントの定義:**
* **ビジネス要件:** アプリケーションの依存関係、セキュリティ要件などを考慮して、セグメントを定義します。
* **粒度:** セグメントの粒度を細かくしすぎると管理が複雑になるため、適切な粒度を設定します。

##### 2. **ポリシーの作成:**
* **許可と禁止:** ワークロード間の通信を許可するルールと禁止するルールを明確に定義します。
* **動的なポリシー:** 環境の変化に合わせて、ポリシーを動的に変更できるようにします。

##### 3. **エンフォースメント:**
* **ネットワークポリシー:** ネットワークポリシーを定義し、ネットワークトラフィックを制御します。
* **サービスメッシュ:** サービスメッシュを利用することで、マイクロサービス間の通信を制御し、セキュリティを強化できます。

##### 4. **監視と管理:**
* **ログ収集:** ネットワークトラフィックを監視し、異常な活動を検知します。
* **ポリシー違反の検出:** ポリシー違反を検出し、アラートを発報します。

#### マイクロセグメンテーションのメリット

* **セキュリティ強化:** 攻撃範囲を最小限に抑え、セキュリティ侵害の影響を軽減します。
* **コンプライアンス:** PCI DSS、GDPRなどの規制への対応を支援します。
* **レジリエンス:** システムの障害発生時における影響範囲を限定します。

#### マイクロセグメンテーションの導入事例

* **金融機関:** 顧客情報などの機密データを保護するために、マイクロセグメンテーションを導入しています。
* **医療機関:** HIPAA規制への対応のために、マイクロセグメンテーションを導入しています。
* **eコマース企業:** 顧客データの漏洩を防ぐために、マイクロセグメンテーションを導入しています。

#### まとめ

マイクロセグメンテーションは、現代のネットワーク環境において、セキュリティを強化するための重要な技術です。メタデータ、タグ、サービスアカウントを活用することで、より柔軟かつ精度の高いセキュリティポリシーを適用することができます。


## 1.2 Virtual Private Cloud（VPC）インスタンスを設計する以下のような点を考慮します。

### IP アドレスの管理とお客様所有 IP アドレスの使用（BYOIP）

### スタンドアロン VPC と共有 VPC：✔
#### 設計のポイント
* プロジェクトの特性: 各プロジェクトの規模、セキュリティ要件、リソースの利用状況などを考慮して、最適なVPCを選択する。
* ネットワーク設計: サブネットの分割、ルーティングの設定、ファイアウォールルールの設定などを適切に行う。
* IAM: IAMポリシーを細かく設定し、権限の最小化を図る。
* モニタリング: ネットワークの状況を継続的に監視し、問題が発生した場合に迅速に対応する。

### 複数と単一

### リージョンとマルチリージョンの比較：✔
#### リージョンとマルチリージョンを選択する際の考慮事項
* アプリケーションの性質:
    - ミッションクリティカルなアプリケーション: 高可用性が求められるため、マルチリージョンが適している。
    - 低遅延が求められるアプリケーション: リージョン内に配置することで、遅延を最小限に抑えることができる。
* データの地域性:
    - データの保存場所が規制されている場合は、その地域のリージョンを選択する必要がある。
* コスト:
    - コストが厳しく制限されている場合は、リージョンを選択し、必要な機能のみを有効にする。
* 災害復旧:
    - 災害発生時にサービスを継続するために、マルチリージョンが有効。
#### マルチリージョンの実装方法
* リージョン間のレプリケーション: データベースやストレージを複数のリージョンにレプリケートすることで、データの可用性を高める。
* ロードバランシング: 複数のリージョンに配置されたインスタンスにトラフィックを分散させる。
* リージョン間VPN: 複数のリージョン間のプライベートネットワーク接続を確立する。

### VPC ネットワーク ピアリング：✔
#### VPC ネットワーク ピアリングを検討する理由
* リソースの共有: 異なる VPC に配置されたリソースを相互に利用できます。
* ネットワークの拡張: VPC を拡張する際に、既存の VPC との接続を容易に行えます。
* マルチクラウド環境: 複数のクラウドプロバイダを利用する場合、VPC ピアリングを利用してネットワークを統合できます。
#### VPC ネットワーク ピアリングの設計における考慮事項
1. ピアリングする VPC の決定
    * プロジェクト構造: どのプロジェクトの VPC をピアリングするかを決定します。
    * リソースの配置: ピアリングする VPC に配置するリソースの種類と役割を明確にします。
2. サブネット設計
    * CIDR範囲: ピアリングする VPC の CIDR 範囲が重複しないように注意します。
    * ルーティング: 各 VPC 間のルーティングを適切に設定します。
3. セキュリティ
    * ファイアウォール: ファイアウォールルールを設定し、許可するトラフィックを制限します。
    * IAM: IAM (Identity and Access Management) を利用して、アクセス権限を管理します。
    * VPN: 必要に応じて、VPN を利用してセキュリティを強化します。
4. パフォーマンス
    * ネットワーク遅延: ピアリングによるネットワーク遅延を考慮し、アプリケーションの要件に合わせた設計を行います。
    * 帯域幅: 必要な帯域幅を確保します。
5. コスト
    * データ転送量: ピアリングによるデータ転送量に応じて、コストが発生します。
    * 維持費: VPC ピアリングの設定や管理に、一定のコストがかかります。
#### VPC ネットワーク ピアリングの設計例
* 複数の環境の接続: 開発環境、ステージング環境、本番環境の VPC をピアリングし、共通のリソースを共有します。
* 異なるリージョンの接続: 異なるリージョンに配置された VPC をピアリングし、災害復旧や負荷分散を実現します。
* マルチクラウド環境: GCP と他のクラウドプロバイダの VPC をピアリングし、ハイブリッドクラウド環境を構築します。
#### VPC ネットワーク ピアリングの注意点
* 推移的ピアリングは不可: 直接ピアリングした VPC 間でのみ通信が可能です。
* CIDR の重複: ピアリングする VPC の CIDR 範囲が重複すると、ネットワーク障害が発生する可能性があります。
* セキュリティリスク: ファイアウォールルールを適切に設定しないと、セキュリティリスクが高まります。

### ファイアウォール（サービス アカウント ベース、タグベースなど）：✔
#### ファイアウォール設計の検討事項
1. ファイアウォールの種類
* VPC ファイアウォール: VPC レベルでトラフィックを制御します。
    - ルール: プロトコル、ポート、IPアドレス、タグなどを指定してルールを作成します。
    - 適用範囲: 全てのインスタンスに適用されます。
* Cloud NGFW: より高度なファイアウォール機能を提供します。
    - 機能: IPS、IDS、URLフィルタリングなど
    - 適用範囲: VPC ファイアウォールと同様に、VPC レベルで適用できます。
2. ファイアウォールルールの作成
3. サービスアカウントベースのファイアウォール
*  原則: サービスアカウントに権限を付与し、その権限に基づいてトラフィックを制御します。
* メリット:
    - 細かい権限管理が可能
    - IAM (Identity and Access Management) と連携し、セキュリティを強化
* デメリット:
    - サービスアカウントの管理が複雑になる可能性がある
4. タグベースのファイアウォール
* 原則: インスタンスにタグを付与し、タグに基づいてトラフィックを制御します。
* メリット:
    - 柔軟なルール設定が可能
    - インスタンスの属性に基づいてルールを適用できる
* デメリット:
    - タグの管理が煩雑になる可能性がある
5. その他の考慮事項
* デフォルトルール: デフォルトでは、全てのトラフィックが拒否されるように設定することを推奨します。
* 最小権限の原則: 必要最低限の権限のみを付与します。
* 定期的なレビュー: ファイアウォールルールを定期的に見直し、必要に応じて変更します。
* ログ: ファイアウォールログを分析し、セキュリティインシデントを検出します。
#### 設計例
* 開発環境: 開発環境のインスタンスには、インターネットからのアクセスを許可し、内部ネットワークからのアクセスは制限する。
* 本番環境: 本番環境のインスタンスには、外部からのアクセスを最小限に制限し、内部ネットワークからのアクセスのみを許可する。
* データベースサーバー: データベースサーバーへのアクセスは、特定のアプリケーションからのみ許可する。


### カスタムルート

### マネージド サービス（Cloud SQL、Memorystore など）の使用：✔
#### マネージドサービスとVPCの連携方法
* プライベートIP接続:
    - マネージドサービスをプライベートIPアドレスでアクセスできるように設定することで、VPC内のインスタンスから安全にアクセスできます。
    - Cloud SQL、Memorystoreなど、多くのマネージドサービスでサポートされています。
* Cloud SQL Proxy:
    - Cloud SQLに接続するためのセキュアなプロキシサーバーです。
    - VPC内のインスタンスからCloud SQLに接続する場合に便利です。
* サーバーレス VPC アクセス:
    - Serverless VPC Accessを使用することで、Serverless Framework（Cloud Functions、Cloud Runなど）からプライベートIPアドレスを持つリソースにアクセスできます。
#### マネージドサービス利用時の考慮事項
* ネットワーク設定:
    - VPCネットワークとマネージドサービスのネットワーク設定を連携させる必要があります。
    - ファイアウォールルール、IAMポリシーなどを適切に設定する必要があります。
* セキュリティ:
    - データの暗号化、IAMによるアクセス制御、ネットワーク分離などを考慮する必要があります。
* パフォーマンス:
    - ネットワーク遅延、I/O性能などを考慮し、アプリケーションの要件に合わせたインスタンスタイプを選択する必要があります。
* コスト:
    - 利用するサービスの種類、インスタンスタイプ、ストレージ容量などによって、コストが異なります。
* 高可用性:
    - マネージドサービスのレプリケーション設定や、マルチリージョン展開などを検討することで、高可用性を確保できます。
#### 設計例
* Webアプリケーション:
    - WebサーバーをVPC内に配置し、Cloud SQLをデータベースとして利用する。
    - Cloud SQL Proxyを使用して、WebサーバーからCloud SQLに安全に接続する。
* モバイルアプリのバックエンド:
    - Cloud Functionsでバックエンドロジックを実装し、Memorystoreをキャッシュとして利用する。
    - Serverless VPC Accessを使用して、Cloud FunctionsからMemorystoreにアクセスする。



### マルチ NIC と内部ロードバランサをネクストホップまたは等価コスト マルチパス（ECMP）ルートとして使用する VPC へのサードパーティ デバイス挿入（NGFW）
Google Cloud VPCにおいて、複数のネットワークインターフェースカード（NIC）を持つインスタンスに、内部ロードバランサを介してサードパーティ製の次世代ファイアウォール（NGFW）を接続し、ECMP (Equal-Cost Multi-Path) ルートを用いて冗長化と高可用性を確保する構成は、高度なネットワーク設計となります。この構成は、大規模なネットワーク環境や高可用性が求められるシステムにおいて、より柔軟かつ安全なネットワークを実現するために有効です。

#### 各要素の役割とメリット
* マルチNIC:
    - 単一のインスタンスに複数のNICを割り当てることで、複数のネットワークに接続できます。
    - NGFWへの冗長な接続が可能になり、可用性を高めます。
* 内部ロードバランサ:
    - NGFWへのトラフィックを分散し、負荷を分散します。
    - フェイルオーバー機能により、障害発生時の影響を最小限に抑えます。
* ECMPルート:
    - 複数の経路を持つ等コストのルートを設定することで、トラフィックを複数の経路に分散させます。
    - 冗長性と可用性を高め、ネットワークのボトルネックを解消します。
* サードパーティデバイス挿入（NGFW）:
    - ネットワークトラフィックを検査し、セキュリティを強化します。
    - IPS、IDS、URLフィルタリングなどの高度なセキュリティ機能を提供します。
#### 設計のポイント
1. ネットワーク設計:
    - VPC内のサブネット設計: NGFW、インスタンス、ロードバランサを配置するサブネットを適切に設計します。
    - ルーティング: ECMPルートを設定し、トラフィックを複数の経路に分散させます。
    - ファイアウォールルール: NGFWのファイアウォールルールを適切に設定し、セキュリティを確保します。
2. インスタンス設計:
    - マルチNICインスタンスの作成: NGFWを接続するインスタンスに複数のNICを割り当てます。
    - インスタンスグループの作成: 内部ロードバランサのバックエンドとして使用するインスタンスグループを作成します。
3. 内部ロードバランサの設定:
    - ヘルスチェック: NGFWのヘルスチェックを設定し、障害発生時にトラフィックを正常なインスタンスに転送します。
    - ターゲットプール: インスタンスグループをターゲットプールに追加します。
    - バックエンドサービス: ターゲットプールとプロトコルを関連付けます。
4. カスタムルートの設定:
    - ECMPルートを作成し、複数のNGFWにトラフィックを分散させます。
5. セキュリティ:
    - IAM: IAMポリシーを使用して、アクセス権限を管理します。
    - SSL/TLS: NGFWとインスタンス間の通信を暗号化します。
#### 具体的な手順
1. VPCとサブネットの作成: NGFW、インスタンス、ロードバランサを配置するためのサブネットを作成します。
2. マルチNICインスタンスの作成: NGFWをインストールするインスタンスを作成し、複数のNICを割り当てます。
3. 内部ロードバランサの作成: ヘルスチェック、ターゲットプール、バックエンドサービスを作成します。
4. カスタムルートの作成: ECMPルートを作成し、内部ロードバランサのIPアドレスをネクストホップとして設定します。
5. NGFWの設定: NGFWのファイアウォールルール、NAT設定などを適切に行います。
6. インスタンスへの接続: インスタンスからNGFWを経由して外部ネットワークにアクセスできるように、ルートテーブルを設定します。
#### 考慮事項
* パフォーマンス: ECMPルートによるパケットの振り分けは、ハッシュ関数に基づいて行われるため、パケットロスが発生する可能性があります。
* 複雑性: 複数の要素を組み合わせるため、設定が複雑になります。
* コスト: マルチNICインスタンスや内部ロードバランサの利用により、コストが増加する可能性があります。
* ベンダー依存性: 使用するNGFWの種類によって、設定方法が異なります。


## 1.3 ハイブリッド クラウドとマルチクラウドのネットワークを設計する。 以下のような点を考慮します。

### Dedicated Interconnect と Partner Interconnect
#### 設計例
* 大規模データセンターとの接続: 大量のデータを高速かつ安全に転送するために、Dedicated Interconnectを利用する。
* 複数のリージョンへの展開: 異なるリージョンに配置された複数のクラウドプラットフォームを、Partner Interconnectで接続し、グローバルなネットワークを構築する。
* ハイブリッドクラウド環境: オンプレミス環境とGoogle Cloudを、Dedicated Interconnectで接続し、アプリケーションをハイブリッドに展開する。

### マルチクラウド接続

### ダイレクト ピアリング

### IPsec VPN
#### Google CloudにおけるIPsec VPNの構築
Google Cloudでは、Cloud VPNというマネージドVPNサービスが提供されています。Cloud VPNを利用することで、以下のメリットが得られます。

* 簡単設定: 数回のクリックでVPN接続を構築できます。
* 高可用性: 複数のゾーンにまたがってVPNゲートウェイを配置し、高可用性を確保できます。
* スケーラビリティ: 需要に応じて、VPNゲートウェイの帯域幅を柔軟に調整できます。
* 統合: Google Cloudの他のサービスとの連携が容易です。
#### 具体的な検討事項
* オンプレミス環境との接続:
    - VPNゲートウェイの配置: オンプレミス環境にVPNゲートウェイを設置し、Cloud VPNと接続します。
    - NATトラバーサル: プライベートIPアドレスを使用している場合は、NATトラバーサルを設定する必要があります。
* 他のクラウド環境との接続:
    - ピアリング: 他のクラウドプロバイダーとのピアリングを設定し、VPN接続を確立します。
* セキュリティグループ:
    - VPNトラフィックを許可するセキュリティグループを設定します。
* ルートテーブル:
    - VPNトラフィックを適切なルートテーブルに転送するように設定します。
* ダイナミックルーティング:
    - ネットワーク構成が頻繁に変わる場合は、BGPなどのダイナミックルーティングプロトコルを利用することを検討します。

### フェイルオーバーと障害復旧戦略
#### Google Cloudで実現できるフェイルオーバーと障害復旧
* リージョン間冗長化:
    - リージョンペア: 異なるリージョンにペアとなるリソースを配置し、障害発生時に自動的にフェイルオーバーを行います。
    - マルチリージョンオートメーション: TerraformやCloud Deployment Managerなどのツールを使用して、複数のリージョンへのデプロイを自動化します。
* プリエンプティブVM:
    - コストを抑えながら、高負荷時に自動的にインスタンスを増やすことができます。
    - 障害が発生した場合、新しいプリエンプティブVMを起動することで、迅速な復旧が可能です。
* マネージドサービス:
    - Cloud SQL、Cloud Storageなど、Googleが管理するサービスは、高い可用性と耐障害性を備えています。
* Cloud Load Balancing:
    - 複数のバックエンドサーバーへの負荷分散を行い、可用性を向上させます。
* Cloud CDN:
    - 静的コンテンツをグローバルに配信し、パフォーマンスを向上させるとともに、障害発生時の影響を軽減します。
* Cloud Functions:
    - イベント駆動型のサーバーレス関数で、自動化タスクを実行できます。
    - 障害検知や復旧処理を自動化するために活用できます。
#### 具体的な検討事項
* データレプリケーション:
    - Cloud SQLやCloud Spannerなどのマネージドデータベースサービスを利用することで、データのレプリケーションを自動化できます。
    - Cloud Storageのマルチリージョンバケットを活用することで、オブジェクトストレージの冗長化を実現できます。
* バックアップ:
    - Cloud Backupを利用して、仮想マシン、ディスク、データベースなどのバックアップを自動化します。
* テスト:
    - 定期的に障害復旧テストを実施し、復旧手順の有効性を確認します。
* セキュリティ:
    - 障害発生時に悪意のある攻撃を受けるリスクを考慮し、セキュリティ対策を強化します。

### リージョン ルーティング モードとグローバル VPC ルーティング モード
#### どちらのモードを選択すべきか？
##### リージョンルーティングモードを選択する場合
* 小規模なネットワーク: 複数のリージョンにまたがる大規模なネットワークではなく、単一のリージョンまたは少数のリージョンで構成されるネットワークの場合。
* セキュリティ: リージョン間の通信を制限することで、セキュリティを高めたい場合。
* 管理の簡素化: 複雑なルーティング構成を避けたい場合。
##### グローバルVPCルーティングモードを選択する場合
* 大規模なネットワーク: 複数のリージョンにまたがる大規模なネットワークで、リージョン間での通信が必要な場合。
* 高い可用性: 障害発生時に、他のリージョンにトラフィックを転送することで、可用性を高めたい場合。
* 柔軟性: ネットワーク構成を柔軟に変更したい場合。

### オンプレミスのロケーションから複数の VPC へのアクセス（例: 共有 VPC、マルチ VPC ピアリング トポロジなど）
1. 共有VPC
* 概要: 複数のプロジェクトで共通のIPアドレス空間を共有できるVPCです。
* メリット:
    - 単一のVPCとして管理できるため、シンプルで効率的
    - 複数のプロジェクト間の接続が容易
* デメリット:
    - すべてのプロジェクトが同じIPアドレス空間を共有するため、セキュリティリスクが増大する可能性がある
    - 複数のプロジェクト間のトラフィックを制御するのが難しい場合がある
2. マルチVPCピアリング
* 概要: 異なるVPC間を直接接続する機能です。
* メリット:
    - 異なるプロジェクトのVPC間でプライベートIPアドレスを使用して通信できる
    - 柔軟なネットワーク構成が可能
* デメリット:
    - 各VPCペアごとにピアリングを設定する必要があるため、管理が複雑になる可能性がある
3. Cloud Interconnect
* 概要: オンプレミスネットワークとGoogle Cloud VPCを直接接続する高帯域幅のプライベートネットワーク接続です。
* メリット:
    - 高い帯域幅と低遅延を実現できる
    - オンプレミスネットワークとの統合が容易
* デメリット:
    - コストが高い
    - 設置に時間がかかる
4. Cloud VPN
* 概要: IPsec VPNを使用して、オンプレミスネットワークとGoogle Cloud VPCを接続するサービスです。
* メリット:
    - コストが比較的安価
    - 柔軟な接続設定が可能
* デメリット:
    - 帯域幅がCloud Interconnectに比べて狭い
    - VPNの設定と管理が必要

### ハイブリッド接続ソリューションにより提供される帯域幅と制約
#### 帯域幅の制約と対処法
* Cloud VPN:
    - 帯域幅が限られているため、大容量データ転送には不向き
    - 対処法: 複数のVPNトンネルを構築することで帯域幅を増やす、Cloud Interconnectに切り替える
* Cloud Interconnect:
    - 物理的な回線のため、帯域幅の変更に時間がかかる
    - 対処法: 必要な帯域幅を事前に見積もり、余裕を持たせて契約する
* Partner Interconnect:
    - 通信事業者のサービス品質に依存するため、安定性が保証されない場合がある
    - 対処法: 複数の通信事業者と契約することでリスクを分散す

### オンプレミス ロケーションから Google のサービスまたは API へのプライベート アクセス
#### なぜプライベートアクセスが必要か？
* セキュリティ強化: インターネットを経由しないため、データ漏洩のリスクを低減できます。
* パフォーマンス向上: インターネット経由の通信に比べて、遅延が少なく、安定した通信を実現できます。
* コスト削減: インターネット回線のコストを削減できます。

### オンプレミス ロケーションとクラウド間の IP アドレス管理
#### Google CloudのIPアドレス管理機能
* VPCサービス: VPCネットワークの作成、管理、およびルーティングの設定を行います。
* Cloud DNS: DNSサービスを提供します。
* Cloud NAT: NATサービスを提供します。
* Cloud Router: BGPルーティングをサポートします。
#### 設計のポイント
* シンプル化: なるべくシンプルなIPアドレススキームを設計し、管理の負荷を軽減します。
* 拡張性: 将来的にネットワークが拡大した場合でも、柔軟に対応できる設計にします。
* セキュリティ: IPアドレス範囲を制限し、不正なアクセスを防止します。
* 高可用性: 障害発生時に、IPアドレス管理システムが停止しないように冗長化を考慮します。

### DNS ピアリングと転送
#### 設計のポイント
* DNSゾーンの設計: 各ゾーンの役割を明確にし、適切なレコードを配置します。
* 権限委譲: DNSレコードの管理権限を適切に委譲します。
* セキュリティ: DNS攻撃から保護するための対策を講じます。
* パフォーマンス: DNSクエリに対する応答時間を短縮するための対策を講じます。
* モニタリング: DNSの設定が正しく機能しているか、定期的に監視します。
#### 具体的な活用例
* 共有サービスのDNSレコード: 複数のVPCで利用する共有サービス（例えば、認証サービス）のDNSレコードを一つのゾーンに集約し、DNSピアリングで共有する。
* オンプレミス環境との統合: オンプレミス環境のDNSサーバーに、GCPのDNSレコードを転送することで、既存のDNSインフラと統合する。
* マルチクラウド環境: AWSやAzureなどの他のクラウドプロバイダーのDNSサービスと連携し、マルチクラウド環境におけるDNS管理を統一する。


## 1.4 Google Kubernetes Engine の IP アドレス指定プランを設計する。以下のような点を考慮します。

### 一般公開クラスタノードと限定公開クラスタノード
#### 設計例
* 一般公開クラスタ:
    - インターネットからアクセス可能なWebアプリケーションをデプロイする
    - ロードバランサーを使用して、複数のノードに負荷分散を行う
* 限定公開クラスタ:
    - 内部ネットワークで利用するマイクロサービスをデプロイする
    - プライベートサービスコネクトを使用して、他のGCPサービスと接続する
#### 注意点
* 限定公開クラスタの制限:
    - Kubernetes Dashboardへのアクセスは、プライベートIPアドレスから行う必要があります。
    - ノードへのSSH接続も、プライベートIPアドレスから行う必要があります。
* IPアドレス枯渇: IPアドレスを効率的に利用するため、適切なCIDRブロックを割り当て、サブネットを分割する必要があります。
* セキュリティ: ファイアウォールルールを厳格に設定し、不要なアクセスを遮断する必要があります。


### コントロール プレーンのパブリック エンドポイントとプライベート エンドポイント
#### 設計例
* パブリックエンドポイント:
     - インターネットからGKEクラスタを管理したい場合
     - 負荷分散を使用して、複数のクラスタへのアクセスを集中管理したい場合
* プライベートエンドポイント:
     - 内部ネットワークからのみGKEクラスタを管理したい場合
     - 高いセキュリティが求められる環境でGKEを利用する場合
     - オンプレミス環境とGKEを連携させる場合
#### 注意点
* プライベートエンドポイントの制限:
     - プライベートエンドポイントを使用する場合、インターネットから直接コントロールプレーンにアクセスすることはできません。
     - VPCサービスコントロールの設定が複雑になる場合があります。
* DNS設定: プライベートエンドポイントを使用する場合、DNS設定を適切に行う必要があります。


### サブネットとエイリアス IP
#### 設計例
* 大規模なウェブアプリケーション:
     - フロントエンド、バックエンド、データベースをそれぞれ異なるサブネットに配置
     - 各サブネットに適切なCIDRブロックを割り当て
     - エイリアスIPを利用して、Pod IPアドレス空間を拡張
* マイクロサービスアーキテクチャ:
     - 各マイクロサービスを異なるサブネットに配置
     - サービスメッシュを利用して、サービス間の通信を制御
     - エイリアスIPを利用して、サービス間のトラフィックを分離
#### 注意点
* IPアドレスの重複: サブネットやエイリアスIPの範囲が重複しないように注意する。
* ルーティング: サブネット間のルーティングを正しく設定する。
* セキュリティ: ファイアウォールルールを適切に設定し、不要なトラフィックを遮断する。

### RFC 1918、RFC 1918 以外、プライベートで使用されるパブリック IP（PUPI）アドレス オプション
#### 設計例
* RFC 1918アドレス:
     - 内部ネットワークで稼働するマイクロサービス
     - オンプレミスとの接続
* RFC 1918以外アドレス:
     - インターネットからアクセス可能なWebアプリケーション
     - Cloud Load Balancingを利用した負荷分散
* PUPIアドレス:
     - プライベートIP環境で、パブリックIPアドレスを必要とするサービス
#### 注意点
* アドレス枯渇: IPアドレスを効率的に利用するため、CIDRブロックを適切に割り当てる。
* ルーティング: 複雑なネットワーク構成では、ルーティングの設定に注意が必要。
* セキュリティ: ファイアウォールルールを適切に設定し、不要なアクセスを遮断する。


# セクション 2: Virtual Private Cloud（VPC）インスタンスの実装（試験内容の約 21%）

## 2.1 VPC を構成する。以下のような点を考察します。

### Google Cloud VPC のリソース（例: ネットワーク、サブネット、ファイアウォール ルールなど）
#### 設計のポイント
* ワークロードの分離: 異なる種類のワークロードを別のサブネットに配置することで、セキュリティを高め、トラブルシューティングを容易にします。
* セキュリティ: ファイアウォールルールを厳格に設定し、不要なアクセスを遮断します。
* スケーラビリティ: 将来的にネットワークが拡大することを考慮し、柔軟な設計を行います。
* パフォーマンス: ネットワーク遅延を最小限に抑えるために、適切なサブネット設計を行います。
* コスト: 利用するリソースに応じてコストが変動するため、コストを考慮した設計を行います。
#### 設計手順
* ワークロードの分析: デプロイするアプリケーションの種類、規模、セキュリティ要件などを分析します。
* VPCの作成: VPCネットワークを作成し、カスタムモードまたはオートサブネットモードを選択します。
* サブネットの作成: 各ワークロードに対応するサブネットを作成し、IPアドレス範囲を割り当てます。
* ファイアウォールルールの設定: 入出力のトラフィックを制御するためのファイアウォールルールを設定します。
* ルーティングの設定: トラフィックの転送先を決定するためのルートテーブルを設定します。
* その他のリソースの設定: 必要に応じて、VPN、Cloud NAT、Cloud Load Balancingなどを設定します。

### VPC ネットワーク ピアリング

### 共有 VPC ネットワークの作成と他のプロジェクトとのサブネットの共有
#### 共有VPCネットワークの活用例
* 複数のチームが共通のネットワークを利用する環境:
    - 各チームが独自のプロジェクトを持ちながら、共通のネットワークリソースを利用できます。
* マルチクラウド環境:
    - 複数のクラウドプロバイダーの環境を統合し、一元管理できます。
* オンプレミスとの接続:
    - オンプレミス環境とGCP環境をVPNで接続し、共通のネットワークとして利用できます。
#### 注意点
* ホストプロジェクトの重要性: ホストプロジェクトの可用性は、すべてのサービスプロジェクトに影響するため、高可用性設計が重要です。
* 権限管理: 各プロジェクトの権限を適切に管理することで、セキュリティリスクを軽減できます。
* ネットワーク設計の複雑化: 共有VPCは、ネットワーク設計を複雑にする可能性があります。

### Google サービスへの API アクセス（例: 限定公開の Google アクセス、公開インターフェースなど）

### 作成後の VPC サブネット範囲の拡大
#### サブネット範囲拡大の必要性と注意点
Google Cloud VPCのサブネット範囲は、一度作成すると変更が制限されます。これは、ネットワーク設定の安定性とセキュリティを確保するためです。しかし、以下のような状況でサブネット範囲の拡大が必要になることがあります。

* IPアドレスの枯渇: 予想以上に多くのインスタンスが作成され、IPアドレスが不足する場合。
* ネットワーク設計の変更: ネットワーク構成を変更し、サブネットのIPアドレス範囲を調整する必要がある場合。
*** ただし、サブネット範囲を拡大する際には、以下の点に注意が必要です。***

* 既存リソースへの影響: サブネット範囲の変更は、そのサブネットに属する既存のリソースに影響を与える可能性があります。
* ルーティング設定: ルーティングテーブルの設定を見直す必要がある場合があります。
* ファイアウォールルール: ファイアウォールルールも、拡大されたIPアドレス範囲に対応するように調整する必要があります。
* ダウンタイム: サブネット範囲の拡大作業中に、一時的にネットワーク接続が中断される可能性があります。

#### サブネット範囲拡大の手順
1. 新しいサブネットの作成:
    - 既存のサブネットと同じリージョンに、新しいサブネットを作成します。
    - 新しいサブネットのIPアドレス範囲は、既存のサブネット範囲とオーバーラップしないように注意します。
2. リソースの移行:
     - 既存のサブネットから、新しいサブネットへリソースを移行します。
    - インスタンスの場合は、停止して再起動することで、新しいサブネットに割り当てられます。
3. ルーティング設定の変更:
    - ルーティングテーブルを更新し、新しいサブネットへのルーティングを追加します。
4. ファイアウォールルールの調整:
    - ファイアウォールルールを、新しいIPアドレス範囲に対応するように調整します。
#### 代替案: セカンダリIP範囲の利用
サブネット範囲の拡大に代わる方法として、セカンダリIP範囲（エイリアスIP）の利用が考えられます。セカンダリIP範囲は、一つのインスタンスに複数のIPアドレスを割り当てることができる機能です。

* メリット:
    - サブネット範囲を変更せずに、IPアドレスを増やすことができる。
    - 柔軟なIPアドレス管理が可能。
* デメリット:
    - すべてのインスタンスがセカンダリIP範囲に対応しているわけではない。
    - 複雑なネットワーク構成になる可能性がある。

## 2.2 ルーティングを構成する。以下のような点を考慮します。

### 静的ルーティングと動的ルーティング
#### 静的ルーティングの活用例
* シンプルなネットワーク: 少数のサブネット間の通信で構成されるシンプルなネットワーク
* 特定のトラフィックの制御: 特定の宛先へのトラフィックを常に特定の経路で転送したい場合
* 冗長性の低い環境: ルーティングプロトコルの障害に耐えられない環境
#### 動的ルーティングの活用例
* 大規模なネットワーク: 多くのサブネットやルーターが存在する大規模なネットワーク
* 複雑なネットワーク: 複数のルーティング領域やポリシーが存在する複雑なネットワーク
* 冗長性の高い環境: ルーティングプロトコルによる自動的な経路選択により、障害発生時の復旧が早い
### Google Cloudにおけるルーティングの設定
Google Cloudでは、Cloud Routerを使用して、VPCネットワーク間のルーティングを設定できます。Cloud Routerは、BGP（Border Gateway Protocol）をサポートしており、動的なルーティング環境を構築することができます。
#### 静的ルートの設定:
* 手順: Google Cloud Consoleまたはgcloudコマンドを使用して、手動でルートを追加します。
* 用途: 特定の宛先へのトラフィックを常に特定の経路で転送したい場合に利用します。
#### 動的ルートの設定:
* 手順: Cloud Routerを構成し、BGPピアリングを設定することで、他のネットワークとの間で動的なルーティング情報を交換します。
* 用途: 大規模なネットワークや、複数のネットワーク間の接続を構築する場合に利用します。

### グローバルとリージョン範囲での動的ルーティング
#### グローバル動的ルーティングの活用例
* 大規模なマルチリージョン展開: 複数のリージョンに分散してサービスを提供する場合
* グローバルなロードバランシング: グローバルな負荷分散を実現したい場合
* ハイブリッドクラウド環境: オンプレミス環境と複数のリージョンを接続する場合
#### リージョン動的ルーティングの活用例
* 特定のリージョンに限定されたサービス: 特定のリージョンでサービスを提供する場合
* セキュリティ重視の環境: ネットワークの範囲を限定することで、セキュリティリスクを軽減したい場合
#### Google Cloudにおける動的ルーティングの設定
Google Cloudでは、Cloud Routerを使用して動的ルーティングを設定します。Cloud Routerは、BGP（Border Gateway Protocol）をサポートしており、他のネットワークとの間で動的なルーティング情報を交換することができます。

* 動的ルーティングモードの設定: Cloud Routerを作成する際に、動的ルーティングモードを「グローバル」または「リージョン」に設定します。
* BGPピアリングの設定: Cloud Routerと他のネットワークとの間でBGPピアリングを設定します。
* ルートフィルタリング: BGPポリシーを使用して、アドバタイズするルートや受け入れるルートをフィルタリングします。

### タグと優先度を使用したルーティング ポリシー
Google Cloud VPCでは、タグと優先度を利用することで、非常に細粒度のルーティングポリシーを構築できます。これにより、特定のインスタンスやサブネットへのトラフィックを、柔軟かつ正確に制御することが可能になります。

#### タグと優先度の利用方法
* ネットワークタグ: インスタンスやサブネットにタグを付与します。
* ルートタグ: ルートにタグを付与します。
* 優先度: ルートに優先度を設定します。優先度が低いルートは、優先度が高いルートと競合した場合に無視されます。
#### 例:

* シナリオ: Webサーバーのトラフィックを、特定のロードバランサーにルーティングしたい。
* 設定:
    - Webサーバーのインスタンスに「webserver」というタグを付与する。
    - ロードバランサーのIPアドレスへのルートを作成し、「webserver」というタグと高い優先度を設定する。
    - この設定により、タグ「webserver」を持つインスタンスからのトラフィックは、必ず指定されたロードバランサーを経由するようになります。
#### ルーティングポリシーの活用例
* 特定のアプリケーションへのトラフィックの分離: 異なるアプリケーションを異なるサブネットに配置し、タグと優先度を利用してトラフィックを分離します。
* 多重ホーム接続の管理: 複数のインターネット接続を持つ場合、タグと優先度を利用して、異なる接続へのトラフィックの振り分けを制御します。
* ポリシーベースルーティング (PBR): パケットの宛先 IP アドレス以外の要素に基づいてネクストホップを選択することができます。プロトコルや送信元 IP アドレスでトラフィックを照合することも可能です。

### ネクストホップとしての内部ロードバランサ
Google Cloud VPCにおいて、ルーティングテーブルのネクストホップに内部ロードバランサを指定することで、特定のトラフィックを内部ロードバランサに転送し、複数のバックエンドサーバに分散させることができます。これにより、高可用性、スケーラビリティ、負荷分散を実現できます。

#### 内部ロードバランサをネクストホップとして利用する際の注意点
* 内部ロードバランサの種類: 内部ロードバランサには、HTTP(S)ロードバランサ、TCPロードバランサ、UDPロードバランサなど、様々な種類があります。それぞれのロードバランサの特性を理解し、適切な種類を選択する必要があります。
* ヘルスチェック: バックエンドサーバの健康状態を監視するためのヘルスチェックを設定する必要があります。ヘルスチェックに異常が発生した場合、内部ロードバランサは当該のバックエンドサーバへのトラフィックを停止します。
* ルーティングテーブルの設定: ルーティングテーブルに、内部ロードバランサのIPアドレスをネクストホップとして設定する必要があります。
* セキュリティ: 内部ロードバランサへのアクセス制御を適切に行う必要があります。

#### 設定手順
1. 内部ロードバランサの作成: Google Cloud Consoleまたはgcloudコマンドを使用して、内部ロードバランサを作成します。
2. バックエンドサーバの登録: 内部ロードバランサに、バックエンドサーバを登録します。
3. ヘルスチェックの設定: バックエンドサーバの健康状態を監視するためのヘルスチェックを設定します。
4. ルーティングテーブルの設定: ルーティングテーブルに、内部ロードバランサのIPアドレスをネクストホップとして設定します。

### VPC ネットワーク ピアリングを介したカスタムルートのインポートとエクスポート
#### 活用事例
* マルチクラウド環境: 異なるクラウドプロバイダー間のネットワーク接続を実現する。
* 複数のプロジェクト間の連携: 異なるプロジェクトで管理されているVPCを接続し、リソースを共有する。
* ハイブリッドクラウド環境: オンプレミス環境とクラウド環境を接続する。
#### 設定手順
* VPC ネットワーク ピアリングの作成: Google Cloud Consoleまたはgcloudコマンドを使用して、ピアリング接続を作成します。
* カスタムルートのインポート/エクスポート: ピアリング接続の設定画面で、カスタムルートのインポート/エクスポートを有効にします。
* ルートテーブルの更新: カスタムルートが追加されたことを確認し、必要に応じてルーティングテーブルを更新します。


## 2.3 Google Kubernetes Engine クラスタの構成と保守を行う。以下のような点を考慮します。

### エイリアス IP を使用した VPC ネイティブ クラスタ

### 共有 VPC を使用したクラスタ

### Kubernetes ネットワーク ポリシーの作成

### 限定公開クラスタとコントロール プレーンのプライベート エンドポイント

### クラスタ コントロール プレーン エンドポイント用の承認済みネットワークの追加

## 2.4 ファイアウォール ルールを構成、管理する。 以下のような点を考慮します。

### ターゲット ネットワーク タグとサービス アカウント

### ルールの優先度

### ネットワーク プロトコル

### 上り / 下りルール

### ファイアウォール ルールのロギング

### ファイアウォール インサイト

### 階層型ファイアウォール

## 2.5 VPC Service Controls を実装する。 以下のような点を考慮します。

### アクセスレベルとサービス境界の作成および構成

### VPC のアクセス可能なサービス

### 境界ブリッジ

### 監査ロギング

### ドライラン モード


# セクション 3: ネットワーク サービスの構成（試験内容の約 23%）

## 3.1 ロード バランシングを構成する。以下のような点を考慮します。

### バックエンド サービスとネットワーク エンドポイント グループ（NEG）

### バックエンド サービスへのトラフィックとヘルスチェックを許可するファイアウォール ルール

### バックエンド サービスとターゲット インスタンス グループのヘルスチェック

### 分散方式を使用したバックエンドおよびバックエンド サービスの構成（例: RPS、CPU、カスタムなど）、セッション アフィニティ、容量スケーリング/スケーラー

### TCP および SSL プロキシ ロードバランサ

### ロードバランサ（例: 外部 TCP/UDP ネットワーク負荷分散、内部 TCP/UDP 負荷分散、外部 HTTP(S) 負荷分散、内部 HTTP(S) 負荷分散など）

### プロトコル転送

### ワークロードの増加への対応（自動スケーリングと手動スケーリングそれぞれを使用した場合）

## 3.2 Google Cloud Armor ポリシーを構成する。 以下のような点を考慮します。

### セキュリティ ポリシー

### ウェブ アプリケーション ファイアウォール（WAF）ルール（例: SQL インジェクション、クロスサイト スクリプティング、リモート ファイル インクルードなど）

### ロードバランサ バックエンドへのセキュリティ ポリシーの接続

## 3.3 Cloud CDN の構成以下のような点を考慮します。

### 有効化と無効化

### Cloud CDN

### キャッシュキー無効化キャッシュ オブジェクト

### 署名付き URL

### カスタム送信元

## 3.4 Cloud DNS の構成と保守を行う。以下のような点を考察します。

### ゾーンとレコードの管理

### Cloud DNS への移行

### DNS Security Extensions（DNSSEC）

### 転送と DNS サーバー ポリシー

### オンプレミス DNS と Google Cloud の統合

### スプリット ホライズン DNS

### DNS ピアリング

### 限定公開 DNS のロギング

## 3.5 Cloud NAT を構成する。以下のような点を考察します。

### アドレス指定

### ポートの割り振り

### タイムアウトのカスタマイズ

### ロギングとモニタリング

### 組織のポリシーの制約ごとの制限

## 3.6 ネットワーク パケット インスペクションを構成する。 以下のような点を考察します。

### 単一 VPC トポロジとマルチ VPC トポロジでの Packet Mirroring

### Packet Mirroring のソースとトラフィックのフィルタを使用した関連トラフィックのキャプチャ

### マルチ NIC VM（次世代のファイアウォール アプライアンスなど）を使用した VPC 間トラフィックのルーティングと検査

### 高可用性マルチ NIC VM ルーティングのネクストホップとしての内部ロードバランサの構成


# セクション 4: ハイブリッド相互接続の実装（試験内容の約 14%）

## 4.1 Cloud Interconnect を構成する。 以下のような点を考慮します。

### Dedicated Interconnect 接続と VLAN アタッチメント

### Partner Interconnect 接続と VLAN アタッチメント

## 4.2 サイト間 IPsec VPN を構成する。 以下のような点を考慮します。

### 高可用性 VPN（動的ルーティング）

### Classic VPN（ルートベースのルーティング、ポリシーベースのルーティングなど）

## 4.3 Cloud Router を構成する。以下のような点を考慮します。

### Border Gateway Protocol（BGP）属性（例:ASN、ルート優先度/MED、リンクローカル アドレスなど）

### BGP によるカスタムルート アドバタイズ

### 信頼性が高く冗長な Cloud Router のデプロイ


# セクション 5: ネットワーク オペレーションの管理、モニタリング、最適化（試験内容の約 16%）

## 5.1 Google Cloud のオペレーション スイートを使用してロギングとモニタリングを行う。以下のような点を考慮します。

### ネットワーク コンポーネントのログの確認（例: VPN、Cloud Router、VPC Service Controls など）

### ネットワーキング コンポーネント（例: VPN、Cloud Interconnect 接続と相互接続のアタッチメント、Cloud Router、ロードバランサ、Google Cloud Armor、Cloud NAT など）

## 5.2 セキュリティを管理、維持する。 以下のような点を考慮します。

### ファイアウォール（例: クラウドベース、プライベート）

### IAM の問題の診断と解決（例: 共有 VPC、セキュリティ/ネットワーク管理者など）

## 5.3 接続性の維持管理とトラブルシューティングを行う。以下のような点を考慮します。

### HTTP(S) ロード バランシングによるトラフィック フローのドレインとリダイレクト

### フローログを使用した、上りトラフィックと下りトラフィックのモニタリング

### ファイアウォール ログとファイアウォール インサイトのモニタリング

### VPN の管理とトラブルシューティング

### Cloud Router の BGP ピアリング問題のトラブルシューティング

## 5.4 レイテンシとトラフィック フローのモニタリング、管理、トラブルシューティングを行う。以下のような点を考慮します。

### ネットワークのスループットとレイテンシのテスト

### ルーティングの問題の診断

### Network Intelligence Center を使用したトポロジの可視化、接続のテスト、パフォーマンスのモニタリング
