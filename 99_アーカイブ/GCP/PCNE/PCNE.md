 
# セクション 1: Google Cloud ネットワークの設計、計画、プロトタイピング（試験内容の約 26%）

## 1.1 全体的なネットワーク アーキテクチャを設計する。 以下のような点を考慮します。

### 高可用性、フェイルオーバー、障害復旧の戦略

ネットワークアーキテクチャを設計する際には、高可用性、フェイルオーバー、障害復旧の戦略を考慮することが非常に重要です。これらの戦略は、ネットワークの安定性と継続的なサービス提供を確保するために不可欠です。以下に、具体的な検討点と対策について詳しく解説します。

#### 1. 高可用性を実現するための戦略

高可用性とは、システムが常に利用可能な状態を維持できる能力のことです。

* **冗長化:**
    * **ハードウェア:** サーバー、ネットワーク機器、ストレージなどを二重化または多重化することで、単一の機器故障による影響を最小限に抑えます。
    * **ソフトウェア:** アプリケーションやサービスを複数のサーバーに分散配置し、負荷分散を行うことで、特定のサーバーの障害によるサービス停止を防ぎます。
* **負荷分散:**
    * 複数のサーバーにトラフィックを分散することで、単一のサーバーへの負荷を軽減し、パフォーマンスの低下を防ぎます。
* **自動化:**
    * 障害検知、復旧処理を自動化することで、人的ミスによる遅延を防ぎ、復旧時間を短縮します。

#### 2. フェイルオーバー戦略

フェイルオーバーとは、障害が発生した際に、別のシステムやコンポーネントに処理を自動的に切り替えることです。

* **フェイルオーバーグループ:**
    * 複数のサーバーをグループ化し、あるサーバーが故障した場合に、他のサーバーが自動的にその役割を引き継ぐように設定します。
* **ハートビート:**
    * 各サーバーが互いに状態を確認し合うことで、障害を早期に検知し、フェイルオーバーをトリガーします。
* **フェイルバック:**
    * フェイルオーバーしたサーバーが復旧した場合に、元のサーバーに処理を戻す仕組みです。

#### 3. 障害復旧戦略

障害復旧とは、大規模な障害が発生した場合に、システム全体を復旧させるための戦略です。

* **バックアップ:**
    * 定期的にデータのバックアップを作成し、障害発生時に復元できるようにします。
* **オフサイトバックアップ:**
    * バックアップデータを社外に保管することで、災害などの大規模な障害にも対応できます。
* **ディザスタリカバリ:**
    * 災害発生時に、別のデータセンターやクラウド環境にシステムを復旧させる計画を策定します。

#### 具体的な検討事項と対策

* **ネットワークトポロジー:**
    * 星型、メッシュ型、リング型など、ネットワークの構成によって可用性が大きく変わります。冗長な経路を確保し、単一障害点を減らすことが重要です。
* **ルーティングプロトコル:**
    * OSPF、BGPなどのルーティングプロトコルは、ネットワークの可用性に大きく影響します。冗長なルーティング経路を確保し、障害発生時に自動的に経路を切り替える必要があります。
* **DNS:**
    * DNSサーバーの冗長化、Anycast DNSの導入などにより、DNSサービスの可用性を高めます。
* **セキュリティ:**
    * DDoS攻撃などのサイバー攻撃への対策を講じることで、ネットワークの安定性を確保します。
* **監視:**
    * ネットワーク機器、サーバー、アプリケーションの状態を常時監視し、異常を早期に検知します。
* **テスト:**
    * 定期的に障害発生を想定したテストを実施し、復旧手順の有効性を確認します。


### DNS 戦略（例: オンプレミス、Cloud DNS、GSLB）
#### GSLB（Global Server Load Balancing）
* 特徴:
    - 複数のデータセンターに分散されたサーバーへの負荷分散を実現する。
    - ネットワークの遅延やユーザーの地理的な位置に基づいて最適なサーバーに接続。
* メリット:
    - グローバルなサービスのパフォーマンス向上。
    - 災害時のフェイルオーバー。
* デメリット:
    - 複雑な構成が必要となる場合がある。
    - 高度なネットワーク知識が必要。

### セキュリティとデータの引き出しの要件：✔

ネットワークアーキテクチャを設計する上で、セキュリティとデータの引き出しは非常に重要な要素です。これらの要件を満たすためには、以下のような点を考慮した設計が必要です。

#### セキュリティ対策

##### 1. アクセス制御
* **認証・認可:** ネットワークへのアクセスを、ユーザーIDとパスワード、または多要素認証を用いて厳密に管理します。
* **アクセス権限:** 各ユーザーやデバイスに、必要な最小限のアクセス権限を付与します。
* **ロールベースアクセス制御 (RBAC):** ユーザーの役割に基づいてアクセス権限を管理することで、権限の委譲を効率的に行えます。

##### 2. 暗号化
* **データの暗号化:** データの保存時、伝送時ともに、暗号化することで、不正アクセスによるデータ漏洩を防ぎます。
* **通信の暗号化:** VPNやSSL/TLSを用いて、ネットワーク通信を暗号化します。

##### 3. ファイアウォール
* **パケットフィルタリング:** 不必要なトラフィックを遮断し、攻撃の入口を減らします。
* **侵入検知・侵入防止システム (IDS/IPS):** ネットワークトラフィックを監視し、異常な通信を検知・阻止します。

##### 4. セキュリティ対策ソフトウェア
* **ウイルス対策ソフトウェア:** マルウェア感染を防ぎます。
* **脆弱性スキャナ:** システムの脆弱性を定期的にスキャンし、パッチを適用します。

##### 5. セキュリティポリシー
* **明確なセキュリティポリシー:** セキュリティに関する規則を明確化し、全従業員に周知徹底させます。
* **定期的な見直し:** セキュリティ脅威は常に変化するため、定期的にセキュリティポリシーを見直す必要があります。

#### データの引き出し対策

##### 1. データ漏洩防止
* **データ分類:** データの重要度に応じて、異なるレベルのセキュリティ対策を適用します。
* **データ損失防止 (DLP):** 機密情報の外部への持ち出しを防止します。
* **ログの記録と分析:** ネットワーク上の活動を記録し、異常な活動を検知します。

##### 2. バックアップ
* **定期的なバックアップ:** データの損失に備え、定期的にデータをバックアップします。
* **オフサイトバックアップ:** 災害や火災などのリスクに備え、バックアップデータを社外に保管します。

##### 3. 災害復旧計画
* **災害発生時の対応:** 災害発生時に迅速にシステムを復旧させるための計画を策定します。

##### 設計時の考慮事項

* **ゼロトラストアーキテクチャ:** ネットワーク内のすべてのデバイスを信頼せず、厳格な認証と認可を行うアーキテクチャです。
* **マイクロセグメンテーション:** ネットワークを小さなセグメントに分割し、攻撃の影響範囲を限定します。
* **クラウドセキュリティ:** クラウドサービスを利用する場合は、クラウドプロバイダーのセキュリティ機能を最大限に活用し、自社のセキュリティポリシーとの整合性を確保します。

##### 具体的な検討例

* **データセンターの配置:** 複数のデータセンターに分散配置することで、単一の拠点の障害による影響を最小限に抑えます。
* **ネットワーク分割:** DMZ (Demilitarized Zone) を設置し、外部ネットワークとの間を分離します。
* **VPNの利用:** リモートアクセスにVPNを利用することで、安全な接続を確保します。
* **多要素認証の導入:** パスワードに加えて、生体認証やワンタイムパスワードなどを組み合わせることで、認証の強度を高めます。

##### 設計のポイント

* **リスクアセスメント:** ネットワークに潜むリスクを特定し、優先順位付けを行います。
* **層状防御:** 複数のセキュリティ対策を組み合わせることで、防御の堅牢性を高めます。
* **継続的な改善:** セキュリティ脅威は常に変化するため、常に最新のセキュリティ対策を導入し、システムを改善していく必要があります。

### 負荷分散：✔

ネットワークアーキテクチャ設計において、負荷分散は、システムの可用性、パフォーマンス、スケーラビリティを向上させる上で非常に重要な要素です。負荷分散によって、複数のサーバーにトラフィックを分散することで、単一のサーバーへの負荷を軽減し、システム全体の安定性を高めることができます。

#### 負荷分散の目的

* **高可用性:** 一つのサーバーが故障した場合でも、他のサーバーが処理を引き継ぎ、サービスの中断を最小限に抑えます。
* **パフォーマンス向上:** 複数のサーバーで処理を分散することで、処理能力を向上させ、応答時間を短縮します。
* **スケーラビリティ:** 負荷が増加した場合に、簡単にサーバーを追加することで、システムの処理能力を拡張できます。

#### 負荷分散の方式

* **ハードウェア型負荷分散:** 専用の負荷分散装置を使用する方式です。高性能で、大規模なネットワークに適しています。
* **ソフトウェア型負荷分散:** サーバーに負荷分散ソフトウェアをインストールする方式です。柔軟性が高く、コストを抑えられるのが特徴です。
* **クラウド型負荷分散:** クラウドサービスが提供する負荷分散機能を利用する方式です。手軽に導入でき、スケーラビリティが高いのが特徴です。

#### 負荷分散アルゴリズム

* **ラウンドロビン:** 各リクエストを順番にサーバーに割り当てる方式です。
* **最小接続:** 接続数が最も少ないサーバーにリクエストを割り当てる方式です。
* **最速応答:** 応答時間が最も短いサーバーにリクエストを割り当てる方式です。
* **重み付けラウンドロビン:** 各サーバーに重みを設定し、重みに応じてリクエストを割り当てる方式です。
* **IPハッシュ:** クライアントのIPアドレスに基づいて、常に同じサーバーにリクエストを割り当てる方式です。

#### 負荷分散の検討事項

* **アプリケーションの種類:** 状態を持たないステートレスなアプリケーションと、状態を持つステートフルなアプリケーションでは、負荷分散の方式が異なります。
* **セッション管理:** ステートフルなアプリケーションでは、セッション情報を保持する必要があります。
* **健康状態チェック:** サーバーの稼働状況を監視し、故障したサーバーを自動的に除外する必要があります。
* **ネットワーク構成:** 負荷分散装置の設置場所、ネットワーク帯域幅、遅延などを考慮する必要があります。
* **コスト:** ハードウェア、ソフトウェア、運用コストなどを総合的に評価する必要があります。

#### 具体的な検討例

* **Webサーバーの負荷分散:** HTTPリクエストを複数のWebサーバーに分散することで、Webサイトのアクセス集中によるダウンを防ぎます。
* **データベースサーバーの負荷分散:** 読み込み処理を複数のデータベースサーバーに分散することで、データベースサーバーの負荷を軽減します。
* **アプリケーションサーバーの負荷分散:** アプリケーション処理を複数のアプリケーションサーバーに分散することで、システム全体の処理能力を向上させます。

#### 設計のポイント

* **負荷分散の目的を明確にする:** 高可用性、パフォーマンス向上、スケーラビリティなど、どのような目的で負荷分散を行うのかを明確にすることが重要です。
* **適切な負荷分散方式を選択する:** アプリケーションの種類、ネットワーク環境、コストなどを考慮して、最適な負荷分散方式を選択します。
* **健康状態チェックを徹底する:** サーバーの故障を早期に検知し、迅速に復旧させることが重要です。
* **定期的な見直し:** システムの状況に合わせて、負荷分散の設定を見直す必要があります。

#### まとめ

負荷分散は、ネットワークアーキテクチャ設計において、システムの信頼性とパフォーマンスを向上させるために不可欠な要素です。適切な負荷分散の設計を行うことで、システムの可用性を高め、ユーザーに安定したサービスを提供することができます。


### プロジェクトごとおよび VPC ごとの割り当ての適用：✔
#### 割り当ての具体的な例
* 開発環境と本番環境の分離: 開発環境と本番環境を異なるプロジェクトに割り当てることで、誤って本番環境のデータを変更してしまうリスクを軽減できます。
* アプリケーションごとの分離: 各アプリケーションを別のプロジェクトに割り当てることで、アプリケーション間の影響を最小限に抑え、障害発生時の影響範囲を限定できます。
* 地域ごとの分離: 地域ごとにプロジェクトを分けることで、データ主権や規制への対応を容易にします。
#### 割り当ての検討時の注意点
* 過度な分割: プロジェクトを細かく分割しすぎると、管理が複雑になる可能性があります。
* 柔軟性: 将来的にプロジェクトの構成を変更できるよう、柔軟な設計を心掛けましょう。
* コスト: プロジェクトの作成や管理には、一定のコストがかかります。コストとメリットを比較検討し、最適な割り当てを決定しましょう。


### ハイブリッド接続（例: 限定公開の Google アクセスを使用したハイブリッド接続）
ハイブリッド接続は、オンプレミス環境とクラウド環境を連携させることで、それぞれの強みを活かしたシステムを構築する手法です。特に、限定公開の Google アクセスを利用したハイブリッド接続は、セキュリティを確保しつつ、オンプレミス環境からGoogle Cloud Platform (GCP) のサービスへ安全にアクセスするための有効な手段となります。

#### ハイブリッド接続設計における検討事項
1. 接続方法の選択
* VPN: 仮想プライベートネットワークは、最も一般的な接続方法です。IPsec VPNやSSL VPNなど、さまざまな種類があります。
* Interconnect: 専用線を利用した高帯域幅、低遅延の接続方法です。大規模なデータ転送や高可用性が求められる場合に適しています。
* 限定公開の Google アクセス: オンプレミスからGCPへのプライベートなアクセスを提供します。インターネットを経由しないため、セキュリティが向上します。
2. ネットワーク設計
* DMZ: デミリタライズドゾーンを設置し、オンプレミスネットワークとGCPネットワークを分離することで、セキュリティを強化します。
* サブネット設計: 各サブネットの役割を明確にし、アクセス制御リスト (ACL) を設定することで、ネットワークトラフィックを制御します。
* ルーティング: 静的ルーティングと動的ルーティングを適切に組み合わせ、パケットが確実に目的地に到達するようにします。
3. セキュリティ
* 認証・認可: 認証方式（ID/パスワード、多要素認証など）と認可方式（ロールベースアクセス制御など）を適切に設定します。
* 暗号化: 通信データを暗号化することで、データ漏洩を防ぎます。
* ファイアウォール: ファイアウォールルールを厳密に設定し、不要なトラフィックを遮断します。
* IDS/IPS: 侵入検知・侵入防止システムを導入し、セキュリティインシデントを早期に検知し対応します。
4. パフォーマンス
* 帯域幅: 必要な帯域幅を確保し、ネットワーク遅延を最小限に抑えます。
* QoS: Quality of Serviceを設定し、重要なトラフィックを優先的に処理します。
5. 可用性
* 冗長化: 複数の接続経路を確保し、障害発生時の影響を最小限に抑えます。
* フェイルオーバー: 障害が発生した場合に、自動的に別の経路に切り替える仕組みを構築します。
6. コスト

#### 限定公開の Google アクセスを利用したハイブリッド接続の設計ポイント
* プライベートIPアドレス: オンプレミスとGCPの間にプライベートIPアドレス空間を構築することで、インターネットを経由しないセキュアな通信を実現します。
* Cloud Router: Cloud Routerを使用して、オンプレミスとGCP間のルーティングを管理します。
* VPNトンネル: Cloud VPNトンネルを確立し、両環境を接続します。
* ファイアウォールルール: ファイアウォールルールを厳密に設定することで、許可されたトラフィックのみを通過させます。

### コンテナ ネットワーキング
コンテナネットワーキングは、コンテナ化されたアプリケーションが互いに通信し、また外部ネットワークと通信するための仕組みです。従来の仮想化ネットワークと比較して、より軽量で柔軟なネットワーク環境を提供します。

#### コンテナネットワーキングの設計における考慮事項
1. ネットワークモデルの選択
* Overlay Network: 物理ネットワークとは別に、仮想的なネットワークを構築する方式です。
    - メリット: 柔軟性が高く、複雑なネットワーク構成に対応しやすい。
    - デメリット: パフォーマンスが物理ネットワークに比べて低下する可能性がある。
* Underlay Network: 物理ネットワーク上に直接コンテナを配置する方式です。
    - メリット: パフォーマンスが高く、シンプルな構成で済む。
    - デメリット: 柔軟性が低い。
2. ネットワークプラグインの選択
* CNI (Container Network Interface): コンテナとネットワークを接続するための標準インターフェースです。
    - Flannel: シンプルで使いやすいプラグイン。
    - Calico: 大規模なネットワークに適しており、セキュリティ機能が充実している。
    - Weave Net: 高度なネットワーク機能を提供するプラグイン。
3. サービス発見
* Service Discovery: コンテナのIPアドレスやポート番号を動的に管理し、他のコンテナからサービスを検出できるようにする仕組みです。
    - Kubernetes Service: Kubernetesクラスタ内のサービスを自動的に検出します。
    - Consul: 分散型のサービス発見ツールです。
4. セキュリティ
* ネットワークポリシー: 各コンテナへのアクセスを制限するネットワークポリシーを設定します。
* TLS: コンテナ間の通信を暗号化します。
* アイデンティティ管理: 各コンテナに固有のアイデンティティを付与し、認証・認可を行います。
5. パフォーマンス
* ネットワーク帯域幅: コンテナ間の通信に十分な帯域幅を確保します。
* 遅延: ネットワーク遅延を最小限に抑えるために、適切なネットワーク設計を行います。


#### コンテナネットワーキングの設計例
* マイクロサービスアーキテクチャ: 各マイクロサービスを別のコンテナに配置し、サービスメッシュを用いて通信を管理します。
* Kubernetesクラスタ: Kubernetesクラスタ内に複数の名前空間を作成し、各名前空間に異なるアプリケーションを配置します。
* サーバーレスアーキテクチャ: サーバーレス関数を実行するためのコンテナを動的に作成し、イベントドリブンな処理を実現します。

### IAM ロール

### SaaS、PaaS、IaaS サービス

### セキュリティ目的でのマイクロセグメンテーション（例: メタデータ、タグ、サービス アカウントの使用）

#### マイクロセグメンテーションとは？

マイクロセグメンテーションは、従来のネットワークセグメンテーションをさらに細分化し、個々のワークロード（サーバー、コンテナなど）単位でセキュリティポリシーを適用する技術です。これにより、ネットワーク内の攻撃範囲を最小限に抑え、セキュリティを大幅に強化することができます。

#### マイクロセグメンテーションにおけるメタデータ、タグ、サービスアカウントの活用

##### メタデータ
* **ワークロードの識別:** 各ワークロードに固有のメタデータを付与することで、そのワークロードがどのような役割を果たしているのかを明確にします。
* **ポリシーの適用:** メタデータに基づいて、ワークロード間の通信を許可または禁止するポリシーを定義します。
* **例:**
    * 環境（開発、本番）
    * アプリケーションの種類（Webサーバー、データベース）
    * 所有者（部署、チーム）

##### タグ
* **柔軟な分類:** ワークロードに複数のタグを付与することで、より詳細な分類が可能になります。
* **動的なポリシー:** タグに基づいて、ポリシーを動的に変更することができます。
* **例:**
    * Tier（Tier1、Tier2）
    * リージョン（東京、大阪）
    * プロジェクト名

##### サービスアカウント
* **権限の管理:** 各ワークロードに専用のサービスアカウントを割り当てることで、最小権限の原則に基づいたアクセス制御を実現します。
* **ロールベースアクセス制御 (RBAC):** サービスアカウントに特定のロールを付与し、そのロールに紐づいた権限を付与します。
* **例:**
    * リードオンリーアクセス
    * 書き込みアクセス
    * 管理者権限

#### マイクロセグメンテーションの設計における検討事項

##### 1. **セグメントの定義:**
* **ビジネス要件:** アプリケーションの依存関係、セキュリティ要件などを考慮して、セグメントを定義します。
* **粒度:** セグメントの粒度を細かくしすぎると管理が複雑になるため、適切な粒度を設定します。

##### 2. **ポリシーの作成:**
* **許可と禁止:** ワークロード間の通信を許可するルールと禁止するルールを明確に定義します。
* **動的なポリシー:** 環境の変化に合わせて、ポリシーを動的に変更できるようにします。

##### 3. **エンフォースメント:**
* **ネットワークポリシー:** ネットワークポリシーを定義し、ネットワークトラフィックを制御します。
* **サービスメッシュ:** サービスメッシュを利用することで、マイクロサービス間の通信を制御し、セキュリティを強化できます。

##### 4. **監視と管理:**
* **ログ収集:** ネットワークトラフィックを監視し、異常な活動を検知します。
* **ポリシー違反の検出:** ポリシー違反を検出し、アラートを発報します。

#### マイクロセグメンテーションのメリット

* **セキュリティ強化:** 攻撃範囲を最小限に抑え、セキュリティ侵害の影響を軽減します。
* **コンプライアンス:** PCI DSS、GDPRなどの規制への対応を支援します。
* **レジリエンス:** システムの障害発生時における影響範囲を限定します。

#### マイクロセグメンテーションの導入事例

* **金融機関:** 顧客情報などの機密データを保護するために、マイクロセグメンテーションを導入しています。
* **医療機関:** HIPAA規制への対応のために、マイクロセグメンテーションを導入しています。
* **eコマース企業:** 顧客データの漏洩を防ぐために、マイクロセグメンテーションを導入しています。

#### まとめ

マイクロセグメンテーションは、現代のネットワーク環境において、セキュリティを強化するための重要な技術です。メタデータ、タグ、サービスアカウントを活用することで、より柔軟かつ精度の高いセキュリティポリシーを適用することができます。


## 1.2 Virtual Private Cloud（VPC）インスタンスを設計する以下のような点を考慮します。

### IP アドレスの管理とお客様所有 IP アドレスの使用（BYOIP）

### スタンドアロン VPC と共有 VPC：✔
#### 設計のポイント
* プロジェクトの特性: 各プロジェクトの規模、セキュリティ要件、リソースの利用状況などを考慮して、最適なVPCを選択する。
* ネットワーク設計: サブネットの分割、ルーティングの設定、ファイアウォールルールの設定などを適切に行う。
* IAM: IAMポリシーを細かく設定し、権限の最小化を図る。
* モニタリング: ネットワークの状況を継続的に監視し、問題が発生した場合に迅速に対応する。

### 複数と単一

### リージョンとマルチリージョンの比較：✔
#### リージョンとマルチリージョンを選択する際の考慮事項
* アプリケーションの性質:
    - ミッションクリティカルなアプリケーション: 高可用性が求められるため、マルチリージョンが適している。
    - 低遅延が求められるアプリケーション: リージョン内に配置することで、遅延を最小限に抑えることができる。
* データの地域性:
    - データの保存場所が規制されている場合は、その地域のリージョンを選択する必要がある。
* コスト:
    - コストが厳しく制限されている場合は、リージョンを選択し、必要な機能のみを有効にする。
* 災害復旧:
    - 災害発生時にサービスを継続するために、マルチリージョンが有効。
#### マルチリージョンの実装方法
* リージョン間のレプリケーション: データベースやストレージを複数のリージョンにレプリケートすることで、データの可用性を高める。
* ロードバランシング: 複数のリージョンに配置されたインスタンスにトラフィックを分散させる。
* リージョン間VPN: 複数のリージョン間のプライベートネットワーク接続を確立する。

### VPC ネットワーク ピアリング：✔
#### VPC ネットワーク ピアリングを検討する理由
* リソースの共有: 異なる VPC に配置されたリソースを相互に利用できます。
* ネットワークの拡張: VPC を拡張する際に、既存の VPC との接続を容易に行えます。
* マルチクラウド環境: 複数のクラウドプロバイダを利用する場合、VPC ピアリングを利用してネットワークを統合できます。
#### VPC ネットワーク ピアリングの設計における考慮事項
1. ピアリングする VPC の決定
    * プロジェクト構造: どのプロジェクトの VPC をピアリングするかを決定します。
    * リソースの配置: ピアリングする VPC に配置するリソースの種類と役割を明確にします。
2. サブネット設計
    * CIDR範囲: ピアリングする VPC の CIDR 範囲が重複しないように注意します。
    * ルーティング: 各 VPC 間のルーティングを適切に設定します。
3. セキュリティ
    * ファイアウォール: ファイアウォールルールを設定し、許可するトラフィックを制限します。
    * IAM: IAM (Identity and Access Management) を利用して、アクセス権限を管理します。
    * VPN: 必要に応じて、VPN を利用してセキュリティを強化します。
4. パフォーマンス
    * ネットワーク遅延: ピアリングによるネットワーク遅延を考慮し、アプリケーションの要件に合わせた設計を行います。
    * 帯域幅: 必要な帯域幅を確保します。
5. コスト
    * データ転送量: ピアリングによるデータ転送量に応じて、コストが発生します。
    * 維持費: VPC ピアリングの設定や管理に、一定のコストがかかります。
#### VPC ネットワーク ピアリングの設計例
* 複数の環境の接続: 開発環境、ステージング環境、本番環境の VPC をピアリングし、共通のリソースを共有します。
* 異なるリージョンの接続: 異なるリージョンに配置された VPC をピアリングし、災害復旧や負荷分散を実現します。
* マルチクラウド環境: GCP と他のクラウドプロバイダの VPC をピアリングし、ハイブリッドクラウド環境を構築します。
#### VPC ネットワーク ピアリングの注意点
* 推移的ピアリングは不可: 直接ピアリングした VPC 間でのみ通信が可能です。
* CIDR の重複: ピアリングする VPC の CIDR 範囲が重複すると、ネットワーク障害が発生する可能性があります。
* セキュリティリスク: ファイアウォールルールを適切に設定しないと、セキュリティリスクが高まります。

### ファイアウォール（サービス アカウント ベース、タグベースなど）：✔
#### ファイアウォール設計の検討事項
1. ファイアウォールの種類
* VPC ファイアウォール: VPC レベルでトラフィックを制御します。
    - ルール: プロトコル、ポート、IPアドレス、タグなどを指定してルールを作成します。
    - 適用範囲: 全てのインスタンスに適用されます。
* Cloud NGFW: より高度なファイアウォール機能を提供します。
    - 機能: IPS、IDS、URLフィルタリングなど
    - 適用範囲: VPC ファイアウォールと同様に、VPC レベルで適用できます。
2. ファイアウォールルールの作成
3. サービスアカウントベースのファイアウォール
*  原則: サービスアカウントに権限を付与し、その権限に基づいてトラフィックを制御します。
* メリット:
    - 細かい権限管理が可能
    - IAM (Identity and Access Management) と連携し、セキュリティを強化
* デメリット:
    - サービスアカウントの管理が複雑になる可能性がある
4. タグベースのファイアウォール
* 原則: インスタンスにタグを付与し、タグに基づいてトラフィックを制御します。
* メリット:
    - 柔軟なルール設定が可能
    - インスタンスの属性に基づいてルールを適用できる
* デメリット:
    - タグの管理が煩雑になる可能性がある
5. その他の考慮事項
* デフォルトルール: デフォルトでは、全てのトラフィックが拒否されるように設定することを推奨します。
* 最小権限の原則: 必要最低限の権限のみを付与します。
* 定期的なレビュー: ファイアウォールルールを定期的に見直し、必要に応じて変更します。
* ログ: ファイアウォールログを分析し、セキュリティインシデントを検出します。
#### 設計例
* 開発環境: 開発環境のインスタンスには、インターネットからのアクセスを許可し、内部ネットワークからのアクセスは制限する。
* 本番環境: 本番環境のインスタンスには、外部からのアクセスを最小限に制限し、内部ネットワークからのアクセスのみを許可する。
* データベースサーバー: データベースサーバーへのアクセスは、特定のアプリケーションからのみ許可する。


### カスタムルート

### マネージド サービス（Cloud SQL、Memorystore など）の使用：✔
#### マネージドサービスとVPCの連携方法
* プライベートIP接続:
    - マネージドサービスをプライベートIPアドレスでアクセスできるように設定することで、VPC内のインスタンスから安全にアクセスできます。
    - Cloud SQL、Memorystoreなど、多くのマネージドサービスでサポートされています。
* Cloud SQL Proxy:
    - Cloud SQLに接続するためのセキュアなプロキシサーバーです。
    - VPC内のインスタンスからCloud SQLに接続する場合に便利です。
* サーバーレス VPC アクセス:
    - Serverless VPC Accessを使用することで、Serverless Framework（Cloud Functions、Cloud Runなど）からプライベートIPアドレスを持つリソースにアクセスできます。
#### マネージドサービス利用時の考慮事項
* ネットワーク設定:
    - VPCネットワークとマネージドサービスのネットワーク設定を連携させる必要があります。
    - ファイアウォールルール、IAMポリシーなどを適切に設定する必要があります。
* セキュリティ:
    - データの暗号化、IAMによるアクセス制御、ネットワーク分離などを考慮する必要があります。
* パフォーマンス:
    - ネットワーク遅延、I/O性能などを考慮し、アプリケーションの要件に合わせたインスタンスタイプを選択する必要があります。
* コスト:
    - 利用するサービスの種類、インスタンスタイプ、ストレージ容量などによって、コストが異なります。
* 高可用性:
    - マネージドサービスのレプリケーション設定や、マルチリージョン展開などを検討することで、高可用性を確保できます。
#### 設計例
* Webアプリケーション:
    - WebサーバーをVPC内に配置し、Cloud SQLをデータベースとして利用する。
    - Cloud SQL Proxyを使用して、WebサーバーからCloud SQLに安全に接続する。
* モバイルアプリのバックエンド:
    - Cloud Functionsでバックエンドロジックを実装し、Memorystoreをキャッシュとして利用する。
    - Serverless VPC Accessを使用して、Cloud FunctionsからMemorystoreにアクセスする。



### マルチ NIC と内部ロードバランサをネクストホップまたは等価コスト マルチパス（ECMP）ルートとして使用する VPC へのサードパーティ デバイス挿入（NGFW）
Google Cloud VPCにおいて、複数のネットワークインターフェースカード（NIC）を持つインスタンスに、内部ロードバランサを介してサードパーティ製の次世代ファイアウォール（NGFW）を接続し、ECMP (Equal-Cost Multi-Path) ルートを用いて冗長化と高可用性を確保する構成は、高度なネットワーク設計となります。この構成は、大規模なネットワーク環境や高可用性が求められるシステムにおいて、より柔軟かつ安全なネットワークを実現するために有効です。

#### 各要素の役割とメリット
* マルチNIC:
    - 単一のインスタンスに複数のNICを割り当てることで、複数のネットワークに接続できます。
    - NGFWへの冗長な接続が可能になり、可用性を高めます。
* 内部ロードバランサ:
    - NGFWへのトラフィックを分散し、負荷を分散します。
    - フェイルオーバー機能により、障害発生時の影響を最小限に抑えます。
* ECMPルート:
    - 複数の経路を持つ等コストのルートを設定することで、トラフィックを複数の経路に分散させます。
    - 冗長性と可用性を高め、ネットワークのボトルネックを解消します。
* サードパーティデバイス挿入（NGFW）:
    - ネットワークトラフィックを検査し、セキュリティを強化します。
    - IPS、IDS、URLフィルタリングなどの高度なセキュリティ機能を提供します。
#### 設計のポイント
1. ネットワーク設計:
    - VPC内のサブネット設計: NGFW、インスタンス、ロードバランサを配置するサブネットを適切に設計します。
    - ルーティング: ECMPルートを設定し、トラフィックを複数の経路に分散させます。
    - ファイアウォールルール: NGFWのファイアウォールルールを適切に設定し、セキュリティを確保します。
2. インスタンス設計:
    - マルチNICインスタンスの作成: NGFWを接続するインスタンスに複数のNICを割り当てます。
    - インスタンスグループの作成: 内部ロードバランサのバックエンドとして使用するインスタンスグループを作成します。
3. 内部ロードバランサの設定:
    - ヘルスチェック: NGFWのヘルスチェックを設定し、障害発生時にトラフィックを正常なインスタンスに転送します。
    - ターゲットプール: インスタンスグループをターゲットプールに追加します。
    - バックエンドサービス: ターゲットプールとプロトコルを関連付けます。
4. カスタムルートの設定:
    - ECMPルートを作成し、複数のNGFWにトラフィックを分散させます。
5. セキュリティ:
    - IAM: IAMポリシーを使用して、アクセス権限を管理します。
    - SSL/TLS: NGFWとインスタンス間の通信を暗号化します。
#### 具体的な手順
1. VPCとサブネットの作成: NGFW、インスタンス、ロードバランサを配置するためのサブネットを作成します。
2. マルチNICインスタンスの作成: NGFWをインストールするインスタンスを作成し、複数のNICを割り当てます。
3. 内部ロードバランサの作成: ヘルスチェック、ターゲットプール、バックエンドサービスを作成します。
4. カスタムルートの作成: ECMPルートを作成し、内部ロードバランサのIPアドレスをネクストホップとして設定します。
5. NGFWの設定: NGFWのファイアウォールルール、NAT設定などを適切に行います。
6. インスタンスへの接続: インスタンスからNGFWを経由して外部ネットワークにアクセスできるように、ルートテーブルを設定します。
#### 考慮事項
* パフォーマンス: ECMPルートによるパケットの振り分けは、ハッシュ関数に基づいて行われるため、パケットロスが発生する可能性があります。
* 複雑性: 複数の要素を組み合わせるため、設定が複雑になります。
* コスト: マルチNICインスタンスや内部ロードバランサの利用により、コストが増加する可能性があります。
* ベンダー依存性: 使用するNGFWの種類によって、設定方法が異なります。


## 1.3 ハイブリッド クラウドとマルチクラウドのネットワークを設計する。 以下のような点を考慮します。

### Dedicated Interconnect と Partner Interconnect
#### 設計例
* 大規模データセンターとの接続: 大量のデータを高速かつ安全に転送するために、Dedicated Interconnectを利用する。
* 複数のリージョンへの展開: 異なるリージョンに配置された複数のクラウドプラットフォームを、Partner Interconnectで接続し、グローバルなネットワークを構築する。
* ハイブリッドクラウド環境: オンプレミス環境とGoogle Cloudを、Dedicated Interconnectで接続し、アプリケーションをハイブリッドに展開する。

### マルチクラウド接続

### ダイレクト ピアリング

### IPsec VPN
#### Google CloudにおけるIPsec VPNの構築
Google Cloudでは、Cloud VPNというマネージドVPNサービスが提供されています。Cloud VPNを利用することで、以下のメリットが得られます。

* 簡単設定: 数回のクリックでVPN接続を構築できます。
* 高可用性: 複数のゾーンにまたがってVPNゲートウェイを配置し、高可用性を確保できます。
* スケーラビリティ: 需要に応じて、VPNゲートウェイの帯域幅を柔軟に調整できます。
* 統合: Google Cloudの他のサービスとの連携が容易です。
#### 具体的な検討事項
* オンプレミス環境との接続:
    - VPNゲートウェイの配置: オンプレミス環境にVPNゲートウェイを設置し、Cloud VPNと接続します。
    - NATトラバーサル: プライベートIPアドレスを使用している場合は、NATトラバーサルを設定する必要があります。
* 他のクラウド環境との接続:
    - ピアリング: 他のクラウドプロバイダーとのピアリングを設定し、VPN接続を確立します。
* セキュリティグループ:
    - VPNトラフィックを許可するセキュリティグループを設定します。
* ルートテーブル:
    - VPNトラフィックを適切なルートテーブルに転送するように設定します。
* ダイナミックルーティング:
    - ネットワーク構成が頻繁に変わる場合は、BGPなどのダイナミックルーティングプロトコルを利用することを検討します。

### フェイルオーバーと障害復旧戦略
#### Google Cloudで実現できるフェイルオーバーと障害復旧
* リージョン間冗長化:
    - リージョンペア: 異なるリージョンにペアとなるリソースを配置し、障害発生時に自動的にフェイルオーバーを行います。
    - マルチリージョンオートメーション: TerraformやCloud Deployment Managerなどのツールを使用して、複数のリージョンへのデプロイを自動化します。
* プリエンプティブVM:
    - コストを抑えながら、高負荷時に自動的にインスタンスを増やすことができます。
    - 障害が発生した場合、新しいプリエンプティブVMを起動することで、迅速な復旧が可能です。
* マネージドサービス:
    - Cloud SQL、Cloud Storageなど、Googleが管理するサービスは、高い可用性と耐障害性を備えています。
* Cloud Load Balancing:
    - 複数のバックエンドサーバーへの負荷分散を行い、可用性を向上させます。
* Cloud CDN:
    - 静的コンテンツをグローバルに配信し、パフォーマンスを向上させるとともに、障害発生時の影響を軽減します。
* Cloud Functions:
    - イベント駆動型のサーバーレス関数で、自動化タスクを実行できます。
    - 障害検知や復旧処理を自動化するために活用できます。
#### 具体的な検討事項
* データレプリケーション:
    - Cloud SQLやCloud Spannerなどのマネージドデータベースサービスを利用することで、データのレプリケーションを自動化できます。
    - Cloud Storageのマルチリージョンバケットを活用することで、オブジェクトストレージの冗長化を実現できます。
* バックアップ:
    - Cloud Backupを利用して、仮想マシン、ディスク、データベースなどのバックアップを自動化します。
* テスト:
    - 定期的に障害復旧テストを実施し、復旧手順の有効性を確認します。
* セキュリティ:
    - 障害発生時に悪意のある攻撃を受けるリスクを考慮し、セキュリティ対策を強化します。

### リージョン ルーティング モードとグローバル VPC ルーティング モード
#### どちらのモードを選択すべきか？
##### リージョンルーティングモードを選択する場合
* 小規模なネットワーク: 複数のリージョンにまたがる大規模なネットワークではなく、単一のリージョンまたは少数のリージョンで構成されるネットワークの場合。
* セキュリティ: リージョン間の通信を制限することで、セキュリティを高めたい場合。
* 管理の簡素化: 複雑なルーティング構成を避けたい場合。
##### グローバルVPCルーティングモードを選択する場合
* 大規模なネットワーク: 複数のリージョンにまたがる大規模なネットワークで、リージョン間での通信が必要な場合。
* 高い可用性: 障害発生時に、他のリージョンにトラフィックを転送することで、可用性を高めたい場合。
* 柔軟性: ネットワーク構成を柔軟に変更したい場合。

### オンプレミスのロケーションから複数の VPC へのアクセス（例: 共有 VPC、マルチ VPC ピアリング トポロジなど）
1. 共有VPC
* 概要: 複数のプロジェクトで共通のIPアドレス空間を共有できるVPCです。
* メリット:
    - 単一のVPCとして管理できるため、シンプルで効率的
    - 複数のプロジェクト間の接続が容易
* デメリット:
    - すべてのプロジェクトが同じIPアドレス空間を共有するため、セキュリティリスクが増大する可能性がある
    - 複数のプロジェクト間のトラフィックを制御するのが難しい場合がある
2. マルチVPCピアリング
* 概要: 異なるVPC間を直接接続する機能です。
* メリット:
    - 異なるプロジェクトのVPC間でプライベートIPアドレスを使用して通信できる
    - 柔軟なネットワーク構成が可能
* デメリット:
    - 各VPCペアごとにピアリングを設定する必要があるため、管理が複雑になる可能性がある
3. Cloud Interconnect
* 概要: オンプレミスネットワークとGoogle Cloud VPCを直接接続する高帯域幅のプライベートネットワーク接続です。
* メリット:
    - 高い帯域幅と低遅延を実現できる
    - オンプレミスネットワークとの統合が容易
* デメリット:
    - コストが高い
    - 設置に時間がかかる
4. Cloud VPN
* 概要: IPsec VPNを使用して、オンプレミスネットワークとGoogle Cloud VPCを接続するサービスです。
* メリット:
    - コストが比較的安価
    - 柔軟な接続設定が可能
* デメリット:
    - 帯域幅がCloud Interconnectに比べて狭い
    - VPNの設定と管理が必要

### ハイブリッド接続ソリューションにより提供される帯域幅と制約
#### 帯域幅の制約と対処法
* Cloud VPN:
    - 帯域幅が限られているため、大容量データ転送には不向き
    - 対処法: 複数のVPNトンネルを構築することで帯域幅を増やす、Cloud Interconnectに切り替える
* Cloud Interconnect:
    - 物理的な回線のため、帯域幅の変更に時間がかかる
    - 対処法: 必要な帯域幅を事前に見積もり、余裕を持たせて契約する
* Partner Interconnect:
    - 通信事業者のサービス品質に依存するため、安定性が保証されない場合がある
    - 対処法: 複数の通信事業者と契約することでリスクを分散す

### オンプレミス ロケーションから Google のサービスまたは API へのプライベート アクセス
#### なぜプライベートアクセスが必要か？
* セキュリティ強化: インターネットを経由しないため、データ漏洩のリスクを低減できます。
* パフォーマンス向上: インターネット経由の通信に比べて、遅延が少なく、安定した通信を実現できます。
* コスト削減: インターネット回線のコストを削減できます。

### オンプレミス ロケーションとクラウド間の IP アドレス管理
#### Google CloudのIPアドレス管理機能
* VPCサービス: VPCネットワークの作成、管理、およびルーティングの設定を行います。
* Cloud DNS: DNSサービスを提供します。
* Cloud NAT: NATサービスを提供します。
* Cloud Router: BGPルーティングをサポートします。
#### 設計のポイント
* シンプル化: なるべくシンプルなIPアドレススキームを設計し、管理の負荷を軽減します。
* 拡張性: 将来的にネットワークが拡大した場合でも、柔軟に対応できる設計にします。
* セキュリティ: IPアドレス範囲を制限し、不正なアクセスを防止します。
* 高可用性: 障害発生時に、IPアドレス管理システムが停止しないように冗長化を考慮します。

### DNS ピアリングと転送
#### 設計のポイント
* DNSゾーンの設計: 各ゾーンの役割を明確にし、適切なレコードを配置します。
* 権限委譲: DNSレコードの管理権限を適切に委譲します。
* セキュリティ: DNS攻撃から保護するための対策を講じます。
* パフォーマンス: DNSクエリに対する応答時間を短縮するための対策を講じます。
* モニタリング: DNSの設定が正しく機能しているか、定期的に監視します。
#### 具体的な活用例
* 共有サービスのDNSレコード: 複数のVPCで利用する共有サービス（例えば、認証サービス）のDNSレコードを一つのゾーンに集約し、DNSピアリングで共有する。
* オンプレミス環境との統合: オンプレミス環境のDNSサーバーに、GCPのDNSレコードを転送することで、既存のDNSインフラと統合する。
* マルチクラウド環境: AWSやAzureなどの他のクラウドプロバイダーのDNSサービスと連携し、マルチクラウド環境におけるDNS管理を統一する。


## 1.4 Google Kubernetes Engine の IP アドレス指定プランを設計する。以下のような点を考慮します。

### 一般公開クラスタノードと限定公開クラスタノード
#### 設計例
* 一般公開クラスタ:
    - インターネットからアクセス可能なWebアプリケーションをデプロイする
    - ロードバランサーを使用して、複数のノードに負荷分散を行う
* 限定公開クラスタ:
    - 内部ネットワークで利用するマイクロサービスをデプロイする
    - プライベートサービスコネクトを使用して、他のGCPサービスと接続する
#### 注意点
* 限定公開クラスタの制限:
    - Kubernetes Dashboardへのアクセスは、プライベートIPアドレスから行う必要があります。
    - ノードへのSSH接続も、プライベートIPアドレスから行う必要があります。
* IPアドレス枯渇: IPアドレスを効率的に利用するため、適切なCIDRブロックを割り当て、サブネットを分割する必要があります。
* セキュリティ: ファイアウォールルールを厳格に設定し、不要なアクセスを遮断する必要があります。


### コントロール プレーンのパブリック エンドポイントとプライベート エンドポイント
#### 設計例
* パブリックエンドポイント:
     - インターネットからGKEクラスタを管理したい場合
     - 負荷分散を使用して、複数のクラスタへのアクセスを集中管理したい場合
* プライベートエンドポイント:
     - 内部ネットワークからのみGKEクラスタを管理したい場合
     - 高いセキュリティが求められる環境でGKEを利用する場合
     - オンプレミス環境とGKEを連携させる場合
#### 注意点
* プライベートエンドポイントの制限:
     - プライベートエンドポイントを使用する場合、インターネットから直接コントロールプレーンにアクセスすることはできません。
     - VPCサービスコントロールの設定が複雑になる場合があります。
* DNS設定: プライベートエンドポイントを使用する場合、DNS設定を適切に行う必要があります。


### サブネットとエイリアス IP
#### 設計例
* 大規模なウェブアプリケーション:
     - フロントエンド、バックエンド、データベースをそれぞれ異なるサブネットに配置
     - 各サブネットに適切なCIDRブロックを割り当て
     - エイリアスIPを利用して、Pod IPアドレス空間を拡張
* マイクロサービスアーキテクチャ:
     - 各マイクロサービスを異なるサブネットに配置
     - サービスメッシュを利用して、サービス間の通信を制御
     - エイリアスIPを利用して、サービス間のトラフィックを分離
#### 注意点
* IPアドレスの重複: サブネットやエイリアスIPの範囲が重複しないように注意する。
* ルーティング: サブネット間のルーティングを正しく設定する。
* セキュリティ: ファイアウォールルールを適切に設定し、不要なトラフィックを遮断する。

### RFC 1918、RFC 1918 以外、プライベートで使用されるパブリック IP（PUPI）アドレス オプション
#### 設計例
* RFC 1918アドレス:
     - 内部ネットワークで稼働するマイクロサービス
     - オンプレミスとの接続
* RFC 1918以外アドレス:
     - インターネットからアクセス可能なWebアプリケーション
     - Cloud Load Balancingを利用した負荷分散
* PUPIアドレス:
     - プライベートIP環境で、パブリックIPアドレスを必要とするサービス
#### 注意点
* アドレス枯渇: IPアドレスを効率的に利用するため、CIDRブロックを適切に割り当てる。
* ルーティング: 複雑なネットワーク構成では、ルーティングの設定に注意が必要。
* セキュリティ: ファイアウォールルールを適切に設定し、不要なアクセスを遮断する。


# セクション 2: Virtual Private Cloud（VPC）インスタンスの実装（試験内容の約 21%）

## 2.1 VPC を構成する。以下のような点を考察します。

### Google Cloud VPC のリソース（例: ネットワーク、サブネット、ファイアウォール ルールなど）
#### 設計のポイント
* ワークロードの分離: 異なる種類のワークロードを別のサブネットに配置することで、セキュリティを高め、トラブルシューティングを容易にします。
* セキュリティ: ファイアウォールルールを厳格に設定し、不要なアクセスを遮断します。
* スケーラビリティ: 将来的にネットワークが拡大することを考慮し、柔軟な設計を行います。
* パフォーマンス: ネットワーク遅延を最小限に抑えるために、適切なサブネット設計を行います。
* コスト: 利用するリソースに応じてコストが変動するため、コストを考慮した設計を行います。
#### 設計手順
* ワークロードの分析: デプロイするアプリケーションの種類、規模、セキュリティ要件などを分析します。
* VPCの作成: VPCネットワークを作成し、カスタムモードまたはオートサブネットモードを選択します。
* サブネットの作成: 各ワークロードに対応するサブネットを作成し、IPアドレス範囲を割り当てます。
* ファイアウォールルールの設定: 入出力のトラフィックを制御するためのファイアウォールルールを設定します。
* ルーティングの設定: トラフィックの転送先を決定するためのルートテーブルを設定します。
* その他のリソースの設定: 必要に応じて、VPN、Cloud NAT、Cloud Load Balancingなどを設定します。

### VPC ネットワーク ピアリング

### 共有 VPC ネットワークの作成と他のプロジェクトとのサブネットの共有
#### 共有VPCネットワークの活用例
* 複数のチームが共通のネットワークを利用する環境:
    - 各チームが独自のプロジェクトを持ちながら、共通のネットワークリソースを利用できます。
* マルチクラウド環境:
    - 複数のクラウドプロバイダーの環境を統合し、一元管理できます。
* オンプレミスとの接続:
    - オンプレミス環境とGCP環境をVPNで接続し、共通のネットワークとして利用できます。
#### 注意点
* ホストプロジェクトの重要性: ホストプロジェクトの可用性は、すべてのサービスプロジェクトに影響するため、高可用性設計が重要です。
* 権限管理: 各プロジェクトの権限を適切に管理することで、セキュリティリスクを軽減できます。
* ネットワーク設計の複雑化: 共有VPCは、ネットワーク設計を複雑にする可能性があります。

### Google サービスへの API アクセス（例: 限定公開の Google アクセス、公開インターフェースなど）

### 作成後の VPC サブネット範囲の拡大
#### サブネット範囲拡大の必要性と注意点
Google Cloud VPCのサブネット範囲は、一度作成すると変更が制限されます。これは、ネットワーク設定の安定性とセキュリティを確保するためです。しかし、以下のような状況でサブネット範囲の拡大が必要になることがあります。

* IPアドレスの枯渇: 予想以上に多くのインスタンスが作成され、IPアドレスが不足する場合。
* ネットワーク設計の変更: ネットワーク構成を変更し、サブネットのIPアドレス範囲を調整する必要がある場合。
*** ただし、サブネット範囲を拡大する際には、以下の点に注意が必要です。***

* 既存リソースへの影響: サブネット範囲の変更は、そのサブネットに属する既存のリソースに影響を与える可能性があります。
* ルーティング設定: ルーティングテーブルの設定を見直す必要がある場合があります。
* ファイアウォールルール: ファイアウォールルールも、拡大されたIPアドレス範囲に対応するように調整する必要があります。
* ダウンタイム: サブネット範囲の拡大作業中に、一時的にネットワーク接続が中断される可能性があります。

#### サブネット範囲拡大の手順
1. 新しいサブネットの作成:
    - 既存のサブネットと同じリージョンに、新しいサブネットを作成します。
    - 新しいサブネットのIPアドレス範囲は、既存のサブネット範囲とオーバーラップしないように注意します。
2. リソースの移行:
     - 既存のサブネットから、新しいサブネットへリソースを移行します。
    - インスタンスの場合は、停止して再起動することで、新しいサブネットに割り当てられます。
3. ルーティング設定の変更:
    - ルーティングテーブルを更新し、新しいサブネットへのルーティングを追加します。
4. ファイアウォールルールの調整:
    - ファイアウォールルールを、新しいIPアドレス範囲に対応するように調整します。
#### 代替案: セカンダリIP範囲の利用
サブネット範囲の拡大に代わる方法として、セカンダリIP範囲（エイリアスIP）の利用が考えられます。セカンダリIP範囲は、一つのインスタンスに複数のIPアドレスを割り当てることができる機能です。

* メリット:
    - サブネット範囲を変更せずに、IPアドレスを増やすことができる。
    - 柔軟なIPアドレス管理が可能。
* デメリット:
    - すべてのインスタンスがセカンダリIP範囲に対応しているわけではない。
    - 複雑なネットワーク構成になる可能性がある。

## 2.2 ルーティングを構成する。以下のような点を考慮します。

### 静的ルーティングと動的ルーティング
#### 静的ルーティングの活用例
* シンプルなネットワーク: 少数のサブネット間の通信で構成されるシンプルなネットワーク
* 特定のトラフィックの制御: 特定の宛先へのトラフィックを常に特定の経路で転送したい場合
* 冗長性の低い環境: ルーティングプロトコルの障害に耐えられない環境
#### 動的ルーティングの活用例
* 大規模なネットワーク: 多くのサブネットやルーターが存在する大規模なネットワーク
* 複雑なネットワーク: 複数のルーティング領域やポリシーが存在する複雑なネットワーク
* 冗長性の高い環境: ルーティングプロトコルによる自動的な経路選択により、障害発生時の復旧が早い
### Google Cloudにおけるルーティングの設定
Google Cloudでは、Cloud Routerを使用して、VPCネットワーク間のルーティングを設定できます。Cloud Routerは、BGP（Border Gateway Protocol）をサポートしており、動的なルーティング環境を構築することができます。
#### 静的ルートの設定:
* 手順: Google Cloud Consoleまたはgcloudコマンドを使用して、手動でルートを追加します。
* 用途: 特定の宛先へのトラフィックを常に特定の経路で転送したい場合に利用します。
#### 動的ルートの設定:
* 手順: Cloud Routerを構成し、BGPピアリングを設定することで、他のネットワークとの間で動的なルーティング情報を交換します。
* 用途: 大規模なネットワークや、複数のネットワーク間の接続を構築する場合に利用します。

### グローバルとリージョン範囲での動的ルーティング
#### グローバル動的ルーティングの活用例
* 大規模なマルチリージョン展開: 複数のリージョンに分散してサービスを提供する場合
* グローバルなロードバランシング: グローバルな負荷分散を実現したい場合
* ハイブリッドクラウド環境: オンプレミス環境と複数のリージョンを接続する場合
#### リージョン動的ルーティングの活用例
* 特定のリージョンに限定されたサービス: 特定のリージョンでサービスを提供する場合
* セキュリティ重視の環境: ネットワークの範囲を限定することで、セキュリティリスクを軽減したい場合
#### Google Cloudにおける動的ルーティングの設定
Google Cloudでは、Cloud Routerを使用して動的ルーティングを設定します。Cloud Routerは、BGP（Border Gateway Protocol）をサポートしており、他のネットワークとの間で動的なルーティング情報を交換することができます。

* 動的ルーティングモードの設定: Cloud Routerを作成する際に、動的ルーティングモードを「グローバル」または「リージョン」に設定します。
* BGPピアリングの設定: Cloud Routerと他のネットワークとの間でBGPピアリングを設定します。
* ルートフィルタリング: BGPポリシーを使用して、アドバタイズするルートや受け入れるルートをフィルタリングします。

### タグと優先度を使用したルーティング ポリシー
Google Cloud VPCでは、タグと優先度を利用することで、非常に細粒度のルーティングポリシーを構築できます。これにより、特定のインスタンスやサブネットへのトラフィックを、柔軟かつ正確に制御することが可能になります。

#### タグと優先度の利用方法
* ネットワークタグ: インスタンスやサブネットにタグを付与します。
* ルートタグ: ルートにタグを付与します。
* 優先度: ルートに優先度を設定します。優先度が低いルートは、優先度が高いルートと競合した場合に無視されます。
#### 例:

* シナリオ: Webサーバーのトラフィックを、特定のロードバランサーにルーティングしたい。
* 設定:
    - Webサーバーのインスタンスに「webserver」というタグを付与する。
    - ロードバランサーのIPアドレスへのルートを作成し、「webserver」というタグと高い優先度を設定する。
    - この設定により、タグ「webserver」を持つインスタンスからのトラフィックは、必ず指定されたロードバランサーを経由するようになります。
#### ルーティングポリシーの活用例
* 特定のアプリケーションへのトラフィックの分離: 異なるアプリケーションを異なるサブネットに配置し、タグと優先度を利用してトラフィックを分離します。
* 多重ホーム接続の管理: 複数のインターネット接続を持つ場合、タグと優先度を利用して、異なる接続へのトラフィックの振り分けを制御します。
* ポリシーベースルーティング (PBR): パケットの宛先 IP アドレス以外の要素に基づいてネクストホップを選択することができます。プロトコルや送信元 IP アドレスでトラフィックを照合することも可能です。

### ネクストホップとしての内部ロードバランサ
Google Cloud VPCにおいて、ルーティングテーブルのネクストホップに内部ロードバランサを指定することで、特定のトラフィックを内部ロードバランサに転送し、複数のバックエンドサーバに分散させることができます。これにより、高可用性、スケーラビリティ、負荷分散を実現できます。

#### 内部ロードバランサをネクストホップとして利用する際の注意点
* 内部ロードバランサの種類: 内部ロードバランサには、HTTP(S)ロードバランサ、TCPロードバランサ、UDPロードバランサなど、様々な種類があります。それぞれのロードバランサの特性を理解し、適切な種類を選択する必要があります。
* ヘルスチェック: バックエンドサーバの健康状態を監視するためのヘルスチェックを設定する必要があります。ヘルスチェックに異常が発生した場合、内部ロードバランサは当該のバックエンドサーバへのトラフィックを停止します。
* ルーティングテーブルの設定: ルーティングテーブルに、内部ロードバランサのIPアドレスをネクストホップとして設定する必要があります。
* セキュリティ: 内部ロードバランサへのアクセス制御を適切に行う必要があります。

#### 設定手順
1. 内部ロードバランサの作成: Google Cloud Consoleまたはgcloudコマンドを使用して、内部ロードバランサを作成します。
2. バックエンドサーバの登録: 内部ロードバランサに、バックエンドサーバを登録します。
3. ヘルスチェックの設定: バックエンドサーバの健康状態を監視するためのヘルスチェックを設定します。
4. ルーティングテーブルの設定: ルーティングテーブルに、内部ロードバランサのIPアドレスをネクストホップとして設定します。

### VPC ネットワーク ピアリングを介したカスタムルートのインポートとエクスポート
#### 活用事例
* マルチクラウド環境: 異なるクラウドプロバイダー間のネットワーク接続を実現する。
* 複数のプロジェクト間の連携: 異なるプロジェクトで管理されているVPCを接続し、リソースを共有する。
* ハイブリッドクラウド環境: オンプレミス環境とクラウド環境を接続する。
#### 設定手順
* VPC ネットワーク ピアリングの作成: Google Cloud Consoleまたはgcloudコマンドを使用して、ピアリング接続を作成します。
* カスタムルートのインポート/エクスポート: ピアリング接続の設定画面で、カスタムルートのインポート/エクスポートを有効にします。
* ルートテーブルの更新: カスタムルートが追加されたことを確認し、必要に応じてルーティングテーブルを更新します。


## 2.3 Google Kubernetes Engine クラスタの構成と保守を行う。以下のような点を考慮します。

### エイリアス IP を使用した VPC ネイティブ クラスタ
GKE の VPC ネイティブ クラスタは、エイリアス IP を使用することで、従来のルートベースのクラスタよりも高い柔軟性と制御性を提供します。

#### 構成と保守の検討点
1. ネットワーク設計
* サブネット: クラスタのノードと Pod に割り当てるサブネットを設計します。
    * ノードサブネット: コントロールプレーンとワーカーノードの IP アドレスを割り当てます。
    * Pod サブネット: Pod に IP アドレスを割り当てます。
    * サービスサブネット: Service の IP アドレスを割り当てます。
* IP アドレス範囲: 各サブネットに適切な IP アドレス範囲を割り当てます。
    * CIDR 表記で指定します。
    * 他のネットワークと重複しないように注意します。
* ルーティング: クラスタ内のノードや Pod 間の通信経路を設定します。
* カスタムルートを作成し、必要に応じてルートテーブルに登録します。
2. クラスタの作成
3. サービスの公開
* LoadBalancer サービス: 外部からアクセス可能なサービスを作成します。
    * 静的 IP アドレスを割り当てたり、外部 IP アドレスを自動的に割り当てることができます。
* NodePort サービス: ノードの IP アドレスとポート番号でサービスにアクセスします。
* ClusterIP サービス: クラスタ内のサービス間通信に使用します。
4. セキュリティ
ファイアウォール: VPC ファイアウォールルールを使用して、入出力トラフィックを制御します。
IAM: Identity and Access Management を利用して、クラスタへのアクセス権限を管理します。
Secret Management: Secret Manager を利用して、機密情報を安全に管理します。
5. 保守
* ノードの自動スケーリング: 負荷に応じてノード数を自動的に調整します。
* バックアップ: PersistentVolume を使用して、データをバックアップします。
* パッチ適用: Kubernetes のバージョンアップやセキュリティパッチを適用します。
* モニタリング: Cloud Monitoring を利用して、クラスタの健康状態を監視します。

### 共有 VPC を使用したクラスタ
GKE で共有 VPC を利用すると、複数のプロジェクト間でネットワークリソースを共有し、より柔軟なネットワーク構成を実現できます。

#### 構成と保守の検討点
1. 共有 VPC の設定
* ホストプロジェクト: 共有 VPC を作成するプロジェクトを指定します。
* サービスプロジェクト: 共有 VPC を利用するプロジェクトを指定します。
* サブネット: 各プロジェクトで使用するサブネットを定義します。
* ファイアウォール: 共通のファイアウォールルールを設定します。
2. GKE クラスタの作成
* プロジェクト: サービスプロジェクトを指定します。
* ネットワーク: 共有 VPC のネットワークを指定します。
* サブネット: 割り当てられたサブネットを指定します。
* IAM: 共有 VPC のリソースへのアクセス権限を適切に設定します。
3. ネットワークポリシー
* Istio: サービスメッシュの導入を検討し、より詳細なトラフィック制御を実現します。
* NetworkPolicy: Pod レベルで通信を制御します。
4. セキュリティ
* IAM: Identity and Access Management を利用して、クラスタへのアクセス権限を管理します。
* Secret Management: Secret Manager を利用して、機密情報を安全に管理します。
* ファイアウォール: 共有 VPC のファイアウォールルールに加えて、GKE のネットワークポリシーを利用して、入出力トラフィックを制御します。
5. 保守
* ノードの自動スケーリング: 負荷に応じてノード数を自動的に調整します。
* バックアップ: PersistentVolume を使用して、データをバックアップします。
* パッチ適用: Kubernetes のバージョンアップやセキュリティパッチを適用します。
* モニタリング: Cloud Monitoring を利用して、クラスタの健康状態を監視します。

#### 共有 VPC の活用例
* 複数のチームが同一のネットワーク環境を利用する場合
* 複数の環境（開発、ステージング、本番）を同一のネットワークで管理する場合
* ハイブリッドクラウド環境で、オンプレミス環境とクラウド環境を接続する場合

### Kubernetes ネットワーク ポリシーの作成
Kubernetes ネットワークポリシーは、Pod 間のネットワーク通信を制御するためのメカニズムです。IP アドレスやポート番号だけでなく、Pod に付与されたラベルに基づいて、入出力トラフィックを許可または拒否することができます。

#### ネットワークポリシーの活用例
* 特定の Pod へのアクセス制限: 特定の Pod へのアクセスを許可する IP アドレスやポートを制限します。
* マイクロサービス間の通信制御: 各マイクロサービス間の通信を許可するポートやプロトコルを制限します。
* デプロイメント間の分離: デプロイメントごとに異なるネットワークポリシーを適用し、相互干渉を防ぎます。
#### ネットワークポリシーの注意点
* デフォルトの動作: ネットワークポリシーは、明示的に許可されていない通信を拒否します。
* パフォーマンス: 複雑なネットワークポリシーは、ネットワークのパフォーマンスに影響を与える可能性があります。
* テスト: ネットワークポリシーを適用する前に、必ずテスト環境で動作を確認してください。
#### GKE でのネットワークポリシー
GKE では、Calico や Cilium などの CNI (Container Network Interface) プラグインを使用して、ネットワークポリシーをサポートしています。これらのプラグインは、Kubernetes のネットワークポリシーを実際のネットワーク構成にマッピングします。

### 限定公開クラスタとコントロール プレーンのプライベート エンドポイント
限定公開クラスタは、GKE クラスタのノードとコントロールプレーンが、パブリックインターネットに直接アクセスできないように構成されたクラスタです。これは、セキュリティを強化し、意図しない外部からのアクセスを防止するために有効な手段です。

#### コントロールプレーンのプライベートエンドポイント
コントロールプレーンのプライベートエンドポイントは、VPC 内の内部 IP アドレスであり、限定公開クラスタのコントロールプレーンにアクセスするために使用されます。これにより、パブリックインターネット経由でのアクセスを制限し、セキュリティを強化できます。

#### 検討すべき点
1. セキュリティ
* アクセス制御: コントロールプレーンのアクセスを、特定の VPC ネットワークや IAM ロールに制限することで、不正アクセスを防ぎます。
* ファイアウォール: VPC ファイアウォールルールを使用して、コントロールプレーンへの入出力トラフィックを厳密に制御します。
* 秘密管理: Secret Manager を利用して、機密情報を安全に管理します。
2. ネットワーク構成
* VPC ネットワーク: 限定公開クラスタ用の VPC ネットワークを適切に設計します。
    * サブネット: ノード、サービス、Pod などのためのサブネットを割り当てます。
    * IP アドレス範囲: 十分な IP アドレス範囲を確保します。
* ルーティング: コントロールプレーンへのルーティングを正しく設定します。
* VPN: オンプレミス環境との接続が必要な場合は、VPN を利用します。
3. アクセス方法
* kubectl: kubectl コマンドを使用して、プライベートエンドポイントに接続し、クラスタを管理します。
* Cloud Shell: Cloud Shell から、プライベートエンドポイントにアクセスできます。
* Cloud SQL Proxy: Cloud SQL にアクセスする場合、Cloud SQL Proxy を利用します。
4. サービスの公開
* 内部ロードバランサー: クラスタ内のサービスを内部的に公開します。
* NodePort: ノードの IP アドレスとポート番号でサービスにアクセスします。
* Ingress: Ingress コントローラーを使用して、外部からのアクセスを制御します。
5. 保守
* ノードの自動スケーリング: 負荷に応じてノード数を自動的に調整します。
* バックアップ: PersistentVolume を使用して、データをバックアップします。
* パッチ適用: Kubernetes のバージョンアップやセキュリティパッチを適用します。
* モニタリング: Cloud Monitoring を利用して、クラスタの健康状態を監視します。

### クラスタ コントロール プレーン エンドポイント用の承認済みネットワークの追加
#### 承認済みネットワークとは？
GKE クラスタのコントロールプレーンへのアクセスを、特定の IP アドレス範囲に制限する機能です。これにより、セキュリティを強化し、不正なアクセスを防止することができます。
#### 承認済みネットワークを追加するメリット
* セキュリティ強化: 許可された IP アドレスからのみコントロールプレーンにアクセスできるため、セキュリティリスクを軽減できます。
* アクセス制御: 特定のプロジェクトやチームにアクセスを制限することで、権限管理を細かく行えます。
* コンプライアンス: セキュリティ基準を満たすために、アクセス制御を厳格化できます。
#### 活用事例
* 特定のVPCからのみアクセスを許可する:
    * クラスタを特定のVPCに限定することで、他のネットワークからのアクセスを遮断できます。
* 特定のプロジェクトからのみアクセスを許可する:
    * 特定のプロジェクトに属するサービスアカウントからのみアクセスを許可できます。
* オンプレミス環境からのアクセスを許可する:
    * VPN接続を利用して、オンプレミス環境からクラスタにアクセスできます。
#### 注意点
* IPアドレスの変更: 許可するIPアドレスを変更する場合は、クラスタを更新する必要があります。
* アクセス不能: 誤った設定により、クラスタにアクセスできなくなる可能性があります。
* セキュリティグループとの連携: VPCファイアウォールルールと連携させることで、より強固なセキュリティを実現できます。

## 2.4 ファイアウォール ルールを構成、管理する。 以下のような点を考慮します。

### ターゲット ネットワーク タグとサービス アカウント
Google Cloud のファイアウォールルールは、IP アドレスだけでなく、ターゲット・ネットワークタグ や サービスアカウント を指定できることで、より柔軟かつ安全なネットワーク構成を実現できます。

* ターゲット・ネットワークタグ:
    * インスタンスに割り当てられたタグに基づいて、ファイアウォールルールを適用できます。
    * IP アドレスが動的に変化しても、タグベースでルールを適用できるため、管理が容易です。
* サービスアカウント:
    * サービスアカウントに紐づいた仮想マシンやコンテナに対して、きめ細かいアクセス制御が可能です。
    * IAM (Identity and Access Management) と連携することで、より強固なセキュリティを実現できます。
#### 具体的な活用例
* 開発環境と本番環境の分離:
    * 各環境に異なるネットワークタグを割り当て、ファイアウォールルールでアクセスを制限します。
* アプリケーションごとのアクセス制御:
    * 各アプリケーションに異なるサービスアカウントを割り当て、ファイアウォールルールでアクセスを制御します。
* セキュリティ強化:
    * 特定のポートへのアクセスを制限したり、特定の IP アドレスからのアクセスを許可するなど、セキュリティポリシーに合わせてファイアウォールルールを構成します。

### ルールの優先度
Google Cloud のファイアウォールルールは、複数のルールが定義されている場合、優先度 に基づいて評価されます。優先度の高いルールが、より優先的に適用されるため、ファイアウォールルールの順序は、ネットワークセキュリティの設計において非常に重要です。

### ネットワーク プロトコル
Google Cloud のファイアウォールルールでは、非常に多様なネットワークプロトコルを指定し、トラフィックを制御することができます。これにより、きめ細やかなセキュリティ設定が可能になります。

#### サポートされるプロトコル
Google Cloud のファイアウォールルールでサポートされる主なプロトコルは以下の通りです。
* TCP: 一般的なインターネット通信で広く利用されるコネクション型プロトコルです。Web通信 (HTTP/HTTPS) やメール (SMTP) など、多くのアプリケーションで利用されます。
* UDP: コネクションレス型プロトコルで、TCPよりも高速なデータ伝送が可能です。DNS、DHCP、ストリーミングサービスなど、リアルタイム性や低遅延が求められるアプリケーションで利用されます。
* ICMP: ネットワークの到達可能性確認やエラー報告に使用されるプロトコルです。Pingコマンドなどで利用されます。
* ICMPv6: IPv6ネットワークに対応したICMPです。
* SCTP: ストリーム制御伝送プロトコルで、信頼性の高いマルチストリーム通信を提供します。
* ESP: Encapsulating Security Payloadの略で、IPsecで利用される暗号化プロトコルです。
* AH: Authentication Headerの略で、IPsecで利用される認証プロトコルです。

#### 具体的な活用例
* Webサーバーへのアクセス許可: TCPポート80と443へのアクセスを許可します。
* DNSサーバーへのアクセス許可: UDPポート53へのアクセスを許可します。
* SSH接続の許可: TCPポート22へのアクセスを許可し、特定のIPアドレスからのみ接続を許可します。
* ICMPパケットのブロック: ICMPをブロックすることで、Ping攻撃を防ぎます。
* IPsec VPNの許可: ESPまたはAHを許可することで、IPsec VPN接続を可能にします

### 上り / 下りルール
#### 上り/下りルールを設定する際の注意点
* 暗黙のルール: Google Cloud では、すべてのインスタンスを保護するための暗黙のルールが存在します。例えば、すべての受信接続をブロックするルールなどです。これらの暗黙のルールは、優先度が非常に低い設定になっています。
* ルール間の関係: 上りルールと下りルールは相互に影響を与える可能性があります。ルールを作成する際は、全体的なネットワーク構成を考慮する必要があります。
* テスト: ルールを変更する際は、必ずテスト環境で動作を確認してから本番環境に適用してください。

### ファイアウォール ルールのロギング
Google Cloud のファイアウォールルールロギングは、ネットワークトラフィックを監視し、セキュリティインシデントの検出やトラブルシューティングに不可欠な機能です。ファイアウォールルールによって許可または拒否されたトラフィックに関する詳細な情報をログとして記録することで、ネットワークの状況を把握し、セキュリティリスクを軽減することができます。

#### ファイアウォールルールロギングのメリット
* セキュリティインシデントの検出:
    * 許可されていないトラフィックの検出
    * 攻撃の痕跡の発見
    * 異常なトラフィックパターンの特定
* トラブルシューティング:
    * 接続問題の原因究明
    * ファイアウォールルールの有効性の検証
* コンプライアンス:
    * 監査証跡の確保
    * 規制への準拠
#### ログの活用例
* セキュリティインシデントの調査: 特定のIPアドレスからのアクセスを調査したり、異常なトラフィックパターンを検出したりすることができます。
* ファイアウォールルールのチューニング: ファイアウォールルールが意図したとおりに機能しているかを確認し、必要に応じてルールを調整することができます。
* 容量計画: ネットワークトラフィックの増加を予測し、リソースの計画を立てることができます。

### ファイアウォール インサイト
Google Cloud のファイアウォールインサイトは、ファイアウォールルールの有効性や最適化 を支援する機能です。ファイアウォールルールによって生成されたログデータを分析し、以下の情報を提供することで、ネットワークセキュリティの改善に役立ちます。

* 未使用のルール: 使用されていないファイアウォールルールを特定し、不要なルールを削除することで、構成を簡素化できます。
* 過度に緩いルール: 許可範囲が過度に広いルールを特定し、セキュリティリスクを軽減できます。
* ルール間の競合: 複数のルールが同じトラフィックに適用される場合、意図しない結果になる可能性があります。ファイアウォールインサイトは、このような競合を検出するのに役立ちます。
* ルールの使用状況: 各ファイアウォールルールの使用状況を可視化し、ルールの有効性を評価できます。

#### ファイアウォールインサイトの活用方法
* 未使用のルールを特定: ファイアウォールインサイトが特定した未使用のルールを削除することで、誤った設定によるセキュリティリスクを減らすことができます。
過度に緩いルールを修正: 許可範囲を絞り込むことで、攻撃対象を縮小し、セキュリティを強化できます。
* ルール間の競合を解消: 競合するルールを修正または削除することで、ネットワークトラフィックの制御を正確に行うことができます。
* ルールの最適化: ルールの使用状況を分析し、不要なルールを削除したり、許可範囲を調整したりすることで、ファイアウォール構成を最適化できます。

### 階層型ファイアウォール
Google Cloud の階層型ファイアウォールは、組織やフォルダといった階層構造に基づいて、一括でファイアウォールルールを管理できる機能です。従来のVPCファイアウォールルールがVPCネットワーク単位で設定されていたのに対し、階層型ファイアウォールはより上位の階層でポリシーを設定できるため、大規模な環境での管理を効率化できます。

#### 主な特徴
* 階層構造: 組織、フォルダ、プロジェクトといった階層構造でファイアウォールポリシーを定義できます。
* 継承: 上位の階層で定義されたポリシーは、下位の階層に継承されます。
* オーバーライド: 下位の階層で、上位の階層で定義されたポリシーをオーバーライドできます。
* 柔軟性: ターゲット・ネットワーク、サービスアカウント、IPアドレスなど、さまざまな条件でルールを定義できます。
* 可視性: ファイアウォールインサイトを活用することで、ポリシーの効果を可視化し、最適化できます。
#### 階層型ファイアウォールのメリット
* 効率的な管理: 大規模な環境でも、一元的にファイアウォールポリシーを管理できます。
* 一貫性: 組織全体で一貫したセキュリティポリシーを適用できます。
* 柔軟性: 階層構造を活用することで、組織のニーズに合わせて柔軟にポリシーを調整できます。
* セキュリティ強化: より詳細なアクセス制御が可能になり、セキュリティリスクを軽減できます。
#### 階層型ファイアウォールの活用例
* 組織全体のセキュリティポリシーの統一: 組織全体で共通のセキュリティポリシーを適用し、セキュリティレベルの底上げを図ります。
* 開発環境と本番環境の分離: 開発環境と本番環境で異なるファイアウォールポリシーを適用することで、セキュリティリスクを軽減します。
* 部門ごとのポリシー設定: 部門ごとに異なるセキュリティ要件に対応するために、部門単位でファイアウォールポリシーを定義します。


## 2.5 VPC Service Controls を実装する。 以下のような点を考慮します。

### アクセスレベルとサービス境界の作成および構成
VPC Service Controls (VPCSC) は、Google Cloud のリソースへのアクセスを細かく制御するためのセキュリティ機能です。組織やフォルダといった階層構造に基づいて、サービス境界を定義し、各サービス境界へのアクセスレベルを設定することで、データ漏洩のリスクを軽減することができます。

#### アクセスレベルとサービス境界の作成・構成
##### アクセスレベル
アクセスレベルは、サービス境界へのアクセス権限を定義するものです。以下の3つのアクセスレベルが用意されています。

* RESTRICTED: サービス境界内のリソースへのアクセスを制限します。
* PROTECTED: サービス境界内のリソースへのアクセスを保護します。
* UNRESTRICTED: サービス境界内のリソースへのアクセスを制限しません。

##### サービス境界
サービス境界は、アクセスレベルを適用する範囲を定義するものです。組織、フォルダ、プロジェクト単位でサービス境界を作成できます。

#### 具体的な検討事項
1. 組織の構造とセキュリティ要件の分析
* 組織の階層構造を把握し、各階層に合ったアクセスレベルを設定します。
* セキュリティ要件を明確にし、それに基づいてアクセスレベルとサービス境界を設計します。
2. サービス境界の設計
* 粒度: サービス境界の粒度を適切に設定します。
* 依存関係: サービス間の依存関係を考慮し、サービス境界を設計します。
* 例外処理: 例外的なアクセスが必要な場合は、例外処理を定義します。
3. アクセスレベルの設定
* 最小権限の原則: 必要最低限のアクセス権限のみを付与します。
* データの機密性: 機密性の高いデータへのアクセスを制限します。
    * 割に基づいたアクセス制御 (RBAC): IAMロールと組み合わせることで、より詳細なアクセス制御を実現します。
4. API呼び出しの制限
* 許可するAPI: サービス境界内で許可するAPIを明確に定義します。
* データの持ち出し: データの持ち出しを制限するために、ストレージへのアクセスを制限します。
* ネットワークアクセス: ネットワークアクセスを制限するために、VPC Service ControlsとVPCファイアウォールを連携させます。
5. ログの収集と分析
* アクセスログ: アクセスログを収集し、異常なアクセスを検出します。
* セキュリティインシデント対応: アクセスログを分析し、セキュリティインシデントに対応します。

### VPC のアクセス可能なサービス
PC Service Controls (VPCSC) は、Google Cloud のリソースへのアクセスを細かく制御するためのセキュリティ機能です。この機能を活用することで、特定のサービスへのアクセスを許可したり、制限したりすることができます。

#### アクセス可能なサービスの検討ポイント
VPCSCでは、サービス境界内に配置されたリソースから、どのGoogle Cloudサービスにアクセスできるかを厳密に制御できます。この際、以下の点を考慮する必要があります。

1. ビジネス要件とセキュリティ要件のバランス
* 必要なサービスのみ許可: ビジネスに必要なサービスにアクセスを限定することで、セキュリティリスクを最小限に抑えます。
* データの機密性: 機密性の高いデータへのアクセスは、厳格に制限します。
* コンプライアンス: 業界の規制や法令を遵守するために必要なアクセスを許可します。
2. サービス境界の設計
* 粒度: サービス境界の粒度を適切に設定します。
* 依存関係: サービス間の依存関係を考慮し、サービス境界を設計します。
* 例外処理: 例外的なアクセスが必要な場合は、例外処理を定義します。
3. API呼び出しの制限
* 許可するAPI: サービス境界内で許可するAPIを明確に定義します。
* データの持ち出し: データの持ち出しを制限するために、ストレージへのアクセスを制限します。
* ネットワークアクセス: ネットワークアクセスを制限するために、VPC Service ControlsとVPCファイアウォールを連携させます。
4. サービスの分類
* 信頼できるサービス: 内部で開発・管理しているサービスなど、信頼できるサービスへのアクセスを許可します。
* サードパーティサービス: 外部サービスへのアクセスは、厳格に制限します。
* データ処理サービス: データ処理サービスへのアクセスを制限し、データ漏洩のリスクを軽減します。
5. アクセスログの分析
* 異常なアクセス: アクセスログを分析し、異常なアクセスを検出します。
* セキュリティインシデント対応: アクセスログを分析し、セキュリティインシデントに対応します。
#### 具体的な検討例
* 開発環境:
    * 開発に必要なサービス（Cloud Build、Cloud Source Repositoriesなど）へのアクセスを許可
    * プロダクション環境へのアクセスを制限
* プロダクション環境:
    * プロダクション環境で必要なサービス（Cloud SQL、Cloud Storageなど）へのアクセスを許可
    * 開発環境へのアクセスを制限
* データ分析環境:
    * データ分析に必要なサービス（BigQuery、Dataflowなど）へのアクセスを許可
    * プロダクションデータへのアクセスを制限

### 境界ブリッジ
VPC Service Controls (VPCSC) の境界ブリッジは、複数のサービス境界間でリソースを共有し、相互通信を可能にする機能です。通常、異なるサービス境界間での通信は制限されますが、境界ブリッジを使用することで、特定のサービスやリソースへのアクセスを許可することができます。
#### 境界ブリッジの活用例
* データ共有: 異なるサービス境界間でデータを共有する必要がある場合（例：データ分析のためにデータウェアハウスにデータを移行する場合）。
* マイクロサービスアーキテクチャ: 異なるマイクロサービス間で通信が必要な場合。
* レガシーシステムとの連携: レガシーシステムとの連携が必要な場合。
#### 境界ブリッジのメリットとデメリット
* メリット:
    * 柔軟性: 異なるサービス境界間でリソースを共有し、柔軟なシステム設計を可能にします。
    * 効率化: 複数のサービス境界間で重複するリソースを共有することで、管理コストを削減できます。
    * 拡張性: システムの拡張に合わせて、境界ブリッジを柔軟に追加・変更できます。
* デメリット:
    * 複雑性: 複数のサービス境界間で通信を許可することで、セキュリティリスクが増加する可能性があります。
    * 管理の難しさ: 境界ブリッジの設定は複雑であり、誤った設定はセキュリティ問題を引き起こす可能性があります。
#### 境界ブリッジを利用する際の注意点
* 最小権限の原則: 必要な範囲のアクセス権限のみを付与します。
* ログの分析: 境界ブリッジを経由したトラフィックを監視し、異常なアクセスを検出します。
* 定期的なレビュー: ビジネス要件の変化に合わせて、境界ブリッジの設定を定期的に見直します。

### 監査ロギング
VPC Service Controls (VPCSC) の監査ロギングは、サービス境界内のリソースへのアクセスに関する詳細な情報を記録する機能です。このログデータを利用することで、セキュリティインシデントの調査、コンプライアンスの確認、およびトラブルシューティングを行うことができます。

#### 監査ログの活用方法
* セキュリティインシデントの調査: 不審なアクセスやデータ漏洩が発生した場合、監査ログを分析することで原因を特定し、対策を講じることができます。
* コンプライアンスの確認: 監査ログを基に、セキュリティポリシーや法規制への準拠状況を確認することができます。
* トラブルシューティング: システム障害が発生した場合、監査ログを分析することで原因を特定し、問題を解決することができます。
* アクセス制御の最適化: 監査ログを分析することで、アクセス権限の過剰付与や不足を検出し、アクセス制御を最適化することができます。
#### 監査ログの収集と分析
* Cloud Logging: VPCSCの監査ログは、Cloud Loggingに保存されます。
* ログクエリ: LogQLを使用して、監査ログを検索し、分析することができます。
* SIEM: SIEM（Security Information and Event Management）ツールと連携することで、より高度なセキュリティ分析を行うことができます。

### ドライラン モード
VPC Service Controls (VPCSC) のドライランモードは、実際のサービス境界を作成する前に、その設定が意図したとおりに機能するかを検証できる機能です。このモードでは、サービス境界が作成され、アクセス制御が適用されますが、実際のトラフィックには影響を与えません。

#### ドライランモードの活用
* 設定の検証: サービス境界の設定が正しく機能するかを検証できます。
* 影響範囲の評価: サービス境界の作成によって、どの程度の範囲のアクセスが制限されるかを評価できます。
* 問題の発見: 設定ミスや予期せぬ影響を発見することができます。

#### ドライランモードを活用したベストプラクティス
* 段階的な導入: まずは小規模な範囲でドライランモードを試行し、問題がなければ範囲を拡大していくことをおすすめします。
* 自動化: Terraformなどのツールを使用して、ドライランモードの設定を自動化することで、効率化を図ることができます。
* 定期的な検証: 環境の変化に合わせて、定期的にドライランモードで検証を行うことをおすすめします。

#### 具体的な検討事項
* 検証シナリオ: どのシナリオで検証を行うか、具体的に計画を立てます。
* 監査ログの分析: 監査ログを詳細に分析し、問題点を特定します。
* 自動化: 設定の自動化を検討します。
* 定期的な検証: 定期的な検証のスケジュールを策定します。
#### より詳細な検討のためには、以下の情報が必要です。
* 組織の構造: 組織の階層構造、部門構成、リソースの配置など
* セキュリティ要件: アクセス制御、データの機密性など、セキュリティに関する要件
* 既存のネットワーク環境: 現在のネットワーク構成、ファイアウォールルールなど
* アプリケーションの要件: アプリケーション間の通信パターン、セキュリティ要件など


# セクション 3: ネットワーク サービスの構成（試験内容の約 23%）

## 3.1 ロード バランシングを構成する。以下のような点を考慮します。

### バックエンド サービスとネットワーク エンドポイント グループ（NEG）

### バックエンド サービスへのトラフィックとヘルスチェックを許可するファイアウォール ルール

### バックエンド サービスとターゲット インスタンス グループのヘルスチェック

### 分散方式を使用したバックエンドおよびバックエンド サービスの構成（例: RPS、CPU、カスタムなど）、セッション アフィニティ、容量スケーリング/スケーラー

### TCP および SSL プロキシ ロードバランサ

### ロードバランサ（例: 外部 TCP/UDP ネットワーク負荷分散、内部 TCP/UDP 負荷分散、外部 HTTP(S) 負荷分散、内部 HTTP(S) 負荷分散など）

### プロトコル転送

### ワークロードの増加への対応（自動スケーリングと手動スケーリングそれぞれを使用した場合）

## 3.2 Google Cloud Armor ポリシーを構成する。 以下のような点を考慮します。

### セキュリティ ポリシー

### ウェブ アプリケーション ファイアウォール（WAF）ルール（例: SQL インジェクション、クロスサイト スクリプティング、リモート ファイル インクルードなど）

### ロードバランサ バックエンドへのセキュリティ ポリシーの接続

## 3.3 Cloud CDN の構成以下のような点を考慮します。

### 有効化と無効化

### Cloud CDN

### キャッシュキー無効化キャッシュ オブジェクト

### 署名付き URL

### カスタム送信元

## 3.4 Cloud DNS の構成と保守を行う。以下のような点を考察します。

### ゾーンとレコードの管理

### Cloud DNS への移行

### DNS Security Extensions（DNSSEC）

### 転送と DNS サーバー ポリシー

### オンプレミス DNS と Google Cloud の統合

### スプリット ホライズン DNS

### DNS ピアリング

### 限定公開 DNS のロギング

## 3.5 Cloud NAT を構成する。以下のような点を考察します。

### アドレス指定

### ポートの割り振り

### タイムアウトのカスタマイズ

### ロギングとモニタリング

### 組織のポリシーの制約ごとの制限

## 3.6 ネットワーク パケット インスペクションを構成する。 以下のような点を考察します。

### 単一 VPC トポロジとマルチ VPC トポロジでの Packet Mirroring

### Packet Mirroring のソースとトラフィックのフィルタを使用した関連トラフィックのキャプチャ

### マルチ NIC VM（次世代のファイアウォール アプライアンスなど）を使用した VPC 間トラフィックのルーティングと検査

### 高可用性マルチ NIC VM ルーティングのネクストホップとしての内部ロードバランサの構成



# セクション 4: ハイブリッド相互接続の実装（試験内容の約 14%）

## 4.1 Cloud Interconnect を構成する。 以下のような点を考慮します。

### Dedicated Interconnect 接続と VLAN アタッチメント

### Partner Interconnect 接続と VLAN アタッチメント

## 4.2 サイト間 IPsec VPN を構成する。 以下のような点を考慮します。

### 高可用性 VPN（動的ルーティング）

### Classic VPN（ルートベースのルーティング、ポリシーベースのルーティングなど）

## 4.3 Cloud Router を構成する。以下のような点を考慮します。

### Border Gateway Protocol（BGP）属性（例:ASN、ルート優先度/MED、リンクローカル アドレスなど）

### BGP によるカスタムルート アドバタイズ

### 信頼性が高く冗長な Cloud Router のデプロイ



# セクション 5: ネットワーク オペレーションの管理、モニタリング、最適化（試験内容の約 16%）

## 5.1 Google Cloud のオペレーション スイートを使用してロギングとモニタリングを行う。以下のような点を考慮します。

### ネットワーク コンポーネントのログの確認（例: VPN、Cloud Router、VPC Service Controls など）

### ネットワーキング コンポーネント（例: VPN、Cloud Interconnect 接続と相互接続のアタッチメント、Cloud Router、ロードバランサ、Google Cloud Armor、Cloud NAT など）

## 5.2 セキュリティを管理、維持する。 以下のような点を考慮します。

### ファイアウォール（例: クラウドベース、プライベート）

### IAM の問題の診断と解決（例: 共有 VPC、セキュリティ/ネットワーク管理者など）

## 5.3 接続性の維持管理とトラブルシューティングを行う。以下のような点を考慮します。

### HTTP(S) ロード バランシングによるトラフィック フローのドレインとリダイレクト

### フローログを使用した、上りトラフィックと下りトラフィックのモニタリング

### ファイアウォール ログとファイアウォール インサイトのモニタリング

### VPN の管理とトラブルシューティング

### Cloud Router の BGP ピアリング問題のトラブルシューティング

## 5.4 レイテンシとトラフィック フローのモニタリング、管理、トラブルシューティングを行う。以下のような点を考慮します。

### ネットワークのスループットとレイテンシのテスト

### ルーティングの問題の診断

### Network Intelligence Center を使用したトポロジの可視化、接続のテスト、パフォーマンスのモニタリング
