## 1
### Q. 4
データの取り込みと配信を一元化するために、貴社はどのシステムを選ぶべきか。
- トピック内の特定のオフセットへのシーク機能
-多数のトピックにおけるパブリッシュ/サブスクライブ・セマンティクスのサポート
- キーごとの順序付けを維持するか？
1. 　Apache Kafka
2. Cloud Storage
3. Dataflow
4. Firebase Cloud Messaging
<details><div>
    答え：1
説明
正しい選択肢は A. Apache Kafka です。
Apache Kafkaは、データ統合のための機能を備えたメッセージングシステムを提供する分散ストリーミングプラットフォームであり、トピック内の特定のオフセットにシークする機能、数百ものトピック上でパブリッシュ／サブスクライブセマンティクスをサポートする機能、キーごとの順序付けを保持する機能などを備えています。
不正解の選択肢
オプションB. Cloud Storageは、Apache Kafkaのようなデータ統合の機能を提供していないため、不正解です。
オプションC. Dataflowは、トピック内の特定のオフセットにシークする機能、数百のトピックでのパブリッシュ/サブスクライブ・セマンティクスのサポート、およびキーごとの順序付けを保持する機能を提供しないため、不正解です。
オプション D. Firebase Cloud Messaging は、トピック内の特定のオフセットへのシーク機能、何百ものトピックでの発行/購読セマンティクスのサポート、およびキーごとの順序付けの保持を提供していないため、不正解です。
</div></details>

### Q. 10
何百万台ものコンピュータのCPUとメモリ使用量に関する時系列データを効果的に保存するデータベースの選択に関する決断に迫られていると想像してほしい。要件は、このデータを1秒間隔で取得したサンプルとして保存することです。このデータはアナリストがリアルタイムのアドホック分析に使用するため、データベースは効率的なクエリ実行をサポートする必要があります。さらに、クエリを実行するたびに料金が発生するのを防ぎ、選択したスキーマ設計が将来的なデータセットの拡張に対応できることを目的としています。これらの目的に最適なデータベースとデータモデルはどれでしょうか？
1. 　
2. 
3. コンピューター エンジンのコンピューター識別子と各秒のサンプル時間を組み合わせた行キーを使用して、Bigtable で幅の狭いテーブルを作成します。
4. 
<details><div>
    答え：3
説明
正解はCです。Bigtableに、コンピュータ・エンジンのコンピュータ識別子と各秒のサンプル時間を組み合わせた行キーを持つ狭いテーブルを作成します。
こうすることで、アナリストはデータをすばやく照会できるようになり、スキーマ設計がデータセットの将来の成長を可能にします。Bigtableは、データへの高速アクセスとクエリを可能にするので、この種のデータには最適です。
不正解の選択肢
BigQueryはリアルタイムのアドホック分析をサポートしていないため、オプションAは不正解です。
BigQueryはリアルタイムのアドホック分析をサポートしておらず、各秒の間隔で行を更新するのは効率的ではないため、オプションBは不正解です。
Bigtableはワイドテーブルをサポートしておらず、各秒の値を列データとして結合するのは非効率的であるため、オプションDは不正解です。
参考リンク
https://cloud.google.com/bigtable/docs/schema-design-time-series
</div></details>

### Q. 13
顧客が自社の商品を購入する確率を予測するためにBigQuery MLで線形回帰モデルを開発する際、重要な予測要因として都市名の変数がありますが、モデルの学習と展開のためにデータを列に効率的に構造化し、必要な変数を保持しながら必要なコーディング工数を最小限に抑えるにはどうすればよいでしょうか？
1. 　
2. BigQueryのSQLを使用して、ワンホットエンコーディング法を使用してstateカラムを変換し、各都市をバイナリ値を持つカラムにします。
3. 
4. 
<details><div>
    答え：2
説明
正解はBです。
これは各都市に新しい列を作成し、都市名に基づいて各行にバイナリ値を割り当てるので、データを準備する最も効率的な方法です。これにより、モデルは都市名を予測変数として使用できるようになります。
不正解の選択肢
A. 都市情報の列を含まない新しいビューをBigQueryで作成しても、都市を予測変数として使用するために必要な情報をモデルに提供することはできません。
C. C. TensorFlow を使用して語彙リストを持つカテゴリ変数を作成すると、時間がかかりすぎ、必要以上のコーディングが必要になる。
D. クラウドデータフュージョンを使って、各都市を1,2,3,4,5とラベル付けされた地域に割り当て、その番号を使ってモデルで都市を表すことは、予測変数として都市を使うために必要な情報をモデルに提供しない。
</div></details>

### Q. 14
あなたは、北米で広く事業を展開する有名銀行に雇われている。あなたの仕事は、銀行口座取引を管理するために設計されたデータストレージシステムを構築することです。あなたの具体的なニーズには、ACIDコンプライアンス原則の遵守と、SQLクエリを使用してデータを取得する機能が含まれます。この目的に適したソリューションは何でしょうか？
1. 　トランザクションデータをCloud Spannerに格納する。ステールリードを有効にしてレイテンシを減らす。
2. トランザクションデータをCloud Spannerに格納する。ロック付き読み書きトランザクションを使用する。
3. トランザクションデータをBigQueryに保存する。クエリキャッシュを無効にして一貫性を確保する。
4. トランザクションデータをCloud SQLに格納する。分析にはBigQueryとの連携クエリを使用する。
<details><div>
    答え：2
説明
オプションB：
Cloud Spannerはグローバルに分散され、ACIDコンプライアンスを提供する一貫性の強いデータベースサービスであるため、銀行口座のトランザクションを処理するのに適している。Cloud Spannerでロック付き読み書きトランザクションを使用すると、データの一貫性と整合性を確保できます。
以下はオプションBに関する考慮事項です：
強力な一貫性： Cloud Spannerは強力な一貫性を提供します。これは銀行環境でデータの整合性を維持するために極めて重要です。
ACIDコンプライアンス： Cloud SpannerはACIDに準拠しており、トランザクション・データ・ストレージの要件を満たしています。
読み書きトランザクションのロック 読み書きトランザクションをロックすることで、データへのアクセスを制御して競合を防ぎ、データの整合性を確保できます。
不正解の選択肢
A. 
Cloud SpannerはACIDに準拠しており、トランザクション・データに適していますが、ステール・リードを有効にするとデータの一貫性が損なわれる可能性があります。ステイル・リードを有効にすると、最新ではないデータを読み込むことができるため、データの整合性が重要な銀行口座のトランザクションには適していません。
C. 
BigQueryは分析ワークロード用に設計されており、トランザクションデータベースではない。ACID コンプライアンスや強力なトランザクション一貫性は提供しません。BigQueryのクエリキャッシュを無効にしても、これらの基本的な要件には対処できません。
D. 
Cloud SQL は、ACID コンプライアンスと強力な一貫性を提供するマネージド・リレーショナル・データベースであり、トランザクション・データの保存に適しています。BigQueryとの連携クエリを分析に使用することで、トランザクション処理と分析で両方のサービスの強みを活用できます。このアプローチはバランスが取れており、指定された要件を満たすことができます。
</div></details>

### Q. 16
現在、Spark、Hive、HDFSを利用した大規模なオンプレミスクラスターをコロケーション施設で使用していますが、コスト削減を最大化しつつ、クラウドへの移行をタイムリーに行うにはどうすればよいでしょうか？このクラスタはピーク時の利用を想定して設計されていますが、多くのバッチジョブがあるため、需要が変動しています。貴社はまた、オンプレミスのオーバーヘッドとメンテナンスコストの削減を目指し、クラウドのサーバーレス・オファリングを採用することで、インフラを近代化しようとしています。コロケーション施設の契約更新まで2カ月しかありませんが、これらの目的を達成するためにどのような移行戦略をお勧めしますか？
1. 　
2. ワークロードをDataproc plus Cloud Storageに移行し、後でモダナイズする。
3. 
4. 
<details><div>
    答え：2
説明
クラウドに移行してオーバーヘッドを削減し、コスト削減のメリットを享受するという貴社の目標と、最初の移行期間が2カ月という限られた期間であることを考慮すると、推奨されるアプローチは次のようになります：
B. 
このアプローチが適している理由は以下の通りです：
混乱を最小限に抑える： Googleクラウド上のマネージドSparkおよびHadoopサービスであるDataprocにワークロードを移行することで、既存のSparkおよびHiveジョブの中断を最小限に抑えることができます。DataprocはSparkとHiveのワークロードを実行するための使い慣れた環境を提供するため、迅速な移行が容易です。
コスト効率： データストレージソリューションとしてDataprocとCloud Storageを併用することで、クラウドのコスト効率の高いストレージオプションを活用することができます。クラウドストレージは拡張性が高く、競争力のある価格設定なので、オンプレミスのインフラストラクチャのオーバーヘッドなしにデータを保存できます。
時間的制約： 初期移行に2ヶ月というタイトなスケジュールを考えると、短時間で比較的簡単に移行できる戦略を優先することが重要です。Dataprocとクラウド・ストレージへの移行は、ワークロードをすぐにモダナイズするのに比べ、より直接的な方法です。
近代化： 最初の移行が完了した後に、最新化を計画することができます。ワークロードがクラウドで実行されるようになったら、BigQuery for HiveのモダナイゼーションやDataflow for Sparkのモダナイゼーションのようなサーバーレスオファリングを徐々に検討し、サーバーレスの機能とコストの最適化を活用しながら進めることができます。
オプションC（SparkワークロードをDataprocとHDFSに移行し、HiveワークロードをBigQuery用にモダナイズする）は、Hiveをすぐにモダナイズする特定のニーズがある場合に検討できます。ただし、オプションBに比べて複雑さが増し、実行に時間がかかる可能性があります。
オプションD（SparkとHiveの両方のワークロードをすぐに最新化する）は、最新化の取り組みがコード、アーキテクチャ、およびプロセスの変更を伴う可能性があるため、特に2カ月の時間枠を考えると、より長くリスクの高い経路になる可能性があります。
参考リンク
Cloud Dataproc:- https://cloud.google.com/dataproc/
</div></details>

### Q. 18
テーブルをBigQueryに移行してデータモデルを決定する際、クエリのパフォーマンスを最適化するためにテーブルをどのように構造化すべきでしょうか？問題のテーブルには、複数の店舗での購入に関するデータが含まれており、トランザクションのタイムスタンプ、購入したアイテム、店舗ID、各店舗の市や州などの詳細が含まれています。定期的なクエリでは、過去30日間の個々のアイテムの売上を追跡し、州、都市、特定の店舗に基づいて購入パターンを分析します。
1. 　トランザクション時間でパーティショニングし、最初に州、次に市、次に店舗IDでクラスタリングします。
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解はAです。
このオプションを使用すると、トランザクションの時間、州、市、および店舗IDによってテーブルをすばやくクエリできるため、正解です。これにより、探している特定の店舗、市町村、州をすばやく絞り込むことができるため、テーブルをクエリする際に最高のパフォーマンスが得られます。
不適切なオプション
最初に店舗 ID でクラスタリングすると、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション B は正しくありません。
最初に州によってトップレベル・クラスタリングを行うと、テーブルをクエリするときに最高のパフォーマンスが得られないため、オプション C は正しくありません。
最初にストア ID を指定したトップレベル・クラスタリングでは、テーブルへのクエリ時に最高のパフォーマンスは得られないため、オプション D は正しくありません。
参照リンク
https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 19
Pub/Sub フィードのサブスクライバのコードを更新しています。展開時にサブスクライバが誤ってメッセージを承認してしまい、メッセージが失われることを懸念しています。サブスクライバは確認メッセージを保持するように設定されていません。
展開後のエラーからの回復を保証するにはどうすればよいですか?
1. 　ローカル・マシンにPub/Subエミュレータをセットアップします。本番環境にデプロイする前に、新しいサブスクライバ・ロジックの動作を検証してください。
2. 新しいサブスクライバコードをデプロイする前に、Pub/Sub スナップショットを作成します。Seek 処理を使用して、スナップショットの作成後に利用可能になったメッセージを再配信します。
3. デプロイには Cloud Build を使用します。デプロイ後にエラーが発生した場合は、Seek オペレーションを使用して、デプロイ開始時に Cloud Build によってログに記録されたタイムスタンプを検索します。
4. Pub/Sub トピックでデッドレタリングを有効にして、正常に承認されなかったメッセージを捕捉する。展開後にエラーが発生した場合は、デッド・レター・キューでキャプチャされたメッセージをすべて再配信します。
<details><div>
    答え：2
説明
オプション B. 
新しいサブスクライバ・コードをデプロイする前に Pub/Sub スナップショットを作成することで、特定の時点のサブスクリプションの状態を取得できます。新しいサブスクライバコードの問題により、誤って承認され失われたメッセージがある場合、Seek 操作を使用して、スナップショットの作成後に利用可能になったメッセージを再送信することができます。
この方法は、誤った確認応答によって失われたメッセージを回復するのに効果的です。ただし、メッセージの回復を確実に行うには、スナップショットの作成と管理に依存します。
誤ったオプション
A. 
ローカルでのテストは開発に不可欠な要素ですが、本番環境でのサブスクライバの動作にエラーがないことを保証するものではありません。Pub/Sub エミュレータは本番環境を完全に再現しているとは限らず、動作に違いが生じる可能性があります。さらに、このオプションは、デプロイ後にエラーが発生した場合にメッセージを回復するメカニズムを提供しません。
C. 
Cloud Build はデプロイメントを管理するための貴重なツールですが、Cloud Build によってログに記録されたタイムスタンプに依存してエラーを回復することは、最も単純で効率的な方法ではない可能性があります。手作業が必要であり、メッセージ復旧に必要なメッセージ固有の詳細を取得できない可能性があります。さらに、タイムスタンプだけでは、メッセージ処理の正確な状態をピンポイントで特定するには不十分な場合があります。
D. 
デッドレターを有効にすることは、正常に処理できなかったメッセージをキャプチャするための確立された方法です。これは、処理中にエラーが発生したメッセージを回復するための体系的かつ自動化された方法を提供し、デプロイ後のメッセージ回復を確実にするための、より強固なオプションとなります。
参考リンク
Cloud Pub/Sub:- https://cloud.google.com/pubsub/
</div></details>

### Q. 20
著名な不動産会社に勤務するあなたは、機械学習用に6TBもの膨大な住宅販売データを準備する仕事を任されています。あなたの目的は、データ変換にSQLを利用し、機械学習モデルを確立するためにBigQuery MLを採用することです。このモデルは、未処理の生のデータセットに対して予測を行うことを目的としています。予測段階でスキューを効果的に回避するために、ワークフローを構成する上でどのような手順を踏むべきですか？
1. 　モデルを作成する際、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データに対して変換を指定しません。
2. 
3. BigQueryビューを使用して前処理ロジックを定義します。モデルを作成する際、そのビューをモデルの学習データとして使用します。予測時には、生の入力データに対して変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
4. Dataflowを使用してすべてのデータを前処理する。予測時には、入力データに対してさらなる変換を指定せずに、BigQueryのML.EVALUATE句を使用します。
<details><div>
    答え：1
説明
オプションA. 
モデル作成時には、BigQueryのTRANSFORM句を使用して前処理ステップを定義します。モデルの学習時には、これらの前処理ステップが学習データに適用されます。
予測時には、BigQueryのML.EVALUATE句を使用し、生の入力データには変換を指定しません。これは、予測を行う前にモデルが内部的に生の入力データに同じ前処理ステップを適用することに依存していることを意味します。
モデルの前処理ロジックが十分に定義され、トレーニングデータと一貫している場合、オプションAは効果的に機能するかもしれませんが、予測中にモデル自身が未加工の入力データの前処理を正しく処理する必要があります。このアプローチは、モデル内部の前処理が予測の歪みを防ぐのに十分であることを前提としています。
実際には、オプション A とオプション B のどちらを選択するかは、モデル内部の前処理ロジッ クの具体的な特性と信頼性、および予測プロセスにおける透明性と制御の要件によって決まります。どちらのオプションも有効ですが、前処理と予測の一貫性に対するアプローチが異なります。
正しくないオプション
オプションC - 
BigQueryビューを使用して前処理ロジックを定義することは、学習データと予測データ間の一貫性を確保するための有効なアプローチです。しかし、このオプションには、ML.EVALUATE を使用する前の生の入力データに対する明示的な変換ステップがありません。このビューは一貫した前処理ロジックを提供しますが、スキューを防止するために、生の入力データが同じ前処理ステップを受けることを確実にすることが重要です。
オプションD - 
Dataflowを使用してすべてのデータを前処理することは、データ変換と準備のための実行可能なソリューションです。しかし、このオプションはDataflowの前処理と予測中のモデル内部の前処理が同一であることを前提としています。また、前処理ステップには必要ないかもしれないが、Dataflowによってさらなる複雑さがもたらされる。
オプションCとオプションDの両方は、ML.EVALUATEを使用する前に生の入力データを一貫して変換する必要性に明示的に対処していません。
参考リンク
BigQuery ML:- https://cloud.google.com/bigquery/docs/bigqueryml-intro
</div></details>

### Q. 21
あなたはある会社の株価を分析しています。5秒ごとに、過去30秒分のデータの移動平均を計算する必要があります。あなたはPub/Subからデータを読み込み、DataFlowを使って分析を行っています。ウィンドウ・パイプラインをどのようにセットアップしますか？
1. 　5秒間の固定ウィンドウ
2. 継続時間30秒の固定ウィンドウ
3. 継続時間5秒のスライディング・ウィンドウ
4. 継続時間30秒、周期5秒のスライディング・ウィンドウを使用します。以下のトリガーを設定して結果を出力する： AfterWatermark.pastEndOfWindow()を設定する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
30秒のスライディング・ウィンドウ： 期間30秒のスライディング・ウィンドウを使用することは、移動平均計算のために直近の30秒間のデータを考慮し続けることを意味します。これはあなたの要求と一致しています。
期間5秒： 期間5秒は、ウィンドウが5秒ごとに前方にスライドすることを示します。こ れに よ り 、 直近 30 秒のデー タ に基づいて 5 秒ご と に移動平均を計算す る こ と が保証 さ れます。この設定は、5秒ごとに移動平均を計算するという要件に合致しています。
トリガー設定： トリガーは、透かしがウィンドウの最後を通過した後に結果を出すように設定されています。これにより、ウィンドウが前方にスライドしたときに計算がトリガーされ、移動平均計算の望ましいタイミングと一致します。
誤ったオプション
オプションA（5秒間の固定ウィンドウ）は、過去30秒分のデータを取り込みません。これは、5秒間の固定ウィンドウを提供しますが、要件を満たしていません。
オプションB（継続時間30秒の固定ウィンドウ）は、30秒のウィンドウをキャプチャしますが、5秒ごとに前方にスライドしません。これは、5秒ごとに移動平均を計算するという要件に合致しません。
オプションC（継続時間5秒のスライディング・ウィンドウ）は5秒のスライディング・ウィンドウをキャプチャしますが、過去30秒のデータの移動平均を計算するために必要な30秒の継続時間を持ちません。さらに、トリガー設定は30秒後にデータを処理するように設定されており、5秒間隔の要件とは一致しません。
参考リンク
ビーム・ウィンドウの基本:https://beam.apache.org/documentation/programming-guide/#windowing-basics
</div></details>

### Q. 22
データのスケーラブルな処理とBigQueryへのロードを保証すると同時に、これらのイベントをPub/Subトピックにパブリッシュするために構築しているパイプライン内で、メッセージのシーケンシングは気にしなくても、1時間ごとにアプリケーションイベントを集約できるようにするには、どのようなテクノロジを採用すべきでしょうか？
1. 　
2. 
3. 
4. Pub/Subトピックから継続的に読み取り、タンブリング・ウィンドウを使用して必要な集約を実行するストリーミングDataflowジョブを作成します。
<details><div>
    答え：4
説明
正しい選択肢はDです。
ストリーミングDataflowジョブはPub/Subトピックからのメッセージを継続的に処理し、タンブリング・ウィンドウを使用して必要な集計を実行できるため、このオプションは正しい。これにより、大量のイベントに対応しながら、タイムリーにデータが処理され、BigQueryにロードされます。
不正解の選択肢
クラウド関数は、新しいメッセージがトピックにパブリッシュされたときにのみトリガされ、1時間ごとの区切りでイベントを処理および集計できないため、オプションAは不正解です。
オプション B は、クラウド関数が Pub/Sub トピックから利用可能なすべてのメッセージをプルし、1 回の実行で必要な集計を実行できるだけであり、1 時間ごとの区切りでイベントを処理および集計することはできないため、不正解です。
バッチデータフロージョブは、Pub/Subトピックから利用可能なすべてのメッセージをプルし、1回の実行で必要な集計を実行できるだけであり、不連続な時間間隔にわたってイベントを処理および集計することはできないため、オプションCは正しくありません。
参考リンク
https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines
</div></details>

### Q. 23
大手金融機関の従業員として、Dialogflowを使用してモバイルアプリケーション内でチャットボットを作成しようとしているあなたは、過去のチャット記録を綿密に調査し、顧客がカスタマーサービスに連絡した理由と一致する意図に従って、すべての会話を分類しました。顧客からの問い合わせの約70%は率直な要求が中心で、通常、最初の10件以内に解決されます。一方、残り30％の問い合わせは複雑で、対応にかなりの時間と労力を要する。このような状況を踏まえて、最初に自動化の優先順位をつけるべきインテントはどれでしょうか？
1. 　生のエージェントがより複雑なリクエストに対応できるように、リクエストの70%をカバーする10のインテントを自動化する。
2. より複雑な要求を最初に自動化する
3. 最短インテントと最長インテントのブレンドを自動化する
4. 「支払い」などの一般的な単語が一度しか表示されない場所でインテントを自動化する
<details><div>
    答え：1
説明
正しい選択肢 A. 
顧客リクエストの70%をカバーする最も一般的な10のインテントを自動化することは、現実的なアプローチです。自動化によって、顧客からの問い合わせの大部分に効率的に対応することに重点を置いています。これらのインテントを自動化することで、一般的なリクエストに対して迅速かつ一貫したレスポンスを提供できるようになり、効率が向上するだけでなく、ユーザーエクスペリエンスも向上します。
生身のエージェントが定型的で頻繁に発生するリクエストの処理から解放されることで、より複雑で個別対応が必要な残りの30%の問い合わせに、より多くの時間と注意を割くことができます。これにより、リソースの割り当てが最適化され、複雑な問題に対する全体的なサービス品質が向上します。
誤ったオプション
オプションB（「より複雑なリクエストを最初に自動化する」）は、場合によっては合理的なアプローチですが、大半の顧客からの問い合わせの効率を最適化するという当面の問題には対処できないかもしれません。複雑なリクエストに集中するあまり、最も一般的で簡単なリクエストがおろそかになる可能性がある。
オプションC（「最も短いインテントと最も長いインテントの混合を自動化する」）は、様々なインテントタイプで自動化のバランスを取ろうとしているが、顧客リクエストの分布と一致しない可能性がある。あまり一般的でないインテントを不必要に自動化する可能性がある。
オプションD（「"payment "などの一般的な単語が一度だけ出現する場所のインテントを自動化する」）は、必ずしも頻度や複雑さではなく、特定のキーワードに基づいてインテントを優先する。このアプローチでは、最も一般的または重要なインテントを捕捉できない可能性があります。
参考リンク
AI製品： https://cloud.google.com/products/ai/
</div></details>

### Q. 24
あなたは、現在構築中のBigQueryベースのデータウェアハウスのデータモデルを作成する責任を与えられました。スター型データスキーマを使用する既存のオンプレミス販売データウェアハウスをBigQueryプラットフォームに移行することが、目下の課題です。しかし、過去30日間の履歴データに対してクエリを実行したところ、パフォーマンスのボトルネックが発生しました。Googleが推奨するベストプラクティスに従って、ストレージ費用を抑えながらクエリ速度を向上させるには、どのような対策を講じればよいでしょうか？
1. 　データの非正規化
2. 顧客IDごとにデータをシャーディングする
3. ビューで次元データをマテリアライズする
4. トランザクションの日付でデータをパーティショニングします。
<details><div>
    答え：4
説明
BigQueryで過去30日分のデータをクエリする際に、データウェアハウスのストレージコストを増加させずにクエリのパフォーマンスを高速化するには、次のことを考慮する必要があります：
D. 
パーティショニング： パーティショニングとは、特定の属性（この場合はトランザクション日付など）に基づいて、データをより小さく管理しやすい塊に整理することです。パーティショニングは、時間ベースのデータのクエリ・パフォーマンスを向上させる効果的な方法です。データを日付でパーティショニングすると、BigQueryは特定の日付範囲のクエリを実行する際に、無関係なパーティションを効率的に削除することができます。
時間ベースのクエリ： パーティショニングは、過去30日間のデータをクエリする要件に適しています。これにより、BigQueryは関連するパーティションに焦点を当てることができ、データセット全体をスキャンするよりも大幅に高速化されます。
コスト効率： パーティショニングはデータの論理的な整理であるため、ストレージコストを増加させることはありません。使用するストレージの代金は支払いますが、パーティショニング自体がストレージ・コストを増加させることはありません。コストに影響を与えることなく、クエリのパフォーマンスを最適化します。
誤ったオプション
オプションA（データの非正規化）は、特定のタイプのクエリには役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスの問題には特に対応していません。
オプションB（顧客IDごとにデータをシャーディングする）は、日付ベースのクエリのパフォーマンスを直接改善しない可能性があり、特定の日付範囲のデータをクエリするときに複雑さをもたらす可能性があります。
オプションC（ビューで次元データをマテリアライズする）は、クエリを単純化するのに役立ちますが、時間ベースのデータに対するクエリ・パフォーマンスを最適化するには、パーティショニングほど効果的ではないかもしれません。
参考リンク
BigQuery パーティショニング: https://cloud.google.com/bigquery/docs/partitioned-tables
</div></details>

### Q. 25
5年分のログデータをクラウドストレージにアップロードしました。あるユーザーから、ログの特定のデータポイントが想定される範囲から外れており、潜在的なエラーがあることを指摘されました。あなたの目的は、この問題を解決し、コンプライアンス目的で元のデータを保持しながら、将来的にプロセスを再実行できるようにすることです。どのような手順を踏むべきでしょうか？
1. 　データをBigQueryにインポートし、エラーのある行をスキップする
2. Compute Engineのインスタンスを作成し、エラーのある行をスキップしながらデータをコピーする
3. データフローワークフローを作成し、クラウドストレージからデータを読み取り、予期される範囲外の値をチェックし、値を適切なデフォルトに設定し、更新されたレコードをクラウドストレージの新しいデータセットに書き込む。
4. 更新されたレコードをクラウドストレージの同じデータセットに書き込む
<details><div>
    答え：3
説明
コンプライアンス上の理由から元のデータを保持しながら、ログデータ内の想定範囲外のデータポイントの問題に対処するには、次のことを検討する必要があります：
C. C. 
このオプションが適切な理由は以下の通り：
データ変換： データ変換： データフローを使用することで、元のデータセットを保持したまま、期待範囲外のデータポイントを識別して修正するデータ変換ロジックを実装することができます。これにより、誤ったデータが確実に修正されます。
オリジナルデータの保持： 更新されたレコードをクラウド・ストレージの新しいデータセットに書き込むことで、コンプライアンス上の理由からオリジナル・データの整合性を維持することができます。このアプローチでは、元のデータセットがそのまま維持され、分析や使用のために修正されたクリーンなバージョンが提供されます。
誤ったオプション
オプションA（データをBigQueryにインポートし、エラーのある行をスキップする）はうまくいくかもしれませんが、コンプライアンス上の理由で必要となる可能性がある、元のデータを変更されていない状態で保持することはできません。
オプションB（Compute Engineのインスタンスを作成し、エラーのある行をスキップしながらデータをコピーする）は、手作業で複雑なプロセスになる可能性があり、Dataflowのようなデータ処理フレームワークを使用するほど効率的ではないかもしれない。
オプションD（更新されたレコードをクラウドストレージの同じデータセットに書き込む）は、元のデータを上書きする。
</div></details>

### Q. 26
サーバーレスツールとSOL構文を活用して開発を加速し、パイプラインの実行時間を短縮しながら、スピードと処理要件を満たすGoogle Cloudパイプラインを構築するにはどうすればよいでしょうか？現在のアプローチでは、大規模なデータ変換にPySparkを使用しており、実行に12時間以上かかっています。生データがクラウドストレージに転送されていることは重要です。
1. 　Dataproc上でパイプラインを実行する
2. Cloud SQLにデータを取り込み、連携クエリを使用
3. Cloud StorageからBigQueryにデータを取り込み、PySparkコマンドをBigQuery SQLクエリに変換してデータを変換し、変換結果を新しいテーブルに書き込みます。
4. Apache Beam Python SDKの使用
<details><div>
    答え：3
説明
Google Cloud上の構造化データで速度と処理要件を満たしながら、開発とパイプラインの実行時間を短縮するには、次のことを検討する必要があります：
C. C. 
サーバーレスでスケーラブル： BigQueryはサーバーレスデータウェアハウスであり、インフラストラクチャを管理することなく大規模なデータ処理を行うことができます。高速処理のために設計されているため、パイプラインの実行時間を短縮できる。
SQL構文： SQL構文を使用したいので、BigQueryは完全に管理された強力なSQLエンジンを提供します。PySparkのコマンドを直接BigQueryのSQLクエリに変換できるので、移行や変換のプロセスがスムーズになります。
クラウドストレージとの統合： BigQueryはクラウドストレージとシームレスに統合されており、クラウドストレージからBigQueryにデータを取り込んで分析や変換を行うことができます。
変換の書き込み： BigQueryはSQL変換の結果を新しいテーブルに書き出すことをサポートしており、元のデータを保持したまま、さらなる分析のために変換されたデータを保存できます。
誤ったオプション
オプションA（Dataproc上でパイプラインを実行する）では、Dataprocクラスタのセットアップと管理が必要になるため、BigQueryのようなフルマネージドサービスを使用する場合と比較して、コスト効率や利便性が劣る可能性があります。
オプションB（Cloud SQLにデータを取り込み、連携クエリを使用）は、データ処理に複数のサービスを使用するため複雑さが生じ、BigQueryのようなパフォーマンスメリットが得られない可能性がある。
オプションD（Apache Beam Python SDKの使用）は有効な選択肢ですが、BigQueryのビルトインSQL機能を活用するのに比べて開発工数がかかる可能性があります。Pythonの使用を好み、データ変換プロセスをより制御する必要がある場合は、Apache Beamが適切な選択肢になる可能性があります。
</div></details>

### Q. 27
テキストファイルを取り込んで変換するDataflowパイプラインをテストしています。Dataflowジョブは、圧縮されたgzipファイル、デッドレターキューによるエラー処理、データ結合のためのSideInputsの利用により、予想よりも遅く実行されています。パイプラインの完了を加速するために、どのようなアクションを取るべきでしょうか？
1. 　圧縮Avroファイルへの切り替え
2. バッチサイズを小さくする
3. エラーをスローしたレコードを再試行する
4. SideInputの代わりにCoGroupByKeyを使用する。
<details><div>
    答え：4
説明
正しい選択肢 D. 
CoGroupByKey： CoGroupByKey: CoGroupByKeyは、Apache Beam（Dataflowの基盤）の変換で、複数の入力PCollectionsからのデータを共通のキーに基づいてグループ化する。複数のソースからのデータを効率的に結合するために使用できます。SideInputsの使用に関連したパフォーマンス問題が発生している場合、CoGroupByKeyに切り替えることが有効な最適化かもしれません。SideInputsは、特に大きなデータセットを扱う場合、要素ごとのルックアップを伴うため、オーバーヘッドが発生する可能性があります。
SideInputsの代わりにCoGroupByKeyを使用するように処理戦略を変更することで、パフォーマンスの問題に対処できる可能性があります。このオプションの選択は、パイプラインの仕様と、どこでボトルネックが発生しているかに依存します。パイプラインの動作とパフォーマンス特性を分析し、十分な情報を得た上で決定することが重要です。
誤ったオプション
オプションA（圧縮Avroファイルへの切り替え）は、主にデータストレージと圧縮効率に対処しますが、特にパフォーマンスのボトルネックが圧縮ではなくデータ処理にある場合、Dataflowジョブを直接迅速化しない可能性があります。
オプションB（バッチサイズを小さくする）は、ある程度ジョブ効率を向上させることができますが、SideInputsやjoinオペレーションに関連するパフォーマンス問題に対処する最も効果的な方法ではないかもしれません。小さいバッチは並列処理に役立つが、処理戦略を根本的に変えないかもしれない。
オプションC（エラーをスローしたレコードを再試行する）は、エラー処理に重点を置いており、ジョブ実行時間の問題に直接対処していない。エラーを効果的に処理することは不可欠ですが、ジョブの完了を早める主要な方法ではありません。
参考リンク
https://beam.apache.org/documentation/transforms/python/aggregation/cogroupbykey/
</div></details>

### Q. 28
あなたは、PII（個人を特定できる情報）データを含む可能性のあるファイルをクラウドストレージにストリームし、最終的にBigQueryにストリームするリアルタイム予測エンジンを構築しています。PIIデータへの不正アクセスを防ぐために、クラウドデータ損失防止API（DLP API）を使用して、名前や電子メールなどの機密データをマスキングしながら参照整合性を維持するにはどうすればよいでしょうか。
1. 　暗号化トークンを作成し、トークン化されていないデータをロックダウンされたバケツに保存する
2. すべてのPIIデータを再編集する
3. BigQueryのすべてのテーブルをスキャンし、検出したデータをPIIでマスクする
4. PIIデータを暗号化フォーマット保持トークンで置き換えて偽名を作成する。
<details><div>
    答え：4
説明
参照整合性を維持しながら、PII データに権限のない個人がアクセスできないようにするには、次のアプローチを検討する必要があります：
D. D. 
このオプションが適切な理由は以下のとおりです：
暗号化形式保存トークン： 暗号化トークン：暗号化トークンを使用することで、PII データの形式と参照整合性を保持したまま、PII データを仮名化することができます。これにより、名前や電子メールなどの結合キーが引き続き効果的に使用できるようになります。
機密データの保護： 暗号化トークンを使用することで、強力なデータ保護が実現し、権限のない個人による機密PIIデータへのアクセスや悪用が困難になります。
不正なオプション
オプション A（暗号化トークンを作成し、トークン化されていないデータをロックダウンされたバケツに保存する）は、PII データを仮名化するという点ではオプション D に似ていますが、フォーマットと参照整合性を維持するために不可欠な暗号化フォーマット保持トークンの使用を指定していません。
オプションB（すべてのPIIデータを再編集する）は、機密情報を永久に削除します。これは、結合キーの参照整合性を維持する必要がある場合には適していない可能性があります。
オプションC（BigQueryのすべてのテーブルをスキャンし、検出したデータをPIIでマスクする）はBigQueryに有効かもしれませんが、クラウドストレージからのPIIデータ取り込みプロセスに直接対応しておらず、暗号化トークンの使用についても言及していません。
参考リンク
クラウドDLP
</div></details>

### Q. 29
図書館の本とその詳細(著者や出版年など)をモニタリングするアプリケーションをオンプレミスのデータ ウェアハウスから BigQuery に移行する際に、借りた書籍の著者に関する情報のクエリ速度を最速にするために、Google が推奨するスキーマ設計手法に従ってデータをどのように構成しますか?既存の設定では、著者の詳細を個別のテーブルに保持し、現在のリレーショナル データベース内の共有キーを介して書籍情報にリンクします。
1. 　スキーマを同じに保ち、書籍と各属性の異なるテーブルを維持し、現在行っているようにクエリを実行します
2. 幅が広く、作成者の銘、性、年月日など、各属性の列を含むテーブルを作成します
3. 書籍と著者に関する情報を含むテーブルを作成しますが、著者フィールドは著者列内にネストします。
4. スキーマを同じに保ち、すべてのテーブルを結合するビューを作成し、常にビューをクエリします
<details><div>
    答え：3
説明
図書館の図書追跡アプリケーションを BigQuery に移行する際に、借りた各書籍の著者に関するクエリの速度を最適化するには、次の方法を検討する必要があります。
C. 
ネストされたデータ: BigQuery は、テーブル内のネストされたフィールドと繰り返されるフィールドをサポートしています。著者情報を著者列内に入れ子にすることで、コストのかかる結合を回避しながら、書籍と著者の関係を維持できます。これにより、各書籍の著者に関する効率的なクエリが可能になります。
結合の削減: 著者情報を同じテーブル内に保持すると、著者の詳細と書籍の詳細を照会するときに結合が不要になります。これにより、クエリの実行が高速化され、待機時間が短縮されます。
簡略化されたクエリ: 入れ子になったデータを使用すると、クエリを簡略化し、複数のテーブルを結合する複雑さを回避できます。著者情報は、書籍情報と同じ行内で直接アクセスできます。
正しくないオプション -
オプション A (書籍と属性のテーブルを分けてスキーマを同じに保つ) は、結合が必要になる可能性が高く、著者に関するクエリでは効率的ではない可能性があります。
オプション B (各属性の列を含む幅の広いテーブルを作成する) は、特に作成者に複数の属性がある場合、スキーマが非正規化され、保守性が低下する可能性があります。
オプション D(すべてのテーブルを結合するビューを作成する)では、結合が必要になるため、クエリのパフォーマンスが低下する可能性があり、ネストされたデータ構造に対する BigQuery の機能を十分に活用できない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/nested-repeated
</div></details>

### Q. 30
データ ポイントを受信して GUID を生成するサービスを通じて、新しい Web サイト ユーザーにグローバル一意識別子 (GUID) を提供するときに、バックプレッシャーの懸念を最小限に抑えるためにパイプラインを構成するにはどうすればよいでしょうか。このデータは、内部システムと外部システムの両方から発生し、パイプライン内のマイクロサービスを介してHTTP呼び出しを介してアクセスされ、システムへのバックプレッシャーを回避しながら、マルチスレッドの可能性がある毎秒数万件の大量のメッセージの影響を受けます。
1. 　HTTP経由でサービスを呼び出します
2. パイプラインをクラス定義で静的に作成します
3. DnFnのstartbundleメソッドで新しいオブジェクトを作成します
4. ジョブを 10 秒単位でバッチ処理します。
<details><div>
    答え：4
説明
D. 
このオプションは、メッセージを 10 秒間隔でバッチ処理することを提案します。このアプローチの理論的根拠は次のとおりです。
バックプレッシャーの低減: 処理のためにメッセージをバッチ処理すると、メッセージの取り込みと処理の速度を制限することで、バックプレッシャーを減らすことができます。これにより、パイプラインへのデータフローを制御し、処理負荷の急増を防ぐことができます。
ただし、このアプローチにはトレードオフも生じることに注意することが重要です。
待機時間: メッセージをバッチ処理すると、一部のメッセージが次のバッチ ウィンドウまで遅延する可能性があるため、処理に待機時間が発生する可能性があります。これは、リアルタイムまたは低待機時間の処理が重要なシナリオには適していない可能性があります。
複雑さ: バッチ処理を実装すると、特にマイクロサービスや HTTP 呼び出しを処理する場合に、パイプラインが複雑になる可能性があります。定期的にバッチを管理およびフラッシュするメカニズムが必要になります。
正しくないオプション -
オプション A (HTTP 経由でサービスを呼び出す): このオプションは、通常、リアルタイムまたはほぼリアルタイムの処理に適していますが、バックプレッシャーを減らすという目標に合わない場合があります。各メッセージに対して HTTP 呼び出しを行う際の高スループットと潜在的なボトルネックを考慮することが重要です。
オプション B (クラス定義でパイプラインを静的に作成する) と C (DoFn の startBundle メソッドで新しいオブジェクトを作成する): これらのオプションは、バックプレッシャーに直接対処するのではなく、パイプライン コンポーネントの設計とインスタンス化に関連しています。これらは、高スループットのシナリオにおけるバックプレッシャーの懸念を本質的に軽減するものではありません。
</div></details>

### Q. 31
データ ウェアハウスを Google Cloud に移行し、オンプレミスのデータセンターをシャットダウンしているところです。この取り組みの優先度が高いことを認識した上で、クラウドへの初期データ転送に十分な帯域幅が提供されることを期待しています。移動するファイルの量はそれほど多くありませんが、個々のファイルは 90 ギガバイトを占有します。さらに、トランザクション システムから Google Cloud ベースのウェアハウスへの更新フローをリアルタイムで一定に維持することを目指しています。
データの移行と、ウェアハウスへの中断のない書き込みの保証の両方に推奨されるツールは何ですか?
1. 　移行用のストレージ転送サービス。Pub/Sub と Cloud Data Fusion
2. 移行用の BigQuery Data Transfer Service。Pub/Sub と Dataproc
3. gsutil (移行用)Pub/Sub と Dataflow によるリアルタイム更新。
4. 移行とリアルタイム更新の両方に gsutil
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
データ移行(gsutil):
gsutil: Google Cloud Storage Utility(gsutil)は、Google Cloud Storage との間でデータを効率的に転送するためのコマンドライン ツールです。これは、90 GB のファイルなどの大きなファイルの移行を処理するのに適しています。これは、初期データ読み込みのための簡単で効率的な選択です。
リアルタイム更新(Pub/Sub とデータフロー):
Pub/Sub: Google Cloud Pub/Sub は、トランザクション システムからダウンストリーム サービスにリアルタイムでデータをストリーミングするために使用できるスケーラブルなメッセージング サービスです。リアルタイムのデータストリーミング用に設計されており、他のGoogle Cloudサービスとうまく統合できます。
データフロー: Google Cloud Dataflow は、強力なストリームおよびバッチ データ処理サービスです。Pub/Sub からのリアルタイム データ ストリームを処理し、変換、集計、その他のデータ処理タスクを実行するために使用できます。リアルタイムのデータ更新に適しており、複雑なデータ処理シナリオを処理できます。
正しくないオプション -
オプション A (移行用のストレージ転送サービス。Pub/Sub と Cloud Data Fusion (リアルタイム更新用):
ストレージ転送サービス: ストレージ転送サービスは大規模なデータ転送に効率的ですが、主に 1 回限りまたは定期的な転送用に設計されています。リアルタイムのデータストリーミングには最適化されていません。
Cloud Data Fusion: Cloud Data Fusion はデータ統合サービスですが、通常はリアルタイムの更新ではなく、バッチ処理や ETL 処理に使用されます。リアルタイムの更新に使用すると、ソリューションが複雑になりすぎる可能性があります。
オプション B(移行用の BigQuery Data Transfer Service。Pub/Sub と Dataproc (リアルタイム更新用):
BigQuery Data Transfer Service: BigQuery Data Transfer Service は、BigQuery への自動データインポートに重点を置いているため、Google Cloud Storage への大容量ファイルの移行には適していない場合があります。
Dataproc: Google Cloud Dataproc は、主に Apache Spark と Hadoop のジョブの実行に使用されますが、リアルタイムの更新には必要ない場合があります。バッチ処理に適しています。
オプション D(移行とリアルタイム更新の両方に gsutil):
gsutil: gsutil はデータ移行には適していますが、リアルタイムのデータ ストリーミングや処理用には設計されていません。リアルタイム更新に gsutil を使用するのは現実的ではありません。
参考リンク -
https://cloud.google.com/storage/docs/gsutil
</div></details>

### Q. 32
Bigtable を使用して取引アプリケーションでこれらのインデックスの株式市場データを保存および提供する際に、すべての主要インデックスの最新の株価にアクセスするための最もシンプルなクエリを確実に行うには、Bigtable 内で行キーとテーブルをどのように構成すればよいでしょうか。
1. 　すべてのインデックスに対して一意のテーブルを 1 つ作成し、インデックスとタイムスタンプを行キーの設計として使用します
2. すべてのインデックスに対して一意のテーブルを 1 つ作成し、行キーの設計として逆タイムスタンプを使用します。
3. インデックスごとに個別のテーブルを用意し、行キーの設計としてタイムスタンプを使用します
4. インデックスごとに個別のテーブルを用意し、行キーの設計として逆タイムスタンプを使用します
<details><div>
    答え：2
説明
B. 
このオプションが適切であると考えられる理由は次のとおりです。
すべてのインデックスに対して 1 つのテーブル: すべてのインデックスに対して 1 つのテーブルを使用することで、複数のテーブルを作成する必要がなくなり、管理が簡素化されます。インデックスの数が多い場合は、それぞれに個別のテーブルを管理するのが面倒になる可能性があるため、特に便利です。
行キーとしての逆タイムスタンプ: 行キー設計として逆タイムスタンプを使用すると、最新の株価に簡単にアクセスできます。Bigtable は行を辞書式に並べ替えるため、最新のデータがテーブルの先頭に配置され、効率的に取得できます。
オプションBは機能しますが、いくつかのトレードオフと複雑さが伴います。
複雑な範囲クエリ: 最新のデータを取得するのは効率的ですが、履歴データに対して範囲クエリを実行するとより複雑になる場合があります。古いデータを効率的に取得するために、追加のロジックを実装する必要がある場合があります。
データの分離: 1 つのテーブルを使用すると、すべてのインデックスが一緒に格納されます。特定のインデックスを含むクエリを実行したり、特定のインデックスのデータを分離したりする必要がある場合は、追加のフィルター処理や処理が必要になることがあります。
正しくないオプション -
オプション A (すべてのインデックスに対して一意のテーブルを 1 つ作成し、インデックスとタイムスタンプを行キーの設計として使用します):
この方法では、タイムスタンプを抽出するために解析を必要とする複雑な行キー設計になる可能性があります。これにより、履歴データの範囲クエリの効率が低下する可能性があります。
オプション C (インデックスごとに個別のテーブルを用意し、行キーの設計としてタイムスタンプを使用します):
各インデックスのデータへのアクセスは簡素化されますが、インデックスの数が増えると、個別のテーブルを維持する必要があるため、管理オーバーヘッドが発生する可能性があります。
オプション D (インデックスごとに個別のテーブルを用意し、行キーの設計として逆タイムスタンプを使用します):
このオプションでは、インデックスごとに分離できますが、テーブルが急増し、管理が困難になる可能性があります。
参考リンク https://cloud.google.com/bigtable/docs/schema-design
</div></details>

### Q. 33
データの取り込みやレポート作成のパフォーマンスを損なうことなく 1 つのマスター データセットを維持するには、BigQuery のストリーミング API を使用して、Google が推奨するプラクティスに従って、レポートのみのデータ ウェアハウスのデータ読み込みプロセスをどのように構築すればよいのでしょうか?
1. 　3 時間ごとに運用テーブルを更新する
2. 90 分ごとに運用テーブルを更新する
3. ステージングされたデータを運用テーブルに移動し、ステージング テーブルの内容を 3 時間ごとに削除するステージング テーブルを用意します。
4. ステージング テーブルの内容を 30 分ごとに削除する
<details><div>
    答え：3
説明
C. 
このオプションが適切な理由は次のとおりです。
ステージング テーブル: ステージング テーブルを使用して、受信データを最初に取り込んで格納することは、一般的なベスト プラクティスです。これは、データ インジェスト用のバッファーを提供し、インジェスト プロセスを運用データセットから分離するのに役立ちます。
定期的な ETL: ステージング テーブルから運用テーブルに定期的に (この場合は 3 時間ごと) データを移動することで、マスター データセットの更新のタイミングを制御できます。これにより、レポートクエリが進行中の取り込みの影響を受けなくなります。
データのクリーンアップ: データを移動した後にステージング テーブルの内容を削除すると、過剰なデータが蓄積されることなく、新しいデータ インジェストに引き続き使用できます。
正しくないオプション -
オプション D (ステージング テーブルの内容を 30 分ごとに削除する) は、一部のユース ケースでは頻繁すぎる可能性があり、特に監査やエラー分析にデータ保持が必要な場合に、データ管理のオーバーヘッドが増加する可能性があります。
オプション A と B (3 時間または 90 分ごとに運用テーブルを更新する) では、レポート データセットの変更の反映に遅延が発生し、レポートの適時性に影響を与える可能性があります。
参考リンク -
https://cloud.google.com/bigquery/docs/streaming-data-into-bigquery
</div></details>

### Q. 34
新しい Dataflow バッチ ジョブを開始します。ジョブは正常に開始され、いくつかの要素を処理しますが、突然失敗して終了します。Dataflow モニタリング インターフェースにアクセスすると、パイプライン内の特定の DoFn に関連するエラー メッセージが検出されます。
これらのエラーの考えられる根本原因は何ですか?
1. 　ジョブの検証
2. ワーカー コードの例外
3. グラフまたはパイプラインの構築
4. アクセス許可が不十分
<details><div>
    答え：2
説明
B. 
Dataflow ジョブを開始すると、しばらくの間は正常に実行され、ワーカー コードの例外やエラーが原因で失敗することがあります。これらの例外により、ジョブが突然シャットダウンする可能性があります。特定の DoFn (パイプライン内の要素を処理するために定義する関数) に関連するエラーが表示される場合は、その DoFn 内のコードに問題がある可能性があります。
正しくないオプション -
A. ジョブの検証: Dataflow は通常、ジョブを開始する前に検証し、オプションの欠落や構成ミスなどの問題をチェックします。ジョブの検証で問題が発生した場合、ジョブは最初から開始されていない可能性があります。
C. グラフまたはパイプラインの構築: Dataflow パイプラインの構築方法の問題(コンポーネントの接続の誤りやフローの設定ミスなど)に関連します。これらの問題は通常、ジョブの検証または構築中に検出されますが、発生した場合、ジョブが開始時に失敗したり、期待どおりに実行されなかったりする可能性があります。
D. アクセス許可が不十分: これはアクセス許可とアクセス制御に関連しており、ジョブの開始や必要なリソースへのアクセスを妨げる可能性があります。アクセス許可が不十分な場合、ジョブが開始されなかったり、実行前に問題が発生したりする可能性があります。
参考リンク -
https://cloud.google.com/dataflow/docs/guides/common-errors
</div></details>

### Q. 35
新規顧客向けに、Google Cloud コンピューティング リソースの純消費量を詳細に記した日次レポートを迅速かつ効果的に作成し、これらのリソースのユーザーを特定するにはどうすればよいでしょうか。
1. 　Cloud Logging データを BigQuery に毎日エクスポートします。プロジェクト、ログタイプ、リソース、ユーザーでフィルタリングされたビューを作成します。
2. プロジェクト、リソース、ユーザーで Cloud Logging のデータをフィルタリングし、そのデータを CSV 形式でエクスポートする
3. Cloud Logging でデータをフィルタリングして BigQuery にインポートする
4. Cloud Logging データを CSV 形式で Cloud Storage にエクスポートし、Dataprep を使用してクレンジングする
<details><div>
    答え：1
説明
Google Cloud コンピューティング リソースの正味消費量とリソースを使用したユーザーを示す日次レポートを迅速かつ効率的に生成するには、次のオプションが最も適しています。
ある。
このオプションが適切な理由は次のとおりです。
Cloud Logging から BigQuery へ: ログデータを効率的に保存、分析するための一般的な方法は、Cloud Logging のデータを BigQuery にエクスポートする方法です。これにより、BigQuery のクエリ機能とスケーラビリティを活用できます。
フィルタリング用のビュー: BigQuery でビューを作成すると、プロジェクト、ログタイプ、リソース、ユーザーなどの特定の条件に基づいてデータを事前にフィルタリングできます。この事前フィルタリングにより、レポートを生成するための関連データを操作できるようになります。
毎日のエクスポート: 毎日のエクスポートを実行すると、レポートごとに新しいデータセットを操作でき、データを最新の状態に保つことができます。
正しくないオプション -
オプション B(プロジェクト、リソース、ユーザーで Cloud Logging のデータをフィルタリングし、そのデータを CSV 形式でエクスポートする)は機能する可能性がありますが、より複雑なクエリやレポート要件に対応する BigQuery の柔軟性と拡張性に欠けます。
オプション C(Cloud Logging でデータをフィルタリングして BigQuery にインポートする)では、追加のデータ移動手順が導入されるため、直接エクスポートよりも効率が悪く、タイムリーにならない可能性があります。
オプション D(Cloud Logging データを CSV 形式で Cloud Storage にエクスポートし、Dataprep を使用してクレンジングする)は複雑さを増し、日次レポートを生成するための BigQuery の直接的なアプローチほど効率的ではない可能性があります。
参考リンク -https://cloud.google.com/logging/docs/export/bigquery
</div></details>

### Q. 36
現在、単一のアジア地域内の顧客のみに対応しているスタートアップのWebアプリケーションが、最初はコストの最適化を優先し、後にネイティブJDBCドライバーを使用する要件でグローバルなプレゼンスとパフォーマンスの向上に焦点を当てながら、グローバルな顧客サービスを可能にするための資金を求める場合、どのような手順を踏む必要がありますか?
1. 　最初に Cloud Spanner を使用して単一リージョンのインスタンスを構成し、資金を確保した後に複数リージョンの Cloud Spanner インスタンスを構成します。
2. 最初に Cloud SQL for PostgreSQL の高可用性インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアのレプリケーションで Bigtable を使用します。
3. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアで Bigtable を使用します。
4. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、可用性の高い構成の Cloud SQL for PostgreSQL を使用します。
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
Cloud Spanner のスケーラビリティ: Cloud Spanner は、グローバルに分散された水平方向にスケーラブルなデータベースであり、複数のリージョン間で強力な一貫性を提供できます。単一リージョンのインスタンスから開始し、マルチリージョンのインスタンスを構成することは、資金を確保した後、グローバルなプレゼンスとパフォーマンスを最適化するという目標と一致します。
強力な整合性: Cloud Spanner は、強力な整合性が保証されていることで知られており、データの一貫性が重要なグローバル アプリケーションに適しています。
ネイティブ JDBC サポート: Cloud Spanner はネイティブ JDBC ドライバをサポートし、ウェブアプリケーションの要件との互換性を確保します。
正しくないオプション -
B. 最初に Cloud SQL for PostgreSQL の高可用性インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアのレプリケーションで Bigtable を使用します。
このオプションでは、可用性の高い Cloud SQL for PostgreSQL インスタンスから始めることをお勧めしますが、これは当初必要以上にコストが高くなる可能性があります。Bigtable はグローバル レプリケーションを提供できますが、Cloud SQL を最初に選択した時点では、資金調達前の費用最適化という目標に合致していない可能性があります。
C. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、米国、ヨーロッパ、アジアで Bigtable を使用します。
オプション B と同様に、当初の費用最適化を主な目標としている場合、Cloud SQL for PostgreSQL から始めるのは最も費用対効果の高い選択肢ではない可能性があります。また、Cloud SQL のグローバル拡張機能は、Cloud Spanner に比べて制限されています。
D. 最初に Cloud SQL for PostgreSQL ゾーン インスタンスを使用し、資金を確保した後、可用性の高い構成の Cloud SQL for PostgreSQL を使用します。
このオプションでは、Bigtable や Cloud Spanner などのグローバルに分散されたデータベースを使用しないため、グローバルなプレゼンスとパフォーマンスを最適化するという資金調達後の目標に合わない可能性があります。
要約すると、オプション B、C、D にはそれぞれメリットがありますが、オプション A は、Cloud Spanner のグローバルなスケーラビリティと強力な整合性機能を活用して、初期費用の最適化目標と資金調達後のグローバル展開とパフォーマンスの最適化の両方の目標と一致するため、シナリオに最適な選択肢です。
参照リンク - リージョン構成とマルチリージョン構成 - Cloud Spanner
</div></details>

### Q. 37
大規模なデータ転送に関する Google が推奨するベスト プラクティスを遵守しながら、わずか数時間でデータ転送を完了することを目標に、オンプレミスのデータセンターから Google Cloud に 1 PB のデータを安全かつ効率的に移行するには、どのような手順を踏む必要がありますか?
1. 　Cloud Interconnect and Storage Transfer Service
2. Transfer Appliance を使用し、エンジニアに手動でデータの暗号化、復号化、検証を依頼します。
3. loud VPN、並列 gcloud compute scp ジョブ、チェックサム
4. データを 3 TB のバッチに削減し、gsutil を使用し、チェックサムを実行する
<details><div>
    答え：2
説明
Google が推奨するプラクティスに従いながら、安全な接続を介してオンプレミスのデータセンターから Google Cloud に 1 PB のデータを効率的に移行するには、次のアプローチを検討する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
Transfer Appliance: Google の Transfer Appliance は、大量のデータを安全かつ効率的に移行できるように設計されています。これは、データをオフラインで読み込み、Google Cloud Storage に取り込むために Google に送付するために使用できる物理ストレージ アプライアンスです。
手動暗号化: Transfer Applianceの使用中に、アプライアンスにロードする前にデータを手動で暗号化できます。これにより、転送中のデータセキュリティが確保されます。
手動検証:データ転送が完了した後、エンジニアはデータを復号化して元のデータセットと比較することで、データの整合性を手動で検証できます。この検証プロセスにより、データが正確に転送されたことが保証されます。
正しくないオプション -
オプションA(Cloud Interconnect and Storage Transfer Service)は、わずか数時間で1 PBのデータを移行するために必要な速度を提供しない可能性があるため、このような大量のデータ転送には適していない可能性があります。
オプション C(Cloud VPN、並列 gcloud compute scp ジョブ、チェックサム)は、このような大量のデータを迅速かつ安全に転送するための最も効率的な方法ではない可能性があります。
オプション D(データを 3 TB のバッチに削減し、gsutil を使用し、チェックサムを実行する)は、小規模なデータセットでは実現可能ですが、大量のデータが含まれるため、わずか数時間で 1 PB の移行を行うのは現実的ではない可能性があります。
速度、セキュリティ、Google のベスト プラクティスの遵守を目標とする 1 PB のデータ移行では、手動で暗号化と検証を行う Transfer Appliance の使用をおすすめします。この方法は、大規模なデータセットを Google Cloud に転送するための安全で効率的な方法を提供します。
参考リンク -
https://cloud.google.com/products/data-transfer/
</div></details>

### Q. 38
CSV ファイルを Cloud Storage から BigQuery に読み込む際に、1 つの列に STRING や INT64 などのデータ型が混在していたり、電話番号や住所などの値の形式に一貫性がなかったりするなど、ファイルの既知のデータ品質の問題を考慮して、データ品質を維持し、必要なクレンジングと変換を実行するためのデータ パイプラインをどのように確立すればよいのでしょうか。
1. 　BigQuery に読み込む前に、Data Fusion を使用してデータを変換します。
2. データを BigQuery に読み込む前に、Data Fusion を使用して CSV ファイルを AVRO などの自己記述型データ形式に変換します。
3. 目的のスキーマを使用してステージング テーブルに CSV ファイルを読み込み、SQL で変換を実行してから、結果を最終的な変換先テーブルに書き込みます。
4. 目的のスキーマでテーブルを作成し、CSV ファイルをテーブルにロードし、SQL を使用してその場で変換を実行します。
<details><div>
    答え：1
説明
A. 
このオプションが適切な理由は次のとおりです。
変換のための Data Fusion: Google Cloud Data Fusion は、ETL(抽出、変換、読み込み)プロセスのための強力なツールです。データ品質の問題に対処するために不可欠な、データ変換、クレンジング、エンリッチメントの機能を提供します。
高度な変換: Data Fusion では、ビジュアル インターフェースやカスタム コードを使用して複雑なデータ変換を実行できるため、データ型の不一致や一貫性のない書式設定などの問題を処理するのに適しています。
BigQuery との統合: Data Fusion は BigQuery とシームレスに統合できるため、変換されたデータを BigQuery テーブルに直接読み込むことができるため、データ パイプラインが簡素化されます。
オプション A は、BigQuery に読み込む前に Google Cloud Data Fusion を使用してデータ変換を行うもので、データ品質の問題に対処し、高度な変換機能を提供する包括的なアプローチです。これは、シナリオで説明されているように、複雑なデータ クレンジングと変換タスクを処理する場合に推奨される選択肢です。
正しくないオプション -
B. データを BigQuery に読み込む前に、Data Fusion を使用して CSV ファイルを AVRO などの自己記述型データ形式に変換します。
データ形式の変換は特定のシナリオでは役立ちますが、データ型の不一致や一貫性のない書式設定など、質問に記載されているデータ品質の問題に直接対処するものではありません。
C. 目的のスキーマを使用してステージング テーブルに CSV ファイルを読み込み、SQL で変換を実行してから、結果を最終的な変換先テーブルに書き込みます。
変換に SQL を使用することは有効なアプローチですが、データ品質の問題は SQL のみを使用して効果的に処理できることを前提としていますが、複雑な問題には当てはまらない場合があります。
D. 目的のスキーマでテーブルを作成し、CSV ファイルをテーブルにロードし、SQL を使用してその場で変換を実行します。
このオプションでは、最終的な変換先テーブルにデータを直接読み込む必要がありますが、データ品質の問題に事前に対処しないと危険です。一般に、データの検証と変換にはステージング テーブルを使用する方が安全です。
参照リンク: Data Fusion の概要
</div></details>

### Q. 39
e コマース プラットフォームでの顧客の購入確率を予測することを目的とした新しいディープ ラーニング モデルの開発に取り組んでいる間、初期トレーニング データセットと新しいテスト データセットの両方を使用して、モデルのパフォーマンスの評価を実施しました。この評価の結果、モデルが提供されたデータに対して過学習の傾向を示していることが明らかになりました。目的は、新しいデータの結果を予測する際に、モデルの精度を高めることです。この目標を達成するには、どのような手順を踏む必要がありますか?
1. 　データセットのサイズを増やし、入力特徴量を増やす
2. トレーニング データセットのサイズを大きくし、入力特徴の数を減らします。
3. データセットのサイズを小さくし、入力フィーチャを増やす
4. データセットのサイズを小さくし、入力特徴量を減らす
<details><div>
    答え：2
説明
新しいデータを予測する際の過学習に対処し、深層学習モデルの精度を向上させるには、次のことを行う必要があります。
B. 
このオプションが適切な理由は次のとおりです。
トレーニング データを増やす: トレーニング データセットのサイズを大きくすると、モデルの一般化が向上し、過学習を減らすことができます。データが多いほど、基になるパターンがより広く表現され、新しいデータでのモデルのパフォーマンスが向上する可能性があります。
入力特徴量を減らす: 入力特徴量が多すぎる過度に複雑なモデルは、トレーニング データ内のノイズをキャプチャできるため、過学習する傾向があります。入力特徴の数を減らすことで、モデルを単純化し、最も関連性の高い情報に焦点を合わせることができるため、汎化を改善できます。
過学習を軽減する最も効果的な方法は、トレーニング データセットのサイズを大きくすると同時に、入力フィーチャの数を減らしてモデルを単純化することです。この組み合わせにより、モデルの汎化が向上し、新しいデータの精度が向上します。
正しくないオプション -
オプション A、C、および D は、推奨されるアプローチではありません。
オプション A (データセットのサイズを増やし、入力特徴量を増やす): データセットのサイズと入力特徴の数の両方を増やすと、過学習がさらに悪化する可能性があります。モデルがすでに複雑すぎる場合は、データが多いだけでは役に立たない可能性があります。
オプション C (データセットのサイズを小さくし、入力フィーチャを増やす): データセットのサイズを小さくすると、モデルの一般化がさらに困難になる可能性があります。入力特徴量を増やしてデータを減らすと、モデルがさらにオーバーフィットになる可能性があります。
オプション D (データセットのサイズを小さくし、入力特徴量を減らす): データセットのサイズと入力特徴の数の両方を減らしても、モデルが意味のあるパターンを学習するための十分な情報が得られない可能性があります。
</div></details>

### Q. 40
オンライン小売業者の顧客サービスを強化するためのチャットボットを効果的に作成し、テキストと音声の両方のクエリを処理できると同時に、ローコードまたはノーコードのソリューションを模索し、キーワードベースの応答のための簡単なトレーニングを確保するにはどうすればよいでしょうか?
1. 　
2. 
3. 
4. Dialogflow を使用してチャットボットを実装し、収集された最も一般的なクエリに基づいてインテントを定義します。
<details><div>
    答え：4
説明
D. 
Dialogflow は、モバイルアプリ、ウェブ アプリケーション、デバイス、ボット、自動音声応答システムなどに会話型ユーザー インターフェースを簡単に設計して統合できる自然言語理解プラットフォームです。Dialogflow を使用すると、ユーザーがプロダクトと対話するための新しい魅力的な方法を提供できます。Dialogflow では、テキスト入力や音声入力(電話や音声録音など)など、顧客からの複数のタイプの入力を分析できます。また、テキストまたは合成音声のいずれかで、いくつかの方法で顧客に応答することもできます。
参考リンク -
https://cloud.google.com/dialogflow/docs
</div></details>

### Q. 41
航空宇宙企業独自の形式から BigQuery にフライトデータを最も効果的にインポートし、リソース消費を最小限に抑えながら、この新しいデータソース間の接続を確立し、BigQuery へのデータ ストリーミングを容易にするにはどうすればよいでしょうか。
1. 　定期的な ETL バッチ ジョブの Cloud Functions の関数をトリガーするシェル スクリプトを記述する
2. 標準の Dataflow パイプラインを使用して BigQuery に生データを保存し、後で形式を変換する
3. Apache Hive を使用して、データを CSV 形式で BigQuery にストリーミングする Dataproc ジョブを作成します。
4. Apache Beam カスタム コネクタを使用して、データを Avro 形式で BigQuery にストリーミングする Dataflow パイプラインを作成します。
<details><div>
    答え：4
説明
オプション D. 
このシナリオでは、特定の形式の独自のフライト データがあり、最小限のリソース消費で効率的に BigQuery にインポートする必要があります。
Apache Beam カスタム コネクタと Dataflow を併用して Avro 形式で BigQuery にデータをストリーミングすることは、いくつかの理由から最適な選択肢です。
Apache Beam は、複雑なデータ インジェストと変換タスクを処理できる強力で柔軟なデータ処理フレームワークです。
Avro はコンパクトで効率的なデータシリアル化形式であり、大量のデータのストリーミングと保存に適しています。
カスタム コネクタを使用すると、データ インジェスト プロセスを独自のデータ形式に合わせて調整し、スムーズで効率的なデータ転送を確保できます。
Dataflow は、データ量に合わせて自動的にスケーリングできるマネージド サービスであり、リソースを手動で管理してプロビジョニングする必要性を減らします。
正しくないオプション -
A. 定期的な ETL バッチ ジョブの Cloud Functions の関数をトリガーするシェル スクリプトを記述する:
このオプションは、定期的なバッチジョブの実行を示唆していますが、リアルタイムのデータストリーミングには適していない可能性があります。
また、データのストリーミングに効率的である可能性のある Avro 形式の使用についても言及していません。
B. 標準の Dataflow パイプラインを使用して BigQuery に生データを保存し、後で形式を変換する:
このアプローチでは、データが未加工の形式で BigQuery に保存されますが、これは BigQuery の機能を利用する最も効率的な方法ではない可能性があります。
これには、既に保存されているデータを変換する追加の手順が含まれますが、これは、目的の形式でデータをストリーミングするほどリソース効率が良くない可能性があります。
C. Apache Hive を使用して、データを CSV 形式で BigQuery にストリーミングする Dataproc ジョブを作成します。
Apache Hive はバッチ処理には適したツールですが、リアルタイムのデータ ストリーミングには適していない可能性があります。
CSV 形式は Avro ほどストリーミングに効率的ではなく、より多くのリソースを消費する可能性があります。
オプション D は、Apache Beam とカスタム コネクタを活用して Avro 形式で BigQuery にデータをストリーミングし、リソース消費を最小限に抑えながら効率的かつリアルタイムのデータ取り込みを実現するため、最も適切な選択肢です。
参照リンク - Apache Beam のプログラミング モデル
</div></details>

### Q. 42
オンライン証券会社には、大量の取引処理アーキテクチャが必要です。ジョブをトリガーするセキュア・キューイング・システムを作成する必要があります。ジョブはGoogle Cloudで実行され、同社のPython APIを呼び出して取引を実行します。ソリューションを効率的に実装する必要があります。あなたは何をするべきか?
1. 　Pub/Sub プッシュ サブスクリプションを使用して Cloud Functions の関数をトリガーし、Python API にデータを渡します。
2. Compute Engine インスタンスでホストされるアプリケーションを作成して、Pub/Sub トピックへのプッシュ サブスクリプションを作成する
3. NoSQLデータベースでのキューの作成
4. Cloud Composer の使用
<details><div>
    答え：1
説明
Google Cloud で実行されるジョブをトリガーし、会社の Python API を呼び出して取引を実行する安全なキューイング システムを作成するための最も効率的で適切なオプションは次のとおりです。
オプション A: 
Google Cloud Pub/Sub は、独立したアプリケーション間でリアルタイムかつ信頼性の高いメッセージングを実現するために設計されたメッセージング サービスです。
このシナリオでは、取引リクエストが発行される Pub/Sub トピックを設定できます。
Pub/Sub トピックへのプッシュ サブスクリプションを作成すると、メッセージがトピックにパブリッシュされたときに Cloud Functions の関数が呼び出されます。
その後、Cloud Functions の関数は取引データを Python API に渡して実行できます。
このアーキテクチャは効率的でスケーラブルであり、大量の取引処理に適しています。
正しくないオプション -
オプション B では、Compute Engine インスタンスでホストされるアプリケーションを作成して、Pub/Sub トピックへのプッシュ サブスクリプションを作成することを提案しています。これは機能しますが、Compute Engine インスタンスの管理とスケーリングが必要であり、Cloud Functions を使用する場合ほど効率的ではなく、サーバーレスでもない可能性があります。
オプションCは、NoSQLデータベースでのキューの作成について言及しています。NoSQL データベースはキューイングなど多くの目的に使用できますが、Google Cloud Pub/Sub などの専用のキューイング システムを設定する方が効率的で、この種のタスクに特化して構築されています。
オプション D では、Google Cloud のマネージド ワークフロー オーケストレーション サービスである Cloud Composer の使用について言及しています。Cloud Composer はさまざまなタスクに使用できますが、この特定のユースケースで Pub/Sub で Cloud Functions を直接使用する場合と比較して、単純なメッセージ キューイングと Python API 呼び出しの実行用に Cloud Composer を設定すると、不必要に複雑になる可能性があります。
参考リンク -
https://cloud.google.com/run/docs/triggering/pubsub-push
</div></details>

### Q. 43
あなたの会社は、データベースに 10 TB を超える現在のシステムから医療情報の大きな結果セットを取得し、さらにクエリを実行するためにデータを新しいテーブルに格納できるようにしたいと考えています。データベースは、メンテナンスの少ないアーキテクチャを持ち、SQL経由でアクセスできる必要があります。大規模な結果セットのデータ分析をサポートできるコスト効率の高いソリューションを実装する必要があります。あなたは何をするべきか?
1. 　Cloud SQL を使用
2. BigQuery をデータ ウェアハウスとして使用する。大きなクエリをキャッシュするための出力先を設定します。
3. Compute Engine で MySQL クラスタを使用
4. Cloud Spanner を使用
<details><div>
    答え：2
説明
大規模な結果セットのデータ分析をサポートしながら、メンテナンスが少なく、SQLへのアクセス性も備えている、最も費用対効果の高いソリューションは次のとおりです。
オプション B: 
説明：
Google BigQuery は、大規模なデータセットや複雑なクエリを処理するために設計された、サーバーレスで拡張性が高く、費用対効果の高いデータ ウェアハウス ソリューションです。
BigQuery は SQL に似たクエリ機能を備えており、SQL 経由でアクセスできます。
ストレージ、インデックス作成、クエリ パフォーマンスの最適化など、データの管理を自動的に処理します。
BigQuery ではクエリ結果をキャッシュできるため、大きな結果セットを複数回取得する際のパフォーマンスが大幅に向上し、クエリ費用を削減できます。
これは完全に管理されたサービスであり、手動のメンテナンスとスケーリングの必要性を排除します。
正しくないオプション -
オプション A(Cloud SQL を使用)とオプション C(Compute Engine で MySQL クラスタを使用)は、手動管理が必要で、BigQuery ほどシームレスにスケーリングできず、データ量が多い場合はコストがかかる可能性があるため、非常に大規模なデータセットや複雑な分析を処理するには最適な選択肢ではない可能性があります。
オプション D(Cloud Spanner を使用)は、グローバルに分散された可用性の高いデータベース サービスですが、大規模な結果セットの分析ではなく、トランザクション データ向けに設計されています。このユースケースでは、最も費用対効果の高いオプションではない可能性があります。
参考リンク-
https://cloud.google.com/bigquery/docs/cached-results
</div></details>

### Q. 44
オンプレミスのデータセンターに 15 TB のデータがあり、Google Cloud に転送したいとします。データは毎週変更され、POSIX 準拠のソースに保存されます。ネットワーク運用チームは、パブリック インターネットに 500 Mbps の帯域幅を付与しました。Google が推奨する方法に従って、週単位で Google Cloud にデータを確実に転送したい。あなたは何をするべきか?
1. 　Cloud Scheduler を使用して gsutil をトリガーする
2. Transfer Appliance を使用
3. データ センターにオンプレミス データ用の Storage Transfer Service をインストールし、毎週の転送ジョブを構成します。
4. Google Cloud 仮想マシンへの Storage Transfer Service のインストール
<details><div>
    答え：3
説明
パブリック インターネットへの帯域幅が 500 Mbps の場合、オンプレミスのデータセンターから Google Cloud に 15 TB のデータを毎週確実に転送するには、Google が推奨するデータ転送方法の使用を検討する必要があります。このシナリオでは、
オプション C: 
このオプションが適している理由は次のとおりです。
Storage Transfer Service は、Google Cloud が提供するマネージド サービスで、オンプレミスのデータソースまたは別のクラウド プロバイダから Google Cloud Storage にデータを転送するのに役立ちます。これは、大規模で定期的な転送を効率的に処理するように設計されています。
データセンターに Storage Transfer Service をインストールすると、スケジュールされた自動転送ジョブを設定して、定期的に(毎週など)Google Cloud にデータを移動できます。
Storage Transfer Service は、並列処理、再開可能な転送、および効率的で信頼性の高いデータ転送を保証するその他の機能を処理して、転送プロセスを最適化できます。
正しくないオプション -
オプション A(Cloud Scheduler を使用して gsutil をトリガーする)は機能しますが、gsutil コマンドとそのスケジュールを管理する必要があります。Storage Transfer Service と同じレベルの自動化と組み込みのデータ転送の最適化は提供されません。
オプション B (Transfer Appliance を使用) は、非常に大規模なデータセットや、ネットワーク帯域幅が制限要因となる状況に適しています。ただし、データが 15 TB で帯域幅が 500 Mbps のこのシナリオでは、必要以上に複雑でコストがかかる可能性があります。
オプション D(Google Cloud 仮想マシンへの Storage Transfer Service のインストール)は、標準または推奨されるアプローチではありません。Storage Transfer Service は、データ転送の目的でオンプレミスで実行するように設計されており、仮想マシンにインストールすると、不必要な複雑さが加わります。
参考リンク -
https://cloud.google.com/storage-transfer/docs/overview
</div></details>

### Q. 45
ACID準拠のデータベースを必要とするシステムを設計しています。障害が発生した場合に、システムが必要とする人間の介入が最小限であることを確認する必要があります。あなたは何をするべきか?
1. 　ポイントインタイム リカバリを使用した Cloud SQL for MySQL
2. 高可用性を有効にして Cloud SQL for PostgreSQL インスタンスを構成するを選択する必要があります。
3. 複数のクラスタを持つ Bigtable
4. マルチリージョン構成の BigQuery
<details><div>
    答え：2
説明
障害発生時に人的介入を最小限に抑えた ACID 準拠のデータベースを必要とするシステムを設計するには、オプション B: 
Cloud SQL for PostgreSQL は、フルマネージドで可用性が高く、ACID 準拠のリレーショナル データベース サービスを提供します。これは、信頼性とデータの整合性で知られるPostgreSQLに基づいています。
Cloud SQL インスタンスの高可用性を有効にすると、同じリージョン内の別のゾーンにスタンバイ レプリカが作成されます。プライマリ・インスタンスに障害が発生すると、スタンバイへの自動フェイルオーバーが発生し、ダウンタイムが最小限に抑えられ、データの整合性が確保されます。
PostgreSQLは一般に、ACID(原子性、一貫性、分離性、耐久性)トランザクションを強力にサポートしているため、データの整合性と信頼性を必要とするアプリケーションに適しています。
誤ったオプション-
オプション A(ポイントインタイム リカバリを使用した Cloud SQL for MySQL)は適切な選択肢ですが、ACID トランザクションをより強力にサポートする PostgreSQL が好まれることがよくあります。
オプション C(複数のクラスタを持つ Bigtable)は、ACID 準拠のリレーショナル データベース機能を提供するようには設計されていません。Bigtable は、さまざまなタイプのワークロードに使用される NoSQL データベースです。
オプション D(マルチリージョン構成の BigQuery)は、このシナリオには適用されません。BigQuery はデータ ウェアハウスおよび分析サービスであり、トランザクション リレーショナル データベースではありません。
参考リンク -
https://cloud.google.com/sql/docs/postgres
</div></details>

### Q. 47
メディアストリーミングプラットフォームは、動画の視聴回数やクリック率などのユーザーインタラクションデータを保存して分析する必要があります。そのためには、高い読み取りと書き込みのスループットを低レイテンシーで処理できるデータベースが必要です。このシナリオに最も適した GCP サービスはどれですか?
1. 　BigQuery
2. クラウドストレージ
3. Bigtable
4. Firestore
<details><div>
    答え：3
説明
このシナリオの正しいオプションは C.  です。
Bigtable は、低レイテンシの読み取りおよび書き込み操作で大量のデータを処理できるように設計された、非常にスケーラブルで高性能な NoSQL データベースです。これは、ビデオの視聴回数やクリックスルー率などのユーザー操作データを保存および分析するためにメディア ストリーミング プラットフォームが必要とする、高い読み取りおよび書き込みスループットを低遅延で処理する必要があるシナリオに適しています。
正しくないオプション -
A. BigQuery: BigQuery は、大規模なデータセットに対して SQL のようなクエリを実行するために最適化されたデータ ウェアハウスおよび分析プラットフォームです。Bigtable と比較してクエリのレイテンシが長くなる可能性があるため、リアルタイム、高スループット、低レイテンシのデータ ストレージと取得には最適ではありません。
B. クラウドストレージ:クラウドストレージは、主にファイルやオブジェクトなどの非構造化データを保存するために設計されたオブジェクトストレージサービスです。ユーザー操作のデータ分析に必要な、リアルタイムで低遅延のデータアクセスとクエリ機能は提供されません。
D. Firestore: Firestore は、ドキュメント指向のデータ用に設計された NoSQL データベースであり、モバイル アプリケーションやウェブ アプリケーションによく使用されます。リアルタイム データを処理できますが、メディア ストリーミング プラットフォームの高スループット、低レイテンシの要件に対しては、Bigtable ほどパフォーマンスが高くない可能性があります。また、Firestore にはドキュメントとコレクションの制限があり、非常に高速なデータのスケーラビリティに影響を与える可能性があります。
</div></details>

### Q. 48
組織は、モバイル アプリから収集されたユーザーの行動データに基づいてレコメンデーション システムを構築したいと考えています。複雑なクエリを効率的に処理し、リアルタイム分析機能を提供できるデータベースが必要です。どのGCPサービスを検討すべきですか?
1. 　Cloud Bigtable
2. BigQuery
3. Cloud Datastore
4. Cloud SQL
<details><div>
    答え：2
説明
この質問の正しい選択肢は B.  です。
ここで説明するシナリオでは、モバイルアプリから収集したユーザー行動データに基づいてレコメンデーションシステムを構築する必要があります。
複雑なクエリ: レコメンデーション システムの構築には、多くの場合、ユーザーの行動を分析し、パーソナライズされたレコメンデーションを生成するための複雑なクエリが含まれます。BigQuery は、大規模なデータセットに対して複雑な SQL クエリを実行するために最適化された、フルマネージドのサーバーレス データ ウェアハウスです。分析ワークロードの処理に優れているため、このシナリオには有力な選択肢となります。
効率性: BigQuery はクエリを効率的に実行するように設計されているため、リアルタイム分析タスクに適しています。大量のデータを処理でき、クエリの応答時間が短くなります。
正しくないオプション -
A. Cloud Bigtable: Bigtable は、高スループットで低レイテンシのデータ アクセス用に最適化された NoSQL データベースです。時系列データやキー値ストレージなどの特定のユースケースには優れていますが、複雑な分析クエリやリアルタイム分析には適していません。
C. Cloud Datastore: Cloud Datastore は、ウェブ アプリケーションやモバイル アプリケーションの構造化データの保存と取得に適した NoSQL データベースです。ただし、複雑なレコメンデーションシステムやリアルタイム分析に必要なパフォーマンスとクエリ機能が提供されない場合があります。
D. Cloud SQL: Cloud SQL はマネージド リレーショナル データベース サービスです。トランザクション ワークロードや構造化データには適していますが、BigQuery の方が適している複雑な分析クエリやリアルタイム分析には適していない可能性があります。
複雑なクエリを効率的に処理し、リアルタイム分析機能を提供する必要があるレコメンデーション システムの場合、分析ワークロードと大規模なデータセットの処理に強みを持つ BigQuery は、GCP サービスとして最適です。
</div></details>

### Q. 50
あなたは、車両のリアルタイムの位置データを保存および取得する必要がある物流会社のデータストレージソリューションを設計しています。このユースケースに最適なGCPサービスはどれですか?
1. 　Cloud SQL
2. Bigtable
3. Firestore
4. Cloud Pub/Sub
<details><div>
    答え：2
説明
このシナリオの正しいオプションは B.  です。
Bigtable は、高スループットで低レイテンシのデータ アクセスを実現するように設計された、フルマネージドの NoSQL データベース サービスです。大量のデータを処理でき、車両のリアルタイム位置データの保存に適しているため、このユースケースに最適です。車両の位置を効率的に追跡するために必要なスケーラビリティ、パフォーマンス、およびリアルタイムのデータアクセスを提供します。
正しくないオプション -
A. Cloud SQL: Cloud SQL はフルマネージドのリレーショナル データベース サービスであり、複数の車両のリアルタイムの位置データの保存と取得には適していません。構造化データに適しており、車両のリアルタイム追跡に必要なスケーラビリティとパフォーマンスは提供されません。
C. Firestore: Firestore は、柔軟でスケーラブルなリアルタイムのデータ ストレージ用に設計された NoSQL ドキュメント データベースです。リアルタイム データを処理できますが、車両の大量の位置データを保存するのには適していない場合があります。Firestore は、モバイルアプリやウェブアプリなど、ドキュメント形式のデータ ストレージを必要とするアプリケーションでより一般的に使用されます。
D. Cloud Pub/Sub: Cloud Pub/Sub は、独立したアプリケーション間でメッセージを送受信できるメッセージング サービスです。これはデータベースではなく、データを保存しません。これは、コンポーネント間のリアルタイムのイベントストリーミングとメッセージングに使用できますが、データストレージを目的としたものではありません。
スタート
演習テスト1: Google Cloud Professional Data Engineer - Practice Test #1
スタート
演習テスト2: Google Cloud Professional Data Engineer - Practice Test #2
スタート
演習テスト3: Google Cloud Professional Data Engineer - Practice Test #3
スタート
演習テスト4: Google Cloud Professional Data Engineer - Practice Test #4
法人向けサービスのお問い合わせ
Udemyで教える
出資
規約
ヘルプとサポート
サイトマップ
アクセシビリティに関する声明
特定商取引に関する表記
</div></details>

## 2
### Q. 質問4: 未回答
Cloud Datastore を利用して、車両のテレメトリ データをリアルタイムで取り込むことを選択しました。目的は、費用対効果を維持しながら、長期的なデータの増加に対応するストレージソリューションを確立することです。また、このデータのスナップショットを定期的に生成して、代替環境での Cloud Datastore のポイントインタイム リカバリ(PIT)やデータのクローン作成を容易にします。2つの異なる方法を使用して、これらの目標を達成するにはどうすればよいでしょうか。(2つ選択)
1. 　マネージド エクスポートを使用し、Nearline クラスまたは Coldline クラスを使用して Cloud Storage バケットにデータを保存します。
2. 管理対象エクスポートを使用してから、そのエクスポート用に予約された一意の名前空間の下にある別のプロジェクトの Cloud Datastore にインポートします。
3. 
4. 
<details><div>
    答え：1,2
説明
車両のテレメトリ データをリアルタイムで Cloud Datastore に取り込み、コストを抑えながら長期保存用のデータのスナップショットを作成するという目標を達成するには、次の 2 つの方法を検討できます。
A. 
説明: Cloud Datastore の管理対象エクスポート機能を使用して、データを定期的にエクスポートできます。エクスポート後、データを Cloud Storage バケットに保存します。Nearline または Coldline ストレージクラスを選択することで、コストを低く抑えながら、スナップショットを長期保存用にアーカイブできます。
B. 管理対象エクスポートを使用してから、そのエクスポート用に予約された一意の名前空間の下にある別のプロジェクトの Cloud Datastore にインポートします。
説明: データのスナップショットを作成する別の方法として、Cloud Datastore の管理対象エクスポートを使用する方法があります。エクスポート後、そのエクスポート用に特別に予約された一意の名前空間を使用して、別の Cloud Datastore プロジェクトにデータをインポートできます。これにより、別の環境にデータのコピーを別個に作成できます。
正しくないオプション -
その他のオプション(C、D、E)は、Cloud Datastore データのスナップショットを作成し、コストを最小限に抑えながら長期保存用にアーカイブするという目標に直接対応していません。オプション C と D では、BigQuery にデータをインポートするか、データを管理するアプリケーションを作成するかについて説明しますが、これはスナップショットを作成する最も効率的な方法ではありません。オプションEでは、クラウドソースリポジトリにデータを保存することについて言及していますが、これはデータスナップショットには適していません。
</div></details>

### Q. 質問8: 未回答
あなたは、それぞれ独自のサプライヤーから約 750 の異なるコンポーネントを調達する製造会社の一員です。データセットには、平均して、コンポーネントごとに 1000 個のラベル付き例が含まれています。目的は、倉庫スタッフがコンポーネントの写真から入荷コンポーネントを識別するのに役立つアプリを作成することです。最初の動作バージョンを概念実証として迅速に開発することを目指しています。
どのように進めればよいですか?
1. 既存のデータセットで Cloud Vision AutoML を使用します。
2. Cloud Vision AutoML を使用しますが、データセットを 2 回削減します。
3. 認識のヒントとしてカスタム ラベルを指定して、Cloud Vision API を使用します。
4. 転移学習手法を活用して独自の画像認識モデルをトレーニングします。
<details><div>
    答え：1
説明
オプション A: 
Cloud Vision AutoML はカスタム画像認識タスク専用に設計された機械学習サービスであるため、これは正しいオプションです。これにより、シナリオに不可欠な既存のデータセットを使用してカスタム画像認識モデルをトレーニングできます。オプションAが最良の選択である理由は次のとおりです。
カスタマイズ：Cloud Vision AutoMLを使用すると、特定のユースケースに合わせたカスタムモデルを構築できます。シナリオでは、倉庫作業員が撮影した写真からさまざまなコンポーネントを認識するには、正確な結果を得るためにカスタマイズされたソリューションが必要です。
精度：カスタム モデルは、ドメイン固有のデータでトレーニングされるため、多くの場合、汎用モデルよりもパフォーマンスが高くなります。既存のデータセットを使用してモデルをトレーニングすることで、コンポーネントの認識精度を高めることができます。
使いやすさ:カスタム機械学習モデルのトレーニングは複雑になりがちですが、Cloud Vision AutoML を使用するとプロセスが簡素化され、機械学習の深い専門知識がなくてもアクセスできるようになります。これは、迅速な概念実証という目標とよく一致します。
正しくないオプション -
オプション B: Cloud Vision AutoML を使用しますが、データセットを 2 回削減します。
データセットを減らすと、貴重なトレーニングデータが失われ、モデルの精度に悪影響を与える可能性があります。PoC では、最良の結果を得るために、できるだけ多くの関連データを使用する必要があります。
オプション C: 認識のヒントとしてカスタム ラベルを指定して、Cloud Vision API を使用します。
Cloud Vision API はさまざまな画像分析タスクに役立ちますが、カスタム画像認識を必要とする特定のシナリオには適していない可能性があります。カスタムラベルをヒントとして指定すると認識が向上しますが、ラベル付けされた画像のデータセットが大量にある場合は、Cloud Vision AutoMLでカスタムモデルをトレーニングするほど効果的ではありません。
オプション D: 転移学習手法を活用して独自の画像認識モデルをトレーニングします。
転移学習手法を使用して独自の画像認識モデルをトレーニングすることは有効なアプローチであり、特定のシナリオでは非常に効果的ですが、画像内のコンポーネントを認識するための迅速な概念実証 (PoC) の作成を含む特定の状況には最適な選択肢ではない可能性があります。
</div></details>

### Q. 質問9: 未回答
あなたは画像認識に関連する特殊なプロジェクトに携わっており、チームは、開発したカスタム C++ TensorFlow 操作に主に依存するモデルを作成しました。これらの操作は、主要なトレーニング プロセスに不可欠であり、リソースを大量に消費する行列の乗算を伴います。現在、モデルのトレーニング プロセスが完了するまでに数日かかる場合があります。目標は、Google Cloud アクセラレータを活用して費用対効果を維持しながら、このトレーニング時間を大幅に短縮することです。
この目標を達成するには、どのような手順を踏む必要がありますか?
1. 　
2. 
3. 
4. CPU を使用したまま、モデルをトレーニングするクラスターのサイズを増やします。
<details><div>
    答え：4
説明
D. 
カスタム C++ TensorFlow Ops:モデルは、カスタム C++ TensorFlow 演算に大きく依存しています。TPU や GPU とシームレスに連携するようにこれらの運用を移行することは、複雑で時間のかかるプロセスであり、多くの場合、これらのアクセラレータの最適化には大幅なコード変更と専門知識が必要です。
TPUの:Cloud TPU は、特定のディープ ラーニング ワークロード向けの優れたアクセラレータですが、アーキテクチャと互換性のある TensorFlow オペレーション向けに最適化されています。カスタム演算を TPU で実行するように適応させるのは困難な場合があり、モデルが特殊なハードウェアを最大限に活用できない限り、大きなメリットが得られない可能性があります。
GPUサポート:カスタム演算に GPU カーネル サポートを実装することは、GPU の使用を計画している場合、正しい方向への一歩です。ただし、GPU と TPU はアーキテクチャが異なるため、個別の最適化が必要です。このオプションは、特にGPUアクセラレーションをターゲットとしている場合に適しています。
クラスタのスケーリング:CPU にとどまり、クラスターのサイズを増やすことで、複数の CPU ノードにワークロードを分散できます。これにより、計算負荷の高いタスクであっても、トレーニング時間を大幅に短縮できます。多くの場合、トレーニングをスピードアップするための最も簡単で費用対効果の高い方法です。
コストに関する考慮事項:TPU と GPU は、CPU ベースのクラスターと比較して、使用コストが高くなる可能性があります。CPU にとどまり、クラスターをスケーリングすることで、パフォーマンスとコスト効率のバランスを取ることができます。
カスタム C++ TensorFlow 演算を使用するシナリオと、コストを低く抑えながらトレーニング時間を最小限に抑える必要があることを考えると、CPU にとどまり、クラスターをスケーリングする (オプション D) ことが、最も実用的でコスト効率の高いアプローチです。TPU や GPU などのアクセラレータへの移行は長期的な目標かもしれませんが、これらのハードウェア プラットフォーム向けのカスタム運用の最適化に伴う複雑さとコストを慎重に検討して取り組む必要があります。
</div></details>

### Q. 発行： 未回答
自然言語処理領域内の回帰問題に取り組んでおり、1 億個のラベル付き例を含むデータセットを備えています。データをランダムにシャッフルし、90/10 の比率でトレーニング セットとテスト セットに分割しました。ニューラル ネットワークに学習させ、テスト セットでそのパフォーマンスを評価すると、トレーニング セットの二乗平均平方根誤差 (RMSE) がテスト セットの誤差の 2 倍であることがわかります。
モデルのパフォーマンスを向上させるには、どのような手順を実行する必要がありますか?
1. 　トレーニングとテストの分割でテスト サンプルのシェアを増やします。
2. より多くのデータを収集し、データセットのサイズを大きくしてみてください。
3. 正則化手法 (ドロップアウトやバッチ正規化など) を試して、過学習を回避します。
4. 追加のレイヤーを導入したり、使用する語彙や n-gram のサイズを増やしたりするなどして、モデルの複雑さを増します。
<details><div>
    答え：3
説明
モデルの二乗平均平方根誤差 (RMSE) が、トレーニング セットではテスト セットの 2 倍であるという観察結果は、過学習を示しています。過学習は、モデルが学習データに近づきすぎて、一般的なパターンではなく学習データにノイズや特異性をキャプチャすることを学習した場合に発生します。モデルのパフォーマンスを向上させるには、過学習を減らすことに重点を置く必要があります。正しいアプローチは次のとおりです。
C. 
正則化手法:ドロップアウト、バッチ正規化、L2 正則化などの手法は、過学習を軽減するように設計されています。トレーニング中にモデルのパラメーターに制約を導入し、トレーニング データに近づきすぎないようにし、目に見えないデータへの一般化を促進します。
テストセットサイズの拡大(オプションA):トレーニングとテストの分割でテスト サンプルのシェアを増やしても、過学習には直接対処できません。重要なのは、既存のテストセットの相対的なパフォーマンスであり、そのサイズではありません。
より多くのデータを収集する(オプションB):より多くのデータを収集すると、特定のケースでは役立ちますが、必ずしも過学習が解決されるとは限りません。一般に、データセットのサイズを増やすことを検討する前に、まずモデルを最適化し、正則化手法を適用することをお勧めします。
モデルの複雑性を増す(オプションD):モデルの複雑さが増すと、過学習が解決されるどころか悪化する可能性があります。複雑なモデルほどパフォーマンスが向上するというのは、よくある誤解です。適切な正則化を備えた単純なモデルは、多くの場合、過度に複雑なモデルよりも優れた性能を発揮します。
正しくないオプション -
A. トレーニングとテストの分割でテスト サンプルのシェアを増やします。
トレーニングとテストの分割でテスト サンプルの割合を増やしても、過学習の問題に直接対処できるわけではありません。トレーニングとテストの間でデータの割り当てが変更されるだけで、モデルの動作には影響しません。
問題は、テストセットのサイズではなく、モデルがトレーニングセットから未知のデータにうまく一般化できないことです。このオプションでは、過学習の根本原因には対処できません。
B. より多くのデータを収集し、データセットのサイズを大きくしてみてください。
より多くのデータを収集することは、特に意味のあるパターンを学習するための十分なデータがモデルにない場合に、場合によっては有用な戦略となる可能性があります。ただし、このシナリオでは、既にかなりのデータセット (100M の例) があります。
データセットのサイズを大きくしても、過学習の問題に直接対処できない場合があります。過学習は、多くの場合、モデルが複雑すぎるか、使用可能なデータの量に対してパラメーターが多すぎることが原因です。一般に、大規模なデータセットがある場合は、モデルの正則化に重点を置く方が効果的です。
D. 追加のレイヤーを導入したり、使用する語彙や n-gram のサイズを増やしたりするなどして、モデルの複雑さを増します。
モデルの複雑さが増すと、過学習は解決されるどころか悪化する可能性があります。より複雑なモデルでは、トレーニング データにノイズや特異性が当てはめられやすく、一般化が不十分になる可能性があります。
過学習は、通常、モデルが既に複雑すぎて使用可能なデータがない場合に発生します。複雑さを増すことは、推奨されるアプローチではありません。代わりに、モデルを単純化し、正則化手法を適用して過学習を防ぐことをお勧めします。
</div></details>

### Q. 質問15: 未回答
データ サイエンティストが BigQuery ML モデルを開発し、予測を配信するための ML パイプラインの構築についてサポートを求めています。REST API アプリケーションは、100 ミリ秒未満の待ち時間内に個々のユーザー ID の予測を提供するという基準を満たす必要があります。使用される予測クエリは、SELECT predicted_label、user_id FROM ML.PREDICT (MODEL 'dataset.model', table user_features) です。
この ML パイプラインの作成にはどうすればよいでしょうか。
1. 　クエリへの WHERE 句の追加とデータ閲覧者ロールの付与
2. 承認済みビューの作成
3. クエリから結果を読み取るための Dataflow パイプラインの作成
4. BigQueryIO を使用して Dataflow パイプラインを作成し、クエリからすべてのユーザーの予測を読み取り、BigtableIO を使用して結果を Bigtable に書き込み、アプリケーションが Bigtable から個々のユーザーの予測を読み取れるように、アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与することです。
<details><div>
    答え：4
説明
REST API アプリケーションで BigQuery ML を使用して低レイテンシで予測を提供する場合、最適なオプションは、オプション D: 
その理由は次のとおりです。
レイテンシーに関する考慮事項:個々のユーザー ID のレイテンシーが 100 ミリ秒未満の予測を提供することは、困難な要件です。BigQuery への直接クエリは、この低レイテンシの要件を常に満たしているとは限りません。
データフロー パイプライン:Dataflow パイプラインを作成することで、データを効率的に処理、変換できます。Dataflow は BigQuery から予測を読み取り、低レイテンシのアクセスに最適化された別のストレージ システム(Bigtable など)に書き込むことができます。
Bigtable ストレージ:Bigtable は、低レイテンシ、高スループットのストレージを提供する NoSQL データベースです。Bigtable に予測を保存すると、個々のユーザー ID の予測をすばやく取得できます。
ロールベースのアクセス制御:アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与すると、Bigtable から予測を読み取るために必要な権限がアプリケーションに付与されます。
正しくないオプション -
オプション A (クエリへの WHERE 句の追加とデータ閲覧者ロールの付与):このオプションでは低レイテンシの要件には対応しておらず、BigQuery を直接クエリしてもレイテンシの目標を達成できない可能性があります。
オプション B (承認済みビューの作成):承認済みビューの作成は、特定のデータへのアクセスを制御するのに役立ちますが、必ずしも低レイテンシーの要件に対応できるわけではなく、低レイテンシーで予測を提供する必要があります。
オプション C(クエリから結果を読み取るための Dataflow パイプラインの作成):このオプションはデータの処理に使用できますが、低レイテンシーの要件には対応しておらず、低レイテンシーで予測を提供するソリューションが必要になります。
</div></details>

### Q. 質問23: 未回答
貴社のデータ アナリストは、プロジェクトで Cloud IAM オーナーのロールを保持し、さまざまな GCP プロダクトでの作業を円滑に進めます。会社のポリシーにより、BigQuery のデータ アクセスログを 6 か月間保持することが義務付けられています。あなたの仕事は、これらのログへのアクセスを、すべてのプロジェクトにわたって指定された監査担当者に制限することです。
これを達成するには、どのような手順を踏む必要がありますか?
1. 　
2. 
3. 
4. 集計されたエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。エクスポートされたログを含むプロジェクトへのアクセスを制限します。
<details><div>
    答え：4
説明
社内の監査担当者のみがすべてのプロジェクトのデータアクセスログにアクセスでき、ログを 6 か月間保持できるようにするための正しいアプローチは、オプション D です。
オプション D: 
このオプションが最も適している理由は次のとおりです。
集約されたエクスポート シンク:集約されたエクスポート シンクを使用すると、複数のプロジェクトから 1 つの場所にログをエクスポートできるため、監査ログの一元的な管理とアクセスが容易になります。
クラウドストレージバケット:Cloud Storage バケットへのログのエクスポートは、ログを安全に保存するための一般的で効率的な方法です。
監査ログ用に新しく作成されたプロジェクト:監査ログ専用の別のプロジェクトを作成すると、ログを分離してセキュリティで保護するのに役立ちます。このプロジェクトにアクセスできるのは、許可された担当者のみです。
アクセスの制限:エクスポートされたログを含むプロジェクトでIAMポリシーとアクセス制御を設定することで、アクセスを監査担当者のみに制限し、許可された個人のみがログにアクセスして確認できるようにすることができます。
正しくないオプション -
オプション A: 各データ アナリストのプロジェクトでデータ アクセス ログを有効にします。Cloud IAM ロールによる Stackdriver Logging へのアクセスを制限します。
このオプションでは、各データ アナリストのプロジェクトでデータ アクセス ログを個別に有効にしてから、Stackdriver Logging へのアクセスを制限します。ただし、このオプションにはいくつかの欠点があります。
複雑さ：複数のプロジェクトでデータアクセスログを個別に有効にすることは、特にプロジェクトとデータアナリストの数が増えるにつれて、管理が複雑になる可能性があります。
限定的な中央集権化:ログは複数のプロジェクトに分散し、アクセス制御を効果的に一元化して管理することが困難になります。
潜在的なギャップ:個々のプロジェクト構成によっては、一部のログがキャプチャされず、監査にギャップが生じる可能性があります。
限定的な保持制御:すべてのプロジェクトで一貫した保持期間を管理することは困難な場合があります。
オプション B: プロジェクトレベルのエクスポート シンクを介して、データ アナリストのプロジェクトの Cloud Storage バケットにデータアクセスログをエクスポートします。Cloud Storage バケットへのアクセスを制限します。
このオプションでは、各データアナリストのプロジェクト内の Cloud Storage バケットにログをエクスポートし、アクセスを制限します。問題は次のとおりです。
分散ストレージ:ログは複数のプロジェクトに分散され、中央監査が複雑になる可能性があります。
限定的な制御:データアクセスログの保持とアクセス制御は、プロジェクトごとに個別に管理されるため、統一されたポリシーを適用することは困難でした。
アクセスの複雑さ:プロジェクトごとに個々の Cloud Storage バケットのアクセス制御を管理するのは面倒な場合があり、権限の一貫性を確保するのは困難です。
オプション C: プロジェクトレベルのエクスポート シンクを介して、監査ログ用に新しく作成されたプロジェクトの Cloud Storage バケットにデータ アクセス ログをエクスポートします。エクスポートされたログでプロジェクトへのアクセスを制限します。
このオプションでは、監査ログ用の新しいプロジェクトを作成しますが、個々のプロジェクトからログをエクスポートします。このアプローチには、次のような問題があります。
散在エクスポート:監査ログ用の中央プロジェクトを作成しても、ログは個々の Data Analyst プロジェクトからエクスポートされるため、一元化されません。
アクセス制御の複雑さ:ログを含む中央プロジェクトでのアクセス制御の管理は複雑になる可能性があり、アクセスを完全に一元化するわけではありません。
保持管理:一貫した保存期間を確保することは、依然として困難な場合があります。
</div></details>

### Q. 質問42: 未回答
サードパーティ企業に分析のために BigQuery のデータセットへのアクセス権を付与する際に、データの鮮度を維持し、データ共有費用を最小限に抑えるには、どのソリューションを選択すればよいでしょうか?
1. 　Analytics Hub を使用してデータ アクセスを制御し、サードパーティ企業にデータセットへのアクセスを提供します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
オプション A: 
Analytics Hubを使用してデータアクセスを制御することは、コストを低く抑え、データを最新の状態に保ちながら、サードパーティ企業にデータセットへのアクセスを提供できるため、最適なソリューションです。
正しくないオプション -
Cloud Scheduler はジョブとタスクのスケジュール設定に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション B は正しくありません。
BigQuery で別のデータセットを作成することは、最も費用対効果の高いソリューションではなく、データが最新であることを保証できないため、オプション C は正しくありません。
Dataflow はデータの処理と変換に使用されるサービスであり、サードパーティ企業にデータセットへのアクセスを提供するための最適なソリューションではないため、オプション D は正しくありません。
</div></details>

### Q. 質問43: 未回答
現在、オンプレミスのデータ ウェアハウス ソリューションを BigQuery に移行している会社では、さまざまなトランザクション データベース ソースからの更新を毎日適用するために、変更データ キャプチャ(CDC)プロセスを強化したいと考えています。この改善は、データ ウェアハウス変更アプリケーションのパフォーマンスの最適化に重点を置き、ログベースの CDC ストリームを介して BigQuery でソース システムからの変更にすばやくアクセスできるようにすることを目的としています。BigQuery レポートの表で変更を利用できるようにするためのレイテンシを最小限に抑えながら、コンピューティングのオーバーヘッドを削減するには、どの 2 つのアクションを実行すべきでしょうか。(2つ選択)
1. 　DML INSERT、UPDATE、または DELETE を実行して、個々の CDC レコードをレポート テーブルに直接リアルタイムで直接レプリケートします。
2. 新しい各 CDC レコードと対応する操作の種類をステージング テーブルにリアルタイムで挿入します。
3. レポート テーブルから古いレコードを定期的に削除します。
4. DML MERGE を定期的に使用して、レポート テーブルで複数の DML INSERT、UPDATE、および DELETE 操作を同時に実行します。
5. 新しい各 CDC レコードと対応する操作の種類をレポート テーブルにリアルタイムで挿入し、具体化されたビューを使用して、一意の各レコードの最新バージョンのみを公開します。
<details><div>
    答え：2,4
説明
B. 
この手順は、ソース システムから変更をリアルタイムでキャプチャし、ステージング テーブルに格納するために不可欠です。ステージング テーブルは、受信 CDC データのバッファーを提供し、データをレポート表に移動する前に、必要なビジネス ロジックを検証、変換、および適用できます。このアプローチは、レポート データセットの一部になる前に、データの一貫性と正確性を確保するのに役立ちます。
D. 
定期的な MERGE 操作の使用は、累積された変更をステージング テーブルからレポート テーブルに適用するための効果的な戦略です。これにより、複数の CDC レコードを 1 つの DML 操作に統合し、個々の INSERT、UPDATE、または DELETE に関連するオーバーヘッドを削減できます。このアプローチにより、計算コストが最適化され、レポート テーブルを効率的に維持できます。
正しくないオプション -
A. DML INSERT、UPDATE、または DELETE を実行して、個々の CDC レコードをレポート テーブルに直接リアルタイムで直接レプリケートします。
このオプションを使用すると、すべての CDC レコードのレポート テーブルで個々の DML 操作が大量に発生する可能性があり、リソースを大量に消費し、最適なクエリ パフォーマンスが得られない可能性があります。
C. レポート テーブルから古いレコードを定期的に削除します。
古いレコードの削除はデータ管理に必要ですが、CDC データのほぼリアルタイムの処理要件には対応していません。このオプションは、タイムリーな更新ではなく、データ保持に重点を置いています。
E. 新しい各 CDC レコードと対応する操作の種類をレポート テーブルにリアルタイムで挿入し、具体化されたビューを使用して、一意の各レコードの最新バージョンのみを公開します。
具体化されたビューはクエリのパフォーマンスを最適化するのに役立ちますが、このアプローチでは CDC データ自体のリアルタイム処理には対応していません。具体化されたビューは、通常、集計または概要を事前に計算するために使用され、リアルタイムのデータキャプチャや変換用には設計されていません。
待機時間を最小限に抑え、コンピューティング オーバーヘッドを削減してほぼリアルタイムの CDC を実現するには、手順 B と D を組み合わせることをお勧めします。ステージング テーブル (B) で変更をリアルタイムでキャプチャし、これらの変更をレポート テーブル (D) に定期的にマージして、データセットを効率的に更新します。
</div></details>

### Q. 質問46: 未回答
金融機関は、機密性の高い顧客データを安全に保管し、規制コンプライアンスを確保する必要があります。これには、暗号化、監査ログ、きめ細かなアクセス制御を備えたマネージド・データベース・サービスが必要です。どのGCPサービスを選ぶべきか?
1. 　Cloud SQL
2. Bigtable
3. Firestore
4. BigQuery
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. 
Cloud SQL は、機密データを処理するように設計された Google Cloud のマネージド リレーショナル データベース サービスです。保存中および転送中の暗号化、自動バックアップ、きめ細かなアクセス制御などの機能を提供します。これは、規制コンプライアンスと機密性の高い顧客データの安全なストレージを必要とするアプリケーションに適しています。構造化されたリレーショナルデータベースの使用は、取引データやコンプライアンスの目的で金融機関で好まれることがよくあります。
正しくないオプション -
B. Bigtable は、主に高スループットでスケーラブルなワークロード向けに設計された NoSQL データベースであり、機密性の高い顧客データを安全に保存し、規制コンプライアンスを確保するには最適な選択肢ではない可能性があります。Cloud SQL と同じレベルの組み込みのセキュリティ機能やコンプライアンス機能は提供されません。
C. Firestore は、一般的に柔軟でスキーマレスのデータ ストレージに使用される NoSQL ドキュメント データベースですが、金融機関が必要とする特定のセキュリティおよびコンプライアンス機能を提供しない場合があります。Firestore は通常、より柔軟で俊敏なデータ ストレージのニーズに合わせて選択されます。
D. BigQuery は、大規模なデータセットの分析とクエリに使用される、サーバーレスで拡張性の高いデータ ウェアハウスです。データ分析には使用できますが、主にトランザクション データベースではなく、Cloud SQL と同じレベルのセキュリティとコンプライアンス機能を提供していません。
Cloud SQL は、必要なセキュリティとコンプライアンスの機能に加えて、機密性の高い顧客データを金融機関に安全に保管するために必要な構造を備えているため、最も適切な選択肢です。
</div></details>

### Q. 質問47: 未回答
あなたの会社は、投稿、コメント、いいねなどのユーザー生成コンテンツを保存するために、柔軟でスキーマレスなデータベースを必要とするソーシャルメディアプラットフォームを開発しています。このシナリオに適したGCPデータベースサービスはどれですか?
1. 　BigQuery
2. Firestore
3. Cloud Datastore
4. Cloud SQL
<details><div>
    答え：2
説明
この質問の正しい選択肢は B. Firestore です。
このシナリオの要件は、ソーシャル メディア プラットフォームの投稿、コメント、いいねなどのユーザー生成コンテンツを保存することです。時間の経過とともに変化する可能性のある、このユーザー生成コンテンツのさまざまな構造に対応するには、柔軟なスキーマレスデータベースが必要です。
Firestore は、柔軟でスキーマレスなデータ ストレージを提供する NoSQL ドキュメント データベースです。非構造化データや半構造化データを簡単に処理できるため、ユーザーが作成したコンテンツをソーシャルメディアプラットフォームに保存するための優れた選択肢となります。Firestore は、このようなアプリケーションに不可欠なリアルタイムの同期とスケーラビリティも提供します。
正しくないオプション -
A. BigQueryの場合:BigQuery は分析用のデータ ウェアハウスであり、ユーザーが生成したコンテンツを保存するための柔軟なスキーマレス データベースではありません。構造化データに対して複雑なSQLクエリを実行するように設計されているため、ソーシャルメディアの投稿やコメントなどの非構造化コンテンツや半構造化コンテンツにはあまり適していません。
C. クラウドデータストア:Cloud Datastore も Google Cloud が提供する NoSQL データベースですが、より最新の機能と優れたスケーラビリティにより、Firestore がほぼこれに取って代わりました。このシナリオでも Cloud Datastore は機能しますが、新しいプロジェクトでは一般的に Firestore をおすすめします。
D. Cloud SQL:Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。固定スキーマが適用されるため、ソーシャルメディアプラットフォームにおけるユーザー生成コンテンツの柔軟でスキーマレスな性質にはあまり適していません。Cloud SQL は、構造化データ ストレージとリレーショナル データベースのニーズに適しています。
</div></details>

### Q. 質問48: 未回答
オンラインゲーム会社は、スコア、実績、ゲームの進行状況などのプレーヤー統計をリアルタイムで保存して処理したいと考えています。頻繁な更新とクエリを処理できるデータベースが必要です。どのGCPサービスをお勧めしますか?
1. 　Bigtable
2. Cloud Datastore
3. BigQuery
4. Cloud SQL
<details><div>
    答え：1
説明
質問の正しいオプションは次のとおりです。 A. Bigtable
このシナリオでは、オンラインゲーム会社は、頻繁な更新とクエリを使用して、プレーヤーの統計をリアルタイムで保存および処理する必要があります。Bigtable は、Google Cloud Platform(GCP)上の NoSQL で拡張性が高く、低レイテンシのデータベース サービスであり、大量のデータを高い読み取りおよび書き込みスループットで処理するように設計されています。
リアルタイム データ処理: Bigtable は、リアルタイム データを低レイテンシで処理することに優れているため、ゲームプレイ中にリアルタイムで更新されるプレイヤーの統計情報を保存および処理するのに適しています。
スケーラビリティ: Bigtable は、多数のプレイヤーと広範な統計を扱うゲーム会社にとって不可欠な、大量のデータに対応するために簡単に拡張できます。
頻繁な更新とクエリ: Bigtable の設計は、高頻度の読み取りおよび書き込み操作に最適化されているため、プレイヤーの統計情報の記録と取得に適しています。
正しくないオプション -
B. クラウドデータストア:
Cloud Datastore も NoSQL データベースですが、一般的には、より構造化されたトランザクション データ ストレージを必要とするアプリケーションに適しています。頻繁な更新とクエリを伴うリアルタイムのゲーム統計については、Bigtable ほどパフォーマンスが高くない可能性があります。
C. BigQueryの場合:
BigQuery は、大規模なデータセットの分析とクエリ用に設計されたデータ ウェアハウス サービスです。これは、このシナリオの主要な要件であるリアルタイムのデータストレージと処理にはあまり適していません。
D. Cloud SQL:
Cloud SQL は、マネージド リレーショナル データベース サービスです。構造化データやトランザクションデータには適していますが、頻繁な更新やクエリを伴うリアルタイムのゲーム統計に必要なパフォーマンスとスケーラビリティを提供しない場合があります。
Bigtable は、リアルタイム処理機能、スケーラビリティ、頻繁な更新やクエリを処理する能力など、ゲーム会社のプレイヤー統計の要件に合致しているため、最も適切な選択肢です。
</div></details>

### Q. 質問49: 未回答
組織はニュース Web サイトを運営しており、ユーザーの行動データを分析してコンテンツのレコメンデーションをパーソナライズする必要があります。リアルタイムのデータストリーミングと複雑な分析を効率的に処理できるGCPデータベースサービスはどれですか?
1. 　Cloud Pub/Sub
2. Bigtable
3. Firestore
4. BigQuery
<details><div>
    答え：4
説明
質問の正しいオプションは D. BigQuery です。
BigQuery は、フルマネージドのサーバーレス データ ウェアハウスであり、リアルタイムのデータ ストリーミングや複雑な分析の処理に適しています。BigQuery は、大規模なデータセットの複雑な分析に優れたデータ ウェアハウスおよび分析プラットフォームです。ストリーミング挿入などの機能を通じてリアルタイムのデータストリーミングを効率的に処理でき、強力な分析のためのSQLのようなクエリ言語を提供します。これは、ユーザーの行動データに対して複雑なクエリを実行してコンテンツのレコメンデーションをパーソナライズするのに適しており、このシナリオに最も適した選択肢です。
コンテンツのレコメンデーションをパーソナライズするためにユーザーの行動データを分析する必要がある場合や、リアルタイムのデータ ストリーミングと複雑な分析が必要な場合、BigQuery は要件に最適な GCP データベース サービスです。
正しくないオプション -
A. Cloud Pub/Sub の場合: Cloud Pub/Sub は、イベントドリブン システムの構築とデータのストリーミングのためのメッセージング サービスです。データのストリーミングには便利ですが、BigQuery のようなデータベース サービスではなく、複雑な分析は実行しません。これは通常、メッセージ キューイングとイベント ドリブン アーキテクチャに使用されます。
B. Bigtable の場合: Bigtable は、高スループット、低レイテンシ、スケーラビリティを実現するように設計された NoSQL データベースです。大量のデータへの高速な読み取りおよび書き込みアクセスを必要とするアプリケーションには適していますが、複雑な分析には最適化されていません。Bigtable は、時系列データやキー値ストレージなどのユースケースに適しています。
C. Firestore: Firestore は、モバイル アプリケーションやウェブ アプリケーション向けに設計された NoSQL データベースです。リアルタイム データを処理できますが、主にトランザクション データに使用され、複雑な分析には使用されません。これはドキュメントベースのストレージ用に設計されており、クライアント間でデータをリアルタイムで同期する必要があるアプリケーションに適しています。
</div></details>

## 3
### Q. 質問2: 未回答
地震データを解析するシステムを設計します。抽出、変換、読み込み (ETL) プロセスは、Apache Hadoop クラスターで一連の MapReduce ジョブとして実行されます。ETLプロセスでは、一部のステップで計算コストがかかるため、データセットの処理に数日かかります。次に、センサーのキャリブレーション手順が省略されていることがわかります。今後、センサーのキャリブレーションを体系的に実施するために、ETLプロセスをどのように変更する必要がありますか?
1. 　
2. 新しい MapReduce ジョブを導入して、センサーのキャリブレーションを生データに適用し、この後、他のすべての MapReduce ジョブがチェーンされるようにします。
3. 
4. 
<details><div>
    答え：2
説明
正しいアプローチは B です。 
オプションBでは、センサーキャリブレーション専用のMapReduceジョブを導入し、すべてのデータがこの重要なステップを経てからさらに処理されるようにします。センサーキャリブレーションの省略に対処するための体系的かつ組織的な方法を提供し、ETLパイプラインで処理されるすべてのデータが将来一貫してキャリブレーションされることを保証します。
正しくないオプション -
A. 変換 MapReduce ジョブを変更して、他の処理を行う前にセンサーのキャリブレーションを適用します。
このオプションは、既存の変換ジョブを変更するだけなので、過去のセンサー調整の省略の問題には対処しません。今後のデータはキャリブレーションされますが、キャリブレーションされていないデータを遡及的に修正することはありません。
C. ETL プロセスの出力にセンサー キャリブレーション データを追加し、すべてのユーザーがセンサー キャリブレーションを自分で適用する必要があることを文書化します。
このオプションでは、センサのキャリブレーションの責任がエンドユーザーに移るため、体系的で信頼性の高いプロセスには理想的ではありません。ユーザーはキャリブレーションを忘れたり、誤って適用したりして、不整合につながる可能性があります。
D. シミュレーションを通じてアルゴリズムを開発し、キャリブレーション係数に基づいて最後の MapReduce ジョブから出力されたデータ出力の分散を予測し、その補正をすべてのデータに適用します。
このアプローチは洗練されているように聞こえますが、シミュレーションと予測に依存しているため、信頼性の高いセンサーのキャリブレーションには十分な精度が得られない可能性があります。また、複雑で、ある程度の不確実性が生じます。
</div></details>

### Q. 質問3: 未回答
オンライン小売業者の既存のアプリケーションは、Google App Engine でホストされています。新しい会社のイニシアチブでは、顧客との直接取引を可能にするためにアプリケーションを拡張しる必要があります。ビジネス インテリジェンス(BI)ツールを使用してショッピング トランザクションを効果的に管理し、複数のソースからのデータを分析するために、単一の Google Cloud データベースを活用することを目指しています。この要件には、どの Google Cloud データベースを選択すればよいでしょうか?
1. 　
2. Cloud SQL
3. 
4. 
<details><div>
    答え：2
説明
オンライン小売業者がショッピング トランザクションを管理する必要があるこのシナリオでは、データベース ソリューションとして Cloud SQL(オプション B)を選択するのが適切です。
Cloud SQL が適している理由は次のとおりです。
トランザクション データ: Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。これは、トランザクション データの保存と管理用に設計されており、ショッピング トランザクションを管理する要件と一致しています。
ACIDコンプライアンス: Cloud SQLデータベースは、ACID(原子性、一貫性、分離性、耐久性)に準拠し、トランザクションの信頼性と一貫性を確保します。
互換性: 小売業者の既存のアプリケーションがすでに Google App Engine で実行されている場合、Cloud SQL は App Engine とシームレスに統合されるため、自然な選択です。
BIツールの統合:Cloud SQLは、さまざまなBIツールのデータソースとして使用でき、小売業者は必要に応じてデータ分析を実行できます。
構造化データ: Cloud SQL は構造化データに適していますが、これは通常、トランザクション システムの場合です。
正しくないオプション -
BigQuery(オプション A): BigQuery は分析ワークロードや大規模なデータセットのクエリには優れていますが、通常、トランザクション データのプライマリ データベースとしては使用されません。これは、履歴データまたは集計データの保存と分析に適しています。
Cloud Bigtable(オプション C): Cloud Bigtable は、高スループット、低レイテンシの読み取り/書き込みオペレーション用に最適化された NoSQL データベースです。これは、大規模なリアルタイムのデータアクセスを必要とするアプリケーションに適していますが、従来のトランザクションデータには最適な選択ではない可能性があります。
Cloud Datastore(オプション D):Cloud Datastore は、高可用性とスケーラビリティを必要とするアプリケーションに適した NoSQL データベースです。ただし、一般的には非構造化データまたは半構造化データに使用され、トランザクション データ管理には適していない場合があります。
</div></details>

### Q. 質問5: 未回答
分析チームは、さまざまな指標を利用して、会社と再び関わる可能性が高い顧客を特定するための基本的な統計モデルを作成しようとしています。このモデルは Apache Spark を使用して実行し、データは Google Cloud Storage に保存される予定で、このタスクに Google Cloud Dataproc を利用することを提案しました。初期テストでは、このジョブは 30 ノード クラスタで約 15 分で完了し、結果は Google BigQuery に保存されることが示されています。目的は、このタスクを毎週実行することです。コスト効率を高めるためにクラスタ構成を最適化するにはどうすればよいでしょうか。
1. 　ワークロードを Google Cloud Dataflow に移行します。
2. クラスターにプリエンプティブル仮想マシン (VM) を使用します。
3. メモリの大きいノードを使用して、ジョブの実行を高速化します。
4. ワーカー ノードで SSD を使用して、ジョブの実行を高速化します。
<details><div>
    答え：2
説明
Google Cloud Dataproc の Apache Spark で週単位のワークロードを実行する際に、クラスタのコストを最適化するための正しいオプションは次のとおりです。
B. 
プリエンプティブル VM: プリエンプティブル VM は、標準のオンデマンド VM よりも大幅に安価であるため、Google Cloud の費用対効果の高いオプションです。ただし、Google Cloud によっていつでもプリエンプト(終了)される可能性があり、通常は短期間(最大 24 時間)でプリエンプト(終了)される可能性があります。週単位の統計モデルの実行など、長期的なアップタイムを必要としないワークロードでは、プリエンプティブル VM を使用すると、かなりのコストを節約できます。
正しくないオプション -
A. 
Google Cloud Dataflow への移行はオプションかもしれませんが、これは別のテクノロジーであり、既存の Apache Spark ベースのワークロードに大幅な変更が必要になる場合があります。これにより、複雑さが増し、開発作業が増える可能性があります。また、Dataflow と Dataproc のコストへの影響は、特定のユースケースによって異なります。
C. 
メモリの大きいノードを使用すると、ジョブのパフォーマンスが向上する可能性がありますが、コストが大幅に増加する可能性もあります。コストを最適化するこのシナリオでは、特にジョブが小さなプリエンプティブル ノードで効率的に実行される場合、より大きなノードを選択することは最も効率的なアプローチではない可能性があります。
D. 
ワーカー ノードに SSD を追加すると、データの読み取り/書き込みパフォーマンスが向上する可能性がありますが、必ずしもコスト最適化戦略ではありません。SSD はインフラストラクチャ コストを増加させる可能性があり、30 ノード クラスターで既に 15 分で実行されているジョブのパフォーマンス向上は大きくない可能性があります。コストの最適化が主な目的である場合、このオプションは最適な選択ではない可能性があります。
</div></details>

### Q. 質問6: 未回答
会社は、バッチベースとストリームベースのイベントデータの両方を受信します。Google Cloud Dataflow を使用して、予測可能な期間にわたってデータを処理したい。ただし、場合によっては、データが遅れたり、順序どおりに届かなかったりすることがあります。
遅延したデータや順序が正しくないデータを処理するために、Cloud Dataflow パイプラインをどのように設計すればよいですか?
1. 　
2. 
3. 透かしとタイムスタンプを使用して、時間差データをキャプチャします。
4. 
<details><div>
    答え：3
説明
Google Cloud Dataflow パイプラインで遅延または順序が正しくないデータを処理するには、次のことを行う必要があります。
C. 
ウォーターマークとタイムスタンプ: Google Cloud Dataflow のようなストリーム処理パイプラインでは、ウォーターマークとタイムスタンプは、遅延データや順不同のデータを処理するために不可欠な概念です。ウォーターマークはイベント時間の進行状況を表し、特定の期間にデータが完了したと見なすのが安全である時期を Dataflow が理解するのに役立ちます。タイムスタンプは、イベントがいつ発生したかを示します。
ウォーターマークとタイムスタンプを使用すると、次のことができます。
処理時間ではなくイベント時間に基づいてウィンドウを定義します。これにより、遅れて到着しても、関連する時間枠に属するデータを取得できます。
イベントが到着したときにタイムスタンプを割り当て、ウォーターマークを使用してイベント時間の進行状況を追跡することで、順不同のデータを処理します。Dataflow は、イベントのタイムスタンプに基づいて、適切なウィンドウにイベントを正しく配置できます。
正しくないオプション -
A. すべてのデータを取得するために 1 つのグローバル ウィンドウを設定します。
このアプローチでは、データの遅延や順序の乱れの問題には対処できません。すべてのデータが 1 つのウィンドウにあるかのように扱われ、指定された時間枠の後に到着したイベントを正しく処理するために必要な柔軟性は提供されません。
B. スライディング ウィンドウを設定して、すべての時間差データをキャプチャします。
スライディング ウィンドウは、一定の間隔でデータをキャプチャする場合に便利ですが、本質的に遅延データや順序が正しくないデータは処理されません。遅延データはスライディング ウィンドウの範囲外にある可能性があり、スライディング ウィンドウのみを使用してそのようなデータを処理するのに十分ではない可能性があります。
D. すべてのデータソースの種類 (ストリームまたはバッチ) にタイムスタンプがあることを確認し、タイムスタンプを使用して時間差データのロジックを定義します。
データソースにタイムスタンプを付けることはおすすめの方法ですが、Dataflow パイプライン内で遅延したデータや順序が正しくないデータを処理するという主要な問題には対処できません。タイムスタンプだけでは、イベント時間処理の複雑さを処理し、遅延データが処理ウィンドウで正しく考慮されるようにするには不十分です。
</div></details>

### Q. 質問8: 未回答
Google Cloud でデータ パイプラインを構築しています。機械学習プロセスでは、カジュアルな方法を使用してデータを準備する必要があります。ロジスティック回帰モデルをサポートする場合。また、null 値を監視して調整する必要もありますが、null 値は実数値のままで、削除することはできません。あなたは何をするべきか?
1. 　
2. Cloud Dataprep を使用して、サンプルソースデータ内の null 値を見つけます。Cloud Dataprep ジョブを使用して、すべての null を 0 に変換します。
3. 
4. 
<details><div>
    答え：2
説明
ロジスティック回帰モデル用のデータを準備しながら、実数値を維持する必要がある NULL 値を監視および処理するには、次のオプションを検討する必要があります。
B. 
このオプションが適切な理由は次のとおりです。
Cloud Dataprep: Cloud Dataprep は、データを視覚的に探索、クリーニング、変換できるデータ準備サービスです。null 値を 0 などの特定の値に置き換える機能など、null 値を処理するための使いやすいツールを提供します。
Null 値の処理: 機械学習では、特に実数値の特徴を操作する場合、null 値を 0 などの特定の数値に置き換えるのが一般的です。このアプローチにより、データが実数値のままになり、ロジスティック回帰モデルで効果的に使用できます。
正しくないオプション -
A. Cloud Dataprep を使用して、サンプルのソースデータから null 値を見つけます。Cloud Dataprep ジョブを使用して、すべての null を「none」に変換します。
null を 'none' に変換すると、数値以外の値がデータに導入され、ロジスティック回帰には適していません。ロジスティック回帰には数値入力特徴が必要です。
C. Cloud Dataflow を使用して、サンプル ソース データ内の null 値を検索します。Cloud Dataprep ジョブを使用して、すべての null を「none」に変換します。
Cloud Dataflow は強力なデータ処理サービスですが、通常、単純な null 値の置換タスクには使用されません。さらに、null を 'none' に変換することは、ロジスティック回帰モデルには適していない場合があります。
D. Cloud Dataflow を使用して、サンプルのソースデータで null 値を見つけます。カスタムスクリプトを使用してすべてのnullを0に変換します。
Cloud Dataflow はデータの前処理タスクに使用できますが、カスタム スクリプトを使用して null を 0 に置き換えると、不必要に複雑になる可能性があります。Cloud Dataprep は、このようなデータ準備タスクをよりユーザーフレンドリーで効率的に処理する方法を提供します。
</div></details>

### Q. 質問13: 未回答
あなたは、Google Cloud のデータ パイプラインに大量のテキスト ファイル用のストレージを作成する任務を負っています。目的は、ANSI SQL クエリを有効にし、圧縮を実装し、Google のベスト プラクティスに準拠しながら、入力場所からの並列読み込みを容易にすることです。これらの目標を達成するには、どのような手順を踏む必要がありますか?
1. 　
2. Cloud Dataflow を使用して、テキスト ファイルを圧縮された Avro に変換します。クエリには Cloud Storage と BigQuery の永続的なリンク テーブルを使用します。
3. 
4. 
<details><div>
    答え：2
説明
Google Cloud 上のデータ パイプライン用に非常に大きなテキスト ファイルのストレージを設計し、ANSI SQL クエリをサポートし、Google が推奨するプラクティスに従って入力場所からの圧縮と並列読み込みをサポートするには、次のオプションを検討する必要があります。
B. 
Cloud Dataflow: Cloud Dataflow を使用すると、並列読み込みをサポートしながら、テキスト ファイルを Avro 形式に変換できます。データ変換機能を提供し、大規模なデータセットを効率的に処理できます。
Cloud Storage: 変換されたデータを Cloud Storage に保存することは、効率的なデータ ストレージの一般的な方法です。Cloud Storage は、大量のデータを処理するように設計されており、データの耐久性と可用性を提供します。
BigQuery: データのクエリに BigQuery を使用すると、ANSI SQL を分析に活用できます。Cloud Storage のデータを参照する永続的なリンク テーブルを BigQuery で作成することで、データをクエリするための便利でパフォーマンスの高い方法が提供されます。
正しくないオプション -
A. Cloud Dataflow を使用して、テキスト ファイルを圧縮された Avro に変換します。ストレージとクエリに BigQuery を使用する:
BigQuery は Avro ファイルを保存できますが、Cloud Storage と比較して最も効率的なストレージ形式ではありません。さらに、Cloud Storage を参照する BigQuery でリンク テーブルを使用すると、柔軟性と制御性が向上します。
C. Grid Computing Tools を使用してテキスト ファイルを gzip に圧縮します。ストレージとクエリに BigQuery を使用する:
BigQuery は gzip 圧縮データを処理できますが、このオプションでは、クエリ最適化のためのより構造化された効率的なストレージを提供できる Avro 形式へのテキスト ファイルの変換には対応していません。
D. Grid Computing Tools を使用してテキストファイルを gzip に圧縮します。Cloud Storage を使用し、クエリのために Cloud Bigtable にインポートします。
Cloud Bigtable は、BigQuery のような ANSI SQL クエリの実行ではなく、高スループットで低レイテンシの NoSQL データ向けに設計されています。このオプションは、ANSI SQL クエリをサポートするための要件には適合しておらず、NoSQL ワークロードに適しています。
</div></details>

### Q. 質問15: 未回答
入力データが CSV 形式である Google Cloud 上のデータ パイプライン デプロイ用に 20 TB のテキスト ファイルのストレージを計画する場合、目的は、さまざまなエンジンを介して Cloud Storage のデータにアクセスする複数のユーザーの集計値をクエリするコストを削減することです。この目標を達成するには、どのようなストレージ サービスとスキーマの設計を選択する必要がありますか?
1. 　
2. 
3. ストレージには Cloud Storage を使用します。クエリ用に BigQuery の永続的なテーブルとしてリンクします。
4. 
<details><div>
    答え：3
説明
複数のエンジンを使用して Cloud Storage 内のデータをクエリする複数のユーザーの集計値をクエリするコストを最小限に抑えるには、次のオプションを検討する必要があります。
C. 
クラウドストレージ: 20 TB のテキストファイルを Cloud Storage に保存することは、大量のデータを処理するための費用対効果が高く効率的なオプションです。
BigQuery: BigQuery でデータを永続的なテーブルとしてリンクすると、データに対して SQL クエリを効率的に実行できます。BigQuery は分析用に設計されており、複雑なクエリをサポートし、大規模なデータセットを処理できます。
正しくないオプション -
A. ストレージには Cloud Bigtable を使用します。Compute Engine インスタンスに HBase シェルをインストールして、Cloud Bigtable データをクエリします。
Cloud Bigtable は、BigQuery のような ANSI SQL クエリの実行ではなく、高スループットの NoSQL ワークロード向けに設計されています。HBase をインストールして Compute Engine インスタンスを使用すると、複雑さが増し、ユースケースの費用対効果が高くない可能性があります。
B. ストレージに Cloud Bigtable を使用する。クエリ用に BigQuery の永続的なテーブルとしてリンクする:
BigQuery で Cloud Bigtable データをリンクすることは可能ですが、通常は NoSQL ストレージに特定の要件があり、BigQuery のデータに対して SQL のようなクエリを実行する必要がある場合に使用されます。ただし、CSV テキストデータを処理するには、Cloud Storage の方が費用対効果が高く、わかりやすいオプションです。
D. ストレージには Cloud Storage を使用します。クエリ用に BigQuery の一時テーブルとしてリンクする:
BigQuery でデータを一時テーブルとしてリンクすることは、一時データや永続化する必要のないデータのためのオプションです。20 TB のデータがあるため、効率的なクエリには永続的なテーブルを使用する方が適切です。
</div></details>

### Q. 質問17: 未回答
金融サービス組織は、クラウドテクノロジーに移行し、50TBの金融時系列データをクラウド環境に保存することを目指しています。このデータは頻繁に更新され、新しい情報が継続的にストリーミングされます。同時に、同社は現在のApache Hadoopジョブをクラウドに移行し、このデータから洞察を引き出す予定です。このデータを効果的に保存し、目的のクラウドベースの運用をサポートするには、どの特定の製品を採用する必要がありますか?
1. 　Cloud Bigtable
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. 
Cloud Bigtable が正しい選択と見なされる理由は次のとおりです。
スケーラビリティ: Cloud Bigtable は、高スループットで水平方向にスケーラブルなワークロード向けに設計された NoSQL データベースです。大量のデータを処理でき、頻繁な更新やデータのストリーミングを行うシナリオに適しています。
低レイテンシー: 特にリアルタイムの洞察が必要な場合に、金融時系列データに不可欠なデータへの低レイテンシーアクセスを提供します。
Apache Hadoop の統合: Cloud Bigtable は HBase API を介して Apache Hadoop と統合されているため、既存の Apache Hadoop ジョブをクラウドに移行して、大幅な変更を行うことなく Bigtable に保存されているデータを分析できます。
正しくないオプション -
B. Google BigQuery:
BigQuery は、大規模なデータセットに対して SQL のようなクエリを実行するのに最適ですが、主要なストレージ ソリューションではありません。これは、生の時系列データを格納するよりも、分析ワークロードに適しています。BigQuery にデータを読み込んで分析することはできますが、特にリアルタイムの更新と低レイテンシのアクセスが不可欠な場合は、50 TB の金融時系列データのプライマリ ストレージには最適ではない可能性があります。
C. Google Cloud Storage:
Cloud Storage はオブジェクト ストレージ サービスであり、Cloud Bigtable のようなデータベース システムと同じリアルタイムのデータ アクセス機能やクエリ機能を提供しない場合があります。Cloud Storage にデータを保存することもできますが、通常は耐久性のあるストレージ レイヤとして使用され、追加の処理を行わないとトランザクションや分析のワークロードには適さない場合があります。
D. Google Cloud データストア:
Cloud Datastore は、特定のユースケースに適した NoSQL データベースですが、大量の財務時系列データを処理し、Apache Hadoop ジョブをサポートするには、Cloud Bigtable と同じレベルのパフォーマンスとスケーラビリティを備えていない可能性があります。
</div></details>

### Q. 質問18: 未回答
組織は、ユーザーレベルのデータを含むテーブルを含む Google BigQuery データセットを維持しています。このデータの集計を他の Google Cloud プロジェクトに公開しながら、ユーザーレベルのデータへのアクセスを制御したいと考えています。さらに、全体的なストレージ コストを最小限に抑え、他のプロジェクトの分析コストがそれらのプロジェクトに割り当てられるようにする必要があります。彼らは何をすべきか?
1. 　
2. 集計結果を提供する新しいデータセットとビューを作成して共有します。
3. 
4. 
<details><div>
    答え：2
説明
ユーザーレベルのデータへのアクセスを制御し、ストレージ コストを最小限に抑え、他のプロジェクトの分析コストがそれらのプロジェクトに割り当てられるようにしながら、Google BigQuery データセットのユーザーレベルのデータの集計を他の Google Cloud プロジェクトに公開するには、組織は次のオプションを検討する必要があります。
B. 
新しいデータセット: 集計結果専用の新しいデータセットを作成することで、集計データをユーザーレベルのデータから分離し、アクセス制御と権限を分離することができます。これは、生のユーザーレベルデータへのアクセスを制御するのに役立ちます。
ビュー: 新しいデータセット内にビューを作成すると、ユーザーレベルのデータから必要な集計を生成するSQLクエリを定義できます。ビューは仮想テーブルとして機能し、データのフィルター処理および集計されたパースペクティブを提供します。
共有: その後、新しいデータセットとそれに関連するビューを他の Google Cloud プロジェクトと共有して、元のデータセット内のユーザーレベルのデータを安全に保ちながら、それらのプロジェクトが集計データにアクセスできるようにすることができます。
コスト管理: データセットとビューを分離することで、コストをより適切に管理および割り当てることができます。新しいデータセットとビューのクエリを実行するときに他のプロジェクトによって発生する分析コストは、それらのプロジェクトに関連付けられ、組織の全体的なコストが最小限に抑えられます。
正しくないオプション -
オプション A の、集計結果を提供する許可済みビューを作成して共有することも有効なアプローチです。ただし、新しいデータセットとビューを作成すると、集計されたデータがユーザーレベルのデータからより適切に分離され、長期的にはよりクリーンでスケーラブルなソリューションになる可能性があります。
オプション C では、集計結果を含む新しいデータセットとテーブルを作成して共有できますが、特にストレージ コストが懸念される場合は、集計を個別のテーブルに具体化するよりも、集計のビューを作成する方が一般的に効率的です。
オプション D は、データセットに dataViewer Identity and Access Management (IAM) ロールを作成して共有を有効にすることですが、それだけでは十分ではありません。それでも、ユーザーレベルのデータへのアクセスを制御しながら、特定の集計結果を提供するために、新しいデータセットまたはビューを作成する必要があります。
</div></details>

### Q. 質問29: 未回答
MariaDB SQL データベースを GCE VM インスタンスにデプロイ中であり、監視とアラートの設定が必要です。目標は、最小限の開発作業でネットワーク接続、ディスク IO、レプリケーション ステータスなどの指標を MariaDB から収集し、StackDriver を利用してダッシュボードとアラートを作成することです。この構成をどのように実現できますか?
1. 　
2. 
3. 
4. Ops Agent をインストールし、MySQL プラグインを設定します。
<details><div>
    答え：4
説明
最小限の開発労力で MariaDB から指標を収集し、ダッシュボードとアラートに StackDriver を使用するには、次の点を考慮する必要があります。
D. 
StackDriver エージェント: StackDriver Agent は、最小限の労力で VM インスタンスからシステムとアプリケーションの指標を収集するように設計されています。これにより、指標を収集して StackDriver にエクスポートするプロセスが簡素化されます。
MySQLプラグイン:StackDriver Agentには、MariaDBなどのMySQL互換データベースからデータベース関連の指標を収集するために特別に設計されたMySQLプラグインが含まれています。このプラグインは、ネットワーク接続、ディスク I/O、レプリケーション ステータスなどの重要なメトリックをキャプチャできます。
正しくないオプション -
オプション A(OpenCensus Agent をインストールし、カスタム指標収集アプリケーションを作成する)では、MariaDB 指標を収集して StackDriver にエクスポートするために、より多くの開発作業とカスタム コーディングが必要になります。これは、StackDriver エージェントが提供する組み込みの MySQL プラグインを使用する場合と比較して、より複雑なソリューションです。
オプション B(ヘルスチェックを使用して MariaDB インスタンスをインスタンス グループに配置する)は、主にインスタンスの可用性に対応しますが、データベース固有の指標を直接収集して StackDriver にエクスポートすることはありません。
オプション C(StackDriver Logging Agent をインストールし、MariaDB ログを読み取るための fluentd in_tail プラグインの構成)は、ログの収集に重点を置いており、データベースから詳細なパフォーマンスと正常性の指標を収集するのには適していません。
参照：
https://cloud.google.com/monitoring/custom-metrics/open-census
</div></details>

### Q. 質問31: 未回答
2 TB のリレーショナル データベースを Google Cloud Platform に移行するという課題があり、アプリケーションのリファクタリングに制限があり、費用対効果に重点が置かれています。このシナリオでは、データの保存と提供にどの Google Cloud サービスを選択すればよいですか?
1. 　
2. 
3. 
4. Cloud SQL
<details><div>
    答え：4
説明
2 TB のリレーショナル データベースを Google Cloud Platform に移行する要件を考えると、コストを主な懸念事項とし、アプリケーションの大幅なリファクタリングを行わずに、次のオプションを検討する必要があります。
D. クラウド SQL
リレーショナル データベースの互換性: Cloud SQL は、MySQL、PostgreSQL、SQL Server などの一般的なデータベース エンジンと互換性のあるマネージド リレーショナル データベース サービスを提供します。既存のデータベースがリレーショナルの場合、Cloud SQL はアプリケーション コードへの変更を最小限に抑えた簡単な移行パスを提供します。
費用対効果: Cloud SQL にはさまざまな料金階層と柔軟なスケーリング オプションが用意されているため、ワークロードと予算に適した構成を選択できます。ニーズに合わせて適切なマシンタイプとストレージ容量を選択できるため、コストを管理できます。
正しくないオプション -
オプション A、B、および C は、2 TB のリレーショナル データベースの単純な移行には適していない場合があります。
A. Cloud Spanner: Cloud Spanner は拡張性が高く、グローバルに分散されたデータベース サービスですが、トランザクション ワークロードの高可用性とスケーラビリティを実現するように設計されています。2TBのリレーショナルデータベースは、通常、ミッションクリティカルなグローバルに分散されたアプリケーションに使用されるため、コストが主な懸念事項である場合、やり過ぎになる可能性があります。
B. Cloud Bigtable: Cloud Bigtable は、通常、分析データや時系列データに使用される大規模な NoSQL データを保存および提供するために設計されています。これはリレーショナルデータベースではないため、従来の2TBリレーショナルデータベースの移行には適していない可能性があります。
C. Cloud Firestore: Cloud Firestore は、主にモバイルおよびウェブ アプリケーション向けに設計された NoSQL ドキュメント データベースです。通常、従来のリレーショナル データベースの移行には使用されず、大幅なアプリケーション リファクタリングが必要になる場合があります。
</div></details>

### Q. 質問32: 未回答
リアルタイム アプリケーションに Bigtable を使用しており、読み取りと書き込みが混在する負荷が高い。最近、追加のユース ケースを特定し、データベース全体の特定の統計を計算するために分析ジョブを時間単位で実行する必要があります。本番アプリケーションの信頼性と分析ワークロードの両方を確保する必要があります。あなたは何をするべきか?
1. 　
2. 
3. 単一クラスタ ルーティングで 2 番目のクラスタを追加する
4. 
<details><div>
    答え：3
説明
オプション C: 
このオプションでは、分析ワークロードを処理するために、Bigtable インスタンスに別のクラスタを追加します。この分離により、運用アプリケーションのリアルタイム トラフィックと分析ジョブが異なるクラスターで実行されることが保証され、分離レベルが提供されます。
単一クラスター ルーティングを使用すると、アプリ プロファイル (運用環境の場合はライブ トラフィック、分析の場合はバッチ分析) に基づいて、どのクラスターがどのタイプのトラフィックを処理するかを指定できます。このアプローチにより、トラフィック ルーティングを効果的に管理できます。
主な利点は、ワークロードを同じインスタンス内に保持しながら、ワークロードをある程度分離できるため、費用対効果と運用効率が高いことです。
正しくないオプション -
オプション A(Bigtable ダンプを GCS にエクスポート):Bigtable データを Google Cloud Storage(GCS)にエクスポートし、エクスポートしたファイルに対して分析を実行するのはバッチ指向のアプローチであり、リアルタイム分析や本番アプリケーションとのシームレスな統合はできません。また、分析プロセスの複雑さと遅延も増します。
オプション B(マルチクラスタ ルーティング):マルチクラスター ルーティングはワークロードの分離に適していますが、このオプションでは、運用環境にライブ トラフィック アプリ プロファイルを使用し、分析にバッチ分析プロファイルを使用することをお勧めします。ただし、ライブ トラフィック プロファイルはリアルタイム トラフィック用に設計されており、分析に使用すると、運用アプリケーションの信頼性に影響を与える可能性があります。
オプション D (既存のクラスターのサイズを 2 回増やす):既存のクラスターのサイズを増やすと、スケーリングに役立つ場合がありますが、リアルタイムのワークロードと分析のワークロードを明確に分離することはできません。このオプションは、リソースの競合につながる可能性があり、信頼性の問題に効果的に対処できない可能性があります。
</div></details>

### Q. 質問41: 未回答
ここでは、BigQuery データ ウェアハウスのメイン インベントリ テーブルを読み取る、ほぼリアルタイムのインベントリ ダッシュボードを作成します。履歴在庫データは、品目および場所ごとの在庫残高として保存されます。毎時間、数千件のインベントリーの更新があります。ダッシュボードのパフォーマンスを可能な限り向上させ、データが正確であることを確認する必要があります。どのような手順を踏む必要がありますか?
1. BigQuery の UPDATE 文を活用して、在庫残高が変化しているときに更新する
2. 
3. BigQuery ストリーミングを使用して、日次在庫移動テーブルに変更をストリーミングします。履歴在庫残高テーブルに結合するビューで残高を計算します。在庫残高表を毎晩更新します。
4. 
<details><div>
    答え：3
説明
C. 
オプション C が推奨される理由は次のとおりです。
ほぼリアルタイムのデータ:BigQuery ストリーミングを使用すると、在庫の変更が発生したときにキャプチャできるため、在庫移動表をほぼリアルタイムで最新の状態に保つことができます。これは、インベントリ ダッシュボードにとって非常に重要です。
パフォーマンス：履歴在庫残高テーブルを在庫移動テーブルから分離することで、移動データを照会するときにスキャンされるデータの量を減らすことができます。これにより、クエリのパフォーマンスが大幅に向上します。
精度：ビューでの残高の日次計算により、在庫残高テーブルに最も正確なデータが反映されます。このプロセス中に、必要なデータクレンジングと検証を実行する機会があります。
効率：在庫残高テーブルを毎晩更新することで、データを統合して最適化し、クエリのパフォーマンスにより適したものにすることができます。これは、ダッシュボードの速度を維持するのに役立ちます。
キーポイント -
ほぼリアルタイムのインベントリ ダッシュボードを作成する必要があります。
ダッシュボードは、BigQuery データ ウェアハウスのメイン インベントリ テーブルを読み取ります。
履歴在庫データは、品目および場所ごとの在庫残高として保存されます。
毎時間、数千件のインベントリーの更新があります。
ダッシュボードのパフォーマンスを可能な限り向上させ、データが正確であることを確認する必要があります。
正しくないオプション -
オプション A(BigQuery UPDATE ステートメントを使用)は、同時実行の問題が発生する可能性があるため、リアルタイム更新に適しておらず、クエリのパフォーマンスに影響を与える可能性があります。オプション B (在庫残高テーブルのパーティション分割) では、クエリのパフォーマンスは向上しますが、リアルタイムの更新やデータの正確性はオプション C ほど効果的には対応できません。
オプション D(BigQuery バルクローダーを使用)は、バッチ読み込みのシナリオに適しており、インベントリ ダッシュボードに必要なほぼリアルタイムのデータ更新を提供できない場合があります。したがって、このコンテキストでは最適な選択ではありません。
</div></details>

### Q. 質問43: 未回答
BigQuery テーブル内のデータのサンプルで Dataprep レシピを作成しました。このレシピを使用して、ロード・ジョブの実行が完了した後、同じスキーマを持つデータの新しい日次アップロードをクリーンアップおよび変換します。どのように進めればよいですか?
1. 　
2. 
3. 
4. Dataprep ジョブを Dataflow テンプレートとしてエクスポートし、Composer ジョブに組み込むことです。
<details><div>
    答え：4
説明
正しいオプションは D. 
データフローテンプレートとしてエクスポートする:Dataprep ジョブを Dataflow テンプレートとしてエクスポートすると、受信データに対して実行できる再利用可能なデータ変換ワークフローが作成されます。
Composerジョブに組み込む:Google Cloud Composer は、複雑なワークフローをオーケストレーションできるマネージド Apache Airflow サービスです。Dataflow テンプレートを Composer ジョブに組み込むことで、大規模なデータ処理パイプラインの一部として Dataprep ベースのデータ変換の実行をスケジュールし、管理することができます。
正しくないオプション -
A. Dataprep で cron スケジュールを作成します。Dataprep ではジョブの実行をスケジュールできますが、これらのスケジュールは通常、Dataprep 環境内で Dataprep ジョブを実行するためのものであり、このシナリオで必要な外部でのオーケストレーションのためのものではありません。
B. App Engine の cron ジョブを作成します。App Engine の cron ジョブは、HTTP エンドポイントのトリガーなど、App Engine 環境に固有のタスクには適していますが、データ変換ワークフローやその他の外部プロセスのオーケストレーションを目的としたものではありません。
C. レシピを Dataprep テンプレートとしてエクスポートし、Cloud Scheduler でジョブを作成します。Cloud Scheduler を使用してジョブをトリガーすることもできますが、Dataprep ジョブは通常、Dataprep 環境内で実行されます。このオプションでは、Dataprep ジョブの実行を大規模なデータ パイプラインにシームレスに組み込むことはできません。
参考リンク -
クラウドコンポーザー:- https://cloud.google.com/composer/
</div></details>

### Q. 質問47: 未回答
研究機関は、世界中で行われている実験から大規模な科学データを収集し、処理します。そのためには、ペタバイト規模のデータを低遅延で効率的に管理できるストレージソリューションが必要です。このシナリオにはどのGCPサービスが適していますか?
1. 　
2. 
3. Google クラウドストレージ
4. 
<details><div>
    答え：3
説明
研究機関が大規模な科学データを効率的に収集して処理し、ペタバイト規模のデータを低遅延で管理する必要があるシナリオに適したオプションは次のとおりです。
C. Google クラウドストレージ
Google Cloud Storage(オプション C): Google Cloud Storage は、ペタバイト規模のデータを含む大量のデータを保存および取得するように設計されています。オブジェクトへの低遅延アクセスを提供し、大規模なデータを効率的に格納および管理する必要があるシナリオに適しています。耐久性、スケーラビリティ、高可用性を提供し、データストレージの信頼できる選択肢となっています。
正しくないオプション -
A. Cloud Pub/Sub(オプション A):
Cloud Pub/Sub は、イベントドリブン システム向けのメッセージング サービスです。リアルタイムのメッセージングとイベントの取り込みに使用されますが、大規模なデータストレージ用には設計されていません。
B. Bigtable(オプション B):
Bigtable は、高スループットで低レイテンシのワークロード向けに設計された NoSQL データベースですが、大規模な科学データの保存と管理には適していない可能性があります。これは、大規模なデータセットの長期保存ではなく、高速でリアルタイムのデータアクセスと分析に適しています。
D. クラウドデータストア(オプション D):
Cloud Datastore は NoSQL データベース サービスであり、ウェブやモバイル アプリケーションのデータ ストレージには適していますが、ペタバイト規模の科学データの管理には適していない可能性があります。トランザクション データに重点を置いており、この特定のユースケースでは Google Cloud Storage と同じスケーラビリティと費用対効果を提供できない場合があります。
</div></details>

### Q. 質問48: 未回答
eラーニングプラットフォームは、生徒の進捗状況とクイズの結果をリアルタイムで追跡する必要があります。また、レポートと分析を生成する必要もあります。このユースケースに適したデータベースを提供するGCPサービスはどれですか?
1. 　
2. 
3. BigQuery
4. 
<details><div>
    答え：3
説明
生徒の進捗状況や小テストの結果をリアルタイムで追跡したり、eラーニングプラットフォームでレポートや分析を生成したりするには、BigQuery(オプションC)が最適なGCPサービスです。その理由は次のとおりです。
正しいオプションは C. BigQuery -
BigQuery は、大規模なデータセットの処理と複雑な SQL クエリの迅速な実行を専門とする、フルマネージドでサーバーレスかつ拡張性の高いデータ ウェアハウスです。
リアルタイム分析用に設計されており、データ分析とレポート作成タスクに優れたパフォーマンスを提供します。
データをリアルタイムで取り込んで分析できるため、生徒の進捗状況やクイズの結果をその都度追跡するのに適しています。
大量のデータを処理できるため、レポートや分析の生成に適しています。
正しくないオプション -
A. Firestore:
Firestore は、クライアント(モバイル アプリケーションやウェブ アプリケーションなど)間での柔軟なリアルタイムのデータ ストレージと同期に適した NoSQL ドキュメント データベースです。Firestore はリアルタイムのデータ更新を処理でき、学生関連のデータの管理には適していますが、BigQuery と比較すると、複雑な分析やレポート作成のタスクには適していない可能性があります。
B. Cloud SQL:
Cloud SQL はマネージド リレーショナル データベース サービスですが、従来のリレーショナル データベースの制限により、リアルタイムの分析やレポート作成には適していない場合があります。構造化データやトランザクション ワークロード向けに設計されているため、複雑な分析クエリでは BigQuery ほど効率的に実行できない場合があります。
D. クラウドデータストア:
Cloud Datastore は、半構造化データの保存とクエリに適した NoSQL データベースです。リアルタイムのウェブスケール アプリケーション向けに設計されていますが、BigQuery が提供する詳細なレポートと分析に必要な堅牢な分析機能は提供されない場合があります。
</div></details>

### Q. 質問49: 未回答
スマートシティに展開されたIoTデバイスからセンサーデータを収集して分析するプロジェクトに取り組んでいます。膨大な量の受信データを処理し、リアルタイム分析をサポートできるGCPサービスはどれですか?
1. 　
2. Bigtable
3. 
4. 
<details><div>
    答え：2
説明
この質問の正しい選択肢は、B. Bigtable です。
このシナリオでは、スマート シティに展開されたデバイスからの IoT センサー データを処理しており、通常は大量の受信データが生成されます。また、リアルタイム分析のサポートも必要です。
Bigtable は、大量のデータを低レイテンシと高スループットで処理するために設計された NoSQL データベースです。大量のセンサー データの取り込みと保存に適しています。Bigtable はリアルタイムのデータ取り込みを処理でき、効率的なクエリをサポートしているため、大規模なデータセットのリアルタイム分析に適しています。センサーの読み取り値などの時系列データに最適化されているため、このユースケースに適しています。
正しくないオプション -
A. Cloud Pub/Sub の場合:
Cloud Pub/Sub は、リアルタイムのイベントの取り込みと配信のために設計されたメッセージング サービスです。リアルタイム データの取り込みには適していますが、分析に必要なストレージとクエリ機能は提供されません。大規模なデータの処理と分析の実行に必要なストレージとクエリ機能が不足しています。
C. BigQueryの場合:
BigQuery は、大規模なデータセットに対して SQL に似たクエリを実行するために設計されたデータ ウェアハウスですが、リアルタイムのデータ取り込みには最適化されていません。BigQuery は分析クエリやバッチ処理には優れていますが、大量のリアルタイム データ インジェストを処理するには最適な選択肢ではない可能性があります。
D. Firestore:
Firestore は柔軟な NoSQL データベースですが、ドキュメントベースのデータの管理に適しており、一般的にモバイル アプリケーションやウェブ アプリケーションに使用されます。IoTセンサーからの大量の時系列データを処理し、リアルタイム分析を実行するには最適な選択ではない可能性があります。
</div></details>

### Q. 質問50: 未回答
マーケティング会社は、Web、モバイルアプリ、メールキャンペーンなど、さまざまなソースからの顧客データを保存して分析したいと考えています。複数のチャネルからのデータを統合して分析できるデータベースが必要です。どのGCPサービスを検討すべきでしょうか?
1. 　BigQuery
2. 
3. 
4. 
<details><div>
    答え：1
説明
さまざまなソースからの顧客データを保存および分析し、複数のチャネルからのデータを統合および分析することを検討しているマーケティング会社にとって、検討すべき最適なGCPサービスはA.BigQueryです。
BigQuery は、大規模なデータセットを処理し、分析とデータ ウェアハウスのために複雑な SQL クエリを実行するように設計されています。複数のソースとチャネルからのデータの統合と分析を効率的に処理できます。
正しくないオプション -
B. Firestore は、主にモバイルおよび Web アプリケーションの開発に使用される NoSQL ドキュメント データベースです。アプリケーションの構造化データの管理には適していますが、複数のチャネルにまたがる複雑なデータ分析には適していない可能性があります。
C. Cloud Datastore は、ウェブおよびモバイル アプリケーション用に設計された NoSQL データベースでもあります。Firestore と同様に、アプリケーションの構造化データの保存には適していますが、BigQuery のような分析機能やクエリ パフォーマンスには欠けています。
D. Cloud SQL は、フルマネージドのリレーショナル データベース サービスです。トランザクションデータベースには最適ですが、さまざまなソースやチャネルからのデータを扱うマーケティング会社が必要とする複雑な分析やデータ統合には最適化されていません。
</div></details>

## 4
### Q. 質問2: 未回答
外部顧客から、データベースからのデータのダンプが毎日提供されます。データはカンマ区切り値(CSV)ファイルとして Google Cloud Storage GCS に送られます。このデータを Google BigQuery で分析したいが、データに誤った形式または破損した行が含まれている可能性があります。
このパイプラインをどのように構築する必要がありますか?
1. 　
2. 
3. 
4. Google Cloud Dataflow バッチ パイプラインを実行してデータを BigQuery にインポートし、分析のために別の配信不能テーブルにエラーをプッシュします。
<details><div>
    答え：4
説明
Google BigQuery の Google Cloud Storage(GCS)にある日次 CSV ファイルのデータを分析しながら、破損または形式が正しくない可能性のある行を処理するパイプラインを構築するには、次の方法をお勧めします。
D. Google Cloud Dataflow バッチ パイプラインを実行してデータを BigQuery にインポートし、分析のために別の配信不能テーブルにエラーをプッシュします。
このアプローチが適切な理由は次のとおりです。
データの変換と検証: Google Cloud Dataflow は、データの変換と検証のための強力なツールです。Dataflow を使用して GCS から CSV ファイルを取り込み、データの検証と変換ロジックを適用してから、クリーンなデータを BigQuery に読み込むことができます。これにより、BigQuery に挿入する前に、必要に応じてデータのクリーニング、エンリッチメント、修正を行うことができます。
エラー処理: Dataflow は堅牢なエラー処理機能を提供します。正しく書式設定されていない行や破損している行は、配信不能テーブルにリダイレクトされ、そこで問題を個別に分析およびデバッグできます。これにより、不良データによって BigQuery への正常なデータの読み込みが妨げられることがなくなります。
バッチ処理: 毎日のデータ ダンプを処理するため、Dataflow などのバッチ処理アプローチがこのシナリオに適しています。これにより、データを継続的に監視するのではなく、より大きなチャンクでデータを処理できます。
正しくないオプション -
オプション A(フェデレーション データ ソースを使用)は、単純なケースでは機能する可能性がありますが、Dataflow と同じレベルの制御とエラー処理は提供されません。SQL クエリでのデータ品質の問題の処理は、複雑で効率が低下する可能性があります。
オプション B(Google Stackdriver で BigQuery モニタリングを有効にしてアラートを作成する)は、BigQuery 自体のパフォーマンスと運用上の問題のモニタリングとアラートに重点が置かれており、データ品質やデータのインポートの問題には直接対処していません。
オプション C(gcloud CLI を使用して BigQuery にデータをインポートし、max_bad_records を 0 に設定する)では、BigQuery にデータが読み込まれますが、破損した行や形式が正しくない行を処理するための堅牢なメカニズムは提供されません。max_bad_records を 0 に設定すると、エラーのある行が拒否され、データが失われる可能性があります。
</div></details>

### Q. 質問6: 未回答
あなたの会社は規制の厳しい業界に属しており、個々のユーザーが業務に必要な最小限の情報にのみアクセスできるようにするデータセキュリティポリシーを実装する必要があります。Google BigQuery を使用してこのポリシーを適用します。次の 3 つのアプローチのうち、どれを選びますか?(3つ選択してください。
1. 　
2. テーブルへのアクセスをロールで制限します。
3. 
4. BigQuery API へのアクセスを承認済みのユーザーに制限する
5. 複数のテーブルまたはデータベース間でデータを分離します。
6. 
<details><div>
    答え：2,4,5
説明
個々のユーザーが Google BigQuery で業務を行うために必要な最小限の情報にのみアクセスできるようにするという要件を適用するには、次の方法を使用できます。
B. テーブルへのアクセスをロールで制限します。さまざまなレベルのアクセス権限を持つさまざまなロールをユーザーまたはグループに割り当てます。これにより、特定のテーブルまたはデータセットをクエリまたは変更できるユーザーを制御できます。
D. BigQuery API へのアクセスを承認済みのユーザーに制限する:API アクセスを管理することで、BigQuery API を使用してデータを操作できるユーザーを制限できます。承認されたユーザーまたはアプリケーションのみがアクセスできるようにする必要があります。
E. 複数のテーブルまたはデータベース間でデータを分離します。アクセス要件に基づいてデータを異なるテーブルまたはデータセットに分割して整理します。これにより、ユーザーは自分のロールに関連するデータにのみアクセスできます。
これらのアプローチは、規制の厳しい業界におけるデータアクセス制御と規制へのコンプライアンスを確保するのに役立ちます。オプション A、C、および F は、全体的なデータ セキュリティとガバナンスにも役割を果たす可能性がありますが、ユーザー固有のデータ アクセス制限を適用するための直接的なメカニズムではありません。
</div></details>

### Q. 質問9: 未回答
Google Cloud Platform で実行される POS アプリケーションを開発しています。アプリケーションは支払いトランザクションを処理し、ユーザーベースが指数関数的に増加すると予想されます。データベースのインフラストラクチャのスケーリングを管理したくないため、スケーラブルで信頼性が高く、安全な Google データベース サービスを選択する必要があります。
どのGoogleデータベースサービスを使用する必要がありますか?
1. 　Cloud SQL
2. 
3. 
4. 
<details><div>
    答え：1
説明
正解 - A. Cloud SQL
ユーザーベースが急激に増加する可能性があると予想される POS アプリケーションで支払いトランザクションを処理する場合、インフラストラクチャのスケーリングの管理を避けたい場合は、Cloud SQL が適しています。その理由は次のとおりです。
1. 　Cloud SQL はフルマネージドのリレーショナル データベース サービスです: スケーリングやメンテナンスなどのインフラストラクチャ管理を行うため、アプリケーションの開発とビジネス ロジックに集中できます。
2. ACID コンプライアンス: Cloud SQL は、支払いトランザクションを処理し、データの一貫性と信頼性を確保するために不可欠な強力な ACID(Atomicity、Consistency、Isolation、Durability)コンプライアンスを提供します。
3. 一般的なデータベースエンジンとの互換性: Cloud SQL は、MySQL、PostgreSQL、SQL Server など、複数のデータベースエンジンをサポートしているため、アプリケーション固有の要件に柔軟に対応できます。
正しくないオプション -
BigQuery(オプション B)、Cloud Bigtable(オプション C)、Cloud Datastore(オプション D)は価値ある Google Cloud データベース サービスですが、ユースケースは異なります。
- BigQuery は、フルマネージドでサーバーレス、かつ拡張性の高いデータ ウェアハウス サービスであり、支払いトランザクションなどのトランザクション処理ではなく、主に分析やビジネス インテリジェンスのワークロードに使用されます。
- Cloud Bigtable は、高スループット、低レイテンシ、スケーラビリティを実現するように設計された NoSQL データベース サービスで、通常、大規模な高速な読み取りおよび書き込み操作を必要とするアプリケーションに使用されます。トランザクション処理には最適ではない可能性があります。
- Cloud Datastore は、ウェブ アプリケーションやモバイル アプリケーションの構築に適した NoSQL ドキュメント データベース サービスですが、特定の ACID 要件により、支払いトランザクションの処理には最適ではない場合があります。
</div></details>

### Q. 質問17: 未回答
会社では、独自のシステムを使用して、6 時間ごとにクラウドベースのデータ インジェスト サービスにインベントリ データを送信しています。データには、在庫品目 ID、名前、数量、場所など、いくつかのフィールドのペイロードが含まれます。送信のタイムスタンプも含まれます。送信に懸念がある場合は、システムによってデータが再送信されます。データの重複排除を最も効率的に行うにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. 各データエントリのハッシュ値とその他のメタデータを格納するデータベーステーブルを維持します。
<details><div>
    答え：4
説明
D. 各データエントリのハッシュ値とその他のメタデータを格納するデータベーステーブルを維持します。
送信されたデータの重複排除を行う最も効率的な方法は、各データエントリのハッシュ値とその他のメタデータを格納するデータベーステーブルを維持することです。このアプローチが効率的である理由は次のとおりです。
1.ハッシュ:各データエントリのハッシュ値の計算は、高速で効率的なプロセスです。ハッシュ関数は、データの内容に基づいて固定サイズのハッシュコードを生成し、比較的迅速に計算できます。
2.ストレージ:ハッシュ値やその他のメタデータをデータベーステーブルに格納することで、効率的なインデックス作成とクエリが可能になります。ハッシュ値を主キーとして使用したり、インデックス付き列で使用して高速検索を行ったりすることができます。
3.重複排除:新しいデータを受信すると、そのハッシュ値を計算し、データベースにすでに保存されているハッシュ値と比較できます。一致するハッシュ値が見つかった場合は、データが重複していることをすばやく判断し、適切なアクションを実行できます。
4.タイムスタンプ:データには送信のタイムスタンプが含まれます。このタイムスタンプをハッシュ値とともに使用して、再送信の場合に特定のデータエントリの最新バージョンを識別できます。
ハッシュ値とメタデータを使用してデータベーステーブルを維持することは、特に再送信やその他の問題のためにデータ転送に重複が含まれる可能性がある場合に、データの重複を排除するためのスケーラブルで効率的な方法です。このアプローチにより、受信データの迅速かつ信頼性の高い重複排除が可能になります。
</div></details>

### Q. 質問18: 未回答
あなたの会社は、Google Cloud に保存されている非常に大規模なデータセットに対して複雑な分析を実行したいと考えている新しいデータ サイエンティストを採用しました ストレージと Google Compute Engine の Cassandra クラスタ内。サイエンティストは、主に機械学習プロジェクト用のラベル付きデータセットと、いくつかの視覚化タスクを作成したいと考えています。彼女は、ラップトップがタスクを実行するのに十分なパワーがなく、速度が低下していると報告しています。あなたは彼女がタスクを実行するのを手伝いたいです。 あなたは何をするべきか?
1. 　
2. 
3. 
4. Google Compute Engine 上の仮想マシン(VM)に Google Cloud Datalab をデプロイします。
<details><div>
    答え：4
説明
Datalab は廃止され、Datalab create コマンドを使用して新しい Datalab インスタンスを作成することはできません。詳細については、以下の参照リンクを参照してください。
D. Google Compute Engine 上の仮想マシン(VM)に Google Cloud Datalab をデプロイします。
Google Cloud Datalab は、データの探索、分析、可視化のための強力なインタラクティブ ツールです。これは、データ サイエンスと機械学習のタスクに合わせて調整された Jupyter Notebook 環境を提供します。このシナリオでは、いくつかの理由から、Google Compute Engine 上の VM に Google Cloud Datalab をデプロイするのが最適なオプションです。
1. 　パフォーマンス: Google Cloud Datalab は、十分なコンピューティング リソースを備えた VM にデプロイできるため、データ サイエンティストは、大規模なデータセットを操作したり、複雑な分析を実行したりするための強力なコンピューティング環境にアクセスできます。
2. スケーラビリティ: Google Compute Engine 上の VM は、データ サイエンティストの特定の要件を満たすために、さまざまなレベルの CPU およびメモリ リソースでプロビジョニングできます。このスケーラビリティにより、より大きなデータセットを効率的に操作できます。
3. 統合: Google Cloud Datalab は、Google Cloud Storage、Cassandra、およびその他の Google Cloud Platform サービスとシームレスに統合されます。これにより、データサイエンティストは、単一の環境内で複数のソースからのデータに簡単にアクセスして分析できます。
4. コラボレーション: Google Cloud Datalab はチーム メンバーと共同で共有できるため、データ分析や機械学習プロジェクトでの効果的なコラボレーションが可能になります。
5. バージョン管理: Datalab ノートブックは、Git などのツールを使用してバージョン管理でき、データ分析コードとドキュメントを管理するための構造化された整理されたアプローチを提供します。
Google Cloud Datalab を Google Compute Engine にデプロイすることで、データ サイエンティストはデータ分析、可視化、機械学習のタスクに堅牢で柔軟な環境を提供し、ノートパソコンの限界に関する懸念に対処できます。
参考リンク -
https://cloud.google.com/vertex-ai/docs/workbench/introduction
</div></details>

### Q. 質問22: 未回答
プライベートなユーザーデータを含む機密性の高いプロジェクトに取り組んでいる。Google Cloud Platform にプロジェクトを設定し、社内で作業を格納しました。外部コンサルタントが、プロジェクトの Google Cloud Dataflow パイプラインでの複雑な変換のコーディングを支援します。ユーザーのプライバシーをどのように保護する必要がありますか?
1. コンサルタントにプロジェクトの閲覧者ロールを付与する
2. コンサルタントにプロジェクトの Cloud Dataflow デベロッパー ロールを付与する
3. サービス アカウントを作成して付与する
4. コンサルタントが別のプロジェクトで作業するためのデータの匿名化されたサンプルを作成することです。
<details><div>
    答え：4
説明
正解は、オプション D: コンサルタントが別のプロジェクトで作業するためのデータの匿名化されたサンプルを作成することです。
オプションDは、データのプライバシーとセキュリティを優先するため、正しい選択です。これには、次の手順が含まれます。
1. 　データの匿名化: 外部コンサルタントとデータを共有する前に、機密性の高いユーザーデータのサニタイズまたは匿名化されたサンプルを作成します。これは、プライバシーを確保するために、個人を特定できる情報(PII)や機密情報を削除または難読化することを意味します。
2. 別のプロジェクト: コンサルタントが作業する別のプロジェクトまたは環境を設定します。このプロジェクトには、匿名化されたデータセットと、Dataflow パイプラインの開発に必要なツールが含まれています。
3. コラボレーション: コンサルタントは、実際の機密データにアクセスすることなく、この制御された環境内でコラボレーションを行うことができます。匿名化されたデータセットを使用して Dataflow パイプラインを開発、テスト、最適化できます。
正しくないオプション -
A. オプション A では、コンサルタントにプロジェクトの閲覧者ロールを付与することを提案します。これにより、すべてのリソースへの読み取り専用アクセスが許可されますが、データのプライバシーや分離には対処されません。
B. オプション B では、コンサルタントにプロジェクトの Cloud Dataflow デベロッパー ロールを付与することをおすすめします。Dataflow パイプラインの開発は可能ですが、データのプライバシーを確保したり、コンサルタントの作業を機密データから分離したりすることはできません。
C. オプション C では、アクセスを管理する方法であるサービス アカウントの作成について言及していますが、データのプライバシーと分離を維持する方法は指定されていません。通常、サービス アカウントは認証と承認に使用されますが、データ アクセスを制御するには慎重に構成する必要があります。
</div></details>

### Q. 質問26: 未回答
多くの場合、会社の顧客データベースと注文データベースには大きな負荷がかかっています。これにより、運用に支障をきたすことなく分析を実行することが困難になります。データベースはMySQLクラスタ内にあり、mysqldumpを使用して夜間バックアップが取得されます。運用への影響を最小限に抑えて分析を実行したい。あなたは何をするべきか?
1. 　
2. ETL ツールを使用して、MySQL から Google BigQuery にデータをロードします。
3. 
4. 
<details><div>
    答え：2
説明
B. ETL ツールを使用して、MySQL から Google BigQuery にデータをロードします。
その理由は次のとおりです。
最小限の影響:ETL(抽出、変換、ロード)ツールを使用してGoogle BigQueryにデータをロードすると、運用中のMySQLクラスタに大きな影響を与えることなく分析を実行できます。ETLプロセスは、中断を最小限に抑えるために、オフピーク時にスケジュールできます。
スケーラビリティ: Google BigQuery は、大規模なデータ分析を処理するように設計されています。大規模なデータセットを効率的に処理およびクエリできるため、ソースMySQLクラスタに過負荷をかけることなく分析タスクに適しています。
懸念事項の分離: データを BigQuery に移動することで、分析ワークロードをオペレーショナル データベースから分離します。この分離は、分析タスクが顧客データベースと注文データベースのパフォーマンスと可用性に影響を与えないようにするためのベストプラクティスです。
リアルタイム分析: Google BigQuery はリアルタイムのデータストリーミングをサポートしているため、データが利用可能になったときにデータを取り込むことができます。これは、夜間のバックアップを待たずにほぼリアルタイムの分析を行うのに役立ちます。
正しくないオプション -
MySQL クラスターにノードを追加する (オプション A) やオンプレミスの Apache Hadoop クラスターに接続する (オプション C) などのオプションは分析に役立つ可能性がありますが、ソース データベースに追加の負荷がかかる可能性があります。Google Cloud Dataproc とバックアップを含むオプション D も機能しますが、分析に BigQuery を直接使用するほど簡単で効率的ではない可能性があります。したがって、ETLプロセスでGoogle BigQueryを使用することが、このユースケースに推奨されるアプローチです。
</div></details>

### Q. 質問36: 未回答
スパム分類子をトレーニングしています。学習データを過剰適合していることに気付きます。この問題を解決するために実行できる 3 つのアクションはどれですか?(3つ選択してください。
1. 　より多くのトレーニング例を取得する
2. 
3. より小さな特徴セットを使用する
4. 
5. 正則化パラメーターを増やす
6. 
<details><div>
    答え：1,3,5
説明
正解-
A. より多くのトレーニング例を取得する: より多くのトレーニング例を取得することは、モデルの一般化に役立つため、過学習を減らすための一般的な方法です。
C. より小さな特徴セットを使用する: 特徴の数を減らすと、モデルが単純化され、過学習を減らすことができます。このアクションは効果的です。
E. 正則化パラメーターを増やす: L1 または L2 正則化の強度などの正則化パラメーターを増やすと、複雑なモデルにペナルティを課すことで過学習を減らすことができます。したがって、このアクションも有効なアプローチです。
正しくないオプション -
B. 学習例の数を減らす: 学習例の数を減らすと、通常、過学習の問題が悪化します。一般に、トレーニング例が多いと、モデルが一般化をより適切に学習するのに役立ちます。これらを減らすと、モデルがさらに過剰適合する可能性があります。
D. より多くの特徴セットを使用する: 特徴の数を増やすと、モデルが複雑になるため、過学習が悪化する可能性があります。新しい特徴が適切でなかったり、ノイズが発生したりすると、モデルがトレーニング データに近づきすぎて、過学習が発生する可能性があります。
F. 正則化パラメーターを減らす: L1 または L2 正則化の強度を下げるなど、正則化パラメーターを減らすと、過学習が増加する傾向があります。正則化は、モデルがトレーニング データに近づきすぎないようにするために使用されます。これらのパラメーターを減らすと、モデルがより複雑になり、データが過剰適合する可能性があります。
</div></details>

### Q. 質問44: 未回答
Google Kubernetes Engine(GKE)上で動作するデータ処理アプリケーションがあります。コンテナーは、コンテナー レジストリから使用可能な最新の構成で起動する必要があります。GKE ノードには、GPU、ローカル SSD、8 Gbps の帯域幅が必要です。データ処理インフラストラクチャを効率的にプロビジョニングし、デプロイ プロセスを管理する必要があります。
あなたは何をするべきか?
1. 　
2. Cloud Build を使用して Terraform ビルドを使用してジョブをスケジュールし、インフラストラクチャをプロビジョニングし、最新のコンテナ イメージで起動します。
3. 
4. 
<details><div>
    答え：2
説明
GPU、ローカル SSD、および 8 Gbps 帯域幅を使用してデータ処理インフラストラクチャを効率的にプロビジョニングし、展開プロセスを管理するには、オプション B が最適です。
B. Cloud Build を使用して Terraform ビルドを使用してジョブをスケジュールし、インフラストラクチャをプロビジョニングし、最新のコンテナ イメージで起動します。
Cloud Build: Cloud Build は、アプリケーションをビルド、テスト、デプロイできるマネージド CI / CD サービスです。これを使用して、コンテナー イメージをビルドおよびデプロイするための自動化されたワークフローを作成できます。Cloud Build でジョブをスケジュールすることで、インフラストラクチャとコンテナを常に最新の状態に保つことができます。
Terraform: Terraform は、宣言的な方法でインフラストラクチャを定義およびプロビジョニングできる一般的なコードとしてのインフラストラクチャ (IaC) ツールです。Terraform を使用して、GPU、ローカル SSD、ネットワーク構成など、必要な仕様で GKE クラスタを作成、管理できます。
コンテナ イメージ: Cloud Build は、ソースコードやコンテナ構成に変更があった場合に、最新のコンテナ イメージをビルドしてコンテナ レジストリにプッシュするように設定できます。これにより、コンテナーで常に最新のイメージが使用されるようになります。
効率性: Terraform と Cloud Build を使用することで、インフラストラクチャのプロビジョニングとコンテナのデプロイ プロセスを自動化し、効率性と一貫性を高めることができます。
正しくないオプション -
オプション A(Compute Engine スタートアップ スクリプトを使用)とオプション C(GKE を使用してコンテナを自動スケーリング)は、GPU やローカル SSD などの特定の要件を持つ GKE クラスタのプロビジョニングと管理には適していません。
オプション D(Dataflow と Cloud Scheduler を使用)は、GPU、ローカル SSD、8 Gbps 帯域幅を使用して GKE クラスタをプロビジョニングする要件とは無関係のようです。データフローは通常、インフラストラクチャのプロビジョニングではなく、データ処理に使用されます。
</div></details>

### Q. 質問46: 未回答
あなたは大手eコマース企業のデータエンジニアです。現在、会社では Cloud Dataproc を使用して、顧客の購入履歴の大規模なデータセットを処理しています。しかし、Cloud Dataproc ではスケーラビリティとパフォーマンスの面でニーズを満たしていないことがわかりました。顧客の購入履歴の大規模なデータセットを処理するために Cloud Dataproc を置き換えるために、次の GCP サービスのうちどれを会社にお勧めしますか?
1. 　
2. 
3. BigQuery
4. 
<details><div>
    答え：3
説明
正解はBigQueryです。BigQuery は、大規模なデータセットを簡単に処理できる、ペタバイト規模のフルマネージド分析データ ウェアハウスです。また、拡張性とパフォーマンスも高いため、顧客の購入履歴の大規模なデータセットを処理するのに最適です。
正しくないオプション -
A. Cloud Data Fusion は、フルマネージドのクラウドネイティブ データ統合サービスです。大規模なデータセットを処理するようには設計されていません。
B. Cloud Dataflow は、フルマネージドのストリーミング データ処理サービスです。顧客の購入履歴の大規模なデータセットを処理するようには設計されていません。
D. Cloud Dataproc は、Hadoop と Spark のマネージド サービスです。大規模なデータセットを処理するための BigQuery ほどスケーラブルでもパフォーマンスも高くありません。
</div></details>

### Q. 質問47: 未回答
IoT デバイスからリアルタイム データを取り込んで処理するためのデータ パイプラインを設計しています。このデータは、リアルタイムのダッシュボードと分析を強化するために使用されます。
このパイプラインを設計する最適な方法は、次のうちどれですか?
1. 　Cloud Pub/Sub を使用してデータを取り込み、BigQuery に保存します。Dataflow を使用して BigQuery のデータを処理し、リアルタイムの指標を生成します。Cloud Data Studio を使用して、リアルタイムのダッシュボードを作成します。
2. 
3. 
4. 
<details><div>
    答え：1
説明
A. Cloud Pub/Sub を使用してデータを取り込み、BigQuery に保存します。Dataflow を使用して BigQuery のデータを処理し、リアルタイムの指標を生成します。Cloud Data Studio を使用して、リアルタイムのダッシュボードを作成します。
IoT デバイスからリアルタイム データを取り込んで処理するデータ パイプラインを設計する最善の方法は、Cloud Pub/Sub、BigQuery、Dataflow、Cloud Data Studio を使用することです。
Cloud Pub/Sub は、IoT デバイスからデータを取り込むために使用できるフルマネージドのリアルタイム メッセージング サービスです。BigQuery は、データの保存と処理に使用できるペタバイト規模のフルマネージド分析データ ウェアハウスです。Dataflow は、ストリーミング パイプラインとバッチ データ処理パイプラインを構築して実行するためのフルマネージド サービスです。Cloud Data Studio は、リアルタイムのダッシュボードの作成に使用できるデータ可視化ツールです。
このパイプラインを実装するには、まず、IoT デバイスから取り込むデータの種類ごとに Cloud Pub/Sub トピックを作成する必要があります。次に、これらのトピックにデータを発行するように IoT デバイスを構成する必要があります。
次に、データを保存するための BigQuery データセットを作成する必要があります。次に、Dataflow パイプラインを作成して、Cloud Pub/Sub トピックからデータを読み取り、BigQuery データセットに書き込む必要があります。
最後に、Cloud Data Studio のレポートを作成して、データをリアルタイムで可視化する必要があります。
このパイプラインは、大量のリアルタイム データを処理でき、増大するニーズに合わせてスケーラブルになります。
</div></details>

## 5
### Q. 問題28: 正解
Google Cloud上のデータパイプラインのために、Cloud Pub/SubからBigQueryへのJSONメッセージの書き込みと変換を行うサービスを選択しています。サービスのコストは最小限に抑えたいと考えています。また、サイズが変化する入力データ量を監視し、最小限の手動操作で対応したいと考えています。
要件を達成するためにするべきことは何ですか？
1. 　
2. 
3. Cloud Dataflowを使用して変換を実行する。Cloud Monitoringでジョブシステムの遅延を監視する。ワーカーインスタンスにデフォルトのオートスケーリング設定を使用する
4. 
<details><div>
    答え：3
説明
Pub/Subのデータを処理するスケーラブルなサービスを選択する必要があります。
また、データ量の監視も自動的に行えるようにする必要があります。
Pub/Sub は、スケーラブルで耐久性のあるイベントの取り込みおよび配信システムです。
Dataflow は、メッセージの重複排除、1 回限りの処理、タイムスタンプ付きイベントからのデータ ウォーターマークの生成により、Pub/Sub のスケーラブルな「最低 1 回」配信モデルを補完する。
Dataflow を使用するには、Apache Beam SDK でパイプラインを記述し、Dataflow サービスでパイプライン コードを実行する。
データ量監視についてはCloud Monitoring（Cloud Monitoring）が有効です。
Cloud Monitoring は、Google Cloud、Amazon Web Services（AWS）、ホストされた稼働時間プローブ、アプリケーション インストゥルメンテーションから指標、イベント、メタデータを収集する。
BindPlane サービスを使用して、150 以上の共通のアプリケーション コンポーネント、オンプレミス システム、ハイブリッド クラウド システムからデータを収集することもできます。
データを取り込むと、Google Cloud のオペレーション スイートはダッシュボード、グラフ、アラートを介して分析情報を提供する。
したがって、正解は「Cloud Dataflowを使用して変換を実行する。Cloud Monitoringでジョブシステムの遅延を監視する。ワーカーインスタンスにデフォルトのオートスケーリング設定を使用する」です。
参照：
https://cloud.google.com/Pub/Sub/docs/Pub/Sub-dataflow
https://cloud.google.com/migrate/compute-engine/docs/4.8/how-to/monitoring/using-Cloud Monitoring-monitoring
</div></details>

## 6
### Q. 問題18: 不正解
あなたは、企業が経済動向を把握することを支援する経済コンサルティング会社に勤務しています。分析の一環として、Google BigQuery を使用して、パン、ガソリン、牛乳など、最も一般的に販売されている 100 種類の商品の平均価格と顧客データを関連付けています。これらの商品の平均価格は30分ごとに更新されます。このデータが常に最新であることを確認し、BigQueryの他のデータとできるだけ低コストで組み合わせられるようにしたいと考えています。
要件を達成するためにするべきことは何ですか？
1. 　
2. データをリージョンの Google Cloud Storage バケットに保存して更新し、BigQuery で連携データソースを作成する
3. 
4. 
<details><div>
    答え：2
説明
BigQueryは巨大なデータセットのためのフルマネージドクエリサービスですが、データをBigQueryのデータセットに移動しなくても、BigQueryのデータアクセスレイヤーを使用してデータ連携をすることが可能です。
これは、BigQueryは連携型のデータアクセスモデルを備えており、Bigtable、Cloud Storage、Google Driveから直接、永続テーブルと一時テーブルを使ってデータを照会することができるからです。
複数のGoogle Cloud Platformサービスにデータがあり、データレイクやデータウェアハウス戦略を構築している場合、この機能がコスト最適化の観点からも有用になる場合があります。
今回の例であれば、BigQueryにインポート処理をする場合よりも、Cloud Storageのストレージコストの方が安くなるためコスト最適なソリューションを実現できます。
したがって、正解は「データをリージョンの Google Cloud Storage バケットに保存して更新し、BigQuery で連携データソースを作成する」です。
参照：
https://cloud.google.com/blog/products/gcp/accessing-external-federated-data-sources-with-bigquerys-data-access-layer
</div></details>

## 7
### Q. 問題26: 未回答
あなたは、サードパーティから毎月CSV形式のデータファイルを受け取っています。このデータをクレンジングする必要がありますが、3ヶ月に一度、ファイルのスキーマが変更されます。これらの変換を実行するための要件は以下の通りです。
- 変換をスケジュール通りに実行すること
- 開発者ではないアナリストが変換を修正できるようにすること
- トランスフォームを設計するためのグラフィカルなツールを提供すること
要件を達成するためにするべきことは何ですか？
1. 　Cloud Dataprep を使用して変換レシピを構築・維持し、スケジュールに基づいて実行する
2. 
3. 
4. 
<details><div>
    答え：1
説明
変換レシピの定期的な変更が可能でありかつ、定期実行可能なサービスを選択する必要があります。
また、開発者ではないアナリストのためにノーコードによるデータ変換をサポートする必要があります。
Cloud Dataprep by Trifacta は、分析、レポート、機械学習に使用する構造化データと非構造化データを視覚的に探索、クリーニング、準備できるインテリジェント データ サービスです。
Dataprep はサーバーレスで、規模に関係なく稼働します。
デプロイや管理が必要なインフラストラクチャはなく、素早くデータ変換ロジックを構築し定期実行も行うことが可能です。
Dataprep は、最適なデータ変換操作を UI で操作を行うたびに自動で提案、予測します。
変換のシーケンスを定義しておけば、Dataprep は内部的に Dataflow または BigQuery を使用し、あらゆるサイズの構造化データセットまたは非構造化データセットをわずか数回のクリックで処理できるようにします。
そのため、コードを記述する必要がなくなります。
したがって、正解は「Cloud Dataprep を使用して変換レシピを構築・維持し、スケジュールに基づいて実行する」です。
参照：
https://cloud.google.com/dataprep/
https://cloud.google.com/dataprep/docs/html/Overview-of-RapidTarget_136155049
</div></details>

### Q. 問題48: 未回答
Google Cloudにデータパイプラインを導入するにあたり、20TBのテキストファイルのストレージを設計しています。入力データはCSV形式です。複数のユーザーが複数のエンジンでCloud Storageのデータを照会する場合、集約値の照会コストを最小化したいと考えています。
どのストレージサービスとスキーマデザインを使用すべきでしょうか？
1. 　
2. 
3. ストレージにはCloud Storageを使用する。問い合わせ用にBigQueryのパーマネントテーブルとしてリンクする
4. 
<details><div>
    答え：3
説明
適切なストレージを選択しつつ、参照のためのコスト最適なテーブルを設計する必要があります。
Cloud StorageはCSVデータを低コストで大量に保存する際に最適なストレージです。
また、Cloud Storageに保存されたCSVファイルは、BigQueryによるクエリがネイティブにサポートされているので、データ照会を容易に行うことができます。
BigQueryのテーブル設計について注意が必要な点は、照会コストを最小にするという要件です。
一時テーブルを利用する場合は、BigQuery データセットの 1 つにテーブルを作成するわけではありません。
つまり、テーブルはデータセットに恒久的に保存されないので、クエリを行うたびにコストがかかります。
永続的なテーブルは、データセットに作成され、外部データソースにリンクされます。
テーブルが永続的であるため、データセットレベルのアクセス制御を使用して、基礎となる外部データソースへのアクセス権を持つ他の人とテーブルを共有し、低コストでテーブルを照会することが可能になります。
したがって、正解は「ストレージにはCloud Storageを使用する。問い合わせ用にBigQueryのパーマネントテーブルとしてリンクする」です。
参照：
https://cloud.google.com/blog/products/gcp/accessing-external-federated-data-sources-with-bigquerys-data-access-layer
https://cloud.google.com/bigquery/external-data-cloud-storage
</div></details>

### Q. 問題50: 未回答
あなたは、ユーザーの注文する料理を予測する機械学習ベースの食品注文サービスのデータベーススキーマを設計しています。以下は、あなたが保存する必要のある情報の一部です。
- ユーザーのプロフィール。ユーザーが好きなもの、嫌いなもの
- ユーザーのアカウント情報。名前、住所、好みの食事時間
- 注文情報。いつ、どこから、どのお店に注文するか
データベースは、サービスのすべてのトランザクションデータを格納するために使用されます。あなたはデータスキーマを最適化したいと考えています。
どのGoogle Cloud Platformサービスを使うべきでしょうか？
1. 　
2. 
3. 
4. Cloud Datastore
<details><div>
    答え：4
説明
ユーザープロファイルは、ユーザーの過去の活動や嗜好に基づいて、ユーザーの体験をカスタマイズするためのものです。
そのため、リレーショナルデータベースよりも柔軟なスキーマ構造を保持する必要があります。
Datastoreの柔軟なスキーマにより、アプリケーションの新機能をサポートするために新しいプロパティを追加するなど、時間の経過とともにユーザプロファイルの構造を変化させることができます。
スキーマの変更はダウンタイムなしで行われ、ユーザー数が増加してもパフォーマンスが低下することはありません。
したがって、正解は「Cloud Datastore」です。
参照：
https://cloud.google.com/architecture/building-scalable-web-apps-with-cloud-datastore
https://cloud.google.com/architecture/building-scalable-web-apps-with-cloud-datastore#integration-with-other-gcp-products</div></details>

## 8
### Q. 
あなたは、単一のテーブルで繰り返し実行されるクエリについて、BigQuery の最適化に取り組んでいます。クエリされるデータは約 1 GB で、一部の行は 1 時間に約 10 回変更されることが予想されます。SQL ステートメントは可能な限りの最適化が済んでおり、クエリのパフォーマンスをさらに最適化したいと考えています。どうすればよいですか。
1. 　テーブルに基づくマテリアライズド ビューを作成して、そのビューをクエリします。
2. クエリデータのキャッシュ保存を有効にして、後続のクエリを高速化します。
3. スケジュール設定済みクエリを作成して、レポート作成の数分前にそのクエリを実行します。
4. 多数のスロットを事前に予約して、クエリの実行のためのコンピューティング能力を最大化します。
<details><div>
正解
1. 　テーブルに基づくマテリアライズド ビューを作成して、そのビューをクエリします。
フィードバック
A: 選択肢 A は正解です。マテリアライズド ビューは、パフォーマンスを向上させるためにクエリの結果を定期的にキャッシュ保存します。マテリアライズド ビューは、頻繁にクエリされる小さなデータセットに適しています。基盤となるテーブルデータが変更されると、影響を受ける部分をマテリアライズド ビューが無効化して再度読み込みます。
B: 選択肢 B は不正解です。キャッシュ保存は自動的に有効化されますが、基盤となるデータが変更されるとパフォーマンスを発揮できません。
C: 選択肢 C は不正解です。スケジュール設定済みクエリにより定期的なクエリをスケジュールできますが、パフォーマンスは特に最適化されません。また、クエリを早く実行しすぎると古いデータが使用される場合があります。
D: 選択肢 D は不正解です。多くのスロットを予約すると、BigQuery スロットの可用性は確保されますがパフォーマンスは向上しません。
 
https://cloud.google.com/bigquery/docs/materialized-views-intro
 
https://cloud.google.com/bigquery/docs/materialized-views-best-practices
 
https://cloud.google.com/bigquery/docs/materialized-views
</div></details>

### Q. 
Cloud Spanner データベースには、マーケティング チームが頻繁にアクセスするお客様のアドレス情報が保存されています。お客様が居住する国と州を入力すると、この情報は、外部キーで接続されている別のテーブルに保存されます。現在のアーキテクチャにはパフォーマンスの問題があり、あなたは Google の推奨手法に従ってパフォーマンスを改善したいと考えています。どうすればよいですか。
1. 　インターリーブされたテーブルを作成して、国の下に州を保存します。
2. データを非正規化して、対応する国とともに各州ごとの行を作成します。
3. 既存のアーキテクチャを維持しながら、国と州に短い 2 文字のコードを使用します。
4. 国を 1 つのセルのテキストに結合します。たとえば、「country:state1,state2, …」などです。必要な場合はデータを分割します。
<details><div>
正解
1. 　インターリーブされたテーブルを作成して、国の下に州を保存します。
フィードバック
A: 選択肢 A は正解です。Cloud Spanner はインターリーブをサポートしており、同じスプリットにデータが保存されるようにします。これにより、強いデータ局所性関係が必要なときのパフォーマンスが向上します。
B: 選択肢 B は不正解です。リレーショナル データベースでは、非正規化は好ましい手法ではありません。繰り返しデータにより複数の行が発生するためです。
C: 選択肢 C は不正解です。フィールドの大きさを略称で小さくしても、あまり違いは生じません。データのアクセスと結合がパフォーマンスのさらに大きな問題となるためです。
D: 選択肢 D は不正解です。複数の種類のデータを同じセルに詰め込むことは、リレーショナル データベースでは推奨されません。
 
https://cloud.google.com/spanner/docs/schema-and-data-model#creating-interleaved-tables
</div></details>

### Q. 
あなたの会社はビジネス クリティカルなシステムを PostgreSQL で実行しています。このシステムは、数百万ものユーザーに対応しており、世界中の多くの場所から同時にアクセスされます。データベース管理チームは冗長性とスケーリングを手動で管理しており、あなたは、データベースを Google Cloud に移行したいと考えています。グローバル スケールと可用性を提供する一方でメンテンナンスが最少のソリューションが必要です。どうすればよいですか。
1. 　BigQuery に移行します。
2. Cloud Spanner に移行します。
3. Cloud SQL for PostgreSQL インスタンスに移行します。
4. PostgreSQL がインストールされているベアメタル マシンに移行します。
<details><div>
正解
2. Cloud Spanner に移行します。
フィードバック
A: 選択肢 A は不正解です。BigQuery はグローバル スケールをサポートしていません。また、BigQuery は、PostgreSQL のようなトランザクション データベースの移行にはあまり適していません。分析に重点が置かれているためです。
B: 選択肢 B は正解です。Cloud Spanner は、リレーショナル データをサポートする、グローバル スケールで高可用性のデータベースを提供します。
C: 選択肢 C は不正解です。Cloud SQL のオプションはリージョナルで、Cloud Spanner に比べてスケーラビリティが小さくなります。
D: 選択肢 D は不正解です。ベアメタル マシンで PostgreSQL を実行すると、必要なメンテナンスが増えます。
 
https://cloud.google.com/spanner/docs/migrating-postgres-spanner
</div></details>

### Q. 
あなたの会社は、BigQuery の知識がないビジネス アナリストを数人雇用していますが、今後、彼らは BigQuery を使用して大量のデータを分析する予定です。あなたは、BigQuery でのコスト管理を行い、クエリ結果の品質を維持しつつ予算が超過しないようにする必要があります。どうすればよいですか。
1. 　プロジェクト レベルまたはユーザーレベルでカスタマイズした 1 日の割り当てを許容できる値に設定します。
2. BigQuery テーブルのデータを減らしてアナリストがクエリするデータ量を減らしてから、残りのデータをアーカイブします。
3. クエリ検証ツールまたは --dry_run を使用して費用を見積もれるようにアナリストをトレーニングし、アナリストが使用量を自身で制御できるようにします。
4. 各アナリストに対し BigQuery の 1 日あたりの費用をエクスポートして Looker でデータを可視化し、アナリストが使用量を自身で制御できるようにします。
<details><div>
正解
1. 　プロジェクト レベルまたはユーザーレベルでカスタマイズした 1 日の割り当てを許容できる値に設定します。
フィードバック
A: 選択肢 A は正解です。BigQuery プロジェクトとユーザーが複数ある場合は、1 日あたりに処理されるクエリデータの量に上限を指定するカスタム割り当てをリクエストして、コストを管理できます。
B: 選択肢 B は不正解です。部分的なデータのみをアナリストに渡しても、正確なクエリ結果が得られません。
C: 選択肢 C は不正解です。費用が予算を超過する可能性が残ります。この手法は、アナリストがガイドラインを常に遵守することが前提となります。
D: 選択肢 D は不正解です。費用が予算を超過する可能性が残ります。また、この手法は、アナリストが毎日チャートを確認してそれに応じて行動を調整することが前提となります。
 
https://cloud.google.com/bigquery/docs/custom-quotas
</div></details>

### Q. 
あなたのチームは Dataproc ワークロードを実行しており、ワーカーノードは処理に約 45 分かかります。費用の面から、ワーカーノードを積極的にシャットダウンすることも含めてシステムを最適化するさまざまな選択肢を検討してきましたが、指標ではジョブ全体がさらに長くなってしまいます。費用を抑えながらジョブ完了までの時間を延長せずにシステムを最適化するには、どうすればよいですか。
1. 　正常なデコミッションのタイムアウトを 45 分より大きく設定します。
2. Cloud Data Fusion での処理を書き換えて、ジョブを自動で実行します。
3. Dataflow での処理を書き換えて、同一データのストリーム処理を使用します。
4. 各ワーカーノードの vCPU の数を増やして処理完了までの時間を短縮します。
<details><div>
正解
1. 　正常なデコミッションのタイムアウトを 45 分より大きく設定します。
フィードバック
A: 選択肢 A は正解です。正常なデコミッションにより、ワーカーノードで進行中の作業が Dataproc クラスタから削除される前に終了します。
B: 選択肢 B は不正解です。Cloud Data Fusion でのデータ パイプラインの再構築は、労力、費用、時間が増大します。
C: 選択肢 C は不正解です。Dataflow のコードの書き換えは、労力、費用、時間が増大します。
D: 選択肢 D は不正解です。vCPU の数の増加により費用が大幅に増大します。
 
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/scaling-clusters
 
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/autoscaling#choosing_a_graceful_decommissioning_timeout
</div></details>

### Q. 
IT チームは構造化データの保存に BigQuery を使用しています。財務チームは、最近、スタンドアロンのデスクトップ版スプレッドシート プロセッサから Google Workspace Enterprise エディションに移行しました。財務チームがデータ分析情報を必要なとき、IT チームは BigQuery でクエリを実行してデータを CSV ファイルにエクスポートし、メールの添付ファイルとして財務チームメンバーに送信します。財務チームが慣れているデータ分析方法を変えずにこのプロセスを改善するには、どうすればよいですか。
1. 　BigQuery でクエリを実行して、分析可能な結果ビューへのアクセスを財務チームに許可します。
2. BigQuery でクエリを実行して、Google データポータルのデータ ビジュアリゼーションへのアクセスを財務チームに許可します。
3. BigQuery でクエリを実行して、データを CSV にエクスポートし、そのファイルを Cloud Storage バケットにアップロードして財務チームと共有します。
4. BigQuery でクエリを実行して、財務チームがアクセスして分析できる Google スプレッドシートの共有スプレッドシートに結果を保存します。
<details><div>
正解
4. BigQuery でクエリを実行して、財務チームがアクセスして分析できる Google スプレッドシートの共有スプレッドシートに結果を保存します。
フィードバック
A: 選択肢 A は不正解です。財務チームは Google Cloud へのアクセス権が必要なことに加えて、BigQuery の使用に関するトレーニングも必要となります。財務チームにとって BigQuery はなじみのある方法ではありません。
B: 選択肢 B は不正解です。データポータルでビジュアリゼーションへのアクセスを許可するだけでは、財務チームはデータを分析できません。
C: 選択肢 C は不正解です。財務チームは Google Cloud へのアクセス権が必要なことに加え、Cloud Storage の使用に関するトレーニングも必要となります。財務チームにとって Google Cloud はなじみのある方法ではありません。
D: 選択肢 D は正解です。コネクテッド シートにより、Google スプレッドシートを通じて BigQuery データを簡単に共有できます。
 
https://cloud.google.com/bigquery/docs/connected-sheets
 
https://cloud.google.com/bigquery/docs/writing-results#saving-query-results-to-sheets
 
https://www.youtube.com/watch?v=rkimIhnLKGI
</div></details>

### Q. 
あなたの暗号通貨取引会社では、価格を可視化してお客様の取引の意思決定をサポートしています。さまざまな取引がリアルタイムで行われるため、価格データは、処理に Dataflow を使用するデータ パイプラインに提供されます。移動平均を計算するにはどうすればよいですか。
1. 　Dataflow でホッピング ウィンドウを使用します。
2. Dataflow でセッション ウィンドウを使用します。
3. Dataflow でタンブリング ウィンドウを使用します。
4. Dataflow SQL を使用して、時間でグループ化された平均を計算します。
<details><div>
正解
1. 　Dataflow でホッピング ウィンドウを使用します。
フィードバック
A: 選択肢 A は正解です。ホッピング ウィンドウを使用して移動平均を計算できます。
B: 選択肢 B は不正解です。セッション ウィンドウは移動平均の計算には使用されません。
C: 選択肢 C は不正解です。タンブリング ウィンドウは移動平均の計算には使用されません。
D: 選択肢 D は不正解です。時間によるグループ化だけでは移動平均を計算できません。
 
https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines
</div></details>

### Q. 
あなたは、数百万人のトレーダーがいる証券取引所用の取引プラットフォームを構築しています。取引データは迅速に書き込まれます。あなたは、特定の株式の経時的な価格変動などのデータを迅速に取得して、可視化データをトレーダーに表示する必要があります。そのために Google Cloud のストレージ ソリューションを選択しなくてはなりません。どうすればよいですか。
1. 　Bigtable を使用します。
2. Firestore を使用します。
3. Cloud SQL を使用します。
4. Memorystore を使用します。
<details><div>
正解
1. 　Bigtable を使用します。
フィードバック
A: 選択肢 A は正解です。Bigtable は、高スループットの読み取りと書き込みを必要とする時系列データに推奨されるデータベースです。
B: 選択肢 B は不正解です。Firestore には、時系列データに最適な高スループット機能がありません。
C: 選択肢 C は不正解です。Cloud SQL には、時系列データに最適な高スループット機能がありません。
D: 選択肢 D は不正解です。Memorystore は高速インメモリ データベースで、大量のデータの永続的な保存には向いていません。
 
https://cloud.google.com/bigtable/docs/overview#what-its-good-for
</div></details>

### Q. 
あなたは BigQuery で作業するアナリスト チームのメンバーで、すでに SQL に精通しています。チームは、BigQuery のデータを使用する、マルチラベルの機械学習分類モデルを構築する必要があります。トレーニング データセットには 6,000 行のデータがあります。推論は 200 のラベルの可能性の内の一つとなると考えられます。高精度のモデルを作成するにはどうすればよいですか。
1. 　BigQuery ML を使用してモデルを作成します。
2. データを CSV ファイルにエクスポートします。TensorFlow を使用してモデルを構築します。
3. BigQuery のデータを AutoML に接続し、AutoML でモデルを構築します。
4. AI Notebooks を使用してデータに接続して、モデルをインタラクティブに構築します。
<details><div>
正解
3. BigQuery のデータを AutoML に接続し、AutoML でモデルを構築します。
フィードバック
A: 選択肢 A は不正解です。高精度のモデルを構築するには BigQuery ML は多くのデータを必要としますが、手元にあるデータは多くありません。
B: 選択肢 B は不正解です。TensorFlow でカスタムモデルを構築するには十分なデータがありません。
C: 選択肢 C は正解です。データ量が比較的少なく多様なため、このデータのみでは構築されたモデルの精度は低くなります。AutoML は他の類似データに基づく転移学習を使用するため、適切です。
D: 選択肢 D は不正解です。AI Notebooks でカスタムモデルを構築するには十分なデータがありません。
 
https://cloud.google.com/vertex-ai/docs/start/automl-model-types#tabular
</div></details>

### Q. 
機械学習モデルの構築に使用するデータセットがあります。そのデータセットはあなたにはなじみのないものですが、社内の他のユーザーはそれで作業しておりよく知っています。あなたは、ML モデルを反復的に構築しつつ、データを自身で確認したいと考えています。また、インタラクティブに協力してチーム環境で ML モデルを構築することも考えています。  どうすればよいですか。
1. 　Vertex AI Workbench ノートブックを使用して、ノートブックを同僚と共有します。
2. Google ドキュメントを使用して、ドキュメントを同僚と共有します。
3. BigQuery テーブルを使用して同僚にビューを提供します。
4. BigQuery を使用して、データを Looker で可視化します。ダッシュボードを同僚と共有します。
<details><div>
正解
1. 　Vertex AI Workbench ノートブックを使用して、ノートブックを同僚と共有します。
フィードバック
A: 選択肢 A は正解です。Vertex AI Workbench ノートブックでは、他のユーザーと協力して、インタラクティブかつ反復的に機械学習モデルを構築できます。
B: 選択肢 B は不正解です。Google ドキュメントはコラボレーション機能を提供しますが、他の ML モデル構築ツールと直接統合されていません。
C: 選択肢 C は不正解です。BigQuery ビューの共有ではデータが共有されるだけで、モデル構築作業の残りの部分はサイロ化された状態となります。
D: 選択肢 D は不正解です。データのビジュアリゼーションのみを共有するだけでは、目的の達成には不十分です。他の ML モデル構築機能も必要です。
 
https://cloud.google.com/vertex-ai-workbench
 
https://cloud.google.com/vertex-ai/docs/workbench/introduction
</div></details>

### Q. 
あなたの会社は Cloud SQL を 2 つのリージョンで実行しています。1 つ目のリージョンである us-central1 はエンドユーザーに近く、本番環境での使用頻度は多く、予測可能です。もう一つのリージョンである europe-west1 は開発チームに近く、使用は断続的です。労力、レイテンシ、パフォーマンス面で妥協することなく費用を削減するには、どうすればよいですか。
1. 　米国リージョンの確約利用割引（CUD）を利用します。開発チームの割り当て方法をそのまま保持します
2. 米国リージョンの確約利用割引（CUD）を利用します。開発チームの割り当てを米国リージョンに移動し、低い費用のメリットを利用します。
3. 希望する費用の削減の程度に応じて、VM に割り当てられている仮想 CPU の数を 1% 単位で減らします。
4. カスタムのより低コストの VM を Compute Engine にプロビジョニングして、必要に応じてデータベースをインストールします。
その他:
<details><div>
正解
1. 　米国リージョンの確約利用割引（CUD）を利用します。開発チームの割り当て方法をそのまま保持します
フィードバック
A: 選択肢 A は正解です。使用が予測可能な場合、Cloud SQL の確約利用割引を利用できます。
B: 選択肢 B は不正解です。すべてのシステムを米国に移動して確約利用割引を利用すると費用の面でメリットがありますが、レイテンシの面でデメリットがあります。
C: 選択肢 C は不正解です。vCPU を減らすとパフォーマンスが低下します。
D: 選択肢 D は不正解です。データベース管理のローリングは、労力が余計にかかります。
 
https://cloud.google.com/sql/cud
 
https://cloud.google.com/blog/products/databases/reduce-cloud-sql-costs-with-optimizations-by-active-assist/
</div></details>


## 9
### Q.質問6: 未回答
Pub/Sub トピックにパブリッシュされたアプリケーション イベントを効率的に処理して BigQuery に読み込み、大量のイベントのスケーラビリティを確保し、時間間隔で集約するにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. Pub/Sub トピックから継続的に読み取り、サンプリングウィンドウを使用して必要な集計を実行するストリーミングDataflowジョブを使用します
<details><div>
    答え：
説明
参照:https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines#tumbling-windows
</div></details>

### Q.質問7: 未回答
Pub/Sub の過去 5 秒分のデータを使用して、企業の株価の移動平均を 30 秒ごとに計算するには、DataFlow でウィンドウ パイプラインをどのように設定すればよいでしょうか?
1. 　
2. 
3. 
4. 期間が30秒、期間が5秒のスライディングウィンドウを使用し、AfterWatermark.pastEndOfWindow()のトリガーを使用して結果を出力します
<details><div>
    答え：
説明
次のウィンドウは、Apache Beam SDK または Dataflow SQL ストリーミング拡張機能で設定します。
ホッピング ウィンドウ (Apache Beam ではスライディング ウィンドウと呼ばれます) ホッピング ウィンドウは、データ ストリーム内の一貫した時間間隔を表します。
ホッピング ウィンドウは重なり合うことができますが、タンブリング ウィンドウはバラバラです。
たとえば、ホッピング ウィンドウは 30 秒ごとに開始され、1 分間のデータをキャプチャできます。ホッピング ウィンドウが開始する頻度は、期間と呼ばれます。この例では、1 分のウィンドウと 30 秒の期間があります。
参照:https://cloud.google.com/dataflow/docs/concepts/streaming-pipelines#hopping-windows
</div></details>

### Q.質問8: 未回答
大手不動産会社の従業員は、SQL と BigQuery ML を使用して機械学習用に 6 TB の住宅販売データを準備する必要があります。結果のモデルを生データセットに対する予測に使用する予定です。予測時のスキューを防ぐには、どのワークフローに従う必要がありますか?
1. BigQueryのTransform句を使用して、モデル作成時の前処理ステップを定義します。次に、予測時に、生の入力データに変換を指定せずにBigQueryのML.EVALUATE句を使用します
2. 
3. 
4. 
<details><div>
    答え：
説明
Aが答えです。https://cloud.google.com/bigquery-ml/docs/bigqueryml-transform
TRANSFORM 句を使用すると、モデル作成時にすべての前処理を指定できます。
前処理は、機械学習の予測フェーズと評価フェーズで自動的に適用されます
</div></details>

### Q.質問9: 未回答
サブスクライバーのコードを Pub/Sub フィードに更新し、デプロイ後に誤ったメッセージ確認によってメッセージが失われないようにする必要があります。次のオプションのうち、どれを選択する必要がありますか?
1. 　
2. 新しいサブスクライバー コードをデプロイする前に、Pub/Sub スナップショットを作成します。Seek 操作を使用して、スナップショットの作成後に使用可能になったメッセージを再配信します。
3. 
4. 
<details><div>
    答え：
説明
新しいサブスクライバー コードをデプロイする前に、Pub/Sub スナップショットを作成します。Seek 操作を使用して、スナップショットの作成後に使用可能になったメッセージを再配信します。
以下のリストの 2 番目の参照 (以下の 2 番目のリンクを参照) によると、新しいサブスクライバー コードをデプロイする際の懸念事項は、新しい実行可能ファイルが誤ってメッセージを確認し、メッセージの損失につながる可能性があることです。スナップショットをデプロイメント・プロセスに組み込むと、新しいサブスクライバー・コードのバグから回復できます。
タイムスタンプをシークするには、まず retain-acked-messages を使用して確認応答メッセージを保持するようにサブスクリプションを構成する必要があるため、回答を C にすることはできません。retain-acked-messages が設定されている場合、Pub/Sub は確認済みのメッセージを 7 日間保持します
参照：
https://cloud.google.com/pubsub/docs/replay-message
https://cloud.google.com/pubsub/docs/replay-overview#seek_use_cases
</div></details>

### Q.質問10: 未回答
BigQuery のテーブルには、複数の店舗で行われた購入に関する情報が含まれています。
最適なクエリパフォーマンスを得るには、最適なデータモデルを選択する必要があります。
このテーブルには、トランザクションの時間、購入したアイテム、店舗 ID、店舗が所在する市区町村や都道府県などの情報が含まれています。
多くの場合、クエリを実行して、過去 30 日間の各品目の売上を表示し、州、市区町村、および個々の店舗ごとの購入傾向を分析します。
クエリのパフォーマンスを最大にするために、このテーブルをどのようにモデル化しますか?
1. 　トランザクション時間でテーブルをパーティション分割し、都道府県、市区町村、店舗IDでクラスタ化します
2. 
3. 
4. 
<details><div>
    答え：
説明
トランザクション時間によるパーティション分割は、一般的なユースケースであるトランザクションの日付によるデータのフィルタリングに役立ちます。
都道府県、市区町村、店舗 ID でこの順序でクラスタリングすると、地理的な地域ごとにデータをグループ化し、効率的なフィルタリングと集約が可能になります。
このアプローチは、州、都市、店舗ごとの傾向を分析したり、地域ごとにどの製品がよく売れているかを特定したりするのにも役立ちます
したがって、パーティショニングは明らかです:クラスタリングはオプションAですでに言及されています。そのため、最高のパフォーマンスを実現するには、両方が必要です。
</div></details>

### Q.質問11: 未回答
金融機関は顧客がオンラインで登録することを許可しており、ユーザーデータは BigQuery に取り込まれる前に Pub/Sub に送信されます。ただし、セキュリティ上の理由から、顧客の政府発行の識別番号 (GIIN) を編集し、必要に応じてカスタマー サービス担当者が元の値を表示できるようにする必要があります。これを実現するには、どのオプションを選択する必要がありますか?
1. 　
2. BigQueryの列レベルのセキュリティを使用し、CustomerServiceユーザーグループのメンバーのみがGIIN列を表示できるようにテーブル権限を設定します
3. 
4. 
<details><div>
    答え：
説明
要件は、権限のある担当者がIDを表示できるようにすることですが、オプションDには明示的に言及されていません。
</div></details>

### Q.質問12: 未回答
同社は現在、Spark、Hive、HDFSを使用して大規模なオンプレミスクラスターを運用しており、コスト削減の恩恵を受け、インフラストラクチャを最新化するためにクラウドに移行することを計画しています。コロケーション施設との契約更新のタイミングにより、最初の移行には2か月しかありません。コスト削減を最大化し、移行を予定どおりに完了するには、どの移行戦略を採用すべきですか?
1. 　
2. ワークロードを Dataproc と Cloud Storage に移行する。後でモダナイズする：このオプションでは、モダナイズせずにワークロードをワークロードを Dataproc と Cloud Storage に移行し、あとで、モダナイズすることを提案します。
3. 
4. 
<details><div>
    答え：
説明
最適なアプローチは、ワークロードを Dataproc と Cloud Storage に移行することで、コストを削減しながら、後でワークロードをモダナイズできるようにすることです。また、このソリューションにより、移行が 2 か月以内に完了するようになります。
オプション A と C は最新化に対応しておらず、後回しにすることを提案しており、追加コストにつながる可能性があります。
オプション D は、2 か月の期間とワークロードをクラウドに移行する必要があることを考えると、野心的すぎる可能性があります。
</div></details>

### Q.質問14: 未回答
あなたは、北米で事業を展開する大手銀行の取引データの保存と管理を担当しています。ACIDコンプライアンスを確保し、データへのSQLアクセスを提供できるデータストレージソリューションが必要です。次のうち、適切なオプションはどれですか?
1. 　
2. Cloud Spanner を使用してトランザクションデータを保存し、読み取り・書き込みトランザクションのロックを利用する
3. 
4. 
<details><div>
    答え：
説明
このユースケースに適したソリューションは、Cloud Spanner を使用してトランザクション データを保存し、読み取り/書き込みトランザクションのロックを利用することです。Cloud Spanner はフルマネージドのリレーショナル データベースであり、NoSQL データベースのスケーラビリティとパフォーマンスの利点を提供すると同時に、ACID コンプライアンスとデータへの SQL アクセスも提供します。さらに、読み取り/書き込みトランザクションをロックすることで、一貫性が確保され、書き込み操作中のデータ破損から保護されます。
</div></details>

### Q.質問15: 未回答
BigQuery ML で線形回帰モデルを開発し、顧客が自社の商品を購入する可能性を予測しています。このモデルでは、主要な予測コンポーネントとして都市名が必要ですが、モデルをトレーニングして提供するために、データを列に整理する必要があります。データを準備する最も効率的な方法はどれですか?
1. 　
2. BigQuery の SQL を使用して、都道府県列にワンホット エンコーディングを適用し、各市区町村をバイナリ値列に変換する
3. 
4. 
<details><div>
    答え：
説明
都市名を主要な予測要素として BigQuery ML で線形回帰モデルのデータを準備する最も効率的な方法は、BigQuery の SQL を使用して都道府県列にワンホット エンコーディングを適用し、各市区町村をバイナリ値列に変換することです。
選択肢Bが正解です。ワンホット エンコードは、線形回帰モデルでカテゴリ変数を処理するための標準的な方法です。各都市のダミー変数を作成し、モデルが都市情報を予測変数として取り込むことを可能にします。
このアプローチは、オプション C や D に比べてコーディングが少なくて済み、実装も簡単です。
したがって、正解はオプション B: BigQuery で SQL を使用して one-hot エンコーディングを state 列に適用し、各都市をバイナリ値の列に変換することです
</div></details>

### Q.質問18: 未回答
何百万台ものコンピューターの時系列の CPU とメモリ使用量の 1 秒間隔のサンプルを保存し、リアルタイムのアドホック分析を可能にし、スケーラビリティを確保し、実行されるすべてのクエリに対して課金されないようにするのに最適なデータベースとデータ モデルは何ですか?
1. 　
2. 
3. ComputeEngine のコンピュータ識別子と各秒のサンプル時間を組み合わせた行キーを使用して、Bigtableで幅の狭いテーブルを作成します
4. 
<details><div>
    答え：
説明
何百万台ものパソコンの CPU とメモリの使用量を 1 秒間隔のサンプルで時系列で保存し、リアルタイムのアドホック分析とスケーラビリティを実現し、クエリを実行するたびに課金されないようにする最適なデータベースとデータモデルは、コンピューター エンジンのコンピューター識別子と各秒のサンプル時間を組み合わせた行キーを使用して、Bigtable で幅の狭いテーブルを作成することです。
このモデルでは、効率的かつ高速なデータ取得が保証され、クエリのパフォーマンスを低下させることなく大量のデータを処理できます。
BigQuery は時系列データの保存には適しておらず、BigQuery と Bigtable のワイド テーブル モデルは、効率的なクエリ パフォーマンスと将来のスケーラビリティには適していません。
参照:https://cloud.google.com/bigtable/docs/schema-design-time-series
</div></details>

### Q.質問22: 未回答
二項分類問題の既定のパラメーターを使用してサポート ベクター マシン (SVM) 分類器に学習させ、検証セットで曲線下面積 (AUC) 0.87 を達成しました。モデルの AUC を改善したい。どのオプションを選択する必要がありますか?
1. SVM分類器でハイパーパラメータ調整を実行する
2. 
3. 
4. 
<details><div>
    答え：
説明
ハイパーパラメーターの調整では、モデルのパラメーターを最適化してパフォーマンスを向上させます。SVMモデルはデフォルトのパラメータで学習されているため、改善の余地がある可能性があります。
ハイパーパラメーター調整を実行することで、SVM 分類器のパフォーマンスが向上し、AUC が高くなる可能性があります。
オプションBは、ディープニューラルネットワークのパフォーマンスがデータの性質と問題に依存するため、必ずしも当てはまるとは限りません。
オプション C は、モデルの実際のパフォーマンスがコンテキストによって大きく異なる可能性があるため、信頼できるアプローチではありません。
オプション D は、モデルのパフォーマンスを向上させるための一般的なアプローチではなく、二項分類の問題には適していない可能性があります。
</div></details>

### Q.質問27: 未回答
Google が推奨する方法に従い、費用、時間、労力を最小限に抑えながら、オンプレミスのデータセンターから Memorystore for Redis インスタンスに Redis データベースを移行するにはどうすればよいでしょうか。どのオプションが最適ですか?
1. RedisデータベースをRDBファイルとしてバックアップし、gsutilを使用してCloudStorageバケットにコピーし、そのファイルをMemorystoreforRedisインスタンスにインポートする
2. 
3. 
4. 
<details><div>
    答え：
説明
オプションAが最良の選択です。Redis データベースを Memorystore for Redis に移行する場合は、データベースの RDB バックアップを作成し、RDB ファイルを Cloud Storage にコピーしてから、Memorystore インスタンスにインポートすることをおすすめします。この方法は、迅速かつ簡単に実装でき、ダウンタイムも最小限に抑えられます。
オプション B は、Compute Engine インスタンス上に Redis データベースのセカンダリ インスタンスを作成し、ライブ カットオーバーを実行する必要があるため、推奨されません。この方法は複雑になる可能性があり、データの損失やダウンタイムの延長につながる可能性があります。
オプション C では、オンプレミスのデータセンターから Redis データベースを読み取り、そのデータを Memorystore for Redis インスタンスに書き込む Dataflow ジョブを作成します。この方法は複雑になる可能性があり、コストと時間が増加する可能性があります。
オプション D では、シェル スクリプトを記述して Redis データを移行し、新しい Memorystore for Redis インスタンスを作成します。この方法ではエラーが発生しやすく、データの損失やダウンタイムの延長につながる可能性があります。したがって、推奨されるアプローチではありません。
</div></details>

### Q.質問28: 未回答
Cloud Data Loss Prevention(Cloud DLP)と Google が推奨するサービス アカウントを使用しながら、銀行業界の政府規制で義務付けられ、会社のデータ保護基準で義務付けられている、顧客の個人を特定できる情報(PII)へのアクセスを制御するには、どのオプションに従う必要がありますか?
1. 必要なIAMロールをすべての従業員に割り当て、プロジェクトリソースにアクセスするための１つのサービスアカウントを作成します。
2. 
3. 
4. 
<details><div>
    答え：
説明
オプション A では、必要な Identity and Access Management (IAM) ロールをすべての従業員に割り当て、プロジェクト リソースにアクセスするための 1 つのサービス アカウントを作成することを提案します。このアプローチにより、アクセス制御をより一元的に管理でき、各従業員の特定のアクセスニーズに基づいてIAMロールを割り当てることができます
</div></details>

### Q.質問29: 未回答
大量の集計データを表示し、BigQuery とデータポータルを使用して多数の同時ユーザーがいることが予想される顧客向けダッシュボードを最適化して、最小限のレイテンシで迅速な可視化を実現するにはどうすればよいでしょうか。
1. BigQuery BI Engine とマテリアルズビューの併用
2. 
3. 
4. 
<details><div>
    答え：
説明
BigQuery BI Engine は、BigQuery 向けのフルマネージドのインメモリ分析サービスであり、ユーザーは大規模で複雑なデータセットを、秒未満のクエリ応答時間と高い同時実行性でインタラクティブに分析できます。
具体化されたビューと共に使用すると、一般的に使用される分析クエリのクエリ処理を高速化できます。マテリアライズドビューは、クエリの結果をテーブルに格納し、ビューがクエリされるたびに結果を再計算するのではなく、そのテーブルをクエリします。
これにより、特に大規模で複雑なクエリの場合、クエリの応答時間を大幅に短縮できます。
マテリアライズドビューで BigQuery BI Engine を使用することは、大量の同時ユーザーを含む大量の集計データを表示する顧客向けダッシュボードのパフォーマンスを最適化するための推奨されるアプローチです。
</div></details>

### Q.質問30: 未回答
オープンソース ツールと Google Kubernetes Engine(GKE)を使用してワークフロー パイプラインのスケジューリングを実装する必要があります。タスクを簡素化して自動化するには、共有 VPC のネットワークに関する考慮事項にも対応する Google マネージド サービスを使用します。どのオプションを選択する必要がありますか?
1. 　
2. 
3. 
4. 共有VPC構成でCloudComposerを使用し、サービスプロジェクトにCloudComposerリソースを配置する
<details><div>
    答え：
説明
Cloud Composer は、Apache Airflow 上に構築されたマネージド ワークフロー オーケストレーション サービスであり、ワークフローを作成、スケジュール、モニタリングできます。
BigQuery、Cloud Storage、Dataflow など、他の Google Cloud サービスと統合できます。共有 VPC ネットワークに関する考慮事項に対応するには、Cloud Composer リソースをサービス プロジェクトに配置する必要があります。
これは、共有 VPC セットアップでは、サービス プロジェクトには複数のプロジェクト間で共有されるリソースが含まれ、ホスト プロジェクトには共有 VPC 構成が含まれているためです。
Cloud Composer リソースをサービス プロジェクトに配置することで、ネットワーク構成を簡素化し、ワークフローがホスト プロジェクトで必要なリソースにアクセスできるようにすることができます。また、このアプローチにより、アクセス制御と監視を一元化できるため、セキュリティとコンプライアンスの維持に役立ちます
</div></details>

### Q.質問31: 未回答
障害発生時に人間の介入を最小限にとどめるACID準拠のデータベースシステムをどのように設計すればよいのでしょうか。以下から 1 つのオプションを選択します。
1. 　
2. 高可用性を有効にしてCloudSQLforPostgreSQLインスタンスを構成します
3. 
4. 
<details><div>
    答え：
説明
Cloud SQL for PostgreSQL インスタンスを高可用性で構成すると、別のゾーンのスタンバイ レプリカ インスタンスに自動的にフェイルオーバーされるため、障害発生時の人的介入が最小限に抑えられます。
また、このオプションにより、データベースが ACID に準拠していることも保証されます。
他のオプションでは自動フェールオーバーは提供されず、障害が発生した場合に人間の介入が必要になる場合があります。
オプションAは、高可用性のためのクロスゾーンレプリケーションを提供しません。
オプション C では自動フェールオーバーは提供されません。
オプションDはデータウェアハウスであるため、ACID準拠のデータベースではありません。
</div></details>

### Q.質問32: 未回答
組織には、オンプレミスのデータセンターの POSIX 準拠のソースに保存されている 15 TB のデータがあり、Google Cloud に転送する必要があります。データは毎週変更され、ネットワーク運用チームはパブリック インターネットに 500 Mbps の帯域幅を許可しています。Google が推奨する方法に従って、信頼性の高い週次データ転送を行う必要がある。あなたは何をするべきか?
1. 　
2. 
3. Storage Transfer Service エージェントをオンプレミスのデータセンターにインストールし、毎週の転送ジョブを構成します
4. 
<details><div>
    答え：
説明
Storage Transfer Service エージェント (データ センター内のオンプレミス データ用) をインストールし、毎週の転送ジョブを構成します。Storage Transfer Service は、オンプレミスのデータセンターから Google Cloud への大量のデータの転送を処理できる、フルマネージドで費用対効果の高いサービスです。
毎週の転送ジョブを構成する機能により、限られた帯域幅ネットワークを介して大量のデータを定期的に転送するための信頼性の高い自動化されたソリューションを提供します
パフォーマンスを向上させるためにオンプレミスにエージェントをインストールする理由。
参照:https://cloud.google.com/storage-transfer/docs/managing-on-prem-agents#file_system_transfer_details
参照:https://cloud.google.com/storage-transfer/docs/managing-on-prem-agents
</div></details>

### Q.質問33: 未回答
10 TB を超えるデータを含むデータベースから医療情報の大規模な結果セットを取得し、さらにクエリを実行するために新しいテーブルに格納するには、費用対効果の高いソリューションを見つける必要があります。データベースは、メンテナンスの少ないアーキテクチャを持ち、SQL経由でアクセスできる必要があります。どのオプションを選択する必要がありますか?
1. 　
2. BigQueryをデータウェアハウスとして使用し、大きなクエリをキャッシュするための出力先を設定する
3. 
4. 
<details><div>
    答え：
説明
医療情報の大規模な結果セットを取得したい企業にとって、BigQuery のようなデータ ウェアハウス ソリューションは理想的です。
BigQuery は、大量のデータを迅速かつ費用対効果の高い方法で保存およびクエリできる、フルマネージドのサーバーレス データ ウェアハウスです。また、データへのSQLベースの容易なアクセスを提供し、アナリストやデータサイエンティストがデータにアクセスできるようにします。大きなクエリをキャッシュするための出力先を設定すると、クエリの繰り返しを回避することで、パフォーマンスの向上とコストの削減にも役立ちます。
オプション A(Cloud SQL を使用)は、このような大規模なデータベースには適していない可能性があります。
オプションC(MySQLクラスタを使用)では、より多くのメンテナンスと管理が必要です。
オプション D(Cloud Spanner を使用)は、このような大規模なデータセットでは費用対効果が高くないため、高いスケーラビリティと強力な整合性が重要な要件でない限り、必要ない場合があります
</div></details>

### Q.質問34: 未回答
Google Cloud でオンライン証券会社の大量の取引処理アーキテクチャの安全なキューイング システムを作成し、リソース使用量を最小限に抑えながら、ジョブがトリガーされ、会社の Python API を介して実行されるようにするにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
Pub/Sub プッシュ サブスクリプションを実装して、Python API にデータを渡す Cloud Functions の関数をトリガーします。このオプションを使用すると、ジョブをトリガーする安全で効率的なキューイング システムが可能になり、Pub/Sub プッシュ サブスクリプションがトリガーとして機能します。
その後、Cloud Functions の関数はデータを Python API に渡して取引を実行できます。
このアプローチにより、Compute Engine インスタンスでアプリケーションを作成してホストする必要がなくなり、複雑さとコストが増す可能性のある NoSQL データベースを使用する必要がなくなります。
また、Cloud Composer を使用して Pub/Sub トピックをサブスクライブすることは、主に複雑なワークフローの管理に使用されるツールであるため、このシナリオではやり過ぎかもしれません。
</div></details>

### Q.質問39: 未回答
お客様は、転送時間を最小限に抑え、安全な接続のために Google が推奨するベスト プラクティスに従うことを目標に、オンプレミスのデータセンターから Google Cloud に 1 PB のデータを移行する任務を負っています。どのオプションを選択する必要がありますか?
1. Storage Transfer Service は、オンプレミスのデータセンターとGoogleCloudの間にCloudInterconnect接続を確立した後に使用します
2. 
3. 
4. 
<details><div>
    答え：
説明
大量のデータ(1 PB)を数時間で転送するには、パブリック インターネットを使用するよりも高い帯域幅と低遅延を提供できる Cloud Interconnect などの専用ネットワーク接続を使用することをお勧めします。
Storage Transfer Service は、オンプレミスとクラウドストレージ間でデータを転送するために使用でき、Cloud Interconnect をサポートします。このアプローチにより、データ転送が高速、安全、かつ信頼性の高いものになります。
Transfer Appliance を使用するオプション B では、データを手動で処理する必要があり、時間がかかる場合があります。
gcloud compute scp ジョブを使用するオプション C も、時間がかかり、信頼性が低くなる可能性があります。
オプション D では、データを小さなバッチに減らすと、移行プロセスの複雑さが増し、数時間以内にデータを転送するという要件を満たせない可能性があります
</div></details>

### Q.質問40: 未回答
現在、アジアの 1 つの地域の顧客にサービスを提供する Web アプリケーションを実行しています。サービスをグローバルに展開する計画を立てているが、当初はコストを最適化したい。資金を確保したら、ネイティブのJDBCドライバを使用して、グローバルなプレゼンスとパフォーマンスを最適化することを計画しています。どのオプションを選択する必要がありますか?
1. 最初にCloudSpannerの単一リージョンインスタンスを構成し、資金を確保した後に複数リージョンのCloudSpannerインスタンスを構成します
2. 
3. 
4. 
<details><div>
    答え：
説明
このシナリオでは、最初に 1 つのリージョン インスタンスで Cloud Spanner を使用し、資金を確保した後に複数リージョンの Cloud Spanner インスタンスを構成するのが最も費用対効果が高くスケーラブルなオプションです。
Cloud Spanner は、強力な一貫性とスケーラビリティを備えたグローバル分散型リレーショナル データベースです。
単一リージョンのインスタンスから開始し、資金を確保した後に複数リージョンのインスタンスに移行すると、短期的にはコストを最適化しながら、長期的にはグローバルなプレゼンスとパフォーマンスが可能になります。
ネイティブの JDBC ドライバを使用することは、Cloud Spanner でも可能です
</div></details>

### Q.質問41: 未回答
顧客の Google Cloud コンピューティング リソースの正味消費量と、そのリソースを使用したユーザーを示す日次レポートを迅速かつ効率的に生成する必要があります。あなたは何をするべきか?
1. CloudLoggingのデータをBigQueryに毎日エクスポートし、プロジェクト、ログタイプ、リソース、ユーザーでフィルタリングするビューを作成します
2. 
3. 
4. 
<details><div>
    答え：
説明
お客様の Google Cloud コンピューティング リソースの正味消費量とリソースを使用したユーザーを示す日次レポートを生成する最善の方法は、Cloud Logging データを BigQuery に毎日エクスポートし、プロジェクト、ログタイプ、リソース、ユーザーでフィルタリングされたビューを作成することです。
このアプローチでは、データがすでに BigQuery に保存されており、顧客のレポート固有の要件を満たすために簡単にクエリやフィルタリングを行うことができるため、レポートを迅速かつ効率的に生成できます。
さらに、このアプローチにより、Cloud Scheduler や Cloud Functions などのツールを使用して、レポート生成プロセスを簡単に自動化できます。
</div></details>

### Q.質問42: 未回答
Dataflow でバッチ ジョブを開始し、いくつかの要素を処理した後、突然失敗してシャットダウンしました。Dataflow モニタリング インターフェースを調査し、パイプライン内の特定の DoFn に関連するエラーを見つけます。これらのエラーの原因として最も可能性の高いものは次のうちどれですか?
1. 　
2. ワーカーコードのエラー
3. 
4. 
<details><div>
    答え：
説明
いくつかの要素を処理した後、失敗した Dataflow バッチ ジョブの特定の DoFn に関連するエラーの原因として最も可能性が高いのは、
B: ワーカー コードのエラー/例外。
これは、DoFn に記述されたコードに問題があり、例外がスローされて失敗する原因になっていることを意味します。
入力/出力の型が正しくないか、null ポインター例外、またはその他のコーディング エラーが原因である可能性があります。
Dataflow モニタリング インターフェースのエラー メッセージには、エラーの具体的な原因に関する詳細情報が記載されており、問題のデバッグに役立ちます
</div></details>

### Q.質問43: 未回答
BigQuery のストリーミング API を使用するレポート専用データ ウェアハウスで、ステージング テーブルと本番テーブルの両方を使用してデータの読み込みを設計し、マスター データセットを 1 つだけにし、取り込みやレポートのパフォーマンスに影響を与えないようにする最善の方法は何ですか?
1. 　
2. 
3. ステージングされたデータを運用テーブルに移動し、ステージングテーブルの内容を3時間ごとに削除します
4. 
<details><div>
    答え：
説明
最適なアプローチは、ステージングされたデータを運用テーブルに移動し、ステージング テーブルの内容を 3 時間ごとに削除することです (オプション C)。
参照:https://cloud.google.com/blog/products/data-analytics/moving-a-publishing-workflow-to-bigquery-for-new-data-insights
</div></details>

### Q.質問44: 未回答
データ ウェアハウスを Google Cloud に移行し、トランザクション システムからウェアハウスをリアルタイムで更新するためのツールをお勧めできますか?転送されるファイルの数は多くありませんが、各ファイルのサイズは 90 GB です
1. 　
2. 
3. 移行にはgsutilを使用します。Pub/SubとDataflowによるリアルタイム更新
4. 
<details><div>
    答え：
説明
gsutil ツールは、プライベート データセンターから Google Cloud への一般的なエンタープライズ規模のネットワークを介した中小規模の転送(1 TB 未満)のための標準ツールです。
Gsutil は、1 TB 未満のデータについてプロジェクトの期限に間に合うだけの十分な帯域幅がある場合に使用します。
Storage Transfer Service は、移行用のはるかに大きなボリューム用です。
さらに、Cloud Data Fusion と Dataproc はリアルタイムの更新には適していません。BigQuery Data Transfer Service は、すべてのオンプレミス ソースをサポートしているわけではありません。
https://cloud.google.com/architecture/migration-to-google-cloud-transferring-your-large-datasets#gsutil_for_smaller_transfers_of_on-premises_data
</div></details>

### Q.質問45: 未回答
データ ポイントを受信して GUID を返すサービスを使用して、新しい Web サイト ユーザー向けにグローバル一意識別子 (GUID) を生成するパイプラインを設計する最も効果的な方法は何ですか?パイプラインは、毎秒数万件のメッセージを処理し、システムへのバックプレッシャーを最小限に抑えるためにマルチスレッドにする必要があります。
1. 　
2. 
3. 
4. ジョブを10秒単位でバッチ処理します
<details><div>
    答え：
説明
たとえば、定常状態で毎秒数万件のメッセージを処理するパイプラインを想像してみてください。
要素ごとにコールアウトを行った場合、システムは毎秒同じ数の API 呼び出しを処理する必要があります。
また、呼び出しに平均 1 秒かかると、パイプラインに大きなバックプレッシャーがかかります。
このような状況では、代わりにこれらの要求のバッチ処理を検討する必要があります。
参照:https://cloud.google.com/blog/products/data-analytics/guide-to-common-cloud-dataflow-use-case-patterns-part-1
</div></details>

### Q.質問46: 未回答
図書館の本や各書籍に関する情報(著者や出版年など)を追跡するアプリケーションをオンプレミスのデータ ウェアハウスから BigQuery に移行する場合、Google が推奨するスキーマ設計のプラクティスに従いながら、借りた各書籍の著者に関するクエリの速度を最適化するには、データをどのように構成すればよいでしょうか。
1. 　
2. 
3. 書籍と著者に関する情報を含むテーブルを作成しますが、著者フィールドは著者列内に入れ子にします
4. 
<details><div>
    答え：
説明
ベスト プラクティス: 入れ子になったフィールドと繰り返しフィールドを使用して、データ ストレージを非正規化し、クエリのパフォーマンスを向上させます。非正規化は、以前に正規化されたリレーショナル データセットの読み取りパフォーマンスを向上させるための一般的な戦略です。
BigQuery でデータを非正規化するには、ネストされたフィールドと繰り返しフィールドを使用することをおすすめします。
この戦略は、リレーションシップが階層的であり、親子関係など、頻繁に一緒にクエリを実行する場合に使用するのが最適です。
参照:https://cloud.google.com/bigquery/docs/best-practices-performance-nested
</div></details>

### Q.質問47: 未回答
Cloud Data Loss Prevention API(DLP API)を使用して、参照整合性を維持しながらリアルタイム ストリーミング ファイルの PII データをマスクするには、どうすればよいでしょうか。
1. 　
2. 
3. 
4. PIIデータを暗号化形式保持トークンに置き換えてかなを作成し、参照整合性を維持します
<details><div>
    答え：
説明
PII データをマスキングしながら参照整合性を維持するために、暗号化形式保持トークンを使用して機密情報を置き換えることができます。この方法では、同じキー値を使用してデータを結合しながら、機密データを権限のない個人から隠すことができます
</div></details>

### Q.質問48: 未回答
圧縮された gzip テキスト ファイルを取り込んで変換し、SideInputs を使用してデータを結合し、配信不能キューにエラーを書き込む Dataflow パイプラインを高速化するにはどうすればよいでしょうか。
1. 　
2. 
3. 
4. パフォーマンスを向上させるには、SideInput をCoGropuByKeyに置き換えます
<details><div>
    答え：
説明
CoGroupByKey トランスフォームは、複数の PCollection オブジェクトをマージ(フラット化)し、共通のキーを持つエレメントをグループ化するコア ビーム トランスフォームです。
サイド入力データ全体を各ワーカーが使用できるようにするサイド入力とは異なり、CoGroupByKey はシャッフル (グループ化) 操作を実行してワーカー間でデータを分散します。
したがって、CoGroupByKey は、結合する PCollection オブジェクトが非常に大きく、ワーカー メモリに収まらない場合に最適です。
CoGroupByKey は、ワーカー メモリを大幅に超える PCollection オブジェクトの大部分をフェッチする必要がある場合に使用します
参照:https://cloud.google.com/architecture/building-production-ready-data-pipelines-using-dataflow-developing-and-testing#choose_correctly_between_side_inputs_or_cogroupbykey_for_joins
</div></details>

### Q.質問49: 未回答
組織は、Google Cloud で構造化データを処理するためのバッチ パイプラインの最適化を検討しています。現在、データ変換に PySpark を使用していますが、パイプラインの実行に 12 時間以上かかっています。開発とパイプラインの実行時間を短縮するために、SQL 構文をサポートできるサーバーレス ソリューションが必要です。生データはすでに Cloud Storage に保存されています。パフォーマンスと処理の要件を満たしながら Google Cloud でパイプラインを構築するには、どのアプローチを取るべきか
1. 　
2. 
3. CloudStorageからBigQueryにデータを取り込み、PySparkコマンドをBigQuerySQLクエリに変換してデータを変換し、その変換を新しいテーブルに書き込みます
4. 
<details><div>
    答え：
説明
BigQuery は、パフォーマンスと処理の要件を満たすオプションです。
参照:https://medium.com/paypal-tech/comparing-bigquery-processing-and-spark-dataproc-4c90c10e31ac
</div></details>

### Q.質問50: 未回答
5 年分のログデータを Cloud Storage にアップロードしました。ユーザーから、ログデータ内の一部のデータポイントが想定範囲外であり、エラーを示していると報告されました。この問題を修正し、コンプライアンス上の理由から元のデータが保持されるようにする必要があります。あなたは何をするべきか?
1. 　
2. 
3. Dataflowワークフローを使用して、CloudStorageからデータを読み取り、想定される範囲外の値を特定して修正し、更新されたデータをCloudstorageの新しいデータセットに書き込みます
4. 
<details><div>
    答え：
説明
コンプライアンス上の理由から元のデータを保持したままこの問題を解決する最善の方法は、Cloud Storage からデータを読み取り、想定される範囲外の値を特定して修正し、更新されたデータを Cloud Storage の新しいデータセットに書き込む Dataflow ワークフローを使用することです。このアプローチにより、元のデータは保持され、修正されたデータは別々に保存されます。
オプションAは、エラーのある行が削除され、元のデータが失われるため、適切な解決策ではありません。
オプション B は、データが重複し、ストレージ コストが増加するため、お勧めしません。
オプションDは、元のデータセットを上書きすると元のデータが失われることを意味するため、コンプライアンス上の理由から理想的ではないため、適切なアプローチではありません
</div></details>

## 10
 ### Q. 質問7: 未回答
複数のユーザーがいる BigQuery データ ウェアハウスで、各チームがチーム メンバーシップに基づいて特定のテーブルのみを表示する場合、ユーザー権限をどのように管理すればよいですか?
1. 　
2. 
3. 
4. 各チーム用に作成されたデータセットで、各チームの承認されたビューを作成します。データが存在するデータセットの承認済ビューへのデータ閲覧者アクセス権を付与し、ユーザー・グループに対して承認済ビューが存在するデータセットへのデータ閲覧者アクセス権を付与します
<details><div>
    答え：
説明
要件オプションAを達成した場合、私の見解は、オプションDはオプションAよりも絶対確実な方法です。
参照:https://cloud.google.com/bigquery/docs/authorized-views
</div></details>

 ### Q. 質問10: 未回答
ORC データ形式とプライマリ ツールとして Hive を使用するオンプレミスの Hadoop システムを Cloud Dataproc に移行します。すべての ORC ファイルを Cloud Storage バケットに正常にコピーしたので、パフォーマンスを向上させるために、一部のデータをクラスタのローカルの Hadoop Distributed File System(HDFS)に複製する必要があります。
Cloud Dataproc で Hive を使い始めるには、次の 2 つの方法のうちどれですか?2つ選択してください
1. 　
2. 
3. gsutilを使用して、すべてのORCファイルをCloudStorageバケットからDataprocクラスタのマスターノードに転送し、Hadoopを実行してHDFSにコピーし、HDFSからHiveテーブルをマウントします
4. CloudStorageConnectorforHadoopを使用して、ORCファイルを外部Hiveテーブルとしてマウントし、外部HiveテーブルをネイティブHiveテーブルにレプリケートします
<details><div>
    答え：
説明
オプションCは有効な解決策ですが、ファイルを手動でHDFSにコピーするなど、回避できる追加の手順が必要です。
オプション D は、Cloud Storage Connector for Hadoop を利用して ORC ファイルを外部 Hive テーブルとしてマウントし、外部 Hive テーブルをネイティブ Hive テーブルに複製して、効率的なデータ アクセスとレプリケーションを可能にするため、有効なソリューションです。
オプションAは、すべてのORCファイルをHDFSにコピーすることを提案しているため、最も効率的なソリューションではない可能性があるため、正しくありません。また、Hive テーブルをローカルにマウントすることは、Dataproc の分散性を活かさないため、最適な選択肢ではない可能性があります。
オプション B は、すべての ORC ファイルをクラスター内の任意のノードにコピーすると、データ スキューやネットワークの輻輳が発生する可能性があるため、理想的ではありません。また、HDFSにデータをレプリケートする方法についても説明していません。
オプション E は BigQuery に ORC ファイルを読み込むため、この問題の直接的な解決策にはなりませんが、このユースケースでは望ましいデータ ストレージ ソリューションではない可能性があります。
</div></details>

 ### Q. 質問11: 未回答
サードパーティから受け取った毎月のCSVデータファイルのスキーマが3か月ごとに変更される場合、どのようにクレンジングできますか?これらの変換を実装するための要件には、開発者以外のアナリストが変換を変更できるようにすること、変換を設計するためのグラフィカル ツールを提供すること、およびスケジュールに従って変換を実行することが含まれます
1. DataprepbyTrifactaを使用して、変換レシピを構築および管理し、スケジュールに基づいて実行します
2. 
3. 
4. 
<details><div>
    答え：
説明
Dataprep by Trifacta を使用して、変換レシピを構築および管理し、スケジュールに基づいて実行します。
Dataprep by Trifacta は、変換を設計するためのグラフィカル ツールを提供し、開発者以外のアナリストが変換を変更できるようにします。また、スケジュールに従って変換を実行することもできます
</div></details>

 ### Q. 質問23: 未回答
データ サイエンティストが BigQuery ML モデルを作成し、REST API アプリケーションに予測を提供する ML パイプラインを構築したいと考えています。APIは、100ミリ秒未満のレイテンシーで個々のユーザーIDの予測を提供する必要があります。次のクエリは、予測を生成します: SELECT predicted_label、user_id FROM ML.PREDICT (MODEL 'dataset.model', table user_features)。ML パイプラインを構築するには、どのアプローチを取る必要がありますか?
1. クエリに WHERE 句を追加してユーザー ID で結果をフィルタリングし、アプリケーション サービス アカウントに BigQuery データ閲覧者ロールを付与する
2. 
3. 
4. 
<details><div>
    答え：
説明
正しいアプローチは、クエリに WHERE 句を追加してユーザー ID で結果をフィルタリングし、アプリケーション サービス アカウントに BigQuery データ閲覧者ロールを付与することです。このアプローチにより、REST API アプリケーションは必要な予測のみを受信し、待機時間の要件を満たすことができます。
その他のオプションは、次の理由で無効です。
B. 指定されたクエリを使用して承認済みビューを作成し、そのビューを含むデータセットをアプリケーション サービス アカウントと共有することは、ビューへのアクセスのオーバーヘッドにより待機時間が 100 ミリ秒を超える可能性があるため、最適なソリューションではありません。
C. BigQueryIO を使用して Dataflow パイプラインを作成し、クエリから結果を読み取り、Dataflow Worker ロールをアプリケーション サービス アカウントに付与する場合は、クエリ結果を操作または変換する必要がないため、必要ありません。
D. BigQueryIO を使用して Dataflow パイプラインを作成し、クエリからすべてのユーザーの予測を読み取り、BigtableIO を使用して結果を Bigtable に書き込み、アプリケーション サービス アカウントに Bigtable 閲覧者ロールを付与することは、個々のユーザーの予測を Bigtable に保存する必要がなく、この方法では不要なレイテンシが追加される可能性があるため、必要ありません。
</div></details>

 ### Q. 質問34: 未回答
お客様は、Cloud Datastore を使用して車両のテレメトリ データをリアルタイムで取り込むストレージ システムを構築すると同時に、システムが長期的なデータ増加に対応し、費用対効果が高いことを確認する必要があります。さらに、データのスナップショットを定期的に作成して、ポイントインタイムリカバリやデータのコピーを別の環境に複製できるようにする必要があります。これらのスナップショットを長期間アーカイブする場合。これを実現できる2つの方法はどれですか?次のオプションから 2 つ選択します。
1. マネージドエクスポートを使用してCloudDatastoreからデータをエクスポートし、NearlineまたはColdlineストレージクラスのCloudStorageバケットに保存します
2. マネージドエクスポートを使用してCloudDatastoreからデータをエクスポートし、エクスポート用に予約された一意の名前空間の下にある別のプロジェクトのCloudDatastoreにインポートする
3. 
4. 
<details><div>
    答え：
説明
費用を低く抑えながら、Cloud Datastore を使用して車両のテレメトリ データをリアルタイムで取り込み、アーカイブし、ポイントインタイム リカバリやクローン作成のための定期的なスナップショットを作成できる 2 つの方法は、A と B です
</div></details>

 ### Q. 質問38: 未回答
オンプレミスのデータウェアハウス ソリューションを BigQuery に移行して CDC のパフォーマンスを最適化し、コンピューティングのオーバーヘッドを削減しながら、ソース システムへの変更を BigQuery レポートの表でほぼリアルタイムで利用できるようにするための 2 つの推奨手順は何ですか?(2つ選択してください。
1. 　
2. 新しい各CDCレコードとそれに対応する操作の種類をステージングテーブルにリアルタイムで挿入する
3. 
4. DML MERGE を定期的に使用して、レポートテーブルで複数のDML INSERT,UPDATE,DELETE操作を同時に実行します
<details><div>
    答え：
説明
差分テーブルには、初期読み込み以降の特定のテーブルのすべての変更イベントが含まれます。すべての変更イベントを使用可能にしておくと、傾向、特定の瞬間にテーブルが表すエンティティの状態、または変更頻度を特定するのに役立ちます。
データを頻繁かつ一貫してマージする最善の方法は、複数の INSERT、UPDATE、および DELETE ステートメントを 1 つのアトミック操作に結合できる MERGE ステートメントを使用することです
参照:https://cloud.google.com/architecture/database-replication-to-bigquery-using-change-data-capture#overview_of_cdc_data_replication
</div></details>

 ### Q. 質問39: 未回答
BigQuery データセットを費用対効果の高い方法でサードパーティ企業と共有しながら、データを常に最新の状態に保つにはどうすればよいでしょうか。次のオプションを検討してください。
1. AnalyticsHubでデータアクセスを制御し、データアクセスを監視および監査しながら、サードパーティ企業に元のデータセットへのアクセス権を付与します
2. 
3. 
4. 
<details><div>
    答え：
説明
Analytics Hub では、BigQuery の特定のデータセット、ビュー、テーブルに対するアクセス ポリシーと権限を定義できます。
これにより、特定のユーザーまたはグループへのアクセスを制限し、IPアドレスやユーザーIDなどの要因に基づいてきめ細かなアクセス制御を設定できます。
Analytics Hub を使用することで、サードパーティ企業が必要な特定のデータにのみアクセスできるようにし、データアクセスを監視および監査して、規制やセキュリティのベストプラクティスへのコンプライアンスを維持することもできます。
参照:https://cloud.google.com/bigquery/docs/analytics-hub-introduction
</div></details>

 ### Q. 質問46: 未回答
Google Cloud Platform で 3 つのデータ処理ジョブを作成しました。1 つのジョブは、Cloud Storage にアップロードされたデータを変換し、その結果を BigQuery に書き込みます。2 つ目のジョブは、オンプレミス サーバーからデータを取り込み、Cloud Storage にアップロードします。3 番目のジョブは、サードパーティのデータプロバイダから情報を取得し、Cloud Storage にアップロードします。これら 3 つのワークフローの実行をスケジュールして監視し、必要に応じて手動で実行できる必要があります。どのオプションを選択する必要がありますか?
1. CloudComposerで直接費巡回グラフを作成し、ジョブをスケジュールしてモニタリングします
2. 
3. 
4. 
<details><div>
    答え：
説明
オプション A は、ワークフローの自動化と管理のためのプラットフォームを提供する Cloud Composer で DAG(Direct Acyclic Graph)を作成できるため、有効な選択肢です。これにより、ワークフローの実行をスケジュールおよび監視し、必要に応じて手動で実行できます。このオプションは、3 つのワークフローを管理する方法を提供するため、特定のシナリオに適しています。
Stackdriver Monitoring は GCP 上のアプリケーションやインフラストラクチャの健全性とパフォーマンスをモニタリングできますが、ワークフローの自動化や管理用には設計されていないため、オプション B は最適な選択ではありません。
ワークフローのスケジュール設定とモニタリングのための App Engine アプリケーションの開発は最も簡単なソリューションではないため、オプション C は最適な選択ではありません。これには多大な開発作業が必要であり、リソースの最適な使用ではない可能性があります。
Compute Engine インスタンスで cron ジョブを設定すると、管理に多大な労力がかかり、最も効率的なソリューションではない可能性があるため、オプション D は最適な選択ではありません。また、ワークフローを監視する機能も提供されません。
全体として、オプションAは、GCPでワークフローをスケジュールおよび監視するための効率的で簡単なソリューションを提供するため、最良の選択です
</div></details>

## 11
 ### Q. 質問2: 未回答
BigQuery データ ウェアハウスのメイン インベントリ テーブルを読み取るほぼリアルタイムのインベントリ ダッシュボードを作成する必要があります。履歴在庫データは、品目および場所ごとの在庫残高として保存され、毎時数千件の在庫更新があります。目標は、データが正確であり、ダッシュボードのパフォーマンスが最大であることを確認することです。次のオプションのうち、どれを選択する必要がありますか?
1. 　
2. 
3. BigQuery ストリーミングを使用して、日次在庫移動テーブルに変更をストリーミングします。履歴在庫残高テーブルに結合するビューで残高を計算します。在庫残高表を毎晩更新します。
4. 
<details><div>
    答え：
説明
最大限のパフォーマンスと正確なデータを備えたほぼリアルタイムの在庫ダッシュボードを作成するのに最適なオプションは、オプション C: BigQuery ストリーミングを使用して、毎日の在庫移動テーブルに変更をストリーミングすることです。履歴在庫残高テーブルに結合するビューで残高を計算します。在庫残高表を毎晩更新します。
オプション A は、BigQuery の UPDATE ステートメントを使用して在庫残高の変化を更新することを提案していますが、特に 1 時間ごとに数千件の在庫更新が発生する場合に、クエリのパフォーマンスが低下する可能性があるため、推奨されません。
オプション B は、在庫残高テーブルを項目ごとにパーティション分割して、インベントリ更新のたびにスキャンされるデータの量を減らすことを提案しており、一部のクエリのパフォーマンスは向上する可能性がありますが、ほぼリアルタイムの更新と正確なデータの必要性には対応していません。
オプション D では、BigQuery 一括ローダーを使用して在庫の変更を日次在庫移動表に一括読み込みし、過去の在庫残高表に結合するビューで残高を計算し、在庫残高表を夜間に更新することを提案しています。このオプションでは、バッチ読み込みと夜間の更新が含まれるため、リアルタイム分析のための最新情報が提供されない場合があります。
したがって、オプション C は、変更を日次在庫移動テーブルにストリーミングし、履歴在庫残高テーブルに結合するビューで残高を計算し、在庫残高テーブルを毎晩更新するため、最適なソリューションです。このアプローチにより、ダッシュボードはクエリのパフォーマンスを維持しながら、最新かつ正確なデータにアクセスできます。
</div></details>

 ### Q. 質問10: 未回答
あなたは、Cloud Pub/Sub のデータを BigQuery の静的参照データで強化する Apache Beam パイプラインを設計する任務を負っています。参照データは、1 つのワーカーのメモリに格納できます。結果のデータは、さらに分析するために BigQuery に書き込まれます。このパイプラインにはどのジョブの種類と変換を使用する必要がありますか?
1. 　
2. 
3. Pub/Subを使用してデータをストリーミングし、BigQueryを使用して参照データでデータをエンリッチするストリーミングジョブ。再度インプットは、参照データを１つのワーカーのメモリに保存するために使用され、エンリッチメントされたデータは分析のためにBigQueryに書き込みまれます
4. 
<details><div>
    答え：
説明
このシナリオでは、データがリアルタイムで強化されるため、ストリーミング ジョブが必要です。PubSubIO 変換は Cloud Pub/Sub からのデータのストリーミングに使用され、BigQueryIO は BigQuery からの参照データでデータをエンリッチするために使用されます。小さな参照データは、サイドインプットを使用して 1 つのワーカーのメモリに保存し、エンリッチメントされたデータを BigQuery に書き込んで BigQueryIO を使用して分析することができます
ストリーミング分析アプリケーションでは、多くの場合、データは、さらなる分析に役立つ可能性のある追加情報で強化されます。たとえば、トランザクションの店舗 ID がある場合、店舗の場所に関する情報を追加できます。この追加情報は、多くの場合、要素を取得し、ルックアップ テーブルから情報を取り込むことによって追加されます。
参照:https://cloud.google.com/dataflow/docs/tutorials/ecommerce-java#side-input-pattern
</div></details>

 ### Q. 質問11: 未回答
Google Cloud Bigtable を、読み取り操作と書き込み操作が混在する高負荷のリアルタイム アプリケーションに使用しているとします。最近、データベース全体の特定の統計を計算するために、時間単位の分析ジョブを実行する必要がある新しいユース ケースを特定しました。主な優先事項は、本番アプリケーションの信頼性を確保しながら、分析ワークロードを正常に実行することです。あなたならどのオプションを選びますか?
1. 　
2. 
3. 
4. 単一クラスタルーティングを使用して既存のインスタンスに２番目のクラスタを追加します。通常のワークロードを処理するバッチ分析プロファイルを構成します
<details><div>
    答え：
説明
読み取りと書き込みの組み合わせを実行するアプリケーションと並行して、多数の大規模な読み取りを実行するバッチ分析ジョブを 1 つのクラスターを使用して実行すると、大規模なバッチ ジョブによってアプリケーションのユーザーの処理が遅くなる可能性があります。
レプリケーションを使用すると、単一クラスター ルーティングでアプリ プロファイルを使用して、バッチ分析ジョブとアプリケーション トラフィックを異なるクラスターにルーティングできるため、バッチ ジョブがアプリケーションのユーザーに影響を与えないようにすることができます。
参照:https://cloud.google.com/bigtable/docs/replication-overview#use-cases
</div></details>

 ### Q. 質問24: 未回答
組織がユーザーレベルのテーブルを含む Google BigQuery データセットの集計データを他の Google Cloud プロジェクトと共有しながら、元のユーザーレベルのデータへのアクセスを制御し、他のプロジェクトのストレージと分析のコストを最小限に抑えるには、どのようなアプローチをお勧めしますか?
1. 　
2. 集計結果を提供する新しいデータセットとビューを作成して共有する必要があります
3. 
4. 
<details><div>
    答え：
説明
承認されたビューは、ソース データとは別のデータセットに作成する必要があります。そうすれば、データ所有者は、基になるデータへのアクセス権を同時に付与することなく、承認されたビューへのアクセス権をユーザーに付与できます。 したがって、新しいデータセットを作成し、そのデータセット内にビューを作成するため、B が正解です。
参照:https://cloud.google.com/bigquery/docs/share-access-views
</div></details>

 ### Q. 質問39: 未回答
スパム分類器をトレーニングする際の過学習に対処する 3 つの可能な方法は何ですか?3 つのオプションを選択します。
1. 　トレーニング例の数を増やす
2. 
3. 機能セットを縮小して使用する
4. 
5. 正規化パラメータの値を増やす
<details><div>
    答え：
説明
より多くのトレーニング例を取得する: トレーニング例を増やすと、データのより広い範囲のバリエーションをキャプチャできるため、モデルの一般化が容易になります。
より小さな特徴セットを使用する: より小さな特徴セットを使用すると、データ内のノイズを適合させる容量を制限することで、モデルを単純化し、過学習を減らすことができます。
正則化パラメーターを増やす: L1 や L2 正則化などの正則化パラメーターを増やすと、大きな重みとバイアスにペナルティを課し、モデルが最も関連性の高い特徴に焦点を合わせるようにすることで、過学習を制御するのに役立ちます。
</div></details>

 ### Q. 質問45: 未回答
Google Cloud のデータ パイプラインでロジスティック回帰モデルのデータを準備しながら、実数値のままで削除できない null 値をモニタリングして調整するにはどうすればよいでしょうか。
1. 　
2. Cloud Dataperpを使用してサンプルソースデータのNull値を特定し、Cloudperpジョブを使用してすべてのnull地を0に変換します
3. 
4. 
<details><div>
    答え：
説明
Google Cloud のロジスティック回帰モデルで null 値を含むデータを準備するための推奨されるアプローチは次のとおりです。
Cloud Dataprep を使用して、サンプルのソースデータから null 値を見つけます。
Cloud Dataprep ジョブを使用して、すべての null を 0 に変換します。このアプローチでは、Cloud Dataprep を使用して null 値を識別し、機械学習モデルで null 値を処理するための一般的なアプローチである 0 に置き換えます。
また、ロジスティック回帰モデルにとって重要な、null 値を実数値変数として保持しながら null 値をモニタリングして調整する機能も備えているため、Cloud Dataprep を使用することをおすすめします。
</div></details>

 ### Q. 質問47: 未回答
予測可能な期間にバッチベースとストリームベースのイベントデータの両方を処理する必要があるが、遅延データや順序が正しくないデータが発生する可能性がある Google Cloud Dataflow パイプラインには、どのような設計アプローチが推奨されますか?このシナリオを処理するには、次のオプションのうちどれを選択する必要がありますか?
1. 　
2. 
3. 透かしとタイムスタンプを使用して、時間差データをキャプチャします
4. 
<details><div>
    答え：
説明
予測可能な期間にバッチベースとストリームベースのイベントデータの両方を処理する必要があるが、データの遅延や順序が正しくない可能性がある Google Cloud Dataflow パイプラインの推奨設計アプローチは、ウォーターマークとタイムスタンプを使用してラグデータをキャプチャすることです。したがって、正しいオプションは C です。
ウォーターマークは、データストリーム内のイベント時間の進行状況を指定するために使用され、遅延データを識別するために使用できます。
タイムスタンプは、各データ要素にイベント時間を割り当てるために使用されます。
ウォーターマークとタイムスタンプを使用することで、パイプラインはオンタイム データと遅延データを区別し、それに応じて処理できます。これにより、パイプラインが正確かつ効率的な方法でデータを処理できるようになります。
</div></details>

 ### Q. 質問49: 未回答
衣料品会社は、顧客におすすめのファッションを勧めたいと考えていました。彼らは同じモデルを構築したかったのです。ファッション業界が進化し続けるにつれて、エンドユーザーのファッションの好みは時間の経過とともに変化し続けます。そのため、新しいファッション関連データが利用可能になったときにモデルにストリーミングするためのデータパイプラインを構築する必要があります。このようなシナリオでは、このデータを使用してモデルをトレーニングする方法を教えてください。
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
受信データを継続的に監視し、データ分布が元のトレーニング データの分布から変更されていることがわかった場合は、新しいデータでモデルを再トレーニングすることをお勧めします
</div></details>

 ### Q. 質問50: 未回答
当初は、3 つの診療所で数百人の患者が参加する小規模なパイロット プロジェクトで、患者の記録を管理するデータベースを設計しました。ただし、プロジェクトの拡張により、データベースは非常に大きなデータセットを処理する必要があり、既存の設計ではレポートをタイムリーに生成するには不十分になります。データベース設計では、どのような調整を考慮する必要がありますか?
1. 　
2. 
3. マスター患者レコード票を別々の患者テーブルと訪問表に正規化し、必要に応じて追加の票を作成して、事故結合の必要性を排除します
4. 
<details><div>
    答え：
説明
正規化は、データの整合性を強化し、データの冗長性を低下させるためにリレーショナルデータベースで採用されている戦略です。患者レコードを患者と診察の個別のテーブルに再構築し、自己結合も削除することで、クエリのパフォーマンスが向上した、よりスケーラブルなデータベースになります。このアプローチにより、データの整合性が維持されるだけでなく、大量のデータセットの管理も合理化されます。オプション A、B、D は特定のコンテキストで利点を提供する可能性がありますが、プロジェクトの範囲が大幅に拡大され、自己結合に関連するパフォーマンスの問題に対処する場合は、正規化 (オプション C) が最も回復力がありスケーラブルなソリューションとして浮上します。
</div></details>

 ### Q. 質問51: 未回答
約 1 年前に新しいゲーム アプリがリリースされ、開発者は前日のログ ファイルを LOGS_yyyymmdd のテーブル命名規則を使用して別の Google BigQuery テーブルにアップロードしています。テーブル ワイルドカード関数は、すべての時間範囲の日次および月次レポートを生成するために使用されています。ただし、開発者は、000,<> テーブルの制限を超えたために、長い日付範囲をカバーする一部のクエリが失敗するという問題に遭遇しました。どうすればこの問題を解決できますか?
1. 　
2. 
3. 
4. 
<details><div>
    答え：
説明
特定のシナリオに基づいて、長い日付範囲をカバーするときに 1,000 テーブルの制限を超えたためにクエリが失敗する問題を解決するための最も適切な解決策は、すべての日次ログ テーブルを日付パーティション テーブルに変換することです。
日付範囲に基づいてテーブルをパーティション分割することで、各パーティションは個別のテーブルとして扱われ、1 つのクエリでクエリする必要があるテーブルの数を減らしながら、毎日新しいパーティションを追加することでアプリを水平方向にスケーリングできます。
これにより、アプリはテーブル ワイルドカード関数を使用して、テーブルの制限を超えることなく、すべての時間範囲の日次レポートと月次レポートを生成できます。
</div></details>
