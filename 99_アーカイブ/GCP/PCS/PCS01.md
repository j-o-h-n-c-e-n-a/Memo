## 1
### Q.  問題1: 未回答
あなたのチームは、プロジェクトco-vpc-prodをホストプロジェクトとする共有VPCネットワークを設定します。あなたのチームは、ホストプロジェクトのファイアウォールルール、サブネット、およびVPNゲートウェイを設定しました。エンジニアリンググループAが、10.1.1.0/24サブネットのみにCompute Engineインスタンスをアタッチできるようにする必要があります。
この要件を満たすために、あなたのチームはエンジニアリンググループAに何を付与する必要がありますか？
1. サブネットレベルでのCompute Shared VPC Adminロール
2. サブネットレベルでのCompute Network Userロール
3. ホストプロジェクトレベルでのCompute Shared VPC Adminロール
4. ホストプロジェクトレベルでのCompute Network Userロール
<details><div>
    答え：2
この問題では、共有VPCに関するアクセス権限の管理について理解することが重要です。共有VPCのサブネットを利用できるようにするロールの付与を求められていますが、特定のサブネットへのアクセス制限を想定する必要があります。そのため、全体のホストプロジェクトレベルではなく、特定のサブネットレベルでのロール付与が必要です。さらに、求められているのは管理者裹括機能ではなく、単純にユーザとしてCompute Engineインスタンスを配置する能力なので、適切なユーザロールを選択することが注意点です。
基本的な概念や原則：
共有VPC：Google Cloudの機能で、異なるプロジェクト間で同一のVPCネットワークを共有することができます。一部のプロジェクトがネットワークリソースを所有し（ホストプロジェクト）、他のプロジェクトがそれらのリソースを利用します（サービスプロジェクト）。
ホストプロジェクト：共有VPCでネットワークリソース（サブネット、ファイアウォールルール、VPNゲートウェイ等）を所有しているプロジェクトです。
サービスプロジェクト：共有VPCでホストプロジェクトのネットワークリソースを利用するプロジェクトです。
Compute Network Userロール：Google CloudのIAMロールで、特定のサブネットに対してCompute Engineインスタンスの作成を許可します。このロールをサービスプロジェクトに付与することで、サービスプロジェクトが特定のサブネットにインスタンスをアタッチできるようになります。
Compute Shared VPC Adminロール： Google CloudのIAMロールで、共有VPCのホストプロジェクトとサービスプロジェクト間の関連を作成・管理する権限があります。ただし、このロールでは特定のサブネットにインスタンスをアタッチする機能は付与されません。
正解についての説明：
（選択肢）
・サブネットレベルでのCompute Network Userロール
この選択肢が正解の理由は以下の通りです。
まず、Compute Network Userロールは、指定したリソースでCompute Engineネットワークリソースを使用するためのアクセスを提供します。このロールは、リソースレベル（プロジェクト、フォルダ、組織）だけでなく、特定のネットワークやサブネットにも割り当てることができます。
したがって、ある特定のサブネットにCompute Engineインスタンスをアタッチする能力をエンジニアリンググループAに提供するためには、サブネットレベルでのCompute Network Userロールを付与する必要があります。
また、このロールを付与することで、エンジニアリンググループAは10.1.1.0/24サブネットにインスタンスをアタッチできるようになりますが、その他のネットワークリソース（例えば、他のサブネットやファイアウォールルール）に影響を与えることはありません。これは、この選択肢が特定の要件を達成しつつ、ネットワークリソースの適切なアクセス管理を維持するために重要な側面です。
不正解についての説明：
選択肢：ホストプロジェクトレベルでのCompute Network Userロール
この選択肢が正しくない理由は以下の通りです。
ホストプロジェクトレベルでのCompute Network Userロールを付与すると、エンジニアリンググループAは共有ネットワーク内の全てのサブネットにCompute Engineインスタンスをアタッチできてしまいます。選択肢の要件では特定のサブネットだけにインスタンスをアタッチすることを求めているため、サブネットレベルでのロール付与が正解となります。
選択肢：ホストプロジェクトレベルでのCompute Shared VPC Adminロール
この選択肢が正しくない理由は以下の通りです。
ホストプロジェクトレベルでのCompute Shared VPC Adminロールは一般的にはShared VPCを管理するために使いますが、特定のサブネットへのインスタンスのアタッチ制限には適さないためです。
それに対して、サブネットレベルでのCompute Network Userロールは、特定のサブネットへのインスタンスのアタッチを限定することが出来ます。
選択肢：サブネットレベルでのCompute Shared VPC Adminロール
この選択肢が正しくない理由は以下の通りです。
Compute Shared VPC Adminロールは、Shared VPC全体の管理権限を与えるもので、特定のサブネットへの接続許可を制御する事ができません。
一方、Compute Network Userロールは特定のリソースに対して、ネットワークリソースへのアクセス制御を提供するため、サブネットレベルでのアクセス制限が可能です。
参考リンク：
https://cloud.google.com/compute/docs/shared-vpc
https://cloud.google.com/vpc/docs/provisioning-shared-vpc
https://cloud.google.com/iam/docs/understanding-roles#compute-engine-roles
</div></details>

### Q.  問題2: 回答
ある顧客がエンジニアを解雇し、そのエンジニアのGoogleアカウントが自動的にデプロビジョニングされるようにする必要があります。
顧客はどうすればよいですか？

1. ディレクトリサービスとCloud Directory Syncを構成し、Cloud IdentityのIAMパーミッションを削除します
2. Cloud SDKとディレクトリサービスを使用して、Cloud IdentityのIAMパーミッションを削除します
3. Cloud SDKとディレクトリサービスを使用して、Cloud Identityからユーザをプロビジョニングおよびデプロビジョニングします
4. Cloud Identityからユーザをプロビジョニングおよびデプロビジョニングするために、ディレクトリサービスとCloud Directory Syncを構成します
<details><div>
    答え：4
この問題では、解雇したエンジニアのGoogleアカウントが自動的にデプロビジョニングされることを実現する方法について問われています。ここでキーワードとなるのは"自動的にデプロビジョニング"です。正解選択に向けて、ユーザのプロビジョニング（準備）とデプロビジョニング（取り消し）を自動化するための適切なツールまたはサービスを選ぶことが必要です。
基本的な概念や原則：
Cloud Identity：Google CloudのIdentity and Access Management（IAM）サービスです。ユーザー、グループ、アプリケーションのアクセス権をセントラルに管理します。
プロビジョニングとデプロビジョニング：それぞれ、新しいユーザーやシステムへのリソースやサービスの提供開始と、不要になったリソースやサービスの削除を指します。これはユーザーアカウントのライフサイクル管理において重要なプロセスです。
ディレクトリサービス：組織内のユーザーやリソース、ポリシーを管理するためのサービスです。LDAP（Lightweight Directory Access Protocol）などのプロトコルを使用します。
Cloud Directory Sync：Google Cloud IdentityとオンプレミスのLDAPディレクトリサービスを同期するツールです。アカウントのプロビジョニングとデプロビジョニングを自動化できます。
Cloud SDK：Google Cloudのリソースとアプリケーションをコマンドラインから操作するためのツールセットです。しかし、アカウントの自動デプロビジョニングには適していません。
正解についての説明：
（選択肢）
・Cloud Identityからユーザをプロビジョニングおよびデプロビジョニングするために、ディレクトリサービスとCloud Directory Syncを構成します
この選択肢が正解の理由は以下の通りです。
まず、Cloud IdentityはGoogle Cloudのアイデンティティとアクセスマネージメント（IAM）のプラットフォームであり、企業はこれを使用してユーザのアカウントを管理します。特に、ユーザのプロビジョニング（ユーザをシステムに追加すること）とデプロビジョニング（ユーザのアクセスを削除または制限すること）に使用されます。
また、Cloud Directory Syncは企業のオンプレミスディレクトリサービス（LDAP）とGoogle Cloud Identityを同期させるツールです。これにより、ユーザの追加や削除などの変更がオンプレミスとGoogle Cloudで一貫性を保つことができます。
したがって、エンジニアを解雇した際にそのアカウントを自動的にデプロビジョニングするためには、ディレクトリサービスとCloud Directory Syncを使ってCloud Identityからユーザをデプロビジョニングするのが最善の方法です。これにより、エンジニアのアカウントの安全な管理と、必要ないアカウントの迅速な削除が可能になります。
不正解についての説明：
選択肢：Cloud SDKとディレクトリサービスを使用して、Cloud IdentityのIAMパーミッションを削除します
この選択肢が正しくない理由は以下の通りです。
Cloud SDKとディレクトリサービスを使用してCloud IdentityのIAMパーミッションを削除する手段は、手動的な運用となりエンジニアのGoogleアカウントを自動的にデプロビジョニングする要件を満たしません。
それに対し、ディレクトリサービスとCloud Directory Syncを構成することで、ユーザーのプロビジョニングとデプロビジョニングが自動化されます。
選択肢：Cloud SDKとディレクトリサービスを使用して、Cloud Identityからユーザをプロビジョニングおよびデプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
Cloud SDKはAPIやGoogle Cloudの管理タスクをコマンドラインから制御するツールで、自動的にユーザのデプロビジョニングを行う機能は提供していません。
一方、Cloud Directory Syncはディレクトリサービスと連携し、自動的にユーザのプロビジョニングやデプロビジョニングを行う機能を提供しています。
選択肢：ディレクトリサービスとCloud Directory Syncを構成し、Cloud IdentityのIAMパーミッションを削除します
この選択肢が正しくない理由は以下の通りです。
ディレクトリサービスとCloud Directory Syncを配置し、Cloud IdentityのIAMパーミッションを削除する行為は、IAMパーミッション全体を削除する行為であり、解雇されたエンジニアのアカウントを特定してデプロビジョニングする意図を達成しません。一方で正解の選択肢では、ディレクトリサービスとCloud Directory Syncを利用することで特定のユーザーを効率的にデプロビジョニングすることが可能です。
参考リンク：
https://cloud.google.com/architecture/identity/using-ldap-to-synchronize-google-identity-accounts
https://cloud.google.com/identity/docs/concepts/overview-cloud-identity#sync
https://support.google.com/a/answer/106368?hl=en
</div></details>

### Q.  問題3: 未回答
企業のユーザーアカウントでフィッシング攻撃が増加していることに気づきました。あなたは、暗号署名を使用してユーザーを認証し、ログインページのURLを検証するGoogle 2段階認証（2SV）オプションを実装したいと考えています。どのGoogle 2SVオプションを使うべきですか？
1. Titanセキュリティキー
2. Google認証アプリ
3. Googleプロンプト
4. Cloud HSMキー
<details><div>
    答え：1
この問題では、フィッシング攻撃対策としての2段階認証（2SV）オプションについて問われています。特に、暗号署名とログインページのURL検証機能が必要とされています。選択肢を評価する際には、これらの具体的な要求事項を満たすものを選ぶ必要があります。また、各選択肢が具体的にどのような機能を提供しているのか、それが要求事項とどのように一致しているのかを理解することも求められます。
基本的な概念や原則：
Titanセキュリティキー：Googleが提供している2段階認証装置です。暗号署名を使用してユーザーを認証し、ログインページのURLを検証する機能を持つ実体セキュリティキーです。
フィッシング攻撃：攻撃者が、信頼性のあるものになりすましてユーザーに接触し、個人情報や信用情報を詐取する攻撃手法です。
2段階認証（2SV）：ユーザーのアカウントセキュリティを強化するための手法です。パスワードの他に、ユーザーの所有物（携帯電話やセキュリティキーなど）や生体認証（指紋や顔認証など）を追加の認証手段とします。
Googleプロンプト：Googleの2段階認証の一つで、信頼されたデバイスでプロンプトを表示し、ユーザーが認証操作を行う形式です。
Google認証アプリ：Googleの2段階認証の一つで、スマートフォンアプリから取得する一時的なパスコードを使います。
Cloud HSMキー：Google Cloudで提供されるCloud HSM（HSM）のキーです。高いセキュリティ要件に対応する暗号キー管理を提供しますが、2段階認証の用途には使用されません。
正解についての説明：
（選択肢）
・Titanセキュリティキー
この選択肢が正解の理由は以下の通りです。
まず、TitanセキュリティキーはGoogleが提供する2段階認証（2SV）のハードウェアデバイスで、ユーザーの認証情報のセキュリティを強化します。ハードウェアキーは複数の認証メカニズムを使用します。暗号署名によって、ユーザーのパスワードそのものが攻撃者に知られるリスクを相当に減少させます。
また、ユーザーがサイトにアクセスする際のURLの検証を行うことで、フィッシング攻撃を防ぐための有効な手段となります。
したがって、フィッシング攻撃が増加している現状を考えると、Titanセキュリティキーは最適な選択と言えます。
不正解についての説明：
選択肢：Googleプロンプト
この選択肢が正しくない理由は以下の通りです。
Googleプロンプトでは、ユーザーのアカウント認証をスマートフォン上で行いますが、暗号署名を使用した認証やログインページのURLの検証は含まれていません。
それに対して、Titanセキュリティキーは暗号署名を使用してハードウェアレベルでの認証を行い、フィッシング攻撃対策に効果的です。
選択肢：Google認証アプリ
この選択肢が正しくない理由は以下の通りです。
Google認証アプリは2段階認証のオプションですが、ユーザー認証に暗号署名を使用したり、ログインページのURLを検証したりする機能は提供していません。
それに対して、Titanセキュリティキーは暗号署名を使用してユーザーを認証し、ログインページのURLを検証する機能を持っています。
選択肢：Cloud HSMキー
この選択肢が正しくない理由は以下の通りです。
Cloud HSMキーは暗号化キーの保管と管理に使用される機能であり、2段階認証には直接利用できません。
一方、TitanセキュリティキーはExpress 2段階認証に対応し、ユーザーの認証とURLの検証が可能です。
参考リンク：
https://cloud.google.com/identity-platform/docs/web/2fa
https://cloud.google.com/iam/docs/using-2-step-verification
https://support.google.com/a/answer/9176657?hl=en
</div></details>

### Q.  問題4: 回答
2つのVPCネットワークを接続するためにVPCピアリングを使用することに関連する2つのセキュリティ特性はどれですか？（2つ選択）

1. ピアリングされたネットワーク間で特定のサブネットを共有する機能があります
2. 非推移的なピアリングされたネットワークによって直接ピアリングされたネットワークのみが通信できます
3. あるピアリングされたネットワークから別のピアリングされたネットワークに対してタグを使用して作成できるファイアウォールルールがあります
4. 異なるGoogle Cloudの組織に属するネットワークのピア機能があります
5. ピアリングされたネットワークのルート、ファイアウォール、VPNを一元管理できます
<details><div>
    答え：2,4
この問題では、Google CloudのVPCピアリングのセキュリティ特性についての理解を問われています。VPCピアリングの特性とそれがどのようにセキュリティに関連するかを認識している必要があります。選択肢を絞り込むためには、Google CloudのVPCピアリングの機能をどの程度理解しているかが重要になります。後者の選択肢を見て、それがVPCピアリングの一部として提供されている正確な機能であるかどうかを評価します。
基本的な概念や原則：
VPCピアリング：2つのVPCネットワークを接続し、プライベートな通信を可能にする機能です。異なるプロジェクトや異なるGoogle Cloudの組織間でも実装できます。
非推移的なピアリング：ピアリングされたネットワーク間での通信は直接的な関係を持つネットワーク間のみ許可します。つまり、あるネットワークAが別のネットワークBとピアリング接続を持ち、ネットワークBがさらに別のネットワークCとピアリング接続を持っている場合でも、ネットワークAとネットワークC間の通信は許可されません。
Google Cloudの組織：Google Cloudリソースを管理するためのエンティティで、企業の階層構造を反映しています。組織リソースを使用することで、リソースに対するアクセス管理やポリシー設定などを一元管理できます。
正解についての説明：
（選択肢）
・非推移的なピアリングされたネットワークによって直接ピアリングされたネットワークのみが通信できます
・異なるGoogle Cloudの組織に属するネットワークのピア機能があります
この選択肢が正解の理由は以下の通りです。
VPCピアリングは二つのVPCネットワークの間でプライベートな接続を設定します。その特性の一つに"非推移的"があります。つまり、ピアリングされたネットワークは直接、相互に通信が可能ですが、さらに他のネットワークに対して通信はできません。この非推移性は、通信パスが明確であることを保証し、ネットワークのセキュリティポリシー管理をシンプルにして、間違った通信を避けることができます。
また、VPCピアリングは異なるGoogle Cloudの組織間でも設定が可能です。これにより、異なる組織間でもセキュアに通信することができ、ビジネスパートナーや異なる部門間でのデータ共有等が可用性とセキュリティを維持したままで行えます。これらの特性は、Google Cloudのネットワーク設定における柔軟性とセキュリティを高めます。
不正解についての説明：
選択肢：ピアリングされたネットワークのルート、ファイアウォール、VPNを一元管理できます
この選択肢が正しくない理由は以下の通りです。
VPCピアリングでは、各VPCネットワークのルート、ファイアウォール、VPNは各々独立に管理されます。ピアリングされたネットワークのルートやファイアウォール、VPNを一元管理することはできません。このため、この選択肢は不適切です。
選択肢：あるピアリングされたネットワークから別のピアリングされたネットワークに対してタグを使用して作成できるファイアウォールルールがあります
この選択肢が正しくない理由は以下の通りです。
Google CloudのVPCピアリングでは、ファイアウォールルールを使用してタグを設定して他のピアリングされたネットワークを操作することができません。各ネットワークが独立した管理領域であるため、一方から他方の設定を直接制御することはできません。
選択肢：ピアリングされたネットワーク間で特定のサブネットを共有する機能があります
この選択肢が正しくない理由は以下の通りです。
VPCピアリングではサブネットの共有はできません。各VPCは独立したIPアドレス範囲を持ち、ピアリングではそれらのIPアドレス間の通信ルートが確立されるのみであり、特定のサブネットの共有は不可能です。
参考リンク：
https://cloud.google.com/vpc/docs/vpc-peering
https://cloud.google.com/vpc/docs/using-vpc-peering
https://cloud.google.com/vpc/docs/firewalls
</div></details>

### Q.  問題5: 未回答
あなたは会社のセキュリティ管理者です。Googleが推奨するベストプラクティスに従って、ドメイン制限共有組織ポリシーを実装し、必要なドメインのみがプロジェクトにアクセスできるようにしました。現在、エンジニアリングチームから、組織ドメイン外の外部パートナーのユーザーがプロジェクト内のリソースにアクセスできないとの報告を受けています。
推奨されるベストプラクティスに従いつつ、パートナーのドメインの例外をどのように設定すべきですか？

1. ドメイン制限共有組織ポリシーをオフにします。GoogleのIAM（Identity and Access Management）サービスを使用して、外部パートナーに必要な権限を付与します
2. ドメイン制限共有組織ポリシーをオフにします。ポリシーの値を "Custom"に設定します。各外部パートナーのCloud IdentityまたはGoogle Workspaceの顧客IDを組織ポリシーの例外として追加し、ポリシーをオンに戻します
3. ドメイン制限付き共有の組織ポリシーをオフにします。各パートナーのGoogle WorkspaceカスタマーIDをGoogleグループに追加し、Googleグループを組織ポリシーの例外として追加してから、ポリシーをオンに戻します
4. ドメイン制限共有組織ポリシーをオフにします。ポリシーの値を "すべて許可"に設定します
<details><div>
    答え：2
この問題では、特定の制限を設けている状況で、Google Cloudの組織ポリシーを使用して、例外的に特定のドメインからのリソースへのアクセスを許可する方法が求められています。問題文から、セキュリティ管理者がドメイン制限の共有組織ポリシーを既に実装していることがわかります。これにより、必要なドメインからのみプロジェクトへのアクセスが許可されています。しかし、現在の設定では組織ドメイン外の外部パートナーがプロジェクト内のリソースにアクセスできないという問題が発生しています。推奨されるベストプラクティスに従いつつ、問題を解決するための適切な手段を選択することが求められます。
基本的な概念や原則：
ドメイン制限共有組織ポリシー：Google Cloud上のリソースへのアクセスを特定のドメイン内のユーザーに限定するポリシーです。このポリシーを適用することで、組織内部からの不適切なアクセスや情報漏洩のリスクを低減することができます。
Cloud Identity：Google CloudのIdentity and Access Managementサービスです。ユーザー、グループ、アプリケーションのアイデンティティを一元的に管理し、アクセス権を制御します。
Google Workspace：Googleのクラウドベースの生産性向上ツールのセットです。Gmail、ドキュメント、スプレッドシート、プレゼンテーションなど、共同作業を効率化するツールが一体化されています。
IAM（Identity and Access Management）：ユーザーやサービスアカウントへのリソースへのアクセスを管理するGoogle Cloudのサービスです。特定のユーザーがリソースをどのように操作できるかを詳細に制御することができます。
Googleグループ：特定の目的や話題の周りにメンバーを集め、コンテンツを通じてコミュニケーションをとることが可能なグループです。メールアドレス一つで何人でも同時にメールを送ることができます。
例外設定：ベースラインとしてのポリシーを適用した上で、特定のケースのみを除外するための設定です。例外設定は、より広範なポリシー設定のなかで特定のユーザーやリソースのためのフレキシビリティを提供します。
正解についての説明：
（選択肢）
・ドメイン制限共有組織ポリシーをオフにします。ポリシーの値を "Custom"に設定します。各外部パートナーのCloud IdentityまたはGoogle Workspaceの顧客IDを組織ポリシーの例外として追加し、ポリシーをオンに戻します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの組織ポリシーはセキュリティやコンプライアンスを担保するツールの一つであり、"ドメイン制限共有"ポリシーを利用することで特定のドメインからのアクセスだけを許可することができます。ただし、通常このポリシーは自身のドメインに制約をかけます。このため、特定のパートナーのドメインのみを許可する仕組みは組織ポリシー自体にはなく、設問の状況を直接解決する機能はありません。
そのため、解決策として"ポリシー"自体を"カスタム"に設定して制約を緩和し、ポリシーの例外としてパートナーのCloud IdentityまたはGoogle Workspaceの顧客IDを追加します。この方法を採れば、特定のドメインのみを許可しつつポリシー自体は有効かつ管理しやすい状態を保つことができます。
そして、パートナーのユーザーがチームのプロジェクトにアクセスできるようになります。
このように、Googleが推奨するセキュリティ慣行を維持しつつ、特定の外部パートナーに対するアクセスを許可するためには、組織ポリシーをカスタム設定するのが最善の策です。
不正解についての説明：
選択肢：ドメイン制限共有組織ポリシーをオフにします。ポリシーの値を "すべて許可"に設定します
この選択肢が正しくない理由は以下の通りです。
"すべて許可"に設定すると、セキュリティベストプラクティスに反し、全てのドメインからのアクセスが可能となり、管理下から外れる可能性があります。これは不要なセキュリティリスクを招く可能性があり、Googleの推奨するベストプラクティスに従うことができません。
選択肢：ドメイン制限共有組織ポリシーをオフにします。GoogleのIAM（Identity and Access Management）サービスを使用して、外部パートナーに必要な権限を付与します
この選択肢が正しくない理由は以下の通りです。
ドメイン制限共有組織ポリシーを一時的にオフにするだけでは、セキュリティのベストプラクティスを維持することができません。
また、IAMを使用して外部パートナーに権限を与えても、組織ポリシーが再度オンになった時点で、パートナーは再びアクセスできなくなってしまいます。この問題を解決するために、正解の選択肢のように、パートナーのIDを組織ポリシーの例外として追加することが必要です。
選択肢：ドメイン制限付き共有の組織ポリシーをオフにします。各パートナーのGoogle WorkspaceカスタマーIDをGoogleグループに追加し、Googleグループを組織ポリシーの例外として追加してから、ポリシーをオンに戻します
この選択肢が正しくない理由は以下の通りです。
Googleグループを使って組織ポリシーの例外を追加する方法はベストプラクティスとは異なります。ベストプラクティスでは、外部パートナーのCloud IdentityまたはGoogle Workspaceの顧客IDを直接組織ポリシーの例外として追加することが推奨されています。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-domains
https://cloud.google.com/identity/docs/how-to/setup#creating-managing-groups
https://support.google.com/a/answer/7338880
</div></details>

### Q.  問題6: 未回答
あなたのチームは、本番プロジェクトで稼働しているCompute EngineインスタンスがパブリックIPアドレスを持っていないことを確認したいと考えています。フロントエンドアプリケーションのCompute EngineインスタンスはパブリックIPを必要とします。プロダクトエンジニアは、リソースを変更するEditorロールを持っています。あなたのチームは、この要件を実施したいと考えています。
あなたのチームはどのようにこれらの要件を満たすべきですか？

1. 1つはパブリックIPを持つサブネット、もう1つはパブリックIPを持たないサブネットです
2. フロントエンドのCompute EngineインスタンスのパブリックIPのみを許可するように、組織ポリシーを設定します
3. Editorロールを削除し、エンジニアにCompute Admin IAMロールを付与します
4. 本番プロジェクトのVPCネットワークでプライベートアクセスを有効にします
<details><div>
    答え：2
この問題では、特定のCompute Engineインスタンスに対してのみパブリックIPアドレスを許可し、その他の場合では禁止する方法を考える必要があります。Compute Engineの扱いを理解して、公開しないようにするにはどうすればいいのか理解することが重要です。また、要件を達成するために組織ポリシーの設定が必要なことも理解しなければなりません。これにより、エンジニアがリソースを変更しながらも、フロントエンドのCompute Engineインスタンスが指定された要件を満たすことができるようになります。
基本的な概念や原則：
組織ポリシー：Google Cloudのリソースに対して一貫性のある管理を行えるようにするツールで、特定のリソースがどのように動作すべきかを定義します。
Compute Engineインスタンス：Google Cloudの仮想マシン（Virtual Machines）を指し、ユーザーはCompute Engineインスタンス上で自分のアプリケーションやウェブサイトを動作させることができます。
パブリックIP：インターネット上の任意の場所からアクセス可能なIPアドレス。Compute EngineのインスタンスにはパブリックIPを割り当てることができます。
VPCネットワーク：Virtual Private Cloud（VPC）ネットワークはGoogle Cloudの仮想ネットワークで、リソース（Compute Engineインスタンスなど）を論理的に分離し、ほかのネットワークから隔離します。
IAMロール：Google Cloud Identity and Access Management（IAM）のロールは特定の権限のセットで、ユーザーやサービスアカウントに割り当てることができます。ロールを使用して認可を行います。
サブネット：ネットワーク内の部分ネットワークで、ネットワークを独立したセグメントに分割する手段を提供します。一部がパブリックIPを持つ一方で、他部分はパブリックIPを持たないように設定することができます。
正解についての説明：
（選択肢）
・フロントエンドのCompute EngineインスタンスのパブリックIPのみを許可するように、組織ポリシーを設定します
この選択肢が正解の理由は以下の通りです。
組織ポリシーは、特定のリソースの使用を制限または制御するための仕組みであり、Google Cloudの特定の機能を許可または拒否することが可能です。この問題のシナリオでは、フロントエンドアプリケーションのCompute EngineインスタンスはパブリックIPを必要とする一方で、本番プロジェクトで稼働するCompute EngineインスタンスがパブリックIPを持っていないことを確認したいとの要件があります。この要件を満たすためには、パブリックIPをフロントエンドインスタンスだけに限定的に許可するように組織ポリシーを設定すれば良いのです。この方法により、プロダクトエンジニアがEditorロールを持っていても、許可されたインスタンス以外でパブリックIPを作成または使用することはできません。つまり、適切な組織ポリシーを設定することにより、要件通りの制御が可能となります。
不正解についての説明：
選択肢：本番プロジェクトのVPCネットワークでプライベートアクセスを有効にします
この選択肢が正しくない理由は以下の通りです。
本番プロジェクトのVPCネットワークでプライベートアクセスを有効化すると、パブリックIPなしでもGoogle Cloudサービスへアクセス可能になりますが、既存のCompute EngineインスタンスがパブリックIPを持っていないかの確認や、これ以上パブリックIPの追加を制限する機能はありません。一方正解の組織ポリシーを設定する方法で、特定のインスタンスのみパブリックIPの割り当てを許可するリソースを制御することが可能です。
選択肢：Editorロールを削除し、エンジニアにCompute Admin IAMロールを付与します
この選択肢が正しくない理由は以下の通りです。
Editorロールを削除し、エンジニアにCompute Admin IAMロールを付与しても、エンジニアはCompute EngineインスタンスにパブリックIPアドレスを持つ能力を引き続き持つため、問題の要件は満たせません。
逆に、組織ポリシーを設定することで、特定のCompute EngineインスタンスにパブリックIPの使用を制限することができます。
選択肢：1つはパブリックIPを持つサブネット、もう1つはパブリックIPを持たないサブネットです
この選択肢が正しくない理由は以下の通りです。
選択肢にあるサブネットを使った方法では、別々のサブネットに分けることでパブリックIPを制御しますが、それのみではEditorロールのエンジニアがリソース変更を防げません。
それに対して、組織ポリシーを使うとパブリックIPアドレスの許可制御をリソースレベルで強制し、適切なエンフォースメントが可能になります。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題7: 未回答
あなたは組織のCloud Identity管理者です。Google Cloud環境では、グループを使用してユーザー権限を管理します。各アプリケーションチームには専用のグループがあります。あなたのチームはこれらのグループを作成する責任を負い、アプリケーションチームはGoogle Cloudコンソールを使用してチームメンバーを自分で管理できます。アプリケーションチームが、組織内のユーザーのみをグループに追加できるようにする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. Cloud IdentityログをBigQueryにエクスポートします。グループに追加された外部メンバーのアラートを設定します。アラートがCloud Functionsインスタンスをトリガーして、グループから外部メンバーを削除します
2. 組織に所属するユーザープリンシパルにグループメンバーシップを制限する条件を含むアイデンティティおよびアクセス管理（IAM）ポリシーを設定します
3. Google Workspace Adminコンソールで関連するグループの設定を変更し、外部ユーザーをグループに追加できないようにします
4. スコープ内のグループへの組織外のプリンシパルの割り当てを拒否する、アイデンティティおよびアクセス管理（IAM）拒否ポリシーを定義します
<details><div>
    答え：3
この問題では、Google Cloudの環境において、各アプリケーションチームが組織内のユーザーだけをそのグループに追加できるように制限する方法を求められています。管理者の視点から設定を考える必要があり、アプリケーションチームがGoogle Cloudコンソールを用いて自身のチームメンバーを管理できている点に注目します。不正解の選択肢には複数の方法がありますが、組織内のユーザーだけをグループに追加できるように制限する方法として最も効率的な選択肢を選びます。この問題ではGoogle Cloudの知識はもちろん、グループ管理や権限管理の基本的な理解も必要です。
基本的な概念や原則：
Google Workspace Adminコンソール：Google Workspaceの管理者がユーザーやグループの設定を管理するためのツールです。各グループのポリシーを制御し、外部ユーザーのアクセスを許可または拒否することができます。
Cloud Identity：Google CloudのIdentity and Access Management（IAM）サービスです。組織のユーザーやグループ、サービスアカウントの管理を行うことができます。
Google Cloudコンソール：Google Cloudの各サービスをグラフィカルなインターフェースから管理できるツールです。ユーザーやチームはここから資源を作成、設定、管理することができます。
アイデンティティおよびアクセス管理（IAM）ポリシー：Google Cloud内のリソースへのアクセス制御を行うことができる仕組みです。しかし、特定のプリンシパルのグループメンバーシップを直接制限することはできません。
拒否ポリシー：IAMにおいて、特定のプリンシパルに対するリソースアクセスを拒否するルールを作成するための機能です。しかし、これは個々のグループに対する機能ではなく、リソース全体に適用されます。
Cloud Functions：Google Cloudのサーバーレス実行環境です。イベント駆動のコードを実行するためのサービスで、ログの監視やアラートの設定などに利用できます。
BigQuery：Google Cloudの大規模データ分析サービスです。ログデータの長期保存やアドホックなクエリ分析に適していますが、リアルタイムのアクセス制御には向いていません。
正解についての説明：
（選択肢）
・Google Workspace Adminコンソールで関連するグループの設定を変更し、外部ユーザーをグループに追加できないようにします
この選択肢が正解の理由は以下の通りです。
まず、Google Workspace Adminコンソールは、アカウントの全体的な管理を行うためのツールであり、ここから各種設定変更を行います。身内のユーザーだけをグループに追加したい場合、グループの設定を変更して、外部のユーザーがグループに追加できないように制限することができます。これにより、アプリケーションチームが自分たちのチームを管理する際に、自社のユーザーのみを対象にすることが保証されます。それにより、不適切なアクセス許可の付与または意図しない共有を防ぐことができます。
したがって、Google Workspace Adminコンソールでグループ設定を変更することは、この要件を満たす最適な方法となります。
不正解についての説明：
選択肢：組織に所属するユーザープリンシパルにグループメンバーシップを制限する条件を含むアイデンティティおよびアクセス管理（IAM）ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
IAMポリシーはリソースアクセスの権限を制御する目的のためのもので、組織内のユーザーが特定のグループに追加されるのを制限する目的のためのものではありません。そのため、このシナリオで提案されている要件を満たすためには適切な選択肢ではありません。
選択肢：スコープ内のグループへの組織外のプリンシパルの割り当てを拒否する、アイデンティティおよびアクセス管理（IAM）拒否ポリシーを定義します
この選択肢が正しくない理由は以下の通りです。
IAM拒否ポリシーはソースから宛先へのリクエストを制御し、特定のリソースに対するアクセスを無効にします。しかし、これはグループへのメンバーの追加を制御するものではなく、このシナリオには適していません。
それに対して、Google Workspace Adminコンソールのグループ設定を変更することで、特定のグループに外部ユーザーを追加することを制限することができます。
選択肢：Cloud IdentityログをBigQueryにエクスポートします。グループに追加された外部メンバーのアラートを設定します。アラートがCloud Functionsインスタンスをトリガーして、グループから外部メンバーを削除します
この選択肢が正しくない理由は以下の通りです。
まず、この方法は対症療法であり、予防的ではありません。問題の発生を防ぐのではなく、問題が発生した後に対応します。
また、この選択肢は管理が複雑で、外部ユーザーが一時的にアクセスできる窓が開く可能性があります。正解の選択肢では、設定変更により予め不正操作を防いでいるため、より適切です。
参考リンク：
https://cloud.google.com/identity/docs/how-to/setup#creating-groups-for-your-organization
https://cloud.google.com/identity/docs/managing-groups
https://support.google.com/a/answer/167097?hl=en
</div></details>

### Q.  問題8: 未回答
小規模なスタートアップのオフィスマネージャーは、支払いと請求書の照合や請求アラートの作成を担当しています。コンプライアンス上の理由から、オフィスマネージャーは、これらのタスクに必要なアイデンティティおよびアクセス管理（IAM）権限のみを持つことが許可されています。
オフィスマネジャーが持つべき2つのIAMロールはどれですか？（2つ選択）
1. Organization Administrator
2. Project Creator
3. Billing Account Costs Manager
4. Billing Account Viewer
5. Billing Account User
<details><div>
    答え：3,4
この問題では、支払と請求書の照合や請求アラートの作成といった特定のタスクに必要なアクセス権限を授けるため、オフィスマネージャーにどのIAMロールを許可するべきかを判断することが求められます。最も重要な点は、必要最低限の権限の原則を理解して適用することです。これはコンプライアンス上の理由から、具体的なタスクに必要な権限のみをオフィスマネージャーに許可する必要があるためです。この原則に基づき、選択肢を見ると必要なタスクに合致するIAMロールを見つけ出すことが求められます。
基本的な概念や原則：
Billing Account Viewer：Google Cloudの課金アカウントの詳細な情報や課金データを閲覧するための権限です。コスト管理に必要な情報を確認するために必要となります。
Billing Account Costs Manager：Google Cloudの課金情報を管理するための権限です。課金アラートの作成など、コストに関わる操作を行うために必要となります。
IAM（Identity & Access Management）：Google Cloudのリソースへのアクセスをユーザー、グループ、サービスアカウントに対して、ロールベースで制御するためのフレームワークです。必要最小限の権限を付与することでセキュリティを確保します。
Organization Administrator：Google Cloudの全組織の管理を行うための権限です。オフィスマネージャーには不要な広範囲な権限となります。
Project Creator：新しいGoogle Cloudプロジェクトを作成する権限です。請求や経費の管理とは直接関係がないため、オフィスマネージャーには不要な権限です。
Billing Account User：課金アカウントをプロジェクトに関連付ける権限です。経費の照合や請求アラート作成には直接必要ではないため、オフィスマネージャーには不要な権限です。
正解についての説明：
（選択肢）
・Billing Account Viewer
・Billing Account Costs Manager
この選択肢が正解の理由は以下の通りです。
まず、オフィスマネージャーが行うタスクを考えてみると、支払いや請求書の照合とアラート作成が挙げられます。これらのタスクを行うためには、請求情報を確認できる必要があります。これは"Billing Account Viewer"のIAMロールが提供します。このロールはユーザーに、プロジェクトの請求情報を表示する権限を提供するため、請求や支払いの管理タスクに必要となります。
次に、請求アラートの作成は、特定のコスト閾値が超過したときに通知を送信する機能であり、"Billing Account Costs Manager"のロールに含まれます。このロールは、予算の作成と管理の権限を提供し、コスト管理に関するタスクを効果的に行うことを可能にします。
したがって、オフィスマネージャーが支払いと請求書の照合や請求アラートの作成を効果的に行うためには、"Billing Account Viewer"と"Billing Account Costs Manager"の2つのIAMロールが必要となります。
不正解についての説明：
選択肢：Organization Administrator
この選択肢が正しくない理由は以下の通りです。
Organization Administratorは全体的な権限を持つロールで、支払いや請求書の管理を行うオフィスマネージャーには必要以上の機能が多すぎます。
それに対して、Billing Account ViewerとBilling Account Costs Managerは請求やコスト管理に特化したロールで、必要な権限のみを適切に提供します。
選択肢：Project Creator
この選択肢が正しくない理由は以下の通りです。
Project Creatorロールをオフィスマネージャーに付与すると、新しいプロジェクトを開始することが可能になりますが、これは請求および支払いという彼の責任範囲を逸脱します。
一方、Billing Account ViewerとBilling Account Costs Managerのロールは、請求と支払いに関連する情報の表示と管理を可能にし、彼のタスクに適しています。
選択肢：Billing Account User
この選択肢が正しくない理由は以下の通りです。
Billing Account Userのロールは、請求アカウントに関連するすべてのアクションを実行できる権限で、支払いや請求情報の閲覧だけでなく、請求アカウントのリンクや解除まで可能にします。これは彼が必要とするロールよりもはるかに広範な権限を持っているため、コンプライアンスの観点から不適切です。
参考リンク：
https://cloud.google.com/billing/docs/how-to/billing-access
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://cloud.google.com/billing/docs/how-to/budgets
</div></details>

### Q.  問題9: 未回答
Google Cloud APIにアクセスする必要があるオンプレミスのホストがあります。これらのホスト間のプライベート接続を強制し、コストを最小限に抑え、運用効率を最適化する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. すべてのオンプレミスのトラフィックをIPsec VPNトンネル経由でGoogle Cloudにルーティングし、プライベートGoogleアクセスを有効にしたVPCに送信します
2. インターネットを通じて、オンプレミスとVPCのホスト間でVPCピアリングを設定します
3. ネットワーク経由でデータを送信する前に、Cloud Key Management Service（KMS）キーでデータを暗号化することをすべてのアプリケーションに義務付けるセキュリティポリシーを実施します
4. すべてのオンプレミスのトラフィックを、Cloud Interconnectまたはパートナーインターコネクトを経由して、プライベートGoogleアクセスが有効なVPCにGoogle Cloudにルーティングします
<details><div>
    答え：1
この問題では、オンプレミスのホストからGoogle Cloud APIにチャネルを通じて、プライベートにアクセスする方法が求められています。問題文から、プライバシーの強化、コスト削減、そして効率化が必須の要件となっています。そのため、適切なプライベート接続を設定し、トラフィックをルーティングするための最適なGoogle Cloudのサービスとその設定を選択することが求められます。これらの要件を考慮に入れ、実現可能な方法を選択肢から見つけることが重要です。
基本的な概念や原則：
IPsec VPNトンネル：オンプレミスのネットワークとGoogle Cloudのネットワークを安全に接続するための仮想プライベートネットワークです。
プライベートGoogleアクセス：VPCネットワークからGoogle CloudのAPIとサービスへのプライベートアクセスを提供します。パブリックインターネットを通さずにGoogleサービスに直接アクセスできます。
VPCピアリング：VPC間でネットワーク接続を直接設定し、ネットワークラウンドトリップディレイを分散させるサービスです。
Cloud Key Management Service：Google Cloudの暗号化キーの生成、使用、管理を提供するマネージドサービスです。しかし、ネットワーク層での暗号化を行いません。
Cloud Interconnect：Google Cloudとオンプレミスインフラストラクチャの間で専用のプライベート接続を提供するGoogle Cloudのサービスです。しかし、コストが発生します。
パートナーインターコネクト：サードパーティのサービスプロバイダーを経由してGoogle Cloudへの接続を提供するGoogle Cloudのサービスです。しかし、コストと運用効率に影響を与える可能性があります。
VPC：Google Cloudの仮想プライベートクラウド（VPC）は、Google Cloudリソースの論理的に隔離されたセクションを提供します。これによりユーザーは仮想ネットワークを定義できます。
正解についての説明：
（選択肢）
・すべてのオンプレミスのトラフィックをIPsec VPNトンネル経由でGoogle Cloudにルーティングし、プライベートGoogleアクセスを有効にしたVPCに送信します
この選択肢が正解の理由は以下の通りです。
まず、オンプレミスのホストからGoogle Cloud APIへのアクセスをプライベートな接続で強制するためには、VPNトンネルを利用するのが一般的です。IPsec VPNトンネルはオンプレミスとGoogle Cloud間に暗号化された通信経路を確立することが可能で、これによりデータの盗聴や改竄を防ぐことができます。
また、プライベートGoogleアクセスを有効にしたVPC（Virtual Private Cloud）にトラフィックを送信することで、Google Cloudの内部ネットワークを通じてGoogle APIに安全にアクセスすることが可能になります。これにより、パブリックインターネットを介さずにGoogle Cloudのリソースへのアクセスを保証することができ、セキュリティを強化することができます。
加えて、この方法はコストを最小限に抑える効果もあります。IPsec VPNは比較的低コストで設定・運用でき、プライベートGoogleアクセスを利用すればインターネット経由のデータ転送料を節約することができます。これらの要素が合わさり、運用効率を最適化する方法となります。
不正解についての説明：
選択肢：インターネットを通じて、オンプレミスとVPCのホスト間でVPCピアリングを設定します
この選択肢が正しくない理由は以下の通りです。
VPCピアリングはGoogle Cloud内のVPCネットワーク間での接続を可能にする機能であり、オンプレミス環境とVPC間の接続には使用できません。
それに対し、正解のIPsec VPNはオンプレミスとGoogle Cloud間の安全な接続を提供します。
選択肢：ネットワーク経由でデータを送信する前に、Cloud Key Management Service（KMS）キーでデータを暗号化することをすべてのアプリケーションに義務付けるセキュリティポリシーを実施します
この選択肢が正しくない理由は以下の通りです。
Cloud KMSを使用したデータの暗号化はセキュリティを強化する一方で、オンプレミスからGoogle Cloud APIへの接続をプライベートにすることは実現できません。
また、運用効率の最適化やコストの最小化にも寄与しないため、問題の要件を満たす解答とは言えません。
選択肢：すべてのオンプレミスのトラフィックを、Cloud Interconnectまたはパートナーインターコネクトを経由して、プライベートGoogleアクセスが有効なVPCにGoogle Cloudにルーティングします
この選択肢が正しくない理由は以下の通りです。
Cloud Interconnectやパートナーインターコネクトは、一度設定すれば堅牢な接続を提供しますが、その設定や維持にはそれなりの手間とコストがかかります。
一方、IPsec VPNトンネルは低コストで設定可能で、運用効率も高いため、このケースには最適です。
参考リンク：
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/vpn/docs/concepts/overview
https://cloud.google.com/vpc/docs/vpc-peering
</div></details>

### Q.  問題10: 未回答
オンラインチャットを介してサポートセンターのエージェントと作業するとき、あなたの組織の顧客は、しばしば個人を特定できる情報（PII）を含むドキュメントの写真を共有します。あなたのリーダーシップチームは、このPIIが通常のチャットログの一部として保存されていることを懸念しています。
あなたは、データの有用性を維持しながら、この懸念を解決したいと考えています。
この要件を満たすために、どうすればよいですか？

1. 分析のためにテキストを保存する前に、DLP APIソリューションの汎化アクションとバケッティングアクションを使用して、テキストからPIIを再編集します
2. Cloud Key Management Serviceを利用して、顧客から共有された個人情報を暗号化してから分析用に保管します
3. オブジェクトのライフサイクル管理を使用して、PIIを含むすべてのチャット記録が破棄され、分析のために保存されないようにします
4. 分析用に保存する前に、DLP APIの画像検査と再編集アクションを使用して、画像からPIIを再編集します
<details><div>
    答え：4
この問題では、あなたの組織で扱われる個人を特定できる情報（PII）の適切な管理方法が求められています。特に、顧客から受け取った写真などの情報が通常のチャットログの一部として保存されているという状況があり、その適正な処理方法について考える必要があります。注意すべきは、データの有用性を損なわないようにしながら、PIIを適切に管理しなければならないという点です。具体的には、画像のPIIを再編集するもの、暗号化するもの、或いは破棄するものなど、様々な選択肢が用意されており、その中から最適な手段を選ぶ必要があります。
基本的な概念や原則：
DLP API：Google Cloudの強力なデータ損失防止APIです。このAPIは、機密情報を検出、分類、および匿名化することができます。特に、PII情報の検出と除去に利用できます。
画像の検査と再編集：DLP APIの機能で、画像内の帰属可能情報（PII）を検出し、該当部分を塗りつぶすなどして無害化する作業です。
Cloud Key Management Service：Google Cloudのマネージド暗号化キー作成と管理サービスです。ただし、暗号化は情報の使用の際にはデータを複合化する必要があります。
オブジェクトライフサイクル管理：Google Cloud Storageでデータのライフサイクルを自動化する機能ですが、PII情報を除去する目的ではなく、あくまでデータの保管期間やバージョン管理を適切に行うためのものです。
汎化アクションとバケッティングアクション：DLP API内の操作で、情報の詳細度を下げ、情報の特徴を保持しつつ特定の個人を特定しづらくする処理を指します。しかし、これはテキスト情報に対して行われるため、画像に対するPIIの除去には適用されません。
正解についての説明：
（選択肢）
・分析用に保存する前に、DLP APIの画像検査と再編集アクションを使用して、画像からPIIを再編集します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのDLP（Data Loss Prevention）APIは、データから潜在的に敏感な情報を特定、分類、除去することができるプラットフォームサービスです。これを利用することで、個人を特定できる情報（PII）が含まれる可能性のある画像データに対して、自動的に検査と再編集を行い、それらのPIIをぼかすことが可能となります。
画像検査と再編集アクションをDLP APIで行うことで、PIIが含まれる画像を適切に処理し、同時に元のデータの有用性は維持できます。具体的には、顧客から提供される情報の全体像を認識し続けながら、PIIを保護することができます。
これにより、顧客とのオンラインチャットで共有される画像情報からPIIを削除するという、リーダーシップチームの懸念を解消することができます。以上の理由から、DLP APIの画像検査と再編集アクションを使用するという選択肢が最適な解答となります。
不正解についての説明：
選択肢：Cloud Key Management Serviceを利用して、顧客から共有された個人情報を暗号化してから分析用に保管します
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Serviceは暗号化サービスであり、データの有用性を維持しながら個人情報を隠蔽する機能は提供していません。DLP APIの再編集機能とは異なり、暗号化された個人情報は解析する際に複合化が必要となり、管理が難しくなります。
選択肢：オブジェクトのライフサイクル管理を使用して、PIIを含むすべてのチャット記録が破棄され、分析のために保存されないようにします
この選択肢が正しくない理由は以下の通りです。
オブジェクトのライフサイクル管理はデータ削除や保存ポリシーを自動的に適用する機能であり、PIIを含むデータを特定し、自動的に破棄する機能はありません。
対照的に、DLP APIの画像検査と再編集機能は、直接PIIを特定し措置を取ることが可能で、データの有用性を維持しつつ懸念を解決する最適な解答です。
選択肢：分析のためにテキストを保存する前に、DLP APIソリューションの汎化アクションとバケッティングアクションを使用して、テキストからPIIを再編集します
この選択肢が正しくない理由は以下の通りです。
問題文で顧客が共有する情報はドキュメントの写真であり、画像データの扱いが必要です。ここでの不正解選択肢はテキストデータの処理に関するものであるため、問題文の要件と一致しません。正解の選択肢はDLP APIの画像検査と再編集アクションを使用するため、顧客が共有する写真の情報を適切に扱うことができます。
参考リンク：
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/dlp/docs/automating-dlp
https://cloud.google.com/dlp/docs/concepts-limitations
</div></details>

### Q.  問題11: 未回答
あなたの会社は業界特有の規制に従わなければなりません。そのため、org1という組織内のすべての新しいCloud Storageリソースに顧客管理の暗号化キー（CMEK）を強制する必要があります。
どのようなコマンドを実行すべきですか。
1. 
- 組織のポリシー：constraints/Google Cloud.restrictNonCmekServices
- バインディング：org1
- ポリシーの種類：許可
- ポリシー値：storage.googleapis.com
2. 
- 組織のポリシー：constraints/Google Cloud.restrictStorageNonCmekServices
- バインディング：org1
- ポリシーの種類：許可
- ポリシー値：サポートされているすべてのサービス
3. 
- 組織のポリシー：constraints/Google Cloud.restrictStorageNonCmekServices
- バインディング：org1
- ポリシーの種類：拒否
- ポリシー値：storage.googleapis.com
4. 
- 組織のポリシー：constraints/Google Cloud.restrictNonCmekServices
- バインディング：org1
- ポリシーの種類：拒否
- ポリシー値：storage.googleapis.com
<details><div>
   答え：4
この問題では、業界特有の規制に対応するために、組織内のすべての新しいCloud Storageリソースに顧客管理の暗号化キーを強制するための設定方法について理解することが求められています。Google Cloudの組織ポリシーを操作するためのコマンドと、Cloud Storageのリソースに対してCMEKを強制するための適切なポリシー名を選択しなければなりません。そのためには、Google Cloudの組織ポリシーに関する知識と、CMEKを用いる際の設定や仕様について理解していなければなりません。正しいポリシー名、適切なバインディング、そしてポリシーの種類と値を選ぶことで、規制対応の設定を達成することができます。
基本的な概念や原則：
組織ポリシー：Google Cloudでのリソース管理を制御する仕組みです。特定の制約を満たす必要がある場合や、セキュリティ要件を遵守するために使用されます。
constraints/Google Cloud.restrictNonCmekServices：Google Cloud Storage内でCMEK（顧客管理暗号化キー）を使用しないサービスを制限する組織ポリシーの制約です。
Cloud Storage：Google Cloudの複数のリージョンに分散してデータを格納できるオブジェクトストレージサービスです。
暗号化キー：データのセキュリティを確保するために使用される一連の文字またはバイトです。CMEKはユーザーが管理する暗号化キーです。
ポリシーの種類：許可（Allow）または拒否（Deny）のどちらか一方の設定を適用することで、特定の操作が実行可能か否かを制御します。
バインディング：特定のロールが特定のユーザーまたはグループに付与されていることを示すIAMポリシーの部分です。
storage.googleapis.com: Google Cloud StorageのURLです。このURLをポリシー値に含めることで、Cloud Storageに対する特定のポリシーが適用されます。
正解についての説明：
（選択肢）
・- 組織のポリシー：constraints/Google Cloud.restrictNonCmekServices
- バインディング：org1
- ポリシーの種類：拒否
- ポリシー値：storage.googleapis.com
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudでは、特定のリソースに対して特定の制約を設けることができるようにするために組織のポリシー制約を提供しています。この設問では、顧客管理の暗号化キー（CMEK）を強制するための組織のポリシーを設定する必要があります。そのため、"constraints/Google Cloud.restrictNonCmekServices"という制約を選択します。この制約は、CMEKを使用しないサービスの使用を制限するためのものです。
次に、このポリシーを適用する対象となるバインディングは"org1"であり、組織全体にこのポリシーが適用されます。
それから、"拒否"はポリシーリストの一部であり、指定されたサービスがCMEKを使用していない場合には、そのサービスの使用を拒否します。
最後に、設定したいサービスは"storage.googleapis.com"であり、これはGoogle Cloud StorageのAPIエンドポイントです。これにより、新たに作成されるすべてのCloud StorageリソースにCMEKの使用が強制されます。以上の理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：- 組織のポリシー：constraints/Google Cloud.restrictStorageNonCmekServices
- バインディング：org1
- ポリシーの種類：許可
- ポリシー値：サポートされているすべてのサービス
この選択肢が正しくない理由は以下の通りです。
まず、組織のポリシー名が正しくありません。正しい名前は"constraints/Google Cloud.restrictNonCmekServices"です。そのため、不正解の選択肢が指し示す"constraints/Google Cloud.restrictStorageNonCmekServices"は間違えています。
また、ポリシーの種類が"許可"となっていますが、CMEKを強制するには"拒否"とするべきです。
選択肢：- 組織のポリシー：constraints/Google Cloud.restrictStorageNonCmekServices
- バインディング：org1
- ポリシーの種類：拒否
- ポリシー値：storage.googleapis.com
この選択肢が正しくない理由は以下の通りです。
組織のポリシーの制約の名前が正しくありません。キーを強制するための正しい制約名は'constraints/Google Cloud.restrictNonCmekServices'であり、'constraints/Google Cloud.restrictStorageNonCmekServices'は存在しない制約名です。この違いが試験成績に影響を与えるため注意が必要です。
選択肢：- 組織のポリシー：constraints/Google Cloud.restrictNonCmekServices
- バインディング：org1
- ポリシーの種類：許可
- ポリシー値：storage.googleapis.com
この選択肢が正しくない理由は以下の通りです。
要件はCMEKが強制されることであり、そのためにポリシーの種類は"拒否"に設定する必要があります。すなわち、CMEKが使用されないサービスは拒否する必要があります。"許可"というポリシー種類は逆の効果をもたらすため、不正解になります。
参考リンク：
https://cloud.google.com/storage/docs/encryption/using-customer-managed-keys
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/sdk/gcloud/reference/alpha/resource-manager/org-policies/allow-policy-constraints
</div></details>

### Q.  問題12: 未回答
あなたのアプリケーションは、グローバルな外部HTTP(S)ロードバランサーの背後で、高可用性のクロスリージョンソリューションとして展開されています。複数のIPアドレスからのトラフィックが著しく急増することに気づきましたが、そのIPが悪意のあるものかどうかは不明です。あなたは、アプリケーションの可用性を懸念しています。これらのクライアントからのトラフィックを指定された時間間隔で制限したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. Google Cloud Armorを使用してrate_based_banアクションを構成し、ban_duration_secパラメータを指定の時間間隔に設定します
2. Google Cloud Armorを使用して拒否アクションを設定し、指定された時間間隔であまりにも多くのリクエストを発行したクライアントを拒否します
3. 特定したIPアドレスからのトラフィックをスロットルするように、VPCにファイアウォールルールを設定します
4. Google Cloud Armorを使用してスロットルアクションを構成し、指定された時間間隔でクライアントごとのリクエスト数を制限します
<details><div>
    答え：4
この問題では、Google Cloudを使用して急増する不明なトラフィックを制御する方法について問われています。アプリケーションの安定性を確保するため、一定時間内に受け取る特定のIPアドレスからのリクエスト数を制限したいとのことです。ここでのキーポイントは、指定時間内に特定のIPアドレスからのリクエスト数を制限することであり、この要件を満たすための最適なGoogle Cloudのサービスまたは機能を選ぶことが求められます。具体的には、Google Cloud Armorのスロットルアクションの設定やVPCのファイアウォールルールの設定などが対策として考えられます。一方で、トラフィックを完全に遮断する方法はこの要件を満たさないことを理解することが重要です。
基本的な概念や原則：
HTTP(S)ロードバランサー：Google Cloudのサービスで、グローバルなトラフィックを複数のバックエンドサービスに分散することができます。高可用性とスケーラビリティを提供します。
Google Cloud Armor：Google Cloudのサービスで、外部HTTP(S)ロードバランサーに対するDDoS攻撃とウェブ攻撃から保護します。また、IPブラックリスト/ホワイトリストなどのアクセス制御ポリシーを構成することもできます。
スロットルアクション：Google Cloud Armorの機能で、指定された時間間隔でクライアントごとのリクエスト数を制限することができます。これは、不正なトラフィックを制御するための方法の一つです。
rate_based_banアクション：Google Cloud Armorの機能で、一定のリクエスト数を超えたクライアントを一時的に利用制限（BAN）することが可能です。ただし、これは一時的な対策であり、指定の時間間隔で制限を施すものではありません。
VPCファイアウォールルール：Google Cloudの仮想プライベートクラウド（VPC）ネットワークに対するインバウンドとアウトバウンドのネットワークトラフィックを制御するルールです。トラフィックのスロットルはできません。
拒否アクション：Google Cloud Armorの機能で、特定の条件を満たすクライアントのリクエストを拒否する設定です。これは永久的な制限であり、指定された時間間隔での制限設定はできません。
正解についての説明：
（選択肢）
・Google Cloud Armorを使用してスロットルアクションを構成し、指定された時間間隔でクライアントごとのリクエスト数を制限します
この選択肢が正解の理由は以下の通りです。
Google Cloud Armorは、Google Cloudの負荷分散インフラストラクチャの上に構築され、HTTP(S)ロードバランサーに対するリクエストを分析して分散型サービス拒否（DDoS）攻撃、SQLインジェクション、跨站脚本攻撃といった様々な種類の脅威から保護するサービスです。Cloud Armorには、IPアドレスや地域に基づいてトラフィックを制御する機能がありますが、その中には"スロットル"アクションも含まれています。これは、指定された時間間隔で一定のリクエスト数を超えると、そのクライアントからの新たなリクエストを一時的に拒否する機能です。
したがって、この問題の要件、すなわち"指定された時間間隔でクライアントごとのトラフィックを制限"することを満たすためには、Google Cloud Armorを使用してスロットルアクションを設定することが、最適な解決策と言えるでしょう。
不正解についての説明：
選択肢：Google Cloud Armorを使用してrate_based_banアクションを構成し、ban_duration_secパラメータを指定の時間間隔に設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorのrate_based_banアクションは、指定された抽出条件に基づいてトラフィックを完全にブロックしますが、スロットルアクションのように特定の時間間隔でリクエスト数を制限するという要件には対応していません。そのため、このケースには適していません。
選択肢：特定したIPアドレスからのトラフィックをスロットルするように、VPCにファイアウォールルールを設定します
この選択肢が正しくない理由は以下の通りです。
VPCのファイアウォールルールは、特定のIPアドレスからの全般的な通信をブロックまたは許可するだけで、ある時間間隔でトラフィックのスロットルを行うような機能は提供していません。
それに対して、Google Cloud Armorではリクエスト数を時間単位で制限するという要件を満たすための具体的な設定が可能です。
選択肢：Google Cloud Armorを使用して拒否アクションを設定し、指定された時間間隔であまりにも多くのリクエストを発行したクライアントを拒否します
この選択肢が正しくない理由は以下の通りです。
拒否アクションは一部のクライアントを完全にブロックしますが、不明なIPアドレスが悪意のあるものかどうかは不明であり、正当なトラフィックを遮断する可能性があります。
これに対し、スロットルアクションはリクエスト数を制限するだけであり、全てのクライアントからのトラフィックを受け入れることが可能です。
参考リンク：
https://cloud.google.com/armor/docs/security-policy-overview
https://cloud.google.com/armor/docs/rate-limiting
https://cloud.google.com/load-balancing/docs/https/
</div></details>

### Q.  問題13: 未回答
あなたは、各ビジネスユニットが数千人のユーザーを抱える大規模な組織に勤務しています。あなたは、アクセス制御の権限管理を各ビジネスユニットに委譲する必要があります。委譲にあたっては、以下の要件があります：
- 各ビジネスユニットが、それぞれのプロジェクトのアクセス制御を管理します。
- 各事業部門は、アクセス制御の権限を規模に応じて管理します。
- 事業部門は、他の事業部門のプロジェクトにアクセスできません。
- ユーザーは、別のビジネスユニットに移動したり、会社を退職したりすると、アクセス権を失います。
- ユーザーとアクセス制御の権限は、オンプレミスのディレクトリサービスによって管理されます。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. 組織単位（OU）に基づいてビジネスユニットをグループ化し、OUに基づいて権限を管理します
2. プロジェクトをフォルダで整理し、フォルダレベルでGoogleグループに権限を割り当てます
3. プロジェクトの命名規則を作成し、GoogleのIAM Conditionsを使用して、プロジェクト名の接頭辞に基づいてアクセスを管理します
4. Google Cloud Directory Syncを使用して、Cloud Identityのユーザーとグループメンバーシップを同期します
5. VPC Service Controlsを使って、各ビジネスユニットのプロジェクトの周囲に境界線を作ります
<details><div>
    答え：2,4
この問題では、大規模な組織の中でアクセス制御の権限管理を各ビジネスユニットに委譲する方法が問われています。特定の要件に基づいてアクセス管理を行い、また、ユーザーとそのアクセス権限がオンプレミスのディレクトリサービス管理下にあるという情報から、オンプレミスとクラウド間の同期や適切なレベルでのアクセス権限の割り当てが必須であることが分かります。また、問題文から、各ビジネスユニットが自身のプロジェクトに対するアクセス制御を管理し、他のビジネスユニットのプロジェクトにはアクセスできないようにする必要があることが明確になっています。これらのパラメータを考慮に入れて適切な選択肢を選びましょう。
基本的な概念や原則：
Google Cloud Directory Sync：オンプレミスのLDAPディレクトリサービスとGoogle Cloud Identityのユーザー情報とグループ情報を同期するツールです。これにより、オンプレミスのディレクトリサービスから一元的にアクセス制御を行うことができます。
フォルダ：Google Cloud Resource Managerの一部で、リソースを論理的にグループ化する機能です。フォルダを活用することで、一つの組織内でのリソース管理を容易にします。
Googleグループ：G Suiteにより提供される、ユーザーをグループ化する機能です。Googleグループに権限を割り当てることで、適切なアクセス制御管理を行うことができます。
VPC Service Controls：Google Cloudのサービスを互いに隔離し、不正なデータアクセスを制限するためのセキュリティ機能です。リソース間の通信を制御しますが、ユーザーやグループのアクセス制御管理は行いません。
組織単位（OU）：一連のリソースに対するアクセス権を管理するため、ユーザーとリソースを階層的にグループ化します。OUの設定は一部のGoogle Cloudのアクセス制御管理には有効ですが、プロジェクト単位での制御は効率的ではありません。
IAM Conditions：Google CloudのIAMポリシーに条件を追加する機能です。リソースの特定の状況下でのアクセスを制御しますが、全ユーザーやグループのアクセスを管理する機能ではありません。
正解についての説明：
（選択肢）
・プロジェクトをフォルダで整理し、フォルダレベルでGoogleグループに権限を割り当てます
・Google Cloud Directory Syncを使用して、Cloud Identityのユーザーとグループメンバーシップを同期します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudのフォルダはリソースを整理し、アクセス制御を設定するための方法です。各ビジネスユニットがそれぞれのプロジェクトのアクセス制御を管理し、他のビジネスユニットのプロジェクトにアクセスできないようにするために、各ビジネスユニットに対してフォルダを作成し、それぞれのフォルダ内にプロジェクトを配置します。フォルダレベルでGoogleグループに権限を割り当てることにより、各ビジネスユニットが自分たちのプロジェクトのアクセス権限を独自に管理できるようになります。
次に、ユーザーとアクセス制御の権限はオンプレミスのディレクトリサービスによって管理されるという要件を満たすためには、Google Cloud Directory Syncを使用するのが理想的です。それにより、オンプレミスのディレクトリサービスで管理されているユーザーとグループのメンバーシップ情報をCloud Identityに同期することが可能となります。ユーザーがビジネスユニットを移動したり、組織を退職したりした場合でも、オンプレミスのディレクトリサービスの情報が変更されるとそれがCloud Identityに反映され、適切なアクセス制御の状態を維持します。
不正解についての説明：
選択肢：VPC Service Controlsを使って、各ビジネスユニットのプロジェクトの周囲に境界線を作ります
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsはプロジェクトのネットワーク接続を制御しますが、詳細なアクセス制御や個々のユーザーの権限管理には適していません。そのため、各ビジネスユニットがアクセス制御を管理するという要件を満たすためには、適した解決策とは言えません。
選択肢：組織単位（OU）に基づいてビジネスユニットをグループ化し、OUに基づいて権限を管理します
この選択肢が正しくない理由は以下の通りです。
Google Cloudでは、組織単位（OU）に基づいて権限を管理することはできません。権限管理はGoogleグループまたはユーザレベルでなければならず、そのためにGoogle Cloudは、フォルダやプロジェクトレベルでGoogleグループに権限を割り当てる方法を提供しています。
選択肢：プロジェクトの命名規則を作成し、GoogleのIAM Conditionsを使用して、プロジェクト名の接頭辞に基づいてアクセスを管理します
この選択肢が正しくない理由は以下の通りです。
プロジェクトの命名規則とIAM Conditionsを使用してアクセスを管理すると、規模の変更やビジネスユニット間のアクセス制御のを手動で行う必要があります。これは、必要な権限の委譲、アクセス制御の管理、シームレスなアクセスの剥奪などの要件を満たす効率的な解決策ではありません。
参考リンク：
https://cloud.google.com/iam/docs/overview
https://cloud.google.com/identity/docs/cloud-directory-sync
https://cloud.google.com/resource-manager/docs/creating-managing-folders
</div></details>

### Q.  問題14: 未回答
あなたの組織は、多くのオープンソースプロジェクトに関わるソフトウェアを開発しており、ソフトウェアのサプライチェーンの脅威を懸念しています。ソフトウェアが改ざんされていないことを証明するために、ビルドの証明書を提供する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
- a. Cloud Buildを使用して、ソフトウェアアーティファクトのためのサプライチェーンレベル（SLSA）レベル3保証を生成します
- b. Google Cloudコンソール内のSecurity insightsサイドパネルで、ビルドの実績を表示します
2. 
- a. ソフトウェアのプロセスを確認します
- b. 秘密鍵と公開鍵のペアを生成し、Pretty Good Privacy（PGP）プロトコルを使用して、企業の住所と連絡先を含むファイルとともに出力ソフトウェアアーティファクトに署名します
- c. PGP署名済み証明書を公開Webページに公開します
3. 
- a. 出所の情報を提供するために外部監査人を雇います
- b. 範囲と条件を定義します
- c. セキュリティ部門または担当者からサポートを受けます
- d. 証明書を公開Webページに公開します
4. 
- a. ソフトウェアコードをオープンソースとしてGitHubに公開します
- b. バグ報奨金プログラムを確立し、オープンソースコミュニティに脆弱性のレビュー、報告、修正を奨励します

<details><div>
    答え：
この問題では、ソフトウェアの安全性と改ざんがないことの証明を行うための対策が求められています。特に、オープンソースプロジェクトの関与という文脈から、公開されているソースが安全であることを他者に証明する手段が必要という課題があります。そのため、ソフトウェアの証明書を提供する必要があることから、セキュリティの確保と透明性が重要なポイントとなります。これらを踏まえ、正確に何を求められているのか理解し、適切なセキュリティ対策を選択することが重要です。
基本的な概念や原則：
Cloud Build：Google Cloudのフルマネージド型のCI/CDプラットフォームです。ソースコードからテスト、ビルド、デプロイまでを自動化できます。
サプライチェーンレベル（SLSA）：ソフトウェアアーティファクトの完全性とトレーサビリティを保証するフレームワークです。SLSAレベルは、ソフトウェアのサプライチェーンセキュリティの具体的な目標を提供します。
Security insights：Google Cloudコンソール内でビルドの詳細情報を提供する機能です。これを使用して、ソフトウェアのサプライチェーンが改ざんされていないことを証明できます。
監査：組織のプロセスやシステムを独立した専門家が評価する作業です。これはソフトウェアの出所情報を提供する効果的な方法ではありません。
PGPプロトコル：暗号化、デジタル署名、圧縮を提供する手法です。ソフトウェアの完全性と出所を証明するために使用できますが、サプライチェーンセキュリティ全体を考慮した場合には完全な解決策とは言えません。
バグ報奨金プログラム：ソフトウェアの脆弱性を見つけるために報奨金を提供するプログラムです。これにより、オープンソースコミュニティが脆弱性のレビュー、報告、修正を奨励されます。なお、これはサプライチェーンセキュリティとは別の問題に対処するものであり、ビルドの証明書を提供するための解決策ではありません。
正解についての説明：
（選択肢）
・1.Cloud Buildを使用して、ソフトウェアアーティファクトのためのサプライチェーンレベル（SLSA）レベル3保証を生成します
2. Google Cloudコンソール内のSecurity insightsサイドパネルで、ビルドの実績を表示します
この選択肢が正解の理由は以下の通りです。
まず、ビルドの安全性と透明性を維持しつつ、ソフトウェアのサプライチェーン脅威を対処するためには、Cloud Buildを適用することが有効です。Cloud Buildは、Google Cloudの継続的インテグレーションとデリバリーサービスであり、SLSAレベル3保証を生成する機能を提供します。SLSAレベル3は、ビルドの証明書やその他のメタデータを提供し、ビルドが公正かつイントルージョンフリーであることを保証します。これは、ソフトウェアが改ざんされていないことを証明するための重要な堅牢性を提供します。
次に、Cloud Buildのオペレーションを視覚化するためには、Google Cloudコンソール内のSecurity insightsサイドパネルを活用します。これにより、開発チームはビルドの事件を簡単にトラッキングし、適切にレポートできます。これは、ソフトウェアのサプライチェーンの安全性を確保する上で不可欠なツールとなります。
不正解についての説明：
選択肢：1. 出所の情報を提供するために外部監査人を雇います
2. 範囲と条件を定義します
3. セキュリティ部門または担当者からサポートを受けます
4. 証明書を公開Webページに公開します
この選択肢が正しくない理由は以下の通りです。
まず、ソフトウェアが改ざんされていないことを証明するために外部監査人を雇うという手法は、ソフトウェアの開発と配布プロセス全体の透明性と信頼性を確保するための公式な技術的アプローチと比べると、相対的に非効率的で時間と費用がかかります。
また、範囲と条件を定義し、セキュリティ部門からサポートを受ける、公開Webページに証明書を公開するといった手法では、ソフトウェアの変更とソースコードの全体の改ざんの可能性に対して確証を提供するには制限があります。これらの方法は、Google Cloudの自動化されたツールを使用してサプライチェーンレベルの保証を提供するよりも、効率的ではないと言えます。
選択肢：1. ソフトウェアのプロセスを確認します
2. 秘密鍵と公開鍵のペアを生成し、Pretty Good Privacy（PGP）プロトコルを使用して、企業の住所と連絡先を含むファイルとともに出力ソフトウェアアーティファクトに署名します
3. PGP署名済み証明書を公開Webページに公開します
この選択肢が正しくない理由は以下の通りです。
PGPを用いた手動の署名方法では、ソフトウェアのサプライチェーンの全体的な透明性や証明が確保できません。対してCloud Buildは自動的にビルド履歴を保持し、SLSAレベル3の保証提供が可能で、Security insightsを用いて証明書の可視化が可能です。これらによりサプライチェーン全体の脅威を検証、管理できるため正解となります。
選択肢：1. ソフトウェアコードをオープンソースとしてGitHubに公開します
2. バグ報奨金プログラムを確立し、オープンソースコミュニティに脆弱性のレビュー、報告、修正を奨励します
この選択肢が正しくない理由は以下の通りです。
ソフトウェアコードをオープンソースとしてGitHubに公開したり、バグ報酬プログラムを確立したりしても、それらは直接的にビルドの証明書を提供するものではありません。
また、これらの方法はソフトウェアのサプライチェーン脅威に対する対策としては有効ですが、ソフトウェアが改ざんされていないことを証明するためには不十分です。特にサプライチェーンレベル（SLSA）の保証が求められているこのケースにおいては、Cloud Buildを使用してSLSA保証を生成するのが適切な解答となります。
参考リンク：
https://cloud.google.com/build/docs/building/build-containers
https://cloud.google.com/binary-authorization/docs/getting-started-cli
https://slsa.dev/levels
</div></details>

### Q.  問題15: 未回答
あなたのチームは、組織レベルで管理者権限を持つユーザーを制限したいと考えています。
あなたのチームはどの2つのロールを制限すべきですか？（2つ選択）

1. Organization Role Viewer
2. Super Admin
3. Compute Admin
4. Organization Administrator
5. GKE Cluster Admin

<details><div>
    答え：2,4
この問題では、Google Cloudの組織レベルの管理者権限を制限したいという要望に対応するための2つのロールを選択する問いが出されています。問題文からは組織レベルの管理者というキーフレーズが示されているため、それに関連するロールに注目する必要があります。セキュリティや権限範囲についての理解が問われているので、そのような観点から選択肢を吟味することが求められます。
基本的な概念や原則：
Organization Administrator：組織全体のリソースを管理する権限を持つロールです。組織全体で使用される機能の設定や変更を行います。
Super Admin：Google Workspaceの全ての管理タスクを実行する最高レベルの管理者ロールです。全ユーザーと組織全体のデータと設定を管理します。
GKE Cluster Admin：Google Kubernetes Engineのクラスターを管理する権限を持つロールです。一般的には開発者や運用者が持つロールで、組織全体の管理ではありません。
Compute Admin：Google CloudのCompute Engineリソースを管理する権限を持つロールです。組織全体を直接管理するロールではありません。
Organization Role Viewer：組織全体のIAMロールを表示する権限を持つロールです。ただし、変更や管理は行えません。
正解についての説明：
（選択肢）
・Organization Administrator
・Super Admin
この選択肢が正解の理由は以下の通りです。
まず、"Organization Administrator"ロールのユーザーは、Google Cloudにおける組織のリソース全体を管理する権限を持ちます。これには、組織全体の設定、ポリシーの設定、組織レベルのIAMロールの管理などが含まれます。そのため、このロールを持つユーザーを制限することは、組織全体のセキュリティと管理を強化するために重要です。
次に、"Super Admin"は、G SuiteやGoogle Workspaceにおける最も強力な管理者ロールであり、全ての管理タスクと設定を実行することが可能です。これには、ユーザーやグループの管理、セキュリティ設定、組織全体のデータアクセスなどが含まれます。そのため、Super Adminの権限も制限することで、高いレベルのアクセス制御とセキュリティ管理が可能になります。
不正解についての説明：
選択肢：GKE Cluster Admin
この選択肢が正しくない理由は以下の通りです。
GKE Cluster AdminはGKEのクラスターに特化した管理者のロールであり、組織全体の管理者権限を持つわけではありません。
それに対して、Organization AdministratorとSuper Adminは組織全体が対象となるため、組織レベルでの権限制限にあたります。
選択肢：Compute Admin
この選択肢が正しくない理由は以下の通りです。
Compute AdminはCompute Engineリソースに対する管理者権限を持つロールですが、組織全体の管理者権限や他のサービスに対する権限は持ちません。
それに対して、Organization AdministratorとSuper Adminは組織全体のリソースやユーザーに対する権限を有し、組織レベルでの管理者権限を制限する目的に合致します。
選択肢：Organization Role Viewer
この選択肢が正しくない理由は以下の通りです。
Organization Role Viewerは、組織のロールに対する読み取り専用の権限を持つだけであり、組織全体での管理者権限を制限する上では効果がありません。
それに対して、Organization AdministratorとSuper Adminはより広範な権限を持つため、これらのロールを制限することで組織全体の管理者権限をより適切に制限することが可能です。
参考リンク：
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/resource-manager/docs/access-control-org
https://cloud.google.com/resource-manager/docs/quickstart-organizations
</div></details>

### Q.  問題16: 未回答
あなたの会社は、Google Cloudリソースへのアクセスを提供するために、Cloud Identityでユーザを手動で作成してきました。環境の継続的な拡大に伴い、Google Cloud Directory Sync（GCDS）インスタンスを認証し、オンプレミスのLDAPサーバと統合して、数百人のユーザを登録する必要があります。実装にあたっては、以下のことが必要です：
- オンプレミスのLDAPサーバーからのユーザーとグループのライフサイクル変更をCloud Identityにレプリケートします。
- Cloud Identityで手動で作成したユーザを無効にします。
LDAP検索属性にGoogle Cloudのスコープ内のユーザーとセキュリティグループが含まれるように構成済みです。
このソリューションを完了するために、次に何をすべきですか。
1. 
- 1.LDAPで見つからないドメインユーザーを削除するオプションを設定します
- 2.ユーザーとグループのライフサイクル変更後にGCDSを実行します
2. 
- 1.LDAP検索属性を構成し、LDAPで見つからない手動で作成したCloud Identityユーザを除外します
- 2.定期的なGCDSタスクを設定します
3. 
- 1.LDAP検索属性を構成し、LDAPで見つからない手動で作成したCloud Identityユーザを除外します
- 2.ユーザーとグループのライフサイクル変更後にGCDSを実行します
4. 
- 1.LDAPで見つからないドメインユーザーを一時停止するオプションを設定します
- 2.定期的なGCDSタスクを設定します
<details><div>
    答え：4
この問題では、Google Cloudリソースへのアクセスを認証するためのユーザ登録方法が求められています。具体的には、オンプレミスのLDAPサーバと統合したGoogle Cloud Directory Sync（GCDS）インスタンスと、Cloud Identityで手動で作られたユーザとの対応づけがキーポイントとなります。手動で作成されたユーザの扱い、Google Cloudのスコープ内のユーザとセキュリティーグループの取り扱いがクリティカルポイントとなります。それぞれのユーザーやグループのライフサイクルを考慮しながら、Google Cloud Directory Sync（GCDS）の適切な設定を選択することが求められます。
基本的な概念や原則：
Cloud Identity：Google CloudのID管理サービスです。Cloud Identityを使用すると、ユーザー、アプリ、デバイスがすぐに利用できるようになります。
Google Cloud Directory Sync（GCDS）：オンプレミスのLDAPサーバとCloud Identityを同期するツールです。ユーザーやグループのライフサイクルの変更をCloud Identityにレプリケートすることができます。
LDAP：Lightweight Directory Access Protocolの略で、ディレクトリサービスにアクセスするためのプロトコルです。オブジェクト指向の情報を問い合わせるまたは変更するために使用します。
ユーザーとグループのライフサイクル：ユーザーやグループが作成され、更新され、削除されるプロセスのことです。このライフサイクルの変化をCloud Identityに反映することで、アクセス権の管理がしやすくなります。
LDAP検索属性：LDAPディレクトリ内のエントリを検索するために使用される属性のことです。これにより特定のユーザーやグループを効率的に見つけることができます。
一時停止オプション：GCDS設定の一部で、LDAPで見つからないドメインユーザーを一時停止することができます。これにより、Cloud Identityで手動で作成したユーザーを無効にすることができます。
定期的なGCDSタスク：GCDSを定期的に実行するスケジューリングのことです。これにより、LDAPサーバーからのユーザーとグループのライフサイクル変更をCloud Identityに自動的に反映できます。
正解についての説明：
（選択肢）
・1.LDAPで見つからないドメインユーザーを一時停止するオプションを設定します
2.定期的なGCDSタスクを設定します
この選択肢が正解の理由は以下の通りです。
まず、第一のリクエストとして、LDAPサーバーからのユーザーとグループのライフサイクルの変更をCloud Identityにレプリケートすることに対応するためには、定期的なGCDSタスクを設定することが必要です。これによりLDAPサーバー上での変更がCloud Identityに自動的に同期されます。
次に、すでにCloud Identityで手動で作成されているユーザーを無効にするためには、"LDAPで見つからないドメインユーザーを一時停止する"オプションを設定することが必要です。この設定を有効にすると、LDAPディレクトリ上で存在しないCloud Identityのユーザーが自動的に無効化され、これにより手動で作成されたユーザーでもLDAPに存在しない場合は無効となります。これらの対応により、要件を満たす設定が可能となります。
不正解についての説明：
選択肢：1.LDAPで見つからないドメインユーザーを削除するオプションを設定します
2.ユーザーとグループのライフサイクル変更後にGCDSを実行します
この選択肢が正しくない理由は以下の通りです。
まず、LDAPで見つからないドメインユーザーを削除すると、Cloud Identityで手動で作成したユーザー情報が完全に消去されますが、正解選択肢では一時停止を選ぶことでより控えめなアプローチをとることが求められています。
また、ユーザーとグループのライフサイクル変更後にGCDSを実行すると一貫性が欠け、定期的なGCDSタスクの設定が適切です。
選択肢：1.LDAP検索属性を構成し、LDAPで見つからない手動で作成したCloud Identityユーザを除外します
2.定期的なGCDSタスクを設定します
この選択肢が正しくない理由は以下の通りです。
LDAPで見つからない手動で作成したCloud Identityユーザを除外するのではなく、一時停止する設定が求められています。このように設定しなければ、オンプレミスのLDAPサーバーからCloud Identityへのユーザーとグループの同期が正しく行われません。
選択肢：1.LDAP検索属性を構成し、LDAPで見つからない手動で作成したCloud Identityユーザを除外します
2.ユーザーとグループのライフサイクル変更後にGCDSを実行します
この選択肢が正しくない理由は以下の通りです。
まず、LDAPで見つからないCloud Identityユーザを手動で除外するのは管理が困難で非効率的です。
また、GCDSは変更が生じるたびではなく、定期的に同期を行う仕組みであり、そのため変更後すぐにGCDSを実行するのは不適切です。
参考リンク：
https://cloud.google.com/identity/docs/gcds
https://cloud.google.com/identity/docs/how-to/gcds-configure
https://support.google.com/a/answer/106368?hl=en
</div></details>

### Q.  問題17: 未回答
ある小売業の顧客は、ユーザーがコメントや商品レビューをアップロードできるようにしています。この顧客は、コメントやレビューが公開される前に、テキストに機密データが含まれていないことを確認する必要があります。
これを実現するために、どのGoogle Cloudサービスを使用する必要がありますか？

1. Cloud Key Management Service
2. BigQuery
3. Web Security Scanner
4. Cloud Data Loss Prevention API

<details><div>
    答え：4
この問題では、コメントや商品レビューから機密データを特定し除去するために最適なGoogle Cloudサービスを選び出す能力が問われています。この手の問題では、各選択肢のサービス機能を理解し、それらが提供する機能が問題の要件とどの程度合致するかを評価することが重要です。また、選択肢で提供される各サービスの適用範囲と想定される利用シーンを理解している必要があります。
基本的な概念や原則：
Cloud Data Loss Prevention API：Google Cloudのサービスで、機密情報の自動的な検出、分類、保護の手段を提供します。テキストや画像に含まれる機密データを識別し、これを削除またはマスクすることができます。
Cloud Key Management Service：Google Cloudのサービスで、暗号化キーをクラウド上で管理するためのものです。このサービスは、データ保護の一環として暗号化キーを生成、使用、管理しますが、直接的なテキスト内容の確認やスキャンは行いません。
BigQuery：Google Cloudのフルマネージド型大規模分析サービスです。大量のデータに対して高速にSQLクエリを実行できますが、特定のテキスト内容の確認やスキャンの機能は含んでいません。
Web Security Scanner：Google Cloudのセキュリティスキャンツールです。Webアプリケーションに対するクロスサイトスクリプティングやフラッシュインジェクションなどの一般的な脆弱性を検出しますが、テキスト内容の確認やスキャンは行いません。
正解についての説明：
（選択肢）
・Cloud Data Loss Prevention API
この選択肢が正解の理由は以下の通りです。
Cloud Data Loss Prevention APIは、機密データを検出し、対策を評価するためのGoogle Cloudのサービスです。APIを使用すると、ユーザーがアップロードしたテキストデータやレビューから侵害可能な機密情報（例えば、クレジットカード番号や個人識別情報）を自動的に検出して、これを非表示にしたり、適切な対策を実施したりすることができます。これにより、ユーザーのコメントやレビューが公開される前に、機密データの公開を防ぐことができます。
したがって、この問題の要件を満たすためにはCloud Data Loss Prevention APIを使用することが適切です。
不正解についての説明：
選択肢：Cloud Key Management Service
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Serviceは暗号鍵の管理と暗号化・復号化の処理を行うサービスであり、テキスト中の機密データの検出には適していません。一方でCloud Data Loss Prevention APIを使用すると、機密データを検出し保護することが可能です。
選択肢：BigQuery
この選択肢が正しくない理由は以下の通りです。
BigQueryは大量のデータを高速に解析するためのデータウェアハウスサービスであって、機密データの検出や分析には特化していません。
それに対して、Cloud Data Loss Prevention APIはテキスト中の機密情報を識別、分類する機能を提供し、質問の要件を満たします。
選択肢：Web Security Scanner
この選択肢が正しくない理由は以下の通りです。
Web Security ScannerはWebアプリケーションの脆弱性を検出するサービスであり、テキストに機密データが含まれていないことを確認するロールはありません。
それに対して、Cloud Data Loss Prevention APIは機密情報の検出と保護を行うため、こちらが正解となります。
参考リンク：
https://cloud.google.com/dlp/docs
https://cloud.google.com/kms/docs
https://cloud.google.com/web-security-scanner/docs
</div></details>

### Q.  問題18: 未回答
あなたのチームは、SIEMですべての開発クラウドプロジェクトの統一されたログビューを取得する必要があります。開発プロジェクトは、NONPROD組織フォルダーの下に、テストプロジェクトとプリプロダクションプロジェクトと一緒にあります。開発プロジェクトは、CLOUDJP-BILLING請求アカウントを他の組織と共有しています。
要件を満たすために、どのロギングエクスポート戦略を使用する必要がありますか？
1. 
- 1. 専用のSIEMプロジェクトで、billingAccounts/CLOUDJP-BILLINGの親とincludeChildrenプロパティをFalseに設定したCloud Storageシンクを作成します
- 2. SIEMでCloud Storageオブジェクトを処理します
2. 
- 1. 専用のSIEMプロジェクトでfolders/NONPRODの親とincludeChildrenプロパティをTrueに設定して、ログをCloud Pub/Subトピックにエクスポートします
- 2. SIEMをトピックにサブスクライブします
3. 
- 1. 各プロジェクトでパブリックに共有されるCloud Storageバケットを使用してCloud Storageシンクを作成します
- 2. SIEMでCloud Storageオブジェクトを処理します
4. 
- 1. 各開発プロジェクトのログを専用のSIEMプロジェクトのCloud Pub/Subトピックにエクスポートします
- 2. SIEMをトピックにサブスクライブします
<details><div>
    答え：2
この問題では、開発クラウドプロジェクト全体のログを一括してSIEMに取り込む方法が求められています。開発プロジェクトはNONPRODフォルダにまとめられていること、請求アカウントは他の組織と共有されていることを認識しておくことが重要です。これらの情報を元に、ログを適切にエクスポートし、SIEMに統合する手法を考えます。適切なエクスポート戦略を考える際には、すべてのプロジェクトからのログを一括処理できるパターンと、セキュリティへの影響を最小限に抑えられるパターンを選ぶことがポイントとなります。
基本的な概念や原則：
ログエクスポート：Google Cloud Loggingの機能で、ログエントリを別のGoogle Cloudサービスに転送する機能です。Cloud Storage、BigQuery、Pub/Subにエクスポート可能で、エクスポート先により解析やデータ取得の方法が異なります。
SIEM：Security Information and Event Managementの略で、セキュリティ情報を一元的に管理・分析するシステムのことです。
Google Cloud Pub/Sub：Google Cloudのパブリッシュサブスクライブ型メッセージングサービスで、リアルタイムかつ信頼性の高いメッセージングが可能です。Pub/Subトピックにエクスポートしたログは、即時性が求められる解析やアラート通知に利用可能です。
フォルダー：Google Cloud Resource Managerの概念で、リソース（プロジェクトや組織など）を階層的に整理するためのものです。
インクルードチルドレンプロパティ：ログエクスポート設定の親フォルダーに関連するすべての子フォルダーとプロジェクトからのログを含めるかどうかを示す設定です。
請求アカウント：Google Cloudの課金管理に用いるアカウントで、特定の課金情報とリソース使用状況について管理します。複数のプロジェクトで共有可能です。
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、大量のデータを安全に保存しアクセスできます。ログのエクスポート先として指定することも可能ですが、ストレージ上のデータをSIEMが処理するためには追加の作業が必要になる場合があります。
正解についての説明：
（選択肢）
・1. 専用のSIEMプロジェクトでfolders/NONPRODの親とincludeChildrenプロパティをTrueに設定して、ログをCloud Pub/Subトピックにエクスポートします
2. SIEMをトピックにサブスクライブします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudのロギングエクスポート機能を使用すると、ログエントリをPub/Subトピックにエクスポートできます。Pub/Subはリアルタイムのメッセージングサービスであり、このトピックに接続されたSIEMシステムはそれらのログエントリをリアルタイムに受信できます。
次に設定レベルについてですが、NONPROD組織フォルダーを親として設定すると、その下に存在する全てのプロジェクト（開発プロジェクト、テストプロジェクト、プリプロダクションプロジェクト）のログを一括で取得できます。これは要件である"全ての開発プロジェクトの統一されたログビューを取得する"ことを実現します。
さらに、includeChildrenプロパティをTrueに設定することで、将来新たに追加されるプロジェクトのログエントリも自動的にエクスポートされるようにしています。
この設定は請求アカウントごとにではなく、組織のフォルダーレベルで設定するため、CLOUDJP-BILLING請求アカウントを他の組織と共有していても問題ありません。
最後に、SIEMをトピックにサブスクライブすることで、エクスポートされたログエントリをSIEMシステムで利用できます。これによりSIEMシステムは統一されたログビューを提供します。
不正解についての説明：
選択肢：1.専用のSIEMプロジェクトで、billingAccounts/CLOUDJP-BILLINGの親とincludeChildrenプロパティをFalseに設定したCloud Storageシンクを作成します
2. SIEMでCloud Storageオブジェクトを処理します
この選択肢が正しくない理由は以下の通りです。
請求アカウントレベルでのログエクスポート設定は、特定のプロジェクトやフォルダのログビューに対しては統一性を提供しません。
また、includeChildrenをFalseに設定すると、それらの子供のリソース（プロジェクトやサービス）のログはエクスポートされず、それらのログを統一的に閲覧することができなくなります。
選択肢：1. 各開発プロジェクトのログを専用のSIEMプロジェクトのCloud Pub/Subトピックにエクスポートします
2. SIEMをトピックにサブスクライブします
この選択肢が正しくない理由は以下の通りです。
各開発プロジェクトのログを個々にエクスポートすると手間がかかり、管理が煩雑になります。対して正解の選択肢では、一括してログを取得するために親フォルダからログをエクスポートしているため、管理が効率的です。
選択肢：1. 各プロジェクトでパブリックに共有されるCloud Storageバケットを使用してCloud Storageシンクを作成します
2. SIEMでCloud Storageオブジェクトを処理します
この選択肢が正しくない理由は以下の通りです。
各プロジェクトでCloud Storageを使用してシンクすると、ログの管理とSIEMへの取り込みが複雑化し、一貫性や効率性が損なわれる可能性があります。特定のフォルダにPub/Subトピックを設定することで、すべてのログを一元管理し、リアルタイム性も保てるため、SIEMの取り込みも容易になります。
参考リンク：
https://cloud.google.com/logging/docs/export/aggregated-exports
https://cloud.google.com/logging/docs/export/configure_export_v2
https://cloud.google.com/pubsub/docs/overview
</div></details>

### Q.  問題19: 未回答
あなたの組織では、認証にGoogle Workspace Enterprise Editionを使用しています。あなたは、Google Cloudに認証した後、従業員が長時間ラップトップを放置することを懸念しています。悪意のある人が従業員の無人のラップトップを使用して環境を変更することを防止する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. セッションを長時間開いたままにしないよう、従業員に義務付けるポリシーを作成します
2. Google Cloudサービスのセッションタイムアウト時間を短く設定します
3. 強固なパスワードと、セキュリティトークンまたはGoogle認証による2段階認証を要求します
4. 不要なGoogle Cloud APIを見直し、無効にします
<details><div>
    答え：2
この問題では、認証後の従業員のセキュリティ保護に関する懸念点とその対策方法について問われています。あなたの組織がGoogle Workspace Enterprise Editionを使用しているという前提条件と、誰かが従業員の無人のパソコンを使用して予期しない変更を加えることを防止したいという要求から、問題の中心は認証後のセキュリティ管理にあることが分かります。選択肢を評価する際には、これらの要点を念頭に置いて考える必要があります。
基本的な概念や原則：
Google Workspace Enterprise Edition：ビジネス向けのGoogleの一連のクラウドベースのコラボレーションと生産性のツールです。会社の全ての従業員に共通の認証環境を提供します。
セッションタイムアウト：セッションが一定時間無操作状態が続くと、自動的にセッションを切断する機能です。これにより、誤ってログインしたまま放置されている場合でも、悪意のある操作を防ぐことができます。
Google Cloud API：Google Cloudの各種サービスと機能をプログラムから操作するためのインターフェースです。必要に応じて有効化・無効化することが可能です。
2段階認証：パスワードだけでなく、スマートフォンなど別のデバイスを用いた認証を追加することで、セキュリティを強化する手法です。パスワードが漏洩した場合でも、2段階目の認証がないとログインできないため安全です。
正解についての説明：
（選択肢）
・Google Cloudサービスのセッションタイムアウト時間を短く設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudサービスのセッションタイムアウト時間を短く設定することで、ユーザーが一定時間アクティビティがない場合、自動的にセッションが切れ、再度ログインが必要になります。これにより、従業員がラップトップを放置した場合でも、認証情報が長時間開放されることを防ぎます。
この操作はセキュリティを強化するための効果的な方法であり、特に公共の場所での作業や共有のデバイスでの作業におけるリスクを減らすことができます。このような設定により、誰かが無人のラップトップを使用して不適切な操作を行うことを効果的に防止できます。
また、セッションタイムアウト時間の設定は、Google Cloudの管理者が容易に行うことができ、ユーザーエクスペリエンスを大幅に低下させることなくセキュリティを確保できます。そのため、この選択肢は、要件を満たすための適切な解答です。
不正解についての説明：
選択肢：セッションを長時間開いたままにしないよう、従業員に義務付けるポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
従業員に義務付けるポリシーを作成するといっても、それが全ての従業員に対して完璧に実施される保証はありません。
それに対して、Google Cloudサービスのセッションタイムアウト時間を短く設定すれば、システム的にセッションを自動で切断し、悪意のある環境変更を防ぐことが可能となります。
選択肢：不要なGoogle Cloud APIを見直し、無効にします
この選択肢が正しくない理由は以下の通りです。
不要なGoogle Cloud APIを無効にすることはセキュリティ上のベストプラクティスですが、それ自体がラップトップが放置された際の環境変更防止には直接寄与しません。
それに対し、セッションタイムアウト時間を短く設定することは、長時間放置されたラップトップからの不正なアクセスを防止できます。
選択肢：強固なパスワードと、セキュリティトークンまたはGoogle認証による2段階認証を要求します
この選択肢が正しくない理由は以下の通りです。
強固なパスワードや2段階認証は確かにセキュリティを強化しますが、すでに認証済みのラップトップを無人で放置されるという問題に対しては直接的な対策にはなりません。
それに対して、セッションタイムアウト時間を短く設定することで、放置された状態でも一定時間経つと自動的にログアウトし、不正アクセスを防げます。
参考リンク：
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#set-session-lengths
https://cloud.google.com/identity/docs/how-to/setup-security-keys
https://support.google.com/a/answer/7576830?hl=en
</div></details>

### Q.  問題20: 未回答
あるアプリケーションをクラウドに移行しようとしています。アプリケーションはCloud Storageのバケットからデータを読み取る必要があります。現地の規制要件により、暗号化に使用するキーマテリアルを完全に管理下に置く必要があり、キーマテリアルにアクセスする正当な根拠が必要です。
この要件を満たすために、どうすればよいですか？

1. Cloud HSM（HSM）にバックアップされたカスタママネージド暗号化キーを使用して、Cloud Storageバケット内のデータを暗号化します。データアクセスログを有効にします
2. オンプレミス環境で鍵を生成し、オンプレミスで管理されているCloud HSM（HSM）に保管します。この鍵をCloud Key Management Service（KMS）の外部鍵として使用します。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムで不正アクセスを拒否するように設定します
3. Customer Managed Encryption Keysを使用してCloud Storageバケット内のデータを暗号化します。未承認グループに対してIAM拒否ポリシーを設定します
4. Cloud Storageバケットにデータをアップロードする前に、データを暗号化するキーをオンプレミス環境で生成します。鍵をCloud Key Management Service（KMS）にアップロードします。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムに不正アクセスを拒否させます

<details><div>
    答え：2
この問題では、アプリケーションがCloud Storageからデータを読取る際に、キーマテリアルを完全に管理下に置き、アクセスに正当性が必要という要件を満たす解決策を求められています。キーマテリアルの管理とアクセス正当性の確認の観点から考えると、オンプレミスで生成された鍵を使用し、Cloud HSMで保管し、アクセスが必要な場合は、Key Access Justificationsを有効にすることが考えられます。この観点を持つことにより、適切な解答を選択することが可能となります。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データの永続性、可用性、耐久性を高めるために利用します。
Cloud HSM：Google Cloudの暗号化キーサービスです。Cloud HSM（HSM）を利用して暗号化キーの生成、管理を行います。
Cloud Key Management Service（KMS）：Google Cloudの暗号鍵管理サービスです。暗号鍵を作成、使用、管理、回転、破棄、復元するためのフルマネージドサービスです。
Key Access Justifications：Google Cloudの原理でアクセスの正当性を追跡し、承認するための機能です。この機能を有効にすると、キーにアクセスするたびにその合理的な理由が文書化されます。
Customer Managed Encryption Keys：顧客が自身で管理・制御するための暗号化キーのことです。これを利用することで、ユーザー自身で暗号キーのライフサイクルの管理を行うことができます。
IAM拒否ポリシー：特定のユーザーやグループが特定のリソースにアクセスすることを拒否するためのIAMの設定です。
データアクセスログ：ユーザーがデータに対して行った操作の詳細を記録したログです。データへのアクセスを監査・監視するために利用します。
正解についての説明：
（選択肢）
・オンプレミス環境で鍵を生成し、オンプレミスで管理されているCloud HSM（HSM）に保管します。この鍵をCloud Key Management Service（KMS）の外部鍵として使用します。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムで不正アクセスを拒否するように設定します
この選択肢が正解の理由は以下の通りです。
まず、要件では暗号化キーやキーマテリアルを完全に管理すること、そしてキーマテリアルにアクセスする正当な根拠が必要であると述べています。そのため、まずオンプレミスの環境で鍵を生成し、そしてCloud HSMに保管することで、鍵の生成と保管を完全に制御下に置くことができます。
更に、生成された鍵をCloud KMSの外部鍵として使用することで、クラウド環境とオンプレミス環境間で鍵の操作が可能となり、Cloud Storageからデータを読み取るというアプリケーションの要求も適切に満たすことができます。
最後に、Key Access Justifications（KAJ）を有効化することで、鍵へのアクセスに正当な根拠が必要となり、外部鍵管理システムで不正アクセスを拒否するよう設定することで、キーマテリアルへのアクセス制御もしっかりと行うことができます。
複合的に、これらの処置を講じることで、規制要件を満たすとともに、クラウド移行という動きにも適応できるため、この選択肢が最も適切です。
不正解についての説明：
選択肢：Customer Managed Encryption Keysを使用してCloud Storageバケット内のデータを暗号化します。未承認グループに対してIAM拒否ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
Customer Managed Encryption Keysを使用したとしても、完全なキーマテリアルの管理を実現することは難しいです。
また、Key Access Justifications（KAJ）は使用されておらず、これによりキーマテリアルへの正当なアクセス根拠の要件を満たすことができません。正解の選択肢では、オンプレミスで管理されたキーとKAJを使用して完全な鍵管理と正当なアクセス根拠を確保しています。
選択肢：Cloud Storageバケットにデータをアップロードする前に、データを暗号化するキーをオンプレミス環境で生成します。鍵をCloud Key Management Service（KMS）にアップロードします。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムに不正アクセスを拒否させます
この選択肢が正しくない理由は以下の通りです。
現地の規制要件により、キーマテリアルを完全に管理下に置かなければならない状況で、鍵をCloud Key Management Service（KMS）にアップロードすると、鍵管理の完全なコントロールが喪失します。これに対して正解の選択肢では、鍵はオンプレミスのHSMで管理され、Cloud KMSは外部鍵としてそれを利用するだけになります。これが規制対策として相応しい選択となります。
選択肢：Cloud HSM（HSM）にバックアップされたカスタママネージド暗号化キーを使用して、Cloud Storageバケット内のデータを暗号化します。データアクセスログを有効にします
この選択肢が正しくない理由は以下の通りです。
Cloud HSMでバックアップされたカスタママネージド暗号化キーを使用すると、キーマテリアルの完全な管理が可能ですが、Key Access Justifications（KAJ）を用いたアクセス正当性の証明が利用できません。
正解の選択肢は、キーマテリアルの完全な管理とKAJを併用しているためより適しています。
参考リンク：
https://cloud.google.com/kms/docs/using-external-keys
https://cloud.google.com/storage/docs/encryption/using-customer-supplied-keys
https://cloud.google.com/kms/docs/key-access-justifications
</div></details>

### Q.  問題21: 未回答
ある企業がGoogle Kubernetes Engine上でウェブショップを運営しており、BigQueryで顧客トランザクションを分析したいと考えています。分析にあたっては、クレジットカード番号がBigQueryに保存されないようにする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. Security Command Centerを活用して、BigQueryでクレジットカード番号タイプの資産をスキャンします
2. Cloud Identity-Aware Proxyを有効にして、BigQueryにログを保存する前にクレジットカード番号をフィルタリングします
3. クレジットカード番号に一致する正規表現を使用してBigQueryビューを作成し、クエリを実行して該当する行を削除します
4. データをBigQueryに取り込む前に、Cloud Data Loss Prevention APIを使用して関連するinfoTypeを再編集します
<details><div>
   答え：4
この問題では、個人情報を扱う企業が法令遵守またはプライバシーポリシーに準拠するために必要な手段を選択する必要があります。具体的には、クレジットカード情報がGoogle BigQuery内に保存されないようにする方策を選ぶことが求められます。順調に選択肢を見極めるためには、Google Cloudの各サービスの特性とその正しい使い方を理解していることが必要です。また、データの保存ではなく、既存のデータの検査やフィルタリングに対する措置は目的を達成できないという認識を持つことも重要です。
基本的な概念や原則：
Cloud Data Loss Prevention API：機密情報を見つけたり、隠したり、それを保護するためのAPIです。クレジットカード番号や社会保障番号など、特定の情報タイプ（infoType）を自動的に検出したり、赤化したりします。
BigQuery：Google Cloudのビッグデータ分析ツールです。膨大なデータを高速にクエリし、分析を行うことができます。
再編集：データの特定の部分を取り除いたり、新たに付加したりすることです。Data Loss Prevention APIでは機密情報の無害化やマスキングを行うために使用します。
Security Command Center：Google Cloudの資産に対する脅威と脆弱性を識別、可視化、通知するためのユニファイドデータプラットフォームです。
Cloud Identity-Aware Proxy：Google Cloudのサービスに対するアクセスを認証・承認制御するためのサービスです。
正解についての説明：
（選択肢）
・データをBigQueryに取り込む前に、Cloud Data Loss Prevention APIを使用して関連するinfoTypeを再編集します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Data Loss Prevention（DLP）APIは、個人情報の保護とプライバシーの維持を支援するサービスで、機密性の高い情報（infoTypeと呼ばれます）を自動的に検出、分類、そしてマスキング（再編集）することが可能です。この場合、クレジットカードの情報が該当します。
そのため、BigQueryに顧客トランザクションデータを取り込む前にCloud DLP APIを使用することで、クレジットカードの情報を再編集（例えばマスキングやトークン化）することができます。結果として、分析プロセスにおいてクレジットカードの情報がBigQueryに保存されないようにする要件を満たすことができます。
よって、Cloud DLP APIを使用して関連するinfoTypeを再編集するのが、この問題で求められている適切な解法です。
不正解についての説明：
選択肢：クレジットカード番号に一致する正規表現を使用してBigQueryビューを作成し、クエリを実行して該当する行を削除します
この選択肢が正しくない理由は以下の通りです。
ビューを使用してクエリを実行しても、元のデータは変更されずクレジットカード番号がBigQueryに保存されてしまいます。対してCloud Data Loss Prevention APIはデータをBigQueryにインポートする前に情報を再編集し、クレジットカード番号がBigQueryに保存されることを防ぎます。
選択肢：Security Command Centerを活用して、BigQueryでクレジットカード番号タイプの資産をスキャンします
この選択肢が正しくない理由は以下の通りです。
Security Command Centerは主にセキュリティリスクを特定と緩和するためのツールであり、クレジットカード番号のような情報がBigQueryに保存されないように事前に再編集する目的には適していません。
一方、Cloud Data Loss Prevention APIは、個人を特定できる情報を自動的に検出、分類、そして再編集する機能を持つため、問題の要件を満たします。
選択肢：Cloud Identity-Aware Proxyを有効にして、BigQueryにログを保存する前にクレジットカード番号をフィルタリングします
この選択肢が正しくない理由は以下の通りです。
Cloud Identity-Aware Proxyは主にアクセス制御と認証の機能を提供するサービスであり、具体的なデータ（クレジットカード番号等）のフィルタリングや編集を行う機能は持っていません。
一方、Cloud Data Loss Prevention APIは機密情報を検出し、それをマスクするような再編集機能を提供しています。これはクレジットカード情報をBigQueryに保存しないという要件を満たす適切な選択肢です。
参考リンク：
https://cloud.google.com/dlp/docs/transformations/redact-sensitive-data
https://cloud.google.com/bigquery/docs
https://cloud.google.com/bigquery/docs/best-practices-security
</div></details>

### Q.  問題22: 未回答
あなたのチームは、ユーザーが組織内でプロジェクトを作成できないようにする必要があります。DevOpsチームだけが、要求者に代わってプロジェクトを作成できるようにする必要があります。
この要求を処理するために、あなたのチームはどの2つのタスクを実行する必要がありますか？（2つ選択）

1. 指定されたユーザーグループに、組織レベルでProject Editorロールを付与します
2. 組織レベルで、すべてのユーザーをProject Creatorロールから削除します
3. 指定されたDevOpsチームにBilling Account Creatorロールを付与します
4. 組織ポリシー制約を作成し、組織レベルで適用します
5. 組織レベルで、指定されたユーザーグループをProject Creatorロールに追加します
<details><div>
    答え：2,5
この問題では、プロジェクト作成の権限をDevOpsチームだけに絞り込むための適切な手段を理解しましょう。そのためには、アクセス制御とロールベースのアクセス制御（RBAC）についての理解が必要となります。組織内の全ユーザーからプロジェクト作成の権限を剥奪し、それを特定のユーザーグループ（この場合DevOpsチーム）だけに付与するという要求を満たすための適切なタスクを選択肢の中から選ぶ必要があります。
基本的な概念や原則：
Project Creatorロール：Google Cloud上で新たにプロジェクトを作成する権限を持つロールです。このロールを削除することで、特定のユーザーがプロジェクトを作成する能力を制限することができます。
組織レベルのIAMポリシー：全体の組織に対して権限を制御する仕組みです。特定のユーザーやグループに対して、Project Creatorロールなどの特定のロールを追加したり削除したりすることができます。
組織ポリシー：特定のGoogle Cloudリソースに対するアクセスや操作を管理するための仕組みです。しかし、このケースの要件（プロジェクト作成の制限）はIAMポリシーを通じて実現するほうが適切です。
Project Editorロール：既存のプロジェクトに対する全てのAPIの読み書き操作を許可するロールです。しかし、このケースでは新規プロジェクトの作成を制限するためには関連性がありません。
Billing Account Creatorロール：新たに課金アカウントを作成する権限を付与するロールですが、プロジェクト作成の制限とは直接関連がありません。
正解についての説明：
（選択肢）
・組織レベルで、すべてのユーザーをProject Creatorロールから削除します
・組織レベルで、指定されたユーザーグループをProject Creatorロールに追加します
この選択肢が正解の理由は以下の通りです。
まず、"組織レベルで、すべてのユーザーをProject Creatorロールから削除します"は適切です。これにより、基本的にはユーザーはプロジェクトの作成ができなくなります。これが問題の要求を満たしていることは明白です。
次に、"組織レベルで、指定されたユーザーグループをProject Creatorロールに追加します"も反対に、特定のユーザーグループ（この場合、DevOpsチーム）だけがプロジェクトを作成できるようにします。それは彼らがProject Creatorのロールを持つためです。これによってDevOpsチームだけが要求者に代わってプロジェクトを作成でき、問題の制約を満たしています。
よって、これら二つのタスクを組み合わせることで、問題で求められている条件を満たすことができます。これが適切な選択肢である理由です。
不正解についての説明：
選択肢：組織ポリシー制約を作成し、組織レベルで適用します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約を作成し、組織レベルで適用することはプロジェクトの作成防止に直接貢献しません。適切なアクションは、全てのユーザーをProject Creatorロールから削除し、特定のユーザーグループをProject Creatorロールに追加することで、プロジェクトの作成を制限します。
選択肢：指定されたユーザーグループに、組織レベルでProject Editorロールを付与します
この選択肢が正しくない理由は以下の通りです。
Project Editorロールはプロジェクトにリソースを追加、削除、変更する権限を持つが、新しいプロジェクトを作成する権限は含まれていません。この課題を解決するためには、Project Creatorロールを適切なユーザーグループに付与する必要があります。
選択肢：指定されたDevOpsチームにBilling Account Creatorロールを付与します
この選択肢が正しくない理由は以下の通りです。
Billing Account Creatorロールは、請求アカウントを作成する権限を与えるものであり、プロジェクトを作成する権限は含まれません。本問題の目的は、特定のユーザーグループだけがプロジェクトを作成できるように制限することであり、Billing Account Creatorロールの付与はその目的に対して効果的ではありません。
参考リンク：
https://cloud.google.com/resource-manager/docs/access-control-proj
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/resource-manager/docs/organization-policy/creating-managing-policies
</div></details>

### Q.  問題23: 未回答
ある企業がデータ/センター全体をGoogle Cloudに移行しました。異なる部署が管理する複数のプロジェクトで数千のインスタンスが稼働しています。どの時点でGoogle Cloudで何が実行されていたかの履歴記録を持ちたいと考えています。
この要件を満たすために、どうすればよいですか？

1. Forseti Securityを使用して、インベントリのスナップショットを自動化します
2. Security Command Centerを使用して、組織全体のすべての資産を表示します
3. Google Cloud Operation Suiteを使って、すべてのプロジェクトにまたがるダッシュボードを作成します
4. リソースマネージャーを組織レベルで使用します
<details><div>
    答え：1
この問題では、ある企業がGoogle Cloud上の異なる部署によって管理される複数のプロジェクトで稼働するインスタンスの履歴記録を持ちたいとしています。つまり、異なる瞬間でどのようなリソースが稼働していたかを積み重ねて把握できる仕組みが求められています。選択肢を観察する際には、全てのリソースのスナップショットを容易に取可以ない方法やリアルタイムの情報しか提供できない方法は適していない点に注意が必要です。
基本的な概念や原則：
Forseti Security：Google Cloud環境におけるセキュリティポリシーの管理や規則違反の検出などを行うオープンソースのツールセットです。特にインベントリサービスを提供し、一定の間隔でリソースのスナップショットを取る機能があります。
Google Cloudリソースマネージャー：Google Cloudのリソースを組織的に表示し、管理するサービスです。しかし、リソースの履歴記録機能は持っていません。
Google Cloud Operation Suite：Google Cloudのモニタリング、ログ記録、診断などの能力を一元的に提供する統合ツールスイートです。ダッシュボードの作成やアラートの設定などが可能ですが、特定の時間点でのリソースのスナップショット作成機能はありません。
Security Command Center：Google Cloud環境におけるセキュリティリスクや脅威を中心的に管理し、表示するサービスです。リソースの現状確認やリスク評価などが可能ですが、一定の間隔でのリソースのスナップショットは取れません。
正解についての説明：
（選択肢）
・Forseti Securityを使用して、インベントリのスナップショットを自動化します
この選択肢が正解の理由は以下の通りです。
Forseti SecurityはGoogle Cloudのセキュリティツール群の一つで、オープンソースで公開されています。Google Cloud全体のリソースの監視やポリシー管理に用いられ、一つのロールとしてリソースのインベントリ管理を担っています。
具体的には、Forseti Securityのインベントリ機能はGoogle Cloud上のリソースのデータ取得を行い、そのスナップショットを生成します。これにより、特定の時点でGoogle Cloudで何が実行されていたか、つまりどのようなリソースが存在していたのかを履歴として保持することが可能となります。
また、このスナップショット取得は自動化することができ、定期的に状態を記録していくことができます。
したがって、数千のインスタンスが稼働している状況においても、Forseti Securityを使用すれば各時点でのGoogle Cloudのインベントリ状況を効率的に監視・記録することができ、企業の要件を満たせます。
不正解についての説明：
選択肢：リソースマネージャーを組織レベルで使用します
この選択肢が正しくない理由は以下の通りです。
リソースマネージャーはリソースの組織と管理に使われますが、実行中のリソースについての履歴情報を取得する機能は提供しません。
一方で、Forseti Securityはインベントリのスナップショットをとることで、特定の時点でのリソースの状況を記録することができます。
選択肢：Google Cloud Operation Suiteを使って、すべてのプロジェクトにまたがるダッシュボードを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suiteは監視、エラー報告、ログの集中管理を提供しますが、インスタンスの履歴記録やスナップショットを提供する機能は含まれていません。
それに対して、Forseti Securityではインベントリのスナップショットを自動化し、どの時点で何が実行されていたかの履歴記録を提供します。
選択肢：Security Command Centerを使用して、組織全体のすべての資産を表示します
この選択肢が正しくない理由は以下の通りです。
Security Command CenterはGoogle Cloudのセキュリティ管理ダッシュボードであり、組織全体の資産を表示することは可能ですが、特定の時点で何が実行されていたかの履歴記録を持つことはできません。
それに対して、Forseti Securityを使用すれば、インベントリのスナップショットを自動化することで、任意の時点でのリソース状況を記録することが可能です。
参考リンク：
https://cloud.google.com/forseti/docs
https://cloud.google.com/security-command-center/docs
https://cloud.google.com/logging/docs/view/overview
</div></details>

### Q.  問題24: 未回答
ある組織が、インフラをオンプレミス環境からGoogle Cloudに移行し始めています。この組織が取りたい最初のステップは、進行中のデータバックアップとディザスタリカバリソリューションをGoogle Cloudに移行することです。オンプレミスの本番環境は、Google Cloudへの移行の次の段階となる。オンプレミス環境とGoogle Cloud間の安定したネットワーク接続も実装される必要があります。
どのGoogle Cloudソリューションを使うべきですか？

1. Cloud Interconnect経由で永続ディスクを使用するCompute Engine仮想マシン
2. Cloud VPN経由で継続的に更新されるデータパイプラインジョブを使用したBigQuery
3. Cloud Interconnect経由でスケジュールタスクとgsutilを使用したCloud Storage
4. Cloud VPN経由で定期的にバッチアップロードジョブを使用したCloud Datastore
<details><div>
    答え：3
この問題では、オンプレミスからGoogle Cloudへのデータバックアップとディザスタリカバリソリューションの移行を達成するための最適なGoogle Cloudソリューションを選ぶことが求められています。問題文には、データの安定的なネットワーク接続とオンプレミス環境からの移行が必要なことが明記されています。これらの要件を満たす適切なサービス、つまりデータ転送と負荷分散接続の能力を持つソリューションを選ぶ必要があります。また、これらの要件を満たすソリューションが複数ある場合は、最初のステップとしてバックアップとディザスタリカバリに特化したものを優先すると良いでしょう。
基本的な概念や原則：
Cloud Interconnect：Google Cloudと企業のネットワークを高速、低遅延、高スループットで接続するサービスです。大量のデータ移行やハイブリッドクラウド環境で有利です。
gsutil：Google Cloud Storageへのアップロード、ダウンロード、バケットとオブジェクトの操作をコマンドラインから行うためのツールです。データ移行やバックアップに使用されます。
Cloud Storage：オブジェクトストレージサービスで、大量のデータを安全に保存・取得することが可能です。バックアップとアーカイブ、ディザスタリカバリィに効果的です。
Cloud VPN：Google Cloudと企業のVPNゲートウェイ間でのセキュアなネットワーク接続を提供するサービスです。プライベートな通信リンクが必要な場合に使用します。
Cloud Datastore：NoSQLドキュメントデータベースで、Web、モバイルアプリケーションなどのユーザーデータの保存、キャッシュなどに使用されます。
BigQuery：Google Cloudの高度なデータ分析ツールで、大量のデータを高速にクエリ処理することが可能です。データの分析とビジュアライゼーションに使用されます。
正解についての説明：
（選択肢）
・Cloud Interconnect経由でスケジュールタスクとgsutilを使用したCloud Storage
この選択肢が正解の理由は以下の通りです。
まず、オンプレミス環境とGoogle Cloud間で安定したネットワーク接続を実装するためには、Cloud Interconnectが適した選択です。Cloud Interconnectは、企業のオンプレミスインフラとGoogle Cloudとの間を高速で安定した接続で結びつけるサービスであり、データ転送のパフォーマンスの向上や接続の安定性の確保を実現します。
次に、データバックアップとディザスタリカバリソリューションをGoogle Cloudに移行するためには、Cloud Storageとgsutilが良い選択です。Cloud Storageは高耐久性を実現した分散ファイルストレージサービスであり、大量のデータを保存・管理するのに適しています。gsutilは、Cloud Storage上のデータにアクセスし操作するためのコマンドラインツールで、これによりデータのアップロード、ダウンロード、コピーや削除などの操作が可能です。これらを組み合わせることでスケジュールタスクを活用し、効率的にバックアップやディザスタリカバリソリューションを実行できます。
不正解についての説明：
選択肢：Cloud VPN経由で継続的に更新されるデータパイプラインジョブを使用したBigQuery
この選択肢が正しくない理由は以下の通りです。
データバックアップやディザスタリカバリソリューションを実現するためには、BigQueryよりもCloud Storageを使用した方が適切です。BigQueryは主に分析用途に特化したサービスで、バックアップストレージとしての使用は最適ではありません。
それに対して、gsutilを使用してCloud Storageにバックアップを行う方が、データ保存とリカバリの観点から効率的です。
選択肢：Cloud Interconnect経由で永続ディスクを使用するCompute Engine仮想マシン
この選択肢が正しくない理由は以下の通りです。
永続ディスクを使用するCompute Engine仮想マシンは主にVMのストレージとして使われますが、データバックアップやディザスタリカバリといったデータの冗長性を重視する用途には不適切です。
一方、Cloud Interconnect経由でスケジュールタスクとgsutilを使用したCloud Storageは、その特性上、データのバックアップや災害復旧に適しています。
選択肢：Cloud VPN経由で定期的にバッチアップロードジョブを使用したCloud Datastore
この選択肢が正しくない理由は以下の通りです。
Cloud DatastoreはNoSQLデータベースであり、データバックアップやディザスタリカバリソリューションを実現するためのサービスではありません。
それに対して、Cloud Storageは大量のデータを安全に保存・バックアップできるため、バックアップやディザスタリカバリの組織のニーズを適切に満たします。
参考リンク：
https://cloud.google.com/storage/docs/uploading-objects
https://cloud.google.com/interconnect/docs
https://cloud.google.com/storage/docs/using-object-versioning
</div></details>

### Q.  問題25: 未回答
ある顧客が、クラウドコンピューティングの弾力的な性質を利用するアプリケーションをCompute Engine上にデプロイしました。
インフラストラクチャオペレーションエンジニアと協力して、Windows Compute EngineのVMが最新のOSパッチをすべて適用していることを確認する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. 毎週のメンテナンスウィンドウの間にすべてのVMを再起動し、StartUpスクリプトがインターネットから最新のパッチをダウンロードするようにします
2. Deployment Managerを使用して、更新されたVMを新しいサービングインスタンスグループ（IG）にプロビジョニングします
3. パッチが利用可能になったら新しいベースイメージをビルドし、CI/CDパイプラインを使用してVMを再構築し、インクリメンタルにデプロイします
4. ドメインコントローラーをCompute Engineにフェデレートし、グループポリシーオブジェクトを介して毎週パッチをロールアウトします
<details><div>
    答え：3
この問題では、Compute Engine上で動作するWindowsアプリケーションが最新のOSパッチを適用した状態を維持するための最適な方法を求めています。ここで注意すべきポイントは、効率的なパッチ管理と無駄なダウンタイムの最小化が課題となっていることです。Windows OSのパッチの適用について考える際、どのようにして新しいパッチがリリースされた場合に迅速かつ効率的にシステムに適用するかが中心的な課題となります。また、どの方法が最もシステムダウンタイムを最小限に抑え、一貫したパフォーマンスを保つかという観点も重要です。
基本的な概念や原則：
Compute Engine：Google Cloudの仮想マシン（VM）を実行するためのインフラストラクチャです。高性能なネットワークとディスクパフォーマンスを提供します。
OSパッチ：OSのセキュリティや機能を更新するためのソフトウェアパッチです。これにより、システムが最新の状態を維持できます。
ベースイメージ：OSやソフトウェアがプリインストールされたVMイメージのことです。新規VM作成時のテンプレートとして使用されます。
CI/CDパイプライン：コードの変更を自動的にビルド、テスト、デプロイするプロセスです。これにより、高速かつ安定したソフトウェアリリースが可能です。
ドメインコントローラー：Windowsネットワークにおけるセキュリティやユーザーアクセスの設定を管理するサーバーです。一般的には、オンプレミス環境で使用されます。
グループポリシーオブジェクト：Windowsネットワークにおいてパソコンやユーザーの設定を一括管理するための仕組みです。
Deployment Manager：Google Cloudのリソースとサービスの設定やデプロイを管理するツールです。
メンテナンスウィンドウ：システムの定期メンテナンスを実行するために設定された時間帯です。この時間帯は通常、システムのダウンタイムが最も少ないと予想される時間帯に設定されます。
正解についての説明：
（選択肢）
・パッチが利用可能になったら新しいベースイメージをビルドし、CI/CDパイプラインを使用してVMを再構築し、インクリメンタルにデプロイします
この選択肢が正解の理由は以下の通りです。
まず、新しいパッチが利用可能になった時点で新しいベースイメージを作成することで、そのパッチが適用された最新のOSを確実に使用することができます。
また、CI/CDパイプラインを使用してVMを再構築することで、新しいイメージを安全かつ効率的にデプロイすることができます。CI/CDパイプラインは、品質の高いソフトウェアを短期間でリリースするための効率的な方法で、これにより常に最新のOSパッチを適用した状態を保つことができます。
そして、インクリメンタルにデプロイすることで、全体のサービスを停止させることなくパッチを適用することができます。このアプローチは都度パッチを手動で適用するよりも効率的で信頼性が高く、新しいパッチがリリースされた時点で素早く対応することが可能です。
不正解についての説明：
選択肢：ドメインコントローラーをCompute Engineにフェデレートし、グループポリシーオブジェクトを介して毎週パッチをロールアウトします
この選択肢が正しくない理由は以下の通りです。
ドメインコントローラーをCompute Engineにフェデレートし、グループポリシーオブジェクトを通じてパッチをロールアウトするという方法は、Windows Compute EngineのVMが最新のOSパッチを適用していることを確認する手段としては非効率的であり、OSアップデートの適用を自動化するのが難しい上、一部のパッチが適用されない可能性もあります。
これに対し、新しいパッチが利用可能になったら新しいベースイメージをビルドし、CI/CDパイプラインを使用してVMを再構築し、インクリメンタルにデプロイする方法は、OSへのパッチ適用を自動化し、最新の状態を維持するための有効な手段です。
選択肢：Deployment Managerを使用して、更新されたVMを新しいサービングインスタンスグループ（IG）にプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
Deployment Managerを使用して新しいインスタンスグループ（IG）をプロビジョニングすると、更新が必要なパッチが全て適用されていることを確認するとは限りません。
対照的に、新しいベースイメージをビルドし、CI/CDパイプラインを使用することで、すべてのパッチが適用されているVMの最新版を作ることが可能となります。
選択肢：毎週のメンテナンスウィンドウの間にすべてのVMを再起動し、StartUpスクリプトがインターネットから最新のパッチをダウンロードするようにします
この選択肢が正しくない理由は以下の通りです。
すべてのVMを再起動するためには、ダウンタイムが必要となります。一方で新しいベースイメージを作成してCI/CDパイプラインでデプロイする方法は、VMの再起動やダウンタイムを必要としないため、アプリケーションの利用性を維持しつつOSパッチを適用することができます。
参考リンク：
https://cloud.google.com/compute/docs/instances/windows/creating-managing-windows-instances
https://cloud.google.com/compute/docs/instances/windows#install-windows-updates
https://cloud.google.com/solutions/cicd-pipeline-for-compute-engine-deployments
</div></details>

### Q.  問題26: 未回答
あなたは、電子カルテシステムで保護された医療情報（PHI）を扱っています。プライバシー担当者は、機密データが分析システムに保存されていることを懸念しています。あなたは、機密データを元に戻せない方法で匿名化することを命じられています。また、匿名化されたデータは、文字セットと長さを保持する必要があります。
どのGoogle Cloudソリューションを使うべきですか？
1. フォーマット保持暗号化によるCloud Data Loss Prevention
2. Cloud Key Management Serviceでラップされた暗号鍵を使用したCloud Data Loss Prevention
3. AES-SIVを用いた決定論的暗号化によるCloud Data Loss Prevention
4. 暗号ハッシュによるCloud Data Loss Prevention
<details><div>
    答え：4
この問題では、医療情報に対する特別な取り扱いに焦点を当てています。機密データを匿名化する方法を探している上で重要な要素は、データが元に戻せないようにすること、そして同時に文字セットと長さを保持することです。質問の解答を決定するためには、Google Cloudの異なる暗号化とデータ保護のソリューションを理解し、それぞれが提供する匿名化の程度と特性について理解する必要があります。
基本的な概念や原則：
Cloud Data Loss Prevention（DLP）：Google Cloudのデータ損失防止サービスです。機密データを検出、分類、匿名化する機能が提供されます。
暗号ハッシュ：一定長の雑音のような出力を生成するためのアルゴリズムです。元のデータからハッシュを計算することは可能ですが、ハッシュから元のデータを復元することは不可能です。
プライバシー担当者：データプライバシーとデータ保護に関する法令遵守の責任を持つ役職です。一般的には、データの使用、収集、保護、開示に関する方針と手順を開発し、維持する責任があります。
PHI（Protected Health Information）：米国の"健康保険移植性と責任法"（HIPAA）に定義された、特定の18種類の識別子を含む個人の健康情報です。特別な保護が必要とされます。
AES-SIVを用いた決定論的暗号化：同じ平文が同じ暗号文を生成する暗号化方法です。ただし、元の情報を復元することが可能なため、匿名化には適しません。
フォーマット保持暗号化：暗号化されたデータが元のデータと同じ形式を保持する暗号化方法です。ただし、この方法も元の情報を復元することが可能なため、匿名化には適しません。
Cloud Key Management Service：Google Cloud上で暗号キーを管理するためのサービスですが、元の情報を復元することが可能なため、匿名化には適しません。
正解についての説明：
（選択肢）
・暗号ハッシュによるCloud Data Loss Prevention
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのData Loss Prevention（DLP）サービスは、機密データの検出、分類、保護を目的として設計されています。これは、医療情報（PHI）などの機密性の高い情報を扱う際に非常に有用です。
さらに、DLPは暗号ハッシュを使用して機密データを一方向に変換し、元のデータに戻すことが不可能にします。これは要求されている匿名化の条件を満たしています。
匿名化されたデータは、元のデータの特性を保持する必要があるという要件に対してもDLPは対応可能です。暗号ハッシュされたデータは、元の文字セットと長さを保持します。
したがって、これらの要件を満たすためには、暗号ハッシュによるCloud Data Loss Preventionを使用することが最適となります。
不正解についての説明：
選択肢：AES-SIVを用いた決定論的暗号化によるCloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
AES-SIVを用いた決定論的暗号化は、元のデータを復元可能な暗号化手法であり、要件である"機密データを元に戻せない方法で匿名化"する方法としては不適合です。
それに対して、暗号ハッシュは一方向性があり、元のデータへの復元が困難であり、この要件を満たします。
選択肢：フォーマット保持暗号化によるCloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
フォーマット保持暗号化によるCloud Data Loss Preventionは、元のデータを元に戻せるため、命じられた要件である機密データを元に戻せない方法で匿名化することを達成できません。
一方、暗号ハッシュによるCloud Data Loss Preventionは、元のデータを復元不可能にするハッシュ関数を使用するため、要件に最も符合します。
選択肢：Cloud Key Management Serviceでラップされた暗号鍵を使用したCloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Serviceでラップされた暗号鍵を使用したCloud Data Loss Preventionだと、暗号鍵を用いることで元のデータに戻すことが可能になるため、機密データを元に戻せない方法で匿名化するという要件を満たすことができません。対して暗号ハッシュによるCloud Data Loss Preventionは一方通行の暗号化であり、元のデータに戻すことができないので要件を満たします。
参考リンク：
https://cloud.google.com/dlp/docs/concepts-hashing
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/dlp/docs/encrypting-cloud-kms
</div></details>

### Q.  問題27: 未回答
HTTPSリソースにアクセスするために、Identity and Access Management（IAM）ユーザーに付与すべきIdentity-Aware Proxyロールはどれですか？
1. IAPセキュアトンネルユーザー
2. セキュリティレビュアー
3. IAPセキュアWebアプリユーザー
4. サービスブローカーオペレーター
<details><div>
    答え：3
この問題では、Google CloudのIdentity-Aware Proxy（IAP）に関連するロールとその機能を理解することが求められています。特にHTTPSリソースへのアクセスの許可を持つIAPロールを選択する必要があります。選択肢には、各種IAPロールが含まれていますが、問題文の要件と一致するロールを選ぶことを心掛けましょう。そのためには、各ロールがどのような許可を持つのかを理解する必要があります。
基本的な概念や原則：
Identity-Aware Proxy（IAP）：Google Cloudのアプリケーションへのセキュアなアクセスを提供するサービスです。公開URLを経由しても、IAPがリクエストの認証とコンテキストベースのアクセス制御を行います。
IAPセキュアWebアプリユーザー：HTTPやHTTPSリソースにアクセスできるIdentity-Aware Proxyのロールです。ユーザーやサービスアカウントに付与されます。
Identity and Access Management（IAM）：Google Cloudリソースへのアクセス制御を中央で管理するサービスです。誰がどのリソースにどのようなアクションを実行できるかを管理します。
IAMロール：特定のリソースに対して許可または拒否される一連の権限です。ユーザー、グループ、またはサービスアカウントに付与することでアクセス制御を行います。
正解についての説明：
（選択肢）
・IAPセキュアWebアプリユーザー
この選択肢が正解の理由は以下の通りです。
まず、IAMのロールは特定のタスクを実行するためにユーザーに付与される権限のセットを定義しますが、その中でも"IAPセキュアWebアプリユーザー"ロールは、Identity-Aware Proxy（IAP）によって保護されたHTTPリソースへのアクセスを可能にするロールです。IAPはGoogle Cloudのサービスで、アクセス制御と脅威の検出を行い、アプリケーションに対して認証と認可を提供します。
したがって、"IAPセキュアWebアプリユーザー"ロールをユーザーに付与することで、HTTPSリソースへのアクセス権が付与されます。
したがって、ユーザーがHTTPSリソースにアクセスするためには"IAPセキュアWebアプリユーザー"ロールが必要となります。
不正解についての説明：
選択肢：セキュリティレビュアー
この選択肢が正しくない理由は以下の通りです。
セキュリティレビュアーロールはIAMのポリシーを確認する権限を持っていますが、そのユーザーがHTTPSリソースにアクセスする権限は付与されません。
それに対して、IAPセキュアWebアプリユーザーロールはIAPを通じたHTTPSリソースへのアクセス権限を付与するため、この問題の要件に合致します。
選択肢：IAPセキュアトンネルユーザー
この選択肢が正しくない理由は以下の通りです。
IAPセキュアトンネルユーザーはユーザーがアプリをクラウドサービスに安全に接続する際に使用されますが、HTTPSリソースへのアクセス権限を付与するには不適切です。
それに対して、IAPセキュアWebアプリユーザーはHTTPSリソースへのアクセス権限を付与するために必要なロールです。
選択肢：サービスブローカーオペレーター
この選択肢が正しくない理由は以下の通りです。
サービスブローカーオペレーターはGoogle Cloud Service Brokerの管理に関連する権限を持っていますが、HTTPSリソースへのアクセス許可には関係がありません。
それに対し、IAPセキュアWebアプリユーザーはIdentity-Aware Proxyを通じてHTTPSリソースへのアクセスを許可するロールであるため、適切な選択です。
参考リンク：
https://cloud.google.com/iap/docs/managing-access#member
https://cloud.google.com/iap/docs/using-tcp-forwarding
https://www.youtube.com/watch?v=7d81SfTTw04
</div></details>

### Q.  問題28: 未回答
あなたは、Google Cloud環境の中央セキュリティ制御を定義しています。組織内のフォルダの1つに対して、VMへの外部IPアドレスの割り当てを拒否する組織ポリシーを設定しました。2日後、そのフォルダの下に外部IPアドレスを持つ新しいVMに関するアラートを受信しました。
このアラートの原因は何ですか？
1. プロジェクトレベルでは、組織ポリシーコントロールが "allow"値で上書きされています
2. 組織ポリシーの制約が適切に実施されず、"ドライラン"モードで実行されています
3. フォルダレベルのポリシー制約は、組織レベルでその制約の "allow"値があるため、何の効果もありません
4. VMは、組織ポリシールールが設定される前にプロジェクトで予約された静的な外部IPアドレスで作成されました
<details><div>
    答え：1
この問題では、Google Cloud環境のセキュリティ設定と、その設定後に起こった事象の関連性を理解することが必要です。特に、あるフォルダが組織ポリシーによってVMへの外部IPアドレスの割り当てを拒否されているにも関わらず、そのフォルダが外部IPアドレスを持つ新しいVMに関するアラートを受け取った事象に焦点を絞り、その原因を探る必要があります。選択肢を見るとき、そのセキュリティ設定がどのように逸脱された可能性があるか考えることが求められています。
基本的な概念や原則：
組織ポリシー：Google Cloudリソースに対して定義可能な制約のセットです。セキュリティ、コンプライアンス、またはコスト管理に関連するルールを組織全体で統一的に適用するのに役立ちます。
ポリシーの継承：Google Cloudのリソース階層では、ポリシーは上位から下位に継承されます。したがって、フォルダやプロジェクトで定義されたポリシーは、その上位レベル（組織）から継承したポリシーを上書きすることが可能です。
IPアドレス割り当て：VMに外部や内部のIPアドレスを割り当てる操作です。組織ポリシーでは、これを許可するかどうか制御することが可能です。
静的IPアドレス：Google Cloud環境でVMに割り当てることが可能な、固定のIPアドレスです。VMが再起動しても変更されません。
リソース階層：Google Cloudでは、リソースは階層的に整理され、この階層を通じてポリシーが継承されます。最上位には組織があり、その下にフォルダ、プロジェクト、リソース（VMなど）があります。
正解についての説明：
（選択肢）
・プロジェクトレベルでは、組織ポリシーコントロールが "allow"値で上書きされています
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、ポリシーの継承が設定されており、上位階層の組織ポリシー設定が下位階層に継承されます。しかし、下位のレベル（たとえばプロジェクトレベルなど）で特定のポリシーを上書きして設定することも可能です。この場合、その上書きされた設定が反映されます。
したがって、組織レベルであるフォルダに設定された外部IPアドレスの割り当てを拒否する組織ポリシーがあるにも関わらず、そのフォルダの下に新しいVMが外部IPアドレスを持つ形で作成されてしまう場合、その原因として考えられるのは、プロジェクトレベルで組織ポリシーコントロールが "allow"値で上書きされていたからです。
このように、組織ポリシーは階層構造を持ち、下位のレベルで上位階層のポリシーを上書きすることができる点を理解することが重要です。
不正解についての説明：
選択肢：VMは、組織ポリシールールが設定される前にプロジェクトで予約された静的な外部IPアドレスで作成されました
この選択肢が正しくない理由は以下の通りです。
組織ポリシーは予約済みの外部IPアドレスにも適用され、既存のリソースに対する影響も及ぼします。
したがって、ポリシールール設定前に予約されたIPでも制御は効力を持つため、この選択肢は適切ではありません。正解はフォルダレベルのポリシーがプロジェクトレベルで上書きされた場合に該当します。
選択肢：組織ポリシーの制約が適切に実施されず、"ドライラン"モードで実行されています
この選択肢が正しくない理由は以下の通りです。
"ドライラン"モードは、リソースを使用せずに設定やツールをテストするためのモードであり、組織ポリシーの制約適用とは異なります。正解はプロジェクトレベルでのポリシーコントロールが上書きされるため、組織レベルのポリシーが適切に適用されない場合があります。
選択肢：フォルダレベルのポリシー制約は、組織レベルでその制約の "allow"値があるため、何の効果もありません
この選択肢が正しくない理由は以下の通りです。
Google Cloudでは組織ポリシーは階層性を持ち、より詳細なレベル（例：プロジェクトレベル）で設定したポリシーが上位レベル（例：フォルダレベル）のポリシーを上書きします。
この問題では、プロジェクトレベルで上書きされているため、アラートが発生した可能性があることから、正解は"プロジェクトレベルでは、組織ポリシーコントロールが "allow"値で上書きされています"になります。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/understanding-hierarchy
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address#reserve_new_static
</div></details>

### Q.  問題29: 未回答
あなたの会社は、Google Cloud上に個人情報を保存するウェブサイトを運営しています。データプライバシー規制を遵守するため、このデータは特定の期間のみ保存することができ、特定の期間が経過したら完全に削除する必要があります。まだその期間に達していないデータは削除されるべきではありません。この規制を遵守するためのプロセスを自動化したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. データを1つのCloud Storageバケットに保存し、バケットのTime to Liveを設定します
2. データを1つのBigQueryテーブルに格納し、適切なテーブルの有効期限を設定します
3. データを1つのBigTableテーブルに格納し、カラムファミリーに有効期限を設定します
4. データを1つの永続ディスクに保存し、期限切れ時にディスクを削除します
<details><div>
    答え：1
この問題では、データ保存期間とその自動化を遵守するための質問です。企業はデータプライバシー規制を遵守し、データの保管期間が経過すると自動的にそれを完全に削除したいと考えています。ここで重要なのは、特定の期間が過ぎたデータのみを削除し、まだ期間が経過していないデータは削除しないという要件です。選択肢の中でこの条件を満たす最適なオプションを決定する際には、Google Cloudの各種ストレージ及びデータ管理サービスの具体的な機能とロールを理解することが不可欠です。
基本的な概念や原則：
Cloud Storageバケット：Google Cloudのオブジェクトストレージサービスで、大量のデータを保存し、管理するための場所（バケット）です。
Time to Live：データが保存される期間を設定するメカニズムです。この期間が経過すると、データは自動的に削除されます。
永続ディスク：Google Cloudのブロックストレージサービスです。永続ディスクはデータを長期間保存するための手段ですが、自動的に期間経過による削除機能は提供していません。
BigQuery：Google Cloudのフルマネージドな大規模データウェアハウスです。ただし、テーブルレベルでのTTL（Time to Live）機能を提供していません。
BigTable：Google CloudのNoSQLビッグデータデータベースサービスです。ハイスループットな読み書きが可能で、1TB以上のデータを保存可能ですが、カラムファミリーに有効期限を設定する機能は提供していません。
正解についての説明：
（選択肢）
・データを1つのCloud Storageバケットに保存し、バケットのTime to Liveを設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageのオブジェクトのライフサイクル管理機能を用いることで、特定の条件を満たしたデータ（この場合は一定の期間が経過したデータ）の削除を自動化することができます。これにより、データ削除の手間を減らし、データプライバシー規制の遵守をサポートします。
特に"Time to Live（TTL）"の設定を利用すると、データが指定した期間が経過した時点で自動的に削除されるようにすることができます。この設定はバケットレベルで行われるため、全体的なデータ管理ポリシーの一部として扱うことが可能です。
したがって、特定の期間が経過したデータを完全に削除する必要がある場合には、この選択肢が最も適切な解決策と言えます。
不正解についての説明：
選択肢：データを1つの永続ディスクに保存し、期限切れ時にディスクを削除します
この選択肢が正しくない理由は以下の通りです。
なぜなら、永続ディスク全体を削除すると、期限が過ぎていないデータまで削除されてしまいます。
逆に、Cloud StorageのTime to Liveを用いれば、各オブジェクトの期限を別々に制御し期限切れデータのみ削除できます。
選択肢：データを1つのBigQueryテーブルに格納し、適切なテーブルの有効期限を設定します
この選択肢が正しくない理由は以下の通りです。
BigQueryテーブルの有効期限はテーブル全体に適用されるため、特定の期間が過ぎたデータだけを削除するという要求を満たせません。
それに対して、Cloud StorageバケットのTime to Live設定は個別のオブジェクトに適用できるため、期限切れのデータだけを自動的に削除することが可能です。
選択肢：データを1つのBigTableテーブルに格納し、カラムファミリーに有効期限を設定します
この選択肢が正しくない理由は以下の通りです。
BigTableのカラムファミリーに有効期限を設定することは、それが行単位ではなくカラム単位でデータを論理的にグループ化するためのもので、データ保存期間の管理には使用できません。
一方、Cloud StorageのTime to Live機能は、オブジェクトの保存期間を自動的に管理できます。
参考リンク：
https://cloud.google.com/storage/docs/managing-lifecycles
https://cloud.google.com/bigquery/docs/table-expiration
https://cloud.google.com/bigtable/docs/creating-managing-column-families#setting-gc-policy
</div></details>

### Q.  問題30: 未回答
あなたは金融会社のセキュリティエンジニアです。あなたの会社はGoogle Cloud上にデータを保存する予定ですが、あなたの会社の経営陣は機密性の高いデータのセキュリティを心配しています。特に、Google社内の社員がGoogle Cloud上の自社のデータにアクセスできることを懸念しています。
どのようなソリューションを提案すべきですか？
1. 管理者のアクティビティログを有効にして、リソースへのアクセスを監視します
2. Google従業員のアクセス承認リクエストで、アクセスの透明性ログを有効にします
3. GoogleのIAM（Identity and Access Management）サービスを使用して、Google Cloud上のアクセス制御を管理します
4. 顧客が管理する暗号鍵を使用します
<details><div>
    答え：2
この問題では、会社のデータセキュリティへの懸念とGoogle Cloudにおけるソリューションの選択肢を理解することが求められています。特に、Google社内の社員がGoogle Cloud上の自社のデータにアクセスできることへの懸念を解消するための適切なソリューション選択です。選択肢からは、Google Cloudの異なるセキュリティ機能について理解していることが必要であり、どの機能が提起された特定のセキュリティ懸念を解消するのかを判断する力が求められます。
基本的な概念や原則：
アクセスの透明性：Googleのエンジニアやサポートスタッフがアクセスを試みた場合にリアルタイムのログを提供する機能です。これにより、Googleの従業員が自社のデータにアクセスした記録を監視・監査することができます。
暗号鍵管理：データの暗号化に使われる鍵を管理することです。顧客が自己管理する鍵では、Googleの従業員自体は暗号化されたデータにアクセスできても、解読することはできません。
Identity and Access Management（IAM）：ユーザーやサービスアカウントの権限を管理するシステムです。特定のリソースへのアクセスを許可、または拒否することができます。
管理者のアクティビティログ：Google Cloudリソースに対する管理者活動を監査するためのログです。これにより、リソースの作成、変更、削除などのアクティビティを追跡できます。しかし、Googleの従業員がデータにアクセスした記録についてはアクセスの透明性が必要です。
正解についての説明：
（選択肢）
・Google従業員のアクセス承認リクエストで、アクセスの透明性ログを有効にします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudのアクセス透明性ログは、Googleのエンジニアやサポートスタッフがユーザーの専用環境にアクセスした際の詳細なログ情報を提供する機能です。これには、対象のリソース、アクセスの理由、アクセスした人の役職とデータへのアクセス時刻などが含まれます。Google従業員のアクセス承認リクエストの透明性ログを有効にすることで、判断と評価を行うための詳細かつ有用な情報が提供されます。これらの情報は、セキュリティ監査と規制の遵守において重要であり、経営陣が懸念する機密データのセキュリティを強化します。
したがって、Google従業員のアクセス承認リクエストで、アクセスの透明性ログを有効にするという選択肢は、セキュリティリスクを軽減する有効なソリューションです。
不正解についての説明：
選択肢：顧客が管理する暗号鍵を使用します
この選択肢が正しくない理由は以下の通りです。
顧客が管理する暗号鍵を使用する方法では、Googleの社員がデータにアクセスする可能性を完全に排除することはできません。ただし、アクセスの透明性ログを有効にすることで、Google社員のアクセス承認リクエストを記録し監視することが可能となります。これにより、会社の要件により適合したセキュリティ対策となります。
選択肢：GoogleのIAM（Identity and Access Management）サービスを使用して、Google Cloud上のアクセス制御を管理します
この選択肢が正しくない理由は以下の通りです。
GoogleのIAMはアクセス制御を管理するものであり、Google従業員のアクセスについての特別な規定はありません。透明性ログを有効にすることで、Google社内のアクセスリクエストを覗き見て、経営陣の懸念を解消することができます。
選択肢：管理者のアクティビティログを有効にして、リソースへのアクセスを監視します
この選択肢が正しくない理由は以下の通りです。
管理者のアクティビティログは主に自社のGoogle Cloudプロジェクト内での管理者の活動を追跡するためのもので、Google社内の社員が自社のデータにアクセスした時のログには対応していません。
一方、透明性ログを有効にすれば、Google従業員によるリソースへのアクセス承認リクエストが記録されます。
参考リンク：
https://cloud.google.com/access-transparency
https://cloud.google.com/access-approval/docs
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題31: 未回答
あなたの会社ではGSuiteを使用しており、Google App Engine上で社内向けのアプリケーションを開発しています。従業員のパスワードが漏洩した場合でも、外部ユーザーがアプリケーションにアクセスできないようにする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. GSuiteですべてのユーザーに2要素認証を適用します
2. プライベートネットワークとGoogle Cloudの間にCloud VPNを設定します
3. GSuite Password Syncを使用してユーザーパスワードをプロビジョニングします
4. App EngineアプリケーションのCloud Identity-Aware Proxyを構成します
<details><div>
    答え：1
この問題では、従業員のパスワードが漏洩した場合でも外部ユーザがアプリケーションにアクセスできないようにするための対策方法を問われています。ここで重要なポイントは、一度パスワードが漏洩した場合でもアクセスをブロックするための追加の認証手段を検討することです。したがって各選択肢を見る際には、これがどのようにそれを達成するかを考えることが必要になります。
基本的な概念や原則：
GSuite：Googleが提供するクラウドベースのプロダクティビティツールのスイートです。メール、カレンダー、ドキュメント共有などの機能を提供します。
2要素認証：パスワード以外にもう一つの認証要素を必要とする認証手法です。パスワードが漏洩した場合でも、第二の証明がなければアクセスできません。
Google App Engine：アプリケーションを開発し、ホストするためのフルマネージドなプラットフォームです。スケーラビリティと高可用性を提供します。
Cloud Identity-Aware Proxy：Google Cloudのリソースへのアクセスを管理するツールです。ユーザーとデバイスの認証および承認を行いますが、パスワードが既に漏洩している場合は十分な保護を提供しません。
GSuite Password Sync：GSuiteのパスワードをActive Directoryと同期させるツールです。パスワードのリセットや同期を自動化しますが、パスワードが既に漏洩している場合は十分なセキュリティを提供しません。
Cloud VPN：Google Cloudとプライベートネットワーク間のセキュアな接続を確立するツールですが、パスワード漏洩に対する防御機能は提供しません。
正解についての説明：
（選択肢）
・GSuiteですべてのユーザーに2要素認証を適用します
この選択肢が正解の理由は以下の通りです。
まず、二要素認証はユーザーのパスワードが漏洩した場合でも、不正なユーザーがシステムに侵入するのを防ぐための非常に強力な手段です。二要素認証は、パスワードだけでなく別の認証手段（例えば、SMSメッセージ、ハードウェアトークン、またはモバイルアプリからのプッシュ通知）を必要とするため、もしユーザーのパスワードが漏洩しても、2つ目の認証要素がなければ悪意のあるユーザーはシステムにアクセスできません。
また、GSuiteを使用している場合、管理者は会社全体に対して二要素認証を強制することができます。これにより、全てのユーザーが二要素認証を使用することを保証し、組織全体のセキュリティを強化することができます。この機能は、アプリケーションとデータを保護するための重要なセキュリティ対策として非常に効果的です。
したがって、GSuiteで2要素認証を適用することは、パスワードが漏洩した場合でもアプリケーションへの不正アクセスを防ぐための最適な選択肢となります。
不正解についての説明：
選択肢：App EngineアプリケーションのCloud Identity-Aware Proxyを構成します
この選択肢が正しくない理由は以下の通りです。
Cloud Identity-Aware Proxyを構成する方法は、アプリケーションへのアクセス制御を実現しますが、パスワード漏洩時に外部ユーザーのアクセスを阻止する能力はありません。
一方、GSuiteで2要素認証を適用すると、パスワードだけでなく2つ目の要素も必要になり、パスワードが漏洩した際のリスクを軽減します。
選択肢：GSuite Password Syncを使用してユーザーパスワードをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
GSuite Password SyncはGSuiteとActive Directoryパスワードを同期するツールですが、パスワード漏洩時に外部ユーザーのアクセス予防には寄与しません。
それに対して、2要素認証はパスワードだけでなく別の認証要素が必要となり、漏洩時の安全性が高まります。
選択肢：プライベートネットワークとGoogle Cloudの間にCloud VPNを設定します
この選択肢が正しくない理由は以下の通りです。
Cloud VPNを設定することによって、プライベートネットワークとGoogle Cloudとの間のセキュアな接続は確立されますが、これはユーザーのパスワードが漏洩した際に外部ユーザーのアクセスを防ぐという要件とは直接関係はないです。逆に2要素認証を用いると、パスワードだけでなく二つ目の要素も必要になるため、パスワード漏洩後も不正アクセスを防ぐことができます。
参考リンク：
https://cloud.google.com/identity/docs/how-to/setup-two-step-verification
https://cloud.google.com/iap/docs/app-engine-quickstart
https://cloud.google.com/vpn/docs/concepts/overview
</div></details>

### Q.  問題32: 未回答
ユーザーがGoogle Cloudとやり取りできるようにするために、Google Cloudの組織で何百ものエフェメラルプロジェクトをデプロイする新しいインフラストラクチャCI/CDパイプラインを作成しています。Googleが推奨するベストプラクティスに従いつつ、組織内のデフォルトネットワークの使用を制限したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. ユーザに、組織レベルでIAM Ownerロールを付与します。プロジェクトの周囲に、compute.googleapis.com APIを制限するVPC Service Controlsの境界を作成します
2. デフォルトのネットワークの作成をスキップしてデプロイできる、定義済みのインフラストラクチャテンプレートセットを持つCI/CDパイプラインだけをユーザーに使用させます
3. 組織レベルで、constraints/compute.skipDefaultNetworkCreation組織ポリシー制約を有効にします
4. 各プロジェクトのデフォルトのネットワークをすべて自動的に削除するために、毎日Cloud Functionsをトリガーするcronジョブを作成します
<details><div>
    答え：3
この問題では、数百ものエフェメラルプロジェクトをデプロイする新しいインフラストラクチャCI/CDパイプラインを作成しており、その際に組織内のデフォルトネットワークの使用を制限したいという要件について考える必要があります。注目すべきは、Googleが推奨するベストプラクティスに従うことと、組織レベルでの管理が必要であることです。また、エフェメラルプロジェクトの多数生成という状況を考慮に入れることで、それぞれのプロジェクトに対する個別の管理ではなく、一括した管理策が必要となります。すなわち、組織全体を対象とした制約の設定が問われています。
基本的な概念や原則：
組織ポリシー：Google Cloudリソースの設定と制御に使用されるポリシーです。特定のリソースに対する行動を制限するために使用します。
constraints/compute.skipDefaultNetworkCreation：この組織ポリシー制約は、プロジェクト作成時のデフォルトネットワークの自動作成を制御します。有効にすると、新規プロジェクトのデフォルトネットワーク作成をスキップします。
Cloud Functions：イベント駆動型のサーバーレスアプリケーションを作成・変更するためのGoogle Cloudのサーバーレス実行環境です。
VPC Service Controls：サービス間のネットワークデータの流れを制御するためのGoogle Cloudのセキュリティ機能です。特定のAPIの使用を制限したり、サービスデータの共有を制御したりすることが可能です。
IAM Ownerロール：特定のリソースに対する全てのIAMポリシーを設定することができるロールです。このロールを持つユーザーはリソースを削除したり、新しいリソースを作成したりすることができます。
CI/CDパイプライン：継続的インテグレーションと継続的デリバリーのプロセスです。開発とテストのステージを自動化し、ソフトウェアリリースを効率的にします。
正解についての説明：
（選択肢）
・組織レベルで、constraints/compute.skipDefaultNetworkCreation組織ポリシー制約を有効にします
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、新しいプロジェクトが作成されると、デフォルトで標準のVPCネットワークが自動的に作成されます。これは管理が難しく、セキュリティ上の問題を引き起こす可能性があります。
したがって、何百ものエフェメラルプロジェクトが頻繁に作成されるこのシナリオでは、デフォルトネットワークの自動作成を防ぐことが重要です。これを達成するために、constraints/compute.skipDefaultNetworkCreationという組織ポリシー制約を有効にすればよいです。この制約が有効になると、新しいプロジェクトが作成されたときにデフォルトネットワークが自動的に作成されなくなります。これにより、組織内のネットワーク使用を制限し、セキュリティを維持することが可能になります。
不正解についての説明：
選択肢：各プロジェクトのデフォルトのネットワークをすべて自動的に削除するために、毎日Cloud Functionsをトリガーするcronジョブを作成します
この選択肢が正しくない理由は以下の通りです。
毎日Cloud Functionsをトリガーするような手動の操作は、非効率かつエラーが起きやすい方法です。正解の選択肢であるconstraints/compute.skipDefaultNetworkCreation組織ポリシー制約を有効にすることで、デフォルトネットワークの作成を自動的に無効化でき、より効果的に管理できます。
選択肢：ユーザに、組織レベルでIAM Ownerロールを付与します。プロジェクトの周囲に、compute.googleapis.com APIを制限するVPC Service Controlsの境界を作成します
この選択肢が正しくない理由は以下の通りです。
ユーザーにIAM Ownerロールを付与すると、彼らはデフォルトネットワークを含むすべてのリソースへの全権アクセスを持つため、使用制限の目的を達成できません。VPC Service ControlsはAPIのアクセスを制限しますが、デフォルトネットワークの使用を制限する機能はありません。
選択肢：デフォルトのネットワークの作成をスキップしてデプロイできる、定義済みのインフラストラクチャテンプレートセットを持つCI/CDパイプラインだけをユーザーに使用させます
この選択肢が正しくない理由は以下の通りです。
テンプレートセットの使用はデフォルトネットワークの作成を制御する直接的な手段ではありません。
それに対して、組織ポリシー制約を有効化するという選択肢は、デフォルトネットワークの作成自体を停止し、制御を厳密に行うことが可能です。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/vpc/docs/using-vpc-service-controls
https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview
</div></details>

### Q.  問題33: 未回答
あなたのセキュリティチームは、Cloud Storageのバケットに保存された機密データを保護するために、徹底的な防御アプローチを導入したいと考えています。あなたのチームには以下の要件があります：
- プロジェクトAのCloud Storageバケットは、プロジェクトBからのみ読み取り可能です。
- プロジェクトAのCloud Storageバケットにはネットワーク外部からアクセスできません。
- Cloud Storageバケット内のデータを外部のCloud Storageバケットにコピーできません。
セキュリティチームは何をすべきですか？
1. VPC Service Controlsを有効にし、プロジェクトAとBの周囲に境界を作成し、Cloud Storage APIをService Perimeter構成に含めます
2. 組織ポリシーでドメイン制限共有を有効にし、Cloud Storageバケットでバケットレベルの統一アクセスを有効にします
3. プロジェクトAとBの両方のネットワークで、ネットワーク間の通信を許可する厳密なファイアウォールルールでプライベートアクセスを有効にします
4. プロジェクトAとBのネットワーク間でVPCピアリングを有効にし、ネットワーク間の通信を許可する厳格なファイアウォールルールを設定します
<details><div>
    答え：1
この問題では、特定の条件下でのCloud Storageバケットのセキュリティ設定を理解することが求められています。問題文から、プロジェクトAのバケットはプロジェクトBからのみ読み取ることが可能で、ネットワーク外部からのアクセスは不可であり、またバケット内のデータを外部のCloud Storageバケットにコピーすることもできないという要件が明らかになります。これより、ある特定のプロジェクトと他のプロジェクトとの相互のアクセス制御、ネットワークからのアクセス制御、そしてデータの外部へのコピーコントロールが求められています。これらを満たすために最も適切なGoogle Cloudの機能やサービスを選択することが問題の解法の鍵となります。
基本的な概念や原則：
VPC Service Controls：Google Cloudのサービスを使う際のデータの送受信を制御するサービスです。サービスとデータの間にセキュリティ境界を設定し、境界を越えるデータ流出を防ぎます。
Service Perimeter：VPC Service Controlsで定義されたセキュリティの境界です。特定のサービス、リソース、APIへのアクセスを制限します。
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、安全かつ耐久性の高いデータの格納、取得を実現します。
ドメイン制限共有：特定のドメインに対してのみリソースへのアクセスを許可するGoogle Cloudのセキュリティポリシーです。ただし、バケット間のデータ移動を制限することはできません。
バケットレベルの統一アクセス：Cloud Storageにおいて、バケット全体で一元化されたアクセス制御を有効にする設定です。オブジェクトごとに異なるアクセス制御を設定することはできません。
プライベートアクセス：Google Cloud上の仮想プライベートネットワーク（VPC）から、Google Cloudのパブリックサービスへのアクセスを許可する設定です。ただし、これだけで外部ネットワークからのアクセスを制限することはできません。
VPCピアリング：異なるVPCネットワーク間でプライベートな通信を可能にする接続方式です。ただし、これだけで特定のプロジェクトからのアクセスのみを許可する設定はできません。
正解についての説明：
（選択肢）
・VPC Service Controlsを有効にし、プロジェクトAとBの周囲に境界を作成し、Cloud Storage APIをService Perimeter構成に含めます
この選択肢が正解の理由は以下の通りです。
まず、VPC Service ControlsはGoogle Cloudのサービスで、仮想プライベートクラウド（VPC）内のデータの流出を防止するために、特定のサービスに対するアクセスを制御する機能を提供しています。これは、プロジェクトAのCloud Storageバケットがネットワーク外部からアクセスされるのを防ぐための対策として有効です。
また、Service Perimeterは、VPC Service Controlsの一部で、特定のサービスとリソースへのアクセスを制限する境界を設定します。この境界をプロジェクトAとBの周囲に設定することで、プロジェクトBからプロジェクトAのCloud Storageバケットに対して読み取りアクセスを許可することが可能となります。
さらに、Cloud Storage APIをService Perimeterの構成に含めることで、Cloud Storageバケット内のデータが外部のCloud Storageバケットにコピーされるのを防ぐことができます。
したがって、この選択肢は、セキュリティチームの要件をすべて満たしています。
不正解についての説明：
選択肢：組織ポリシーでドメイン制限共有を有効にし、Cloud Storageバケットでバケットレベルの統一アクセスを有効にします
この選択肢が正しくない理由は以下の通りです。
組織ポリシーでドメイン制限共有を有効にしても、プロジェクト間のアクセス制限やネットワーク外部からのアクセス制限、特定のAPIの使用を制限することはできません。これらの要件を満たすには、VPC Service Controlsを使用してサービスパーバイオを設定する必要があります。
選択肢：プロジェクトAとBの両方のネットワークで、ネットワーク間の通信を許可する厳密なファイアウォールルールでプライベートアクセスを有効にします
この選択肢が正しくない理由は以下の通りです。
プライベートアクセスとファイアウォールルールは、ネットワーク内の通信に関連がありますが、Google Cloud Storageへのアクセスを制限するための適切な手段ではありません。VPC Service Controlsを使用すると、サービス間のデータの流れを管理して機密データを保護することができるため、問題の要求を満たす最適な方法となります。
選択肢：プロジェクトAとBのネットワーク間でVPCピアリングを有効にし、ネットワーク間の通信を許可する厳格なファイアウォールルールを設定します
この選択肢が正しくない理由は以下の通りです。
VPCピアリングとファイアウォールルールはネットワークレベルでの制御を提供しますが、Cloud Storageバケットへのアクセスの制限や、Cloud Storage内のデータのコピーを防ぐための制御は提供しません。
一方、VPC Service Controlsはこれらの要件を満たす制御を提供します。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs
https://cloud.google.com/storage/docs/uniform-bucket-level-access
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-domains
</div></details>

### Q.  問題34: 未回答
Google Cloud Armorポリシーを使用して、クロスサイトスクリプティング（XSS）やSQLインジェクション（SQLi）などの一般的な攻撃がWebアプリケーションのバックエンドに到達するのを防ぐことを計画しています。
Google Cloud Armorセキュリティポリシーを使用するための2つの要件は何ですか？（2つ選択）
1. Google Cloud Armor Policyのルールは、レイヤー7（L7）属性にのみマッチします
2. ロードバランサーは外部SSLプロキシロードバランサーでなければなりません
3. ロードバランサーはプレミアムネットワークサービスティアを使用する必要があります
4. バックエンドサービスの負荷分散スキームはEXTERNALでなければなりません
5. ロードバランサーは外部HTTP(S)ロードバランサーでなければなりません
<details><div>
    答え：4,5
この問題では、Google Cloud Armorの使用上の設定要件について問われています。まず、Google Cloud ArmorはWebアプリケーションのバックエンドに対する攻撃を防ぐためのものであることに注意が必要です。そのため、設定に関する要件は、ロードバランサーやバックエンドサービス、などのネットワーク設定に関連したものが出てくることを想定する必要があります。選択肢を見た時、それぞれの選択肢がGoogle Cloud Armorに関連する具体的な要件を述べているかどうかを注意深く評価してください。
基本的な概念や原則：
Google Cloud Armor：一般的なウェブベースの脅威（例えば、クロスサイトスクリプティング（XSS）やSQLインジェクション（SQLi）など）に対して保護を提供するGoogle Cloudのサービスです。
バックエンドサービスの負荷分散スキーム：バックエンドに負荷を分散するための方式を指します。EXTERNALスキームは、Google Cloud Armorでのセキュリティポリシーを使用するための必要条件です。
外部HTTP(S)ロードバランサー：Google Cloudのロードバランサーの一種で、外部からのトラフィックをバランスするために使用されます。Google Cloud Armorでのセキュリティポリシーを使用するための必要条件です。
外部SSLプロキシロードバランサー：Google Cloudのロードバランサーの一種で、SSL/TLSトラフィックをバランスするために使用されます。しかし、Google Cloud Armorでのセキュリティポリシー使用には不適合です。
レイヤー7（L7）属性：OSIモデルの最上位レイヤーでアプリケーションの通信を扱います。Google Cloud ArmorのルールはL3、L4トラフィック属性にもマッチすることができます。
：Google Cloudのネットワーク提供モデルで、最高のパフォーマンスを提供します。しかし、Google Cloud Armorの利用条件には含まれません。
正解についての説明：
（選択肢）
・バックエンドサービスの負荷分散スキームはEXTERNALでなければなりません
・ロードバランサーは外部HTTP(S)ロードバランサーでなければなりません
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Armorは、DDoS攻撃やWeb攻撃への防御機能を提供するセキュリティサービスで、エッジネットワークレベルでの保護機能を提供します。これは主に外部からの攻撃を防ぐために設計されており、そのためにはバックエンドサービスの負荷分散スキームがEXTERNALである必要があります。つまり、Google Cloud Armorは公開されるバックエンドサービスに適用され、インターネットトラフィック全体を保護します。
次に、Google Cloud ArmorはHTTP(S)のロードバランシングと密接に統合されています。よって、フロントエンドには外部HTTP(S)ロードバランサーを使用する必要があります。外部HTTP(S)ロードバランサーは公開されたアプリケーションへの全てのトラフィックを処理し、その後Google Cloud Armorによってポリシーが適用されます。このロードバランサーは、クロスサイトスクリプティング（XSS）やSQLインジェクション（SQLi）などの攻撃をフィルタリングし、これらがウェブアプリケーションのバックエンドへ到達するのを防ぎます。
不正解についての説明：
選択肢：ロードバランサーは外部SSLプロキシロードバランサーでなければなりません
この選択肢が正しくない理由は以下の通りです。
Google Cloud ArmorはHTTP(S)のトラフィックに対する脅威と攻撃の防御を提供しますが、SSLプロキシロードバランサーでは対応していません。そのため、ロードバランサーが外部HTTP(S)ロードバランサーである必要があります。
選択肢：Google Cloud Armor Policyのルールは、レイヤー7（L7）属性にのみマッチします
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armor PolicyはL7属性だけでなく、L3およびL4属性（IPアドレスやポート番号など）にもマッチさせることができます。
一方、ロードバランサーが外部HTTP(S)であり、バックエンドサービスの負荷分散スキームがEXTERNALである必要があるのは、Google Cloud Armorが該当の環境でしか動作しません。
選択肢：ロードバランサーはプレミアムネットワークサービスティアを使用する必要があります
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorを使用するためには、外部HTTP(S)ロードバランサーが必要ですが、プレミアムネットワークサービスティアを使用する必要はありません。この場合、ロードバランサーは、スタンダードネットワークサービスティアとプレミアムネットワークサービスティアのいずれでも問題ありません。
参考リンク：
https://cloud.google.com/armor/docs/security-policy-concepts
https://cloud.google.com/load-balancing/docs/https
https://cloud.google.com/armor/docs/supported-features
</div></details>

### Q.  問題35: 未回答
ある大手電子小売業者は、自社のeコマースウェブサイトをGoogle Cloudに移行しようとしています。同社は、顧客がオンラインでチェックアウトする際に、顧客のブラウザとGoogle Cloudの間で決済情報が暗号化されるようにしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. L7ロードバランサーにSSL証明書を設定し、暗号化を要求します
2. ポート443のインバウンドトラフィックを許可し、他のすべてのインバウンドトラフィックをブロックするようにファイアウォールを設定します
3. ポート443のアウトバウンドトラフィックを許可し、他のすべてのアウトバウンドトラフィックをブロックするようにファイアウォールを設定します
4. ネットワークTCPロードバランサーにSSL証明書を設定し、暗号化を要求します
<details><div>
    答え：1
この問題では、eコマースサイトの顧客の決済情報をGoogle Cloudとの間で暗号化するために必要なステップを理解することが求められています。強調すべきは、この問題が求めているのはデータのセキュリティと暗号化に関する知識であるということです。正解選択肢を選ぶ際には、Webトラフィックを保護するための効果的な方法を選び、データを安全に転送できる解決策を選択することが不可欠です。各選択肢が提供するセキュリティレベルとそれぞれの機能を整理し、最適な解決策を選択する必要があります。
基本的な概念や原則：
L7ロードバランサー：トラフィックをバランシングするためのGoogle Cloudのサービスです。アプリケーションレベル（HTTP/HTTPS）のロードバランシングを提供します。SSL/TLS証明書の設定もサポートしています。
SSL証明書：ブラウザとサーバ間の通信を暗号化するための証明書です。通信内容のセキュリティを保証します。
ネットワークTCPロードバランサー：Google Cloudのロードバランサーサービスで、ネットワークトラフィックのバランシングを提供します。しかし、SSL/TLS証明書を使った暗号化はサポートしていません。
暗号化：データを安全に保護するために行われるプロセスです。通信されるデータが第三者によって読み取られるのを防ぎます。
ポート443：HTTPS通信によく用いられるポート番号です。HTTPS通信はSSL/TLSにより暗号化され、セキュアなウェブ通信を可能にします。
正解についての説明：
（選択肢）
・L7ロードバランサーにSSL証明書を設定し、暗号化を要求します
この選択肢が正解の理由は以下の通りです。
まず、SSL証明書（Secure Sockets Layer）は、一般的にデータの暗号化とセキュリティの確保に使用されます。L7ロードバランサー（HTTP(S)ロードバランサー）にSSL証明書を設定することで、ブラウザとサーバー間の通信は暗号化され、双方が安全にデータを交換できます。
具体的には、顧客がオンラインでチェックアウトする際に入力した情報（例：クレジットカード情報などの決済情報）は、SSL証明書によって暗号化されてサーバーに送信されます。こうした暗号化された情報は、暗号化されるため、もし途中で情報が盗まれたとしても、その情報を元に戻すことはほぼ不可能です。
さらに、SSL証明書はデータの完全性も保証します。つまり、データが送信元と送信先の間で変更されることなく正確に伝達されることが確保されます。これにより、経済的な取引を伴うECシステムにおいて、顧客への信頼性を高めることが可能です。
したがって、この方法は電子小売業者の要件を満たす最良の選択です。
不正解についての説明：
選択肢：ネットワークTCPロードバランサーにSSL証明書を設定し、暗号化を要求します
この選択肢が正しくない理由は以下の通りです。
ネットワークTCPロードバランサーは、Transport Layer Security（TLS）またはSecure Sockets Layer（SSL）を提供しません。これらの暗号化プロトコルを利用するためには、L7（HTTP/HTTPS）ロードバランサーを使用する必要があり、こちらはSSL証明書を設定可能で、暗号化も要求できます。
選択肢：ポート443のインバウンドトラフィックを許可し、他のすべてのインバウンドトラフィックをブロックするようにファイアウォールを設定します
この選択肢が正しくない理由は以下の通りです。
ポート443のインバウンドトラフィックを許可し他の全てのインバウンドトラフィックをブロックする、というファイアウォールの設定は暗号化を実施する訳ではありません。
一方、L7ロードバランサーにSSL証明書を設定し暗号化を要求することで顧客の決済情報を暗号化することが可能になります。
選択肢：ポート443のアウトバウンドトラフィックを許可し、他のすべてのアウトバウンドトラフィックをブロックするようにファイアウォールを設定します
この選択肢が正しくない理由は以下の通りです。
ポート443のアウトバウンドトラフィックを許可し、他のすべてのアウトバウンドトラフィックをブロックする設定は、HTTPSトラフィックの通信を許可するものですが、これだけでは決済情報の暗号化は保証できません。正解のL7ロードバランサーにSSL証明書を設定し暗号化を要求する方法が必要となります。
参考リンク：
https://cloud.google.com/load-balancing/docs/ssl-certificates
https://cloud.google.com/load-balancing/docs/https
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題36: 未回答
あなたは組織のセキュリティ管理者です。あなたは、本番環境内でのサービスアカウント作成機能を制限する必要があります。これを組織全体で一元的に達成したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 新しいサービスアカウントの作成を無効にするために、組織ポリシーconstraints/iam.disableServiceAccountKeyUpload booleanを使用します
2. 新しいサービスアカウントの作成を無効にするために、組織ポリシーconstraints/iam.disableServiceAccountKeyCreation booleanを使用します
3. Identity and Access Management（IAM）を使用して、本番環境にアクセスできるすべてのユーザーとサービスアカウントのアクセスを制限します
4. 新しいサービスアカウントの作成を無効にするために、組織ポリシーconstraints/iam.disableServiceAccountCreation booleanを使用します
<details><div>
    答え：4
この問題では、Google Cloudの組織横断的なセキュリティの管理方法が求められています。具体的には、本番環境でのサービスアカウントの作成を制限する方法についてです。問題文からは、組織全体で一元的に制御したいとなっているので、個々のユーザーやサービスアカウントに対する設定ではなく、組織全体をカバーするような設定が必要になります。そこで、組織ポリシーという組織全体の設定をする機能がキーワードになると考えます。そして、どのような組織ポリシーを設定すればいいかを選んでいきます。
基本的な概念や原則：
セキュリティ管理者：組織のセキュリティポリシーやアクセス制御を管理する役職です。セキュリティリスクの軽減やデータ保護に責任を持ちます。
組織ポリシー：Google Cloud内で組織全体または特定のリソースに対する特定の制限や規則を設定するためのツールです。これにより、遵守されるべきポリシーを一元的に管理できます。
constraints/iam.disableServiceAccountCreation：この組織ポリシーは、サービスアカウントの作成を禁止します。これにより、新たなサービスアカウントによるリソースのアクセスを制限できます。
Identity and Access Management（IAM）：Google Cloudのユーザーやサービスアカウントの権限を管理するツールです。しかし、これによるアクセス制限では新規サービスアカウントの作成を禁止することはできません。
constraints/iam.disableServiceAccountKeyCreation：この組織ポリシーは、サービスアカウントキーの作成を禁止します。しかし、サービスアカウント自体の作成を制限するものではありません。
constraints/iam.disableServiceAccountKeyUpload：この組織ポリシーは、サービスアカウントキーのアップロードを禁止します。しかし、これもサービスアカウント自体の作成を制限するものではありません。
正解についての説明：
（選択肢）
・新しいサービスアカウントの作成を無効にするために、組織ポリシーconstraints/iam.disableServiceAccountCreation booleanを使用します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、組織全体で一元的にある種のリソースの作成を制限することが可能な組織ポリシーという概念があります。そのうち、constraints/iam.disableServiceAccountCreation booleanは、組織ポリシーの一つでこの問題の要件、すなわちサービスアカウントの作成を無効にするためのものとなります。この組織ポリシーを有効にすることで、本番環境内におけるサービスアカウントの作成を制限し、組織が保有する全てのプロジェクトに適用することができます。
したがって、あなたが組織全体で一元的に達成したい要件を満たす最善の方法がこの選択肢となります。
不正解についての説明：
選択肢：Identity and Access Management（IAM）を使用して、本番環境にアクセスできるすべてのユーザーとサービスアカウントのアクセスを制限します
この選択肢が正しくない理由は以下の通りです。
IAMを使用してアクセス制限を行うと、アクセス可能なすべてのユーザーとサービスアカウントの特定と設定が必要となります。しかし、提示された要件は一元的にサービスアカウントの作成を制限することなので、IAMを使用することは適切ではありません。この問題は組織全体での制御を必要としており、それは組織ポリシーconstraintsを使用することで実現できます。
選択肢：新しいサービスアカウントの作成を無効にするために、組織ポリシーconstraints/iam.disableServiceAccountKeyCreation booleanを使用します
この選択肢が正しくない理由は以下の通りです。
constraints/iam.disableServiceAccountKeyCreationポリシーは、新しいサービスアカウントキーの生成を無効にしますが、サービスアカウント自体の作成を制限するわけではありません。
一方、正しい選択肢のconstraints/iam.disableServiceAccountCreationポリシーは、サービスアカウントの新規作成を無効にし、求められる要件を満たします。
選択肢：新しいサービスアカウントの作成を無効にするために、組織ポリシーconstraints/iam.disableServiceAccountKeyUpload booleanを使用します
この選択肢が正しくない理由は以下の通りです。
constraints/iam.disableServiceAccountKeyUpload booleanは、サービスアカウントキーのアップロードを無効にするためのものです。サービスアカウントそのものの作成を制限するためには、constraints/iam.disableServiceAccountCreation booleanを使用するのが正しいです。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-service-accounts
</div></details>

### Q.  問題37: 未回答
ある会社では、全従業員がGoogle Cloudを利用できます。各部署にはGoogleグループがあり、すべての部署メンバーがグループメンバーになっています。ある部署のメンバーが新しいプロジェクトを作成した場合、その部署のメンバー全員が自動的にすべての新しいプロジェクトリソースへの読み取り専用アクセス権を持つ必要があります。他の部署のメンバーはプロジェクトにアクセスできません。この動作を設定する必要があります。
これらの要件を満たすにはどうすればよいですか？
1. 組織の下に部署ごとにフォルダを作成します。各部門のフォルダーに対して、その部門に関連するGoogleグループにProject Viewerロールを割り当てます
2. 組織の下に部署ごとにプロジェクトを作成します。各部門のプロジェクトに対して、その部門に関連するGoogleグループにProject Viewerロールを割り当てます
3. 組織の下に部署ごとにプロジェクトを作成します。各部門のプロジェクトに対して、その部門に関連するGoogleグループにProject Browserロールを割り当てます
4. 組織の下に部署ごとにフォルダを作成します。各部門のフォルダに対して、その部門に関連するGoogleグループにProject Browserロールを割り当てます
<details><div>
    答え：1
この問題では、Google Cloudの組織管理におけるアクセス制御の設定方法が問われています。ある部署がプロジェクトを新規作成した場合、その部署の全員が読み取り専用のアクセス権を持つように設定する必要があります。その一方で、他の部署のメンバーはアクセスを許可しないという要件です。これらの要件から、適切なアクセス制御の設定を行って、部門ごとのアクセス権を適切に管理することを問題の中心として考えます。正解選択肢は、この要求に一致するセキュリティモデルと組織のヒエラルキーを提供します。
基本的な概念や原則：
Google Cloudの認証とアクセス管理（IAM）：Google Cloud上のリソースに対するアクセスを管理します。特定のユーザーやグループに対してロールを割り当てることで、リソースへのアクセス権を制御します。
Googleグループ：特定のユーザーのグループを作成し、そのグループに対して一連の権限を割り当てることができます。これにより、特定の部署やチームなどの要件に応じてアクセス権の管理が容易になります。
フォルダ：Google Cloudのリソース階層の一部で、複数のプロジェクトを一箇所で管理するのに役立ちます。フォルダを使用して、異なる部署やチームのプロジェクトを隔離し、アクセス制御およびポリシーを適用することができます。
Project Viewerロール：Google Cloudプロジェクトのすべてのリソースを閲覧する権限が付与されています。リソースの読み取り専用アクセスが可能ですが、リソースの変更や削除は許可されていません。
Project Browserロール：プロジェクトの一部のリソースを閲覧するためのロールです。但し、すべてのリソースを閲覧することはできません。
正解についての説明：
（選択肢）
・組織の下に部署ごとにフォルダを作成します。各部門のフォルダーに対して、その部門に関連するGoogleグループにProject Viewerロールを割り当てます
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudでは、フォルダを使用して組織のリソースを階層的に管理することができます。これにより、個々のフォルダに対してロールを割り当てることも可能となります。各フォルダごとに部門を作成し、それぞれの部門が関連するGoogleグループにProject Viewerロールを割り当てると、その部署のメンバーだけがそのフォルダ（すなわち、その部署のプロジェクト）にアクセス可能となります。Project Viewerロールが割り当てられると、そのロールの持ち主はプロジェクトのリソースを読み取ることができますが、変更することはできません。これにより、読み取り専用のアクセス権が部門のメンバーに提供されます。
また、この設定は部門ごとに行われるため、他の部門のメンバーはプロジェクトにアクセスすることができず、セキュリティが保たれます。
このように、フォルダとロールを活用することで、各部署のメンバーが自動的に新しいプロジェクトリソースへの読み取り専用アクセス権を持つように設定できます。
不正解についての説明：
選択肢：組織の下に部署ごとにフォルダを作成します。各部門のフォルダに対して、その部門に関連するGoogleグループにProject Browserロールを割り当てます
この選択肢が正しくない理由は以下の通りです。
Project BrowserロールはGoogle Cloud Consoleのプロジェクトメタデータの表示のみを許可し、リソースへの具体的な読み取りアクセスは提供しません。具体的なリソースへの読み取りアクセスを提供するという要件があるため、ここでProject Viewerロールが必要となります。
選択肢：組織の下に部署ごとにプロジェクトを作成します。各部門のプロジェクトに対して、その部門に関連するGoogleグループにProject Viewerロールを割り当てます
この選択肢が正しくない理由は以下の通りです。
部署ごとにプロジェクトを作成すると、新しいプロジェクトが作成されるたびに、手動でその部門のGoogleグループにProject Viewerロールを割り当てる必要があります。
一方で、部署ごとにフォルダを作成すれば、フォルダ内に新たに作成されたプロジェクトは自動的に既存のアクセス設定を引き継ぎます。よって、手間を削減しながらも要件を満たすことが可能です。
選択肢：組織の下に部署ごとにプロジェクトを作成します。各部門のプロジェクトに対して、その部門に関連するGoogleグループにProject Browserロールを割り当てます
この選択肢が正しくない理由は以下の通りです。
Project Browserロールを割り当てた場合、部門のメンバーはプロジェクトを表示できますが、新しく作成される全てのプロジェクトリソースへの読み取り専用アクセス権は付与されません。そのため、要件を満たすには、プロジェクトリソースへの読み取り専用アクセス権を持つProject Viewerロールを割り当てる必要があります。
参考リンク：
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://cloud.google.com/iam/docs/understanding-roles#basic-definitions
https://cloud.google.com/resource-manager/docs/access-control-proj
</div></details>

### Q.  問題38: 未回答
オンプレミスのデータセンターとVPCホストネットワークの間にCloud Interconnect接続を設定する必要があります。オンプレミスのアプリケーションがGoogle APIにアクセスできるのはCloud Interconnect経由のみで、パブリックインターネット経由ではアクセスできないようにする必要があります。また、サポートされていないAPIへの流出リスクを軽減するために、VPC Service ControlsでサポートされているAPIのみを使用する必要があります。
ネットワークをどのように設定すればよいですか？
1. *.googleapis.comをrestricted.googleapis.comにマップするCNAMEを作成し、199.36.153.8/30にマップされたrestricted.googleapis.comのAレコードを作成します
2. リージョンサブネットのプライベートGoogleアクセスとグローバルダイナミックルーティングモードを有効にします
3. private.googleapis.comを使用すると、Google Cloudからのみルーティング可能なIPアドレスのセットを使用してGoogle APIにアクセスできます
4. 制限付きgoogleapis.comを使用すると、Google Cloud内からのみルーティング可能なIPアドレスのセットを使用してGoogle APIにアクセスできます。このIPアドレスは、Cloud Interconnect接続上のルートとしてアドバタイズされます
<details><div>
    答え：4
この問題では、オンプレミスのデータセンターとVPCホストネットワーク間のCloud Interconnect接続を設定し、Google APIへのアクセスを制限する方法が求められています。問題文から、Public Internet経由でのアクセスを避けたいという要件と、特定のAPIの利用だけを許可し、サポートされていないAPIへのリスクを軽減したいという要件があることが分かります。これらの要件に基づいて適切なGoogle Cloudの機能やサービスを選択し、ネットワークを設定することが求められています。選択肢の中から、これらの要件を最も適切に満たすネットワークの設定方法を選ぶことが重要です。
基本的な概念や原則：
Cloud Interconnect：オンプレミスのネットワークとGoogle Cloudのネットワークを直接接続するサービスです。これにより、セキュアで高速なデータ転送が可能になります。
制限付きgoogleapis.com：Google Cloud内からのみアクセス可能なGoogle APIの限定版です。これを使用すると、パブリックインターネットではなくCloud Interconnect経由でのみGoogle APIにアクセスできます。
APIアクセスの流出リスクの軽減：特定のAPIの使用を制限することで、不正なアクセスやデータ漏洩のリスクを低減します。
VPC Service Controls：Google Cloudのサービスへのアクセスを制御し、データエクスフィルトレーションのリスクを軽減するためのツールです。
プライベートGoogleアクセス：Google Cloudからのみアクセス可能なGoogle APIです。これを使用すると、パブリックインターネットではなく特定のVPCネットワーク経由でのみGoogle APIにアクセスできます。
グローバルダイナミックルーティングモード：VPCネットワークのルーティングオプションの一つで、VPCネットワーク内のすべてのサブネット間でルーティングを行います。
CNAMEレコード：DNSレコードの一種で、一つのドメイン名（the 'alias'）を別のドメイン名（the 'canonical name'）にマップします。
正解についての説明：
（選択肢）
・制限付きgoogleapis.comを使用すると、Google Cloud内からのみルーティング可能なIPアドレスのセットを使用してGoogle APIにアクセスできます。このIPアドレスは、Cloud Interconnect接続上のルートとしてアドバタイズされます
この選択肢が正解の理由は以下の通りです。
まず、制限付きgoogleapis.comを使用することにより、Google Cloud内からだけアクセス可能なIPアドレスを使用してGoogle APIに接続します。そのため、オンプレミスのアプリケーションがGoogle APIにアクセスする際、パブリックインターネットではなく、Cloud Interconnect経由でしかアクセスできないように制限することが可能です。これにより、不正アクセスやデータリークのリスクを最小限に抑えることができます。
また、このIPアドレスはCloud Interconnect接続のルートとしてアドバタイズされるため、オンプレミスのデバイスからも認識することができ、リーチャブルになります。
さらに、VPC Service Controlsを用いれば、サポートされているAPIのみを使用することで、不適切なAPIへのアクセスも防ぐことができます。以上の理由から、この選択肢は要件を満たす最適な解答となります。
不正解についての説明：
選択肢：リージョンサブネットのプライベートGoogleアクセスとグローバルダイナミックルーティングモードを有効にします
この選択肢が正しくない理由は以下の通りです。
リージョンサブネットのプライベートGoogleアクセスとグローバルダイナミックルーティングモードを有効にしても、オンプレミスのアプリケーションはパブリックインターネット経由でGoogle APIにアクセスするリスクがあり、問題の要件であるGoogle APIへのインターネット経由のアクセスを制限することはできません。
選択肢：*.googleapis.comをrestricted.googleapis.comにマップするCNAMEを作成し、199.36.153.8/30にマップされたrestricted.googleapis.comのAレコードを作成します
この選択肢が正しくない理由は以下の通りです。
不正解の選択肢はオンプレミスのアプリケーションがGoogle APIにアクセスする際にCNAMEとAレコードを使っていますが、これではCloud Interconnect経由限定とはならず、パブリックインターネット経由のアクセスが可能となってしまいます。対して正解は、Cloud Interconnect接続上の特定のIPアドレスセットを使用してアクセスを制限し、要件を満たしています。
選択肢：private.googleapis.comを使用すると、Google Cloudからのみルーティング可能なIPアドレスのセットを使用してGoogle APIにアクセスできます
この選択肢が正しくない理由は以下の通りです。
この質問の要件では、オンプレミス環境からGoogle APIへのアクセスが必要なため、private.googleapis.comの使用は適切ではありません。これはGoogle Cloud内部からのみルーティング可能で、オンプレミス環境からアクセスすることはできません。そのため、制限付きgoogleapis.comを使用してオンプレミス環境からもアクセスできるようにする必要があります。
参考リンク：
https://cloud.google.com/interconnect/docs
https://cloud.google.com/vpc-service-controls/docs
https://cloud.google.com/vpc/docs/configure-private-google-access#restricted-google-access
</div></details>

### Q.  問題39: 未回答
組織のセキュリティ基準に従ってハード化されたOSイメージを作成し、セキュリティチームが管理するプロジェクトに保存しています。Google Cloudの管理者として、運用上のオーバーヘッドを最小限に抑えながら、Google Cloudの組織内のすべてのVMがその特定のOSイメージのみを使用できるようにする必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 自分のプロジェクトで、ユーザーにcompute.imageUserロールを付与します
2. 組織で立ち上げるすべてのプロジェクトにイメージを保存します
3. プロジェクトのユーザーからVMインスタンス作成権限を削除し、あなたとあなたのチームだけにVMインスタンスの作成を許可します
4. OSイメージプロジェクトにおいて、ユーザーにcompute.imageUserロールを付与します
5. 画像アクセス組織ポリシー制約を設定し、セキュリティチームが管理するプロジェクトをプロジェクトの許可リストにリストします
<details><div>
    答え：4,5
この問題では、組織全体で特定のOSイメージのみを使用するように制限し、運用上の負担を最小限にする方法を選ぶ必要があります。そのため問題文中に出てくる"運用上のオーバーヘッドを最小限に抑えながら"となっている所に注目をして選択肢を検討することが重要です。また、課題を解決する方法として、適切な権限設定とポリシーの設定が必要であり、それらを踏まえて選択肢を評価することが必要です。
基本的な概念や原則：
compute.imageUserロール：このロールを持つユーザーは指定したプロジェクトのカスタムイメージを読み込むことができます。他のプロジェクトやユーザーと安全にイメージを共有することが可能です。
画像アクセス組織ポリシー制約：この制約を使用すると、組織内の特定のプロジェクトのみが特定のイメージを使用することを許可できます。セキュリティ基準を満たすことが求められる場合や特定のユーザーのみにアクセスを制限したい場合に使用します。
OSイメージハードニング：セキュリティ基準に応じて調整されたオペレーティングシステムのイメージです。脆弱性を減らすために、不必要なサービスや設定を無効にした状態で提供されます。
組織ポリシー：Google Cloudのリソースに対する特定の制約を設定するためのポリシーです。組織全体又は特定のプロジェクトに対して適用することができます。
正解についての説明：
（選択肢）
・OSイメージプロジェクトにおいて、ユーザーにcompute.imageUserロールを付与します
・画像アクセス組織ポリシー制約を設定し、セキュリティチームが管理するプロジェクトをプロジェクトの許可リストにリストします
この選択肢が正解の理由は以下の通りです。
まず、OSイメージプロジェクトにおいて、ユーザーに "compute.imageUser" ロールを付与すると、そのユーザーはプロジェクト内のカスタムイメージを使用できるようになります。このロールは、Google CloudのIdentity and Access Management（IAM）に配置され、特定のユーザがカスタムイメージを使用するためのアクセスを制御します。
したがって、これによりセキュリティチームが管理するOSイメージのみを組織内のユーザが使用できるようにすることが可能となります。
また、強制的な画像アクセス組織ポリシー制約を適用することで、組織全体が使用できるプロジェクトからのイメージのみを制限します。この制約は組織レベルで設定され、特定のプロジェクトからのイメージのみ許可するものです。
したがって、この制約を適用することで、制御下にあるOSイメージからのみVMを作成することができ、こうすることで組織全体で一貫したセキュリティ基準の適用を確保することが可能となります。
不正解についての説明：
選択肢：自分のプロジェクトで、ユーザーにcompute.imageUserロールを付与します
この選択肢が正しくない理由は以下の通りです。
自分のプロジェクトでユーザーにcompute.imageUserロールを付与すると、そのプロジェクト内でのみ利用が可能になり、全体の組織に適用されません。
それに対して、OSイメージプロジェクトでロールを付与し、組織ポリシーでアクセス制限を設定する方法なら全体に適用されます。
選択肢：組織で立ち上げるすべてのプロジェクトにイメージを保存します
この選択肢が正しくない理由は以下の通りです。
組織で立ち上げるすべてのプロジェクトにイメージを保存する方法では、運用上のオーバーヘッドが増加します。
正解の選択肢は、特定のOSイメージを使用するための権限を付与し、その使用を制限することで、運用上のオーバーヘッドを最小限に抑える効果を得ることができます。
選択肢：プロジェクトのユーザーからVMインスタンス作成権限を削除し、あなたとあなたのチームだけにVMインスタンスの作成を許可します
この選択肢が正しくない理由は以下の通りです。
プロジェクトのユーザーからVMインスタンス作成権限を削除すると、ユーザーはVMを作成できなくなります。これは運用上のオーバーヘッドを増やす結果となり、オーバーヘッドを最小限にするという問題の要求を満たしません。正解の選択肢はイメージの使用権を制限し、特定のイメージだけを使うことを可能にします。
参考リンク：
https://cloud.google.com/compute/docs/access/iam
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題40: 未回答
あなたの会社のクラウドセキュリティポリシーでは、VMインスタンスは外部IPアドレスを持ってはいけないことになっています。外部IPアドレスを持たないVMインスタンスがインターネットに接続してVMを更新できるようにするGoogle Cloudサービスを特定する必要があります。どのサービスを使うべきですか？
1. TCP/UDPロードバランシング
2. Identity-Aware Proxy
3. Cloud NAT
4. Cloud DNS
<details><div>
    答え：3
この問題では、会社のクラウドセキュリティポリシーとVMインスタンスの接続要件が中心的なロールを果たしています。企業のセキュリティ規定では、VMインスタンスが外部IPを持つことは止めている一方で、VMをインターネットに接続して更新できる必要があります。そのため、外部IPを持たずにインターネットに接続可能なGoogle Cloudのサービスを特定することが問題の主旨となっています。選択肢を検討する際には、外部IPなしでインターネットとの通信を可能にする適切なサービスを選ぶことに焦点を当てるべきです。
基本的な概念や原則：
Cloud NAT：Google CloudのマネージドNATサービスで、プライベートIPアドレスのVMインスタンスが外部ネットワークやインターネットにアクセスするのを支援します。これにより、外部IPアドレスを持たないVMインスタンスでも安全な接続が可能になります。
Identity-Aware Proxy：Google Cloudのサービスで、ユーザー認証とコンテキスト認証に基づいてアクセス制御を行うことができます。これにより、外部からの不正なアクセスを防止します。
TCP/UDPロードバランシング：Google Cloudのサービスで、TCPやUDPトラフィックをバックエンドのインスタンスに均等に分配します。これにより、トラフィックの高負荷を効果的に管理することができます。
Cloud DNS：Google Cloudの高性能、高可用性のDNSサービスです。安全で信頼性の高いDNSネーム解決を提供します。
正解についての説明：
（選択肢）
・Cloud NAT
この選択肢が正解の理由は以下の通りです。
まず、Cloud NAT（Network Address Translation）は、登録されている内部IPアドレスを使用してGoogle Cloud上のリソースからインターネットを利用するためのサービスです。外部との接続はCloud NATを介して行われ、VMインスタンス自体は直接外部接続の対象となりません。これは、外部IPアドレスを持たないVMインスタンスがインターネットに接続して更新を行うには理想的な方法です。
また、Cloud NATは送信元NAT（SNAT）と送信先NAT（DNAT）を提供します。これにより、内部IPアドレスしか持たないインスタンスが外部ネットワークと通信することが可能になります。この機能により、セキュリティポリシーに準拠しながら、インターネットからのアクセスを維持することが可能になります。
従って、外部IPアドレスを持たないVMインスタンスがインターネットに接続する方法として、Cloud NATは最適の選択となります。
不正解についての説明：
選択肢：Identity-Aware Proxy
この選択肢が正しくない理由は以下の通りです。
Identity-Aware Proxyはユーザーの認証と認可を管理し、Google Cloudリソースへのアクセスを制御しますが、外部IPアドレスを持たないVMインスタンスがインターネットに接続する機能は提供していません。
一方、Cloud NATはプライベートIPアドレスを持つリソースがインターネットに接続するためのサービスです。
選択肢：TCP/UDPロードバランシング
この選択肢が正しくない理由は以下の通りです。
TCP/UDPロードバランシングは、基本的に受信トラフィックをバランスするためのサービスであり、外部IPを持たないVMインスタンスがインターネットに接続するための要件を直接満たすものではありません。反対に、Cloud NATはプライベートIPアドレスからの接続を可能にし、この問題の要件を満たすための適切なサービスです。
選択肢：Cloud DNS
この選択肢が正しくない理由は以下の通りです。
Cloud DNSはドメイン名解決サービスであり、外部IPアドレスを持たないVMインスタンスがインターネットに接続する機能は提供していません。
一方、Cloud NATは外部IPアドレスを必要とせずにインスタンスがインターネットに接続できるようにするため、ポリシーに合致します。
参考リンク：
https://cloud.google.com/nat/docs/overview
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/vpc/docs/using-nat-gateway
</div></details>

### Q.  問題41: 未回答
個人を特定できる情報（PII）を含む機密性の高いBigQueryワークロードがあり、インターネットからアクセスできないようにしたいと考えています。データの流出を防ぐため、許可されたIPアドレスからのリクエストのみBigQueryテーブルへのクエリを許可する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. サービス境界を使用し、認可されたソースIPアドレスを条件としてアクセスレベルを作成します
2. Cloud Data Loss Prevention（DLP）とともに、リソースサービス利用制限組織ポリシー制約を使用します
3. グローバルHTTPSロードバランサーで、許可されたIPアドレスの許可リストを定義するGoogle Cloud Armorセキュリティポリシーを使用します
4. Cloud Data Loss Prevention（DLP）と共に、許可されたGoogle CloudAPIとサービスの組織ポリシー制約を使用します
<details><div>
    答え：1
この問題では、機密な情報を含むBigQueryワークロードのアクセス制御をどのように行うかということが問われています。特に、指定したIPアドレスからのリクエストのみを許可するという要件に重点を置くべきです。これにより、選択肢に含まれる各ツールやサービスがこの特定の要件に対してどのように対応できるかを理解し、最適な解決策を選択することが求められます。
基本的な概念や原則：
サービス境界：Google Cloudにおけるネットワークセキュリティ機能の一つで、特定のサービスへのアクセスを制限する機能です。境界を設定することで、特定のソースからの接続を制限したり、許可するIPアドレスを指定したりすることができます。
アクセスレベル：サービス境界の条件の一つで、指定されたIPアドレスや範囲からのリクエストを許可したり、特定のユーザーエージェントを必要としたりする状態を定義します。
Google Cloud Armor：Google Cloudのセキュリティサービスの一つで、グローバルHTTPSロードバランサーに対してセキュリティポリシーを適用する機能があります。しかし、BigQueryの制限には適していません。
Cloud Data Loss Prevention（DLP）：機密情報を特定、マスク、匿名化するためのツールです。PIIの保護には有用ですが、IPアドレスに基づいたアクセス制御には使用できません。
リソースサービス利用制限組織ポリシー制約：特定のサービスリソースの使用を制限するポリシーです。サービスの利用自体を制御しますが、IPアドレスに基づいたアクセス制御には使用できません。
正解についての説明：
（選択肢）
・サービス境界を使用し、認可されたソースIPアドレスを条件としてアクセスレベルを作成します
この選択肢が正解の理由は以下の通りです。
サービス境界は、Google Cloud上の特定のリソースへのネットワークアクセスを制御するためのポリシーベースのツールで、これにより各リソースへのアクセスを厳密に制御することが可能です。設問では、特定のIPアドレスからのアクセスのみBigQueryテーブルへのクエリを許可するような要求があったため、サービス境界を使用して、許可されたソースIPアドレスを条件としてアクセスレベルを作成することで、これを実現することができます。
また、サービス境界は、ネットワークとデータのセキュリティを強化するツールでもあります。BigQueryでは、PIIなどの機密性の高い情報を扱う場合、データの流出を防ぐための強固なセキュリティ対策が必要となります。この選択肢は、そのようなセキュリティ要件を確実に満たすための適切な解決策を示しています。
不正解についての説明：
選択肢：グローバルHTTPSロードバランサーで、許可されたIPアドレスの許可リストを定義するGoogle Cloud Armorセキュリティポリシーを使用します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは主にHTTP(S)負荷分散のトラフィックに対するセキュリティの提供に使用され、BigQueryサービス（非HTTP(S)ベース）へのアクセス制御には適していません。
一方、サービス境界は特定のサービスに対し制限を設ける能力があるため、正解となります。
選択肢：Cloud Data Loss Prevention（DLP）とともに、リソースサービス利用制限組織ポリシー制約を使用します
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Preventionは、データを保護し情報漏洩を防止するためのサービスですが、特定のIPアドレスからのリクエストだけを許可する機能は提供していません。
一方、サービス境界を使用しアクセスレベルを作成することで、認可されたソースIPアドレスからのみのアクセスを制限することが可能です。
選択肢：Cloud Data Loss Prevention（DLP）と共に、許可されたGoogle CloudAPIとサービスの組織ポリシー制約を使用します
この選択肢が正しくない理由は以下の通りです。
Cloud DLPと組織ポリシー制約はデータの流出や不適切なパブリックアクセスを防ぐためのツールではありますが、指定したIPアドレスからのリクエストだけを許可することは出来ません。
それに対して、サービス境界とアクセスレベルを使用すれば、許可したIPアドレスからのアクセスのみを許可することができます。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/create-manage-service-perimeters
https://cloud.google.com/access-context-manager/docs/overview
https://cloud.google.com/bigquery/docs/controlled-access
</div></details>

### Q.  問題42: 未回答
オンプレミス環境からBigQueryデータセットへの日々のETLプロセスにおいて、個人を特定できる機密情報（PII）がGoogle Cloud環境にインジェストされていることが判明しました。このデータを冗長化してPIIを難読化する必要がありますが、データ分析の目的で再識別化する必要があります。
どのコンポーネントをソリューションに使用するべきですか？（2つ選択）
1. 自動テキスト再編集機能を備えたCloud Data Loss Prevention
2. Cloud Key Management Service
3. Secret Manager
4. AES-SIVを用いた決定論的暗号化によるCloud Data Loss Prevention
5. 暗号ハッシュによるCloud Data Loss Prevention
<details><div>
    答え：2,4
この問題では、PII（特定可能な個人情報）の取り扱いを問われています。PIIは一度難読化（暗号化）が必要であり、同時に再識別化（復号化）も可能でなければなりません。その上で、適切なGoogle Cloudの機能やサービスを選択することが必要です。問題は2つの答えを求めており、選択肢にはCloud Key Management Service、Cloud Data Loss Preventionなど複数のサービスが提示されています。個々の選択肢が提供するサービスや機能を理解し、問題の要求を満たすものを選ぶことが求められます。
基本的な概念や原則：
Cloud Key Management Service：暗号キーを作成、使用、管理し、アクセスを制御するGoogle Cloudのインフラストラクチャです。キーのライフサイクルを管理する機能やキーのバージョニングを提供します。
決定論的暗号化：同じ平文が常に同じ暗号文になるような暗号方式です。個人を識別できる情報などを確実に難読化し、維持することができます。
Personal Identifiable Information（PII）：個々の人物を特定できる情報のことを指します。名前やメールアドレスなどが該当します。
Cloud Data Loss Prevention：機密データの検出、分類、保護を自動化するためのサービスです。暗号化や変換などを行ってデータの保護を支援します。
AES-SIV（Authenticated Encryption with Associated Data - Synthetic Initialization Vector）：暗号化とメッセージ認証コード生成を一度に行う暗号化方式の一つです。再識別が可能な暗号化を提供します。
正解についての説明：
（選択肢）
・Cloud Key Management Service
・AES-SIVを用いた決定論的暗号化によるCloud Data Loss Prevention
この選択肢が正解の理由は以下の通りです。
まず、Cloud Key Management Service（KMS）は、Google Cloud環境での暗号鍵の管理を容易にするためのサービスです。具体的には、暗号鍵の生成、使用、ローテーション、削除などを管理できます。これにより、データの冗長化などのセキュリティ上の要求を満たすことができます。
また、Google Cloudのデータ損失防止（DLP）APIは、個人を特定できる情報（PII）を自動的に検出、分類、難読化する機能を提供します。
そして、DLP APIはAES-SIVを使用した決定論的暗号化をサポートしており、同一の入力に対して常に同じ暗号文を生成します。これにより、データ分析を行う際に同じデータを再識別化することが可能になります。つまり、DLP APIのAES-SIVを使用した決定論的暗号化は、このケースの需要に適しています。
したがって、PIIを難読化しつつ、データ分析の目的で再識別化するためには、Cloud KMSとCloud DLPのAES-SIVを使用した決定論的暗号化の組み合わせが最適です。
不正解についての説明：
選択肢：Secret Manager
この選択肢が正しくない理由は以下の通りです。
Secret Managerは秘密情報の保存・管理を行うサービスであり、データの暗号化や難読化には使えません。
それに対して、Cloud Key Management Serviceは鍵の管理を、Cloud Data Loss PreventionはPIIの保護を行うため、このケースに適しています。
選択肢：暗号ハッシュによるCloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュによるCloud Data Loss Preventionはデータを難読化しますが一度ハッシュ化された情報は元に戻すことが出来ません。そのため再識別化が必要という要件を満たすことができません。
それに対して、AES-SIVを用いた決定論的暗号化は、一貫した暗号テキストを生成しつつ元の情報に戻すことが可能なため要件を満たします。
選択肢：自動テキスト再編集機能を備えたCloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
自動テキスト再編集機能を備えたCloud Data Loss Preventionは、機密情報を難読化するのに有用ですが、問題の要求である"データ分析の目的で再識別化する必要がある"という条件に合致しません。再編集したデータの再識別化はできません。
一方、AES-SIVを用いた決定論的暗号化は再識別が可能なため、この要件に適しています。
参考リンク：
https://cloud.google.com/kms
https://cloud.google.com/dlp/docs/concepts-deidentification#de-identification_in_the_dlp_api
</div></details>

### Q.  問題43: 未回答
あなたの組織は、最近数回のDDoS攻撃を受けています。 そのため、ドメイン名検索への応答を認証する必要があります。
どのGoogle Cloudサービスを使用する必要がありますか？
1. Cloud NAT
2. DNSSEC付きCloud DNS
3. HTTP(S)ロードバランシング
4. Google Cloud Armor
<details><div>
    答え：2
この問題では、DDoS攻撃に対処してドメイン名検索への応答を認証するためのGoogle Cloudのサービスを選択する必要があることが問われています。認証を強化するための適切なGoogle Cloudのサービスを探求する際に、候補となるサービスがその要件を満たすかどうかを評価することが求められます。その結果、ドメイン名検索の認証に最も適していそうなサービスを選ぶべきです。
基本的な概念や原則：
DNSSEC（Domain Name System Security Extensions）：ドメイン名の応答を認証するためのセキュリティ標準です。DNS応答の完全性と真正性を保証します。
Cloud DNS：Google Cloud上でDNSサービスを提供するマネージドサービスです。DNSSECに対応しています。
DDoS攻撃（Distributed Denial of Service）：複数のシステムから一つのターゲットに対して過剰なトラフィックを送り込むことで、サービスを切断する攻撃手法です。
Cloud NAT：Google CloudのマネージドNATサービスです。プライベートなGoogle Cloud VMインスタンスに、インターネットとの接続を可能にします。
HTTP(S)ロードバランシング：大量のHTTPとHTTPSトラフィックを分散させ、バックエンドインスタンスへ効率的に転送するGoogle Cloudの機能です。
Google Cloud Armor：Google CloudのDDoS防御とWebアプリケーションファイアウォール（WAF）ソリューションです。特定のIPアドレスや地域のトラフィックをブロックする等、セキュリティポリシーをカスタマイズできます。
正解についての説明：
（選択肢）
・DNSSEC付きCloud DNS
この選択肢が正解の理由は以下の通りです。
DNSSECはドメインネームシステムセキュリティ拡張の略で、これを使用することでDNS応答の偽造を防ぎ、ユーザが意図したウェブサイトにアクセスすることを保証します。DDoS攻撃の一部はDNSを狙ったものがあり、攻撃者が偽のDNS応答を送ることでユーザを脅威のあるサイトにリダイレクトします。Cloud DNSはGoogle Cloudの高性能、高可用性のDNSサービスで、DNSSECをサポートしています。このサービスを使うことで、組織はDNS応答の認証を行い、偽造された明示的なDNS応答による攻撃を防御することができます。
したがって、DDoS攻撃を受けてDNS応答の認証が必要となる場合、DNSSEC付きCloud DNSを用いることが適切です。
不正解についての説明：
選択肢：Cloud NAT
この選択肢が正しくない理由は以下の通りです。
Cloud NATはネットワークアドレス変換のためのサービスで、ドメイン名検索への応答を認証する機能は提供していません。
一方、DNSSEC付きのCloud DNSはDNS応答の改ざん防止を目的としたもので、この問題の要件に適しています。
選択肢：HTTP(S)ロードバランシング
この選択肢が正しくない理由は以下の通りです。
HTTP(S)ロードバランシングは、HTTPおよびHTTPSトラフィックを管理するために使用されますが、DNSクエリの認証は提供しません。
一方、DNSSEC付きCloud DNSは、ドメイン名検索への応答を認証する機能を提供します。
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud ArmorはWebアプリケーションのセキュリティを強化するためのサービスであり、主にDDoS攻撃やWebアプリケーションレベルの脅威を防止しますが、ドメイン名検索への応答の認証機能はありません。
それに対して、DNSSEC付きCloud DNSはドメイン名解決の認証を提供します。
参考リンク：
https://cloud.google.com/dns/docs/dnssec
https://cloud.google.com/armor/docs/ddos-protection
https://cloud.google.com/load-balancing/docs/https
</div></details>

### Q.  問題44: 未回答
あなたのチームは、バックエンドのデータベースがフロントエンドのアプリケーションからのみアクセスでき、ネットワーク上の他のインスタンスからはアクセスできないようにする必要があります。
あなたのチームはこのネットワークを、どのように設計すべきですか？
1. フロントエンドアプリケーションとデータベース用に異なるサブネットを作成し、ネットワークの分離を確保します
2. ファイアウォールタグを使用して、アプリケーションからデータベースへのアクセスのみを許可するインバウンドファイアウォールルールを作成します
3. 2つのVPCネットワークを作成し、VPCピアリングを使用して2つのネットワークを接続し、ネットワークの分離を確保します
4. 2つのVPCネットワークを作成し、Cloud VPNゲートウェイを使用して2つのネットワークを接続し、ネットワークの分離を確保します
<details><div>
    答え：2
この問題では、フロントエンドアプリケーションからのみデータベースへのアクセスを許可するネットワーク構成について問われています。選択肢を検討する際には、"アクセス制御"が重要な要素であり、"ネットワークの分離"自体が要件を満たすわけではないことを認識しておく必要があります。つまり、ファイアウォールルールなどのネットワークトラフィックの制御策を用いて、データベースへのアクセスをフロントエンドアプリケーションからのみに制限する解決策を選ぶことが求められます。
基本的な概念や原則：
ファイアウォールタグ：Google Cloudのネットワークファイアウォールルールをインスタンスに関連付けるための識別子です。これにより、特定のインスタンスへの特定のネットワークトラフィックの制御が可能になります。
インバウンドファイアウォールルール：指定したインスタンスへのネットワークトラフィックのふるまいを定義するルールです。特定のトラフィック来源（例：IPアドレス、ファイアウォールタグ）からのアクセスを許可または拒否する設定ができます。
サブネット：ネットワーク内のIPアドレス範囲です。ネットワーク隔離を達成するために使用されますが、サブネット間ではアクセス制御は行えません。
VPCネットワーク：Google Cloud上の仮想プライベートネットワークです。プロジェクト内のリソース間でネットワーク接続を提供します。
Cloud VPN：Google Cloudの仮想プライベートネットワーク（VPN）ソリューションです。Google Cloud VPCとオンプレミスネットワークや、他のクラウドプロバイダー間のセキュアな接続を提供します。
VPCピアリング：2つ以上のVPCネットワーク間のトラフィックを流すための接続です。各ネットワークは個別に管理し、他のネットワークのリソースに対するアクセスを制御します。
正解についての説明：
（選択肢）
・ファイアウォールタグを使用して、アプリケーションからデータベースへのアクセスのみを許可するインバウンドファイアウォールルールを作成します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、ファイアウォール規則を使用してネットワーク通信を制御できます。特にファイアウォールタグを使用することで、特定のインスタンスに対してカスタムのファイアウォール規則を適用することが可能になります。つまり、データベースのインスタンスにファイアウォールタグを付け、そのタグを持つインスタンスに対するアクセスを、フロントエンドのアプリケーションからのものだけに限定するインバウンドファイアウォールルールを作成することで、問題の要求を満たすことができます。このようにしてファイアウォールタグとファイアウォール規則を使用することで、セキュリティを確保すると同時に、必要な通信だけを許可することができます。
不正解についての説明：
選択肢：フロントエンドアプリケーションとデータベース用に異なるサブネットを作成し、ネットワークの分離を確保します
この選択肢が正しくない理由は以下の通りです。
異なるサブネットの作成はネットワークを物理的に分離する方法の一つですが、それだけでは他のインスタンスからバックエンドのデータベースへのアクセスを阻止できません。
それに対して、ファイアウォールタグを用いると特定のインスタンスからの通信のみを許可することが可能です。
選択肢：2つのVPCネットワークを作成し、Cloud VPNゲートウェイを使用して2つのネットワークを接続し、ネットワークの分離を確保します
この選択肢が正しくない理由は以下の通りです。
2つのVPCネットワークを作成し、Cloud VPNを使用して接続する方法は、ネットワーク全体の分離を確保する手段であり、指定のアプリケーションからのみアクセスを許可する細かい制御には対応できません。ファイアウォールタグを使用したルール設定は、特定のアクセスのみを許可する制御を可能にします。
選択肢：2つのVPCネットワークを作成し、VPCピアリングを使用して2つのネットワークを接続し、ネットワークの分離を確保します
この選択肢が正しくない理由は以下の通りです。
2つのVPCネットワークの作成とVPCピアリングを使用する方法は、ネットワークの分離を確保する一方で、指定のアプリケーションからのみデータベースへのアクセスを許可する要件を満たしません。
一方、ファイアウォールタグを使用すると、特定のインスタンスへのアクセス制御が可能なため、問題の要件を満たすことができます。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/vpc/docs/using-firewalls
https://cloud.google.com/compute/docs/networking
</div></details>

### Q.  問題45: 未回答
ある組織でフィッシングメールの受信数が増加しています。
このような状況で従業員の認証情報を保護するために、どの方法を使用すべきですか？
1. 多要素認証
2. ログインページのCaptcha
3. 厳格なパスワードポリシー
4. 暗号化された電子メール
<details><div>
    答え：2
この問題では、フィッシング攻撃に対抗するためのもっとも効果的な方法を選択することが求められています。望ましくない送信者からのメールを受け取る可能性が高いという状況と、従業員の認証情報を守る必要性が提示されています。したがって、問題を解く際の焦点は、送信者のメール内容やアクセス方法を鑑みてどの選択肢が従業員の認証情報の保護に最も貢献するかを判断することです。
基本的な概念や原則：
多要素認証（MFA）：最もクリティカルなセキュリティ対策の1つで、認証のアクションが2つ以上の独立したカテゴリを必要とするアクションです。ユーザーの認証情報を確認するために、物理的なもの（ハードウェアトークン等）、知識（パスワード等）、生体認証（指紋認証等）などの組み合わせを使用します。
フィッシング：犯罪者が正規の事業者や団体などになりすました通信（多くはメール）を送り、ユーザーの重要情報（認証情報やクレジットカード番号など）を詐取する詐欺手口です。
パスワードポリシー：パスワードの長さや複雑さ、有効期限など、パスワードの使用に関するガイドラインまたは規則です。
CAPTCHA：自動スクリプトによる性質の非人間的な行動を防ぐための認証システムです。通常、画像やテキストを解読することで、使用者が人間であることを証明します。
電子メールの暗号化：電子メールの内容を暗号化し、承認された受信者のみが内容を読むことができるようにする技術です。電子メールの内容が第三者によって傍受されるのを防ぎます。
正解についての説明：
（選択肢）
・多要素認証
この選択肢が正解の理由は以下の通りです。
多要素認証は、ユーザーが自分自身であることを証明するために2つ以上の要素を必要とする認証方法です。これには、ユーザー自身しか知らない情報（パスワードやピン）、ユーザー自身が所有する物品（トークンやスマートフォン）、ユーザー自身の生体情報（指紋や声）などが含まれます。多要素認証を使用することで、認証情報がフィッシングなどの詐欺的な手口で盗まれても、不正なアクセスを防ぐことができます。なぜなら、盗まれた認証情報だけではアクセスが完全に許可されないからです。そのため、多要素認証は、フィッシングメールのようなセキュリティ攻撃からユーザーを守る重要な手段となります。フィッシングメールの受信が増えている組織で、従業員の認証情報を保護するためには、多要素認証の導入を検討すべきです。
不正解についての説明：
選択肢：厳格なパスワードポリシー
この選択肢が正しくない理由は以下の通りです。
厳格なパスワードポリシーはパスワードを安全に保つために有用ですが、フィッシングメールによる認証情報の盗難に対しては十分な保護を提供できません。多要素認証の方がフィッシング対策としては優れているため、フィッシング防止のための最適な手段です。
選択肢：ログインページのCaptcha
この選択肢が正しくない理由は以下の通りです。
Captchaは自動化された異常な活動やボットからの認証を防ぐためのものであり、フィッシング攻撃からの従業員の認証情報を保護するのには不適切です。多要素認証の適用は、従業員の認証情報をフィッシングから保護する効果的な手段であり、これがより適切な選択となります。
選択肢：暗号化された電子メール
この選択肢が正しくない理由は以下の通りです。
暗号化された電子メールは、電子メールの内容を保護するもので、フィッシングメールから従業員の認証情報を保護する直接的な対策ではありません。
一方、多要素認証はユーザーが本人であることを確認する追加のステップを提供し、フィッシング攻撃から認証情報を保護します。
参考リンク：
https://cloud.google.com/iam/docs/multifactor-authentication
https://cloud.google.com/identity-platform/docs/web/mfa
https://support.google.com/a/answer/9213912?hl=en
</div></details>

### Q.  問題46: 未回答
あなたの組織はGoogle Cloudに移行しています。プロジェクト内のGoogle Kubernetes Engine（GKE）クラスターに、信頼できるコンテナイメージのみがデプロイされるようにしたいと考えています。コンテナは、一元管理されたArtifact Registryからデプロイされ、信頼できる機関によって署名されている必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. バイナリ認証ポリシーを、プロジェクトのそれぞれの認証とともに設定します
2. PodSecurity標準を有効にし、Restrictedに設定します
3. Google Kubernetes Engine（GKE）のバイナリ認証を強制するカスタム組織ポリシー制約を作成します
4. プロジェクトのSecurity Command Center（SCC）でContainer Threat Detectionを有効にします
5. プロジェクトの信頼済みイメージ組織ポリシー制約を設定します
<details><div>
    答え：1,5
この問題では、Google Kubernetes Engineのコンテナデプロイのセキュリティ要件に対する理解が求められています。このケースでは、特定の信頼度を持つコンテナイメージのみが許可されるようにする必要があります。選択肢を検討する際には、信頼できる機関によるイメージの署名やイメージのデプロイ元を制御できるオプションを選ぶべきであり、一方で、単にコンテナの脅威検出やPodSecurity標準に関する選択肢は問題文の要求を満たさないことに注意してください。
基本的な概念や原則：
信頼済みイメージ組織ポリシー制約：Google Cloudのポリシー制約です。特定のコンテナイメージのみがデプロイされるように制御します。
Artifact Registry：Google Cloudのパッケージ管理サービスです。一元管理されたレジストリにDockerイメージなどのアーティファクトを保存し、共有できます。
バイナリ認証：Google Cloudのセキュリティ機能の一つで、特定のソースからのコンテナイメージのデプロイを管理する機能です。イメージの署名に基づいて、デプロイを許可または拒否します。
Security Command Center（SCC）：Google Cloudの統合脅威防止プラットフォームです。全てのプロジェクトとリソースのセキュリティとデータリスクを管理します。ただし、コンテナイメージの信頼性を保証する機能はありません。
PodSecurity標準：Kubernetesのセキュリティ特性の一つで、Podに対するアクセスを制限します。しかし、コンテナイメージの信頼性を保証する機能はありません。
正解についての説明：
（選択肢）
・プロジェクトの信頼済みイメージ組織ポリシー制約を設定します
・バイナリ認証ポリシーを、プロジェクトのそれぞれの認証とともに設定します
この選択肢が正解の理由は以下の通りです。
まず、プロジェクトの信頼済みイメージ組織ポリシー制約を設定することで、GKEクラスターにデプロイ可能なコンテナイメージを管理することが可能になります。これにより、制約に従って管理されたArtifact Registryからコンテナイメージが提供され、その結果として一貫性とセキュリティが確保されます。これは要件で述べられた信頼できる機関によって署名されたイメージのみがデプロイされることを保証します。
また、バイナリ認証ポリシーを設定することで、指定された信頼条件を満たすコンテナイメージのみがデプロイされるようになります。これはGoogle Cloudのバイナリ認証機能を利用します。この機能は、デプロイされるイメージが信頼できる機関によって署名され、特定のセキュリティ基準を満たしていることを保証します。これらの2つの選択肢は連携して働き、プロジェクト内のGKEクラスターに信頼性の高いコンテナイメージのみがデプロイされることを実現します。
不正解についての説明：
選択肢：プロジェクトのSecurity Command Center（SCC）でContainer Threat Detectionを有効にします
この選択肢が正しくない理由は以下の通りです。
Security Command CenterのContainer Threat Detectionは既にデプロイされたコンテナから不正な行動を検知しますが、信頼できるコンテナイメージがデプロイされることを事前に確保するためのものではありません。正答の選択肢は、信頼済みイメージポリシー及びバイナリ認証ポリシーがそのロールを果たします。
選択肢：Google Kubernetes Engine（GKE）のバイナリ認証を強制するカスタム組織ポリシー制約を作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloudではカスタム組織ポリシー制約を作成することはできません。
一方、正解の選択肢のように、既存の信頼済みイメージ組織ポリシー制約を設定したり、バイナリ認証ポリシーを設定することで、信頼できるコンテナイメージのみがGKEクラスターにデプロイされるように制御できます。
選択肢：PodSecurity標準を有効にし、Restrictedに設定します
この選択肢が正しくない理由は以下の通りです。
PodSecurity標準を有効にして、Restrictedに設定する方法は、コンテナの動作の制限やセキュリティポリシーの適用に利用されますが、信頼性の高いコンテナイメージのデプロイメントに対する制御ではないため要件を充足しません。
それに対して、信頼済みイメージ組織ポリシーやバイナリ認証ポリシーはイメージの信頼性を保証するための機能です。
参考リンク：
https://cloud.google.com/binary-authorization/docs
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/kubernetes-engine/docs/how-to/binary-authorization
</div></details>

### Q.  問題47: 未回答
あなたは組織のセキュリティオペレーションセンター（SOC）を管理しています。現在、ネットワークログに基づいてVPC内のネットワークトラフィックの異常を監視および検出しています。しかし、ネットワークペイロードとヘッダーを使用して環境を調査したいと考えています。
どのGoogle Cloudサービスを使用すべきですか？
1. VPCフローログ
2. Google Cloud Armor
3. Packet Mirroring
4. VPC Service Controlsログ
5. Cloud IDS
<details><div>
    答え：3
この問題では、ネットワークの活動に関する詳しい情報を取得するためのGoogle Cloudのサービスを選ぶ必要があります。問題はネットワークログを使った異常監視から、ネットワークペイロードとヘッダーの調査へと関心が移ることを示しています。したがって、選択肢を検討する際には、ネットワークペイロードとヘッダーの深い洞察を提供する機能を持つサービスを選ぶべきです。
基本的な概念や原則：
Packet Mirroring：Google Cloud上の仮想マシン（VM）インスタンスのネットワークペイロードとヘッダーを検査できるサービスです。外部ネットワーク監視ツールと連携してネットワークトラフィックの異常検出を行います。
Cloud IDS：Google Cloud上のネットワークインフラストラクチャの侵入検知システム（IDS）です。ネットワーク内の不審な動きを検出し、セキュリティイベントを報告します。
VPC Service Controlsログ：VPC Service Controlsの活動やセキュリティイベントを追跡するためのログです。データの外部への潜在的な漏洩を予防します。
VPCフローログ：VPCネットワークのIPトラフィックをキャプチャし記録するサービスです。ネットワークパフォーマンスの問題のトラブルシューティングやセキュリティ分析に利用します。
Google Cloud Armor：Google Cloud上のネットワークリソースを保護するセキュリティサービスです。DDoS攻撃の防止やWebアプリケーションファイアウォール（WAF）機能を提供します。
正解についての説明：
（選択肢）
・Packet Mirroring
この選択肢が正解の理由は以下の通りです。
Packet MirroringはGoogle Cloudのサービスで、ネットワークペイロードとヘッダーの詳細な監視と調査が可能となります。対象となるインスタンスのネットワークトラフィックのコピーを作成し、分析のために別のインスタンスまたはネットワークインタフェースに送信します。これにより、異常や脅威を検出し、状況を解析するための詳細な情報を提供します。
ネットワークの検出やトラフィック分析、監視に関心があるセキュリティオペレーションセンター（SOC）の運用には、Packet Mirroringは極めて有効なツールです。なぜなら、このツールを使用すれば、実際のネットワークトラフィックを直接調査することができ、問題の早期発見と迅速な対応が可能となるからです。この機能は、セキュリティ監視と対策の観点から見て重要です。
不正解についての説明：
選択肢：Cloud IDS
この選択肢が正しくない理由は以下の通りです。
Cloud IDSはサービス全体のネットワークトラフィックを監視し、潜在的な脅威を自動的に検出するサービスですが、ネットワークペイロードとヘッダーの詳細な調査には対応していません。
一方、Packet Mirroringは指定したVPCの一部または全部のネットワークトラフィックをミラーリングし、ペイロードとヘッダーの詳細な分析に利用することが可能です。
選択肢：VPC Service Controlsログ
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsログは、Google Cloudリソースの横断的なアクセス制御やデータ漏えいの防止を主に扱うので、ネットワークペイロードやヘッダを使用した環境調査の目的には合致しません。対してPacket MirroringはVPCネットワークのトラフィックを複製して分析するためのサービスであり、求められている要件を満たします。
選択肢：VPCフローログ
この選択肢が正しくない理由は以下の通りです。
VPCフローログでは、トラフィックのメタデータ、つまり送信者と受信者のIP、パケットサイズ、プロトコル情報等しか取得できません。しかし、ネットワークペイロードやヘッダーの詳細は取得できません。
一方、Packet Mirroringはネットワークペイロードとヘッダー情報を提供します。従ってこの課題に適したサービスはPacket Mirroringです。
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは、DDoS攻撃防御やWebアプリケーション防火壁（WAF）能力を提供するサービスであり、ネットワークペイロードやヘッダーを調査する機能は含まれていません。
一方、Packet Mirroringは特定のトラフィックをミラーリングし、その内容を詳細に調査することを可能にします。
参考リンク：
https://cloud.google.com/traffic-director/docs/packet-mirroring
https://cloud.google.com/network-intelligence-center/docs/using-packet-mirroring
https://cloud.google.com/ids
</div></details>

### Q.  問題48: 未回答
あなたは、Compute Engine上でホストされているCI/CDクラスターを使用して、クラウドインフラストラクチャをデプロイすることを計画しています。あなたは、その認証情報が第三者に盗まれるリスクを最小限に抑えたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. クラスター専用のCloud Identityユーザーアカウントを作成します。プロジェクトレベルでconstraints/iam.disableServiceAccountCreation組織ポリシーを有効にします
2. クラスター専用のCloud Identityユーザーアカウントを作成します。強力なセルフホスト型データ保管庫ソリューションを使用して、ユーザの一時的な資格情報を保管します
3. クラスターのカスタムサービスアカウントを作成します。プロジェクトレベルでconstraints/iam.disableServiceAccountKeyCreation組織ポリシーを有効にします
4. クラスター専用のカスタムサービスアカウントを作成します。プロジェクトレベルでconstraints/iam.allowServiceAccountCredentialLifetimeExtension組織ポリシーを有効にします
<details><div>
    答え：3
この問題では、認証情報の防御策をどのように設定するべきか、具体的には、適切な組織ポリシーとアカウントタイプを利用してCI/CDクラスターの保護をどう実現するかを考察する必要があります。認証情報が盗まれるリスクを最小限に抑えるためには、アカウントの生成、管理方法、そしてその制限に留意することが不可欠です。ポリシー制限によるキー生成の抑制やアカウントタイプの選択による分離など、具体的な戦略を評価する際には、そのアプローチがセキュリティリスクをどの程度に減少させるかを重視してください。
基本的な概念や原則：
カスタムサービスアカウント：Google CloudのアプリケーションがGoogleサービスと通信するために使用する特殊なGoogleアカウントです。特定のサービスへの認証と権限を制御します。
組織ポリシー：Google Cloudのリソースへのアクセスを制御するためのルールです。特定のリソースに対して制限を設けたり、特定のアクションを許可したりすることができます。
constraints/iam.disableServiceAccountKeyCreation：この組織ポリシーを有効にすると、サービスアカウントキーの作成が禁止されます。これにより、認証情報が不正に利用されるリスクを最小限に抑えることができます。
Cloud Identity：Google Cloudの統合されたIdentity and Access Managementサービスです。ユーザーやサービスアカウントの資格情報を管理します。
セルフホスト型データ保管庫：ユーザーが自身のサーバーにデータを保管するためのソリューションです。しかし、一時的な資格情報を保管する場合、最新のセキュリティアップデートが必要なため、リスクが高まることがあります。
constraints/iam.allowServiceAccountCredentialLifetimeExtension：この組織ポリシーを有効にすると、サービスアカウント資格情報の有効期限を延長することが可能になります。しかし、資格情報の有効期限を適切に管理しないと、認証情報の不正利用のリスクが高まります。
正解についての説明：
（選択肢）
・クラスターのカスタムサービスアカウントを作成します。プロジェクトレベルでconstraints/iam.disableServiceAccountKeyCreation組織ポリシーを有効にします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudではサービスアカウントを使用して、アプリケーションに対して特定のGoogle Cloudリソースへのアクセス権を与えることができます。これはCI/CDクラスターが必要とする認証に対する非常にスマートなアプローチで、アプリケーションにユーザーアカウントを使用させる代わりに、限定的で監査可能なアクセス権を与えることが可能です。
加えて、組織ポリシー"constraints/iam.disableServiceAccountKeyCreation"を有効にすると、サービスアカウントキーの作成が無効化されます。これにより、これらのキーが漏洩して不適切に使用されるリスクを最小限に抑えることができます。このため、この選択肢が安全な認証ソリューションであると言えます。
不正解についての説明：
選択肢：クラスター専用のCloud Identityユーザーアカウントを作成します。強力なセルフホスト型データ保管庫ソリューションを使用して、ユーザの一時的な資格情報を保管します
この選択肢が正しくない理由は以下の通りです。
Cloud Identityユーザーアカウントは人間のユーザー向けであり、サービス間の認証には不適切です。
また、一時的な資格情報をセルフホスト型データ保管庫に保存すると、認証情報が盗まれるリスクが増えます。これは正解の選択肢がサービスアカウントキーの作成を無効にする組織ポリシーを使用することで、これらのリスクを軽減しているのと対照的です。
選択肢：クラスター専用のCloud Identityユーザーアカウントを作成します。プロジェクトレベルでconstraints/iam.disableServiceAccountCreation組織ポリシーを有効にします
この選択肢が正しくない理由は以下の通りです。
Cloud Identityユーザーアカウントは人間のユーザー向けであり、サービス間の認証で使用するべきではありません。
また、サービスアカウントの作成を無効にすると、新たなサービスや機能が追加された場合に柔軟に対応できなくなる可能性があります。これらは認証情報のリスクを最小限に抑えるという要件を満たしません。
選択肢：クラスター専用のカスタムサービスアカウントを作成します。プロジェクトレベルでconstraints/iam.allowServiceAccountCredentialLifetimeExtension組織ポリシーを有効にします
この選択肢が正しくない理由は以下の通りです。
constraints/iam.allowServiceAccountCredentialLifetimeExtensionポリシーは、認証情報の有効期限を延長するためのものであり、認証情報の盗難リスクを軽減するためのものではありません。それと対照的に、正解の選択肢ではサービスアカウントキー作成を無効化することで、認証情報の盗難リスクを軽減することが可能です。
参考リンク：
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/access/service-accounts
</div></details>

### Q.  問題49: 未回答
あなたは、Google Cloudで会社のIDを管理する責任者です。あなたの会社では、すべてのユーザーに対して2段階認証（2SV）を実施しています。あるユーザのアクセスをリセットする必要がありますが、そのユーザは2SVの2つ目の要素を失いました。リセットにあたっては、リスクを最小限に抑える必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. Google管理コンソールで、特権管理者アカウントを使用してユーザーアカウントの認証情報をリセットします。初回ログイン後に認証情報を更新するようユーザーに依頼します
2. Google管理コンソールで、すべてのユーザーの2SV要件を一時的に無効にします。ユーザーにログインしてもらい、アカウントに新しいセカンドファクターを追加します。全ユーザーの2SV要件を再度有効にします
3. Google管理コンソールで、該当するユーザーアカウントを選択し、このアカウントの2段階認証を一時的に無効にします。ユーザーにセカンドファクターを更新するよう依頼し、このアカウントの2段階認証を再度有効にします
4. Google管理コンソールで、適切なユーザーアカウントを選択し、ユーザーがログインできるようにバックアップコードを生成します。ユーザーにセカンドファクターを更新するよう依頼します
<details><div>
    答え：3
この問題では、Google CloudでのID管理について考えることが求められています。特に2段階認証（2SV）のリセットに関する問題で、リスクを最小限に抑える解決策を探すことが必要です。該当ユーザーだけに影響を与え、他のユーザーや特権管理者アカウントが関与しない方法を選ぶべきです。また、安全性を保つために、ユーザーが新しいセカンドファクターを設定するように促すことが求められます。
基本的な概念や原則：
Google管理コンソール：Google Cloudのアカウントやサービスの管理を一元化して行うツールです。ユーザーアカウントの設定変更や、認証の有効・無効化などを行うことができます。
2段階認証（2SV）：セキュリティを強化するための認証手法の一つで、ユーザー名とパスワードだけでなく、さらに一つの要素（通常はスマートフォンやセキュリティキーなど）の確認を求める手法です。
バックアップコード：ユーザーが2段階認証の2つ目の要素を失った場合やアクセスできなくなった場合に、代わりに使用できるコードのことです。ただし、不適切な管理により漏洩するリスクがあります。
特権管理者アカウント：システム全体を管理するためのアカウントで、一般のユーザーアカウントよりも高い権限を持っています。このアカウントを利用してユーザーのアカウント設定を変更することが可能ですが、セキュリティ上のリスクも含まれます。
認証情報のリセット：ユーザーがログインできなくなったときなどに行う操作です。初回ログイン後に認証情報を更新するよう依頼することで、セキュリティの維持と利便性の両立を図ります。
正解についての説明：
（選択肢）
・Google管理コンソールで、該当するユーザーアカウントを選択し、このアカウントの2段階認証を一時的に無効にします。ユーザーにセカンドファクターを更新するよう依頼し、このアカウントの2段階認証を再度有効にします
この選択肢が正解の理由は以下の通りです。
Google管理コンソールを使用してユーザーの二段階認証を一時的に無効にすることで、セキュリティの基本的な原則である最小権限の原則を維持しつつ、ユーザーが再度アクセスできるようにすることが可能です。一時的に二段階認証を無効にすることで、ユーザーはセカンドファクター無しでもログインが可能となります。その後、ユーザーに新たなセカンドファクターを設定し直すよう依頼します。再設定が完了したら、二段階認証を再び有効にすることでセキュリティのレベルを元に戻すことができます。これにより、ユーザーのアクセスをリセットしつつ、同時にセキュリティリスクを最小限に抑えることができます。
不正解についての説明：
選択肢：Google管理コンソールで、適切なユーザーアカウントを選択し、ユーザーがログインできるようにバックアップコードを生成します。ユーザーにセカンドファクターを更新するよう依頼します
この選択肢が正しくない理由は以下の通りです。
バックアップコードを生成するだけでは、既存の2段階認証が残っている可能性があり、リスクを最小限に抑えるためには不適切です。正解の選択肢は2段階認証を一時的に無効にし、セカンドファクター更新後再度有効にすることで安全性を担保しています。
選択肢：Google管理コンソールで、すべてのユーザーの2SV要件を一時的に無効にします。ユーザーにログインしてもらい、アカウントに新しいセカンドファクターを追加します。全ユーザーの2SV要件を再度有効にします
この選択肢が正しくない理由は以下の通りです。
すべてのユーザーの2段階認証を無効にすることは、セキュリティリスクが大幅に増加します。
それに対して、正解の選択肢は特定のユーザーだけの2段階認証を一時的に無効化するため、他のユーザーのセキュリティ状態を維持でき、リスクを最小限に抑えています。
選択肢：Google管理コンソールで、特権管理者アカウントを使用してユーザーアカウントの認証情報をリセットします。初回ログイン後に認証情報を更新するようユーザーに依頼します
この選択肢が正しくない理由は以下の通りです。
特権管理者アカウントで認証情報をリセットすると、リセット後の認証情報が漏洩するリスクが発生します。
それに対して、2段階認証を一時的に無効にし、ユーザーにセカンドファクターの変更を依頼する方法なら、ユーザーだけが新しい認証情報を知り得ます。
参考リンク：
https://cloud.google.com/identity-platform/docs/managing-mfa
https://cloud.google.com/identity/docs/how-to/manage-2sv
https://support.google.com/a/answer/2537800?hl=en
</div></details>

### Q.  問題50: 未回答
ある顧客が、Google Cloud上で3層の社内ウェブアプリケーションを立ち上げる必要があります。この顧客の社内コンプライアンス要件では、エンドユーザーのアクセスは、トラフィックが特定の既知のCIDRから発信されていると思われる場合にのみ許可されることになっています。顧客は、アプリケーションにSYNフラッドDDoS防御しかないリスクを受け入れています。Google CloudのネイティブSYNフラッド防御を使用したいと考えています。
これらの要件を満たすには、どの製品を使用すべきですか？
1. VPCファイアウォールルール
2. Cloud Armor
3. Cloud Identity and Access Management
4. Cloud CDN
<details><div>
    答え：2
この問題では、顧客の具体的な要求と、それに応じるためのGoogle Cloudの製品を正しくマッチングする能力が求められています。社内ウェブアプリケーションの立ち上げ、特定のCIDRからのトラフィック制限、SYNフラッドDDoS防御の要望に注目が必要です。選択肢はGoogle Cloudのサービス群からなるため、それぞれの製品の機能と上記の要求とを適切にリンクできる知識が必要となります。
基本的な概念や原則：
Cloud Armor：Google CloudのWebアプリケーションのセキュリティーポリシーサービスです。DDoS攻撃防御と特定の既知のCIDRからのトラフィックに対するアクセス制御を提供します。
CIDR（Classless Inter-Domain Routing）：IPアドレスとそのネットワークを指定するための表現方法です。特定のIP範囲からのアクセスを制御するために使用されます。
SYNフラッド攻撃：TCP/IPプロトコルの脆弱性を利用したDDoS攻撃の一種です。大量のSYNパケットを送信し、サーバーのリソースを枯渇させることを狙います。
VPCファイアウォールルール：Google Cloud VPCのリソースへのネットワークアクセスを制御するためのファイアウォールルールです。IP範囲や特定のプロトコルとポートに対するトラフィックを許可または拒否しますが、SYNフラッド防御は提供しません。
Cloud Identity and Access Management：Google Cloudリソースへの認証と認可を管理するためのサービスです。特定のユーザーまたはサービスアカウントに対するリソースアクセスの許可を制御します。
Cloud CDN：Google Cloudのコンテンツ配信ネットワーク（CDN）サービスです。Webアプリケーションのパフォーマンス向上を目指すものであり、DDoS攻撃防御やCIDRベースのアクセス制御は提供しません。
正解についての説明：
（選択肢）
・Cloud Armor
この選択肢が正解の理由は以下の通りです。
まず、Cloud Armorは、Google Cloudの負荷分散サービスに組み込まれており、ネットワークレベルでの防御機能を提供します。これにより、SYNフラッドといったDDoS攻撃を防ぐことができます。
また、ネットワークトラフィックを制御するルールを簡単に作成し、管理することができます。
さらに、Cloud ArmorはIPベースのアクセス制御も提供します。特定のCIDRからのアクセスだけを許可するという要件もCloud Armorで容易に実現することができます。これにより、企業は自身のコンプライアンスポリシーに基づいてエンドユーザーのアクセスを管理できます。
このように、顧客が社内コンプライアンス要件を満たしながら、Google Cloud上でのウェブアプリケーションの保護を確保するためには、Cloud Armorの利用が最適と言えます。
不正解についての説明：
選択肢：VPCファイアウォールルール
この選択肢が正しくない理由は以下の通りです。
VPCファイアウォールルールは、特定のIPアドレス範囲からのトラフィックをコントロールする機能を提供しますが、SYNフラッドDDoS防御の機能を提供しないため、ここでの要件を満たすことはできません。
一方、Cloud ArmorはGoogle CloudのネイティブSYNフラッド防御機能を備えているため、顧客の要件に適しています。
選択肢：Cloud Identity and Access Management
この選択肢が正しくない理由は以下の通りです。
Cloud Identity and Access Managementは、Google Cloudリソースへのアクセスを制御する目的で使用されますが、特定のCIDRからのアクセス制御やSYNフラッドDDoS防御といったネットワーク層の要件を満たす機能は提供していません。
一方、Cloud ArmorはトラフィックのフィルタリングとDDoS攻撃からの保護を提供し、問題の要件を満たします。
選択肢：Cloud CDN
この選択肢が正しくない理由は以下の通りです。
Cloud CDNはコンテンツ配信ネットワークであり、特定のCIDRからのトラフィックの制限やSYNフラッドDDoS防御といった機能は提供していません。
それに対して、Cloud Armorはネットワークトラフィックの制御やDDoS攻撃の防御を提供する製品であり、要件に適しています。
参考リンク：
https://cloud.google.com/armor/docs/security-policy-concepts
https://cloud.google.com/armor/docs/ddos-defender-overview
https://cloud.google.com/vpc/docs/firewalls
</div></details>



## 2

### Q.  問題1: 未回答
新規ユーザをCloud Identityにオンボーディングしているときに、一部のユーザが企業ドメイン名を使用してコンシューマユーザアカウントを作成していることに気付きました。
Cloud Identityでこれらのコンシューマーユーザーアカウントをどのように管理すべきですか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、企業ドメイン名を使用して作成されたコンシューマユーザーアカウントをCloud Identityでどのように管理するべきかを考える必要があります。このシナリオでは、企業の管理下にない（管理されていない）ユーザーアカウントの取り扱いが焦点となります。選択肢を評価する際には、これらのアカウントを条件に合わせて適切に管理し、組織のセキュリティポリシーやユーザ管理の要件を満たすための手段を選ぶことが求められます。
基本的な概念や原則：
Cloud Identity：Google Cloudのアイデンティティーやアクセス管理（IAM）サービスの一部で、ユーザー、グループ、デバイスの管理を容易にします。
コンシューマユーザアカウント：個々のユーザーがGoogleサービスを利用するために作成するアカウントです。企業用途ではない場合に使用されます。
管理されていないアカウント：企業が所有するドメイン名で作成されたが、企業による管理下にないユーザーアカウントを指します。
転送ツール：一般的に、データをある場所から別の場所へ効率的に移動させるためのツールです。ここでは、管理されていないアカウントをCloud Identityに取り込むためのツールを指すと解釈できます。
Google Cloud Directory Sync：Google Cloudと企業のLDAPディレクトリ（例：Active Directory）を同期させるサービスです。
シングルサインオン（SSO）：複数のサービスやアプリケーションに対して、一度のログインでアクセスを可能にする認証方式です。
正解についての説明：
（選択肢）
・管理されていないユーザーアカウントには、転送ツールを使用します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudには転送ツールが用意されていて、これを使用すると管理されていないユーザーアカウントのメールやドライブデータを管理されるアカウントに移動することができます。このツールは、ユーザーが企業ドメイン名でコンシューマユーザアカウントを作成し、データやメールなどをそのアカウントで利用してた場合、それらの情報をすべて移行する際に有用です。
また、コンシューマユーザーアカウントが企業のデータを保持していて、その管理が難しいという状況に対しても有効な解決法となります。
このように、転送ツールを使用することで企業ドメイン名を使用して作成されたコンシューマユーザーアカウントのデータを適切に管理することが可能となります。これにより、データの逸脱を防ぎつつ適切なユーザーアカウント管理を実現できます。
不正解についての説明：
選択肢：Google Cloud Directory Syncを使用して、管理されていないユーザーアカウントを変換します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Directory Syncは既存のLDAPディレクトリとGoogle Cloud Identityを同期するためのツールであり、管理されていないユーザーアカウントの変換には使用できません。
それに対して、転送ツールはGoogle Cloud Identityで管理されていないユーザーアカウントのデータを移行するための正解選択肢です。
選択肢：コンシューマユーザアカウントごとに新しい管理ユーザアカウントを作成します
この選択肢が正しくない理由は以下の通りです。
新しい管理ユーザーアカウントを作成すると、既存のコンシューマアカウントとの関連性が失われしまいます。
それに対して、転送ツールを使用することで、既存のコンシューマユーザーアカウントをCloud Identityに移行でき、既存のデータや設定を引き継ぐことが可能となるため正解となります。
選択肢：顧客のサードパーティプロバイダを使用してシングルサインオンを構成します
この選択肢が正しくない理由は以下の通りです。
サードパーティプロバイダを使用してシングルサインオンを構成する方法では、企業ユーザーがコンシューマアカウントを作成してしまった問題には対処できません。企業のドメイン名を使用したユーザーアカウントをCloud Identityで一元的に管理するために、転送ツールを使用し、管理されていないアカウントを管理下に置く方法が適しています。
参考リンク：
https://cloud.google.com/identity/docs/manage-unmanaged-users
https://cloud.google.com/identity/docs/how-to/setup#migrate-unmanaged
https://support.google.com/a/answer/10026322?hl=en
</div></details>

### Q.  問題2: 未回答
ある顧客がGoogle Cloud上で分析ワークロードを実行しており、Compute EngineインスタンスがCloud Storageに保存されたデータにアクセスしています。
あなたのチームは、このワークロードがインターネットにアクセスしたり、インターネットからアクセスされたりしないようにしたいと考えています。
あなたのチームは、これらの要件を満たすためにどの2つの戦略を使用する必要がありますか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute EngineインスタンスがCloud Storageに安全にアクセスする方法と、インターネットからのアクセスを防ぐ適切な戦略を選択するための理解が求められています。重要なのは、計算エンジンインスタンスが必要なリソースに限定的な内部からのアクセスのみを保証する戦略を理解し、それによりインターネットへのエクスポージャーを排除することです。各オプションがどのようにこれらの要件に対応するかを考えて選択肢を見極めてください。
基本的な概念や原則：
プライベートGoogleアクセス：特定のサブネットから、パブリックのインターネット上ではなくGoogleの内部ネットワーク経由でGoogle CloudのAPIとサービスにアクセスできる設定です。パブリックIPアドレスを割り当てなくても、Google Cloudのリソースにアクセス可能になります。
パブリックIPアドレスの割当：Compute EngineインスタンスなどのGoogle Cloudのリソースにパブリックインターネットからアクセス可能なIPアドレスを割り当てることです。インターネットからのアクセスを防ぐためには、パブリックIPアドレスを割り当てない設定が必要です。
サブネット：ネットワーク内の異なるセクションまたはセグメントのことです。通常、サブネットはセキュリティと性能を向上させるために使用されます。
IPフォワーディング：一つのインスタンスが他のインスタンスへとネットワークトラフィックを中継することです。しかし、この設定はインターネット接続を防ぐものではありません。
Cloud NAT：プライベートIPアドレスのリソースがインターネットにアクセスする際にNATを行うマネージドサービスです。このケースではインターネット接続を防ぐためには適しません。
正解についての説明：
（選択肢）
・Compute EngineのサブネットでプライベートGoogleアクセスを設定する
・Compute EngineクラスターにパブリックIPアドレスを割り当てないようにします
この選択肢が正解の理由は以下の通りです。
まず、"Compute EngineのサブネットでプライベートGoogleアクセスを設定する"という選択肢についてですが、プライベートGoogleアクセスを設定することでCompute Engineインスタンスが私有IPアドレスを使用してGoogle CloudのAPIやサービスにアクセスすることが可能なるため、この選択肢が適切です。この機能により、インスタンスはCloud StorageなどのGoogle Cloudサービスに接続できますが、インターネットにはアクセスできません。
次に、"Compute EngineクラスターにパブリックIPアドレスを割り当てないようにします"という選択肢ですが、この設定により、Compute Engineインスタンスはインターネットからアクセスされる可能性が極めて少なくなります。パブリックIPアドレスを持つと、そのインスタンスはインターネット上から直接アクセス可能となり、セキュリティリスクが高まりますが、パブリックIPアドレスを割り当てないことによって、そのリスクを減らすことが可能です。
したがって、これら2つの戦略を使用することで、インターネットを経由せずにGoogle Cloud内でデータに安全にアクセスすることが可能となります。
不正解についての説明：
選択肢：Compute Engineクラスターが別のサブネットで実行されていることを確認します
この選択肢が正しくない理由は以下の通りです。
Compute Engineクラスターが別のサブネットで実行されているか否かは、インターネットへのアクセス制限には直接影響を与えません。正解の戦略ではインターネットからの接続を防ぐためにパブリックIPを割り当てず、プライベートGoogleアクセスを使ってCloud Storageに安全にアクセスします。
選択肢：クラスター内のCompute EngineインスタンスのIPフォワーディングをオフにします
この選択肢が正しくない理由は以下の通りです。
IPフォワーディングをオフにするとは、該当のインスタンスが他のネットワークインターフェースを通じてトラフィックを送信または受信できないようにすることを意味します。しかし、これはインターネット接続を防ぐものではなく、正解の選択肢にあるように、パブリックIPアドレスを割り当てない事やプライベートGoogleアクセスを設定する事が必要です。
選択肢：Cloud NATゲートウェイを設定します
この選択肢が正しくない理由は以下の通りです。
Cloud NATゲートウェイはプライベートネットワークからインターネットへの出口専用接続を提供しますが、問題で求められているのはインターネットへのアクセスを制限し、Cloud Storageへのプライベートなアクセスを設定することです。この要件はプライベートGoogleアクセスとパブリックIPの未割当てによって達成できます。
参考リンク：
- https://cloud.google.com/vpc/docs/configure-private-google-access
- https://cloud.google.com/vpc/docs/using-private-google-access
- https://cloud.google.com/compute/docs/ip-addresses#reserved
</div></details>

### Q.  問題3: 未回答
あなたの組織の記録データはCloud Storageに存在します。すべての記録データを少なくとも7年間保持しなければなりません。このポリシーは永続的でなければなりません。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud Storageを使って特定のデータを最低でも7年間保管するための設定方法について問われています。問題を解く際には、あなたの要件を満たす最適な方法を選ぶ必要があります。この問題のキーポイントは、データを"永続的に"保持する必要があることです。また、仕様として少なくとも7年間データを保持するとの要件があります。重要なのは、このデータを保持する施策が永続的であるためにはどうすればよいのかを理解することです。そのためには、Cloud Storageの特徴と、保持ポリシーとバケットロックの使用方法を理解することが重要となります。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。大量のデータを保存し、任意の位置からアクセスすることが可能です。
保持ポリシー：Google Cloud Storageで特定の期間、オブジェクトを保持するために設定するポリシーです。設定期間が過ぎると、自動的にオブジェクトが削除されます。
バケットロック：Google Cloud Storageの機能で、保持ポリシーまたは保持期間を永続的に適用します。バケットロックが有効になると、ポリシーの削除や削減ができなくなります。
ログベースのアラート：Google Cloudの機能で、ログデータに基づいてアラートを生成します。保持ポリシーの変更を監視するために使用することもできますが、バケットロックが有効になっていれば不要です。
Identity and Access Management（IAM）：Google Cloudのサービスで、クラウドリソースへのアクセスを管理します。特定のロールを削除することで、リソースへのアクセスを制限することが可能です。
正解についての説明：
（選択肢）
・1. レコードデータが含まれるバケットを特定します
2. 保持ポリシーを適用し、7年間保持するように設定します
3. バケットロックを有効にします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageバケットに記録データが保存されている前提から、バケットを特定することは本質的に重要となる初めのステップです。
次に、指定期間データを保持するためには保持ポリシーを適用し、その期間を7年間と設定します。この保持ポリシーはオブジェクトの保持期限を制御し、指定期間は削除や上書きができないように制約をかけます。
最後に、このポリシーを永続的にするために、バケットロックを有効にすることで、一度設定された保持ポリシーは変更や削除が不可能となります。これにより、保持期間が終わるまでデータが安全に保護されます。以上の3つのステップが記録データを7年間保持し続けるための適切な手順です。
不正解についての説明：
選択肢：1. レコードデータが含まれるバケットを特定します
2. 保持ポリシーを適用し、7年間保持するように設定します
3. ログベースのアラートを使用してバケットを監視し、保持ポリシーが変更されないようにします
この選択肢が正しくない理由は以下の通りです。
ログベースのアラートは保持ポリシーの変更を検知して警告するものの、その変更を物理的に防ぐことはできません。
それに対して、バケットロックを有効にすると、保持ポリシーが変更されることを物理的に防ぐことができ、この要件を満たす永続性が確保されます。
選択肢：1. レコードデータが含まれるバケットを特定します
2. 保持ポリシーを適用し、7年間保持するように設定します
3. ストレージバケットの更新権限を含むIdentity and Access Management（IAM）ロールを削除します
この選択肢が正しくない理由は以下の通りです。
IAMロールを削除することは、保持ポリシーが永続的に適用されることを保証しません。
それに対して、バケットロックを有効にすると、保持ポリシーは永久的で変更不可能になり、その要件をはるかにより完全に満たします。
選択肢：1. レコードデータが含まれるバケットを特定します
2. データが確実に保持されるようにするためにのみバケットポリシーを有効にします
3. バケットロックを有効にします
この選択肢が正しくない理由は以下の通りです。
バケットポリシーのみを有効にしても7年間のデータ保持を実現することはできません。保持ポリシーを設定して、データが特定の期間削除されないようにしなければなりません。バケットポリシーはデータへのアクセスを制御しますが、7年間のデータ保持を強制することはできません。
参考リンク：
https://cloud.google.com/storage/docs/bucket-lock
https://cloud.google.com/storage/docs/using-bucket-policies#retention
https://cloud.google.com/storage/docs/using-object-versioning
</div></details>

### Q.  問題4: 未回答
あなたの会社では、セキュリティチームとネットワークエンジニアリングチームがすべてのネットワーク異常を特定し、VPC内のペイロードをキャプチャできるようにする必要があります。
どの方法を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のセキュリティとネットワーク監視に関する具体的な要件を満たす最適なソリューションを正確に識別することが求められています。具体的には、すべてのネットワーク異常を特定し、VPC内のペイロードをキャプチャできる必要があります。これらの要素を考えるときには、ネットワークトラフィックの視覚化や分析、そしてペイロードキャプチャが可能な機能を提供する、ネットワーク監視と管理のツールを選ぶことが重要です。
基本的な概念や原則：
Packet Mirroring：Google Cloudのネットワークトラフィックを複製し、分析のためのペイロードをキャプチャする機能です。セキュリティとパフォーマンスの問題を識別・診断するために使用されます。
VPC（Virtual Private Cloud）：Google Cloud上で仮想的にプライベートなネットワーク環境を構築するサービスです。VPC内でデータとリソースを安全に分離・管理することができます。
組織ポリシー：Google Cloud上のリソースに対する制限や規則を定義する機能です。しかし、ネットワーク異常の検出やペイロードのキャプチャには直接的には使用できません。
VPCフローログ：VPC内のネットワークフロー情報をログとして取得する機能です。ネットワークパフォーマンスの分析や問題の診断、セキュリティ分析に利用しますが、具体的なペイロードキャプチャは行えません。
Cloud Audit Logs：Google Cloudのリソースに対する操作を記録する機能です。アクセスや操作の監視、監査に使用されますが、ネットワーク異常の特定やペイロードのキャプチャは行えません。
正解についての説明：
（選択肢）
・Packet Mirroringのポリシーを設定します
この選択肢が正解の理由は以下の通りです。
Packet Mirroringは、Google Cloud Virtual Private Cloud（VPC）内のネットワークのトラフィックをミラーリングし、そのトラフィックをセキュリティ、分析、ネットワークパフォーマンス監視アプリケーションなどに送信します。ネットワークパケットからのペイロードキャプチャならびにネットワーク異常の特定を行うニーズに対して、Packet Mirroringは貴重な情報を提供します。
具体的には、Packet Mirroringは設定したポリシーに基づいて特定のインスタンスのインバウンドとアウトバウンドトラフィックを複製します。これにより、セキュリティチームやネットワークエンジニアリングチームはVPC内のペイロードをキャプチャし、セキュリティ脅威を迅速に特定し、対処することができます。このため、Packet Mirroringのポリシー設定は、ネットワーク異常の特定とペイロードキャプチャの需要を満たす最善の手段となります。
不正解についての説明：
選択肢：組織ポリシーの制約を定義します
この選択肢が正しくない理由は以下の通りです。
組織ポリシーの制約を定義することは、Google Cloudリソース全体のアクセス制限やパラメータを定義するものであり、ネットワーク異常を特定しVPC内のペイロードをキャプチャするために必要な機能を提供しません。
一方、Packet Mirroringは特定のトラフィックをミラーリングし解析することができるため、問題の要件に適合します。
選択肢：サブネットでVPCフローログを有効にします
この選択肢が正しくない理由は以下の通りです。
サブネットでVPCフローログを有効にすると、IPデータのフロー情報は収集されますが、ペイロードの具体的なデータはキャプチャされません。対比すると、Packet Mirroringはネットワークのトラフィックを複製し、ペイロードを含むすべてのデータを特定できるため、問題の要件を満たす選択肢です。
選択肢：Cloud Audit Logsの監視と分析を行います
この選択肢が正しくない理由は以下の通りです。
Cloud Audit Logsはユーザーアクティビティや管理アクティビティのログを提供しますが、ネットワーク異常特定やVPC内のペイロードキャプチャには適していません。
それに対して、Packet Mirroringは特定のトラフィックをキャプチャしモニタリング可能なため、要求を満たします。
参考リンク：
https://cloud.google.com/vpc/docs/packet-mirroring
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/logging/docs/audit
</div></details>

### Q.  問題5: 未回答
あなたは、GDPRの要件に従って、設計によるデータ保護を実装しています。設計レビューの一環として、Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Subのワークロードを含むソリューションの暗号化キーを管理する必要があると言われました。
この実装では、どのオプションを選択すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、データ保護を実装する場面での暗号化キーの管理について読み解く必要があります。特にEUのGDPR要件に適合させることが重要な点で、Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Subのワークロードを含むソリューションに対して、どの暗号化キー管理オプションを選ぶべきかが問われています。ここでは、各選択肢が提供する暗号化キーの管理方法と、それがGDPR要件にどのように適合するかを理解することが重要です。
基本的な概念や原則：
Cloud External Key Manager：Google Cloudリソースへのアクセスの認証に使う暗号化キーを、Google Cloud外部で管理することが可能なサービスです。GDPRの要件など、特定の規制要件に対応が必要な場合に用いられます。
GDPR（General Data Protection Regulation）：EU圏の市民のデータを保護することを目的とした法律です。設計によるデータ保護（Privacy by Design）はこの中で求められる要件の一つです。
Privacy by Design：プロダクトやサービスの設計段階からプライバシー保護を取り入れるアプローチです。つまり、事前に、そしてデフォルトでプライバシーが保護されるような設計を行います。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。データの暗号化キーについては、Cloud External Key Managerを利用して管理することが可能です。
Google Kubernetes Engine：Google Cloudでコンテナのオーケストレーションを行うためのマネージドサービスです。こちらも暗号化キーの管理には、Cloud External Key Managerを利用することが可能です。
Cloud Storage：大規模なデータをストレージとして保存、取得できるGoogle Cloudのサービスです。データの暗号化キーについては、Cloud External Key Managerを использовать для управления。
BigQuery：大規模なデータ分析を行うGoogle Cloudのフルマネージドサービスです。データの暗号化キーについては、Cloud External Key Managerを использовать для управления。
正解についての説明：
（選択肢）
・Cloud External Key Manager
この選択肢が正解の理由は以下の通りです。
Google CloudのExternal Key Managerは、Google Cloudの資源上で暗号化されたデータのキーを外部で管理することを可能にします。これは、GDPRのような特定の規制に対処するための設計によるデータ保護を実現する上で非常に重要です。各種ワークロードに適用可能であり、Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Sub等が該当します。
External Key Managerは組織がGoogle Cloudに保存されているデータの暗号化キーを自身で制御でき、自身のデータセンター、オンプレミスデバイス、またはその他のクラウドプロバイダをキーストレージとして使用することが可能です。
External Key Managerと共に適切なアクセスポリシーを組み合わせることで、組織は自身のGDPRの要件を満たすための暗号化キーの管理を実現でき、データ保護を強化することができます。このような理由から、Cloud External Key Managerは適切な選択とされます。
不正解についての説明：
選択肢：顧客管理の暗号化キー
この選択肢が正しくない理由は以下の通りです。
"顧客管理の暗号化キー"だけでは、あいまいかつ明らかなサービスや手段を指していないため不適切です。
それに対して、Cloud External Key ManagerはGoogle Cloudで提供される明確なサービスであり、これを使うことでCompute Engine、GKE、Cloud Storage、BigQuery、Pub/Subなどのワークロードの暗号化キーを一元的に管理することが可能です。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キーは特定のサービス（Cloud Storageなど）でしか利用できません。
一方、Cloud External Key ManagerはCompute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Subといった複数のサービスに対応しており、より広範な暗号化キー管理が可能です。
選択肢：Googleのデフォルト暗号化
この選択肢が正しくない理由は以下の通りです。
Googleのデフォルト暗号化は、Googleが全ての管理を行うため、使用者自身が暗号化キーを管理することができません。これではGDPRの要件を満たすことが難しくなります。
一方、Cloud External Key Managerは、キーの管理を使用者自身が行えるため、GDPRの要件を満たすことが可能です。
参考リンク：
https://cloud.google.com/security-key-management
https://cloud.google.com/kms/docs/ekm
https://cloud.google.com/compute/docs/disks/customer-managed-encryption
</div></details>

### Q.  問題6: 未回答
あなたは、Google Cloud上の公開アプリケーションに対して、一般的なWebアプリケーション攻撃に対する外部Webアプリケーション保護を実装することを命じられました。
あなたは、これらのポリシーの変更を実施する前に検証したいと考えています。
この要件を満たすために、どのサービスを使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、すでに存在する公開アプリケーションに対して外部Webアプリケーションの保護を強化し、その変更を実施する前に検証をしたいという要件が指定されています。したがって、この問題を解くためには、Google Cloudの中に存在するそれぞれのサービスがどの機能を提供していて、その中でどの機能が要件を満たすかを理解することが重要です。また、適切な保護メカニズムが選択されているか、それが検証可能かどうかに重点を置きます。
基本的な概念や原則：
Google Cloud Armor：Google Cloudのネットワーク安全性を高めるサービスです。一般的なWebアプリケーション攻撃に対する保護を提供しています。
設定済みルールのプレビューモード：Google Cloud Armorの機能で、ポリシー変更の影響を実際に適用する前に確認・検証することができます。
VPCファイアウォールルール：Google Cloud内のネットワークを保護する機能です。仮想プライベートクラウド（VPC）内のリソースへのトラフィックを制御します。
Googleフロントエンド（GFE）：Googleのネットワークエッジに位置する分散型リバースプロキシサーバーです。汎用的な保護機能を提供しています。
クラウドロードバランシング：Google Cloudのトラフィック分散サービスです。可用性と性能を向上させるとともに、特定のファイアウォールルールを適用することも可能です。
正解についての説明：
（選択肢）
・Google Cloud Armorの設定済みルールのプレビューモード
この選択肢が正解の理由は以下の通りです。
Google Cloud ArmorはGoogle CloudのManaged Protectionリソースとして提供され、公開アプリケーションに対する一般的なWebアプリケーション攻撃の保護を提供します。Google Cloud Armorはウェブアプリケーションのセキュリティを強化するためのサービスです。
一方、Google Cloud Armorの設定済みルールのプレビューモードは、既存のセキュリティポリシーの変更を実施する前にその影響を検証するのに重要な機能です。プレビューモードを使用することで、新しいまたは変更されたルールが現実のトラフィックに対してどのように機能するかを確認することができます。このプロセスにより、ポリシーが意図した通りに動作することを確認し、予期しない影響を未然に防ぐことができます。
したがって、外部Webアプリケーション保護を実装し、それを確認したいという要件を満たすために、Google Cloud Armorの設定済みルールのプレビューモードを使用するべきです。
不正解についての説明：
選択肢：モニターモードでのVPCファイアウォールルールの事前設定
この選択肢が正しくない理由は以下の通りです。
VPCファイアウォールルールのモニターモードは、トラフィックに関する情報を収集し分析するためのもので、公開Webアプリケーションに対する一般的なWebアプリケーション攻撃の検証には不適切です。
それに対して、Google Cloud Armorのプレビューモードは特定のWeb攻撃に対する保護策の効果を確認するものであり、要件に適しています。
選択肢：Googleフロントエンド（GFE）固有の保護機能
この選択肢が正しくない理由は以下の通りです。
Googleフロントエンド（GFE）固有の保護機能は一般的なWebアプリケーション攻撃に対する保護を提供しますが、ポリシーの変更を検証する機能は提供していません。対してGoogle Cloud Armorの設定済みルールのプレビューモードはポリシーの変更を実施する前に検証が可能なため、このシナリオには適しています。
選択肢：クラウドロードバランシングのファイアウォールルール
この選択肢が正しくない理由は以下の通りです。
クラウドロードバランシングのファイアウォールルールは、あくまでトラフィックのフィルタリングに使われるツールであり、一般的なWebアプリケーション攻撃に対する保護や、ポリシー変更の前の検証を行う機能を持っていません。
それに対して、Google Cloud Armorの設定済みルールのプレビューモードは、これらの要件を満たします。
参考リンク：
https://cloud.google.com/armor/docs/security-policy-overview
https://cloud.google.com/armor/docs/rule-tuners
https://cloud.google.com/armor/docs/managed-protection#manage_rules
</div></details>

### Q.  問題7: 未回答
あなたは顧客のアーキテクチャに対してセキュリティ評価を実行し、複数のVMにパブリックIPアドレスがあることがわかりました。パブリックIPアドレスを削除するための推奨事項を提供した後、顧客の通常の操作の一環として、それらのVMが外部サイトと通信する必要があることが知らされました。
顧客のVMでのパブリックIPアドレスの必要性を減らすために、あなたは何を推奨すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、外部サイトとの通信が必要な仮想マシン（VM）がパブリックIPアドレスを持たずに機能するソリューションを選択することが求められています。ここで課題となるのは、パブリックIPアドレスを削除した場合でも、通常の操作の一部としてVMが外部サイトと通信できるようにすることです。それぞれの選択肢が提供する機能と、それがパブリックIPアドレスを持たないVMの通信にどのように利用できるかを評価することが重要です。
基本的な概念や原則：
Cloud NAT：Google Cloudのマネージドネットワークアドレス変換（NAT）サービスです。プライベートなGoogle Compute Engineネットワークから、インターネット上の公的なIPサービスへ安全に接続することができます。パブリックIPアドレスの割り当てを減らすことが可能です。
Google Cloud Armor：Google Cloud上のアプリケーションに対するDDoSやウェブ攻撃を防ぐ、マネージドセキュリティサービスです。パブリックIPアドレスの必要性とは関連性が低いです。
Cloud Router：Google Cloud上で動的ルーティングを提供するサービスです。ネットワーク間の通信経路を自動的に更新・管理します。パブリックIPアドレスの必要性とは関連性が低いです。
Cloud VPN：Google Cloud上で仮想プライベートネットワーク（VPN）接続を確立するサービスです。セキュアな接続を提供しますが、パブリックIPアドレスの必要性を減らすものではありません。
正解についての説明：
（選択肢）
・Cloud NAT
この選択肢が正解の理由は以下の通りです。
まず、Cloud NATはGoogle Cloudの管理するNATサービスで、プライベートアドレスを持つ仮想マシン（VM）からインターネットへの接続を可能にします。VMが外部サイトと通信する必要がある場合でも、Cloud NATを使用することでそれらのVMにパブリックIPアドレスを直接割り当てることなく、インターネットに接続することが可能になります。これは、VMの公開露出を最小限に抑えつつ、必要な通信を行うために非常に有用です。
さらに、Cloud NATは、応答を受け取るために一時的な公開IPを確保するアウトバウンド接続（ソースNAT）をサポートしています。これにより、VMが外部のAPIと通信する場合にも、予測可能で制御可能な接続を維持することができます。
したがって、Cloud NATはパブリックIPアドレスの必要性を減らすための適切な推奨事項となります。
不正解についての説明：
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは主に不正なトラフィックやDDoS攻撃から保護するためのサービスであり、リソースのパブリックIPアドレスの必要性を減らすための機能は提供していません。
一方、Cloud NATはプライベートIPのリソースがインターネットと通信するためのサービスであり、必要適切な選択です。
選択肢：Cloud Router
この選択肢が正しくない理由は以下の通りです。
Cloud RouterはVPN接続やインターコネクトを通じてオンプレミスネットワークとGoogle Cloudネットワーク間の動的経路を交換するためのサービスであり、パブリックIPアドレスを削除する目的には適していません。
一方、Cloud NATはプライベートIPアドレスのVMからインターネットへのアウトバウンド通信を可能にし、パブリックIPアドレスの必要性を減らします。
選択肢：Cloud VPN
この選択肢が正しくない理由は以下の通りです。
Cloud VPNはVPN接続を提供しますが、これは一般的に企業のオンプレミスネットワークとクラウド環境を接続するために使用され、VMが外部サイトと通信するためのソリューションではありません。
それに対して、Cloud NATはプライベートIPアドレスのVMから外部ネットワークへのアクセスを許可し、パブリックIPアドレスの必要性を減らします。
参考リンク：
https://cloud.google.com/nat/docs/overview
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address#reserve_new_static
https://cloud.google.com/vpc/docs/vpc
</div></details>

### Q.  問題8: 未回答
セキュリティ運用チームは、組織内の全プロジェクトのセキュリティ関連ログにアクセスする必要があります。このチームには以下の要件があります：
- 最小権限モデルに従い、ログへのアクセス権は表示のみとします。
- 管理者の行動ログにアクセスできるようにする必要があります。
- データアクセスログにアクセスできるようにする必要があります。
- アクセス透明性ログにアクセスできるようにする必要があります。
セキュリティ運用チームに付与されるべきID/IAMロールはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、セキュリティ運用チームが求めている特定の要件に合致するIAMロールを選ぶことが要求されています。最小権限モデルに従い、表示のみの権限を必要としており、管理者の行動ログ、データアクセスログ、アクセス透明性ログへのアクセスが必要です。選択肢を見るとき、これらの要件を満たすものを探す必要があります。ただし、全てのログにアクセスできても、その権限が表示だけであることを確認しなければならない点に注意する必要があります。
基本的な概念や原則：
最小権限モデル：必要最小限の権限のみをユーザーに付与するセキュリティの原則です。不要なアクセス権を排除し、セキュリティリスクを管理します。
roles/logging.privateLogViewer：管理者の行動ログ、データアクセスログ、及びアクセス透明性ログを表示する権限を持つIAMロールです。
管理者の行動ログ：Google Cloudのリソースに関連する管理者のアクティビティを記録したログです。
データアクセスログ：ユーザーやサービスアカウントがGoogle Cloudデータをどのようにアクセスしたかを記録したログです。
アクセス透明性ログ：Google Cloudのリソースに対するGoogle管理者のアクセスを記録したログです。
roles/logging.admin：ログの管理権限を持つIAMロールですが、最小権限モデルに反するためこの事例では適切ではありません。
roles/viewer：Google Cloudのリソース全般を閲覧する権限を持つIAMロールですが、適切なログへのアクセス権限が無いためこの事例では適切ではありません。
roles/logging.viewer：ログの閲覧権限を持つIAMロールですが、一部のプライベートログへのアクセス権限が無いためこの事例では適切ではありません。
正解についての説明：
（選択肢）
・roles/logging.privateLogViewer
この選択肢が正解の理由は以下の通りです。
まず、ログへの表示のみを必要とするという要件を満たすためには、Viewer（閲覧者）の権限が必要です。そのため、Viewerが含まれるroles/logging.privateLogViewerが正解の候補となります。
そして、管理者の行動ログ、データアクセスログ、アクセス透明性ログへのアクセスが必要であることから、これらのログが"プライベートログ"と呼ばれる分類に含まれていることを認識する必要があります。プライベートログとは、特別なアクセス権限を必要とするログを指します。例えば、管理者の行動ログには管理者が行った操作の詳細が記録されているため、セキュリティ上の理由から通常のログ閲覧者ではアクセスできません。データアクセスログとアクセス透明性ログも同様です。
したがって、roles/logging.privateLogViewerロールをセキュリティ運用チームに割り当てることで、閲覧者としての権限を制限しつつ、特別なアクセス権限を必要とするログへのアクセスを許可することができます。これにより、最小権限の原則に従いつつ、要件を満たすことができます。
不正解についての説明：
選択肢：roles/logging.admin
この選択肢が正しくない理由は以下の通りです。
不正解選択肢のroles/logging.adminは、ログに対して表示だけでなく編集や削除もできる権限を持つため、最小権限モデルに反します。正解の権限であるroles/logging.privateLogViewerは、ログの表示だけが許可され、セキュリティ運用チームの要件を満たします。
選択肢：roles/viewer
この選択肢が正しくない理由は以下の通りです。
roles/viewerはプロジェクト全体のリソースを閲覧する権限を持つ一方で、管理者の行動ログやデータアクセスログ、アクセス透明性ログへのアクセス権は付与されません。
それに対して、roles/logging.privateLogViewerはセキュリティに関する全てのログを閲覧する権限を提供します。
選択肢：roles/logging.viewer
この選択肢が正しくない理由は以下の通りです。
roles/logging.viewerロールは一部のログ（管理者の行動、データアクセス、アクセス透明性ログなど）を閲覧する権限がありません。
それに対して、roles/logging.privateLogViewerはこれらの特権的ログにアクセスする権限を含みます。
したがって、全ての要件を満たすためには後者が適しています。
参考リンク：
https://cloud.google.com/iam/docs/understanding-roles#logging-roles
https://cloud.google.com/logging/docs/access-control
https://cloud.google.com/logging/docs/audit#admin-activity
</div></details>

### Q.  問題9: 未回答
ある顧客が、VM上でバッチ処理システムを実行し、出力ファイルをCloud Storageのバケットに保存したいと考えています。ネットワーキングチームとセキュリティチームは、VMがパブリックインターネットにアクセスすることを禁止しています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客のバッチ処理システムがパブリックインターネットにアクセスせずにCloud Storageのバケットに出力ファイルを保存する方法を尋ねています。そのため、あなたが選択肢を判断する際には、VMがパブリックインターネットにアクセスすることなくCloud Storageにデータを保存できるソリューションを考慮する必要があります。特に、Google Cloudのプライベートアクセスオプションに注目するとよいです。
基本的な概念や原則：
Googleのプライベートアクセス：GoogleのAPIやサービスへの内部IPトラフィックを可能にするGoogle Cloudの機能です。これにより、パブリックインターネットへのアクセスを禁止した状態でも、Googleのサービスにプライベートなアクセスが可能となります。
Cloud Storage：データを安全に保存し、何時でも各種アプリケーションからアクセスできるように設計されたGoogle Cloudのオブジェクトストレージサービスです。
ファイヤウォールルール：特定のトラフィックを許可またはブロックするためのネットワークポリシーです。Google CloudではVPCファイヤウォールルールを作成してトラフィックを制御します。
NATゲートウェイ：プライベートなインスタンスがインターネット上のリソースにアウトバウンド通信を行うための中継ポイントを提供します。Google Cloudでは、Cloud NATを使用します。
正解についての説明：
（選択肢）
・Googleのプライベートアクセスを有効にします
この選択肢が正解の理由は以下の通りです。
Googleのプライベートアクセス機能は、Google Cloudのリソースに対する内部接続を提供します。これにより、パブリックインターネット経由でなく、Googleの内部ネットワーク経由でCloud Storageと通信することが可能となります。これはVMがパブリックインターネットに直接アクセスできない、またはそのアクセスが制限されている場合に特に便利です。プライベートアクセスを有効にすることで、バッチ処理システムが出力ファイルをCloud Storageのバケットに保存するニーズを満たすとともに、セキュリティチームとネットワーキングチームによるパブリックインターネットへの接続制限も遵守することができます。
したがって、顧客の要件を満たす最適な選択肢は、Googleのプライベートアクセスを有効にすることです。
不正解についての説明：
選択肢：VMからのインターネットトラフィックをブロックするファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
VMからのインターネットトラフィックをブロックすると、Cloud Storageにアクセスすること自体が不可能になってしまいます。しかし、Googleのプライベートアクセスを有効にすることで、公的なインターネットを経由せずにGoogle Cloudサービスにアクセスできるため、問題の要件を満たします。
選択肢：Cloud Storage APIエンドポイントにアクセスするためにNATゲートウェイをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
NATゲートウェイを利用すると、インターネット経由でCloud Storage APIエンドポイントにアクセスする必要があります。しかし、このネットワーキングチームとセキュリティチームはVMがパブリックインターネットにアクセスすることを禁止しています。
一方、Googleのプライベートアクセスを有効にすると、パブリックインターネット経由ではなくGoogleの内部ネットワーク経由でCloud Storageにアクセスできます。
選択肢：Cloud Storageのバケットをローカルファイルシステムとして各VMにマウントします
この選択肢が正しくない理由は以下の通りです。
Cloud Storageのバケットをローカルファイルシステムとして各VMにマウントする方法を採用しても、VMからインターネットを経由してバケットにアクセスする必要があり、パブリックインターネットへのアクセスを禁止する制約に合致しません。正解のGoogleのプライベートアクセスを有効にする方法なら問題なくバケットにアクセスできます。
参考リンク：
https://cloud.google.com/storage/docs/accessing-private-access
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/storage/docs/gcs-fuse
</div></details>

### Q.  問題10: 未回答
あなたのチームは、ファイアウォールルール、サブネット、ルートなどのネットワークリソースを一元管理できるように、Google Cloud環境を設定する必要があります。また、オンプレミス環境では、リソースがプライベートVPN接続を通じてGoogle Cloudリソースにアクセスする必要があります。
ネットワークリソースはネットワークセキュリティチームが制御する必要があります。
これらの要件を満たすために、あなたのチームはどのタイプのネットワーク設計を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ネットワークリソースの一元管理とプライベートVPN接続を通じたリソースアクセス、及びネットワークセキュリティチームによる制御が求められています。検討すべきは、異なるネットワーク設計の選択肢の中から、これら要件を満たす最適な設計を選ぶことです。特に、オンプレミスとのシームレスな接続と一元化したリソース管理が必要で、セキュリティチームによる管理が重要であることを念頭に置いて選択肢を解析してください。また、各選択肢がどのようなネットワーク設計を表しているかの理解も必要です。
基本的な概念や原則：
共有VPC：Google Cloud上での企業レベルのリソース共有設計です。一つのホストプロジェクト内でネットワークリソース（VPCネットワークやサブネットなど）を作成・管理し、同じ組織の他のプロジェクト（サービスプロジェクトと呼ばれる）に対し、それらリソースを利用する権限を付与できます。
VPCネットワーク：Google Cloudの仮想ネットワーキングの中核をなすリソースです。プロジェクト間でのネットワーク接続や、Google Cloudとオンプレミス環境とのセキュアな接続を提供します。
ホストプロジェクト：共有VPCを作成・管理するプロジェクトです。一元的なネットワーク管理を実現します。
サービスプロジェクト：共有VPCのネットワーキングリソースを使うことを許可されたプロジェクトです。
VPCピアリング：異なるVPCネットワーク間でのトラフィックの送受信を可能にする機能です。
Cloud VPN：Google Cloudとオンプレミスとの間で、暗号化されたIPSec接続を提供します。プライベートプロジェクトからGoogle Cloudリソースへのセキュアな接続を実現します。
正解についての説明：
（選択肢）
・ホストプロジェクトとサービスプロジェクトによる共有VPCネットワーク
この選択肢が正解の理由は以下の通りです。
まず、共有VPCネットワークは、複数のプロジェクトで一つのネットワークを共有することを可能にします。ホストプロジェクトとサービスプロジェクトの概念が用いられ、ホストプロジェクトでネットワークリソース（ファイアウォールルールやサブネットなど）が作成・管理され、サービスプロジェクトからそれらのリソースを利用する形をとります。これによりネットワークリソースを一元管理できます。
また、ネットワーク管理を一部のチーム（この場合はネットワークセキュリティチーム）に委託することが可能なため、制御が必要な場合に役立ちます。
加えて、Google CloudのVPCネットワークは、オンプレミスネットワークとのプライベート接続もサポートしています。Cloud VPNやCloud Interconnectを使用することで、安全にオンプレミス環境との通信が可能になります。これにより、オンプレミスからのリソースアクセス要件も満たすことができます。
したがって、より一元的かつ安全なネットワーク管理を求める場合には、ホストプロジェクトとサービスプロジェクトによる共有VPCネットワークが適切な選択肢となります。
不正解についての説明：
選択肢：各エンジニアリングプロジェクトにおいて、ネットワークチームにCompute Adminロールを付与します
この選択肢が正しくない理由は以下の通りです。
各エンジニアリングプロジェクトでネットワークチームにCompute Adminロールを付与すると、彼らはそのプロジェクトにおけるすべてのCompute Engineリソースに対する管理権限を得ることになり、あくまでネットワークリソースの一元管理を目指すという要件を満たしていません。
一方、ホストプロジェクトとサービスプロジェクトによる共有VPCネットワークを使用すれば、ネットワークリソースの一元管理が可能となります。
選択肢：ハブアンドスポークモデルによる全エンジニアリングプロジェクト間のVPCピアリング
この選択肢が正しくない理由は以下の通りです。
VPCピアリングはネットワークを接続する手段の一つですが、一元管理をするための適切な構造ではありません。ホストプロジェクトとサービスプロジェクトによる共有VPCネットワークは、指定されたプロジェクト内でネットワークリソースを一元管理することが可能で、その方が要件に合致します。
選択肢：ハブアンドスポークモデルを使用した、すべてのエンジニアリングプロジェクト間のCloud VPNゲートウェイ
この選択肢が正しくない理由は以下の通りです。
ハブアンドスポークモデルのCloud VPNゲートウェイは、さまざまなプロジェクト間の接続に用いられますが、ネットワークリソースの一元管理は実現しません。
一方、共有VPCは複数のプロジェクト間でネットワークリソースを共有し、一元的に管理することが可能です。
参考リンク：
https://cloud.google.com/vpc/docs/shared-vpc
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/iam/docs/understanding-roles#compute-engine-roles
</div></details>

### Q.  問題11: 未回答
非機密データの鍵管理の複雑さを軽減し、機密データを保護しながら、鍵の保存期間とローテーションスケジュールを柔軟に制御できる、静止時暗号化戦略を導入する必要があります。すべてのデータタイプに対して、FIPS 140-2 L1準拠が必要です。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、非機密データと機密データの保護について理解し、それぞれのデータをどのように暗号化するかを選択することが重要です。特に、静止時暗号化戦略を導入し、鍵管理の複雑さを軽減し、FIPS 140-2 L1準拠を果たす必要があります。そのような背景下で、非機密データと機密データそれぞれに適した暗号化戦略を選択する能力が求められる問題です。
基本的な概念や原則：
Googleデフォルトの暗号化：Google Cloud上のすべてのデータはデフォルトで暗号化されます。これはデータの安全性を保つために必要であり、特に非機密データの暗号化管理の複雑さを軽減するのに役立ちます。
Cloud Key Management Service：Google Cloudの暗号鍵管理サービスです。これにより、鍵の生成、使用、保護、保存、ローテーション、削除を自分で制御することができます。これは機密データの保護に必要な要件を満たします。
FIPS 140-2 Level 1：米国政府が定める暗号モジュールのセキュリティ要件です。Google Cloudの暗号化とKey Management Serviceはこの基準を満たします。
Cloud External Key Manager：Google Cloudのサービスで、自分のキーをCloud外で管理し、それを使用してGoogle Cloudのデータを暗号化することができます。
鍵の保存期間とローテーションスケジュール：暗号鍵の管理において、鍵をどの程度の期間保存するか、また新しい鍵にどの程度の頻度で切り替えるか（ローテーション）を定めることです。Cloud Key Management Serviceではこれらを柔軟に制御することが可能です。
正解についての説明：
（選択肢）
・非機密データはGoogleデフォルトの暗号化で暗号化し、機密データはCloud Key Management Serviceで暗号化します
この選択肢が正解の理由は以下の通りです。
まず、非機密データの鍵管理の複雑さを軽減するために、Googleデフォルトの暗号化を選択することは理にかなっています。これにより、ユーザの手間をかけずにデータを保護し、鍵の管理コストを削減できます。
一方、機密データを保護し、鍵のローテーションスケジュールと保存期間を柔軟に制御するためには、Cloud Key Management Service（KMS）が必要です。Cloud KMSは、ユーザが鍵を自分で管理することを可能にし、保存期間やローテーションの頻度を自分で制御できる点で優れています。
さらに、Cloud KMSはFIPS 140-2 Level 1に準拠しており、複雑な暗号化要件を満たしたセキュアな環境を提供します。
したがって、非機密データをGoogleデフォルトの暗号化で、機密データをCloud KMSで暗号化することは、要件を満たす最適な解決策です。
不正解についての説明：
選択肢：Cloud External Key Managerを使用して、機密性の低いデータと機密性の高いデータを暗号化します
この選択肢が正しくない理由は以下の通りです。
Cloud External Key Managerはお客様が自身の暗号化キーを管理し、そのキーをGoogle Cloud以外で保管するためのサービスであり、問題の要件である鍵管理の複雑さを軽減する目的とは合わないからです。
一方、Googleデフォルトの暗号化とCloud Key Management Serviceは鍵管理をGoogle Cloudが行い、鍵の保存期間とローテーションスケジュールを柔軟に制御できるため、要件を満たします。
選択肢：Cloud Key Management Serviceで非機密データと機密データを暗号化
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Serviceで全てのデータを暗号化することは技術的に可能ですが、鍵管理の複雑さを軽減するという要件を満たしません。逆に鍵の管理が増え、複雑さは増します。しかし、Googleデフォルトの暗号化を利用することで、非機密データの鍵管理は自動的に行われ、管理の手間を軽減します。
選択肢：非機密データはGoogleデフォルトの暗号化で暗号化し、機密データはCloud External Key Managerで暗号化します
この選択肢が正しくない理由は以下の通りです。
Cloud External Key Managerは、Google Cloud外部の鍵を使用してGoogle Cloudのデータを暗号化するのに使用します。鍵管理の複雑さを軽減するという要件には合致しません。
一方、Cloud Key Management ServiceはGoogle Cloud内部で鍵を管理し、保存期間とローテーションスケジュールを柔軟に制御できます。そのため、要件を満たします。
参考リンク：
https://cloud.google.com/security/encryption/default-encryption
https://cloud.google.com/kms/docs
https://cloud.google.com/docs/compliance/standards/fips
</div></details>

### Q.  問題12: 未回答
あなたは、本番プロジェクトのすべてのGoogle Cloudリソースを監査しています。ファイアウォールルールを変更できるすべてのプリンシパルを特定したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのリソースを監査し、特定の操作（ファイアウォールルールの変更）を行うことが可能な全てのプリンシパルを把握することが目的です。したがって、各選択肢がその要件をどのように満たすかを考慮する際には、ファイアウォールルールを変更する特定のパーミッション（compute.firewalls.create、compute.firewalls.update、compute.firewalls.delete）をどのツールが調査できるのかを重点的に考えます。そのため、ツールの機能やパーミッションの種類に関する知識が必要となります。
基本的な概念や原則：
Policy Analyzer：IAMポリシーを対象にした調査と分析を実行するGoogle Cloudのツールです。特定のパーミッションを持つプリンシパルや、特定のプリンシパルが持つパーミッションを確認することが可能です。
ファイアウォールルール：Google Cloudのネットワークに接続するトラフィックを制御するための規則です。ルールは特定のパーミッションを持つユーザーによって作成、更新、削除することができます。
パーミッション：Google Cloudのリソースに対するアクセスレベルを定義するものです。リソースの作成、更新、削除など、特定の操作がパーミッションによって制御されます。
プリンシパル：Google Cloud IAMの用語で、IAMポリシーが関連付けられるユーザー、グループ、サービスアカウントなどのエンティティのことを指します。
Security Command Center：Google Cloudのセキュリティとデータリスクの統合プラットフォームです。リスクの検出、評価、対応を一元化したダッシュボードから行うことができます。Security Health Analyticsはその一部で、Google Cloudの設定の脆弱性を検出する機能を提供します。
正解についての説明：
（選択肢）
・Policy Analyzerを使用して、パーミッションcompute.firewalls.createまたはcompute.firewalls.updateまたはcompute.firewalls.deleteを照会します
この選択肢が正解の理由は以下の通りです。
まず、Policy AnalyzerはGoogle Cloudのサービスの1つで、組織のGoogle Cloudリソースに対するアクセス権限を分析するために使用されます。特定のパーミッションを持つプリンシパル（ユーザーやサービスアカウントなど）を特定するためには、このツールが最適です。
また、Google Cloudのファイアウォールルールを変更するためには、'compute.firewalls.create'、'compute.firewalls.update'、または'compute.firewalls.delete'のいずれかのパーミッションが必要です。この設問ではファイアウォールルールを変更できる全てのプリンシパルを特定したいので、これらのパーミッションをPolicy Analyzerで照会することで、該当するプリンシパルを特定することが可能となります。
以上の理由から、Policy Analyzerを使用して特定のパーミッションを照会することで、この要件を効率良く満たすことができます。
不正解についての説明：
選択肢：Policy Analyzerを使用して、パーミッションcompute.firewalls.getまたはcompute.firewalls.listをクエリします
この選択肢が正しくない理由は以下の通りです。
compute.firewalls.getやcompute.firewalls.listのパーミッションは、ファイアウォールルールを読み取るためのものであり、ルールを変更する権限を持っているプリンシパルを特定するためには不適切です。
逆に、compute.firewalls.create、compute.firewalls.update、compute.firewalls.deleteはファイアウォールルールを変更するためのパーミッションなので、これらを照会すれば目的が達成できます。
選択肢：ファイアウォールインサイトを使って、ファイアウォールルールの使用パターンを把握しましょう
この選択肢が正しくない理由は以下の通りです。
ファイアウォールインサイトはファイアウォールルールの使用パターンを把握するためのツールであり、特定のパーミッションを持つプリンシパルを特定する機能はありません。
それに対して、Policy Analyzerはパーミッションを照会し、誰がそのパーミッションを持つかを特定することが可能です。
選択肢：Security Command CenterのSecurity Health Analytics - Firewall Vulnerability Findingsを参照します
この選択肢が正しくない理由は以下の通りです。
Security Command CenterのSecurity Health Analytics - Firewall Vulnerability Findingsは、ファイヤーウォールに存在する脆弱性を特定する機能であるため、ファイアウォールルールを変更できるすべてのプリンシパルを特定する目的には適していません。
一方、Policy Analyzerはパーミッションを照会することが可能なため、指定したパーミッションを持つプリンシパルを特定するために適したツールです。
参考リンク：
https://cloud.google.com/iam/docs/policy-analyzer-overview
https://cloud.google.com/security-command-center/docs/how-to-security-health-analytics
https://cloud.google.com/network-intelligence-center/docs/firewall-insights/using-firewall-insights
</div></details>

### Q.  問題13: 未回答
あなたはセキュリティチームの一員で、漏洩したサービスアカウントキーを調査しています。あなたは、どの新しいリソースがサービスアカウントによって作成されたかを監査する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のセキュリティ上の課題、つまりサービスアカウントキーの漏洩を調査する方法について問われています。具体的には、漏洩したサービスアカウントキーを用いて作成された新しいリソースを特定したいという状況です。したがって、サービスアカウントによるリソースの作成というアクションをトラッキング可能なGoogle Cloudの機能を選択肢から選ぶことが必要です。選択肢を見たときには、それぞれの特性と、それが特定のアクションをトラッキングできるかどうかを考慮することが重要です。
基本的な概念や原則：
管理者のアクティビティログ：Google Cloudにおける管理者の操作を記録するログです。サービスアカウントによって新しく作成されたリソースの監査に使用します。
データアクセスログ：Google Cloudのサービスがユーザーデータにアクセスする際の情報を記録するログです。サービスアカウントがリソースにアクセスしたデータの追跡に使われますが、新しいリソースの作成には使用しません。
Access Transparencyログ：Googleのサポートやエンジニアリングチームがユーザーデータにアクセスした際の詳細情報を提供するログです。Googleの職員が行った操作の可視化に使用します。
Google Cloud Operation Suite：ログ管理、監視、トレーシングなどの機能を提供するツールセットです。しかし、特定のサービスアカウントによって新しく作成されたリソースの監査には適していません。
正解についての説明：
（選択肢）
・管理者のアクティビティログを照会します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、管理者のアクティビティログという監査ログが提供されています。これはGoogle Cloud内のリソースに対する管理操作（作成や削除など）の詳細情報を記録します。そのため、サービスアカウントによってどのような新リソースが作成されたかを知りたい場合、管理者のアクティビティログを照会することで、それぞれの操作に対する詳細な情報を取得することが可能です。
また、活動ログはリソースを作成したユーザーやサービスアカウント、リソースの詳細、タイムスタンプなどのデータを提供します。これにより、特定のアカウントによって行われた操作の追跡や、何がいつ何によって変更されたのかを監査することが可能になります。
したがって、サービスアカウントキーの漏洩を調査し、新しいリソースの作成を監査する要件を満たすためには、管理者のアクティビティログの照会が効果的です。
不正解についての説明：
選択肢：データアクセスのログを照会します
この選択肢が正しくない理由は以下の通りです。
データアクセスのログは、Google Cloudのリソースに対する読み取りまたは書き込み操作を記録しますが、新しいリソースがサービスアカウントによって作成されたかどうかを追跡するためには不十分です。
対照的に、管理者のアクティビティログはCloudの管理活動、つまり、リソースの作成や変更などを追跡します。そのため、正確な監査には管理者のアクティビティログの照会が必要です。
選択肢：Access Transparencyのログを照会します
この選択肢が正しくない理由は以下の通りです。
Access TransparencyのログはGoogleの管理者によるアクセスを記録するためのもので、サービスアカウントによって新しく作成されたリソースの監査に用いるものではありません。この要件を満たすには、管理者のアクティビティログを照会することで、サービスアカウントによるリソースの操作をトレースできます。
選択肢：Google Cloud Operation Suite監視ワークスペースに問い合わせます
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite監視ワークスペースは主にインフラストラクチャの動作状況を監視しアラートを管理するためのツールであり、特定のサービスアカウントによって作成されたリソースの監査には対応していません。ただし、管理者のアクティビティログはGoogle Cloud上のあらゆる管理活動を監視、記録するため、サービスアカウントによるリソースの作成活動を照会するのに最も適しています。
参考リンク：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/logging/docs/audit/configure-data-access
</div></details>

### Q.  問題14: 未回答
セキュリティチームは、ユーザーデータの機密性を確保するために暗号鍵を使用しています。あなたは、Cloud Key Management Service（Cloud KMS）で潜在的に漏洩した対称暗号鍵の影響を軽減するプロセスを確立したいと考えています。
インシデントが発生する前にチームが取るべき手順はどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Key Management Service（Cloud KMS）での対称暗号鍵のセキュリティ管理について理解していることが求められています。特に、暗号鍵のローテーションとメッセージの暗号化上限に焦点を当てる必要があります。そして問題は、鍵の漏洩が起こる前、つまり予防策を講じることでインシデントの影響を軽減する手順を尋ねていることに留意してください。不正解の選択肢が反応的な対応を示しているのに対し、正答は予防的な対策を示すべきです。
基本的な概念や原則：
Cloud Key Management Service（Cloud KMS）：Google Cloudの暗号鍵管理サービスです。暗号鍵の作成、管理、監視、および破棄を行うことができます。
暗号鍵のローテーション：一定期間ごとに暗号鍵を新しくすることです。これにより秘密鍵が漏洩しても影響を最小限に抑えることができます。
キーバージョン：暗号鍵の異なるバージョンを指します。異なるキーバージョンが同じ暗号化タスクに使用されると、鍵の漏洩リスクを減らすことができます。
メッセージの暗号化：メッセージやデータを秘密鍵を使って不可解な形に変換することです。逆に、公開鍵を使って元のメッセージに戻すこともできます。暗号化されたメッセージの受け手だけが秘密鍵を持っている必要があります。
主要なバージョンの手動ローテーション：手動で新しいキーバージョンを作成し、既存の鍵に取って代わらせることです。ただし、鍵のローテーションは自動化するほうがセキュリティ上有利です。
正解についての説明：
（選択肢）
・定期的なキーバージョンの自動ローテーションを有効にします
・各キーバージョンで暗号化されるメッセージの数を制限します
この選択肢が正解の理由は以下の通りです。
定期的なキーバージョンの自動ローテーションを有効にします、という選択肢は、潜在的に漏洩した対称暗号鍵の影響を軽減するために重要な手段となります。キーローテーションとは、定期的に新しい暗号鍵を生成し、古いものを置き換えることです。Cloud KMSではこの機能を自動化することが可能で、もし暗号鍵が漏洩した場合でも、それが使える期間を短くすることでリスクを軽減することができます。
また、各キーバージョンで暗号化されるメッセージの数を制限します、という選択は、特定の鍵が多くの情報を暗号化するのを防ぐことで、鍵が漏洩した際に開示される情報の量を制限するために有用です。これは、もし鍵が悪意ある者によって解読された場合や、鍵が落ち度により公開されてしまった場合でも、影響を受ける情報の量を制約します。
不正解についての説明：
選択肢：漏洩した鍵へのアクセスを無効にし、失効させます
この選択肢が正しくない理由は以下の通りです。
問題文ではインシデントが発生する前に取るべき手順を求めていますが、この選択肢は既に暗号鍵が漏洩した後の対応を述べているため、予防措置としては不適切です。
一方、正解選択肢の鍵の自動ローテーションや利用制限は、鍵の漏洩リスクを未然に防ぐための措置と言えます。
選択肢：その時々のスケジュールで、主要なバージョンを手動でローテーションします
この選択肢が正しくない理由は以下の通りです。
その時々のスケジュールで主要なバージョンを手動でローテーションする方法は不確実性が高く、また人間の側からの操作ミスの可能性も考えられます。
一方、定期的なキーバージョンの自動ローテーションは一貫性があり、漏洩リスクの軽減に貢献します。
選択肢：Cloud KMS APIを無効にします
この選択肢が正しくない理由は以下の通りです。
Cloud KMS APIを無効にすると、暗号化や復号化などのキー操作が全く実行できなくなります。暗号鍵の漏洩予防方法としては不適切であり、正解の選択肢のようにキーバージョンのローテーションや暗号化メッセージ数の制限を行うべきです。
参考リンク：
https://cloud.google.com/kms/docs/rotating-keys
https://cloud.google.com/kms/docs/envelope-encryption
https://cloud.google.com/kms/docs/restricting-crypto-key-versions
</div></details>

### Q.  問題15: 未回答
ある雇用主は、従業員の異常値を特定し、収入格差を是正するために、ボーナス報酬の経年変化を追跡したいと考えています。このタスクは、個人の機密性の高い報酬データを公開することなく実行する必要があり、異常値を特定するために可逆的でなければなりません。
これを達成するために、どのCloud Data Loss Prevention APIの機能を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Data Loss Prevention APIの機能中で、個人の機密性の高い情報を公開せずに異常値を特定するために使用すべき方法を特定する必要があります。この際、特に重要な要件は"可逆的でなければならない"という点です。機能の選択時には、データのプライバシーを保護しつつ、必要なときに元の情報に戻すことができる機能を選ぶことが求められます。
基本的な概念や原則：
CryptoReplaceFfxFpeConfig：Google Cloud Data Loss Prevention APIの機能で、指定された情報型の一部または全部を暗号化する際に使用されます。形式保存型の暗号化（FFXまたはFPE）を行い、その結果出力される値は元の値と同じ形式を維持します。結果は逆変換が可能なため、異常値の検出など、特定の分析タスクに要求される可視性を維持します。
一般化：特定の情報をより広範なカテゴリに変更する処理です。個人を特定できる詳細な情報を保護するために使用されます。
秘匿化：データを閲覧できない形式に変換する処理です。元のデータを完全に非表示にするため、再特定化が困難になります。
暗号ハッシュ：データを一意に識別するための固定長の文字列に変換する処理です。元のデータからハッシュ値を取得することは可能ですが、その逆は通常は不可能です。
正解についての説明：
（選択肢）
・CryptoReplaceFfxFpeConfig
この選択肢が正解の理由は以下の通りです。
CryptoReplaceFfxFpeConfigは、Google Cloud Data Loss Prevention APIの特性の一つであり、特定のデータをトークン化（元の値と一対一で対応する別の値に変換する手法）する機能を持っています。この選択肢が提供する形式保存トークン化（FPE）は、異常値を特定するために必要な、元のデータを復元可能なトークン化方法です。つまり、適用した結果、データは元の形式を維持し、機密データを保護しながらも、その構造と妥当性を保つことができます。具体的には、個人の報酬データを見たときに異常な値を特定できたり、ボーナス報酬の経年変化を追跡したりすることが可能になります。このため、元のデータの公開なしにこれらの操作を実行するための適切な方法と言えます。
不正解についての説明：
選択肢：一般化
この選択肢が正しくない理由は以下の通りです。
一般化は、情報を侮辱的または識別できなくするための手法であり、元のデータを回復することはできません。
この問題では、異常値を特定するためにデータを元に戻すことが求められているため、一般化は不適切です。
一方、CryptoReplaceFfxFpeConfigはデータの暗号化と複号化を可能にし、必要な場合に元の値に戻すことができます。
選択肢：秘匿化
この選択肢が正しくない理由は以下の通りです。
秘匿化は、元のデータを取り出すことができない文字列に置き換えます。
一方、従業員の異常値を特定し、歴年のボーナス報酬の経過を追跡するためには、元のデータを復元できる必要があります。ここで必要なのは、元のテキストを一意の暗号テキストに変換し、のちにその暗号テキストを元のテキストに戻すことが可能なCryptoReplaceFfxFpeConfigです。
選択肢：暗号ハッシュ
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュは一方向の操作で、一度暗号化されたデータは元の形に戻すことができません。そのため、異常値を特定するためには適しません。
一方、CryptoReplaceFfxFpeConfigは逆変換可能な暗号化方法であり、データの機密性を保ちつつ後から元の形に戻すことができます。
参考リンク：
https://cloud.google.com/dlp/docs/transformations/reference
https://cloud.google.com/dlp/docs/concepts-format-preserving-encryption
https://cloud.google.com/dlp/docs/samples/dlp-deidentify-reidentification-fpe-with-surrogate
</div></details>

### Q.  問題16: 未回答
あなたは組織のGoogle Cloudプロジェクトの1つ（プロジェクトA）を管理しています。VPCのサービスコントロール（SC）境界が、Pub/Subを含むこのプロジェクトへのAPIアクセス要求をブロックしています。別のプロジェクト（プロジェクトB）のサービスアカウントで実行されているリソースが、プロジェクト内のPub/Subトピックからメッセージを収集する必要があります。プロジェクトBはVPC SCの境界には含まれていません。最小特権の原則を使用して、プロジェクトBからプロジェクトAのPub/Subトピックへのアクセスを提供する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、あるGoogle Cloudプロジェクト（プロジェクトA）から別のプロジェクト（プロジェクトB）へAPIアクセスを許可する方法が求められています。重要な点は、プロジェクトAにはVPC Service Controls（SC）が設定されており、プロジェクトBからプロジェクトAのPub/Subトピックへアクセスする必要があるという条件です。これに対して、最小特権の原則を適用するために、どのようなアクセス制御メカニズムを使用するべきかを選択する必要があります。解答を選択する際には、イングレスポリシーの設定、アクセスレベルの作成、境界ブリッジの設置、制限サービスリストの編集など、各選択肢の意味と適用可能性を理解する必要があります。
基本的な概念や原則：
VPC Service Controls：Google Cloudリソースへのアクセスをセキュリティ境界で制御するサービスです。APIリクエストが境界のパラメータを満たす場合のみ、リソースへのアクセスが許可されます。
Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。1つ以上のPub/Subクライアントが特定のトピックからメッセージを購読することが可能です。
サービスアカウント：アプリケーションがGoogle Cloudリソースと対話するための認証用の特別なアカウントです。サービスアカウントは個別のプロジェクトに関連付けられ、そのプロジェクトのリソースへのアクセス許可を持つことができます。
認証ポリシー：Google Cloudリソースへのアクセスを制御するためのルールです。認証ポリシーは、アクセスを許可または拒否するサービスアカウントやアクセスレベルと関連付けられます。
最小特権の原則：セキュリティのベストプラクティスで、各ユーザーやアプリケーションが正しく機能するのに必要な最小限のアクセス権のみを持つべきという原則です。
アクセスレベル：VPC Service Controlsの一部で、特定のリソースへのアクセスを制限するための設定です。ユーザーやサービスアカウントがアクセスできるリソース、及びそのリソースへのアクセスタイプを定義します。
境界ブリッジ：存在しない概念で、誤った選択肢の一つとして出ています。学習者はGoogle Cloudの構成イメージを理解し、適切な語彙に精通する必要があります。
正解についての説明：
（選択肢）
・プロジェクトAの境界に対してイングレスポリシーを設定し、プロジェクトBのサービスアカウントに対してメッセージを収集するためのアクセスを許可します
この選択肢が正解の理由は以下の通りです。
イングレスポリシーは、サービスコントロール（SC）境界内からの入力要求を制御するもので、プロジェクトBのサービスアカウントからのアクセス要求を個別に許可することができます。
したがって、最小特権の原則に基づいて、プロジェクトBのサービスアカウントに対してアクセス権を付与するためには、プロジェクトAの境界に対してイングレスポリシーを設定するのが適切です。それにより、プロジェクトBのサービスアカウントはプロジェクトAのPub/Subトピックからメッセージを収集するための最小限の権限が得られます。
そして、その他のアクセスを制限したままにすることで、セキュリティを確保できます。適切な設定と優れたアクセス制御を実現するために、イングレスポリシーの設定は非常に重要な手段となります。
不正解についての説明：
選択肢：プロジェクトBの開発者が、プロジェクトAにあるPub/Subトピックをサブスクライブできるアクセスレベルを作成します
この選択肢が正しくない理由は以下の通りです。
プロジェクトBの開発者がプロジェクトAのPub/Subトピックへのアクセスレベルを作成すると、そのアクセスレベルが最小特権の原則に反し、不必要な権限を与える可能性があります。
一方、イングレスポリシーを設定することで、最小限の特権を持つ限定的なアクセスを提供することが可能になります。
選択肢：プロジェクトAとプロジェクトBの間に境界ブリッジを作り、両プロジェクト間で必要なコミュニケーションを可能にします
この選択肢が正しくない理由は以下の通りです。
Google Cloudには"境界ブリッジ"という概念は存在しません。
一方で、VPC Service Controlsはイングレスコントロールを利用し、特定のAPIアクセスの許可を行うことができます。最小特権の原則に基づいて特定のサービスアカウントに対するアクセスを許可するため、正解の選択肢が適切です。
選択肢：プロジェクトAの境界構成で、制限されたサービスのリストからPub/Sub APIを削除します
この選択肢が正しくない理由は以下の通りです。
境界構成でPub/Sub APIを削除すると、全てのサービスがPub/Subトピックへのアクセスが可能となり最小特権の原則に反します。
逆に、イングレスポリシーを設定することで、必要なサービスアカウントだけがアクセスできるようにコントロールが可能となります。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/ingress-policy
https://cloud.google.com/vpc-service-controls/docs/perimeter-bridges
https://cloud.google.com/pubsub/docs/access-control
</div></details>

### Q.  問題17: 未回答
ある企業は、アナリストと管理者の両方が共有するCloud Storageのバケットに、アプリケーションのログをバックアップしています。アナリストは、個人を特定できる情報（PII）を含まないログにのみアクセスできるようにする必要があります。PIIを含むログファイルは、管理者のみがアクセスできる別のバケットに保存する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、アプリケーションログの管理と個人を特定できる情報（PII）の取り扱い方について問われています。重要なのは、アナリストがPIIを含まないログにのみアクセスできるようにしつつ、管理者だけがPIIを含むログにアクセスできるようにするという要件を満たすソリューションを見つけることです。それぞれのロールに応じた適切なアクセス制限を設けるための方法を理解することが求められています。このシナリオでは、Google Cloudの各サービス間でどのように連携させれば、この要件を効果的に満たせるかが問われています。
基本的な概念や原則：
Cloud Storage：Google Cloudのデータ保存とデータダウンロードサービスです。高い対応力と伸縮性を持ち、データの保存、取得、更新、削除などが可能です。
Cloud Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。アプリケーション間で非同期にメッセージを配信することができます。
Cloud Functions：Google Cloudのイベント駆動型のサーバーレス実行環境です。特定のイベントに対して自動的に反応する関数を作成することができます。
Data Loss Prevention（DLP）：個人を特定する情報（PII）を見つける、隠す、管理するためのGoogle Cloudのサービスです。データのスキャンと検出を行い、PIIの漏洩を防ぎます。
ログファイル：アプリケーションの動作を記録したファイルです。エラーの診断やアプリケーションの性能監視などに使用します。
個人を特定する情報（PII）：個々の人々を直接または間接的に特定する情報です。厳重な管理と保護が必要です。
Cloud Data Loss Prevention API：Google CloudのAPIで、開発者がDLP機能を自分のアプリケーションに統合できます。データをスキャンし、PIIを見つけて隠すことができます。
正解についての説明：
（選択肢）
・Cloud Pub/SubとCloud Functionsを使用して、共有バケットにファイルがアップロードされるたびにData Loss Preventionスキャンをトリガーします。スキャンでPIIが検出された場合、管理者だけがアクセスできるCloud Storageバケットに移動させます
この選択肢が正解の理由は以下の通りです。
まず、Cloud Pub/SubとCloud Functionsを使用すると、共有バケットに新たなファイルがアップロードされたときに、自動的に特定の処理を実行することが可能になります。これにより、ログファイルがアップロードされた瞬間にData Loss Prevention（DLP）スキャンを自動的に開始するという要件を満たすことができます。
また、DLPスキャンを使用することにより、アップロードされるすべてのログファイルから個人を特定可能な情報（PII）が検出されます。
さらに、Cloud Functionsの中で、DLPスキャンがPIIを検出した場合には、該当のログファイルを管理者だけがアクセス可能なCloud Storageバケットへと移動させるような処理を書くことも可能です。これにより、PIIを含むログファイルは必ず管理者しかアクセスできないバケットに格納され、アナリストがPIIを含まないログにのみアクセスできるように制御されます。以上の理由から、この選択肢が最適な解答です。
不正解についての説明：
選択肢：共有バケットと管理者だけがアクセスできるバケットの両方にログをアップロードします。Cloud Data Loss Prevention APIを使用してジョブトリガーを作成します。PIIを含むファイルを共有バケットから削除するようにトリガーを設定します
この選択肢が正しくない理由は以下の通りです。
不正解の選択肢では、ログがPIIを含むかどうかに関わらず最初から両方のバケットへログをアップロードすることになります。これは、アナリストがPIIを含む可能性のあるデータにアクセスするリスクを増大させ、指定の要件に反します。
一方、正しい選択肢では、PIIのスキャンが行われた後でのみ、データが移動されます。
選択肢：アナリストと管理者の双方が共有するバケット上で、PIIを含むオブジェクトを削除するようにオブジェクトライフサイクル管理を設定します
この選択肢が正しくない理由は以下の通りです。
オブジェクトライフサイクル管理を設定してPIIを含むオブジェクトを削除すると、管理者もその情報にアクセスすることができなくなります。これは要件を満たしません。正解の選択肢では、データ保護を確保しつつ、必要な利害関係者がアクセスできるように適切なバケットにデータを移動します。
選択肢：アナリストと管理者の双方が共有するバケットに、PIIデータがアップロードされたときのみトリガーされるCloud Storageトリガーを設定します。Cloud Functionsを使ってトリガーを捕捉し、そのようなファイルを削除します
この選択肢が正しくない理由は以下の通りです。
この選択肢では、PIIデータを含むファイルが単に削除されてしまいます。しかし、要件は管理者のみがアクセスできるバケットに保存することで、削除することではありません。
従って、この不正解の選択肢は要件を満たしていません。
参考リンク：
https://cloud.google.com/storage/docs/using-pubsub
https://cloud.google.com/dlp/docs/quickstarts
https://cloud.google.com/functions/docs/calling/storage
</div></details>

### Q.  問題18: 未回答
お客様の組織では、Compute Engine VM上で実行されるすべてのワークロードを保護し、インスタンスがブートレベルまたはカーネルレベルのマルウェアによって侵害されていないことを確認したいと考えています。また、ハードウェアベースのソリューションを使用することで、VM上で使用されているデータが基盤となるホストシステムから読み取れないようにする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute Engine VM上でのワークロードのセキュリティを担保し、VMの攻撃から保護するための記述が求められています。マルウェアの侵害からの保護、ホストシステムからのデータの読取り防止といった情報から、マルウェアからの保護課題とデータの閲覧防止が必要なことが理解されます。マルウェアからの保護にはセキュアブートとvTPM、基本的なホストシステムからのデータの読取り防止にはConfidential Computingの利用が考えられます。これらの情報から正しくGoogle Cloudのサービスを選択すれば問題解決の手がかりとなります。
基本的な概念や原則：
セキュアブート：システムが安全に起動することを保証するセキュリティ機能です。不正やマルウェアによるシステムの改ざんを防ぎます。
Virtual Trusted Platform Module（vTPM）：VMに対してTPM（Trusted Platform Module）と同様の機能を提供するソフトウェアコンポーネントです。信頼性、整合性、アクセス制御などのセキュリティ要素を担保します。
整合性モニタリング：システムやデータの整合性を監視するプロセスです。不正アクセスやデータの改ざんを検知します。
Google Shielded VM：Google Cloudで提供される、セキュアブート、vTPM、整合性モニタリングを備えたVMです。これらの機能により仮想マシンのセキュリティを強化します。
Confidential Computing：処理中のデータを暗号化し、ユーザーやクラウドプロバイダーからもデータへのアクセスを遮断する技術です。これにより、データがホストシステムから読み取れないように保護します。
組織のポリシー：組織がセキュリティや運用の指針として定めるルールのことです。これを使用して必要なアクションを強制することが可能です。
Cloud Run：コードをフルマネージドの環境で実行するためのサービスですが、本問題の要件を満たすためのソリューションではありません。
正解についての説明：
（選択肢）
・1. セキュアブート、Virtual Trusted Platform Module（vTPM）、整合性モニタリングを含むGoogle Shielded VMを使用します
2. Confidential Computingをアクティブ化します
3. 組織のポリシーを使用してこれらのアクションを強制します
この選択肢が正解の理由は以下の通りです。
まず、GoogleのShielded VMはシステムがブートレベルまたはカーネルレベルのマルウェアに侵害されていないことを保証する機能を提供します。特に、セキュアブートがOSの起動プロセスの正当性を確認し、Virtual Trusted Platform Module（vTPM）が暗号化キーの保護と他のセキュリティ関連の操作を提供し、整合性モニタリングがブートローダやカーネルに異常がないか検出ます。
次に、Confidential Computingは、ワークロードのデータを処理中も暗号化することで、基盤となるホストシステムからデータが読み取られるのを防ぎます。これは一般的な盗聴攻撃やデータ漏洩から保護します。
最後に、これらのセキュリティ対策を組織全体で確実に適用するために、組織のポリシーを使用してアクションを強制します。これは、各ユーザーがそれぞれ自分の判断でセキュリティ設定を決めてしまい、組織全体のセキュリティが確保されないことを防ぐためです。
以上のすべてにより、要件が満足されるため、この選択肢が正解となります。
不正解についての説明：
選択肢：1. セキュアブート、Virtual Trusted Platform Module（vTPM）、整合性モニタリングを含むGoogle Shielded VMを使用します
2. Cloud Run関数を作成して、VM設定を確認し、指標を生成し、関数を定期的に実行します
この選択肢が正しくない理由は以下の通りです。
Cloud Run関数はVMの設定を確認したり指標を生成したりするのに利用できますが、それらはブートレベルやカーネルレベルのマルウェア保護やハードウェアベースのデータ保護といった要求には直接対応していません。それらの要求は、Google Shielded VMとConfidential Computingを用いることで満たすことができます。
選択肢：1. Security Command Center（SCC）PremiumでVirtual Machine Threat Detectionをアクティブ化します
2. SCCでの結果を監視します
この選択肢が正しくない理由は以下の通りです。
Security Command Center（SCC）PremiumでVirtual Machine Threat Detectionを使用すると、既存の脅威を検出できますが、ハードウェアレベルでのマルウェア侵害を確実に防ぐにはShielded VMなどのソリューションが必要です。
また、基盤となるホストシステムからのデータ読み取りを防ぐためには、Confidential Computingが必要で、これはSCCでは提供されません。
選択肢：1. Google Cloud Marketplaceから安全に強化されたイメージを使用します
2. イメージを展開するときに、Confidential Computingオプションを有効にします
3. 組織のポリシーを使用して、正しいイメージとConfidential Computingの使用を強制します
この選択肢が正しくない理由は以下の通りです。
まず、誤った選択肢はブートレベルやカーネルレベルでのマルウェア防止に具体的な対策を提案していません。
対照的に、正答はソリューションとしてShielded VMを提案し、安全なブート、vTPM、整合性モニタリングによりこれらの問題に対処します。
参考リンク：
https://cloud.google.com/security/shielded-cloud/shielded-vm
https://cloud.google.com/confidential-computing
https://cloud.google.com/resource-manager/docs/organization-policy/organization-policy-introduction
</div></details>

### Q.  問題19: 未回答
あなたの会社は機密データをCloud Storageに保存しています。オンプレミスで生成したキーを暗号化処理に使用したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のデータ暗号化のニーズとその実施方法について考察します。ここでは、ユーザーが持っているオンプレミスで生成されたキーの利用が問題の中心となります。そのため、各選択肢においてはどの選択肢がユーザーが持っている既存のキーの利用を可能にしているかを重視する必要があります。キーの種類や管理方法についての理解も問われるため、それぞれの選択肢がどのような操作を示しているのか理解することが重要です。
基本的な概念や原則：
顧客が提供する暗号化キー（CSEK）：Google Cloud Storageにデータを保存する際に、ユーザーが自身で生成し管理する暗号化キーです。データを暗号化してアップロードし、ダウンロード時に復号化する際に使用します。
データ暗号化キー（DEK）：データの暗号化と復号化に使用する鍵です。鍵の管理方法は顧客が選択可能で、全ての鍵は顧客だけが管理することも、Googleが管理することも可能です。
Cloud Key Management Service（KMS）：Google Cloud上で暗号鍵を管理するためのフルマネージドサービスです。鍵の生成、使用、管理、回転、削除を行うことが可能です。ただし、この問題のシナリオでは、オンプレミスで生成したキーを使用する必要があるため適切とは言えません。
鍵暗号化キー（KEK）：他の暗号鍵（通常はデータ暗号化キー）の暗号化と復号化に使用される鍵です。これにより、DEKの安全性を強化することができます。
正解についての説明：
（選択肢）
・データ暗号化キー（DEK）の管理には、顧客が提供する暗号化キーを使用します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、Cloud Storageに保存されたデータを暗号化するための複数の方法を提供しています。しかしながら、オンプレミスで生成したキーを暗号化処理に使用したい場合、顧客が提供する暗号化キー（Customer-Supplied Encryption Key, CSEK）を使う方法が適しています。CSEKは、データを保存する前に、そのデータを暗号化するために使用されるキーです。このキーは、Googleによって管理されず、キーの管理責任は完全にユーザー側にあります。そのため、CSEKを使用すると、ユーザーは自分で生成したキーでデータを暗号化できるほか、自身でキーのライフサイクルを管理することもできます。これは、あなたの会社が機密データを扱う際のセキュリティ要件を満たすために必要な制御を提供します。
不正解についての説明：
選択肢：Cloud Key Management Serviceを使用して、データ暗号化鍵（DEK）を管理します
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Serviceを使用した場合、Google Cloudがキー管理を担当します。ただし、要件はオンプレミスで生成したキーを使用することです。正解は、顧客提供鍵（CSEK）を使用することで、オンプレミスで生成したキーを用いることが可能となります。
選択肢：鍵暗号化キー（KEK）を管理するために、Cloud Key Management Serviceを使用します
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Serviceを使用すると、Google Cloudがキーの管理を担当します。しかし、問題文ではオンプレミスで生成したキーを使用したいと明記されているため、自分でキー管理を行う必要があります。だからこそ、正解の選択肢では"顧客が提供する暗号化キー"を使用すると記されています。
選択肢：鍵暗号化キー（KEK）の管理には、顧客が提供する暗号化キーを使用します
この選択肢が正しくない理由は以下の通りです。
鍵暗号化キー（KEK）は、他の暗号キーをセキュアに管理するために使用されます。しかし、データそのものを暗号化する際のキーとして顧客指定の暗号化キーを直接使用するためには、データ暗号化キー（DEK）を使用する必要があります。よって、この選択肢は不適切です。
参考リンク：
https://cloud.google.com/storage/docs/encryption/customer-supplied-keys
https://cloud.google.com/kms/docs
https://cloud.google.com/storage/docs/encryption
</div></details>

### Q.  問題20: 未回答
あなたの組織では、継続的インテグレーションとデリバリー（CI/CD）プラットフォームとしてGitHub Actionsを使用しています。最も安全な方法でCI/CDパイプラインからGoogle Cloudリソースへのアクセスを有効にする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、GitHub ActionsというCI/CDプラットフォームを用いて、最も安全な方法でGoogle Cloudリソースへのアクセスを実現する必要があります。これを解くためにはGoogle Cloudの認証・認可機構についての理解が必要です。選択肢の中にはサービスアカウントキーやワークロードIDフェデレーション等、いくつかのアクセス制御メカニズムが提示されていますが、最も安全で、かつGitHub Actionsと適合するものを選ぶ必要があります。
基本的な概念や原則：
ワークロードIDフェデレーション：これは、サービスアカウントキーを使用せずにGoogle Cloudリソースにアクセスするための機能です。これにより、サードパーティのIDプロバイダーからの認証情報をGoogle Cloudのサービスアカウントと関連づけることができます。
IDプールプロバイダー：外部のIDプロバイダー（GitHubなど）とGoogle Cloud間のトラストリレーションを設けることで、プロバイダーの認証情報を受け入れることを指します。
サービスアカウントキー：Google Cloudのサービスアカウントの認証情報の一部です。これを公開すると、潜在的なリスクがあります。
GitHub Actions：GitHubのCI/CDプラットフォームです。リポジトリ内のコードに対するビルド、テスト、デプロイ等の動作を自動化することができます。
Workload Identity：Kubernetes上のサービスアカウントとGoogle Cloudサービスアカウントをリンクするシステムです。GKEクラスターを使用していますが、GitHubと直接統合する機能はありません。
正解についての説明：
（選択肢）
・GitHubをIDプールプロバイダーとして使用するよう、ワークロードIDフェデレーションを設定します
この選択肢が正解の理由は以下の通りです。
まず、ワークロードIDフェデレーションは、外部のIDプロバイダからの認証情報をGoogle Cloudに統合できるようにするもので、これによりCI/CDパイプラインからGoogle Cloudリソースへの安全なアクセスを実現します。GitHubをIDプールプロバイダとして設定することで、既存のGitHub Actions認証が使用され、セキュリティ上の一貫性が維持されます。
さらに、ワークロードIDフェデレーションを使用することで、Google Cloudへのアクセス時にサービスアカウントキーを長期間保持する必要がなくなり、それ自体がセキュリティ上のメリットとなります。
したがって、GitHubをIDプールプロバイダーとして使用するように、ワークロードIDフェデレーションを設定するという選択肢は、CI/CDパイプラインからGoogle Cloudリソースへの最も安全な方法でのアクセスを有効にするための適切な手段となります。
不正解についての説明：
選択肢：サービスアカウントキーを作成し、GitHubパイプラインの設定ファイルに追加します
この選択肢が正しくない理由は以下の通りです。
サービスアカウントキーをGitHubパイプラインの設定ファイルに追加すると、セキュリティリスクが高まります。キーが公開された場合、不正なアクセスを許可してしまう可能性があります。
これに対して、ワークロードIDフェデレーションを設定すると、厳密なアクセス制御が可能であり、より安全です。
選択肢：サービスアカウントキーを作成し、GitHubリポジトリのコンテンツに追加します
この選択肢が正しくない理由は以下の通りです。
サービスアカウントキーをGitHubリポジトリのコンテンツに追加すると、誤ったアクセスやキーの漏洩のリスクが高まります。これはセキュリティ上好ましくありません。
それに対して、ワークロードIDフェデレーションを設定してGitHubをIDプールプロバイダーとして使用すると、短期的なGoogle Cloud資格情報を提供し、よりセキュアなアクセスが可能になります。
選択肢：Workload Identityを使用してGitHubに認証情報を提供するGoogle Kubernetes Engineクラスターを設定します
この選択肢が正しくない理由は以下の通りです。
Workload IdentityはGKEクラスター内部での認証に使用され、GitHubなどの外部サービスからGoogle Cloudリソースへアクセスするような直接的な連携は提供しません。
一方、ワークロードIDフェデレーションを設定すると、GitHubをIDプロバイダーとして認識し、CI/CDパイプラインからGoogle Cloudリソースへのアクセスを安全に可能にします。
参考リンク：
https://cloud.google.com/iam/docs/workload-identity-federation
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://docs.github.com/en/actions/security-guides/automatic-token-authentication
</div></details>

### Q.  問題21: 未回答
クラウドサービスの提供と利用に適用される情報セキュリティ管理に関するガイドラインを定めた国際的なコンプライアンス基準はどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、クラウドサービスの提供と利用に適用される情報セキュリティ管理に関するガイドラインを定めたコンプライアンス基準を特定することが求められています。ここで注意すべきは、すべての選択肢がISO 27000シリーズ（情報セキュリティ管理システムの一部）であることですが、それらの中でも特にクラウドサービスの情報セキュリティについて言及されているものを選ぶことが必要です。
基本的な概念や原則：
ISO 27017：クラウドサービスの提供と利用に特化した、情報セキュリティ管理のための国際標準です。
ISO 27001：情報セキュリティ管理システム（ISMS）のための国際標準です。全般的な情報セキュリティを対象としています。
ISO 27002：情報セキュリティ管理のためのベストプラクティスとコントロールを提供する標準です。主に組織の情報セキュリティポリシーの設定と実行に利用されます。
ISO 27018：パーソナルデータを保護するための、クラウドコンピューティングサービスに特化した国際標準です。
正解についての説明：
（選択肢）
・ISO 27017
この選択肢が正解の理由は以下の通りです。
ISO 27017は、クラウドサービスの提供者と利用者のための情報セキュリティ管理に関する具体的なガイドラインを定めた国際的な規格です。この基準では、クラウドサービスの利用者と提供者の間でロールと責任を明確に区分し、両者が適切なセキュリティ対策を講じることを求めています。
またこの規格は、攻撃者によるセキュリティ侵害のリスクを軽減し、クラウド環境の信頼性と透明性を確保するための詳細なガイドラインも提示しています。そのため、クラウドサービスの提供と利用に適用される情報セキュリティ管理に関する国際的なコンプライアンス基準として、ISO 27017は最適な選択肢となります。
不正解についての説明：
選択肢：ISO 27001
この選択肢が正しくない理由は以下の通りです。
ISO 27001は情報セキュリティ管理システム全般の国際標準であり、特にクラウドサービスの提供及び利用に特化した基準ではありません。
それに対して、ISO 27017は具体的にクラウドサービスに関する情報セキュリティ管理のガイドラインを定めたもので、問題文の要求に直接対応します。
選択肢：ISO 27002
この選択肢が正しくない理由は以下の通りです。
ISO 27002は情報セキュリティ全般のベストプラクティスを提供する一方、ISO 27017は特にクラウドサービスの提供や利用に焦点を当て、その情報セキュリティ管理について具体的なガイドラインを定めています。よって問題の要求にはISO 27017が適しています。
選択肢：ISO 27018
この選択肢が正しくない理由は以下の通りです。
ISO 27018は、個人情報を保護するためのクラウド専用のプライバシースタンダードであり、情報セキュリティ管理全般のガイドラインではありません。対照的にISO 27017は、クラウドサービスの提供と利用に適用される情報セキュリティ管理に関する国際的なスタンダードとなります。
参考リンク：
https://cloud.google.com/security/compliance/iso-27001
https://cloud.google.com/security/compliance/iso-27017
https://www.iso.org/standard/43757.html
</div></details>

### Q.  問題22: 未回答
あなたは、プライベートクラウドからGoogle Cloudへのデータ移行を検討している組織のコンサルタントです。この組織のコンプライアンスチームはGoogle Cloudに精通しておらず、Google Cloud上でコンプライアンス要件がどのように満たされるかについてのガイダンスが必要です。具体的なコンプライアンス要件の1つは、静止状態の顧客データを特定の地理的境界内に置くことです。Google Cloud上でデータレジデンシー要件を満たすために、どのオプションを推奨しますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのデータ移行に関連する問題について、コンプライアンス要件を満たすための最適なソリューションを選択すべきです。問題の主旨を理解するために、重要な情報に注意を払ってください。まず、組織のコンプライアンスチームはGoogle Cloudに精通しておらず、コンプライアンス要件をどのように満たすかについてガイダンスが必要である必要があります。そして、組織の特定のコンプライアンス要件が、静止状態の顧客データを特定の地理的境界内に置くことである必要があります。これに基づいて、選択肢を評価します。
基本的な概念や原則：
組織ポリシーサービス：Google Cloudリソースに適用するポリシーを定義し、管理するサービスです。特定の地理的境界内にデータを配置するなど、データの配置に関する制約を設けることが可能です。
データレジデンシー：データが保存される物理的な場所を指します。法令や規制、組織のポリシーにより、特定の地域や国内でデータを保持することが求められる場合があります。
Shielded VMインスタンス：不正なソフトウェアや不適切な仮想マシンインスタンスの起動を防ぐ仮想マシンです。しかし、データレジデンシーの制約を満たすロールはありません。
アクセス制御リスト：特定のユーザーやグループに対するリソースへのアクセス許可を制御します。しかし、データの地理的な配置には影響を及ぼしません。
Google Cloud Armor：Google Cloud上のアプリケーションやサービスを保護するセキュリティサービスです。データの攻撃から防御しますが、データレジデンシーの制約を満たすロールはありません。
正解についての説明：
（選択肢）
・組織ポリシーサービス制約
この選択肢が正解の理由は以下の通りです。
組織ポリシーサービス制約を使用すると、Google Cloud内のリソースの場所を制御することができます。これは、特定のデータセンターや地理的境界内にデータを保管するというデータレジデンシーの観点から、非常に重要です。組織ポリシーサービスを使用すると、どのリージョンやゾーンにリソースを配置できるかを制限するポリシーを設定できます。この制約は、特定の地理的範囲内にデータを保持するというコンプライアンス要件を満たすのに役立ちます。
さらに、Google Cloudが準拠している規制や証明書について説明した公式ドキュメントをコンプライアンスチームに提供することもお勧めします。これにより、彼らはGoogle Cloudが組織のコンプライアンス要件をどのように満たしているかを理解しやすくなります。
不正解についての説明：
選択肢：Shielded VMインスタンス
この選択肢が正しくない理由は以下の通りです。
Shielded VMインスタンスは、VMに対する悪意ある攻撃を防ぐ保護機能を提供するものであり、データレジデンシー要件、すなわちデータを特定の地理的境界内におくというコンプライアンス要件を満たすものではありません。一方で組織ポリシーサービス制約を使用すると、Google Cloudリソースの配置を制御し、データレジデンシー要件を満たすことができます。
選択肢：アクセス制御リスト
この選択肢が正しくない理由は以下の通りです。
アクセス制御リストはネットワークのセキュリティ設定で、特定のユーザー等からのアクセスを制御する仕組みであり、データが物理的にどこに保存されるかを決定する機能はありません。反対に、組織ポリシーサービス制約はGoogle Cloudリソースの配置を制御することが可能で、データの地理的境界を定義できます。
選択肢：地理的位置によるアクセス制御
この選択肢が正しくない理由は以下の通りです。
地理的位置によるアクセス制御は、ユーザの地理的位置に基づいてデータへのアクセスを制御するものであり、データレジデンシー（静止状態のデータ配置）要件とは異なります。
一方、組織ポリシーサービス制約は特定の地理的境界内にデータを配置することで、データレジデンシー要件を満たすことができます。
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは、ウェブアプリケーションのセキュリティとDDoS攻撃の防御を主目的とするサービスであり、データのレジデンシー、つまりデータの地理的配置をコントロールする機能は提供していません。
一方で、組織ポリシーサービス制約を使用すると、特定の地域でのリソースの作成を制限することができ、データのレジデンシー要件を満たすことが可能です。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/storage/docs/locations
https://cloud.google.com/compliance/offerings
</div></details>

### Q.  問題23: 未回答
あなたは組織のセキュリティオペレーションセンター（SOC）を管理しています。現在、パケットヘッダ情報に基づいてGoogle Cloud VPCのネットワークトラフィックの異常を監視し、検出しています。しかし、調査を支援するために、ネットワークフローとそのペイロードを調査する機能が必要です。
どのGoogle Cloudサービスを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ネットワークフローとそのペイロードの監視と調査に適したGoogle Cloudのサービスを特定する必要があります。ここではネットワークトラフィックの異常を監視するロールとパケットヘッダ情報だけでなくペイロードも検査するという要件が重要となります。選択肢を評価する際には、これらの要件を満たすサービスを見極めることが求められます。
基本的な概念や原則：
Packet Mirroring：Google Cloud上の仮想マシン（VM）のネットワークトラフィックを複製し、深度パケット検査（DPI）、パフォーマンスモニタリングなどの分析のために使うことができるサービスです。
Marketplace IDS：Google Cloud Marketplace上で提供されている侵入検知システム（IDS）の一つです。ネットワークトラフィックを監視し、攻撃や不審な活動を検出します。
VPCフローログ：VPCネットワーク内のインスタンスからのパケット情報（送信元IP、宛先IP、パケットのサイズなど）をコレクトし、記録したものです。
VPC Service Controls：Google Cloudのサービス間のデータ交換を制御するためのサービスです。セキュリティ対策とデータのプライバシー保護に役立ちます。
Google Cloud Armor：Google Cloudのウェブアプリケーションファイアウォール（WAF）と分散型サービス拒否（DDoS）対策ソリューションです。特定のIP範囲のトラフィックをブロックしたり、自動的にスケールアウトする能力があります。
正解についての説明：
（選択肢）
・Packet Mirroring
この選択肢が正解の理由は以下の通りです。
Packet MirroringはGoogle Cloudのネットワークトラフィックを監視して異常を検出し、分析する機能を提供します。VPCのネットワークトラフィックを複製し、選択した受信者に送信します。これにより、セキュリティ、パフォーマンス監視、ネットワークトラフィック調査を目的とした詳細な分析が可能になります。特に問題が指摘している、ネットワークフローとそのペイロードを調査する機能という要件を十分に満たすことができます。
また、Packet Mirroringはパケットレベルでの深い洞察を可能にするため、既存のパケットヘッダ情報に基づく監視にも有力な補完となります。
したがって、セキュリティオペレーションセンター（SOC）の管理とネットワーク異常の監視と検出において、Google CloudのPacket Mirroringを使用すべきです。
不正解についての説明：
選択肢：Marketplace IDS
この選択肢が正しくない理由は以下の通りです。
Marketplace IDSはサードパーティの侵入検知システムであり、それ自体ではネットワークフローとそのペイロードの調査は可能としません。
一方、Packet MirroringはVPCのネットワークトラフィックを複製し、フローとペイロードを詳細に調査できるため問題の要件を満たします。
選択肢：VPCフローログ
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフローの情報を提供しますが、ペイロードを調査する機能は持っていません。
一方、Packet Mirroringは指定したインスタンスのトラフィックをミラーリングし、ネットワークフローとペイロードを詳細に調査できます。
選択肢：VPC Service Controlsログ
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsログは、VPC内部の情報を提供しますが、特定のネットワークフローとペイロードの詳細情報を提供するものではありません。
一方、Packet Mirroringは指定されたVPCネットワーク内のトラフィックをミラーリングし、詳細なパケットデータの分析を可能にするため、要件を満たします。
選択肢：Google Cloud Armorディープパケットインスペクション
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorのディープパケットインスペクションは存在しません。Google Cloud Armorは主にHTTP(S)負荷分散に対するDDoS攻撃を防ぐツールです。
一方、Packet MirroringはVPCのネットワークトラフィックを複製して分析するためのサービスで、ペイロードの調査を可能にします。
参考リンク：
https://cloud.google.com/vpc/docs/using-packet-mirroring
https://cloud.google.com/vpc/docs/flow-logs
https://cloud.google.com/armor/docs/security-policy-overview
</div></details>

### Q.  問題24: 未回答
オンプレミスのデータセンターとVPCホストネットワークの間にCloud Interconnect接続を設定する必要があります。オンプレミスのアプリケーションが、パブリックインターネット経由ではなく、Cloud Interconnect経由でのみGoogle APIにアクセスできるようにする必要があります。サポートされていないAPIへの流出リスクを軽減するために、VPC Service ControlsでサポートされているAPIのみを使用する必要があります。
ネットワークはどのように設定すればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Interconnectを使用してオンプレミスのデータセンターとVPCホストネットワークを接続し、パブリックインターネットではなくCloud Interconnect経由でのみGoogle APIにアクセスできるようにし、さらにサポートされていないAPIへの流出リスクを軽減するためにVPC Service ControlsでサポートされているAPIのみを使用するネットワーク設定が求められています。設問からは、ニーズとしてセキュリティとコントロールが強調され、各種のGoogle Cloudの機能とサービスを適切に組み合わせ利用することにより、この要件を満たすことが出来るでしょう。特に重要なのは、セキュリティ、コントロール、APIへのアクセスの方法です。
基本的な概念や原則：
Cloud Interconnect：オンプレミスネットワークとGoogle Cloudのプライベート接続を提供するサービスです。パブリックインターネットを介さずに通信でき、ネットワークのパフォーマンスと信頼性が向上します。
制限付きgoogleapis.com：Google Cloud APIにプライベートIPアドレスからアクセスするためのサービスです。Google Cloud内からのみルーティング可能なIPアドレスセットを提供します。
VPC Service Controls：Google CloudのAPIとサービスに対して、データの流出を防ぐためのセキュリティ境界を設ける機能です。この制御を使用することで、リスクを軽減してセキュリティを向上させることができます。
Google API：Google Cloudの機能を操作するためのインターフェースです。これは、コードからGoogle Cloudのリソースの作成、削除、更新などを行う際に使用します。
プライベートGoogleアクセス：GoogleのAPIとサービスにプライベートIPアドレスからアクセスする機能です。プライベートなネットワーク経由でGoogle Cloudの機能に接続することが可能になります。
正解についての説明：
（選択肢）
・制限付きgoogleapis.comを使用すると、Google Cloud内からのみルーティング可能なIPアドレスのセットを使用してGoogle APIにアクセスできます。このIPアドレスは、Cloud Interconnect接続上のルートとしてアドバタイズされます
この選択肢が正解の理由は以下の通りです。
まず、制限付きgoogleapis.comを使用することで、オンプレミスのアプリケーションはGoogle APIに対してパブリックインターネット経由でなく、プライベート接続を経由することが可能になります。これは、オンプレミスとVPCホストネットワーク間で通信を行うためにCloud Interconnectを使用する設定と一致しています。そのため、制限付きgoogleapis.comの使用は、Cloud Interconnectのプライベート接続を通じた通信の設定を有効にします。
さらに、制限付きgoogleapis.comには、Google Cloud内からのみアクセス可能な特定のIPアドレスのセットが含まれています。これは、オンプレミスのアプリケーションがGoogle APIにアクセスする際の通信をより安全に制限します。
最後に、制限付きgoogleapis.comのIPアドレスは、Cloud Interconnect接続上のルートとしてアドバタイズされます。このことは、オンプレミスのアプリケーションがGoogle APIに接続するためのルートが明確に確立されていることを意味します。
したがって、制限付きgoogleapis.comの使用は安全性とパフォーマンスを高め、必要な要件を満たすための適切な選択です。
不正解についての説明：
選択肢：リージョンサブネットのプライベートGoogleアクセスとグローバルダイナミックルーティングモードを有効にします
この選択肢が正しくない理由は以下の通りです。
リージョンサブネットのプライベートGoogleアクセスとグローバルダイナミックルーティングモードを有効にすると、VPCからのAPIリクエストはパブリックインターネットを経由する可能性があります。これは問題の要件、"パブリックインターネット経由ではなくCloud Interconnect経由でのみGoogle APIにアクセス"を満たしていません。
選択肢：APIバンドルが "all-apis"のプライベートサービスコネクトエンドポイントIPアドレスを設定し、Cloud Interconnect接続上のルートとしてアドバタイズします
この選択肢が正しくない理由は以下の通りです。
"all-apis"のプライベートサービスコネクトエンドポイントは、すべてのGoogle APIにアクセスできますが、これはサポートされていないAPIへの流出リスクを軽減する要件に反します。
一方、制限付きgoogleapis.comは、サポートされているAPIのみがアクセス可能で、リスク軽減の要件を満たします。
選択肢：private.googleapis.comを使用すると、Google Cloudからのみルーティング可能なIPアドレスのセットを使用してGoogle APIにアクセスできます
この選択肢が正しくない理由は以下の通りです。
まず、誤った選択肢で提案されているprivate.googleapis.comは、オンプレミスのアプリケーションからGoogle APIに接続するために使われるものではありません、これはGoogle Cloud内部から接続できるように設計されています。
一方、制限付きgoogleapis.com（正解選択肢）は、Cloud Interconnect接続を通じてGoogle APIに接続するために使われ、オンプレミスのアプリケーションからアクセスできるように設計されています。
参考リンク：
https://cloud.google.com/interconnect/docs/how-to/restricting-api-access
https://cloud.google.com/vpc-service-controls/docs/set-up-private-connectivity
https://cloud.google.com/vpc/docs/configure-private-google-access#restricted-google-access
</div></details>

### Q.  問題25: 未回答
あなたは会社のために新しいGoogle Cloudの組織を作成する担当者です。
特権管理者アカウントを作成する際に取るべき2つのアクションはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの組織において特権管理者アカウントを作成する際のベストプラクティスに関する理解が求められています。特権管理者アカウントは組織における重要なロールを果たすため、セキュリティの観点から最適な手法を選ぶことが不可欠です。選択肢を評価する際には、アカウントのセキュリティ強化やリスクの低減がどの程度図られているかを考えると良いでしょう。
基本的な概念や原則：
多要素認証（MFA）：セキュリティを向上させる認証手法で、2つ以上の異なる認証要素を組み合わせてアクセスの許可を行います。特権管理者アカウントの安全性の確保に役立ちます。
物理的なトークン：多要素認証（MFA）の一部として使用されるデバイスで、特定の認証情報を生成または保管します。紛失や盗難による認証情報の漏洩リスクを軽減します。
非特権ID：日常業務用に提供される、特権を持たないアカウント。特権管理者が日常業務を行う際のリスクを軽減します。
Identity and Access Management（IAM）：ユーザーやサービスに対して適切な権限を付与、管理する機能です。アクセス制御を行うことで、セキュリティを確保します。
正解についての説明：
（選択肢）
・物理的なトークンを使用して、特権管理者の認証情報を多要素認証（MFA）で保護します
・特権管理者の日々の活動のために、非特権IDを提供します
この選択肢が正解の理由は以下の通りです。
まず、物理的なトークンを使用して、特権管理者の認証情報を多要素認証（MFA）で保護することで、アカウントの不正なアクセスを防止出来ます。特権管理者アカウントは、組織全体の設定やリソースへのアクセスをコントロールする能力があるため、これらのアカウントへのアクセスを厳密に保護することが重要となります。MFAは、それを可能にし、アカウントのセキュリティを向上させます。
また、特権管理者の日々の活動のために、非特権IDを提供することも重要となります。これにより、管理者が日常的な作業で特権を使わないで済み、特権アカウントを使う必要がある場合のみそれを使用するようになるため、不必要に強力な特権を持つアカウントが使われるのを防ぎます。これにより、誤って設定を変更するリスクや不正なアクセスによる被害を最小限に抑えることが出来ます。
不正解についての説明：
選択肢：Google Adminコンソールでアクセスレベルを作成し、特権管理者がGoogle Cloudにログインできないようにします
この選択肢が正しくない理由は、Google Adminコンソールでアクセスレベルを作成し、特権管理者がGoogle Cloudにログインできないようにするというアクションは、特権管理者アカウントの保護や日々の活動を助けるものではありません。特権管理者は組織の全Google Cloudリソースを管理するため、ログイン不能にすると組織のITインフラストラクチャの管理が不可能になります。このため、正解の選択肢と比べてもこの選択肢は適切なものではありません。
選択肢：Google Cloud Consoleで、組織レベルの特権管理者のIdentity and Access Management（IAM）ロールを無効にします
この選択肢が正しくない理由は以下の通りです。
特権管理者のロールを無効にするという方法は、管理者が頻繁に行う操作や設定の誤りからシステム全体が影響を受けるリスクを減らす一方で、組織の管理が困難になる可能性もあります。対してMFAや非特権IDの利用は、特権管理者の認証を強化し、操作が制限されることなく安全性を向上させるため、適切な対策となります。
選択肢：プライベート接続を使用して特権管理者アカウントを作成し、認証情報をインターネット上に送信しないようにします
この選択肢が正しくない理由は以下の通りです。
Google Cloudのアカウント作成はインターネット経由で行われ、プライベート接続を使用して特権管理者アカウントを作成することは技術的に不可能です。
一方、問題の要件を満たす適切なアクションでは、MFAを使用して認証情報を保護し、普段使用する非特権アカウントを提供することです。
参考リンク：
https://cloud.google.com/iam/docs/using-mfa
https://cloud.google.com/resource-manager/docs/creating-managing-organization
https://cloud.google.com/iam/docs/creating-managing-service-accounts
</div></details>

### Q.  問題26: 未回答
あなたの所属するDevOpsチームはPackerを使用して、次のプロセスでCompute Engineイメージを構築します。
1. 一時的なCompute Engine VMを作成します。
2. Cloud StorageバケットからVMのファイルシステムにバイナリをコピーします。
3. VMのパッケージマネージャーを更新します。
4. 外部パッケージをインターネットからVMにインストールします。
セキュリティチームは、VM上のパブリックIPアドレスの使用を制限するために、組織ポリシーのconstraints/compute.vmExternalIpAccessを有効にしました。これに応じて、DevOpsチームはスクリプトを更新して、Compute Engine VM上のパブリックIPアドレスを削除しました。ただし、接続の問題によりビルドパイプラインが失敗します。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、組織ポリシーで設定した外部IPアドレスへのアクセス制限により、ビルドプロセスが失敗してしまうDevOpsチームの対応策が求められています。ポイントとなるのは、パブリックIPへのアクセスを許可せずに、依然として外部からのパッケージインストールやCloud Storageバケットからのファイル転送などを維持する方法です。そのため、private IPを活用した接続手順や設定の確認、またNATやプライベートGoogleアクセスなどの機能を適切に利用することが重要となります。解答を選択する際は、これらの要素を理解し、各選択肢が提供する機能やその影響をきちんと評価することが求められます。
基本的な概念や原則：
Cloud NAT：Google CloudのマネージドNATサービスで、プライベートインターネットアクセスを提供します。特に、VPC内でのパブリックIPアドレスの使用を制限する場合に使用されます。
プライベートGoogleアクセス：Google Cloudサービスへのインターネットアクセスが制限されたインスタンスに対して、非公開IPアドレスを使用してGoogle Cloud APIとサービスにアクセスする機能です。
VPC：Google Cloudの仮想プライベートクラウド（VPC）ネットワークを構築、展開してホストするサービスで、プロジェクトのVMインスタンスに冗長性と規模の拡張性を提供します。
組織ポリシー：組織レベルで設定可能な制限や制約のことで、セキュリティ強化やコンプライアンスのために使用されます。
Packer：オープンソースのツールで、複数のプラットフォームに対するイメージを自動化的に作成します。スクリプトを用いて、一貫性のあるイメージ作成手順を定義することができます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、安全に大量のデータを保存し、世界中からアクセスすることができます。
正解についての説明：
（選択肢）
・Compute Engine VMと同じVPCおよびリージョンにCloud NATインスタンスをプロビジョニングします
・Compute Engine VMがデプロイされているサブネットで、プライベートGoogleアクセスを有効にします
この選択肢が正解の理由は以下の通りです。
まず、組織ポリシーでパブリックIPの使用を制限した場合、Compute Engine VMからインターネットへの直接的な接続ができなくなります。ここでCloud NATをプロビジョニングするという選択肢が有効となります。Cloud NATを使うと、Compute Engine VMがVPC内部から外部のインターネットに接続できるようになります。これにより、VMからの外部パッケージのインストールなどが可能となり、ビルドパイプラインが正常に動作するようになります。
次に、VMがデプロイされているサブネットでプライベートGoogleアクセスを有効にすることにより、VMは外部IPアドレスを持たないままでもGoogle Cloudのサービス（Cloud Storageなど）に接続できます。これにより、Cloud Storageバケットからのバイナリのコピーが失敗することなく実行できます。これら二点により、パブリックIPアドレスを使用することなく、ビルドパイプラインが問題なく実行できるようになります。
不正解についての説明：
選択肢：インターネットからVMへのインバウンド接続を許可するために、アンマネージドインスタンスグループ内のVMでHTTPロードバランサーをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
HTTPロードバランサーをプロビジョニングすることは、インターネットからのインバウンド接続を許可するものではありません。
また、この問題の要件は、VMからインターネットにアウトバウンド接続を行うことで、パブリックIPアドレスを使用せずにインターネットにパッケージをインストールすることです。これは、ロードバランサーでは解決できません。
選択肢：VPCルートを更新して、インターネットとのトラフィックを許可します
この選択肢が正しくない理由は以下の通りです。
VPCルートの更新は、パブリックIPアドレスがない場合でもインターネットと通信するための解決策ではありません。インターネットとの通信を許可するだけで、VMから外部パッケージをダウンロードできるようにはならず、要件とマッチしません。
選択肢：Compute EngineVMと同じVPCおよびリージョンに、Cloud VPNトンネルをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
Cloud VPNトンネルは、異なるネットワーク間の安全な接続を提供します。ただし、この問題はパブリックインターネットへの接続を解決する必要がありますし、Cloud VPNではその解決に不適で、Compute Engine VMが必要とするアクセスを提供しません。
それに対して、Cloud NATとプライベートGoogleアクセスはパブリックIP無しで外部パッケージをインターネットからインストールするための適切な解決策です。
参考リンク：
https://cloud.google.com/nat/docs/using-nat
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/compute/docs/ip-addresses#externaladdresses
</div></details>

### Q.  問題27: 未回答
ある大手金融機関は、ビッグデータ分析をGoogle Cloudに移行しようとしています。BigQueryに静止状態で保存されているデータの暗号化プロセスを最大限に制御したいと考えています。
金融機関はどのような技術を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ビッグデータ分析のクラウド移行とデータ暗号化プロセスについて結びつけて考えることが求められています。特に、BigQueryに保管する静止データの暗号化プロセスを"最大限に制御"したいという要求に着目しなければなりません。そのため各選択肢を評価する際には、これらの観点から最適な技術やサービスがどれかを判断することが重要になります。
基本的な概念や原則：
顧客管理の暗号化キー（CMEK）：Google Cloud上のサービスに対するデータ暗号化の際、ユーザーが自身で管理する暗号化キーです。暗号化プロセスを最大限に制御するために使用します。
BigQuery：Google Cloudのフルマネージドなビッグデータ分析サービスです。高速SQLクエリを使用してペタバイト単位のデータを分析できます。
Cloud Storage：オブジェクトストレージサービスであり、データ分析などに使用するためのデータを保存するための場所を提供しますが、データ暗号化を直接制御する機能は提供していません。
Cloud HSM：Cloud HSM（HSM）のクラウド版で、暗号鍵を高度に保護するためのサービスですが、直接的な暗号化プロセスの制御には関与しません。
顧客提供の暗号鍵（CSEK）：ユーザーがCloud Storageなどに定義する暗号化キーです。Google Cloudがそのキーを管理するため、暗号化プロセスを最大限に制御するオプションではありません。
正解についての説明：
（選択肢）
・顧客管理の暗号化キー（CMEK）を使用します
この選択肢が正解の理由は以下の通りです。
まず、顧客管理の暗号化キー（CMEK）を使用すれば、ユーザーは暗号化プロセスを自分自身で制御することが可能になります。BigQueryでは、データを保存する際に自動的に暗号化されますが、この暗号化をGoogle Cloudが管理するキーで行なうのではなく、顧客が管理するキー（CMEK）で行なうことが可能となります。これにより、顧客は自社のデータに対する暗号化を自身で管理し、さらに厳格なセキュリティガイドラインを満たすことが可能となります。特に金融機関など、高いセキュリティ基準を必要とする業界では、CMEKの使用が推奨されます。
不正解についての説明：
選択肢：Cloud Storageを連携データソースとして使用します
この選択肢が正しくない理由は以下の通りです。
Cloud Storageを連携データソースとして使用することは、データの暗号化プロセスを制御するための手法ではありません。Cloud Storageはデータ保存場所の一つであり、その利用は暗号化プロセスの制御とは関係ありません。
一方、顧客管理の暗号化キー（CMEK）を使用することで、金融機関は暗号化キーを自身で管理し、暗号化プロセスを制御できます。
選択肢：Cloud HSM（Cloud HSM）を使用します
この選択肢が正しくない理由は以下の通りです。
Cloud HSMは高セキュリティの暗号化キー管理を提供しますが、BigQueryのデータ暗号化を直接コントロールする機能は含まれていません。
一方で、顧客管理の暗号化キー（CMEK）を使用すると、ユーザーは自身の暗号化キーを生成・管理できるため、BigQueryのデータ暗号化プロセスを最大限に制御できます。
選択肢：顧客提供の暗号鍵（CSEK）を使用します
この選択肢が正しくない理由は以下の通りです。
BigQueryでは、暗号化キーの管理方法として顧客提供の暗号化鍵（CSEK）は使用できません。BigQueryは従来から自動的にデータを暗号化し、より詳細な制御を可能にするために顧客管理の暗号化鍵（CMEK）を使用することが可能です。
参考リンク：
https://cloud.google.com/bigquery/docs/encryption-cmek
https://cloud.google.com/kms/docs
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題28: 未回答
顧客の会社には複数の事業部門があります。各事業部門は独立して運営されており、それぞれにエンジニアリンググループがあります。あなたのチームは、社内で作成されたすべてのプロジェクトを可視化し、異なるビジネスユニットに基づいてGoogle Cloudプロジェクトを整理したいと考えています。また、各ビジネスユニットは、別々のIAM権限セットを必要とします。
これらのニーズを満たすために、どの戦略を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、異なる事業部門が各々独立して運営され、各部門が異なるIAM権限のセットを必要としているという情報に着目します。また、社内で作成された全てのプロジェクトを可視化し、異なるビジネスユニットに基づいてGoogle Cloudプロジェクトを整理したいというニーズも考慮します。これらを踏まえて、Google Cloudの組織構造とIAMの仕組みを理解した上で最適な戦略を選びます。また、各選択肢が提供できる機能と限界を理解しておくことも重要です。
基本的な概念や原則：
組織ノード：Google Cloudのリソース階層のルート要素です。組織全体の方針を設定したり、リソースの所有権とライフサイクルを管理したりします。
フォルダ：Google Cloudのリソース階層を整理するためのツールです。異なる部門やプロジェクト間など、異なるビジネスユニットに基づいてリソースを整理するのに使用します。
IAM（Identity and Access Management）：特定のユーザーが特定のリソースに対して行えるアクションを制御するGoogle Cloudのサービスです。IAMポリシーを使用して、どのユーザーがどのリソースにアクセスできるかを管理します。
Google Cloudプロジェクト：Google Cloudリソースを整理するための一助です。あるプロジェクト内のリソースは、同じプロジェクト内の他のリソースと相互作用できます。
VPC（Virtual Private Cloud）：Google Cloud内で定義された自分だけのプライベートネットワーク空間です。各VPCは他のVPCから隔離されています。
ラベル：Google Cloudリソースを整理し、追跡するための識別子です。リソース所有者や費用センターなど、自分のニーズに合わせてリソースをカテゴライズできます。
正解についての説明：
（選択肢）
・組織ノードを作成し、各ビジネスユニットのフォルダを割り当てます
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudでは、Google Cloudのリソースを整理し管理するために階層モデルが提供されています。その中で、組織ノードは、全てのリソースのルートとなり、その下にフォルダやプロジェクトを持つことができます。あなたのチームが全てのプロジェクトを可視化し、整理したいと考えているのであれば、組織ノードを作成することで全プロジェクトの見通しを良くすることができます。
また、各ビジネスユニットに対して独立したフォルダを割り当てることで、ビジネスユニットごとに独立してプロジェクトやリソースを整理できます。
さらに、IAM権限はフォルダレベルでも設定できるため、各ビジネスユニットに独自のIAM権限セットを適用することが可能です。
したがって、組織ノードを作成し、各ビジネスユニットのフォルダを割り当てることが、これらの要件を満たす最適な戦略となります。
不正解についての説明：
選択肢：gmail.comアカウントを使用し、各ビジネスユニットごとに独立したプロジェクトを立ち上げる
この選択肢が正しくない理由は以下の通りです。
Gmail.comアカウントを使用し、各ビジネスユニットごとに独立したプロジェクトを立ち上げるだけでは、社内全体のプロジェクトの管理やビジネスユニット間の整理が難しくなります。正しい選択肢である組織ノードとフォルダの割り当ては、構造的な管理を可能にし、各ユニットへのIAM権限セットの適用も容易にします。
選択肢：プロジェクトでGoogle Cloudリソースを割り当て、どの事業部門がリソースを所有しているかを示すラベルを付けます
この選択肢が正しくない理由は以下の通りです。
プロジェクトごとにリソースを割り当て、ラベルを付けて管理する方法では、プロジェクト全体の視覚化や、ビジネスユニットごとの異なるIAM権限セットの適用が難しいためです。
一方、"組織ノードを作成し、各ビジネスユニットのフォルダを割り当てる"選択肢では、これらの要件を満たすことが可能です。
選択肢：事業部ごとにVPC内のGoogle Cloudリソースを割り当て、ネットワークアクセスを分離します
この選択肢が正しくない理由は以下の通りです。
VPCの分離はネットワークアクセスを制御しますが、全プロジェクトの可視化やIAM権限の設定といった課題を解決するものではありません。
一方、組織ノードとフォルダを用いて各事業部ごとに整理することで、プロジェクトの可視化、整理とIAM権限の設定が可能となります。
参考リンク：
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://cloud.google.com/resource-manager/docs/creating-managing-organization
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題29: 未回答
VPCネットワーク上で定義される2つの暗黙のファイアウォールルールはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、VPCネットワーク上で任意に設定される2つの暗黙のファイアウォールルールについて尋ねています。解答する際には、Google CloudのVPCとファイアウォールの仕組みについての知識が必要です。また、VPCで初期に設定される（つまりユーザーが手動で設定しない）暗黙のルールについて理解している必要があります。具体的な操作や特定のポート番号に関する選択肢よりも、全体のトラフィックフロー（インバウンド、アウトバウンド）について記述した選択肢が正解となる可能性が高いです。
基本的な概念や原則：
VPCネットワーク：Google Cloudの仮想ネットワークです。VPCネットワークでは、仮想マシンインスタンスや他のリソースにプライベートIPアドレスを割り当て、それらを隔離したり接続したりすることができます。
ファイアウォールルール：ネットワークに対する特定の種類の通信を許可または拒否するルールです。具体的には、特定のIPアドレス、IPアドレス範囲、プロトコル、ポートに対するインバウンドまたはアウトバウンドの通信を制御します。
暗黙のファイアウォールルール：明示的に設定されていない、デフォルトで存在するファイアウォールルールのことです。Google Cloudでは、すべてのアウトバウンド接続を許可するルールと、すべてのインバウンド接続を拒否するルールが暗黙のルールとして存在します。
正解についての説明：
（選択肢）
・すべてのアウトバウンド接続を許可するルール
・すべてのインバウンド接続を拒否するルール
この選択肢が正解の理由は以下の通りです。
"すべてのアウトバウンド接続を許可するルール"と"すべてのインバウンド接続を拒否するルール"は、Google Cloud VPCネットワークに自動的に定義される2つの暗黙的なファイアウォールルールです。アウトバウンド接続を許可するルールにより、ネットワーク内部から外部へのすべての通信が可能になります。
一方で、インバウンド接続を拒否するルールにより、ネットワークへの未承認の接続が阻止されます。この2つのルールは、セキュリティを確保するために設定され、必要に応じて追加のファイアウォールルールを定義してカスタマイズすることが可能です。
したがって、これらの選択肢は、VPCネットワーク上で自動的に定義される暗黙のファイアウォールルールを正確に表しています。
不正解についての説明：
選択肢：すべてのインバウンドポート25接続をブロックするルール
この選択肢が正しくない理由は以下の通りです。
VPCネットワークで定義されるのは全体的な設定で、特定のポート（この場合は25）に対するルールを暗黙的には設定しません。それに対して正解の選択肢はVPCネットワークのデフォルト設定であり、詳細なポートやプロトコル指定無しに適用されます。
選択肢：すべてのアウトバウンド接続をブロックするルール
この選択肢が正しくない理由は以下の通りです。
Google Cloud VPCネットワークの暗黙のファイアウォールルールは、すべてのアウトバウンド接続を許可するルールです。
逆に、すべてのアウトバウンド接続をブロックするルールは存在しないため、この選択肢は不適切です。
選択肢：すべてのインバウンドポート80接続を許可するルール
この選択肢が正しくない理由は以下の通りです。
選択肢ではインバウンドポート80への接続を許可するルールが黙示的に存在すると述べていますが、Google Cloudの黙示的なファイアウォールルールはポートやプロトコルに依存しないものであり、さらにデフォルトルールではインバウンド接続はすべて拒否されます。
したがって、この選択肢は不適切です。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls#default_firewall_rules
https://cloud.google.com/vpc/docs/firewalls#defaultrules
https://cloud.google.com/network-connectivity/docs/vpn/how-to/configuring-firewall-rules
</div></details>

### Q.  問題30: 未回答
セキュリティチームがファイアウォールルールなどのネットワークリソースを制御できるように、VPCを作成する必要があります。
ネットワークリソースの職務を分離できるようにするために、ネットワークをどのように構成すればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ネットワークリソースに対する職務分離を達成するための最適な構成について考える必要があります。特に、セキュリティチームがネットワークリソースを制御でき、それと共に開発者もネットワークに対する作業が可能であるという要件に注目してください。選択肢を検討する際には、これらの要件を満たしつつ、適切な分離と管理が行える構成を選択することが求められます。
基本的な概念や原則：
共有VPC：Google Cloudの機能で、1つの "ホストプロジェクト" 内にVPCネットワークを作成し、同じGoogleCloudオーガニゼーション内の他の "サービスプロジェクト" とそのVPCネットワークを共有します。ファイアウォールルールやネットワークルーティングなどの中央管理を可能にします。
職務分離：セキュリティのベストプラクティスです。特定の任務や機能を複数の個々に分けることで、フラウドやエラーを防止します。
VPCネットワークピアリング：異なるVPCネットワーク間でトラフィックを私的に交換するための接続を設定する機能です。それらのネットワークは同じプロジェクト、または異なるプロジェクト内にあることができます。
マルチNIC仮想アプライアンス：複数のネットワークインターフェースカード（NIC）を備えた、特定のネットワーク機能（ファイアウォール、ロードバランサーなど）を提供するための仮想アプライアンスです。
Compute Network Adminロール：VPCリソースを含むネットワークリソースの管理を担当します。
Compute Adminロール：Compute Engineのリソース全体を管理します。
正解についての説明：
（選択肢）
・セキュリティチームがファイアウォールルールを管理する共有VPCを設定し、サービスプロジェクトを通じて開発者とネットワークを共有します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの共有VPCはネットワークリソースを複数のプロジェクト間で共有したい場合に有効な機能です。共有VPCを使用することで、一つのプロジェクト（この場合はセキュリティチームのプロジェクト）がネットワーク（例えばVPC内のサブネットやファイアウォールルール）を所有・管理し、そのネットワークの一部分を他のプロジェクト（例えば開発者のプロジェクト）に共有することが可能になります。ファイアウォールルールなどのネットワークリソースをセキュリティチームが一元的に管理できる一方で、開発者はそのネットワーク内で自身のアプリやサービスを動作させることができます。
また、職務分離も実現可能で、それぞれが必要なリソースに対する適切な権限を持つことができます。
したがって、これらの要件を見たとき、共有VPCを用いてVPCを設定し、サービスプロジェクトを通じて開発者とネットワークを共有することは最適な解決方法といえます。
不正解についての説明：
選択肢：複数のVPCネットワークを設定し、ネットワークを接続するためにマルチNIC仮想アプライアンスを設定します
この選択肢が正しくない理由は以下の通りです。
まず、複数のVPCネットワークとマルチNIC仮想アプライアンスを設定する方法は、リソースの分離と管理を行うための効果的な方法ではありません。仮想アプライアンスは通常、特定のネットワーク機能を提供するために使用されますが、ネットワークリソースの職務を分離するための効果的な手段とは言えません。
一方、共有VPCを設定することで、セキュリティチームがファイアウォールルールを一元的に管理し、開発者はそれを活用します。これにより正確な職務の分離が実現可能です。
選択肢：VPCネットワークピアリングを設定し、開発者が共有VPCとネットワークをピアリングできるようにします
この選択肢が正しくない理由は以下の通りです。
VPCネットワークピアリングを設定すると、各VPCが等しくネットワークリソースを制御でき、職務分離する目的に合致しません。
一方、共有VPCを設定すると、セキュリティチームがVPCの管理と制御を行い、開発者のプロジェクトとネットワークを明確に分けられます。
選択肢：プロジェクトにVPCを設定します。Compute Network Adminロールをセキュリティチームに割り当て、 Compute Adminロールを開発者に割り当てます
この選択肢が正しくない理由は以下の通りです。
VPCを各プロジェクトに設定し、Compute Network Adminロールをセキュリティチームに、Compute Adminロールを開発者に割り当てると、職務分離が上手く行われません。なぜなら、Compute Adminロールはファイアウォールルールを含むネットワークリソースの変更が許可されてしまうからです。
それに対して、共有VPCではネットワークリソースを制御できるのはセキュリティチームだけであり、職務分離を達成できます。
参考リンク：
https://cloud.google.com/vpc/docs/shared-vpc
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/vpc/docs/provisioning-shared-vpc
</div></details>

### Q.  問題31: 未回答
コンプライアンス報告の目的で、内部監査部門は、重要なオペレーティングシステム（OS）セキュリティアップデートが利用可能ですが、インストールされていない仮想マシン（VM）のリストを提供する必要があります。このリストは6カ月ごとに提供する必要があり、このタスクを迅速に実行したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、重要なオペレーティングシステム（OS）セキュリティアップデートが利用可能であるがインストールされていない仮想マシン（VM）のリストを提供するソリューションが求められています。そのリストは6ヶ月ごとに提供する必要があります。したがって、具体的には、各VMの更新ステータスを定期的に監査やレポートするソリューションが頼りになります。Google Cloudのサービスの中には、VMのバージョン情報、脆弱性情報、OS更新ログ等を提供するものがあります。それらのサービスを使って解決策を見つける必要があります。注目すべきはタイミングとオペレーションの効率化です。問題が要求する解決策を選択肢から選ぶ際にこれらの観点を念頭に置くことが重要です。
基本的な概念や原則：
OS Config：Google Cloudのサービスで、仮想マシンのOS設定を管理し、アップデートを適用することができます。
パッチステータスダッシュボード：OS Configで利用できる機能で、現存するパッチの状態を確認し、必要なアップデートが適用されていないVMを特定することができます。
Security Command Center：Google Cloudのセキュリティとリスク分析のプラットフォームで、リソースの脆弱性や潜在的な脅威を特定し、それに対応します。
gcloud CLI：Google Cloudのコマンドラインインターフェイスで、Google Cloudのプロダクトとサービスを管理するためのツールです。
Cloud Logging：Google Cloudのログ管理サービスで、アプリケーションとシステムのログデータを収集、保管、分析、表示することができます。
正解についての説明：
（選択肢）
・OS ConfigエージェントがすべてのVMにインストールされていることを確認し、6カ月ごとにパッチステータスダッシュボードを抽出します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのOS Configエージェントは、オペレーティングシステムのアップデートと設定管理を自動化するためのツールです。それは、VM上のパッケージが最新であるかどうかをテストし、必要であれば更新を行います。よって、コンプライアンス報告の目的で重要なOSセキュリティアップデートをチェックするためには、このエージェントが非常に重要となります。
また、Google Cloudでは、パッチステータスダッシュボードという機能を提供しています。このダッシュボードを用いると、全てのVMのパッチステータスを一覧で確認することができます。このダッシュボードを利用することで、監査部門が必要としている、セキュリティアップデートが未インストールのVMのリストを迅速に作成することが可能となります。
以上の理由から、OS Configエージェントを用いて6カ月ごとにパッチステータスダッシュボードを見ることで、監査部門の要件を満たすことができます。
不正解についての説明：
選択肢：すべてのVMに対してSecurity Command Centerのセキュリティスキャンを実行し、重大なOSの脆弱性を持つVMのリストを6カ月ごとに抽出します
この選択肢が正しくない理由は以下の通りです。
Security Command Centerのセキュリティスキャンは、重大なOSの脆弱性を識別するためのものですが、OSのセキュリティアップデートのインストール状況を追跡することはできません。そのため、アップデートがインストールされていないVMを特定することが目的である本題の要件を満たすことができません。
選択肢：コマンドラインインターフェイス（CLI）からgcloud CLIコマンドを実行し、6カ月ごとにVMのOSバージョン情報を抽出します
この選択肢が正しくない理由は以下の通りです。
gcloud CLIコマンドを使用してVMのOSバージョン情報を抽出しても、重要なOSのセキュリティアップデートが利用可能かどうか、またはそれがインストールされているかどうかについての詳細な情報は提供できません。
対照的に、OS Configエージェントは利用可能なセキュリティーアップデートの詳細情報を提供可能です。
選択肢：すべてのVMにCloud Loggingエージェントがインストールされていることを確認し、6ヶ月ごとにOSの最終更新ログ日付を抽出します
この選択肢が正しくない理由は以下の通りです。
Cloud Loggingエージェントは主にログの収集と監査に使用されますが、特定のOSセキュリティアップデートのインストール状態についての情報を提供しません。
それに対して、OS ConfigエージェントはOSのパッチ管理を提供しており、セキュリティアップデートの有無を迅速に把握できます。
参考リンク：
https://cloud.google.com/compute/docs/osconfig/rest
https://cloud.google.com/security-command-center/docs
https://cloud.google.com/logging/docs/agent/logging/
</div></details>

### Q.  問題32: 未回答
ある顧客が、Compute Engine上に多数の3層のWebアプリケーションをデプロイしたいと考えています。
顧客は、アプリケーションの異なる層間の認証されたネットワーク分離をどのように確保すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、3層のWebアプリケーションの異なる層間の認証されたネットワーク分離をどのように確保すべきかを問われています。ここでは、分離手法として用いられる技術やアプローチの理解が問われている点に注意が必要です。具体的には、サービスアカウント、プロジェクト、サブネット、VMタグ、およびそれらに適用できるファイアウォールルールについての理解が求められています。
基本的な概念や原則：
サービスアカウント（SA）：Google Cloudの仮想ユーザーアカウントです。特定のアプリケーションやサービスに特定の認証と許可を提供します。
ファイアウォールルール：ネットワークソフトウェアの特定のアクションに対する許可や制限を設定するルールです。これにより、特定のネットワークトラフィックを許可したり、遮断したりすることが可能です。
プロジェクト：Google Cloudのリソースのオーガニゼーション単位です。リソースの管理と設定の適用を一元化することが可能です。
サブネット：ネットワークをセグメント化することにより、異なる部分ごとにネットワークポリシーを適用することができます。
VMタグ：Google Cloud上の仮想マシンに付けられたラベルです。特定のVMに対する検索、フィルタリング、管理を容易にします。
正解についての説明：
（選択肢）
・各階層を異なるサービスアカウント（SA）で実行し、SAベースのファイアウォールルールを使用します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudのサービスアカウントは、特定のアプリケーションやサービスがGoogle Cloudリソースにアクセスするためのアイデンティティを表します。これらのサービスアカウントを使用して各層を実行することで、アプリケーションの層間に認証されたネットワーク分離を設けることができます。サービスアカウントで各層を分離することにより、特定の層に属するリソースへのアクセスを他の層から制限することができます。
次に、サービスアカウントベースのファイアウォールルールを使用すると、さらに安全性を強化することが可能です。ファイアウォールルールを使用して各サービスアカウントを限定することで、ネットワークの不適切なトラフィックを防ぐことができます。一般的に、ファイアウォールルールと組み合わせてサービスアカウントを使用することで、アプリケーションの異なる層間の安全性と効率性を向上させることができます。
したがって、顧客がアプリケーションの異なる層間の認証されたネットワーク分離を確保するための適切な方法は、各階層を異なるサービスアカウントで実行し、サービスアカウントベースのファイアウォールルールを使用することです。
不正解についての説明：
選択肢：各階層をそれぞれのプロジェクトで実行し、プロジェクトラベルを使って分離します
この選択肢が正しくない理由は以下の通りです。
各階層をそれぞれのプロジェクトで実行し分離する手法は、非効率であり、また管理も複雑になります。
それに対して、サービスアカウントを使って認証を行い、ファイアウォールルールを使用する方法はより効率的でシンプルにネットワーク分離を実現できます。
選択肢：各階層を独自のサブネットで運用し、サブネットベースのファイアウォールルールを使用します
この選択肢が正しくない理由は以下の通りです。
サブネットのファイアウォールルールを使用するのではなく、各階層を異なるサービスアカウントで実行することで、より細かなアクセス制御とセキュリティの観点から優れています。具体的には、各サービスアカウントは特定の階層でのみ利用され、その階層が必要とするリソースへのアクセスのみ許可することで、不審な行動を即時に警告や制限が可能になります。
選択肢：各階層を独自のVMタグで実行し、タグベースのファイアウォールルールを使用します
この選択肢が正しくない理由は以下の通りです。
VMタグでの管理は、VMのロールや機能といった属性を指定するのに使われますが、ネットワーク分離や認証を担保する機能は持っていません。
それに対して、サービスアカウントを用いるとアクセス制御し、認証されたネットワーク分離を達成できます。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/iam/docs/understanding-service-accounts
https://cloud.google.com/compute/docs/instances/service-accounts
</div></details>

### Q.  問題33: 未回答
あなたの組織は、Google Cloudでインフラストラクチャとアプリケーションをデプロイするために、新しい継続的インテグレーションとデリバリー（CI/CD）プロセスを展開しています。多くのチームがCI/CDワークフローの独自のインスタンスを使用することになるでしょう。それはGoogle Kubernetes Engine（GKE）上で実行されます。CI/CDパイプラインは、Google Cloud APIに安全にアクセスできるように設計する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの持つCI/CDプロセスをGKE上でセキュアに実行する方法について問われています。問題文からは、異なるチームが適用するCI/CDワークフローが独立して動作し、かつGoogle Cloud APIに安全にアクセスできる必要性が読み取れます。そのため、サービスアカウントの設定や、その認証方法、また、ワークロードの管理方法について深く理解しつつ適切な選択をすることが求められます。セキュリティと効率性、そして問題文で述べられている要求条件を満たすためのベストプラクティスに焦点を当てて選択肢を評価する必要があります。
基本的な概念や原則：
サービスアカウント：Google Cloudの認証と権限付与を管理するための仮想アカウントです。特定のサービスが他のサービスにアクセスするための鍵を保管します。
継続的インテグレーションとデリバリー（CI/CD）：コードの変更を自動的にビルド、テスト、デプロイするプロセスです。効率的なソフトウェア開発と信頼性の高いリリースを支援します。
Google Kubernetes Engine（GKE）：Google Cloudで提供されるKubernetes環境です。スケーラブルなアプリケーションとシステムのデプロイメントの自動化を実現します。
ワークロードID：Google Kubernetes Engineの機能で、Kubernetesの稼働するワークロードとGoogle Cloudサービスアカウントを関連付けます。
名前空間：Kubernetesのリソースを隔離するための仮想クラスターの単位です。同じ物理クラスター内で複数のチームやプロジェクトが共存できます。
ノードプール：一緒に管理するノード（Kubernetesのワーカーマシン）のグループです。異なるワークロードやユーザー間でリソースを分離します。
秘密鍵・Kubernetesシークレット：重要な情報（パスワード、トークン、キーなど）を安全に保存するためのKubernetesのリソースです。
正解についての説明：
（選択肢）
・1. インフラストラクチャ用とアプリケーション展開用の2つのサービスアカウントを作成します
2. ワークロードIDを使用して、ポッドが2つのパイプラインを実行し、サービスアカウントで認証できるようにします
3. インフラストラクチャとアプリケーションのパイプラインを別の名前空間で実行します
この選択肢が正解の理由は以下の通りです。
多くのチームがCI/CDワークフローの独自のインスタンスを使用するので、個々のワークフローが異なるリソースやサービスにアクセスする可能性があります。このため、インフラストラクチャとアプリケーションの展開のために2つのサービスアカウントを作成することで、チームごとに適したアクセス権限を持つサービスアカウントを使用できます。これにより、セキュリティのリスクを軽減できます。
次に、ワークロードIDを使用してポッドが2つのパイプラインを実行し、それぞれのワークフローの識別に役立ちます。これにより、サービスアカウントを使用した認証も行えます。
最後に、異なる名前空間でパイプラインを実行することで、一つのチームの作業が他のチームの作業に干渉することを防ぎます。これは、Kubernetesの名前空間がロジカルな分離を提供するため、異なる名前空間のリソースは互いに見えません。
このような選択肢がCI/CDプロセスにおけるセキュリティと効率性の向上に不可欠です。
不正解についての説明：
選択肢：1. CI/CDパイプライン専用のサービスアカウントを作成します
2. GKEクラスター内の専用ノードプールでデプロイパイプラインを実行します
3. 作成したサービスアカウントをプール内のノードのIDとして使用して、Google Cloud APIに対して認証します
この選択肢が正しくない理由は以下の通りです。
この選択肢では、全てのCI/CDパイプラインに対して単一のサービスアカウントを使用していますが、一つのサービスアカウントを共有するとセキュリティリスクが高まります。
また、インフラストラクチャ用とアプリケーション展開用の2つのサービスアカウントを作成し、ポッドがこれらのパイプラインを実行し、サービスアカウントで認証するような分離されたアクセス設定が正解です。
選択肢：1. 導入パイプラインごとに個別のサービスアカウントを作成します
2. サービスアカウントの命名規則にパイプラインの識別子を追加します
3. 各パイプラインが専用ポッドで実行されていることを確認します
4. Workload Identityを使用して、デプロイメントパイプラインポッドをサービスアカウントにマッピングします
この選択肢が正しくない理由は以下の通りです。
導入パイプラインごとにサービスアカウントを作成し、それらを個々の識別子で命名すると管理が複雑になり、エラーが発生しやすくなります。
また、各パイプラインが専用ポッドで実行されることを確認するだけでは、セキュリティ上の分離が保証されません。これに対して正解の選択肢では、インフラストラクチャとアプリケーションのパイプラインを別の名前空間で実行することにより、適切なセキュリティ分離を実現しています。
選択肢：1. 各展開パイプラインのサービスアカウントを作成します
2. サービスアカウントの秘密鍵を生成します
3. 秘密鍵を、特定のデプロイパイプラインを実行するポッドのみがアクセスできるKubernetesシークレットとして安全に保存します
この選択肢が正しくない理由は以下の通りです。
サービスアカウントの秘密鍵を生成し、それをKubernetesシークレットとして保存する方法は、シークレットを安全に管理し、ワークロードの適切な認証と認可を確保するためのベストプラクティスではありません。キーの管理は困難で、不適切な管理がセキュリティの脆弱性を引き起こす可能性があるためです。正解選択肢のように、ワークロードIDとサービスアカウントを使用して認証を行う方が、よりセキュアで効率的です。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity
https://cloud.google.com/iam/docs/service-accounts
https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
</div></details>

### Q.  問題34: 未回答
ユーザーが誤って共有VPCホストプロジェクトを削除しないようにしたいと考えています。
どの組織レベルのポリシー制約を有効にするべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のVPCプロジェクトの誤削除を防止するための組織レベルポリシー制約の適用について尋ねています。そのため、共有VPCホストプロジェクトとその防止方法に関連する正確なポリシー制約を固定することが重要です。また、Google Cloudの関連する概念とポリシー制約の理解も必要となります。それぞれの制約がどのような機能を果たし、どのような状況で使用されるのかを把握することが求められます。
基本的な概念や原則：
compute.restrictXpnProjectLienRemoval：組織レベルのポリシー制約で、共有VPCホストプロジェクトの削除を制限します。この制約を有効にすると、課金プロジェクトの削除を防ぐことができます。
Shared VPC：Google Cloudでネットワークリソースを共有する機能です。異なるプロジェクト間でVPCネットワークとそのリソースを共有することができます。
組織レベルのポリシー：Google Cloudリソースの使用を制御するもので、組織全体で適用されます。制約に基づいて特定のアクションの実行を制限することができます。
Lien：リソースが削除されないように保護するマーカーです。特定の状態が維持されるまで、リソースは削除できません。
正解についての説明：
（選択肢）
・compute.restrictXpnProjectLienRemoval
この選択肢が正解の理由は以下の通りです。
Google Cloudの組織レベルポリシー制約は、特定のリソースに対するユーザーアクションを制限する目的で設計されており、誤って重要なプロジェクトやリソースが削除されるのを防ぐために役立ちます。この場合、共有VPCホストプロジェクトの削除を防ぐため"compute.restrictXpnProjectLienRemoval"制約を利用することが求められています。
この制約は、共有VPCホストプロジェクトへの"リーン"（削除防止の保護措置）の解除を制限します。つまり、この制約が有効になっていると、ユーザーは誤って共有VPCホストプロジェクトを削除することができなくなります。
"compute.restrictXpnProjectLienRemoval"制約を有効にすると、誤った操作による影響を最小限に抑えることができるため、重要な共有VPCホストプロジェクトの安全性を確保するために有効な手段となります。
不正解についての説明：
選択肢：compute.restrictSharedVpcHostProjects
この選択肢が正しくない理由は以下の通りです。
compute.restrictSharedVpcHostProjectsは、プロジェクトが共有VPCホストプロジェクトとして設定できるかどうかを制限する組織ポリシー制約で、既存の共有VPCホストプロジェクトの削除を防ぐものではありません。
それに対して、compute.restrictXpnProjectLienRemoval制約を適用すると、共有VPCホストプロジェクトの削除を防ぎます。
選択肢：compute.restrictSharedVpcSubnetworks
この選択肢が正しくない理由は以下の通りです。
compute.restrictSharedVpcSubnetworksという制約は、共有VPCのサブネットは特定のプロジェクトでのみ利用可能という制約を設けるものであるため、誤って共有VPCホストプロジェクトを削除するのを防ぐ目的には働きません。
それに対し、compute.restrictXpnProjectLienRemovalは共有VPCプロジェクトの削除を制約するため、この要件に適しています。
選択肢：compute.sharedReservationsOwnerProjects
この選択肢が正しくない理由は以下の通りです。
compute.sharedReservationsOwnerProjects制約は、コミットメントに対する共有リザベーションの所有者として許可されたプロジェクトを限定するもので、共有VPCホストプロジェクトの削除を防ぐものではありません。
一方、compute.restrictXpnProjectLienRemoval制約は、共有VPCホストプロジェクトの削除を防ぐための制約であり、この要件を満たします。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/vpc/docs/shared-vpc
https://cloud.google.com/resource-manager/docs/creating-managing-liens
</div></details>

### Q.  問題35: 未回答
ある会社のアプリケーションは、ユーザーが管理するサービスアカウントキーとともにデプロイされます。Googleが推奨するプラクティスを使用して、キーをローテーションしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Googleが推奨するサービスアカウントキーのローテーションに関する正しいプロセスを理解することが重要です。ユーザーが管理するサービスアカウントキーをローテーションするための手順について、正しい手順を選択する必要があります。代替案やGoogleが推奨するプラクティスに基づく解決策のみを探すことが求められているため、オプションを検討する際はGoogleの公式ドキュメンテーションを参照して、最善のプラクティスに合致する解決策を選びましょう。
基本的な概念や原則：
サービスアカウントキー：サービスアカウントを使用してGoogle Cloud APIにアクセスするための秘密鍵です。これによってアプリケーションはGoogle Cloudリソースに対するアクセスを認証します。
キーローテーション：セキュリティプラクティスの一つで、定期的に秘密鍵を更新することでセキュリティを維持します。
IAM_SERVICE_ACCOUNT：Identity and Access Management（IAM）のサービスアカウントです。これにより、特定のサービスがリソースに対して持つべき権限を制御します。
Cloud Shell：Google Cloud Consoleから直接アクセスできる、独自のコマンドライン環境です。これを使って、gcloudコマンドラインツールの操作を行えます。
gcloudコマンドラインツール：Google Cloudのリソースやサービスを管理するためのツールです。このツールを使って、サービスアカウントの操作やAPIの呼び出しが可能です。
正解についての説明：
（選択肢）
・新しいキーを作成し、アプリケーションで新しいキーを使用します。サービスアカウントから古いキーを削除します
この選択肢が正解の理由は以下の通りです。
まず、サービスアカウントキーのローテーション（定期的な更新）はセキュリティを強化し、誤使用のリスクを軽減するための一般的なプラクティスです。これは、古いキーが漏洩や不適切な使用によって危険にさらされる可能性を減らすためのものです。
このローテーションを実現するためには、新しいキーを作成し、アプリケーション上でその新しいキーを使用するように更新する必要があります。それから、アプリケーションが新しいキーを問題なく利用できることを確認した後、サービスアカウントから古いキーを削除します。このようにすることで、キーのローテーションを滑らかに行いつつ、キーに関連するセキュリティのリスクを最小限に抑えることができます。これが、Googleが推奨するプラクティスを満たすための適切な方法です。
不正解についての説明：
選択肢：Cloud Shellを開き、gcloud iam service-accounts enable-auto-rotate --iam-account=IAM_ACCOUNTを実行します
この選択肢が正しくない理由は以下の通りです。
Google Cloudでは、自動的にサービスアカウントキーをローテーション（更新）する機能は提供されていません。
したがって、"gcloud iam service-accounts enable-auto-rotate"というコマンドは存在しません。キーのローテーションは手動で行う必要があり、そのためには新しいキーを作成し、それをアプリケーションで使用するように変更し、古いキーを削除する過程が必要です。
選択肢：Cloud Shellを開き、gcloud iam service-accounts keys rotate --iam-account=IAM_ACCOUNT --key=NEW_KEYを実行します
この選択肢が正しくない理由は以下の通りです。
gcloud iam service-accounts keys rotateコマンドは存在しないため、サービスアカウントキーをローテーションするには新しいキーを生成し、古いキーを削除する方法を取らなければなりません。不正解の選択肢は誤ったコマンドを提案しています。
選択肢：新しいキーを作成し、アプリケーションで新しいキーを使用します。古い鍵はバックアップキーとしてシステムに保存します
この選択肢が正しくない理由は以下の通りです。
新しいキーを作成し、アプリケーションで使用すればローテーションの一部を達成できますが、古いキーをバックアップとして保存するというのはGoogleの推奨するプラクティスとは異なります。なぜなら古いキーが保持され続けることでセキュリティリスクを生じる可能性があるからです。正解の選択肢では、新しいキーを使用した後、古いキーが削除されているためセキュリティが確保されています。
参考リンク：
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題36: 未回答
あなたのチームは、Compute EngineインスタンスがインターネットやGoogle APIやサービスにアクセスできないようにする必要があります。
これらの要件を満たすために、どの2つの設定を無効にする必要がありますか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud上でCompute Engineインスタンスのアクセス制限に関する設定について理解することが重要です。パブリックなインターネットアクセスやGoogleサービスへのアクセスを制限するためにどの設定を無効にするか尋ねています。インスタンスがインターネットやGoogleサービスへアクセスする際のネットワークトラフィックやルートについて考え、選択肢を見極めることが求められます。
基本的な概念や原則：
パブリックIP：Google Cloudの仮想マシンインスタンスからインターネットに直接接続するために使用します。これを無効にすると、インスタンスはインターネットと直接通信できなくなります。
Private Google Access：Google Cloudの仮想マシンがプライベートIPアドレスを通じてGoogleのAPIとサービスにアクセスするための機能です。これを無効にすると、VMはGoogleのAPIやサービスにアクセスできなくなります。
IPフォワーディング：仮想マシンがパケットを受信してそれを別のネットワークに転送することを許可する機能です。
静的ルート：特定のネットワークゾーンから別のネットワークゾーンにトラフィックをルーティングするための手段です。
IAM Network Userロール：Google Cloud Identity and Access Management（IAM）のロールの一つで、特定のネットワークリソースへのアクセスを管理します。
正解についての説明：
（選択肢）
・パブリックIP
・Private Google Access
この選択肢が正解の理由は以下の通りです。
まず、"パブリックIP"を無効にすることで、Compute Engineインスタンスはインターネットに直接接続できなくなります。つまり、外部ネットワークからの直接アクセスがブロックされるため、インターネットからのアクセスを防止する目的が達成されます。
次に、"Private Google Access"を無効にすると、そのCompute EngineインスタンスはGoogle Cloudの他のAPIやサービスにアクセスすることができなくなります。Private Google AccessはGoogleのAPIやサービスへの内部接続を可能にする機能であるため、これを無効にするとGoogle Cloud内部のサービスへのアクセスも制限されます。このため、Google APIやサービスへのアクセスを制限する目的も達成されます。
不正解についての説明：
選択肢：IPフォワーディング
この選択肢が正しくない理由は以下の通りです。
IPフォワーディングを無効にすると、インスタンスが他のパケットを受信したり送信したりすることは防げますが、インスターネットやGoogle API, サービスへのアクセスには関係ありません。逆にパブリックIPやPrivate Google Accessを無効にすれば、それらへのアクセスを制限できます。
選択肢：静的ルート
この選択肢が正しくない理由は以下の通りです。
静的ルートを無効にすることはインターネットやGoogle APIやサービスへの接続を制御するための方法ではありません。
一方、パブリックIPを無効にするとインターネット接続が阻まれ、Private Google Accessを無効にするとGoogle APIやサービスへのプライベート接続が不可となります。
選択肢：IAM Network Userロール
この選択肢が正しくない理由は以下の通りです。
IAM Network Userロールは特定のユーザーがネットワークリソースを利用できるかどうかを管理するもので、Compute EngineインスタンスがインターネットやGoogle APIやサービスにアクセスする能力を直接的に制御するものではありません。パブリックIPやPrivate Google Accessを無効にすることで直接的にインスタンスの通信能力を制御できます。
参考リンク：
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/vpc/docs/using-firewalls
https://cloud.google.com/compute/docs/ip-addresses#reservedaddress
</div></details>

### Q.  問題37: 未回答
VPC Service Controlsを有効にして、リソースへのアクセスを妨げることなく、既存環境の境界の変更を許可する必要があります。
どのVPC Service Controlsモードを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、VPC Service Controlsの異なるモードとその特性について知識が必要です。特に、リソースへのアクセスを妨げずに境界の変更を許可することが要請されているため、それを可能にするモードを選ぶことが求められています。問題文から読み取れるように、適切なモードの選択はVPC Service Controlsの理解とそれが提供する操作体験にどのように影響を与えるかに基づいています。
基本的な概念や原則：
VPC Service Controls：Google Cloud上のデータとサービスに対するアクセスの管理をより厳密に行うためのツールです。ユーザーやサービスが特定の境界を越えてデータにアクセスすることを制御します。
ドライランモード：VPC Service Controlsの設定モードの一つで、制約事項を実際に適用することなく、報告のみを行います。リソースへのアクセスを妨げずに、既存環境の境界の変更を許可するのに適しています。
正解についての説明：
（選択肢）
・ドライランモード
この選択肢が正解の理由は以下の通りです。
ドライランモードは、VPC Service Controlsがどのように動作するかを理解するための特定の手段であり、正常な操作を妨げることなく安全境界の変更を評価するのに有用です。ドライランモードでは、制限が適用されると考えられるリクエストがあった場合にも、それらのリクエストは正常に処理されます。しかし、違反が発生したときにはその情報が記録されます。この記録は後で分析するために取得して参照することができます。
したがって、ドライランモードを使用することで、実際にはリソースへのアクセスをブロックしたり、正常な操作を妨げたりすることなく、VPC Service Controlsによって設定された境界の変更がどのように動作するかを評価できます。これにより、既存の環境で予想外の問題が発生するリスクを低減できます。
不正解についての説明：
選択肢：Cloud Runモード
この選択肢が正しくない理由は以下の通りです。
VPC Service ControlsにはCloud Runモードというものは存在しません。
一方、ドライランモードはVPC Service Controlsの設定が実際の挙動を停止することなく可能な境界の変更を試行できるモードで、質問の要件を満たします。
選択肢：ネイティブモード
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsの"ネイティブモード"という選択肢は存在しません。
一方、"ドライランモード"は制限を設定しつつも実際のアクセスを妨げずに、何が制限されるのかを確認するモードです。これにより、既存環境の境界変更を安全に許可することが可能となります。
選択肢：自動適用モード
この選択肢が正しくない理由は以下の通りです。
自動適用モードは現存環境の境界の変更を許可しない厳格なモードで、このモードを使用した場合、許可されていない操作を試みようとするとアクセスを防ぐことができます。これは問題の要件とは一致しません。
一方、ドライランモードはポリシー違反をログに記録するだけでアクセスは妨げませんから、この要件を満たします。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/set-up-vpc-sc
https://cloud.google.com/vpc-service-controls/docs/dry-run
https://cloud.google.com/vpc-service-controls/docs/overview
</div></details>

### Q.  問題38: 未回答
ある顧客が、ソースコード管理（SCM）システムにプレーンテキストのシークレットを保存する代わりに、別の方法を必要としています。
Google Cloudを使って、どのようにこれを実現すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ソースコード管理（SCM）システムにプレーンテキストのシークレットを保存する代わりの方法を客が求めている状況を理解することが求められています。質問の精神を正確にキャッチするためには、シークレットをソースコードリポジトリに直接保存するのではなく、Google Cloudの安全で一貫性のあるストレージや管理方法でシークレットを保存するための助言が求められていることを理解することが重要です。この観点から選択肢を評価します。
基本的な概念や原則：
顧客管理の暗号化キー（CMEK）：Google Cloud上で自分自身で管理する暗号化キーです。暗号化キー管理サービス（Cloud KMS）を使用し、自分のデータをよりしっかりと制御することができます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。直列化されたデータや大量のバイナリデータなど、非構造化データを格納するのに適しています。
Cloud Source Repositories：Google Cloudのプライベートソースコード管理サービスです。Gitのフル機能を提供し、他のGoogle Cloudサービスとの統合も可能です。
Cloud SQL：Google Cloudのフルマネージドリレーショナルデータベースサービスです。MySQL、PostgreSQL、SQL Serverのデータベースエンジンが利用可能です。
Cloud Data Loss Prevention API：機密データを検出、分類、保護するためのGoogle Cloudのサービスです。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。計算リソースを柔軟に管理し、スケールアップできます。
正解についての説明：
（選択肢）
・顧客管理の暗号化キー（CMEK）で暗号化し、Cloud Storageに保管します
この選択肢が正解の理由は以下の通りです。
まず、ソースコード管理システムにプレーンテキストのシークレットを保存するのはセキュリティ上のリスクが高いです。そのため、暗号化キーを用いてシークレットを暗号化し、暗号化されたシークレットを安全に保管する方法が必要となります。Google Cloudの顧客管理の暗号化キー（CMEK）は、この要件を満たす機能を提供します。CMEKは、Google Cloudのリソースを顧客自身が管理する暗号化キーで暗号化するための機能です。これを用いてシークレットを暗号化後、Cloud Storageに保管します。Cloud Storageは大規模なデータをセキュアに、耐久性高く保存するサービスであり、高い可用性を確保することも可能です。つまり、CMEKとCloud Storageを組み合わせることで、セキュアかつ信頼性の高いシークレットの保管方法を提供できます。
不正解についての説明：
選択肢：Cloud Source Repositoriesを使用し、Cloud SQLにシークレットを保存します
この選択肢が正しくない理由は以下の通りです。
Cloud Source Repositoriesはソースコードを管理するためのサービスであり、シークレットを保管するために設計されていません。Cloud SQLでも、シークレットの保管には適していません。
一方、CMEKで暗号化しCloud Storageに保管する選択肢は、シークレットが暗号化され保管されるため、安全性が確保されます。
選択肢：Cloud Data Loss Prevention APIを実行してシークレットをスキャンし、Cloud SQLに保存します
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Prevention APIは、機密情報を識別、分類、保護するためのサービスであり、本質的にはシークレットの管理方法としては適していません。Cloud SQLにそのまま保存すると再びプレーンテキストのシークレットを保存することになり、問題の要件を満たしません。
一方、CMEKを使用して暗号化し、Cloud Storageに保管すると、シークレットは暗号化されて安全に保管され、SCMシステムからのアクセスも容易です。
選択肢：ローカルSSDを持つCompute Engine VMにSCMをデプロイし、プリエンプティブVMを有効にします
この選択肢が正しくない理由は以下の通りです。
ローカルSSDを持つCompute Engine VMにSCMをデプロイし、プリエンプティブVMを有効にするという方法は、シークレットの安全な保管方法とは言えません。プリエンプティブVMは予告なく終了する可能性があり、その際データは消失します。対してCMEKで暗号化し、Cloud Storageに保管するという方法はシークレットを安全に管理できます。
参考リンク：
https://cloud.google.com/kms/docs/encrypt-decrypt
https://cloud.google.com/storage/docs/encryption/customer-managed-keys
https://cloud.google.com/solutions/secrets-management
</div></details>

### Q.  問題39: 未回答
個人情報保護チームは、個人を特定できる情報（PII）を削除する戦略として、クリプトシュレッダー（暗号化キーの削除）を使用しています。Google Cloudのサービスの大部分を利用し、運用のオーバーヘッドを最小限に抑えながら、この方法をGoogle Cloudに実装する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、既存のPII削除戦略をGoogle Cloud環境にどのように適応させるか考える必要があります。注目すべきは、"個人を特定できる情報（PII）を削除する戦略として、クリプトシュレッダー（暗号化キーの削除）を使用している"という制約と、"Google Cloudのサービスの大部分を利用し、運用のオーバーヘッドを最小限に抑える"という要求です。この2つの要素を同時に満たす解答を選択肢から選ぶことになります。
基本的な概念や原則：
Cloud External Key Manager（EKM）：Google Cloud上のデータを暗号化する際の鍵を保持・管理するためのサービスです。自分で鍵を保管し、必要なら削除することができ、データの暗号化・復号化の完全な制御が可能です。
顧客管理暗号化キー：Google Cloud上の情報の暗号化に使用される鍵を、ユーザー自身が管理するオプションです。キーの作成、使用、破棄等のフルコントロールが可能です。
鍵の削除（クリプトシュレッダー）：適切な暗号化がなされている状態で暗号化の鍵を削除することにより、元のデータにアクセス不可能にする安全手順です。個人を特定できる情報（PII）の保護に有効です。
Googleのデフォルト暗号化：Google Cloudでは、データはアップロード時に自動的に暗号化されます。デフォルトの暗号化は、Googleにより管理され、ユーザーは鍵の管理や破棄のオプションを持ちません。
クライアント側暗号化：ユーザーが自分で暗号化鍵を管理し、データをGoogle Cloudに送信する前に自分でデータを暗号化するオプションです。この方法では、鍵の管理や削除は全てユーザーから行われます。
正解についての説明：
（選択肢）
・特定の暗号化キーを削除するために、Cloud External Key Managerを使用します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud External Key Manager（EKM）は、顧客が自身の暗号化キーを制御し、Google Cloudのリソースを暗号化するために使用するサービスです。EKMはGoogle Cloudのサービスとシームレスに統合されており、運用のオーバーヘッドを最小限に抑えることができます。
また、EKMは特定の暗号化キーの削除も容易に行うことができます。
この削除操作は"クリプトシュレッダー"の戦略に対応しています。クリプトシュレッダーは暗号化キーの削除を利用してデータの削除を実現する手法で、キーを削除することで該当データの復号が不可能になり、実質的にデータが削除されることを意味します。
したがって、Cloud EKMを使用することで、個人を特定できる情報（PII）を削除する戦略に従いつつ、Google Cloudの利用を最大化し、運用のオーバーヘッドを最小限に抑えることができます。これが、この選択肢が正解となる理由です。
不正解についての説明：
選択肢：Google Cloudにデータを送信する前にクライアント側で暗号化を使用し、暗号化キーはオンプレミスで削除します
この選択肢が正しくない理由は以下の通りです。
クライアント側での暗号化と暗号化キーのオンプレミスでの削除は、Google Cloudのサービスを活用せず運用のオーバーヘッドが増大します。
一方、Cloud External Key Managerを使うと暗号化キーの管理や削除がGoogle Cloud上で行え、運用の負荷を最小限に抑えることができます。
選択肢：顧客管理暗号化キーを使用して、特定の暗号化キーを削除します
この選択肢が正しくない理由は以下の通りです。
顧客管理暗号化キーを使用して特定の暗号化キーを削除すると、それによって保護されていたデータが不完全になり、復元できなくなります。
一方、Cloud External Key Managerを使用すると、暗号化キーを外部から管理でき、必要に応じてキーを削除できるので、より柔軟に個人情報保護を実現できます。
選択肢：特定の暗号化キーを削除するために、Googleのデフォルト暗号化を使用します
この選択肢が正しくない理由は以下の通りです。
Googleのデフォルト暗号化は暗号化キーをユーザーが管理することはできないため、個別に暗号化キーを削除することは不可能です。Cloud External Key Managerを使用すると独自の暗号化キーを管理して、クリプトシュレッダーとして使用できます。
参考リンク：
https://cloud.google.com/kms/docs/external-key-managers
https://cloud.google.com/kms/docs/crypto-shredding
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題40: 未回答
ある組織が、特定のITワークロードのためにGoogle Cloudの利用を評価しています。ユーザーアイデンティティの管理とライフサイクル管理には、確立されたディレクトリサービスが使用されています。このディレクトリサービスは、組織がアイデンティティの"真実のソース"ディレクトリとして使用し続ける必要があります。
組織の要件を満たすソリューションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ある組織が既存のディレクトリサービスを用いてユーザーアイデンティティとライフサイクルを管理している状況を読み取ることが求められます。組織はそのディレクトリサービスを"真実のソース"として引き続き使用したいと望んでいます。その点を意識し、Google Cloud内で該当のディレクトリサービスと互換性があり、またそのディレクトリサービスを"真実のソース"として続けて利用できるソリューションを選択肢から選ぶ必要があります。
基本的な概念や原則：
Google Cloud Directory Sync（GCDS）：Google Cloudと組織の既存ディレクトリサービスを同期させるツールです。ユーザー、グループ、その他のデータを管理するための一元的な"真実のソース"を維持するのに役立ちます。
ディレクトリサービス：ネットワーク上のリソースやユーザー情報を管理するシステムです。Identity and Access Managementのための中心的な情報源として機能します。
"真実のソース"：ある種の情報の正確かつ信頼性の高いソースを指す用語です。データの一貫性と管理を保証するために、特にアイデンティティ管理では重要なロールを果たします。
Cloud Identity：Google CloudのIdentity and Access Management（IAM）サービスです。ユーザー、グループ、サービスアカウントを管理し、これらのアクセス権を制御します。
Security Assertion Markup Language（SAML）：アイデンティティプロバイダとサービスプロバイダ間で認証および承認データを交換するためのXMLベースのオープンスタンダードです。
Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。この利用によりアプリケーション間でメッセージを非同期に引き渡すことができます。
正解についての説明：
（選択肢）
・Google Cloud Directory Sync（GCDS）
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Directory Sync（GCDS）は、組織がすでに使用しているディレクトリサービスの内容をGoogle Cloudに同期するツールです。これにより、既存のディレクトリサービスを"真実のソース"として維持しながら、Google Cloudにユーザーやグループの情報を反映させることが可能です。GCDSを使用すれば、ユーザーアイデンティティとライフサイクル管理を一元的に制御し続けることができ、その結果、組織のITワークロードをGoogle Cloudに移行してもユーザー管理が煩雑になることを防ぐことができます。
また、GCDSは特定のタイミングや予定に基づいて自動的に同期を行うので、手動での作業負荷やヒューマンエラーを最小限に抑えることができます。
したがって、GCDSは既存のディレクトリサービスを活用しつつ、Google Cloudを効率的に導入するための優れたツールと言えます。
不正解についての説明：
選択肢：Cloud Identity
この選択肢が正しくない理由は以下の通りです。
Cloud Identityは、Google CloudのIdentity and Access Management（IAM）の原生的なソリューションですが、既存の"真実のソース"ディレクトリとの同期機能を提供しません。
逆に、Google Cloud Directory Sync（GCDS）を用いると、既存のディレクトリとGoogle CloudのIAMの間でユーザーやグループ情報を同期し、一元的な管理を実現できます。
選択肢：Security Assertion Markup Language（SAML）
この選択肢が正しくない理由は以下の通りです。
SAMLは、ディレクトリサービスのデータを同期させる機能を提供するものではなく、ユーザー認証情報を交換するための標準的なデータ形式であるため、このシナリオには適用できません。逆にGCDSはGoogle Cloudと既存のディレクトリサービス間でユーザーとグループの情報を同期します。
選択肢：Pub/Sub
この選択肢が正しくない理由は以下の通りです。
Pub/Subはメッセージングサービスであり、アイデンティティ管理やライフサイクル管理に関連する機能を提供していません。
一方、Google Cloud Directory SyncはオンプレミスのディレクトリサービスとGoogle Cloudの間でユーザーやグループ情報を同期するためのツールで、要件に適合します。
参考リンク：
https://cloud.google.com/identity/docs/sync
https://cloud.google.com/solutions/federating-Google Cloud-with-active-directory-introduction
</div></details>

### Q.  問題41: 未回答
あなたの会社のGoogle Cloudの組織には、約200のプロジェクトと1,500台の仮想マシンがあります。ログとイベントの管理に統一された戦略がないため、セキュリティ運用チームの可視性が低下しています。可視性を提供し、セキュリティチームが環境の構成を表示できるようにするログ管理ソリューションを設計する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、大規模なGoogle Cloudの組織内で統一されたログとイベント管理戦略を設計する方法を求められています。200のプロジェクトと1500台の仮想マシンがあるという情報から、それぞれのプロジェクトごとにログを管理すると非効率的であることが推測されます。したがって、全体を通じてログとイベントを統一的かつ効率的に管理するための戦略を考える必要があります。また、セキュリティチームが全体的な状況をみるためのアクセス権限、ログ管理のためのインフラ設計も重要な要素です。どのようなGoogle Cloudのサービスと権限を組み合わせると効果的にログとイベント管理が行えるかを考え、適切な選択肢を選びます。
基本的な概念や原則：
ログシンク：Google CloudのLoggingで使用され、ログエントリをエクスポートするための機能です。シンクは特定の種類のログを指定したCloud Storage、BigQuery、Pub/Subへエクスポートします。
組織レベル設定：Google Cloudのリソース階層の最上位を組織とし、その下にフォルダ、プロジェクト、リソースが配置されます。組織レベルでの設定は全プロジェクトやリソースに影響を与えます。
Pub/Sub：Google Cloudのリアルタイムメッセージングサービスで、アプリケーション間でメッセージを公開、購読することができます。エクスポート先としてログシンクに利用可能です。
セキュリティ情報およびイベント管理（SIEM）：セキュリティログやイベントデータを集約し分析を行うためのソフトウェアやサービスです。セキュリティ運用の視点から状況認識や応答を向上させます。
BigQuery：Google Cloudのサーバーレスかつスケーラブルなデータウェアハウスです。SQLによるデータ分析が可能で、ログの長期保存や分析に使用します。
Viewerロール：Google Cloud IAMで定義されるロールの一つで、特定のリソースに対するリードオンリーアクセスを付与します。組織やプロジェクトなどのリソースに対し閲覧権限をセキュリティ運用チームに付与する際に使用します。
正解についての説明：
（選択肢）
・1. すべての子リソースを含むログシンクを組織レベルで1つ作成します
2. Pub/Subトピックを宛先として使用して、ログをオンプレミスのセキュリティ情報およびイベント管理（SIEM）に取り込み、適切なチームがSIEMにアクセスできるようにします
3. 組織レベルでのViewerロールをセキュリティ運用チームに付与します
この選択肢が正解の理由は以下の通りです。
まず、選択肢では組織全体に対するログシンクの作成を提案しています。これにより、すべての子リソースからのログを一元的に収集し、セキュリティに関する一貫した視点を提供することが可能になります。
次に、Pub/Subトピックを用いたログの取り込みにより、オンプレミスのSIEMにログを送信できます。これは、すでに存在するシステムへの統合を可能にし、既存のプロセスを大きく変更することなくセキュリティの洞察を得られるようにするためです。
最後に、組織レベルでのViewerロールをセキュリティ運用チームに付与することで、深堀り調査や必要な情報へのアクセスを可能にし、全体的なセキュリティポスチャの透明性と理解を強化します。この3つのステップにより、選択肢は組織のセキュリティポスチャの可視性を向上させ、セキュリティ運用チームがより効果的に機能するための道筋となります。
不正解についての説明：
選択肢：1. スコープ内のプロジェクトごとに専用のログシンクを作成します
2. タイムパーティショニングが有効になっているBigQueryデータセットをログシンクの宛先として使用します
3. すべてのプロジェクトのログメトリクスに基づいてアラートを展開します
4. 各プロジェクトのセキュリティ運用チームにMonitoring Viewerロールを付与します
この選択肢が正しくない理由は以下の通りです。
一つ目の理由として、プロジェクトごとに専用ログシンクを作成するのではなく、組織レベルでログシンクを作成することにより、より一貫性のあるログ管理を可能にします。二つ目、BigQueryデータセットを直接ログシンクの宛先と使用するのではなく、Pub/Subトピックを間に挟んでログを送信する方がセキュリティチームの視認性を高めます。
そして最後に、Viewerロールは組織レベルで付与することが推奨されており、それぞれのプロジェクトに対して別々にロールを付与することは過度な管理作業となります。
選択肢：1. "Production"フォルダー内のすべてのリソースのネットワークログとデータアクセスログを有効にします
2. 不必要なコストと待ち時間を避けるために、ログシンクを作成しないでください3. プロジェクトレベルで"Logs Viewer"および"Browser"のロールをセキュリティ運用チームに付与します
この選択肢が正しくない理由は以下の通りです。
まず、全体の可視性を得るためには組織レベルでのログシンクの作成が必要で、"Production" フォルダーだけに制限すると全体の概観が失われます。
また、ロールの付与も組織レベルでViewerを付与するのが最適で、プロジェクトレベルでは不十分です。
最後に、ログシンクを作成しないとログを一元管理できず、必要な情報が散逸してしまいます。
選択肢：1. 子リソースを含む"Production"フォルダー用に1つのシンクを作成し、子リソースを除外する組織レベルで取り込まれたログ用に1つのシンクを作成します
2. 宛先として、セキュリティチームがアクセスできるプロジェクト内の最小保存期間が90日のログバケットを使用します
3. セキュリティ運用チームに組織レベルでのSecurity Reviewerロールを付与します
この選択肢が正しくない理由は以下の通りです。
まず、"Production"フォルダーのシンクと組織レベルのシンクを分割すると、管理が複雑になるだけでなく、全体像の可視性が低下します。
また、本番環境と非本番環境の区別はセキュリティ上必ずしも適切でないかもしれません。
さらに、最小保存期間が90日のログバケットを使用することで、長期保存や詳細な分析の観点から見て限定的となります。最後にSecurity Reviewerロールでは、ログへのアクセス許可がSufficientでない場合があります。これらに比べ、正解の選択肢は、よりシンプルで包括的な戦略を提供します。
参考リンク：
https://cloud.google.com/logging/docs/audit/configure-data-sources
https://cloud.google.com/logging/docs/solutions/siem-integration
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題42: 未回答
組織のオンプレミスネットワークを既存のGoogle Cloud環境に接続する必要があります。この環境には、ProductionとNon-Productionという2つのサブネットを持つ1つのShared VPCが含まれています。また、次のような要件があります：
- プライベートトランスポートリンクを使用します。
- オンプレミス環境を起点とするプライベートAPIエンドポイントを介したGoogle Cloud APIへのアクセスを設定します。
- Google Cloud APIがVPC Service Controls経由でのみ消費されるようにします。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミスネットワークとGoogle Cloud環境を接続する必要があり、そのときの要件としてプライベートトランスポートリンクの使用、オンプレミス環境を起点とするGoogle Cloud APIへのプライベートアクセスの設定、Google Cloud APIがVPC Service Controls経由でのみ利用されることが求められています。これらの要件を満たすためには、オンプレミスとGoogle Cloud間の接続方法とDNS設定が重要になります。また、選択肢の中には似たようなオプションもあるので、それぞれの違いと、求められている具体的な要件を満たすものが何かを正しく理解することが必要です。
基本的な概念や原則：
Dedicated Interconnect：Google Cloudとオンプレミスのネットワークとの間で専用のリンクを提供し、大量のデータを転送するのに有用なサービスです。
Cloud VPN：Google Cloudとオンプレミスのネットワークとの間にVPN接続を確立し、安全なデータ転送を可能にするサービスです。
Partner Interconnect：Google Cloudとオンプレミスのネットワークとの間でパートナーが提供するネットワーク接続を通じてリンクを提供するサービスです。
Direct Peering：Google Cloudと他のネットワーク間で直接的なピアリング接続を提供するサービスです。
DNS設定：ドメイン名とIPアドレスの対応を管理し、ネットワーク上での名前解決を行う設定です。
restricted.googleapis.com：Google Cloud APIエンドポイントの一つで、プライベートGoogleアクセスのDNS名です。
VPC Service Controls：Google Cloud上のサービスに対するデータ漏えいのリスクを制御するためのサービスです。これにより、指定したVPCの境界内でのみGoogle Cloud APIが利用できるように設定できます。
正解についての説明：
（選択肢）
・1.オンプレミス環境とGoogle Cloudの間にDedicated Interconnectリンクを設定します
2.オンプレミスのDNS設定でrestricted.googleapis.comドメインを使用してプライベートアクセスを設定します
この選択肢が正解の理由は以下の通りです。
まず、Dedicated Interconnectリンクを設定することで、オンプレミス環境とGoogle Cloud環境をプライベートトランスポートリンクを使用して接続することが可能になります。これにより、パブリックインターネットを経由せずに安全に通信することが可能となります。
また、オンプレミス環境からGoogle Cloud APIへのアクセスをプライベートAPIエンドポイントを介して設定するためには、オンプレミスのDNS設定で"restricted.googleapis.com"ドメインを使用します。これにより、VPC Service Controls経由でのみGoogle Cloud APIにアクセスすることが可能になります。これは、Google Cloud APIが公演インターネットから公開されず、オンプレミス環境からプライベートトランスポートリンクを経由したアクセスのみが許可されるようにするためです。
したがって、この設定をする事で、要件を達成することが可能です。
不正解についての説明：
選択肢：1.オンプレミス環境とGoogle Cloudの間にCloud VPNリンクを設定します
2.オンプレミスのDNS設定でrestricted.googleapis.comドメインを使用してプライベートアクセスを設定します
この選択肢が正しくない理由は以下の通りです。
Cloud VPNを使用すると、確かにオンプレミスネットワークとGoogle Cloudの間でプライベート接続を提供できますが、ユースケースの要件である"プライベートトランスポートリンクを使用する"を満たさないためです。この要件は、Dedicated Interconnectを用いることで満たされますが、Cloud VPNでは満たされません。
選択肢：1.オンプレミス環境とGoogle Cloudの間にPartner Interconnectリンクを設定します
2.オンプレミスのDNS設定でprivate.googleapis.comドメインを使用してプライベートアクセスを設定します
この選択肢が正しくない理由は以下の通りです。
まず、private.googleapis.comではなくrestricted.googleapis.comを使用する必要があります。それが正しいドメイン名で、直接のGoogle Cloud APIへのアクセスを提供します。
また、Partner InterconnectとDedicated Interconnectの間の主な違いは接続タイプで、要件ではプライベートトランスポートリンクが必要とされていますが、Partner Interconnectはサードパーティを介するためプライベートの要件を満たしません。
選択肢：1.オンプレミス環境とGoogle Cloudの間にDirect Peeringリンクを設定します
2.両方のVPCサブネットにプライベートアクセスを設定します
この選択肢が正しくない理由は以下の通りです。
Direct Peeringリンクはプライベートトランスポートリンクではありません、Dedicated Interconnectリンクの方が該当します。
そして、DNS設定を変更せずに両方のVPCサブネットにプライベートアクセスを設定するだけでは、オンプレ環境からのプライベートAPIエンドポイントを介したGoogle Cloud APIへのアクセスは実現できません。
参考リンク：
https://cloud.google.com/network-connectivity/docs/interconnect/concepts/dedicated-overview
https://cloud.google.com/vpc/docs/configure-private-google-access-hybrid
https://cloud.google.com/vpc-service-controls/docs/private-connectivity
</div></details>

### Q.  問題43: 未回答
ある顧客が他社と共同でCompute Engine上にアプリケーションを構築しています。顧客は自社のGoogle Cloudの組織でアプリケーション層を構築し、他社は別のGoogle Cloudの組織でストレージ層を構築しています。これは3層のウェブアプリケーションです。アプリケーションの各部分間の通信は、どのような通信経路であっても公共のインターネットを通過してはなりません。
どの接続オプションを実装すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題は、Google Cloudの接続オプションに対する理解度を試している問題です。顧客と提携企業がそれぞれ異なるGoogle Cloudの組織でアプリケーションとストレージを構築している事実と、アプリケーション間の通信が公共インターネットを通過してはいけないという要件に注目してください。これらの要件を満たし、またGoogle Cloudの接続オプションが何を可能にするのかを理解することが求められます。
基本的な概念や原則：
VPCピアリング：異なるGoogle Cloudプロジェクト間や異なる組織間のVPCネットワークを接続するためのサービスです。公共のインターネットを経由せずに、他のネットワークへ安全に接続することが可能です。
Cloud VPN：公共インターネット上で暗号化された通信トンネルを確立するサービスです。使用すると、他のクラウドプロバイダーやオンプレミスネットワークとの間でセキュアな接続が可能となりますが、公共のインターネットを経由します。
Cloud Interconnect：Google Cloudとオンプレミスインフラや他のクラウドサービスとの間で高速な専用接続を提供するサービスです。しかし公共のインターネットを経由します。
共有VPC：複数のGoogle Cloudプロジェクト間で一つのVPCネットワークを共有するための設定です。リソースを一元管理し、ネットワーク管理を効率化することが可能です。しかし、異なる組織間の接続には使用できません。
正解についての説明：
（選択肢）
・VPCピアリング
この選択肢が正解の理由は以下の通りです。
VPCピアリングを使用すると、別々のGoogle Cloudの組織に存在するネットワーク間で通信が可能になります。この通信は完全にプライベートネットワーク内で行われ、公共のインターネットを介さずに行われます。そのため、これは問題において必要とされる条件を満たします。
また、VPCピアリングは低レイテンシでの通信を可能にし、ネットワーク間の帯域幅を最大限に活用します。これは、3層のウェブアプリケーションにおいて、アプリケーション層とストレージ層の間での高速な通信が必要となるため重要であり、VPCピアリングが最適な選択肢となります。
不正解についての説明：
選択肢：Cloud VPN
この選択肢が正しくない理由は以下の通りです。
Cloud VPNはインターネット上で暗号化されたトンネルを通じて通信が行われるため、公共のインターネットを通過してしまいます。これは問題文の要件では認められていません。
一方、VPCピアリングはネットワーク間の直接的な接続を可能にし、公共のインターネットを通過することなく通信が可能です。よって、不正解の選択肢は問題の要件に適合していません。
選択肢：Cloud Interconnect
この選択肢が正しくない理由は以下の通りです。
Cloud Interconnectは、オンプレミスとGoogle Cloud間の接続を提供し、公共のインターネットを経由せずに通信できますが、このケースは二つのGoogle Cloudの組織間の接続が求められています。
それに対し、VPCピアリングは二つのGoogle Cloudプロジェクト間のネットワーク接続を提供します。
選択肢：共有VPC
この選択肢が正しくない理由は以下の通りです。
共有VPCはFacebook社と同一のGoogle Cloudの組織内で複数のプロジェクトが同一のVPCネットワークを利用するための機能であり、別のGoogle Cloudの組織との間で利用することはできません。しかし、VPCピアリングは異なる組織間でも接続が可能で公共インターネットを回避できるため、要件を満たします。
参考リンク：
https://cloud.google.com/vpc/docs/vpc-peering
https://cloud.google.com/network-connectivity/docs/vpc-peering/how-to/setting-up-vpc-peering
https://cloud.google.com/architecture/building-internet-connectivity-for-private-vms
</div></details>

### Q.  問題44: 未回答
組織のCloud Storageバケットで、インターネットにデータを公開できないようにしたいと考えています。これをすべてのCloud Storageバケットに適用したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud Storageのセキュリティ設定について評価する必要があります。組織全体でCloud Storageバケットからのデータの公開を防ぐための適切な方法を見つけることが求められています。これを解くためには、Cloud IAMのロールと権限、組織ポリシー、そしてそれらがCloud Storageの公開にどのように影響するかについての知識が不可欠です。選択肢を評価する際には、Google Cloudの各サービスがどのように機能し、どのように連携するかを理解していることが重要です。
基本的な概念や原則：
Cloud Storageバケット：Google Cloudのオブジェクトストレージサービスのバケットです。データを高い可用性と信頼性で保存することができます。
組織ポリシー：Google Cloudのリソース上で策定できる一連のポリシーです。特定の制約に対して値を設定し、各リソースに適用することができます。
ドメイン制限共有：Googleのサービスを使用してデータを共有する際に使用される特定のドメインに制限を設ける方法です。データの公開範囲を組織内に限定できます。
Ownerロール：特定のリソースを所有し、何でもできる権限を持つロールです。オーナーはリソースの設定、削除、課金を含むすべての操作を実行することができます。
IAM（Identity and Access Management）ポリシー：Google Cloud上のリソースへのアクセスをコントロールするためのフレームワークです。IAMロールとメンバーを組み合わせて、誰がどの操作を行えるかを定義します。
*.setIamPolicyパーミッション：IAMポリシーを設定するための権限です。この権限があると、ユーザーはリソースのIAMポリシーを変更して、アクセス権限を付与、変更、または削除することができます。
正解についての説明：
（選択肢）
・エンドユーザーからOwnerロールを削除し、組織ポリシーでドメイン制限共有を実施します
この選択肢が正解の理由は以下の通りです。
まず、適切な組織ポリシーを設定することによって、全てのCloud Storageバケットに対する一律のコントロールつまり組織全体のリソースに対する許可や制約などを一元的に制御することが可能となります。ドメイン制限共有という組織ポリシーは、指定したドメイン内のメンバーのみがリソースにアクセスできるように制限するものであり、これによりインターネットへの不適切なデータ公開を防ぐことができます。
さらに、エンドユーザーからOwnerロールを削除することで、個々のエンドユーザーが自身が所有するバケットのアクセス制御を一定以下に設定することを防ぎます。特にOwnerロールはリソースのフルコントロールを持つため、そのロールを持つユーザーが個々のバケットで公開設定を行うことができてしまいますが、このロールを削除することでエンドユーザーが一人でデータを公開することを防ぐことができます。
以上の理由から、この選択肢が適切な解答となります。
不正解についての説明：
選択肢：エンドユーザーからOwnerロールを削除し、Cloud Data Loss Preventionを構成します
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Preventionはデータを検査し、機密性のある情報を自動的に検出、分類、保護するサービスであり、インターネットへの公開を制御する機能はありません。
これに対し、ドメイン制限共有を行うと、指定したドメインのユーザーしかアクセスできなくなり、要件を満たします。
選択肢：統一されたバケットレベルのアクセスを設定し、組織ポリシーでドメイン制限された共有を実施します
この選択肢が正しくない理由は以下の通りです。
統一されたバケットレベルのアクセス設定はアクセス許可の管理を容易にするもので、特定のユーザーのパーミッションを削除する機能を提供しません。このため、公開設定を防止するための解決策となりません。
それに対して、正解の選択肢の"エンドユーザーからOwnerロールを削除"は直接的に公開権限を制御します。
選択肢：すべてのロールから*.setIamPolicyパーミッションを削除し、組織ポリシーでドメイン制限共有を強制します
この選択肢が正しくない理由は以下の通りです。
*.setIamPolicyパーミッションをすべてのロールから削除すると、全てのIAMポリシーの変更が不可能となります。これはシステムの運用管理を困難にし、過度な措置となります。
一方、Ownerロールをエンドユーザーから削除しドメイン制限共有を行う方策は、データ公開の制御と適切なシステム運用を両立します。
参考リンク：
https://cloud.google.com/storage/docs/using-bucket-policies
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題45: 未回答
ある組織が、インフラをオンプレミス環境からGoogle Cloudに移行し始めています。まず、現在のデータバックアップとディザスタリカバリのソリューションをGoogle Cloudに移行したいと考えています。この組織の本番環境は、今のところ無期限でオンプレミスのままにする予定です。組織は拡張性とコスト効率の高いソリューションを求めています。
どのGoogle Cloudソリューションを使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミス環境からGoogle Cloudにインフラを移行し、特にデータバックアップとディザスタリカバリのソリューションについて考慮している組織のシナリオを扱っています。重要な点は、オンプレミスの本番環境が維持される一方で、ソリューションは拡張性とコスト効率を求めているという部分です。選択肢を検討する際には、これらの要件を満たすという観点から最適なソリューションを選びましょう。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データバックアップやディザスタリカバリー、アーカイブなどに利用されます。高い拡張性とコスト効率を備えています。
gsutil：Google Cloud Storageに対するコマンドラインインターフェースです。データのアップロードやダウンロード、バケットの管理などが可能です。
スケジュールタスク：定期的に特定の作業を実行するためのタスクです。これを利用することで、定期的なバックアップやデータ転送などの作業を自動化できます。
BigQuery：Google Cloudの大規模データ分析サービスです。データ分析のためのデータウェアハウスとして使用されます。
Compute Engine：Google Cloud上で仮想マシンを実行するためのサービスです。ウェブサーバ、データベースサーバなどのインフラを構築します。
Cloud Datastore：NoSQLドキュメントデータベースを提供するマネージドサービスです。Web、モバイルアプリケーションのバックエンドに使用されます。
正解についての説明：
（選択肢）
・スケジュールタスクとgsutilを使ったCloud Storage
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageは、アクセス頻度に応じて最適な価格を提供する強力で柔軟性のあるストレージオプションを提供します。データアーカイブやバックアップストレージなど、さまざまなユースケースに対応しており、コスト効率の高いソリューションを提供できます。
また、アクティブなインターネット接続があればどこからでもアクセスすることができ、高可用性という特性も持っています。
また、gsutilはGoogle Cloud Storageとインタラクトするためのコマンドラインツールで、データをGoogle Cloud Storageバケットに無効化し、BashのようなシェルスクリプトまたはCronのようなタスクスケジューラと組み合わせることで、定期的なバックアップや災害復旧のスクリプトを簡単に作成することが可能です。
この組織がオンプレミス環境のままにすることを考えると、gsutilとスケジュールタスクを使ったCloud Storageは、バックアップと災害復旧のソリューションとして最適です。
不正解についての説明：
選択肢：継続的な更新を伴うデータパイプラインジョブを使用したBigQuery
この選択肢が正しくない理由は以下の通りです。
BigQueryは大量のデータを解析するためのサービスであり、バックアップやディザスタリカバリのソリューションとしては不適切です。
一方、Cloud Storageはデータの保存やバックアップに適しており、スケジュールタスクとgsutilを使えば自動化したバックアップが可能になります。
選択肢：永続ディスクを使用するCompute Engine仮想マシン
この選択肢が正しくない理由は以下の通りです。
Compute Engineの仮想マシンの永続ディスクを使用すると、必要な容量に応じたハードウェアが必要となり、拡張性とコスト効率が低下します。
一方、Cloud Storageはオブジェクトストレージサービスで、データのバックアップとディザスターリカバリに対して拡張性とコスト効率の高さを提供します。
選択肢：定期的にスケジュールされたバッチアップロードジョブを使用したCloud Datastore
この選択肢が正しくない理由は以下の通りです。
Cloud DatastoreはNoSQLデータベースサービスであり、一般的なデータバックアップとディザスタリカバリの目的にはフィットしません。
それに対して、Cloud Storageは大容量のデータを保存することが可能で、スケジュールタスクとgsutilを組み合わせてバックアップやディザスタリカバリに利用できます。
参考リンク：
https://cloud.google.com/storage/docs/uploading-objects
https://cloud.google.com/storage/docs/creating-buckets
https://cloud.google.com/storage/docs/lifecycle#gsutil
</div></details>

### Q.  問題46: 未回答
あなたは、Compute Engine上で実行されるアプリケーションから機密設定データを保存し、取得するためのソリューションを推奨するよう求められています。
この場合、どのオプションが推奨されますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute Engine上の機密情報の取り扱いについて理解することが必要です。特定のCompute Engineアプリケーションから機密設定データを保存・取得するために、どのサービスが最適なのかを判断する力が問われています。各選択肢はそれぞれ異なる用途で使用されるため、機密設定データをどのように管理するべきか、個別のサービスの特性を把握しておくことが重要です。また、全体的なセキュリティの観点からも適切なサービスを選択することが求められます。
基本的な概念や原則：
Secret Manager：Google Cloudの秘密管理サービスです。APIキーやパスワード、設定データなどの秘密情報を安全に保存し、アクセス制御を行うことができます。
Cloud Key Management Service：Google Cloudで暗号化キーを生成、使用、管理するサービスです。Google Cloudの各種サービスと連携し、データの暗号化を助けます。
Compute Engineのゲスト属性：Compute Engineインスタンスに対して設定可能なキーと値のペアの情報です。一度設定した値は、変更や削除ができません。
Compute Engineのカスタムメタデータ：Compute Engineインスタンスのメタデータの一種で、ユーザーが自由に設定できる情報です。この情報は、インスタンスやプロジェクト全体で共有され、設定の柔軟性を提供します。
正解についての説明：
（選択肢）
・Secret Manager
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのSecret Managerは、アプリケーションが必要とする機密設定データ、例えばAPIキー、パスワード、証明書などを管理するための安全で強固な仕組みを提供します。これらの情報はセキュアな方法で保存され、扱う際のセキュリティリスクを大幅に軽減します。Secret Managerは、アクセスポリシーを介したきめ細かなアクセス制御を提供し、アクセスログを自動的に生成します。これにより、誰がいつどの設定データにアクセスしたかが把握できます。
また、Compute Engine上で実行されるアプリケーションから容易にアクセスでき、認証やアクセス制御の手間を省くことができます。これらの特性により、機密設定データを安全に保管し、管理するためにSecret Managerが適切な選択であると言えます。
不正解についての説明：
選択肢：Cloud Key Management Service
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Serviceは暗号鍵の作成、使用、管理を目的としたサービスですが、設定データの保存・取得という目的には適していません。
一方、Secret Managerは機密情報を管理し、アプリケーションからその情報を安全に取得できるよう設計されています。
選択肢：Compute Engineのゲスト属性
この選択肢が正しくない理由は以下の通りです。
Compute Engineのゲスト属性はインスタンスに付随するメタデータを保存する機能ですが、これは機密情報の管理・保管を目的としたものではないため、適切ではありません。
それに対して、Secret Managerは機密情報の保存、取得を安全に管理するための専用のサービスです。
選択肢：Compute Engineのカスタムメタデータ
この選択肢が正しくない理由は以下の通りです。
Compute Engineのカスタムメタデータでは、データのセキュリティが強固に保たれません。誤った設定により全てのVMインスタンスからメタデータがアクセス可能になる可能性があります。
一方、Secret Managerは機密データを安全に管理するための専用サービスであり、アクセス制御が可能であるため、セキュリティを確保しながら機密設定データを保存、取得するには適しています。
参考リンク：
https://cloud.google.com/secret-manager/docs
https://cloud.google.com/kms/docs
https://cloud.google.com/compute/docs/storing-retrieving-metadata
</div></details>

### Q.  問題47: 未回答
あなたの組織は、サードパーティ企業のCompute Engineインスタンス上で動作する金融サービスアプリケーションをホストしています。アプリケーションを使用するサードパーティ企業のサーバーも、別のGoogle Cloudの組織のCompute Engine上で実行されています。Compute Engineインスタンス間のセキュアなネットワーク接続を構成する必要があります。構成にあたっては、次の要件があります：
- ネットワーク接続が暗号化されている必要があります。
- サーバー間の通信は、プライベートIPアドレスを使用する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題は、Google Cloud Compute Engine上で動作する異なる組織間でのセキュアなネットワーク接続の設定方法について問われています。要件として、ネットワーク接続の暗号化とプライベートIPアドレスの使用が必要であることが明示されています。以下にあげる選択肢から最適なものを選び、必要な構成を行います。VPCファイアウォールルールによって制御されるネットワーク接続、VPCピアリングの設定、VPC Service Controlsの境界設定、あるいはApigeeプロキシの設定等が考えられます。正解を選ぶためには、各選択肢がどのような機能を持ち、それが問題の要件を満たすか否かを理解することが重要です。
基本的な概念や原則：
VPC（Virtual Private Cloud）：Google Cloud上でプライベートな仮想ネットワークを作成し、そのネットワーク上でCompute Engineインスタンスなどを稼働させるためのサービスです。専用のIPアドレス範囲を持ち、自由に構成を設定できます。
Cloud VPN：Google Cloud上で仮想プライベートネットワーク（VPN）接続を作成するためのサービスです。VPN接続を使用すると、Google Cloudと他のネットワークをセキュアに接続することができます。通信は暗号化され、プライベートIPアドレスで行うことができます。
VPCファイアウォールルール：Google Cloud VPC内のリソースへのネットワークアクセスを制御するためのルールです。特定のネットワークトラフィックを許可または拒否できます。
VPCピアリング：2つのVPCネットワーク間を直接接続できるネットワークサービスです。通信はプライベートIPアドレスで行われ、ネットワーク遅延が少ないですが、通信は暗号化されません。
VPC Service Controls：Google Cloudサービスへのデータアクセスを管理および制限するツールです。しかし、Compute Engineインスタンス間のネットワーク通信の管理や暗号化には直接影響はありません。
Apigee：Google CloudのAPI管理プラットフォームです。APIに対するトラフィック管理、APIセキュリティ、APIモニタリングなどの機能を提供しますが、Compute Engineインスタンス間のセキュアなネットワーク接続の設定には直接利用できません。
正解についての説明：
（選択肢）
・VPCファイアウォールルールによって制御される、組織のVPCネットワークとサードパーティーのVPCネットワーク間のCloud VPN接続を構成します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのVPC（Virtual Private Cloud）ネットワークは、Compute Engineインスタンス間でプライベートIPアドレスを使用して通信を行うことを可能にします。これにより、サーバー間通信のプライベートIPアドレス使用の要件が満たされます。
次に、Cloud VPNはVPC間の安全な通信チャネルを提供するサービスで、IPSecプロトコルを使用してネットワークの通信を暗号化します。これにより、ネットワーク接続が暗号化される要件も満たされます。
最後に、VPCファイアウォールルールを用いて、VPCネットワーク間の通信の許可や拒否の制御が可能です。これにより、必要とされる安全なネットワーク接続を確保することができます。
したがって、正解はVPCファイアウォールルール制御の下でのCloud VPN接続の設定です。これにより、必要要件のすべてが満たされます。
不正解についての説明：
選択肢：組織のVPCネットワークとVPCファイアウォールルールで制御されるサードパーティーのVPCピアリング接続を設定します
この選択肢が正しくない理由は以下の通りです。
VPCピアリング接続は通信を暗号化しないため、要件に適合しません。
一方、Cloud VPN接続は通信を暗号化するため、こちらが適切な解決策です。VPCピアリングは、プライベートIPアドレスでの通信は可能ですが、暗号化という重要な要件を満たせないため不適切です。
選択肢：Compute Engineインスタンスの周囲にVPC Service Controlsの境界を設定し、アクセスレベルを介してサードパーティにアクセスを提供します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsはデータ漏洩を防ぐためのサービスで、特定のVPCリソースへのアクセスを管理しますが、Compute Engineインスタンス間の暗号化されたネットワーク接続の構成やプライベートIPアドレスを使用した通信の実現には向いていません。これらの要件はCloud VPN接続を通じて達成できます。
選択肢：Compute EngineがホストするアプリケーションをAPIとして公開するApigeeプロキシを設定し、TLSで暗号化することで、サードパーティのみにアクセスを許可します
この選択肢が正しくない理由は以下の通りです。
ApigeeプロキシはAPIのトラフィックを管理することが目的であり、Compute Engineインスタンス間のプライベートなネットワーク接続の設定には適していません。この要件は、VPCネットワーク間のCloud VPN接続が最適で、暗号化通信とプライベートIPアドレスの要件を満たします。
参考リンク：
https://cloud.google.com/vpn/docs/concepts/overview
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#secure_communications_between_vpcs
https://cloud.google.com/vpc/docs/vpc-peering
</div></details>

### Q.  問題48: 未回答
あなたの会社はCompute Engine上にアプリケーションをデプロイしました。このアプリケーションには、クライアントからポート587でアクセスできます。アプリケーションを実行している異なるインスタンス間で負荷分散する必要があります。接続はTLSを使ってセキュアにし、ロードバランサーで終了させる必要があります。
どのようなロードバランサーを使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute Engineで運用されるアプリケーションの負荷分散に適したロードバランサーの種類を問われています。アプリケーションは587番ポートで接続を受け付け、その接続はTLSによりセキュアに保たれるため、接続の終了も行うロードバランサーが要求されています。したがって、その仕様を満たすロードバランサーを選ぶ必要があります。
基本的な概念や原則：
SSLプロキシロードバランサー：非HTTP(S)のTLSトラフィックをバランシングするためのGoogle Cloudのロードバランサーです。サポートしているポート番号は25, 43, 110, 143, 195, 443, 465, 587, 700, 993, 995, 1883, 5222です。
ネットワークロードバランサー：Google Cloudのロードバランサーの一つで、TCP/UDPトラフィックをバランシングします。パフォーマンスや低レイテンシを要求するユースケースに適していますが、TLS終了はサポートしていません。
HTTP(S)ロードバランサー：Google Cloudのロードバランサーで、HTTP(S)トラフィックをグローバルまたはリージョナルにバランシングします。先進のルーティング、SSL/TLS終了、URLマップの機能を提供しますが、非HTTP(S)トラフィックはサポートしていません。
TCPプロキシロードバランサー：Google Cloudのロードバランサーで、TCPトラフィック（SSL/TLSを除く）をバランシングします。高スループットのワークロードに最適化されていますが、SSL/TLS終了はサポートしていません。
正解についての説明：
（選択肢）
・SSLプロキシロードバランサー
この選択肢が正解の理由は以下の通りです。
SSLプロキシロードバランサーは、特定のレイヤー7プロトコル（HTTPS、SSL）を対象としたロードバランシング機能を提供します。このケースでは、クライアントからポート587を通じて安全な通信が必要とされており、TLSを用いた暗号化が要求されています。SSLプロキシロードバランサーは、このようなセキュアな特定のトラフィック（ここでは、サーバのポート587を通じたトラフィック）をバランスを取りつつ透過的に転送する機能を持っています。
また、ロードバランサーで接続を終了させる要件にも対応しています。
したがって、クライアントからの接続を一定の規則で分散させ、定められたトラフィックを効率よくルーティングするためにSSLプロキシロードバランサーは適切な選択であると言えます。
不正解についての説明：
選択肢：ネットワークロードバランサー
この選択肢が正しくない理由は以下の通りです。
ネットワークロードバランサーはネットワークレイヤー（L3）で動作し、TLSの終了などのトランスポート層やアプリケーション層でのロードバランシングはサポートしていません。
それに対して、SSLプロキシロードバランサーはL7で動作し、要求されているTLSの終了を行うことができます。
選択肢：HTTP(S)ロードバランサー
この選択肢が正しくない理由は以下の通りです。
HTTP(S)ロードバランサーは通常、HTTPとHTTPSトラフィックを負荷分散しますがポート587はサポートされていません。しかし、問題ではアプリケーションがポート587でアクセス可能であり、更にTLSでの通信が必要なので、それらを満たすSSLプロキシロードバランサーが適しています。
選択肢：TCPプロキシロードバランサー
この選択肢が正しくない理由は以下の通りです。
TCPプロキシロードバランサーはTCPトラフィック（特定のポート）のみをバランスする能力がありますが、TLS接続の終了を行う機能は持っていません。
それに対して、SSLプロキシロードバランサーはSSL/TLSトラフィックの終了と負荷分散の両方を提供します。
参考リンク：
https://cloud.google.com/load-balancing/docs/ssl
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/compute/docs/load-balancing-and-autoscaling
</div></details>

### Q.  問題49: 未回答
プロダクションプロジェクトのために、チームのログを一元管理する必要があります。ログエクスプローラを使用して、ログを検索および分析できるようにする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、プロダクションプロジェクトのログを一元管理するための最適な方法について問われています。ログエクスプローラを使用し、ログを検索および分析できる手段を選択することが求められています。提示された選択肢の中から、一元的にログを管理し、検索可能かつ分析可能である解決策を選ぶことが重要です。また、選択肢の詳細を理解するために、Google Cloudのログ管理とログエクスプローラについての知識も必要となります。
基本的な概念や原則：
ログエクスプローラ：Google Cloud上の各種サービスから発生するログを一元的に管理し、分析するためのツールです。リアルタイムのログ表示や検索、フィルタリング機能を持ちます。
組織レベル：Google Cloudのリソース階層の最上位にあたるレベルです。組織全体を通じての政策設定やアクセス制御が可能です。
フィルタリング：特定の条件に基づいてデータを選択、除外するプロセスです。ログエクスプローラでは、ログを条件によって絞り込むことができます。
Cloud Monitoring：Google Cloudの状況監視やアラート通知を行うツールです。ワークスペースはCloud Monitoringの監視対象となるリソースのレベルを設定します。
集約組織シンク：複数のプロジェクトに跨るログ情報を一元的に収集、取り扱うための設定です。宛先としてCloud Storageまたはログバケットを選択可能です。
正解についての説明：
（選択肢）
・組織レベルでログエクスプローラを使用し、プロダクションプロジェクトのログをフィルタリングします
この選択肢が正解の理由は以下の通りです。
Google Cloudのログエクスプローラは各種プロジェクトのログを一元的に表示、検索、分析するためのツールです。組織レベルでログエクスプローラを使用すると、組織全体のすべてのプロジェクトに対するログデータを一元管理できます。言い換えれば、複数のプロジェクトにまたがるログデータを、まとめて取り扱うことができます。これは、チーム全体のログを一元管理し、検索および分析することを可能にします。
また、ログエクスプローラには強力なフィルタリング機能があります。これにより、特定のプロジェクトや特定の種類のログエントリに絞って検索や分析を行うことが可能となります。選択肢の通り、それを利用してプロダクションプロジェクトのログをフィルタリングすれば、そのプロジェクトに関連する重要な情報だけを抽出し、効率的に分析することができます。
不正解についての説明：
選択肢：Cloud Monitoringワークスペースを有効にし、監視対象のプロダクションプロジェクトを追加します
この選択肢が正しくない理由は以下の通りです。
Cloud Monitoringワークスペースは、メトリックスを分析し、アラートを設定するためのものであり、ログを一元管理するためには不適切です。
それに対し、組織レベルでログエクスプローラを使用すると、全プロジェクトのログを一元的に管理し、フィルタリングを通じて特定のプロジェクトのログを見ることができます。
選択肢：本番プロジェクトの親フォルダに集約組織シンクを作成し、保存先をCloud Storageバケットに設定します
この選択肢が正しくない理由は以下の通りです。
ログをCloud Storageに保存すると、ログエクスプローラを使って直接ログを検索・分析することができなくなります。
したがって、本番プロジェクトのログを直接検索・分析したい場合は、そのプロジェクトを直接選択してログエクスプローラを立ち上げる、または組織レベルでログエクスプローラを立ち上げ、プロジェクトをフィルタする必要があります。
選択肢：本番プロジェクトの親フォルダに集約組織シンクを作成し、宛先をログバケットに設定します
この選択肢が正しくない理由は以下の通りです。
ログシンクを親フォルダに設定し、ログバケットに集約するという選択肢はログの集約は可能ですが、ログエクスプローラの活用が要求されている課題に対して直接的な解決策にはなりません。
一方で、組織レベルでログエクスプローラを使用することで、直接的にログを検索、分析することが可能となり課題解決に適しています。
参考リンク：
https://cloud.google.com/logging/docs/explorer
https://cloud.google.com/logging/docs/aggregated-sinks
https://cloud.google.com/logging/docs/storage#log-entries-in-cloud-storage
</div></details>

### Q.  問題50: 未回答
あなたは会社のセキュリティチームのメンバーです。あなたは、すべてのパブリックIPアドレスを削除することで、Linuxベーストンホストの外部攻撃サーフェスを減らすよう依頼されています。サイト信頼性エンジニア（SRE）は、社外から内部VPCにアクセスできるように、パブリックロケーションから踏み台ホストにアクセスする必要があります。
このアクセスをどのように有効にすべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、公開IPアドレスを利用しないでサイト信頼性エンジニア（SRE）が社外から踏み台ホストにアクセスすることを可能にするソリューションが求められます。求められる解答は、パブリックインターネットを経由せずに安全な接続を確立できる方法で、かつSREが内部VPCにアクセスできるように設計されている必要があります。選択肢を見るときは、これらの要点とセキュリティチームの要求を満たすものを探すことを重視しなければなりません。
基本的な概念や原則：
ID-AwareプロキシTCP転送：Google CloudのIdentity-Aware Proxy（IAP）を使用して、踏み台ホストへのアクセスを管理し、効果的なセキュリティレイヤーを提供する機能です。公開IPアドレスを持つ踏み台ホストを介さずに、社外から内部VPCへの安全な接続を実現します。
Cloud VPN：Google CloudのVPNサービスで、パブリックインターネット経由でオンプレミスネットワークとGoogle Cloudネットワーク間の暗号化された接続を提供します。しかし、個々のホストへのアクセス制御は行えません。
2段階認証によるOSログイン：Google CloudのCompute Engineで、2段階認証を使用してVMインスタンスへのSSHログインを制御する機能です。しかし、これはパブリックIPアドレスを必要とします。
Google Cloud Armor：Google Cloudの分散型サービス拒否（DDoS）防御、Webアプリケーションファイアウォール（WAF）機能、およびリスク分析機能を提供するサービスです。しかし、これは特定のホストへの認証付きアクセスを提供するものではありません。
正解についての説明：
（選択肢）
・踏み台ホストにID-AwareプロキシTCP転送を実装します
この選択肢が正解の理由は以下の通りです。
まず、ID-AwareプロキシTCP転送を利用することで、パブリックIPアドレスを持たない内部のホストへと安全にアクセスすることが可能となります。これは、Google CloudのIdentity-Aware Proxy（IAP）の機能の一部で、外部からの踏み台ホストへのアクセスを安全に管理するための方法です。
次に、セキュリティチームの要求である"パブリックIPアドレスを削除する"という要件を満たすとともに、SREが社外から内部VPCにアクセスできるようにするというニーズも満たします。IAP TCP転送を用いると、認証と認可が行われたSREだけが必要なリソースにアクセスできるようになり、公開IPアドレスを完全に排除して、セキュリティを強化することが可能です。
したがって、これらの複数の要件を満たす方法として、ID-AwareプロキシTCP転送の実装が最適解と言えます。
不正解についての説明：
選択肢：踏み台ホストのあるリージョンにCloud VPNを導入します
この選択肢が正しくない理由は以下の通りです。
Cloud VPNを導入するとサイト間接続は確保できますが、個々のユーザーのアクセス制御は困難です。
一方、ID-AwareプロキシTCP転送を使用すれば、特定のユーザーにのみVPCへのアクセスを許可することが可能です。なので、ユーザー単位のアクセス制御を行うには、正解の選択肢が適しています。
選択肢：踏み台ホストに2段階認証によるOSログインを実装します
この選択肢が正しくない理由は以下の通りです。
２段階認証によるOSログインは、セキュリティレベルを高めますが、それ自体ではパブリックIPが存在しない場合に踏み台ホストへの接続を実現できません。
一方、ID-AwareプロキシTCP転送を実装することで、パブリックIPなしで踏み台ホストへ接続可能となります。
選択肢：Google Cloud Armorを踏み台ホストの前に実装します
この選択肢が正しくない理由は以下の通りです。
Google Cloud ArmorはDDoS攻撃の防止や脅威の軽減、特定のIPや地域からのトラフィックフィルタリング等、外部からの不正なトラフィックを防ぐことを目的としています。しかし、踏み台ホストへのアクセスを実現するためには、ID-AwareプロキシTCP転送を実装することで、認証されたユーザーのみがコントロールされた環境でサーバにアクセスできるよう設定することが求められています。
参考リンク：
https://cloud.google.com/iap/docs/using-tcp-forwarding
https://cloud.google.com/compute/docs/instances/connecting-advanced#identity_aware_proxy
https://cloud.google.com/architecture/identity/identify-access#identity-aware-proxy
</div></details>

## 3
### Q.  問題1: 未回答
あなたの会社はITインフラの大半をGoogle Cloudに移行する予定です。既存のオンプレミスActive DirectoryをGoogle CloudのIDプロバイダーとして活用したいと考えています。オンプレミスのActive DirectoryとGoogle Cloudを統合し、アクセス管理を構成するために取るべき2つの手順はどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudと既存のオンプレミスActive Directoryを統合し、アクセス管理を構成する方法について求められています。ここで重要な点は、既存のActive DirectoryをGoogle CloudのIDプロバイダーとして活用する予定であるという条件です。この情報から、Active DirectoryとGoogle Cloudを連携させるための適切なGoogle Cloudのサービスや機能を理解し、選択肢から正しいものを選び出すことが必要になります。とくにCloud Identity、Google Cloud Directory Sync、Identity Platform、IAMロールやIAMグループなど、それぞれのロールと機能を理解する上での注意が求められます。
基本的な概念や原則：
Active Directory：Microsoftのディレクトリサービスで、オブジェクト（ユーザーやグループなど）を組織化し、管理します。ネットワーク上でのアクセス制御やユーザー認証を実現します。
Cloud Identity SAML統合：Google Cloudのサービスです。既存のActive DirectoryやLDAPサーバーとCloud Identityを統合します。ユーザーやグループのプロビジョニングを実現します。
Google Cloud Directory Sync：Google Cloud用のディレクトリ同期ツールです。既存のActive DirectoryやLDAPサーバーの情報をGoogle Cloudに同期します。
Identity Platform：Google Cloudの認証サービスです。ユーザーのサインアップ、サインイン、アカウントリカバリーなどの機能を提供します。
IAMロール：Google Cloudのアクセス制御概念です。特定のユーザーやグループがリソースに対して許可される操作を定義します。そのため一般的にはロールの作成はActive Directoryグループの作成では補完できません。
IAMグループ：Google Cloudのアクセス制御のための概念です。特定のユーザーやサービスアカウントをグループ化し、共通の権限を付与することが可能です。しかし、Active Directoryグループを直接作成したり、対応づける機能はありません。
正解についての説明：
（選択肢）
・Cloud Identity SAML統合を使って、Google Cloudにユーザとグループをプロビジョニングします
・Google Cloud Directory Syncをインストールし、Active DirectoryおよびCloud Identityに接続します
この選択肢が正解の理由は以下の通りです。
まず、"Cloud Identity SAML統合を使って、Google Cloudにユーザとグループをプロビジョニングします"は、Active Directory（IDプロバイダー）とGoogle Cloudの統合を可能にします。SAML（Security Assertion Markup Language）は、異なるセキュリティドメイン間で認証と承認情報を交換するための標準プロトコルです。Cloud Identity SAML統合を利用することでオンプレミスのActive Directoryからクラウドに認証情報を安全に受け渡すことが可能となります。
また、"Google Cloud Directory Syncをインストールし、Active DirectoryおよびCloud Identityに接続します"は、オンプレミスのActive DirectoryとGoogle Cloudの間に同期を行うことを可能にします。これにより、オンプレミスのActive Directoryで行われた変更（ユーザの追加や削除など）がGoogle Cloudにも反映されるため、一元的かつ効率的なアクセス管理を実現することができます。これら２つの手順により、オンプレミスのActive DirectoryとGoogle Cloudを連携させ、アクセス管理を効率的に行うことが可能となります。
不正解についての説明：
選択肢：Identity Platformを使用して、ユーザーとグループをGoogle Cloudにプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
Identity Platformはフェデレーションされたアイデンティティ、ユーザ管理、認証を提供するもので、オンプレミスのActive Directoryと直接連携する機能は提供していません。
一方、Cloud IdentityやGoogle Cloud Directory SyncはActive Directoryとの連携をサポートしており、アクセス管理の構成に適しています。
選択肢：各Active Directoryグループに対応する権限を持つIAM（Identity and Access Management）ロールを作成します
この選択肢が正しくない理由は以下のとおりです。
まず、Active Directoryグループに対応するIAMロールを作成しても、それ自体ではオンプレミスのActive DirectoryとGoogle Cloudの統合に貢献せず、必要なアクセス管理を構成できません。
代わりに、Google Cloud Directory Syncを使用してActive DirectoryとCloud Identityを連携したり、Cloud Identity SAML統合を使用してユーザとグループをプロビジョニングする必要があります。
選択肢：各Active Directoryグループに対応する権限を持つIAM（Identity and Access Management）グループを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloudでは、IAMグループは存在せず、IAMロールが提供されるのみです。Active Directoryのグループと対応付けるためには、Cloud IdentityやGoogle Cloud Directory Syncのようなツールを使用してユーザーやグループを同期させるべきです。
参考リンク：
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-synchronizing-user-accounts
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-configuring-single-sign-on
https://support.google.com/a/answer/106368?hl=en
</div></details>

### Q.  問題2: 未回答
Google Cloudリソースへのアクセスを必要とするGoogle Cloud外のアプリケーションを実行しています。ワークロードIDフェデレーションを使用して、外部のIDにIdentity and Access Management（IAM）ロールを付与し、サービスアカウントキーに関連するメンテナンスとセキュリティの負担を軽減しています。別のユーザーのIDを偽装してGoogle Cloudリソースに不正にアクセスしようとする試みから保護する必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud外部のアプリケーションのGoogle Cloudリソースへのアクセス管理について考える必要があります。そして、IDフェデレーションという概念を理解し、これを使用して不正アクセスから保護する措置を選択することが求められています。選択肢を見る際には、特にセキュリティの観点から不適切なアクセスの防止策を選ぶ必要があります。また、全ての解答が適切なセキュリティ対策である可能性はありますが、問題の文脈に最も適したものを2つ選ぶよう求められている点にも注意が必要です。
基本的な概念や原則：
ワークロードIDフェデレーション：Google Cloudの外部のIDをGoogle Cloudの認証に連携させる機能です。IDフェデレーションを使用すると、ワークロードがGoogle Cloudリソースにアクセスするために必要な認証情報を自動的に取得できます。
Identity and Access Management（IAM）：ユーザーやサービスアカウントが何を行うことができるかを制御するGoogle Cloudのツールです。ロールとポリシーを設定してリソースへのアクセスを管理します。
サービスアカウント：アプリケーションがGoogle Cloudサービスと通信するために使用する特殊なアカウントです。サービスアカウントキーは、認証と認可のための情報を保持しています。
専用のプロジェクト：特定の目的やロールに専用されたGoogle Cloudプロジェクトです。効果的なリソース管理とセキュリティ維持に役立ちます。
属性マッピング：ユーザーアイデンティティの属性からGoogle Cloudのロールやポリシーにマッピングするプロセスです。不変属性を使用すると、IDの偽装を防ぐことができます。
正解についての説明：
（選択肢）
・ワークロードIDプールとプロバイダの管理には、専用のプロジェクトを使用します
・属性マッピングで不変属性を使用します
この選択肢が正解の理由は以下の通りです。
まず、ワークロードIDフェデレーションの環境を管理するために、専用のプロジェクトを使用することは、セキュリティ管理に有益です。専用のプロジェクトを使用することで、適切なアクセス制御を保持し、不正アクセスのリスクを軽減することができます。
また、IDフェデレーションを専用のプロジェクトで分離することで、誤って設定を変更したり、不適切なアクセス許可を付与するリスクを軽減することができます。
次に、属性マッピングで不変属性を使用することは、ユーザのIDが偽装されるのを防ぐ効果的な手段です。不変属性は、ユーザのライフサイクル全体で変更されない属性を指します。これらの属性を使用してユーザを一意に識別することで、偽装やアイデンティティの混乱を防ぐことができます。
また、これにより、ユーザのアクセス制御と追跡が容易になり、一貫性のあるセキュリティポリシーの適用を支援します。
不正解についての説明：
選択肢：IAM APIのデータアクセスログを有効にします
この選択肢が正しくない理由は以下の通りです。
IAM APIのデータアクセスログを有効にすることは、Google Cloudリソースへのアクセスのログを取得するためのもので、不正アクセスを防止する機能ではありません。
一方、専用のプロジェクトを使用すると、管理が一元化され詐称のリスクを減らします。
また、属性マッピングで不変属性を使用すると、ユーザーIDが偽装されるリスクを最小限に抑えられます。
選択肢：サービスアカウントになりすますことのできる外部IDの数を制限します
この選択肢が正しくない理由は以下の通りです。
サービスアカウントになりすますことのできる外部IDの数を制限することは、IDを偽装しての不正アクセスを防ぐための直接的な策ではありません。
一方、不変属性を利用することや専用のプロジェクトを使用することで、ID管理の一貫性とセキュリティを確保し、不正アクセスを防ぐことが可能です。
選択肢：サービスアカウントがアクセスできるリソースを制限します
この選択肢が正しくない理由は以下の通りです。
サービスアカウントがアクセスできるリソースを制限することは良いセキュリティ対策であるものの、それは別のユーザーのIDを偽装しての不正アクセスを防ぐ対策ではありません。ワークロードIDプールとプロバイダの管理に専用のプロジェクトを使うことや、属性マッピングで不変属性を使うことで、不正なユーザーの認証対策を行なうことが可能です。
参考リンク：
https://cloud.google.com/iam/docs/workload-identity-federation
https://cloud.google.com/iam/docs/configuring-workload-identity-federation
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題3: 未回答
既存のVPC Service Controlsの境界を新しいアクセスレベルで更新したいと考えています。この変更で既存の境界が壊れるのを避け、オーバーヘッドを最小限に抑えながら、ユーザーへの混乱を最小限に抑える必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、VPC Service Controlsの境界を新しいアクセスレベルで更新する方法について問われていますが、その際に既存の境界が壊れることを避けることと、オーバーヘッドやユーザーの混乱を最小限に抑えることが要求されています。したがって、有効な解決策は、新しい変更が本当に機能するかどうかを確認しながら、段階的かつコントロールされた方法でこれらの更新を行います。また、選択肢を評価する際には、既存の環境に影響を与えることなく、新しいアクセスレベルをテストできる選択肢を選ぶことが重要です。
基本的な概念や原則：
VPC Service Controls：Google Cloudのサービスに対するネットワーク内のアクセスを制御し、データがGoogle Cloudプロジェクトの境界を越えて漏れることを防ぐ稼働環境セキュリティ対策です。
境界ドライランモード：指定されたVPC Service Controlsの境界について、詳細な監査ログの生成を含めて制約をシミュレートするモードです。実際の影響を確認しながら安全に変更をテストするために使用します。
アクセスレベル：Google Cloud Identity-Aware Proxyの機能で、ユーザーやデバイスのコンテキスト情報（位置、IPアドレス、デバイスセキュリティステータスなど）に基づいてクラウドリソースへのアクセスを制御する設定です。
ネットワークセキュリティ：ネットワーク内のアクセスとデータの移動を制御し、不正なアクセスやデータ漏洩を防ぐ技術的な対策や管理的な対策のことです。
監査ログ：システムやネットワークの操作履歴などを記録した情報です。セキュリティ監視や問題解析、性能分析などに使用されます。
正解についての説明：
（選択肢）
・境界のドライランモードを有効にします。新しいアクセスレベルを境界ドライラン構成に追加します。アクセスレベルの検証後、境界の設定を更新します
この選択肢が正解の理由は以下の通りです。
まず、VPC Service Controlsのドライランモードを有効にすることにより、新しいアクセスレベルが境界に影響を与えるであろうシナリオを、境界自体を変更せずにシミュレートすることができます。ドライランモードでは、新しいアクセスレベルが実際のトラフィックに対してどのように影響を与えるかを予測し、意図しない遮断や設定の不一致を防ぐことができます。これにより、既存の境界が壊れることのリスクを最小限に抑えることが可能です。
また、この新しいアクセスレベルは境界のドライラン構成中に追加されます。この段階では、アクセスレベルは境界に対して影響を与えませんが、その効果を見積もることができるのです。そのため、問題が検出された場合には適切に修正できるよう、事前の点検や修正の機会が得られます。
このようなプロセスを経ることで、ユーザーへの混乱を最小限に抑えつつ、オーバーヘッドも最小限に抑えることができます。
また、新しいアクセスレベルが問題なく機能することを確認した後、安全に境界の設定を更新することができます。
不正解についての説明：
選択肢：既存の境界の完全なレプリカを作成します。レプリカに新しいアクセスレベルを追加します。アクセスレベルの検証後、元の境界を更新します
この選択肢が正しくない理由は以下の通りです。
既存の境界の完全なレプリカを作成すると、導入のオーバーヘッドと混乱が増加します。
それに対して、ドライランモードでは、実際の影響を与えずに新しいアクセスレベルの効果を確認でき、オーバーヘッドとユーザーの混乱を最小限に抑えます。
選択肢：既存の境界と決して一致しない新しいアクセスレベルで境界を更新します。過度に寛容にならないように、新しいアクセスレベルを一度に1つの条件ずつ、希望する状態に一致するように更新します
この選択肢が正しくない理由は以下の通りです。
新しいアクセスレベルを1つずつ追加する方法は、オーバーヘッドの増加と混乱の原因になります。
一方、ドライランモードを用いると既存の境界を破壊することなく新しい設定を検証でき、ユーザーへの影響を最小限に抑えることができます。
選択肢：境界のドライランモードを有効にします。新しいアクセスレベルを境界構成に追加します。アクセスレベルの検証後、境界設定を更新します
この選択肢が正しくない理由は以下の通りです。
新しいアクセスレベルを直接境界構成に追加すると、アクセスレベルの影響が即時に反映され、既存の境界が壊れたりユーザーに混乱を招く可能性があります。
一方、正解では新しいアクセスレベルを"境界ドライラン構成"に追加しているため、影響を評価し確認後に正式な設定を更新できます。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/update-perimeter
https://cloud.google.com/access-context-manager/docs/manage-access-levels
https://cloud.google.com/vpc-service-controls/docs/dry-run-mode
</div></details>

### Q.  問題4: 未回答
あなたの組織は最近Security Command Center（SCC）の標準階層を有効にしました。しかしその後、いくつかのCloud Storageバケットが誤って一般公開されました。インシデントの影響を調査し、修復する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、公開されてしまったCloud Storageバケットの影響調査と再発防止に関してどのように対処すべきかが求められています。問題のポイントは公開されたバケットへのアクセスを制限し、それを維持することと、再発防止措置を講じることです。適切な組織のポリシーを適応し、不適切なアクセスを避けるにはどの措置が必要か選択肢の中から選ぶことが求められます。また、措置を講じた後の影響範囲の確認や記録の点も重要な部分として捉えて解答を選ぶべきです。
基本的な概念や原則：
Security Command Center（SCC）：Google Cloudのセキュリティとデータリスクのプラットフォームです。組織のリソースを保護するための洞察と通知を提供します。
Cloud Storageバケット：Google Cloudのオブジェクトストレージサービスです。大量の非構造化データを保存し、管理できます。
公開アクセス：Cloud Storageバケットのコンテンツが一般に公開され、認証なしでアクセスできる状態を指します。セキュリティ上のリスクが考えられるため、管理には注意が必要です。
組織ポリシー：Google Cloudのリソースに対する管理ポリシーの一種で、特定の制約を適用してリソースの使用を管理します。組織全体または特定のフォルダ、プロジェクトに適用できます。
storage.publicAccessPrevention：組織ポリシーの種類の一つで、Cloud Storageバケットに対する公開アクセスを制限することができます。このポリシーを強制することで、誤ってバケットを公開するリスクを軽減できます。
storage.uniformBucketLevelAccess：組織ポリシーの種類の一つで、バケット内のすべてのオブジェクトに対して一貫したアクセス制御を提供することができます。
VPC Service Controls：Google Cloudの仮想プライベートクラウド（VPC）サービスで、特定のサービスからのデータの出入りを制御する機能です。不正アクセスを防ぐための一つの手段です。
正解についての説明：
（選択肢）
・1. バケットの権限を変更してアクセスを制限します
2. バケットの使用ログをクエリして、データへの不正アクセスについて報告します
3. 組織ポリシーstorage.publicAccessPreventionを強制して回帰を回避します。
この選択肢が正解の理由は以下の通りです。
まず、公開されたCloud Storageバケットのアクセスを制限するために、そのバケットのパーミッションを変更する必要があります。これによって、不適切に公開されているデータへのアクセスを即座に停止し、インシデントの影響を最小限に抑えます。
次に、組織全体のポリシーであるstorage.publicAccessPreventionを実施することで、Cloud Storageバケットが誤って一般公開されることを防ぐことができます。このポリシーを適用することで、組織が保有するすべてのバケットに対する公開設定の変更を制限し、同じ問題が再発しないよう対策できます。以上の理由から、これらの手順はインシデントの影響を調査し、修復するのに適切な方法であると言えます。
不正解についての説明：
選択肢：1. すべてのユーザーにアクセスを許可するIdentity and Access Management（IAM）をバケットから削除します
2. 組織ポリシーstorage.uniformBucketLevelAccessを適用して回帰を防止します
3. データアクセスログをクエリして、不正アクセスについて報告します。
この選択肢が正しくない理由は以下の通りです。
storage.uniformBucketLevelAccessポリシーは、バケット全体に一貫したアクセス制御を提供する機能ですが、一般公開を防ぐ機能は提供しません。
それに対して、storage.publicAccessPreventionポリシーは、バケットの一般公開を直接防ぐため、ここでの要件には、公開アクセスの防止が必要なため正解となります。
選択肢：1. 権限を変更して、許可されたユーザーのアクセスを制限します
2. すべての実稼働プロジェクトの周囲にVPC Service Controls境界を適用し、不正なアクセスを直ちに阻止します
3. 管理者のアクティビティ監査ログを確認して、不正なアクセスについて報告します。
この選択肢が正しくない理由は以下の通りです。
まず、不正解の1番目の方法は正解の最初のステップと同じですが、2番目の手段が問題です。VPC Service ControlsはプロジェクトとVPCネットワークのリソースを保護する目的ではありますが、すでに公開されてしまったCloud Storageバケットのアクセス制限問題の解決には適していません。
また、正解の選択肢ではstorage.publicAccessPreventionポリシーを実施することで一般公開の設定を制限しますが、不正解の選択肢にはそのような手段が含まれていません。
選択肢：1. バケットの権限を変更してアクセスを制限します
2. バケットへの不正アクセスがないかデータアクセス監査ログを照会します
3. 設定ミスが修正されたら、Security Command Centerで検出結果をミュートします。
この選択肢が正しくない理由は以下の通りです。
ここで考慮すべき重要なポイントは、同様のインシデントを防ぐための戦略が含まれていないことです。選択肢からは、組織ポリシーのstorage.publicAccessPreventionを実施することによる再発防止の措置が欠けており、このため不適切です。
参考リンク：
https://cloud.google.com/security-command-center/docs
https://cloud.google.com/storage/docs/access-logs
https://cloud.google.com/storage/docs/using-public-access-prevention
</div></details>

### Q.  問題5: 未回答
あなたは会社のセキュリティ管理者で、Google Cloudのアクセス制御（識別、認証、承認）の管理を担当しています。
認証と認可を設定する際に従うべきGoogle推奨のベストプラクティスはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのアクセス制御に関するベストプラクティスについて理解することが求められます。セキュリティ管理者としてのロールを考慮に入れ、認証と認可に関する選択肢に焦点を当てていくことが重要です。また、単にGoogle Cloudのサービスを使用するだけでなく、セキュリティプラクティスに適した選択肢が最善の解答であるという観点も忘れないでください。
基本的な概念や原則：
SSO/SAML：シングルサインオン（SSO）は、複数のサービスへの認証を一度のログインで管理するテクノロジーです。SAML（Security Assertion Markup Language）は、セキュリティ情報を交換するための標準プロトコルで、SSOの実装によく使用されます。
Cloud Identity：Google CloudのIdentity and Access Management（IAM）の一部で、ユーザーの認証とライフサイクル管理を行うサービスです。SSO/SAMLと統合することにより、認証スキームのシームレスな統合が可能です。
事前定義されたロール：Google Cloud IAMでは、特定のサービスに対するアクセス権限が事前に定義されたロールとして提供されています。これにより、適切なアクセス制御とセキュリティが実現できます。
IAM（Identity and Access Management）：Google Cloudのユーザー管理とアクセス制御を担当するサービスです。セキュリティベストプラクティスに従い、適切なアクセス許可をユーザーに付与することが推奨されます。
正解についての説明：
（選択肢）
・ユーザー認証とユーザーライフサイクル管理のために、SSO/SAMLをCloud Identityと統合します
・事前に定義されたロールによるきめ細かなアクセスを提供します
この選択肢が正解の理由は以下の通りです。
まず、SSO/SAMLをCloud Identityと統合することでユーザー認証とユーザーライフサイクル管理を効果的に行うことができます。SSO（Single Sign-On）はユーザーが一度の認証で複数のシステムにアクセスできるようにするもので、SAML（Security Assertion Markup Language）はウェブブラウザを介してシングルサインオンを実現するフレームワークです。これをCloud Identityと統合することでユーザー認証を一元化し、セキュリティの管理を効率化することができます。
次に、事前に定義されたロールによるきめ細かなアクセスを提供することは、セキュリティのベストプラクティスの一つです。これは極小の権限しか持たないロールを個々のユーザーやサービスに割り当てることで、アクセス制御を強化し、潜在的な権限の乱用を防ぐ目的があります。特にGoogle Cloudでは、事前に定義されたロールを用いてユーザーやサービスのアクセスを制御していくのが推奨されています。これにより安全かつ効果的な認証・認可設定が可能となります。
不正解についての説明：
選択肢：Googleのデフォルトの暗号化を使用します
この選択肢が正しくない理由は以下の通りです。
Googleのデフォルトの暗号化はデータの保護に関する重要な側面ですが、ここで求められているのは"認証"と"認可"に関するベストプラクティスです。この選択肢は直接的なアクセス制御には関連していません。
一方、SSO/SAMLのCloud Identityとの統合と事前に定義されたロールによるアクセス提供は、アクセス制御の問題解決策として直接的かつ効果的です。
選択肢：Google Cloudにユーザーを手動で追加します
この選択肢が正しくない理由は以下の通りです。
Google Cloudに手動でユーザーを追加すると、一人ひとりの管理が手間になり、認証と認可の流れが複雑化します。これは、効率よく管理するためのベストプラクティスとは異なります。そのため、SSO/SAMLを用いてCloud Identityと統合することでユーザーライフサイクルを自動化管理し、効率性とセキュリティを確保するのが推奨されます。
選択肢：GoogleのIAM（Identity and Access Management）サービスを使用して、基本的なロールを持つユーザーをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
Google IAMを使用して基本的なロールを持つユーザーをプロビジョニングするという選択肢は、適切なアクセス管理のためのベストプラクティスではありません。基本的なロールを設定すると、ユーザーに必要以上の権限が与えられる可能性があるため、原則として最小権限の原則を遵守した事前定義されたロールによるアクセスを提供する方法が推奨されます。
参考リンク：
https://cloud.google.com/identity/saml
https://cloud.google.com/iam/docs/using-predefined-roles
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題6: 未回答
あなたの会社の新しいCEOは最近、会社の2つの部門を売却しました。あなたの会社の取締役は、これらの部門に関連するGoogle Cloudプロジェクトを新しい組織ノードに移行する手助けをするようあなたに依頼しました。この移行を行う前に必要な準備手順はどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudプロジェクトの組織ノードへの移行にどのような準備が必要かを理解することが求められています。既存のIDやIAMロールの移行と、VPC Service Controlsの境界からのプロジェクトの削除という明確な手順が示されています。選択肢を見る際は、既存の設定や構成を保ちつつ新しい組織ノードへの適切な移行を達成するものを選びます。さらに、互換性やセキュリティを維持し、新しい組織ノードのポリシーに準拠するものを選んでください。
基本的な概念や原則：
継承されたIDおよびIAMロール：Google Cloudのリソース階層において、特定のリソースに付与されたアクセス権限は、その下位のリソースにも継承されます。これにより、プロジェクトや組織全体での権限管理が可能になります。
VPC Service Controls：Google Cloudサービス間の通信を制御して、データ漏えいのリスクを軽減するためのサービスです。サービスパーリメーター（境界）を定義して、それを超えた通信を制限します。
移行プロジェクト：Google Cloud上での移行作業を管理するためのプロジェクトです。資源の移動や権限の付与など、移行に必要な操作がここで行われます。
組織ポリシー：Google Cloudのリソース階層全体で制御を設けるためのフレームワークです。特定の制約を定義して、それに沿ったリソース管理を強制することができます。
正解についての説明：
（選択肢）
・移行対象プロジェクトで継承されたIDおよびIAMロールを特定します
・VPC Service Controlsの境界およびブリッジから特定の移行プロジェクトを削除します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudプロジェクトを他の組織ノードに移行する際、継承されたIDおよびIdentity and Access Management（IAM）ロールを特定することは重要です。これによりアクセス管理が適切に行われ、誤ったアクセスや権限が発生する可能性を最小化します。また新しい組織に移行した後も適切な操作が実行できるようにするためには、それらのアクセス許可や権限が何であるかを明確に理解しておくことが求められます。
次に、VPC Service Controlsは、Google Cloudリソースが特定のVirtual Private Cloud（VPC）ネットワークやプロジェクトに制限されるようにするサービスです。移行対象のプロジェクトがVPC Service Controlsの境界に含まれている場合、そのプロジェクトを移行する前にこれを削除する必要があります。これにより、移行に伴うネットワークの接続問題やセキュリティの問題を防ぐことができるのです。
不正解についての説明：
選択肢：プロジェクトレベルのカスタムIDおよびIAMロールをすべて削除します
この選択肢が正しくない理由は以下の通りです。
プロジェクトレベルのカスタムIDおよびIAMロールをすべて削除する行為は、移行対象のプロジェクトの適切な運用を保証できない可能性があります。そのため、これらを特定する事が重要で、無条件に削除するのはリスクが高いです。
選択肢：組織ポリシーの継承を禁止します
この選択肢が正しくない理由は以下の通りです。
新しい組織ノードへのプロジェクト移行では、組織ポリシーの継承を禁止するのではなく、移行対象プロジェクトで継承されるIDおよびIAMロールと、VPC Service Controlsの境界およびブリッジの設定が必要です。組織ポリシーの継承を禁止することでは、これらの重要な事項が漏れてしまう可能性があります。
選択肢：移行するすべてのプロジェクト用に新しいフォルダを作成します
この選択肢が正しくない理由は以下の通りです。
新しいフォルダを作成するという手順は、移行のための直接的な準備ではなく、組織のリソース整理の一環であり、必須ではありません。
それに対して、IDやIAMロールの特定はアクセス権限を適切に移行するため、VPC Service Controlsの設定は移行によるセキュリティ影響を把握するため、といった準備が必要です。
参考リンク：
https://cloud.google.com/resource-manager/docs/project-migration
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/vpc-service-controls/docs/perimeters
</div></details>

### Q.  問題7: 未回答
Google Cloudコンソールのログインアクティビティイベントと、Google Cloudリソースの設定を変更するAPI呼び出しのセキュリティログをエクスポートし、監査する必要があります。エクスポートは以下の要件を満たす必要があります：
- Google Cloudの組織内のすべてのプロジェクトの関連ログをエクスポートします。
- ログをほぼリアルタイムで外部のSIEMにエクスポートします。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの全体的なログエクスポートおよび監査設定に関する理解が求められています。ここでの課題は、全てのプロジェクトのログをエクスポートし、それをほぼリアルタイムで外部のSIEMに転送することです。特定のパラメータやサービスの使用により、この要求を満たす適切な設定を検討する事が重要です。またSIEMでの対応についても考慮し、適切なフィールドの情報が収集できていることを確認する必要があります。
基本的な概念や原則：
ログエクスポート：Google Cloudのログ検索、分析、保存のための機能です。ログエクスポートを使用すると、Cloud LoggingのログをCloud Storage、BigQuery、またはCloud Pub/Subにエクスポートできます。
includeChildrenパラメータ：Google Cloudのログシンクにおけるパラメータで、これを使用すると親リソース（組織、フォルダ、プロジェクト）の全ての子リソースからログをエクスポートすることができます。
Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。大量のメッセージを生産者から消費者に信頼性高く、高速に送ることが可能です。
SIEM（セキュリティ情報およびイベント管理）：セキュリティ情報やイベントを収集、分析し、監視するシステムやソフトウェアのことです。異常行動やセキュリティ違反の検出に役立ちます。
AuthenticationInfoフィールド：ログエクスポートにおけるフィールドで、認証情報（誰が何をしたか）を含む情報が記録されます。これは、アクセス監査やセキュリティログの分析に重要です。
正解についての説明：
（選択肢）
・includeChildrenパラメータを使用して組織レベルでログシンクを作成し、宛先をPub/Subトピックに設定します
・SIEMが監査ログエントリのAuthenticationInfoフィールドを処理してID情報を収集することを確認します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudのログエクスポートでは、"includeChildren"パラメータを使用してログシンクを作成することにより、組織内のすべてのプロジェクトの関連ログを一度にエクスポートすることが可能になります。これらのログは、Google Cloud Pub/Subトピックにリアルタイムで送れます。Pub/Subトピックを利用することで、ログは指定されたトピックに発行され、Pub/Subからの引き出しはサブスクライバーによって行われます。結果として、これらのログは外部のSIEMシステム（セキュリティ情報およびイベント管理システム）にほぼリアルタイムでエクスポートできます。これにより、リアルタイムでログを監査するための要件が満たされます。
また、Google Cloudの監査ログエントリには様々なフィールドが含まれていますが、その中の"AuthenticationInfo"フィールドは誰が何をしたかといった重要な監査情報を含むため、SIEMがこのフィールドを処理してID情報を収集することが重要です。これにより、正確な監査が可能になります。
不正解についての説明：
選択肢：組織レベルでPub/Sub宛先のログシンクを作成します
この選択肢が正しくない理由は以下の通りです。
単純に"組織レベルでPub/Sub宛先のログシンクを作成します"だけでは、そのログシンクが実際に全てのプロジェクトの関連ログをエクスポートするように設定されていることは保証されません。includeChildrenパラメータを使用して確実にすべての子プロジェクトをカバーする設定が必要です。
選択肢：組織レベルでのデータアクセス監査ログを有効にして、すべてのプロジェクトに適用します
この選択肢が正しくない理由は以下の通りです。
監査ログの有効化は有効なセキュリティステップではありますが、それ自体ではログを外部のSIEMにエクスポートする要件を満たせません。ログエクスポートはログシンクを使用して設定する必要があります。
選択肢：管理コンソールでGoogle Workspaceの監査ログをGoogle Cloudと共有できるようにします
この選択肢が正しくない理由は以下の通りです。
Google Workspaceの監査ログをGoogle Cloudと共有することは、課題の要件に該当しません。ここでは、Google CloudのログインアクティビティとAPI呼び出しのセキュリティログのエクスポート、並びにリアルタイムでのSIEMへの送信が求められていますが、Google Workspaceのログの共有はこれとは別の機能です。
参考リンク：
https://cloud.google.com/logging/docs/export/configure_export_v2
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/pubsub/docs
</div></details>

### Q.  問題8: 未回答
サービスアカウントキーが、複数の公開コードリポジトリで公開されています。ログを確認したところ、そのキーが短命の認証情報を生成するために使用されていることに気づきました。そのサービスアカウントでのアクセスを直ちに削除する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、サービスアカウントキーのセキュリティ侵害に対する対応策を考える必要があります。この問題が要求しているのは、公開されてしまったサービスアカウントキーによる認証情報の生成を直ちに停止する方法です。したがって、各選択肢がこの要件を満たすかどうか、即時性と効果の観点から検討することが求められます。
基本的な概念や原則：
サービスアカウント：Google Cloud内で動作するアプリケーションの認証とアクセス許可に使用される特殊なGoogleアカウントです。コード内で認証するために用いられます。
サービスアカウントキー：サービスアカウントのIDと秘密鍵のペアです。アプリケーションがGoogle Cloud APIにアクセスする際の認証に使用されます。
短命の認証情報：一時的な認証手段で、一定時間後に期限切れとなる認証情報のことです。
サービスアカウントの削除：不正使用を防止するための最終手段で、特定のサービスアカウントを完全に削除します。
サービスアカウントキーの無効化：特定のサービスアカウントキーがGoogle Cloud APIにアクセスできないようにする措置です。ただし、既にキーを持っている者がいれば、新しい認証情報を生成できます。
正解についての説明：
（選択肢）
・侵害されたサービスアカウントを削除します
この選択肢が正解の理由は以下の通りです。
まず、サービスアカウントが危険にさらされた場合、セキュリティ対策として最も直接的で効果的なアクションはそのサービスアカウントを速やかに削除することです。その理由としては、そのサービスアカウントが公開状態であり、そのキーが不正に使われている可能性があります。サービスアカウントを削除することで、そのキーによる不正アクセスを直ちに停止することができます。この手段は即時性と確実性が求められる場合に特に有効です。
ただし、サービスアカウントの削除はそれが使われていたサービスに影響を及ぼす可能性があるので、削除する前にその影響範囲を把握しておく必要があります。
以上の事から、侵害されたサービスアカウントを速やかに削除するのが適切な対策となります。
不正解についての説明：
選択肢：漏洩したサービスアカウントキーを無効にします
この選択肢が正しくない理由は以下の通りです。
漏洩したサービスアカウントキーを無効にするだけでは、そのサービスアカウント自体が存在する限り、新たなキーを生成し、不正なアクセスを続行することが可能です。しかし、対して侵害されたサービスアカウントを削除することで、直ちにそのサービスアカウントからの全てのアクセスを停止し、問題を解決できます。
選択肢：サービスアカウントの認証情報が自動的に期限切れになるまで待ちます
この選択肢が正しくない理由は以下の通りです。
サービスアカウントの認証情報が自動的に期限切れになるまで待つという選択は、セキュリティに対するソフトな対策であり状況の深刻さを無視した行為です。公開されたキーを通じて不正なアクセスが可能な場合、時間が経過することは逆にリスクを増大させてしまいます。そのため、直ちにアクセス削除が必要であり、その目的を達するために侵害されたサービスアカウント自体を削除するのが最適な選択となります。
選択肢：漏洩したサービスアカウントキーを交換します
この選択肢が正しくない理由は以下の通りです。
サービスアカウントキーを交換すると、新しいキーが生成されますが、既存の公開リポジトリでは引き続き古いキーが使われる可能性があります。
それに対して、侵害されたサービスアカウントを削除すると、それにより生成されたすべての認証情報が無効化されるため、より安全です。
参考リンク：
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/iam/docs/granting-changing-revoking-access
</div></details>

### Q.  問題9: 未回答
ある組織のセキュリティとリスク管理チームは、Google Cloudで実行している特定の本番ワークロードの責任の所在とGoogleの責任の所在について懸念しています。彼らは、主にApp Engineを含むGoogle CloudのPaaS（Platform-as-a-Service）を使用してワークロードを実行しています。
App Engineを使用する場合、テクノロジースタックのどの領域に主な責任を負うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、PaaS（Platform-as-a-Service）ソリューションであるApp Engineを使用している組織のセキュリティ責任について考えるよう求められています。具体的には、テクノロジースタックのどの領域に主な責任を担うかを問われています。App Engineのシナリオでは、Googleとエンドユーザーの責任分担モデルを理解した上で、選択肢を評価することが求められます。他のCloudサービスとは異なり、PaaSではプロバイダーが多くのレイヤーの管理を引き受けますが、それでもユーザーの責任範囲として何が残るのか、それを見極める必要があります。
基本的な概念や原則：
PaaS（Platform-as-a-Service）：開発者がアプリケーションをビルド、デプロイ、運用管理するためのプラットフォームを提供するクラウドサービスです。ハードウェアやOS、データベース等のインフラ管理はクラウドプロバイダが担当します。
App Engine：Google CloudのフルマネージドのPaaSサービスです。開発者はアプリ開発に集中でき、インフラ管理の手間を減らすことができます。
XSSおよびSQLi攻撃：ウェブアプリケーション独自の脆弱性を悪用し、悪意のあるスクリプトを挿入したり、データベース操作を行ったりする攻撃方法です。アプリケーションのセキュリティ設計とコーディングが防御の主要な手段となります。
VPCフローログ：仮想プライベートクラウド（VPC）ネットワークのフローデータをキャプチャしてログに保存する機能です。これにより、ネットワークのトラフィックパターンを理解し、ネットワークパフォーマンスの問題をトラブルシューティングすることができます。
ゲストOSの更新とセキュリティパッチ管理：システムの安全性を保つために必要な業務です。しかし、PaaSサービスでは、これらはプロバイダの責任範囲内です。
保存データの暗号化：データを保護し、不許可のアクセスから安全に保つ方法です。PaaSサービスでは、これは通常、プロバイダが担当します。
正解についての説明：
（選択肢）
・XSSおよびSQLi攻撃からの防御
この選択肢が正解の理由は以下の通りです。
PaaS（Platform-as-a-Service）であるGoogle App Engineを使用する場合、インフラストラクチャやオペレーティングシステム、ランタイム環境などの管理はGoogleが行います。しかし、開発者や組織側が責任を持つべき箇所は、アプリケーションのコードとそのセキュリティです。XSS（クロスサイトスクリプティング）やSQLi（SQLインジェクション）攻撃はアプリケーションのセキュリティ脆弱性を突いたものであり、これらの防御は開発者の負担となります。
したがって、Google CloudのPaaSを使用している場合でも、アプリケーションの開発と運用には明確なセキュリティ対策が必要であり、それがこの選択肢が正解となる理由です。
不正解についての説明：
選択肢：VPCフローログの設定と監視
この選択肢が正しくない理由は以下の通りです。
Google CloudのPaaSサービスであるApp Engineは、ネットワークおよびインフラストラクチャの管理をGoogleが担当するので、ユーザーがVPCフローログの設定と監視の責任を持つ必要はありません。
それに対し、XSSやSQLi攻撃からの防御はユーザーのアプリケーションロジックと密接に関連するため、ユーザーの責任です。
選択肢：ゲストOSの最新アップデートとセキュリティパッチの管理
この選択肢が正しくない理由は以下の通りです。
App EngineはPaaSであり、プラットフォームの管理はGoogleによって行われます。
従って、ゲストOSのアップデートやセキュリティパッチの管理はGoogleの責任となります。
一方、XSSやSQLi攻撃からの防御はアプリケーションレベルの問題なので、依然としてユーザの責任となります。
選択肢：すべての保存データの暗号化
この選択肢が正しくない理由は以下の通りです。
App EngineはGoogle CloudのPaaSサービスであり、データの暗号化はGoogleの責任範囲になります。しかしXSSやSQLi攻撃からの防御は開発者のアプリケーション設計の範囲内で、その責任はユーザーにあります。
参考リンク：
https://cloud.google.com/appengine/docs/standard/security-roles
https://cloud.google.com/security/shared-responsibility
https://owasp.org/www-community/attacks/xss/
</div></details>

### Q.  問題10: 未回答
オンプレミスのインターネット接続を経由して、Google Cloudからインターネットに接続するすべてのトラフィックをルーティングします。この目標を安全かつ可能な限り高い帯域幅で達成したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミスとGoogle Cloud間のトラフィックルーティングと帯域幅の最適化に関連する理解が求められています。コンテクストに適した接続タイプと特定のネットワークトラフィック管理策を適用するための適切なGoogle Cloudのサービスや機能を識別することが重要です。また、オンプレミスのインターネット接続を利用する必要があり、Google Cloudからのインターネットへのトラフィックをオンプレミスのファイアウォールを通じて流すことを忘れないでください。
基本的な概念や原則：
Cloud Interconnect：オンプレミス環境とGoogle Cloudとの間で、高い帯域幅と低いネットワーク遅延を実現する接続サービスです。プライベート接続を通じてGoogleのネットワークと直接接続します。
ファイアウォール：ネットワークのセキュリティを高めるために設けられ、ネットワークとインターネットの間にあって不正アクセスを防ぐ機能です。ルールに基づいてネットワークトラフィックを制御します。
HA VPN：高い可用性を提供するGoogle CloudのVPN接続サービスです。冗長性があり、ミッションクリティカルなワークロードのデータ転送に適しています。
ルーティング：ネットワークトラフィックがネットワークのどの部分を通過するかを決定するプロセスです。ルーティングルールに基づき、パケットは宛先に適切なパスで送られます。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。カスタムルーティングを適用することも可能です。
正解についての説明：
（選択肢）
・Cloud Interconnectを設定し、オンプレミスのファイアウォールを介してトラフィックをルーティングします
この選択肢が正解の理由は以下の通りです。
まず、Cloud InterconnectはGoogle Cloudとオンプレミス環境との間で低レイテンシ、大容量、高信頼性の接続を提供します。これにより、ネットワークパフォーマンスの向上を期待でき、Google Cloudからインターネットへの全てのトラフィックのルーティングにおいて、高い帯域幅を確保できます。一般のインターネット接続よりもパフォーマンスが優れているため、ユーザーエクスペリエンスの向上に繋がります。
また、オンプレミスのネットワークとGoogle Cloudとの間に専用のプライベート接続を確立することで、安全性が向上します。この接続には、Googleのエッジネットワークが使用されます。このネットワークはパブリックインターネットから完全に分離されているため、セキュリティの観点からは有利です。
さらに、トラフィックをオンプレミスのファイアウォールを通過させることで、トラフィックの監視とフィルタリングが可能となり、セキュリティを強化できます。これによりGoogle Cloudからオンプレミスへの接続でも安全性が確保されます。
不正解についての説明：
選択肢：Google CloudへのHA VPN接続を作成します。デフォルトの0.0.0.0/0ルートを置き換えます
この選択肢が正しくない理由は以下の通りです。
HA VPN接続は高可用性のVPN接続を提供しますが、高帯域幅の接続は保証されません。
一方、Cloud InterconnectはGoogle Cloudとオンプレミス環境間で高速で安全な接続を提供するため、高帯域幅の要件を満たします。
選択肢：Compute EngineにルーティングVMを作成します。VMをネクストホップとしてデフォルトルートを設定します
この選択肢が正しくない理由は以下の通りです。
ルーティングVMを作成し、これをネクストホップとしてデフォルトルートを設定する手法は、VM上のルーティングを依存する形になり、VMのパフォーマンスや堅牢性に依存してしまいます。
これに対して、Cloud Interconnectを設定することで、Google Cloudとオンプレミスの間で高帯域、安定した接続を提供します。
選択肢：HA VPNでCloud Interconnectを設定します。デフォルトの0.0.0.0/0ルートをオンプレミスの宛先に置き換えます
この選択肢が正しくない理由は以下の通りです。
HA VPNはGoogle Cloud内の仮想プライベートネットワークとオンプレミスネットワークを接続する方法であり、高い帯域幅を要求する状況のためには適していません。
一方、Cloud Interconnectはプライベート接続を提供し、高いスループットを可能とします。
参考リンク：
https://cloud.google.com/interconnect/docs
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/network-connectivity/docs/interconnect/concepts/throughput
</div></details>

### Q.  問題11: 未回答
Google Cloudの組織では、Ownerロール（roles/owner）を持つGoogle Cloudプロジェクトを提供することで、管理機能を各チームに分散できます。この組織には何千ものGoogle Cloudプロジェクトが含まれています。Security Command Center Premiumで複数のOPEN_MYSQL_PORTが検出されました。あなたはガードレールを実施しており、これらのタイプの一般的な誤設定を防止する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、複数あるGoogle Cloudプロジェクトでのセキュリティの脆弱性、特にOPEN_MYSQL_PORTを検出し、これを防止するための"ガードレール"の実装方法について求められています。大量のプロジェクトを管理しており、分散した管理機能を提供する組織での対策が必要となります。そのため、全体的なセキュリティポリシーやファイアウォールの適用や設定を理解し、それらを組織全体に適用するための最適なアプローチを選択することが求められます。また、MySQLのポート公開問題を直接的に解決するための具体的な対策と、それらを実行する際の範囲や優先度の理解も重要です。
基本的な概念や原則：
Ownerロール：Google Cloudのロールの一つで、全リソースに対する全権限を持っています。そのため、このロールを持つユーザーはリソースの作成、削除、変更など様々な操作が可能です。
Security Command Center：Google Cloudのセキュリティとリスクデータを一元化し、可視化するプラットフォームです。誤設定や脅威、不審な活動を検出し、それらに対するレポートを提供します。
ファイアウォール：ネットワークのセキュリティを確保する仕組みの一つで、不正な通信や攻撃を防ぐために、通信の制限や遮断を行います。
階層ファイアウォールポリシー：Google Cloudの機能で、組織全体で適用したい設定を一箇所で管理することができます。組織、フォルダ、プロジェクトの階層を考慮した制御が可能です。
Google Cloud Armor：Google Cloudのセキュリティサービスで、WEBサービスへのDDoS攻撃や不正なアクセスを防ぐ機能を提供します。
仮想プライベートクラウド（VPC）：ユーザー専用のプライベートなネットワーク空間です。Google Cloud上で自身のクラウドネットワークを作成、管理できます。
正解についての説明：
（選択肢）
・内部IP範囲からの接続のみを許可するように、組織で設定された階層ファイアウォールポリシーを作成します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudは階層ファイアウォールポリシーを提供しており、これにより組織のネットワーク全体に対して一貫したセキュリティポリシーを適用することが可能となっています。この組織で設定された階層ファイアウォールポリシーは全てのプロジェクトに適用されるため、一括管理が可能となります。特に、問題となりやすいOPEN_MYSQL_PORT等の脆弱性を含む誤設定を防止するために有効な手段です。
また、内部IP範囲からの接続のみを許可するように設定することで、外部からの不正なアクセスを防止し、セキュリティを強化できます。
これらの主に2つの要点から、この選択肢は問題の要件を満たす最適な解答となります。
不正解についての説明：
選択肢：0.0.0.0/0からのトラフィックを拒否するように、組織で設定された階層ファイアウォールポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
全てのトラフィックを拒否する階層ファイアウォールポリシーを作成すると、一部の必要なサービスもブロックしてしまいます。
それに対して、内部IP範囲からの接続のみ許可する方が、必要なサービスへのアクセスは保ったまま安全性を確保できます。
選択肢：0.0.0.0/0からのトラフィックを拒否するGoogle Cloud Armorセキュリティポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloud ArmorはHTTP(S)トラフィックに対する保護を提供しますが、ここでの問題はMYSQL_PORTの誤設定です。そのためMYSQL_PORTの誤設定を検出し防止するために、階層ファイアウォールポリシーを用いる方が適切です。
選択肢：各仮想プライベートクラウド（VPC）に対して、優先度0で0.0.0.0/0からのトラフィックを拒否するファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
優先度0で0.0.0.0/0からのトラフィックを拒否するファイアウォールルールを各VPCに設定すると、すべてのトラフィックが完全にブロックされてしまいます。これは必要な通信までもを遮断してしまうため、安全にシステムを運用できません。そのため、特定のIP範囲からの接続のみを許可する方が適切です。
参考リンク：
https://cloud.google.com/network-connectivity/docs/hierarchical-firewall/overview
https://cloud.google.com/security-command-center/docs/concepts-security-command-center-overview
https://cloud.google.com/vpc/docs/firewalls
</div></details>

### Q.  問題12: 未回答
あなたは、Google Cloudへのデータ移行を計画している顧客と仕事をしています。あなたは、暗号化された鍵を管理する暗号化サービスを推奨する責任があります。以下の要件があります：
- マスターキーは少なくとも45日ごとにローテーションされる必要があります。
- マスターキーを保管するソリューションは、FIPS 140-2レベル3の認証を受けている必要があります。
- マスターキーは、冗長性のために米国内の複数のリージョンに保管されなければなりません。
これらの要件を満たすソリューションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの暗号化サービスを推奨する際に3つの要件を満たす必要があることが明示されています。キーのローテーション周期、認証、複数リージョンの利用という要件を果たすGoogle Cloudのサービスを選択肢から選ぶことが求められています。各選択肢がこれらの要件をどの程度満たしているかを理解し、最も要件に適合するサービスを選ぶことが肝心です。
基本的な概念や原則：
Cloud HSM：Google CloudのCloud HSM（HSM）サービスです。FIPS 140-2レベル3の認証を持っており、強力な暗号化キーの管理と操作を提供します。
FIPS 140-2：米国政府が承認した暗号モジュールセキュリティ標準です。レベル3は、物理的なタンパリングに対する保護を強化したレベルです。
顧客管理の暗号化キー：顧客が作成、管理する暗号化キーです。Google Cloudサービスの暗号化に使用されますが、キー自体の管理は顧客の責任となります。
Cloud Key Management Service（KMS）：暗号キーの生成、使用、管理、インポート、エクスポート、ローテーションを提供するフルマネージドサービスです。ただし、FIPS 140-2レベル3の認証はありません。
冗長性：システムの信頼性を向上させるための技術です。複数の要素が同じ作業を実行することにより、一部の要素が故障してもシステム全体が続行できるようにします。ここでは、キーを複数のリージョンに保管することが指示されています。
正解についての説明：
（選択肢）
・Cloud HSMによる顧客管理の暗号化キー
この選択肢が正解の理由は以下の通りです。
まず、Cloud HSMはGoogle Cloudの高度な鍵管理サービスで、これを使用することにより適切な周期でのキーローテーションが可能となります。すなわち、Cloud HSMは45日ごと（あるいはそれ以下の期間）のキーローテーションを実現・管理できます。
また、Cloud HSMはFIPS 140-2レベル3の認証を受けたCloud HSM（HSM）を提供します。これにより、顧客は自身の暗号化キーをセキュリティレベルが高い条件下で管理できることを保証できます。
さらに、Cloud HSMはGoogle Cloudの各リージョンで利用可能であり、ユーザーはデータの冗長性を保証するため、同じ鍵を複数のリージョンで使用することが可能です。具体的には、米国内の任意の複数のリージョンでHSMを展開し、同じ鍵を保存することができます。
以上の各要素が、Cloud HSMがこれらの特定の要件を満たす最適なソリューションである理由です。
不正解についての説明：
選択肢：Cloud Key Management Serviceによる顧客管理の暗号化鍵
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Service（KMS）はマスターキーのローテーションや複数リージョンでの保管をサポートしますが、FIPS 140-2レベル3の認証を受けていません。
一方、Cloud HSMはすべての要件を満たしており、特にFIPS 140-2レベル3の認証を受けています。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キー（CSEK）は顧客が完全に制御と管理を行い、Google Cloudは鍵を知らず、保存もしません。そのため、キーのローテーションや複数リージョンへの保管といった要件をクラウド側で制御することはできません。
これに対し、Cloud HSMはGoogle Cloud上でCloud HSMを使用し、キーの管理と冗長性を確保することが可能です。
選択肢：Googleが管理する暗号鍵
この選択肢が正しくない理由は以下の通りです。
Googleが管理する暗号鍵を使用すると、ユーザーは鍵のローテーションスケジュールや保存場所を制御することができません。
一方、Cloud HSMによる顧客管理の暗号化キーを使用すると、ユーザーは鍵のローテーションと保存場所を制御可能であり、FIPS 140-2レベル3の認証も受けています。
参考リンク：
https://cloud.google.com/kms/docs
https://cloud.google.com/hsm/docs
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題13: 未回答
あなたの組織は、機密性の高い医療情報を処理しています。仮想マシン（VM）の使用中にデータが暗号化されることを保証したいと考えています。組織全体に適用されるポリシーを作成する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、機密性の高い医療情報を処理するために、用途中のデータの暗号化を保証する方法について尋ねられています。そのため、仮想マシン（VM）の使用中にデータが暗号化されることを保証できる仕組みについて理解する必要があります。また、組織全体に適用可能なポリシーの作成も求められており、この点も考慮に入れる必要があります。選択肢を検討する際には、データの暗号化を可能にするテクノロジーとそれを組織全体に適用する方法に着目するべきです。
基本的な概念や原則：
Confidential VM：仮想マシン（VM）の使用中にデータを暗号化するGoogle Cloudのサービスです。医療情報など機密性の高いデータを処理する際に利用します。
組織ポリシー：Google Cloudのリソース管理のための機構です。組織全体に適用され、特定のリソースに対する行動を制限したり、特定の設定を強制することができます。
CMEK（customer-managed encryption keys）：顧客管理の暗号化キーのことです。暗号化キーのライフサイクル（作成、使用、破棄）を顧客側で管理することが可能です。
Cloud External Key Manager（EKM）：Google Cloud外部で暗号化キーを管理するサービスです。CMEKとは異なり、暗号化キーがGoogleのインフラストラクチャから完全に分離されます。
暗号化：データを安全に保護するために行われるプロセスです。暗号化されたデータは、適切な復号キーがなければ理解できない形に変わります。データの使用中の暗号化は、機密データの取り扱いにおいて重要です。
正解についての説明：
（選択肢）
・組織全体で作成されるすべてのVMリソースがConfidential VMインスタンスであることを保証する組織ポリシーを導入します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのConfidential VMは、データを使用中に暗号化する機能を提供します。つまり、データはプロセス中常に暗号化され、それがディスクに書き込まれる前に一時的に復号化されることはありません。これにより、仮想マシン（VM）使用中に機密性の高い医療情報が暗号化され続けることを保証することができます。
次に、ポリシーを組織全体に適用するためには、組織全体で作成されるすべてのVMリソースがConfidential VMインスタンスであることを要求する組織ポリシーを導入することが有効です。これにより、組織内のすべてのユーザーがこの暗号化ポリシーを順守することを確実にします。
したがって、医療情報を含むデータを取り扱う組織にとって、この選択肢は最も適切であると言えます。
不正解についての説明：
選択肢：組織全体で作成されたすべてのVMリソースが、CMEK（customer-managed encryption keys）保護を使用することを保証する組織ポリシーを導入します
この選択肢が正しくない理由は以下の通りです。
CMEK保護を使用するポリシーは確かにデータの暗号化を強制しますが、これはデータアットレスト（保存中）の暗号化です。
一方、問題文では使用中のVMデータの暗号化が求められており、これはConfidential VMインスタンスが提供するデータインユース（使用中）の暗号化を必要とします。
選択肢：組織全体で作成されたすべてのVMリソースがCloud External Key Manager（EKM）保護を使用することを保証する組織ポリシーを実装します
この選択肢が正しくない理由は以下の通りです。
Cloud EKMは暗号化キーの管理に利用されるサービスで、VMの利用中のデータ暗号化には直接関与しません。
一方、Confidential VMは使用中のデータが暗号化されることを保証し、その要件を直接満たします。
選択肢：Googleはデフォルトで使用中のデータを暗号化するので、何もする必要はありません
この選択肢が正しくない理由は以下の通りです。
Googleはデフォルトでデータを暗号化しますが、その暗号化は通常のデータ保護としてのもので、機密性が特に高い医療情報に対する特別な保護策とは異なります。Confidential VMではメモリデータ暗号化技術を使用して、使用中のデータをより高度に暗号化し、医療情報などの機密データの保護を強化します。
参考リンク：
- https://cloud.google.com/security/confidential-computing
- https://cloud.google.com/resource-manager/docs/creating-managing-organization
- https://cloud.google.com/compute/docs/instances/confidential-vm
</div></details>

### Q.  問題14: 未回答
あなたは、IPパケットデータに不正なコンテンツや悪意のあるコンテンツが含まれていないか検査する任務を与えられています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、IPパケットデータの検査方法について問われています。特に"不正なコンテンツや悪意のあるコンテンツ"の検査が求められているので、選択肢を見る際にはパケットレベルでの検査や分析が可能なソリューションである必要があります。また、この問題には具体的な技術やツールの名前がいくつか挙げられているので、それらの機能や用途について理解しておくことも重要です。
基本的な概念や原則：
Packet Mirroring：Google CloudのPacket Mirroringは、特定のVMインスタンスのネットワークトラフィックをミラーリングし、不正なトラフィックやセキュリティ攻撃を検出するために使用します。
VPCフローログ：仮想プライベートクラウド（VPC）ネットワーク内のパケットの送受信情報をロギングする機能です。ここから得られた情報はネットワークモニタリング、フォレンジックス、リアルタイムのセキュリティ分析に使用しますが、パケット内容そのものは取得できません。
Cloud Logging：Google Cloudのロギングサービスです。アプリケーションやシステムからのログデータを一元管理し、解析やアラート設定などが可能です。
Fluentd：オープンソースのデータコレクターです。ログデータを統合し、Google Cloudのような一元的なログ管理システムにデータを送信します。
Google Cloud Armor：Google Cloud上のアプリケーションのセキュリティを強化するサービスです。DDoS攻撃の防御やウェブアプリケーションファイアウォール機能などを提供します。
正解についての説明：
（選択肢）
・Packet Mirroringを使用して、特定のVMインスタンスとの間でトラフィックをミラーリングします。ミラーリングされたトラフィックを分析するセキュリティソフトウェアを使用して検査を実行します
この選択肢が正解の理由は以下の通りです。
Packet Mirroringを使用すれば、リアルタイムに特定のVMインスタンスとのパケット通信を複製し、ミラリングすることができます。これにより、その通信通路上でやりとりされる情報の内容を120％確認することが可能になります。すなわち、通信内容に変更を加えたり、通常の通信の流れを中断させることなく、通信内容に対して深く解析を施すことができます。
ここでの要点は、Packet Mirroringによってミラリングされた情報を解析するためのセキュリティソフトウェアを使用することです。このソフトウェアには、例えばIntrusion Detection System（IDS）やIntrusion Prevention System（IPS）、あるいはその他第三者製のネットワークセキュリティツールが含まれます。これらのツールはパケットレベルでの深部解析や内容確認を行うことで、不正なコンテンツや悪意のあるコンテンツを検出できる設計となっています。
したがって、Packet Mirroringとセキュリティソフトウェアを組み合わせて使用することで、IPパケットデータに不正なコンテンツや悪意のあるコンテンツが含まれていないか確認することができます。
不正解についての説明：
選択肢：VPC内のすべてのサブネットでVPCフローログを有効にします。Cloud Loggingを使用して、フローログのデータを検査します
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフローデータのログを収集・分析するサービスであり、IPパケットデータに含まれるコンテンツ自体を検査することはできません。対してPacket Mirroringは特定のVMとのトラフィックをミラーリングし、その内容をセキュリティソフトウェアで検査することが可能です。
選択肢：VPC内の各VMインスタンスにFluentdエージェントを設定します。Cloud Loggingを使ってログデータを検査します
この選択肢が正しくない理由は以下の通りです。
FluentdエージェントとCloud Loggingは主にログデータの収集と分析に利用されます。しかし、IPパケットデータの悪意のあるコンテンツを検知するには適さないため、この解答は不適切です。
それに対して、Packet Mirroringとセキュリティソフトウェアは、パケットレベルでのデータ検査を実現します。
選択肢：Google Cloud Armorのアクセスログを設定し、ログデータの検査を実行します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは主にHTTP(S)負荷分散のトラフィックを監視し、不正なアクセスを防止します。しかし、IPパケットデータの全体的な検査には向かないため、この要件を満たすのに適切ではありません。正解の選択肢では、Packet Mirroringを使用し、特定のVMとのトラフィックをミラーリングして、セキュリティソフトウェアで検査を行います。これにより、より正確なパケットレベルの検査が可能になります。
参考リンク：
https://cloud.google.com/traffic-director/docs/packet-mirroring
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/armor/docs/logging-and-monitoring
</div></details>

### Q.  問題15: 未回答
あなたの会社は、現在us-central-1のGoogle Cloudロードバランサーの後ろにデプロイされ、Standardティアネットワークを使用するように構成されているアプリケーションインスタンスグループを運営しています。インフラチームは、2つ目のGoogle Cloudリージョンであるus-east-2に拡張したいと考えています。両方のリージョンのインスタンスグループに新しいリクエストを配信するために、単一の外部IPアドレスを設定する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、現在のアプリケーションインスタンスグループがus-central-1のGoogle Cloudロードバランサーの後ろに配置され、新たにus-east-2にインスタンスグループを設定したいという状況です。そこで求められているのは、両方のリージョンのインスタンスグループに新しいリクエストを配信する方法で、特にその際単一の外部IPアドレスを設定する必要があります。この要件を満たすため、ネットワークの設定やロードバランサーの利用、VPN接続の作成など、さまざまなGoogle Cloudの機能や設定変更が考慮されます。適切なアプローチを見つけ出すためには、Google Cloudの各種サービスとそれらの設定変更がもたらす影響について理解を深める必要があります。
基本的な概念や原則：
ロードバランサー：トラフィックを複数のサーバーやリージョン間で自動的に分散させるネットワークデバイスです。これにより、各サーバーの負荷を均等にし、ネットワークパフォーマンスを向上させます。
Standardティアネットワーク：Google Cloudのネットワークオプションで、低コストなパフォーマンスを提供します。ただし、マルチリージョン配信には制限があります。
プレミアムティアネットワーク：Google Cloudの高性能ネットワークオプションです。マルチリージョン配信をサポートし、より優れたパフォーマンスを提供します。
インスタンスグループ：同じ設定の仮想マシンをグループ化したものです。ロードバランサーと共に使用すると、トラフィックを複数の仮想マシン間で分散させることが可能です。
ネットワークエンドポイントグループ：Google Cloudの機能で、ネットワークエンドポイント（特定のIPアドレスとポートの組み合わせ）をロジカルにグループ化します。これにより、エンドポイントへのトラフィックフローを制御できます。
静的外部IPアドレス：固定の公開IPアドレスです。インスタンスが停止または削除されても変わらず、アクセス先を一定に保つことができます。
Cloud VPN：Google Cloudの仮想プライベートネットワーク（VPN）接続機能です。異なるネットワーク間の安全な通信を可能にします。
正解についての説明：
（選択肢）
・ロードバランサーのフロントエンドの設定をプレミアムティアのネットワークを使うように変更し、新しいインスタンスグループを追加します
この選択肢が正解の理由は以下の通りです。
まず、プレミアムティアのネットワークを使用すると、Google Cloudが提供するグローバルネットワーク上でトラフィックがルーティングされます。これにより、複数の地域にまたがるリージョンを持つインスタンスグループに対して、単一の外部IPアドレスを用いてリクエストを配信することが可能になります。
一方、スタンダードティアのネットワークでは、トラフィックはリージョン内に限定されるため、複数のリージョン間での負荷分散を行うことはできません。
次に、新しいインスタンスグループを追加することで、新たにus-east-2リージョンに拡張されたインフラの配信先として認識させることができます。これにより、us-central-1とus-east-2の両リージョンで動作するインスタンスグループに、一括してリクエストが配信されるようになります。
したがって、この選択肢が最適です。
不正解についての説明：
選択肢：ロードバランサーのバックエンドの設定を、インスタンスグループの代わりにネットワークエンドポイントグループを使うように変更します
この選択肢が正しくない理由は以下の通りです。
ネットワークエンドポイントグループを使用する変更は、複数のリージョン間で単一の外部IPアドレスを設定する要件には寄与しません。
代わりに、ネットワークティアをプレミアムに変更し、新しいインスタンスグループを追加することで、世界中の任意の場所からのユーザが単一のIPアドレスを通じてアクセスできます。
選択肢：スタンダードティアのネットワークを使ってus-east-2に新しいロードバランサーを作成し、静的な外部IPアドレスを割り当てます
この選択肢が正しくない理由は以下の通りです。
新しいロードバランサーを作成した場合、それは追加の外部IPアドレスを必要とします。問題の要件は、単一の外部IPアドレスを使用することです。これはプレミアムティアのネットワークの複数リージョンをまたぐロードバランサーでのみ可能であり、新しいロードバランサーを作成することでは達成できません。
選択肢：2つのリージョン間でCloud VPN接続を作成し、Private Google Accessを有効にします
この選択肢が正しくない理由は以下の通りです。
Cloud VPN接続とPrivate Google Accessは、専用のIP接続を作成し、プライベートリソースへの安全なアクセスを提供しますが、それは単一の外部IPアドレスからどちらのリージョンにも新しいリクエストを分配するという要件とは関係ありません。これを実現するためには、プレミアムティアのネットワークを使用してロードバランサーを設定する必要があります。
参考リンク：
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address
</div></details>

### Q.  問題16: 未回答
組織は、Cloud IdentityとMicrosoft Active Directoryの同期とSAMLフェデレーションを実装しています。Google Cloudのユーザーアカウントが侵害されるリスクを軽減したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud IdentityとMicrosoft Active Directoryの同期とSAMLフェデレーションが既に実装されている前提の下、Google Cloudのユーザーアカウントが侵害されるリスクを軽減するための方法について問われています。強力なパスワードポリシーの設定と2段階認証の利用により、セキュリティリスクの軽減が可能です。ただし、Active DirectoryやCloud Identityに対するパスワードポリシーの設定の違いや、2段階認証の方法選択に注意を払う必要があります。
基本的な概念や原則：
Cloud Identity：Google CloudのIDaaS（Identity as a Service）です。ユーザーやグループ、アプリケーションなどを一元管理し、安全なアクセスとシングルサインオン（SSO）を実現します。
Microsoft Active Directory：Microsoftによるディレクトリ型のID管理サービスです。ユーザーの認証・認可を行い、ユーザーやコンピュータなどの情報を一元化して管理します。
SAMLフェデレーション：セキュリティアサートマークアップ言語（SAML）を使用して、異なるセキュリティドメイン間でのIDや認証情報を共有する仕組みです。
パスワードポリシー：パスワードの強度や有効期限、再利用の規則などを定義するためのポリシーです。適切なパスワードポリシーは、アカウント侵害のリスクを軽減します。
二段階認証：パスワードだけでなく、さらに何か（セキュリティキー、認証コードなど）を用いてユーザーを認証する方法です。アカウント侵害のリスクを軽減します。
セキュリティキー：二段階認証の一手段となる、物理的なセキュリティデバイスのことです。セキュリティキーを使用することで、認証手段の多様化を通じたセキュリティ強化が可能です。
シングルサインオン（SSO）：ユーザーが一度のログインで複数のシステムやサービスにアクセスできるようにする認証方式です。ユーザビリティの向上と管理コストの削減を実現します。
正解についての説明：
（選択肢）
・強力なパスワード設定でActive Directoryドメインのパスワードポリシーを作成し、Google Adminコンソールでセキュリティキーを使用してSSO（シングルサインオン）後の2段階認証を設定します
この選択肢が正解の理由は以下の通りです。
まず、Active Directoryの強力なパスワード設定により、ユーザーが安易なパスワードを設定し、それが原因でアカウントが侵害されるリスクを低減することができます。これにより、パスワードが強化され、初回の認証段階でアカウントが侵害される可能性が少なくなります。
次に、Google Adminコンソールでセキュリティキーを使用してSSO後の2段階認証を設定することで、ユーザーが認証された状態でSSOを通過した後でも、セキュリティキーを使用して認証を行う必要があります。これにより、ユーザーアカウントが侵害されるリスクをさらに軽減することができます。特に、SSOは便利ではありますが、SSOが侵害された場合には複数のサービスが危険に晒される可能性があるため、SSO後の2段階認証は非常に重要です。
不正解についての説明：
選択肢：強力なパスワード設定でCloud Identityパスワードポリシーを作成し、Google管理コンソールでセキュリティキーを使用して2段階認証を設定します
この選択肢が正しくない理由は以下の通りです。
組織はActive Directoryを使用しているので、パスワードポリシーはActive Directoryに設定すべきです。Cloud Identityではなく、Active Directoryでパスワードポリシーを強制することが重要です。この選択肢ではCloud Identityにパスワードポリシーを設定しているため、誤っています。
選択肢：強力なパスワード設定でCloud Identityパスワードポリシーを作成し、Google管理コンソールでテキストまたは電話による認証コードで2段階認証を設定します
この選択肢が正しくない理由は以下の通りです。
ここではフェデレーションとActive Directory同期が実装されているため、パスワードポリシーはActive Directoryで設定するのが最善です。
それに対し、この選択肢はCloud Identityでのパスワードポリシー設定を提案しており、フェデレーション環境に合っていません。
また、2段階認証のセキュリティは、セキュリティキーよりもテキストまたは電話による認証コードの方が低いため、リスクを軽減するという目的に対して不適切です。
選択肢：強力なパスワード設定でActive Directoryドメインのパスワードポリシーを作成し、Google Adminコンソールでテキストまたは電話による認証コードを使用したSSO（シングルサインオン）後の2段階認証を設定します
この選択肢が正しくない理由は以下の通りです。
テキストメッセージまたは電話による認証コードは、セキュリティキーに比べて侵害されるリスクが高いため、ユーザーアカウントのリスク軽減には不適切です。セキュリティキーは物理的なデバイスであり、侵害される可能性がずっと低いです。
参考リンク：
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-sso-saml
https://cloud.google.com/identity/docs/set-up-sso
https://support.google.com/a/answer/9176657?hl=en
</div></details>

### Q.  問題17: 未回答
ある組織が、オンプレミスにいくつかのミッションクリティカルなアプリケーションを維持しながら、アプリケーションをGoogle Cloudに移行しようとしています。この組織は、少なくとも50Gbpsの帯域幅でデータを転送する必要があります。
サイト間の安全な継続接続を確保するために、何を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、高帯域幅の安全な接続が必要なシナリオを説明しています。オンプレミスのミッションクリティカルなアプリケーションを維持しつつ、Google Cloudへのデータ転送が求められています。サイト間の継続的で安全な接続を求められているので、選択肢を見てどれが最大50Gbpsの帯域幅を提供し、一方から他方への安全な通信を確実にするかを判断する必要があります。選択肢の理解とその機能を理解することが重要です。
基本的な概念や原則：
Cloud Interconnect：Google Cloudと他のネットワーク間で、高容量・低遅延の接続を可能にするサービスです。50Gbps以上の帯域幅を持つ接続を提供します。
Cloud Router：Google Cloudのフルマネージドサービスで、ダイナミックルーティングのためにBGP（Border Gateway Protocol）を使用します。ただし、直接の接続帯域幅を提供するものではありません。
Cloud VPN：Google Cloudと他のネットワーク間にVPN（Virtual Private Network）を構築するサービスです。安全な接続を提供しますが、その帯域幅はCloud Interconnectほど大きくありません。
Partner Interconnect：Google Cloudとサービスプロバイダ間で接続を設定するサービスです。直接の接続を提供しますが、帯域幅はService Providerに依存します。
正解についての説明：
（選択肢）
・Cloud Interconnect
この選択肢が正解の理由は以下の通りです。
まず、Cloud InterconnectはGoogle Cloudとオンプレミスインフラストラクチャとの間で大規模なデータ転送を密に行うことが要求されるシチュエーションに適しています。Cloud Interconnectは低レイテンシ、高スループットの接続を提供し、特定の場合には最大200Gbpsの帯域幅をサポートします。これにより、50Gbpsの帯域幅要件をはるかに上回る能力を持っています。
さらに、Cloud Interconnectは安全な接続を提供します。物理的接続を通じてプライベートなネットワーク接続を確立することにより、データ転送中に外部のインターネットトラフィックが混在することを避けることができます。これにより、セキュリティリスクを低減し、データのプライバシーを保護します。
したがって、ミッションクリティカルなアプリケーションを維持する組織にとっては、サイト間の安全な継続接続を確保するために最適な選択肢となります。
不正解についての説明：
選択肢：Cloud Router
この選択肢が正しくない理由は以下の通りです。
Cloud Routerは主にネットワーク間のルーティング情報を交換するロールを持つものであり、帯域幅の指定は可能ではありません。
一方、Cloud InterconnectはオンプレミスとGoogle Cloud間の高速なプライベート接続を実現することが可能であり、50Gbpsの指定帯域幅も可能です。
選択肢：Cloud VPN
この選択肢が正しくない理由は以下の通りです。
Cloud VPNはサイト間の安全な接続は可能ですが最大スループットは4Gbpsまでであり、要件の50Gbpsの帯域幅を満たすことができません。
逆に、Cloud Interconnectは最大200Gbpsのスループットを提供し、要件を満たすことが可能です。
選択肢：Partner Interconnect
この選択肢が正しくない理由は以下の通りです。
Partner Interconnectはパートナーネットワークプロバイダを介した接続を提供しますが、ユーザーの制御範囲外であるため帯域幅の保証が難しいです。しかし、Cloud InterconnectはGoogle Cloud直結の高速なプライベート接続を提供し、50Gbpsの帯域幅要件を確実に満たすことができます。
参考リンク：
https://cloud.google.com/interconnect/docs/how-to/dedicated
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/interconnect/docs/concepts/overview
</div></details>

### Q.  問題18: 未回答
あなたは、厳しいデータ保護要件がある規制業界の組織に勤めています。その組織はクラウドにデータをバックアップしています。データプライバシー規制を遵守するため、このデータは特定の期間しか保存できず、特定の期間が過ぎると削除しなければなりません。
保管コストを最小限に抑えながら、この規制へのコンプライアンスを自動化したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、データ保護要件を満たしつつ保管コストを抑える手段を求めています。具体的には、バックアップデータの自動削除機能を持つストレージサービスを探すことが必要です。そのため、各選択肢が提供する機能を理解し、それが自動化の要件と互換性があるかを確認することが大切です。また、維持コストも視野に入れ、最もコスト効率の良いオプションを選ぶことが求められます。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、データバックアップ、アーカイブ、分析などの様々な用途に利用できます。データの耐久性と可用性が高いです。
オブジェクトライフサイクル管理：Cloud Storageバケットに保存されたデータオブジェクトの管理を自動化する機能です。特定の条件を満たしたオブジェクトを自動的に移行または削除できます。
永続ディスク：Google Cloudのブロックストレージサービスです。Compute Engineなどの仮想マシンと連携して利用します。
Cloud Bigtable：Google CloudのNoSQLビッグデータデータベースサービスです。読み込みと書き込みを高速に行うことができます。
BigQuery：Google Cloudの完全マネージド型エンタープライズデータウェアハウスです。大量のデータを高速に分析することができます。
正解についての説明：
（選択肢）
・データをCloud Storageバケットに保存し、バケットのオブジェクトライフサイクル管理機能を設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageは高いデータ耐久性とアクセス制御の設定が可能な優れたデータストレージサービスです。これは規制業界の組織とデータ保護要件を満たすのに適しています。しかし、問題の核心はデータが保存できる特定の期間とそれを自動化することです。それがまさにGoogle Cloud Storageのオブジェクトライフサイクル管理機能で実現可能となります。この機能を使用することで、データの保存期間や棚卸しコストについて自動的な管理を行うことができます。例えば、あらかじめ定められた期間が経過したデータを自動的に削除するルールを設定できます。これにより、データ保存の規制遵守が自動化され、適切なコンプライアンスを維持しながら、不要なデータの保管によるコスト増加も防ぐことができます。
不正解についての説明：
選択肢：データを永続ディスクに保存し、期限切れ時にディスクを削除します
この選択肢が正しくない理由は以下の通りです。
永続ディスクでデータを保存し、手動で期限切れになったディスクを削除することは、自動化の要件を満たしません。
一方、Cloud Storageバケットのオブジェクトライフサイクル管理機能を使用すると、データ保管の期間を指定し、その期間が過ぎると自動的にデータを削除することができるため、保管コストを最小限に抑えつつ規制へのコンプライアンスを自動化することが可能になります。
選択肢：Cloud Bigtableテーブルにデータを格納し、カラムファミリーに有効期限を設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Bigtableではカラムファミリーに有効期限を設定することはできますが、これはデータの自動削除を管理するためのものではなく、CellレベルのTTL（Time To Live）を設定するものです。
また、Bigtableは低コストなバックアップオプションではありません。
それに対して、Cloud Storageバケットのオブジェクトライフサイクル管理機能を設定することでデータの自動削除とコスト効率の高いデータ保管が可能になります。
選択肢：データをBigQueryのテーブルに保存し、テーブルの有効期限を設定します
この選択肢が正しくない理由は以下の通りです。
BigQueryのテーブル有効期限設定はユーザーがアクセスしない限り削除されるわけではないので、特定の期間が経ったら自動的に削除されるという要件を満たしません。
一方、Cloud Storageのオブジェクトライフサイクル管理機能を使用すれば、特定の期間が経過したデータを自動的に削除することが可能です。
参考リンク：
https://cloud.google.com/storage/docs/lifecycle
https://cloud.google.com/storage/docs/managing-lifecycles
https://cloud.google.com/storage/docs/creating-buckets
</div></details>

### Q.  問題19: 未回答
機密データを保護し、非機密データの鍵管理の複雑さを軽減する静止時暗号化戦略を実装する必要があります。ソリューションには以下の要件があります：
- 機密データの鍵ローテーションをスケジュールします。
- 機密データの暗号鍵をどの領域に保存するかを制御します。
- 機密データおよび非機密データの暗号化キーへのアクセス待ち時間を最小限に抑えます。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、機密データと非機密データを静止時に安全に暗号化しながら、鍵管理の複雑性を最小限に抑えるための戦略を決定することが求められています。要件によれば、機密データの鍵ローテーションをスケジュールし、どの領域に暗号鍵を保存するか制御する必要があり、暗号鍵へのアクセス待ち時間を最小限に抑える必要もあります。そのため、選択をする際はGoogle Cloudの各暗号化サービスがどのようにこれらの要件を満足するか、または満足しないかを理解することが重要です。また、これらの要件が同時に満たされる解決策を見つけることが求められています。
基本的な概念や原則：
Cloud Key Management Service（KMS）：暗号化キーを管理し、保管するためのフルマネージド型サービスです。鍵の生成、使用、回転、壊棄などを行うことができます。特定のデータへのアクセスをより厳密に制御するために利用されます。
Googleデフォルトの暗号化：Google Cloudでは、データはデフォルトで暗号化されます。これにより、特別な操作を行わなくてもデータの安全性を保つことができます。
鍵ローテーション：適切な時間間隔で暗号化キーを新しくすることです。これにより、同じ鍵が使われ続けて機密性が低下するのを防ぎます。
暗号鍵の保存領域の制御：タイプ、領域、保護レベルなど鍵の性質を元に保存場所を選択する必要があります。特定の領域に保存することで、データと鍵の両方に適切なアクセス制御を適用し、セキュリティを強化します。
Cloud External Key Manager：Google Cloud以外で暗号鍵を管理するためのサービスです。取り扱うデータがより高い機密性を必要とする場合や、特定のコンプライアンス要件を満たすために使用されます。
非機密データと機密データ：データの機密性により、どのような暗号化方法を取るかが異なります。非機密データはデフォルトの暗号化で保護し、機密データはより厳密な暗号化方法を用いることが一般的です。
正解についての説明：
（選択肢）
・非機密データはGoogleデフォルトの暗号化で暗号化し、機密データはCloud Key Management Serviceで暗号化します
この選択肢が正解の理由は以下の通りです。
まず、Googleデフォルトの暗号化は、セキュリティと使いやすさを両立しながら非機密データを自動的に暗号化します。この方式により、非機密データの鍵管理の複雑さが劇的に軽減され、ユーザーは変更や設定をする必要がなく、また待ち時間も発生しません。
一方、Cloud Key Management Serviceを使用すると、機密データの暗号鍵についてのより高いレベルの制御が可能になります。このサービスにより、ユーザーは暗号鍵のローテーションスケジュールを設定し、鍵を保存する地域を選択することができます。
したがって、この選択肢が提供する暗号化戦略は、指定された要件を満たし、機密データの保護と非機密データの鍵管理の簡素化を適切に提供します。
不正解についての説明：
選択肢：Cloud External Key Managerを使用して、機密性の低いデータと機密性の高いデータを暗号化します
この選択肢が正しくない理由は以下の通りです。
Cloud External Key Managerは機密データの鍵管理に役立つ一方で、非機密データの鍵管理の複雑さを増加させる可能性があり、また鍵アクセスの待ち時間も増大する可能性があります。このため、非機密データにはGoogleデフォルトの暗号化を用いるべきです。
選択肢：Cloud Key Management Serviceを使用して、機密性の低いデータと機密性の高いデータを暗号化します
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Serviceを非機密データにも使用すると、鍵管理の複雑さが増すため、要件を満たせません。非機密データの場合、Googleデフォルトの暗号化を用いることで鍵管理の手間を省くことができます。
選択肢：機密性の低いデータはGoogleデフォルトの暗号化で暗号化し、機密性の高いデータはCloud External Key Managerで暗号化します
この選択肢が正しくない理由は以下の通りです。
Cloud External Key Managerは、Google Cloud外部にキーを保管するためのものであり、キーへのアクセス待ち時間が増加し、質問の要件"暗号化キーへのアクセス待ち時間を最小限に抑えます"を満たしません。
一方、Cloud Key Management ServiceではキーはGoogle Cloud内に保存されるため、アクセス待ち時間が短くなります。
参考リンク：
https://cloud.google.com/kms/docs/encrypting-data
https://cloud.google.com/security/encryption-at-rest/default-encryption
https://cloud.google.com/kms/docs/rotating-keys
</div></details>

### Q.  問題20: 未回答
あなたは、Google Cloud内でアプリケーションデータ（転送中のデータ、使用中のデータ、および静止状態のデータを含む）のエンドツーエンドの暗号化を必要とするクライアントの相談を受けています。
これを達成するために、どのオプションを利用すべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud内でアプリケーションデータの全体的な暗号化について問われています。問題中には転送中のデータ、使用中のデータ、および静止状態のデータを暗号化する必要があると明記されます。エンドツーエンドのデータ暗号化を実現するために、全データのライフサイクル（作成、操作、休止）をカバーする選択肢を選ぶことが求められます。そして、ここでは2つの正解を選択するという条件も忘れてはいけません。
基本的な概念や原則：
Confidential Computing：Google Cloudのサービスで、データが転送中も、使用中も、静止状態でも暗号化され、機密性が保たれます。これにより、第三者やシステム管理者からの不正アクセスを防ぐことが可能です。
Istio：オープンソースのサービスメッシュで、マイクロサービス間の通信を管理、保護、監視することができます。エンドツーエンドの暗号化通信を実現します。
クライアント側の暗号化：データがGoogle Cloudに送信される前に、ユーザーのローカル環境でデータを暗号化する手法です。データの保護レベルを高めることができます。
External Key Manager：Google Cloudのリソースを暗号化するための鍵を、Googleのインフラストラクチャ外部で管理するサービスです。
顧客指定の暗号化キー：Google Cloud上のリソースを暗号化するための鍵を、顧客自身が生成し管理するサービスです。
Cloud HSM：Google CloudのCloud HSM（HSM）サービスで、暗号鍵の保護と管理を行うためのクラウドベースのサービスです。
正解についての説明：
（選択肢）
・Confidential ComputingとIstio
・クライアント側の暗号化
この選択肢が正解の理由は以下の通りです。
まず、Confidential ComputingはGoogle Cloud内でデータを扱う際に、それが使用中であっても暗号化されることを保証します。従来、データは転送中や静止状態では暗号化することができましたが、そのデータを処理するときにはデータを暗号化解除する必要がありました。しかし、Confidential Computingによりデータは使用中も暗号化され、データの使用中のセキュリティを保つことが可能になります。
次に、Istioはサービスメッシュとして機能し、ミドルウェアとして複数のマイクロサービス間での通信を制御します。これにより、アプリケーションのデータが転送中も保護されます。Istioは、通信内容の暗号化や認証、トラフィック制御などの機能を持ち、データを安全にやり取りすることが可能です。
最後に、クライアント側の暗号化は、データがクラウドに送られる前にすでに暗号化されている状態を指します。これにより、アップロードされるデータが静止状態のときも暗号化された状態を保つことができます。
これらの組み合わせにより、データが転送中、使用中、静止状態のいずれであっても、エンドツーエンドの暗号化を達成することが可能です。
不正解についての説明：
選択肢：External Key Manager
この選択肢が正しくない理由は以下の通りです。
External Key Managerは暗号化キーをGoogle Cloudの外部で管理するためのサービスで、それ自体がデータのエンドツーエンドの暗号化を提供するものではありません。
一方、Confidential ComputingとIstioはデータの暗号化を提供し、クライアント側の暗号化もエンドツーエンドの保護を提供します。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キーは静止状態のデータの暗号化に対するコントロールを提供しますが、転送中や使用中のデータに対する暗号化はサポートしていません。
一方、Confidential ComputingとIstio、クライアント側の暗号化はそれぞれ使用中、転送中、静止状態のデータの暗号化をサポートします。
選択肢：Cloud HSM
この選択肢が正しくない理由は以下の通りです。
Cloud HSMは強力なCloud HSMで、暗号鍵操作を安全に実行できますが、エンドツーエンドのデータ暗号化を自動的に提供するものではありません。
一方で、IstioとConfidential Computingは通信を保護し、クライアント側暗号化は使用中および静止状態のデータを保護します。
参考リンク：
https://cloud.google.com/security/confidential-computing
https://cloud.google.com/istio/docs/istio-on-gke/overview
https://cloud.google.com/kms/docs/encryption-at-rest-concepts
</div></details>

### Q.  問題21: 未回答
あなたの組織は新しいワークロードを取得しました。Webおよびアプリケーション（App）サーバーは、新しく作成されたカスタムVPC内のCompute Engine上で実行されます。あなたは、以下の要件を満たすセキュアなネットワーク通信ソリューションを構成する責任を負っています：
- Web層とApp層間の通信のみを許可します。
- Web層とApp層のオートスケール時に一貫したネットワークセキュリティを強制します。
- Compute Engineインスタンス管理者がネットワークトラフィックを変更できないようにする必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、新しいワークロードのためにCompute Engine上で実行されるWebサーバーとAppサーバー間の通信をセキュアに管理する方法について問われています。重要な要件として、Web層とApp層間の通信のみを許可し、ネットワークトラフィックの管理をCompute Engineインスタンスの管理者から制限する必要があります。これは、セキュリティの強化が求められており、各層の通信の許可や禁止を正確に管理して、オートスケール時にも一貫性のあるセキュリティを確保する必要があることを示しています。これを解決するためには、適切なサービスアカウントとVPCファイアウォールルールの設定が鍵となります。
基本的な概念や原則：
VPC（Virtual Private Cloud）：Google Cloud内で定義されたプライベートネットワーク空間です。VPCを利用することで、自分だけの分離されたネットワーク環境を作成し、ネットワークの設定や制御を柔軟に行うことができます。
Compute Engine：Google Cloudのインフラストラクチャインスタンスサービスです。仮想マシンを短時間や長時間、大量あるいは少量作成することができます。
サービスアカウント：Google CloudのAPIを使用するアプリケーションを認証するための特殊なアカウントです。サーバ間での認証や権限管理に使用されます。
インスタンステンプレート：Compute Engineの仮想マシンの設定を再利用し、新たなインスタンスを効率的に作成するためのテンプレートです。オートスケーリングなどのシナリオで構成の一貫性を保つために使用されます。
VPCファイアウォールルール：ネットワーク内のトラフィックのフィルタリングを行う際のルールを定義します。特定のネットワークやインスタンスに対して通信を許可または拒否する動作を制御するのに使用します。
ネットワークタグ：Google Cloudのリソースに紐づけることができるラベルのこと。ネットワークタグを利用し、ファイアウォールルールやルーティングルールに紐づけることで、柔軟なネットワークの管理が可能になります。
オートスケーリング：負荷に応じて自動的にリソース数を増減する機能です。コスト効率の改善やパフォーマンスの最適化に寄与します。
正解についての説明：
（選択肢）
・1.それぞれのサービスアカウントで構成されたインスタンステンプレートを使用して、WebサーバーとAppサーバーを再デプロイします
2.それぞれのサービスアカウントでターゲット/ソースを指定する許可VPCファイアウォールルールを作成します
この選択肢が正解の理由は以下の通りです。
まず、セキュリティを強化するためには、各層（Web層とApp層）で異なるサービスアカウントを使用することが推奨されます。サービスアカウントは、特定のリソース（このケースではCompute Engineインスタンス）に、そのリソースがアクセスできるリソースと操作の許可を与えることで、ロールベースのアクセス制御（RBAC）を実装します。この方法で、各インスタンステンプレートは特定のサービスアカウントを使用します。そのため、オートスケーリング時でもそれぞれのインスタンスは一貫したアクセス制御ポリシーを持つことになります。
次に、VPCファイアウォールルールを使用してWeb層とApp層間の通信だけを許可します。前述したサービスアカウントに基づいてファイアウォールルールを適用します。これにより、Compute Engineインスタンスの管理者がネットワークトラフィックを変更できないように制限し、ネットワークセキュリティを強制することができます。
不正解についての説明：
選択肢：1.実行中のすべてのWebサーバーとAppサーバーに、それぞれのネットワークタグを設定します
2.それぞれのネットワークタグでターゲット/ソースを指定する許可VPCファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
ネットワークタグを使用すると、Compute Engineインスタンスの管理者がルールを変更する可能性があるため、最終的にはセキュリティ要件を満たさない可能性があります。
一方、サービスアカウントを使用すると、インスタンスを管理する能力を限定し、セキュリティ要件を満たすことができます。
選択肢：1.実行中のすべてのWebサーバーとAppサーバーに、それぞれのサービスアカウントを設定します
2.それぞれのサービスアカウントでターゲット/ソースを指定する許可VPCファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
実行中のインスタンスにサービスアカウントを後から設定することはできません。新たにサービスアカウントを設定するためにはインスタンスを再デプロイする必要があります。それに対して正解の選択肢では、インスタンステンプレートを使用して新たにサービスアカウントを適用したインスタンスをデプロイする方法が示されており、要件を満たします。
選択肢：1.それぞれのネットワークタグで構成されたインスタンステンプレートを使用して、WebサーバーとAppサーバーを再デプロイします
2.それぞれのネットワークタグでターゲット/ソースを指定する許可VPCファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
ネットワークタグはCompute Engineインスタンス管理者によって変更が可能です。そのため、この選択肢では"Compute Engineインスタンス管理者がネットワークトラフィックを変更できないようにする"という要件を満たすことができません。
一方、正解の選択肢ではサービスアカウントはIAMロールにより権限が制御されるためこの要件を満たします。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/compute/docs/instances/service-accounts
https://cloud.google.com/compute/docs/instance-templates
</div></details>

### Q.  問題22: 未回答
ある企業が、ミッションクリティカルなアプリケーションのコンテナイメージでGoogle Kubernetes Engine（GKE）を使用しています。この企業は、既知のセキュリティ問題についてイメージをスキャンし、Google Cloudの外部に公開することなく、レポートをセキュリティチームと安全に共有したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ミッションクリティカルなアプリケーションのセキュリティを維持しつつ、セキュリティレポートを適切に共有する適切なGoogle Cloudの機能やサービスを選ぶことが求められています。問題指定から、コンテナイメージに対してスキャンを行う必要があり、結果を企業外部に公開せずにセキュリティチームと共有しなければならないことが分かります。したがって、コンテナ象限のセキュリティの最適な管理と、結果の適切なアクセス制御や共有が解答の鍵となります。それらを満たすための適切なGoogle Cloudサービスとその設定方法を選びましょう。
基本的な概念や原則：
Artifact Registry：Google Cloudの統合アーティファクト管理サービスです。Dockerイメージや他の種類のアーティファクトを安全に保存し、共有することができます。また、脆弱性スキャンも可能です。
Google Kubernetes Engine（GKE）：Google Cloudのマネージドサービスです。Kubernetesクラスターを管理し、ワークロードをデプロイ、スケーリング、更新するのを簡単にします。
Cloud Build：Google Cloudのビルドサービスです。ユーザーは、CI/CDパイプラインを使ってソースコードからコンテナイメージをビルドし、Artifact Registry等にプッシュすることができます。
Security Command Center：Google Cloudのセキュリティとリスク管理プラットフォームです。Google Cloudのリソースの脆弱性や脅威を検出し、リスクを可視化・評価することができます。
Container Threat Detection：Security Command Centerの機能で、Google Cloudにデプロイされたコンテナのランタイムセキュリティ問題を検出します。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。gsutilツールを使ってデータをアップロードダウンロードすることが可能です。
GitHub：ソースコードのバージョン管理と共有サービスです。外部サービスとしてセキュリティの管理が必要となります。
正解についての説明：
（選択肢）
・1. Artifact Registry設定で脆弱性スキャンを有効にします
2. Cloud Buildを使用してイメージをビルドします
3. 自動スキャンのためにイメージをArtifact Registryにプッシュします
4. Artifact Registryのレポートを表示します
この選択肢が正解の理由は以下の通りです。
Artifact Registryは、Google Cloudが提供するパッケージ管理サービスであり、コンテナイメージを含む多種多様なアーティファクトを保存、管理することが可能です。すべてのイメージは、保存される際に自動的に脆弱性スキャンされ、結果はレポートとして提供されます。これにより、セキュリティチームは常に最新のセキュリティ状況を確認することができます。このレポートは、Google Cloudの内部で生成・管理され、第三者に公開されることはありません。
また、Cloud Buildは継続的統合（CI）と継続的デプロイ（CD）のためのサービスであり、ここではミッションクリティカルなアプリケーションのイメージのビルドを行います。その後、ビルドしたイメージはArtifact Registryにプッシュされ、脆弱性スキャンが自動的に行われます。Artifact Registryを用いることによって、コンテナイメージの管理とセキュリティの課題を一元的に解決することが可能です。
不正解についての説明：
選択肢：1. Security Command CenterプレミアムレベルでContainer Threat Detectionを有効にします
2. サポートされているバージョンのGKEにないすべてのクラスターを、可能な最新のGKEバージョンにアップグレードします
3. Security Command Centerからの結果を表示して共有します
この選択肢が正しくない理由は以下の通りです。
Security Command CenterのContainer Threat Detectionはランタイムの脅威の検出に使用され、コンテナイメージの脆弱性スキャンには適していません。
また、GKEを最新バージョンにアップグレードすることでセキュリティ問題を解決するとは限らず、脆弱性を具体的にスキャンし、結果を共有する正解のセットとは異なるアプローチです。
選択肢：1. Cloud Buildのオープンソースツールを使用してイメージをスキャンします
2. gsutilを使用して、Cloud Storage内の一般にアクセス可能なバケットにレポートをアップロードします
3. スキャンレポートのリンクをセキュリティ部門と共有します
この選択肢が正しくない理由は以下の通りです。
まず、Cloud Storageの一般公開バケットにレポートをアップロードすると、外部からアクセス可能になり、セキュリティの観点から不適切です。
それに対して、正解の選択肢ではArtifact Registryを利用しているので、この問題は発生しません。
また、Cloud Buildのツールを使うとセキュリティスキャンの範囲が限定的になりますが、Artifact Registryを使うと広範な脆弱性スキャンが行えます。
選択肢：1. GitHubサブスクリプションを取得します
2. Cloud Buildでイメージをビルドし、自動スキャンのためにGitHubに保存します
3. GitHubからレポートをダウンロードし、セキュリティチームと共有します
この選択肢が正しくない理由は以下の通りです。
GitHubはGoogle Cloudプロダクトではなく、Google Cloud環境の外部に存在します。Google Cloudの外部にイメージを公開することなくセキュリティ問題についてスキャンし、レポートをセキュリティチームと共有したい企業の要件を満たすために、GitHubサブスクリプションを取得し、Cloud BuildでビルドしたイメージをGitHubに保存することは適切ではありません。
参考リンク：
https://cloud.google.com/artifact-registry/docs/container-analysis
https://cloud.google.com/container-analysis/docs/vulnerability-scanning
https://cloud.google.com/build/docs/building/build-containers
</div></details>

### Q.  問題23: 未回答
フロントエンドがサブネットAのマネージドインスタンスグループにデプロイされ、データレイヤーが同じVPC上のサブネットBにあるmysql Compute Engine仮想マシン（VM）に保存されているアプリケーションがあります。サブネットAとサブネットBには、他にもいくつかのCompute Engine VMがあります。アプリケーションのフロントエンドだけがポート3306でアプリケーションのmysqlインスタンスのデータにアクセスできるようにしたいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のアプリケーションのフロントエンドからデータレイヤーへのポート3306での通信を調整する方法について問われています。ここで重要なのは、フロントエンドとデータレイヤーが同一のVPC内の異なるサブネットに配置されているという状況と、フロントエンドだけがmysqlインスタンスのデータにアクセスできるようにしたいという要件です。これを達成するためには、適切なファイアウォールルールの設定が必要であり、Google Cloudのサービスアカウントを利用して通信を制限する方法を考える必要があります。この結果、サブネットやタグ指定ではなく、サービスアカウントを使用して特定の通信だけを許可する方法を選択することが必要になります。
基本的な概念や原則：
VPC（Virtual Private Cloud）：Google Cloud上で仮想的なプライベートネットワーク環境を構成する機能です。ネットワーク内でのリソースの通信を自由に設定することができます。
サブネット：VPC内のネットワークをさらに細かく分割したもので、異なるサブネット間通信は設定により制御可能です。
Compute Engine VM（Virtual Machine）：Google CloudのIaaS（Infrastructure as a Service）で提供される仮想マシンのサービスです。
マネージドインスタンスグループ：Compute Engine VMをグループ化し、スケーリングやバランシングなどの機能を一元管理できるサービスです。
ファイアウォールルール：ネットワークのセキュリティを管理するためのルールで、特定のポートやIP範囲からの通信を許可または拒否できます。
サービスアカウント：アプリケーションがGoogle Cloud APIを呼び出すための特殊なアカウントで、リソースへのアクセス権を制御するために使用されます。
タグ：Google Cloudリソースに追加できるメタデータの一種で、ファイアウォールルールやロードバランサーなどと組み合わせてリソースの管理を行うことができます。
正解についての説明：
（選択肢）
・ポート3306で、フロントエンドの固有サービスアカウントからmysql Compute Engine VMの固有サービスアカウントへの通信を許可するインバウンドファイアウォールルールを構成します
この選択肢が正解の理由は以下の通りです。
まず、構成で考慮すべきポイントはフロントエンドのインスタンスからmysql Compute Engine VMへの特定のポート（3306）を通じたアクセスの許可であり、この目的を達成する最も直接的で効果的な方法は、インバウンドファイアウォールルールの構成です。これにより、指定されたポートへの特定のサービスアカウントからの通信を正確に制御できます。
また、固有のサービスアカウントをフロントエンドとmysql Compute Engine VMに適応させることで、他のCompute Engine VMインスタンスからmysqlのデータにアクセスする可能性を大幅に減らし、アクセスを必要とする特定のインスタンスのみに限定できます。これにより、データのセキュリティとプライバシーが向上します。
したがって、この選択肢はアプリケーションの要求を満たし、データのアクセスを制限し、セキュリティを強化するための最適な解決策となります。
不正解についての説明：
選択肢：サブネットAのsrc IPレンジから、ポート3306のmysql Compute Engine VMに適用されるタグ "data-tag"への通信を許可するインバウンドファイアウォールルールを設定します
この選択肢が正しくない理由は以下の通りです。
サブネットAのsrc IPレンジは、フロントエンドだけでなく、そのサブネット内の他のVMも含まれるため、すべてのVMがmysqlインスタンスにアクセスできるようにします。これは問題の要件、すなわち"フロントエンドだけがmysqlインスタンスのデータにアクセスできるようにする" を満たしていません。指定の"固有のサービスアカウント"を使用した場合、特定のフロントエンドインスタンスのみがデータにアクセスできるように制御できます。
選択肢：data-tagでタグ付けされたCompute Engine VMから、fe-tagでタグ付けされた宛先のCompute Engine VMへの通信を許可するアウトバウンドファイアウォールルールを設定します
この選択肢が正しくない理由は以下の通りです。
アウトバウンドルールはインターネットや他のネットワークへの通信を制御しますが、ファイアウォールルールでは同一ネットワーク内のマシーン間通信の制御はできません。同一ネットワークのインスタンス間の通信を制御するために、インバウンドルールを設定する必要があります。
選択肢：fe-tagでタグ付けされたCompute Engine VMから、data-tagでタグ付けされた宛先のCompute Engine VMへの通信を許可するインバウンドファイアウォールルールを設定します
この選択肢が正しくない理由は以下の通りです。
タグベースのファイアウォールルールでは、特定のサービスやアプリケーション間の通信に限定することは困難です。サブネットAとBにいくつかのCompute Engine VMがある場合、他のVMも同じポートでの通信が可能になってしまいます。そのため、制限を強化するためには、特定のサービスアカウント間の通信を許可する設定が適しています。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/compute/docs/instances/managing-instance-access
https://cloud.google.com/iam/docs/understanding-service-accounts
</div></details>

### Q.  問題24: 未回答
ユーザーの代わりにユーザーのGoogle Driveにアクセスする必要がある、社内のApp Engineアプリケーションを作成しています。あなたの会社は、現在のユーザーの認証情報に依存したくありません。また、Googleが推奨するプラクティスにも従いたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ユーザーのGoogle DriveにアクセスするApp Engineアプリケーションを作成する際の認証に関する戦略を理解することが求められています。まず、現在のユーザーの認証情報に依存しない方法を探す必要があることと、Googleの推奨するプラクティスに従うことが要件となっています。したがって、この問題を解くためには、Googleの認証とアクセス制御に関する推奨するプラクティスとサービスアカウントについての理解が必要です。また、ユーザーのユーザーを偽装する方法やG Suiteドメイン全体の委任に関する知識も重要です。
基本的な概念や原則：
サービスアカウント：Google Cloudで使用される特殊な種類のアカウントで、あるアプリケーションが他のGoogle Cloudリソースと通信するために使用されます。
G Suiteドメイン全体の委任：Google Workspace（旧G Suite）のサービスアカウントが、特定のユーザーに代わって操作を実行する権限を得るための設定です。
ユーザー偽装（ユーザー代行）：サービスアカウントが特定のユーザーに代わって操作を実行することです。ユーザーの認証情報に依存せずに、ユーザーのデータに対するAPIのリクエストを行うことができます。
Service Account Userロール：サービスアカウントを代行してアクションを実行するための権限を持つロールです。
G Suite管理者アカウント：Google Workspaceの管理を担当するアカウントです。高い権限を持ち、組織全体の設定を変更することが可能です。
正解についての説明：
（選択肢）
・新しいサービスアカウントを作成し、G Suiteドメイン全体の委任を付与します。アプリケーションに、このアカウントを使用してユーザーを偽装させます
この選択肢が正解の理由は以下の通りです。
まず、Googleではサービスアカウントを使用してアプリケーションに認証と認可の情報を提供します。サービスアカウントは特定のアプリケーション名で、そのアプリケーションがGoogleサービスにアクセスするための認証情報を持つように設計されています。これにより、個々のユーザー認証情報に依存することなく、アプリケーションがGoogleサービスに安全にアクセスできます。そのため、この選択肢はユーザー認証情報に依存しない要件を満たすことができます。
また、ドメイン全体の委任を付与することで、App EngineアプリケーションがユーザーのGoogle Driveにアクセスするための権限を得ることができます。
最後に、ユーザーを偽装させることで、アプリケーションが特定のユーザーとして行動し、そのユーザーのGoogle Driveのデータにアクセスすることが可能になります。これらの理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：新しいサービスアカウントを作成し、すべてのアプリケーションユーザーにService Account Userロールを与えます
この選択肢が正しくない理由は以下の通りです。
すべてのアプリケーションユーザーにService Account Userロールを与えると、ユーザーはサービスアカウントを使用して資源にアクセスできますが、特定のユーザーとして偽装することはできません。
一方、G Suiteドメイン全体の委任を付与すれば、アプリケーションは特定のユーザーとして偽装でき、そのユーザーのDriveにアクセスできます。
選択肢：新しいサービスアカウントを作成し、すべてのアプリケーションユーザーをGoogleグループに追加します。このグループにService Account Userロールを与えます
この選択肢が正しくない理由は以下の通りです。
サービスアカウントを作成し、すべてのアプリケーションユーザーをGoogleグループに追加し、Service Account Userロールを与えるという方法は、ユーザーのGoogle Driveにアクセスするリソースレベルの委任を実現できません。
これに対し、正解の選択肢では、G Suiteドメイン全体の委任を使用してユーザーを偽装することで、ユーザーがアクセス権を持つ各リソースへのアクセスが可能になる解決策が提供されています。
選択肢：専用のG Suite管理者アカウントを使用し、このG Suite資格情報でアプリケーションの操作を認証します
この選択肢が正しくない理由は以下の通りです。
専用のG Suite管理者アカウントを使用する方法は、現在のユーザーの認証情報に依存するため、問題の要件を満たしません。
これに対して、サービスアカウントを使用しG Suiteドメイン全体の委任を付与することで、ユーザーの認証情報に依存せずにユーザーのGoogle Driveにアクセスすることが可能になります。
参考リンク：
https://cloud.google.com/iam/docs/understanding-service-accounts
https://cloud.google.com/iam/docs/impersonating-service-accounts
https://developers.google.com/identity/protocols/oauth2/service-account#delegatingauthority
</div></details>

### Q.  問題25: 未回答
IaaSのセキュリティ責任共有モデルでは、顧客はスタックのどの2つのレイヤーの責任を共有しますか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、IaaS（Infrastructure as a Service）のセキュリティ責任共有モデルに関して、どの2つのレイヤーにおいて顧客が責任を負うのかを特定する必要があります。IaaSサービス提供者と顧客との間でどのセキュリティ要素が共有され、一方でどの要素がサービスプロバイダーの責任であるのか、その知識を基に選択肢を評価します。また、IaaS環境において顧客が直接制御や管理しないものは、顧客責任の範囲外と捉えるべきです。
基本的な概念や原則：
IaaSのセキュリティ責任共有モデル：クラウドサービスプロバイダー（CSP）とお客様がセキュリティ責任を共有するモデルです。CSPは基盤のセキュリティ（物理的なデータセンターやネットワーク）を、お客様はそれ以外（採用したOSやアプリケーションのセキュリティ）を管理します。
ネットワークセキュリティ：ネットワーク内の情報資産を不正アクセスや脅威から守るための手段です。ファイアウォールの設定、NATの適用などが含まれます。
アクセスポリシー：特定のリソースへのアクセスを許可する、または拒否するための規則です。IAM（Identity and Access Management）ロールやポリシーを設定し、特定のユーザー、ユーザーグループ、またはサービスに対するアクセス権を制御します。
ハードウェア：IaaS上では、ハードウェアの管理はCSPが担当します。物理的なデバイスの管理、メンテナンス、更新を含みます。
ストレージ暗号化：ストレージに保存されるデータを暗号化し、不正利用や漏洩から保護する手段です。これもCSPの責任範囲内と考えることが多いです。
正解についての説明：
（選択肢）
・ネットワークセキュリティ
・アクセスポリシー
この選択肢が正解の理由は以下の通りです。
IaaS（Infrastructure as a Service）のセキュリティ責任共有モデルでは、基礎となる物理的なインフラストラクチャはプロバイダーによって管理されますが、コンピューティングリソースとその上で動作するアプリケーションに対するセキュリティは顧客の責任となります。これは、ネットワークセキュリティとアクセスポリシーの2つのレイヤーを含みます。
ネットワークセキュリティについては、顧客は自己のVMでのトラフィックの流れを管理・制御する責任があります。これには、ファイアウォールの設定やネットワークACLsなど、ネットワークレベルでのセキュリティ設定が含まれます。
また、アクセスポリシーについては、顧客は自身のリソースへのアクセスを適切に管理・制御する責任があります。これは誰が何を行うことができるかを定義するためのポリシーを設定することおよびその運用を含みます。
したがって、IaaSのセキュリティ責任共有モデルでは、ネットワークセキュリティとアクセスポリシーが顧客の共有責任となり、正解の選択肢となります。
不正解についての説明：
選択肢：ハードウェア
この選択肢が正しくない理由は以下の通りです。
IaaSのセキュリティ責任共有モデルでは、プロバイダがハードウェアについてのセキュリティを確保するのが一般的です。
一方、ネットワークセキュリティやアクセスポリシーは顧客の責任範囲であり、これらは顧客が設定や管理を行うべき項目です。
選択肢：ストレージの暗号化
この選択肢が正しくない理由は以下の通りです。
IaaSではプロバイダが基盤を提供し、その上で顧客がセキュリティ対策を行う必要がありますが、ストレージの暗号化は基盤の一部であり、プロバイダの責任範囲内です。ネットワークセキュリティやアクセスポリシーは顧客が設定する部分であり、これらの責任を顧客が共有します。
選択肢：ブート
この選択肢が正しくない理由は以下の通りです。
ブートは基本的なコンピューティングプロセスの一部で、オペレーティングシステムを起動するプロセスを指しますが、これはIaaSプロバイダが提供する範囲であり、顧客の責任範囲外です。
一方、ネットワークセキュリティとアクセスポリシーは、クラウドサービスを利用する上で顧客が設定し管理すべき項目であるため、IaaSのセキュリティ責任共有モデルに含まれます。
参考リンク：
https://cloud.google.com/security/foundation
https://cloud.google.com/iam/docs
https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html
</div></details>

### Q.  問題26: 未回答
Google Cloud上に多数のプライベート仮想マシンがあります。リモートからSSH（Secure Socket Shell）を使用してサーバーを管理する必要があります。あなたは、セキュリティとコスト効率を最適化する方法でサーバへのリモートアクセスを構成したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud上の仮想マシンに対しSSHを用いたリモートでの管理の実現手段を問われています。重要なのは、その手段がセキュリティとコスト効率の両面で最適化されていなければならないという点です。よって、選択肢を見る際には、それぞれがどのようにセキュリティを確保し、コスト面でどれだけ効率的かを考慮し、その中で最適と言える手段を選ぶべきです。
基本的な概念や原則：
Identity-Aware Proxy（IAP）：Google Cloudのサービスで、ユーザーの認証とコンテキストに基づくアクセス制御を提供します。VPNや専用のハードウェアなしで、安全なリモートアクセスを実現できます。
ファイアウォールルール：ネットワークの安全性を確保するための規則です。特定のIP範囲からのアクセスの許可や拒否を設定できます。
ロールベースのアクセス制御：特定のロールに基づいてユーザーやサービスへのアクセスを制御するセキュリティ戦略です。IAPで保護されたトンネルユーザーのロールを管理者に付与する事で、SSHアクセスを許可することができます。
サイト間VPN：2つのネットワーク間を安全に接続するための仮想的なプライベートネットワークです。しかし、設定が複雑でコストがかかるため、リモートアクセスの設定には最適化されていません。
パブリックIPアドレス：インターネット上で一意に識別可能なIPアドレスです。しかし、パブリックIPアドレスを持つサーバーインスタンスは、外部からの不正アクセスのリスクがあります。
ジャンプホスト：一般的には、他のすべてのマシンへのアクセスポイントとなる中間的なホストです。しかし、この方法は管理が難しく、セキュリティリスクが高まる可能性があります。
正解についての説明：
（選択肢）
・Identity-Aware Proxy（IAP）IP範囲からのアクセスを許可するファイアウォールルールを 作成します。IAPで保護されたトンネルユーザーのロールを管理者に付与します
この選択肢が正解の理由は以下の通りです。
まず、Identity-Aware Proxy（IAP）の使用は、SSH接続を通じて仮想マシンに安全にアクセスするための効果的な手段です。IAPはGoogle Cloud Identityと統合し、使用者の個々の認証と承認を実行します。これにより、公開サーバーやVPNへの依存を無くし、セキュリティ効率を向上させることが可能になります。
また、IAPへのアクセスを許可するファイアウォールルールを作成することで、信頼されたIP範囲からの接続のみを許可します。これにより不要なトラフィックを排除し、セキュリティが強化されます。
さらに、IAPで保護されたトンネルユーザーのロールを管理者に付与することで、リモートからのサーバー管理を効果的に実現します。これは、資格情報をマネージメントし、端末アクセスを管理者に制限することによってコスト効率とセキュリティをより一層最適化します。
不正解についての説明：
選択肢：企業ネットワークからGoogle Cloudへのサイト間VPNを作成します
この選択肢が正しくない理由は以下の通りです。
企業ネットワークからGoogle Cloudへのサイト間VPNを作成すると、セキュリティは確保できますが、コスト効率が低くなる可能性があります。
一方、Identity-Aware Proxy（IAP）を使用すれば、ユーザーやグループに基づいてアクセス制御を行うことができ、コスト効率も良好です。
選択肢：パブリックIPアドレスを持つサーバーインスタンスを構成します。企業IPからのトラフィックのみを許可するファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
パブリックIPアドレスを持つサーバーインスタンスはコストとセキュリティの面で不利で、静的なパブリックIPは料金が発生し、公開されるため攻撃の対象となり得ます。
一方、Identity-Aware Proxy（IAP）はGoogle Cloudの認証を使用するためセキュリティが強化されますし、クラウド内での通信は無料であるためコスト効率も高まります。
選択肢：パブリックIPを持つジャンプホストインスタンスを作成します。ジャンプホストから接続してインスタンスを管理します
この選択肢が正しくない理由は以下の通りです。
ジャンプホストを使用すると、セキュリティが低下し、不正なアクセスのリスクが増加します。
また、ジャンプホストには追加のコストがかかるため、コスト効率も低下します。
それに対して、IAPを使用すれば、追加のコストなしでセキュアなアクセスを実現でき、セキュリティとコスト効率を最適化します。
参考リンク：
https://cloud.google.com/iap/docs/using-tcp-forwarding
https://cloud.google.com/vpc/docs/using-firewalls
https://cloud.google.com/compute/docs/instances/connecting-advanced#identity-aware-proxy
</div></details>

### Q.  問題27: 未回答
ある企業が、専用サーバールームでワークロードを実行しています。これらのワークロードには、社内のプライベートネットワークからのみアクセスできる必要があります。あなたは、Google Cloudプロジェクト内のCompute Engineインスタンスからこれらのワークロードに接続する必要があります。
要件を満たすためにどの2つのアプローチを取ることができますか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、企業のローカルネットワークとGoogle Cloudプロジェクト間の接続方法について問われています。問題文のキーポイントは、社内ネットワークからのみアクセス可能である要請、そしてGoogle CloudのCompute Engineインスタンスを用いる要件です。各選択肢を見て、これらの特性と要件を満たすものを選ぶことが求められます。ただし、Google Cloudのネットワークの仕組みや各選択肢が何を意味するのか、よく理解していないと見当違いの選択肢を選ぶ可能性がありますので注意が必要です。
基本的な概念や原則：
Cloud VPN：Google Cloudとオンプレミスネットワーク間の安全な接続を提供するフルマネージドのIPsec VPNソリューションです。プライベートネットワークの拡張やハイブリッドクラウド設定に使用します。
Cloud Interconnect：Google Cloudと自社インフラストラクチャ間の専用の物理的接続を提供します。高スループットの要求に対応し、ネットワークの信頼性とパフォーマンスを向上させます。
共有VPC：複数のGoogle Cloudプロジェクト間で単一のVPCネットワークを共有する機能です。ただし、オンプレミスのプライベートネットワークとの接続には使用しません。
VPCピアリング：Google Cloudの異なるプロジェクト間や異なるVPCネットワーク間で通信を許可する機能です。ただし、オンプレミスのプライベートネットワークとの接続には使用しません。
Private Access：Google Cloudのサービスに対してVPCネットワークからプライベートIPアドレスを使用してアクセスする機能です。ただし、オンプレミスのプライベートネットワークとの接続には使用しません。
正解についての説明：
（選択肢）
・Cloud VPNでプロジェクトを構成します
・Cloud Interconnectでプロジェクトを構成します
この選択肢が正解の理由は以下の通りです。
まず、Cloud VPNはプライベートネットワークとGoogle Cloudとの間にVPN（仮想プライベートネットワーク）接続を確立するサービスであり、Compute Engineインスタンスから企業内部のプライベートネットワークに安全に接続するのに最適です。既存のネットワークとGoogle Cloudとを安全な接続でリンクし、仮想的に同一ネットワーク上にあるかのように操作できます。
したがって、Cloud VPNは社内のプライベートネットワークからのみアクセス可能なワークロードへの接続要件を満たします。
一方、Cloud Interconnectは、Google Cloudとオンプレミスのデータセンターまたは他のネットワーク間での大量のデータ通信を高速かつ安全に行うためのサービスで、専用の接続を提供します。Compute Engineインスタンスから社内のワークロードへの高速な接続が必要な場合には、Cloud Interconnectを使用します。つまり、Cloud Interconnectも同様に社内のプライベートネットワークからのみアクセス可能なワークロードへの接続要件を満たします。
したがって、これらの2つの選択肢が正解となります。
不正解についての説明：
選択肢：共有VPCでプロジェクトを構成します
この選択肢が正しくない理由は以下の通りです。
共有VPCは、同一組織内の複数のGoogle Cloudプロジェクト間でネットワークを共有するためのものであり、社内のプライベートネットワークとGoogle Cloudプロジェクト間の接続を担保する機能はありません。
それに対して、Cloud VPNやCloud Interconnectは社内ネットワークとGoogle Cloudとの安全な接続を提供します。
選択肢：VPCピアリングでプロジェクトを構成します
この選択肢が正しくない理由は以下の通りです。
VPCピアリングは、2つのGoogle Cloudプロジェクト間または同じプロジェクト内のVPCネットワーク間でネットワーク接続を行うためのサービスで、企業内部のプライベートネットワークとの接続には用いられません。要件のように社内ネットワークとGoogle Cloudをセキュアに接続するために、Cloud VPNやCloud Interconnectの使用が適切です。
選択肢：すべてのCompute EngineインスタンスをPrivate Accessで構成します
この選択肢が正しくない理由は以下の通りです。
Compute EngineのPrivate Access設定は、インスタンスがGoogle Cloud内のサービスとプライベートに通信できるようにするものであり、社内のプライベートネットワークとは接続できません。しかし、Cloud VPNやCloud Interconnectは直接企業のネットワークとGoogle Cloudを接続し、必要な通信要件を満たすことができます。
参考リンク：
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/network-connectivity/docs/interconnect/concepts/overview
https://cloud.google.com/vpc/docs/configure-private-google-access#gcloud
</div></details>

### Q.  問題28: 未回答
以前はGoogle Managed Encryption Keys（GMEK）を使用してCloud Storageにファイルを保存していましたが、最近社内ポリシーが更新され、Customer Managed Encryption Keys（CMEK）が必要になりました。最小限のコストで迅速かつ効率的にファイルを再暗号化する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、暗号化キーの管理方法の変更に伴うファイルの再暗号化作業について考える必要があります。元々Google Managed Encryption Keys（GMEK）で暗号化されたファイルを、Customer Managed Encryption Keys（CMEK）に変更して再暗号化を行うのですが、その際、最小限のコストで迅速かつ効率的な方法が求められています。選択肢を評価するときは、これらの要因を考慮に入れ、コストや作業時間を小さく抑えつつCMEKへの変更を確実に達成できる方法を選びましょう。
基本的な概念や原則：
Google Managed Encryption Keys（GMEK）：Google Cloudが管理する暗号化キーです。Cloud Storageはデフォルトでこの方式を利用してすべてのオブジェクトの暗号化を行います。
Customer Managed Encryption Keys（CMEK）：顧客がGoogle Cloud上で管理する暗号化キーです。自分の鍵を生成、管理し、顧客のデータを暗号化するために使用します。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データの保存、取得、共有を行うことができます。
オブジェクトの書き換え：Cloud Storage内のオブジェクトを変更する操作です。オブジェクトを違う暗号化方式で再暗号化する場合に使用します。
gsutil：Google Cloud Storageのコマンドラインツールです。ファイルのアップロード、ダウンロード、バケットの作成等、Cloud Storageの操作が可能です。
正解についての説明：
（選択肢）
・バケットの暗号化タイプをCMEKに変更し、オブジェクトを書き換えます
この選択肢が正解の理由は以下の通りです。
まず、Google Managed Encryption Keys（GMEK）をCustomer Managed Encryption Keys（CMEK）に変更するためには、まずバケットの暗号化タイプをCMEKに切り替える必要があります。暗号化タイプを変更した時点ではすでに保存されているオブジェクトの暗号化は変更されませんので、新たな鍵で再暗号化するにはそのオブジェクトを書き換える操作が必要となります。ただし、この書き換え操作は既存のデータに影響を与えるものではありません。つまり、オブジェクト自体を改ざんしたり、新規にアップロードしたりする必要はありません。
このように、暗号化タイプをCMEKに変更し、オブジェクトを書き換えることで、最小限のコストで、迅速かつ効率的に再暗号化を行うことが可能となります。
不正解についての説明：
選択肢：gsutilを使用して、キーファイルを指定して同じCloud Storageバケットにファイルを再アップロードします
この選択肢が正しくない理由は以下の通りです。
gsutilを使用して同じバケットにファイルを再アップロードすると、新たなストレージスペースが必要になり、これに伴うコストが発生します。
一方で、バケットの暗号化タイプをCMEKに変更し、オブジェクトを書き換える方法では、追加のストレージコストが発生しません。
選択肢：ローカルでファイルを暗号化し、gsutilを使って新しいバケットにファイルをアップロードします
この選択肢が正しくない理由は以下の通りです。
ローカルでファイルを暗号化して再アップロードする方法は、時間とリソースを大量に必要とし、コスト効率が悪いです。
対照的に、バケットの暗号化タイプをCMEKに変更し、オブジェクトを書き換える方法は、迅速かつ効率的にファイルを再暗号化できます。
選択肢：セカンダリーリージョンにあるCMEKが有効な新しいバケットにファイルをコピーします
この選択肢が正しくない理由は以下の通りです。
ファイルをセカンダリーリージョンの新しいCMEK有効バケットにコピーする方法では、データ転送にコストがかかります。
一方、正解の選択肢のバケットの暗号化タイプをCMEKに変更しオブジェクトを書き換える方法では、バケット内でのオペレーションは無料ですから最小コストで行えます。
参考リンク：
https://cloud.google.com/storage/docs/encryption/using-customer-managed-keys
https://cloud.google.com/storage/docs/encrypting-objects
https://cloud.google.com/storage/docs/gsutil/commands/rewrite
</div></details>

### Q.  問題29: 未回答
あなたの組織は、Cloud NATを通してインターネットにアクセスする仮想プライベートクラウド（VPC）内で、プライベートIPのみを持つ仮想マシン（VM）を運用しています。毎日、すべてのVMに重要なOSアップデートのパッチを適用し、サマリーレポートを提供する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、プライベートIPのみを持つ仮想マシン（VM）へのOSアップデートのパッチ適用とそのサマリーレポートの提供方法を尋ねています。仮想マシンがプライベートIPアドレスのみを持つという情報からネットワーク接続が限定されることが述べられています。したがって、インターネット接続がなくてもアップデートが可能な方法や、一つ一つのVMにログインすることなくパッチを適用できる、一括管理の効率的な方法が求められています。この点を踏まえ、選択肢を選ぶことが必要です。
基本的な概念や原則：
Cloud NAT：Google Cloudの仮想マシン（VM）やKubernetes EngineのポッドがプライベートIPからインターネットに接続するためのマネージドサービスです。公開アドレスを保持しないインスタンスからのアウトバウンド接続を可能にします。
仮想プライベートクラウド（VPC）：Google Cloud上で個別に分離された仮想ネットワーク環境です。VPC内では自由にサブネットを設定したり、ファイアウォールルールを適用したりすることができます。
VM Manager：Google Cloudのサービスで、OSパッチ管理を含む一連のワークロード管理タスクを自動化できます。管理下にあるVMに対して一元化されたOSパッチ管理を提供します。
OSパッチ管理：OSのセキュリティや機能改善を提供するための一連のアップデートプロセス。これには、パッチの選択、適用、テスト、および確認が含まれます。
Cloud Scheduler：Google Cloudのジョブスケジューラサービスです。定期的なタスクや一回限りのタスクを自動化することができます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データを格納し、必要に応じてアクセスするための安全な場所を提供します。
パブリックIP：インターネットから直接アクセス可能なIPアドレスです。Google Cloudでは、通常のトラフィック向けにIPアドレスを手動で割り当てることが可能です。
正解についての説明：
（選択肢）
・VM ManagerがVMにインストールされ、稼動していることを確認します。OSパッチ管理サービスで、重要なパッチでアップデートするパッチジョブを設定します
この選択肢が正解の理由は以下の通りです。
まず、重要なOSアップデートのパッチを毎日すべてのVMに適用するために、このプロセスを自動化する必要があります。Google CloudのVM Managerは、VM群全体のライフサイクル管理を自動化するためのサービスであり、これにはOSパッチの適用も含まれます。パッチ管理サービスは、重要なパッチでアップデートするジョブを設定する能力を持っているため、これによって毎日のパッチ適用要件を容易に満たすことができます。
さらに、VM ManagerはOSパッチの適用後に報告を生成する機能も持っているため、必須のサマリーレポートの提供も満たせます。
このように、VM Managerを利用することで設問の要件を全て満たすことができるため、この選択肢が正解となります。
不正解についての説明：
選択肢：アウトバウンドファイアウォールルールが送信トラフィックを許可していることを確認します。各VMにログインし、OS固有のアップデートコマンドを実行します。Cloud Schedulerジョブを構成して、重要なパッチを毎日アップデートするようにします
この選択肢が正しくない理由は以下の通りです。
個々のVMにログインしてOS固有のアップデートコマンドを実行するという提案は、管理作業が手動で大量であるという問題を引き起こします。反対に、VM Managerの使用はこれらの作業を自動化し、作業負荷を大幅に軽減します。
選択肢：最新のパッチをCloud Storageバケットにコピーします。各VMにログインし、パッチをバケットからダウンロードし、インストールします
この選択肢が正しくない理由は以下の通りです。
まず、各VMにログインしてパッチを手動でダウンロードし、インストールするのは効率的ではありません。
また、これは自動化の原則に反します。
それに対して、VM ManagerのOSパッチ管理サービスを使うと、パッチのアップデートを自動的に行いサマリーレポートも提供するため、要件を満たします。
選択肢：パブリックIPをVMに割り当てます。アウトバウンドファイアウォールルールが送信トラフィックを許可していることを確認します。各VMにログインし、アクティビティの少ない夜間にOSアップデートが有効になるように、毎日cronジョブを設定します
この選択肢が正しくない理由は以下の通りです。
まず、パブリックIPをVMに割り当てると、インターネット経由での直接的な接続が可能になり、セキュリティリスクが高まります。
また、手動でcronジョブを設定する管理工数は大きく、効率的な運用が困難です。適切なパッチ管理を行うには、自動化され、集中管理可能なツールであるVM Managerの使用が適しています。
参考リンク：
https://cloud.google.com/compute/docs/os-patch-management
https://cloud.google.com/nat/docs/overview
https://cloud.google.com/blog/products/identity-security/simplifying-cloud-operations-with-os-patch-management
</div></details>

### Q.  問題30: 未回答
あなたの組織は、インスタンスロギングデータをヨーロッパ内に保持する規制に準拠する必要があります。あなたのワークロードは、新しいプロジェクトでオランダのリージョンeurope-west4でホストされます。データを国内に保持するためにCloud Loggingを構成する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のリージョン内でロギングデータを保持する規制がある事業環境のセットアップを考慮することが求められています。組織のワークロードがホストされるのはeurope-west4リージョンであり、ロギングデータをこのリージョンで保持する必要があることに焦点を当てる必要があります。したがって、選択肢を評価するときは、Cloud Loggingの設定方法とそのデータの保存リージョンの管理方法に対する理解が必要です。
基本的な概念や原則：
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションとシステムのログデータを一元化し、ストレージ、分析、監視、アラートなどの機能を提供します。
ログバケット：Cloud Loggingでログデータを保存するためのコンテナです。バケットは地域を指定して作成でき、ログデータの保持ポリシーも設定できます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。ログデータのような非構造化データを保存、管理するのに利用します。ただし、Cloud Loggingのログはログバケットで直接管理されます。
ロギングシンク：特定のタイプのログエントリを収集して他のサービス（例えば、Cloud Storage）にエクスポートするための設定です。ただし、ログを特定の地域に保存するためには、その地域にログバケットを作成する必要があります。
gcloud CLI：Google Cloudをコマンドラインから操作するためのツールです。しかし、ロギングの保存リージョンはログバケット単位で設定され、gcloud CLIではなくCloud ConsoleまたはAPIから設定します。
組織ポリシー制約：Google Cloudのリソースに対する特定の制約を設定するためのポリシーです。例えば、リソースの場所を制制することができます。ただし、規制に準拠してログデータを特定の地域に保存するためには、その地域にログバケットを作成する必要があります。
正解についての説明：
（選択肢）
・europe-west4に新しいログバケットを作成し、Defaultバケットを新しいバケットにリダイレクトします
この選択肢が正解の理由は以下の通りです。
まず、Cloud Loggingではリージョンに拠点を置くログバケットを作成することができます。この機能を利用してeurope-west4に新しいログバケットを作成すれば、インスタンスロギングデータをヨーロッパ内に保持するという要件を満たすことが可能です。
また、デフォルトのログバケットを新しく作成したバケットにリダイレクトすることで、新規に生成されるログデータはすべてこの新しいバケットに格納され、既存のログはそのまま保持されます。これにより、今後のログデータも規制順守の観点から適切な場所に保持することが可能になります。以上の機能により、この選択肢は問題の要件を満たす最善の策となります。
不正解についての説明：
選択肢：組織ポリシー制約Google Cloud.resourceLocationsをeurope-west4に設定します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約Google Cloud.resourceLocationsをeurope-west4に設定することは、リソースの配置を制限するものであり、Cloud Loggingのロギングデータの地理的な配置を保証するものではありません。
それに対して、新しいログバケットをヨーロッパのリージョンで作成し、デフォルトのバケットをそちらにリダイレクトすることで、明確にログデータをヨーロッパ内で保持することが可能となります。
選択肢：ログシンクを設定して、すべてのログをeurope-west4のCloud Storageバケットにエクスポートします
この選択肢が正しくない理由は以下の通りです。
ログシンクを使用してすべてのログをeurope-west4のCloud Storageバケットにエクスポートする方法は、ログの保持リージョンを限定できますが、洗練されたログ管理や速やかなアクセスが必要な場合に適していません。
一方、europe-west4に新しいログバケットを作成し、Defaultバケットを新しいバケットにリダイレクトする方法は、Cloud Loggingのフル機能を利用しつつログを保持リージョンを制限できます。
選択肢：gcloud CLIのロギング設定の更新を使用して、ロギングの保存リージョンをeurope-west4に設定します
この選択肢が正しくない理由は以下の通りです。
gcloud CLIには、ロギングの保存リージョンを直接設定する機能は存在せず、ログバケットを特定のリージョンで作成し、Defaultバケットからリダイレクトすることでロギングデータを特定リージョン内に保持する必要があります。そのため、この方法は要件を満たしません。
参考リンク：
https://cloud.google.com/logging/docs/region-support
https://cloud.google.com/logging/docs/storage
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
</div></details>

### Q.  問題31: 未回答
あるDevOpsチームは、Google Kubernetes Engine上で実行する新しいコンテナを作成しています。アプリケーションはインターネットに接続されるため、コンテナの攻撃対象範囲を最小限に抑えたいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Kubernetes Engine（GKE）を使用して実行される新たなコンテナ作成という状況と、そのコンテナの攻撃対象範囲を最小限にするという要求に注目することが求められています。その要求を適切に満たすために、各選択肢がどのような作業を指しているかを理解し、それが問題で要求されている"攻撃対象範囲を最小限にする"という目的にどの程度寄与するかを評価することが重要です。
基本的な概念や原則：
ベースイメージ：コンテナを作成する際の基礎となるイメージです。最小限のOSと必要なソフトウェアを含むことが多いです。セキュリティを高めるためには、必要な機能のみを持つ小さなベースイメージを使用することが推奨されます。
コンテナ：複数のアプリケーションを分離して実行するための仮想化技術です。各コンテナは他のコンテナと独立して動作し、ホストOSのリソースを共有します。
Google Kubernetes Engine（GKE）：Google CloudのマネージドKubernetesサービスです。コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を容易にします。
Cloud Build：Google CloudのCI/CDプラットフォームで、コードのビルド、テスト、デプロイを自動化します。ただし、コンテナの攻撃対象範囲を抑える具体的な機能は提供していません。
Artifact Registry：Google Cloudのアーティファクト管理サービスです。バージョン管理やアクセス制御などを実現しますが、コンテナの攻撃対象範囲を直接的に抑える機能は提供していません。
正解についての説明：
（選択肢）
・小さなベースイメージを使って小さなコンテナを作ります
この選択肢が正解の理由は以下の通りです。
小さなベースイメージを使ってコンテナを作成することは、コンテナの攻撃対象範囲を最小限に抑える優れた手段です。ベースイメージが小さいほど、イメージに含まれる不必要なソフトウェアやライブラリが減るため、それらを経由した攻撃のリスクが低下します。
また、ベースイメージが小さいということは、それに含まれるソフトウェアの数量も少なくなるため、存在する可能性のある脆弱性の数も減少します。
さらに、イメージが小さいと、適用する必要のあるセキュリティアップデートが少なくなるため、コンテナの維持管理も容易になります。こうした特性は、オンラインで公開されるアプリケーションのセキュリティを確保する上で非常に重要で、DevOpsチームが求めるインターネットなどの外部との接続に必要なセキュリティを提供します。
不正解についての説明：
選択肢：Cloud Buildを使ってコンテナイメージを構築します
この選択肢が正しくない理由は以下の通りです。
Cloud Buildを用いてコンテナイメージを構築することは、コンテナの攻撃対象範囲を最小限に抑える目的には寄与しません。それは単にイメージの構築手段であり、セキュリティ向上は主目的ではありません。
一方、小さなベースイメージを用いることは不要なパッケージを排除し、コンテナのサーフェスエリアを小さくすることに直接的に寄与します。
選択肢：Artifact Registryから使用されていないバージョンを削除します
この選択肢が正しくない理由は以下の通りです。
Artifact Registryから使用されていないバージョンを削除することは、ストレージ管理やバージョン管理を助けますが、コンテナの攻撃対象範囲を最小限に抑える目的には直接貢献しません。
一方、小さなベースイメージを用いると不要なソフトウェアやライブラリが排除され、攻撃対象範囲が縮小されます。
選択肢：継続的デリバリーツールを使ってアプリケーションをデプロイします
この選択肢が正しくない理由は以下の通りです。
継続的デリバリーツールを使うことは開発プロセスを高速化・自動化する利点がありますが、コンテナの攻撃対象範囲を最小限にするという目的には直接関連がありません。
一方、小さなベースイメージを使うことは不必要な機能やパッケージを減らし、攻撃対象を最小限に抑える効果があるため正解です。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/concepts/container-images
https://cloud.google.com/solutions/best-practices-for-building-containers
https://cloud.google.com/architecture/best-practices-for-operating-containers
</div></details>

### Q.  問題32: 未回答
あなたの組織は、仮想マシン（VM）をGoogle Cloudに移行しようとしています。プロジェクト全体で使用されるオペレーティングシステムイメージが信頼でき、セキュリティ要件を満たしていることを確認する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudに仮想マシン（VM）を移行しようと考えている組織がOSイメージに対する信頼性とセキュリティ要件をどのように確保すべきか尋ねています。各選択肢が推奨されるシチュエーションと、それらが要件にどのように対応するかを熟考することが重要です。また、留意点として、Google Cloudの具体的な機能とそれらが提供するセキュリティ対策を理解していることが求められます。
基本的な概念や原則：
組織ポリシー：Google Cloud上のリソースに対する制約を定義し、組織全体で一貫したルールを実施するための方法です。特定の種類のリソースがどの場所で作成できるか、特定のAPIがどのプロジェクトで利用できるかなどを制御します。
信頼されたイメージプロジェクト：信頼性とセキュリティが確保されたオペレーティングシステムイメージを提供するプロジェクトです。
ブートディスク：仮想マシン（VM）がブート（起動）する際に使用するディスクです。信頼性の高いイメージから作成されることで、特定のセキュリティ基準を満たすことができます。
Shielded VM：Google Cloudにおける仮想マシン（VM）のセキュリティ強化版です。信頼性の証明、安全なブート、BIOSの整合性を保証します。
Cloud Functions：Google Cloud上のサーバーレスコンピューティングサービスです。特定のイベントに応じて自動的に実行される関数を作成し、管理します。
一般的な脆弱性と暴露（CVE）：公開されているコンピューターセキュリティ脆弱性のデータベースです。セキュリティ監査、脆弱性管理、プロダクトのセキュリティ状態確認などに利用されます。
正解についての説明：
（選択肢）
・ブートディスクは、信頼されたイメージプロジェクトから派生したイメージからのみ作成できることを強制する組織ポリシーを実装します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、組織ポリシーの設定を通じて、特定の制約を適用することができます。ブートディスクの作成に関する制約は、"ブートディスクは信頼されたイメージプロジェクトから派生したイメージからのみ作成できることを強制する"という要件に対する解決策として適用可能です。これにより、組織全体で使用されるオペレーティングシステムイメージの信頼性とセキュリティ要件の確保が可能となります。組織ポリシーを適用することで、指定された信頼されたイメージプロジェクトから派生したイメージを使用しないVMの作成を遮断します。これにより、すべてのVMが定められたポリシーに一致した安全な状態で起動し、セキュリティ要件が維持されます。
不正解についての説明：
選択肢：すべてのプロジェクトでShielded VMサービスを有効にする組織ポリシー制約を実装し、信頼済みイメージリポジトリの使用を強制します
この選択肢が正しくない理由は以下の通りです。
Shielded VMサービスはVMのインテグリティを保証するロールを果たしますが、特定の信頼性が証明されたイメージリポジトリの使用を強制する機能はありません。それに対して正解の選択肢は特定のイメージプロジェクトからのみブートディスクを作成することを強制することで、信頼度とセキュリティ要件の確保を可能にします。
選択肢：信頼できるイメージリポジトリから新しい仮想マシンが作成されたときに自動的にトリガーされるCloud Functionsを実装します。イメージが非推奨でないことを確認します
この選択肢が正しくない理由は以下の通りです。
Cloud Functionsを用いてイメージのチェックを行う方法は、VMが既に作成されてからのチェックになるため、非推奨のイメージを使って作成が行われてしまった場合に対応が遅れ、セキュリティ要件を満たせない恐れがあります。
一方、組織ポリシーを用いて信頼されたイメージからのみブートディスクの作成を要求する方法は、事前に制限を行うことで、非推奨のイメージが使用されるリスクを事前に防ぎます。
選択肢：信頼できるイメージリポジトリに一般的な脆弱性と暴露（CVE）が存在しないことを検証するセキュリティスキャナを自動化します
この選択肢が正しくない理由は以下の通りです。
イメージリポジトリの脆弱性をスキャンすることは重要なセキュリティ慣行ですが、それだけでは問題の要件を満たしません。なぜならそれがプロジェクト全体で使用されるOSイメージが信頼できること、セキュリティ要件を満たすことを確認するという要件を直接的に担保するものではないからです。そのため、正解の選択肢のように組織ポリシーを実装して信頼されたイメージからしかブートディスクが作成できないことを強制する方が適切です。
参考リンク：
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/security-command-center/docs/concepts-security-sources-for-findings
</div></details>

### Q.  問題33: 未回答
Google Cloudを利用している組織で、ユーザが自分のバケット内のオブジェクトを外部に公開できないようにするセキュリティポリシーを適用する必要があります。現在、この組織にはバケットがありません。
この目標を最小の運用オーバーヘッドで達成するために、どのソリューションを実装すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudを利用する組織のセキュリティ要件を理解することが重要です。規定では、ユーザーは自分のバケット内のオブジェクトを外部に公開することができません。さらに、運用オーバーヘッドを最小限に抑える手段を求められています。したがって、選択肢を評価する際には、これらの要件を満たす最も効率的で直接的なソリューションを選択する必要があります。
基本的な概念や原則：
constraints/storage.publicAccessPrevention：Google Cloudの制約で、この設定を有効にするとバケットレベルで公開設定を無効化します。これにより、組織内の任意のユーザがバケット内のオブジェクトを公開することを制限します。
Cloud Functions：サーバーレス環境でコードを実行するGoogle Cloudのサービスです。イベント駆動型のアクションを実行できます。
VPC Service Controls：Google Cloudのサービスで、指定したサービスのデータの流れを制御します。これにより、データがプロジェクトまたは組織の信頼領域を離れないように制限することが可能です。
constraints/storage.uniformBucketLevelAccess：Google Cloudの制約で、この設定を有効にするとバケット内すべてのオブジェクトに対するACL（Access Control Lists）によるアクセス設定を無効化します。しかし、バケット全体の公開設定自体は無効化できません。
サービスアカウント：Google Cloudの認証・認可モデルの一部で、特定のサービスやアプリケーションがGoogle Cloudのリソースにアクセスするために使用されます。
正解についての説明：
（選択肢）
・組織レベルでconstraints/storage.publicAccessPrevention制約を有効にします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの組織ポリシーサービスはリソース階層全体にポリシーを適用する方法を提供します。その一つがpublicAccessPreventionという制約で、これはCloud Storageバケットでの公開アクセスを防止するための制限となります。
この制約を組織レベルで有効にすることで、組織内の全ての新規及び既存のバケットに対して一律に適用されます。これにより、個別にバケットの設定を変更せずとも一括で公開アクセスを制御することができます。これは運用オーバーヘッドを大幅に減らすことにつながります。
そのため、組織全体でオブジェクトの外部への公開を防ぐためには、組織レベルでconstraints/storage.publicAccessPrevention制約を有効にするのが最も効率的な解決策となります。
不正解についての説明：
選択肢：公開バケットを見つけて非公開にするCloud Functionを実行するcronジョブを毎時作成します
この選択肢が正しくない理由は以下の通りです。
Cronジョブを使って毎時Cloud Functionを実行する方法は、運用オーバーヘッドが増えるし、設定の遅延により短時間ではあるがデータ漏洩のリスクがあります。しかし、constraints/storage.publicAccessPrevention制約を有効化すると、ユーザが公開設定を試みても予防でき、運用オーバーヘッドも最小限にすることができます。
選択肢：組織レベルでのconstraints/storage.uniformBucketLevelAccess制約を有効にします
この選択肢が正しくない理由は以下の通りです。
constraints/storage.uniformBucketLevelAccess制約は、すべてのバケットに対して均一なバケットレベルのアクセスを強制するもので、オブジェクトの公開自体を制限するものではありません。対してconstraints/storage.publicAccessPrevention制約は、オブジェクトが外部に公開されるのを防ぐ制約で、今回の目標に適しています。
選択肢：バケットを含むプロジェクトのstorage.googleapis.comサービスを保護するVPC Service Controlsの境界を作成します。バケットを含む新しいプロジェクトを境界へ追加します
この選択肢が正しくない理由は以下の通りです。
VPC Service ControlsはAPIとサービスの保護を実現するものですが、ユーザーがバケット内のオブジェクトを外部に公開する行為自体を防ぐには不適切です。
一方、constraints/storage.publicAccessPrevention制約を有効にすることで、全てのバケットに対し外部公開を禁止するセキュリティポリシーを適用できます。
参考リンク：
https://cloud.google.com/storage/docs/public-access-prevention
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-public-access
https://cloud.google.com/storage/docs/uniform-bucket-level-access
</div></details>

### Q.  問題34: 未回答
ある顧客が、インターネットへのアクセスを制限する必要がある分析ワークロードをCompute Engine上で実行しています。
あなたのチームは、インターネットへのすべてのトラフィックを拒否（優先度1000）するためのアウトバウンドファイアウォールルールを作成しました。
Compute Engineインスタンスは、セキュリティアップデートを取得するためにパブリックリポジトリにアクセスする必要があります。
あなたのチームは何をすべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、インターネットへのアクセス制限が必要なCompute Engineインスタンスに対して、一部のセキュリティアップデート用のリポジトリだけアクセスを許可する必要があります。すでに優先度1000でインターネットへの全トラフィックを拒否するルールが存在するため、このルールより優先度が高くなければならないことに注意が必要です。優先度は数字が低いほど高くなります。これを踏まえて、適切な優先度を持つファイアウォールルールの作成方法を問題から導く必要があります。
基本的な概念や原則：
ファイアウォールルール：Google Cloudのネットワークセキュリティの一部で、特定の種類のトラフィック（プロトコル、ポート、ソースIP範囲、宛先IP範囲）を許可または拒否するための規則です。
優先度：Google Cloudファイアウォールルールの属性で、数値が小さいほど優先度が高いルールとなります。競合するルールがある場合、優先度が高い方が適用されます。
リポジトリへのアクセス：Google Cloud Compute Engineインスタンスがセキュリティアップデートを取得するために、インターネット上の公開リポジトリに接続することが必要です。
CIDRレンジ：IPアドレスの範囲を指定する方法の一つで、ネットワークやサブネットのサイズを効果的に指定できます。ファイアウォールルールでアクセスを許可または拒否するIPアドレス範囲を指定するために使用します。
ネットワークのアウトバウンド：システムから外部へのネットワークトラフィックを指します。インバウンドとは逆の方向のトラフィックです。
セキュリティアップデート：システムの脆弱性を修正するために配布されるアップデートで、定期的に適用することが推奨されます。
正解についての説明：
（選択肢）
・優先度1000未満のリポジトリのCIDRレンジへのトラフィックを許可するアウトバウンドファイアウォールルールを作成します
この選択肢が正解の理由は以下の通りです。
Google Cloudのファイアウォールルールは、優先度に基づいて評価され、数値が小さいほど優先度が高くなります。つまり、複数のルールがある場合、最も低い優先度値を持つルールが適用されます。すでに優先度1000でインターネットトラフィックを拒否するルールが作成されていますが、セキュリティアップデートのための特定のパブリックリポジトリへのアクセスが必要であるため、これらのリポジトリーへのアクセスを許可する新しいルールを作成する必要があります。この新しいルールの優先度は1000未満であるべきです。これにより、パブリックリポジトリへのトラフィックは新しく作成したルールによって許可され、それ以外のインターネットトラフィックは既存の優先度1000のルールによって拒否されます。これにより、必要な通信のみを確保しつつ全体のセキュリティを維持することが可能となります。
不正解についての説明：
選択肢：優先度1000以上のリポジトリのCIDRレンジへのトラフィックを許可するアウトバウンドファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのファイアウォールルールでは、優先度が低い方が先に適用されます。よって、優先度1000以上でアウトバウンドファイアウォールルールを作成しても、すでに優先度1000で全てのトラフィックを拒否するルールが存在するために無視されてしまいます。正解は優先度1000未満で設定し、適用されるようにすることです。
選択肢：優先度1000以上のリポジトリのホスト名へのトラフィックを許可するアウトバウンドファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのファイアウォールルールは数値の小さい優先度が高くなります。
従って、優先度1000以上のルールを作成しても、すでに定義されている優先度1000の全トラフィック拒否ルールより優先されません。これによりインスタンスはパブリックリポジトリにアクセスできず、セキュリティアップデートを取得することができません。
選択肢：優先度1000未満のリポジトリのホスト名へのトラフィックを許可するアウトバウンドファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのファイアウォールルールはホスト名に基づいてトラフフィックを許可または拒否することはできません。送信先や送信元のIPAddressまたはCIDRレンジに基づいて制御します。そのため、リポジトリホスト名へのトラフィックを許可するルールは作成できません。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/compute/docs/instances/connecting-advanced#firewallrules
https://cloud.google.com/compute/docs/instances/managing-instance-access#configure_firewall_rules
</div></details>

### Q.  問題35: 未回答
標準的なネットワーク階層を使用しながら、デフォルトでクライアントIPを維持するために、どのタイプのロードバランサーを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ロードバランサーの種類とそれぞれの機能に関する理解が求められています。特に、デフォルトでクライアントIPを維持するロードバランサーのタイプを選ぶことが問われています。問題文を理解するためには、各ロードバランサーがどのように動作し、それぞれがどのようなネットワーク階層で動くのか、またどのロードバランサーがクライアントIPを維持可能なのか、を把握する必要があります。
基本的な概念や原則：
TCP/UDPネットワークロードバランサー：パケットレベルのロードバランサーであり、リッチなルーティング機能と高いパフォーマンスを提供します。デフォルトでクライアントIPを維持します。
SSLプロキシロードバランサー：SSL（HTTPS）トラフィックのロードバランサーで、SSLオフロード能力を提供します。クライアントIPを維持しないことがあります。
TCPプロキシロードバランサー：TCP（またはSSL）トラフィックのロードバランサーで、迅速なオープンコネクションを提供します。こちらもクライアントIPを維持しないことがあります。
内部TCP/UDPロードバランサー：VPCネットワーク内部にあるインスタンス間でトラフィックをバランスします。クライアントIPの維持が特例となります。
正解についての説明：
（選択肢）
・TCP/UDPネットワーク
この選択肢が正解の理由は以下の通りです。
まず、TCP/UDPネットワークロードバランサーは、トラフィックをバックエンドサーバーに分散するために、トランスポート層（L4）レベルでロードバランスを行います。このレベルで動作するため、クライアントのIPアドレスが変更されずに保持されます。これは特に、クライアントのIPアドレスを維持する必要があるケース、たとえば特定のIPからのリクエストを特定のサーバにルーティングしたいといった場合に有用です。
また、TCP/UDPネットワークロードバランサーは、デフォルトで典型的なネットワーク階層（つまり、マルチレイヤーネットワークトポロジ）で動作します。これにより、ネットワーク設計と管理が容易になり、スムーズな運用が可能となります。
したがって、標準的なネットワーク階層を維持しながらクライアントIPを保持するためには、TCP/UDPネットワークロードバランサーを使用すべきです。
不正解についての説明：
選択肢：SSLプロキシ
この選択肢が正しくない理由は以下の通りです。
SSLプロキシロードバランサーは、クライアントIPアドレスを元の形で維持することができません。クライアントのIPアドレスを保持しながら標準的なネットワーク階層を使用するために、TCP/UDPネットワークロードバランサーが適切な選択肢となります。
選択肢：TCPプロキシ
この選択肢が正しくない理由は以下の通りです。
TCPプロキシロードバランサーはクライアントのIPを維持しません。クライアントからの接続を受け取り、バックエンドインスタンスに転送するときに新しいTCPセッションを開始します。
これに対して、TCP/UDPネットワークロードバランサーはクライアントのIPを維持します。
選択肢：内部TCP/UDP
この選択肢が正しくない理由は以下の通りです。
内部TCP/UDPロードバランサーは特定の状況下でクライアントIPを維持しますが、一般的にはプロキシモードで動作し、クライアントIPを維持しません。しかし正解のTCP/UDPネットワークロードバランサーはパケットに対して直接操作を行うため、デフォルトでクライアントIPを維持します。
参考リンク：
https://cloud.google.com/load-balancing/docs/network
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
</div></details>

### Q.  問題36: 未回答
あなたの組織は最近、Google Kubernetes Engineに新しいアプリケーションをデプロイしました。アプリケーションを保護するためにソリューションをデプロイする必要があります。ソリューションには以下の要件があります：
- スキャンを少なくとも週に1回実行すること
- クロスサイトスクリプティングの脆弱性を検出できること
- Googleアカウントを使用して認証できること
この要件を満たすために、どのソリューションを使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Kubernetes Engine上のアプリケーションを保護するためのソリューションの選択について考える必要があります。問題文の要件明確に把握し、それを満たすソリューションを選び出すことが求められます。定期的なスキャン、クロスサイトスクリプティングの脆弱性検出、Googleアカウントの使用という3つの要件を満たすソリューションを探し、選択することが重要です。選択肢の中から、具体的な要件を満たすものを探し出す際には、各ソリューションの機能や目的を正確に理解することが必要です。
基本的な概念や原則：
Web Security Scanner：Google Cloudの管理型脆弱性スキャンツールです。クロスサイトスクリプティングや他の一般的な脆弱性を検出し、ユーザーに対して警告を発することができます。
Googleアカウント認証：Googleのアカウントを用いたユーザーアクセスの認証メソッドです。これにより、Google Cloudのリソースへのアクセスが保護されます。
Google Cloud Armor：Google Cloud上で動作するビジネスクリティカルなアプリケーションを保護するためのスケーラブルな、マネージド型の分散デノサービスです。しかし、脆弱性スキャンは主な機能ではありません。
Security Health Analytics：Google Cloudのセキュリティ状況を監視し、分析するためのサービスです。一般的なベストプラクティスに基づく脆弱性検査を行いますが、クロスサイトスクリプティングの脆弱性を検出する機能は提供していません。
Container Threat Detection：Google Cloud上のコンテナを対象としたセキュリティ脅威を検出するためのサービスです。サービスは、不正な操作や既知の脅威についてリアルタイムで警告を発しますが、特定の脆弱性スキャン能力はありません。
正解についての説明：
（選択肢）
・Web Security Scanner
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのWeb Security Scannerは、アプリケーションで標準的な脆弱性、例えばクロスサイトスクリプティング（XSS）等を自動的に見つけ出すために設計されています。
したがって、これにより、クロスサイトスクリプティングの脆弱性を検出する要件を満たすことができます。
次に、Web Security Scannerは定期的なスキャンをスケジュールすることが可能です。これにより、スキャンを少なくとも週に1回実行するという要件に対応することができます。
最後に、Web Security ScannerはGoogle Cloud Consoleを通じて管理し、そこではGoogleアカウントが使用されます。これにより、Googleアカウントを使用して認証するという要件も満たします。
したがって、これらの要件全てを満たすために、Web Security Scannerが最適なソリューションとなります。
不正解についての説明：
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは主にDDoS攻撃防止やIPブロックなどのセキュリティポリシーやルールを設定し、トラフィックを制御することが主なロールで、特定の脆弱性スキャンなどは行いません。
それに対して、Web Security Scannerは週に一度のスキャンやクロスサイトスクリプティングの脆弱性を検出する機能を提供しているため、要件に適しています。
選択肢：Security Health Analytics
この選択肢が正しくない理由は以下の通りです。
Security Health Analyticsは、Google Cloudリソースの潜在的なセキュリティリスクを識別し対策するためのツールですが、特定の脆弱性、例えばクロスサイトスクリプティングを対象としたスキャンを提供はしていません。
一方、Web Security ScannerはWebアプリケーションの脆弱性を対象に定期的にスキャンする機能を提供しており、要件を満たします。
選択肢：Container Threat Detection
この選択肢が正しくない理由は以下の通りです。
Container Threat Detectionはコンテナ指向の異常や脅威を検出するものであり、特に脆弱性探知やクロスサイトスクリプティングの検出に特化していません。
一方で、Web Security Scannerはウェブアプリケーションの脆弱性、特にクロスサイトスクリプティングの検出に特化しています。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/armor/docs/security-policy-overview
https://cloud.google.com/kubernetes-engine/docs/concepts/security-overview
</div></details>

### Q.  問題37: 未回答
あなたは、アプリケーションログをCloud Storageにエクスポートしています。ログシンクが統一されたバケットレベルのアクセスポリシーをサポートしていないというエラーメッセージが表示されました。
このエラーはどのように解決すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Storageバケットに対するアクセス制御に焦点を当てています。具体的には、アプリケーションログのエクスポート中に見つかった特定のエラーに対処する方法が問われています。問題を解決するために、統一されたバケットレベルのアクセスポリシーという概念と、それがログシンクとどのように関連しているかをよく理解することが重要です。選択肢を評価するときには、に直接的な解決手段になりそうな選択肢に注目し、他の選択肢がこの具体的なエラーの解決に役立つかどうかを評価することが求められます。
基本的な概念や原則：
バケットレベルのアクセスポリシー：Google Cloud Storageバケットのアクセス制御を定義するためのポリシーです。特定のユーザーやサービスアカウントがバケット内のリソースに対して何をできるかを指定します。
ログシンク：Google Cloudのロギングシステムにおいて、ログエントリをエクスポートする先を指定する機能です。複数のデスティネーション（Cloud Storageバケット、BigQueryデータセット、Pub/Subトピックなど）を定義することができます。
統一モデル：Google Cloud Storageにおけるバケットとオブジェクトのアクセス制御について、IAMポリシーを使って管理する方法です。これは、"全バケットでIAMのみを使用する"というオプションで、このモデルを使用すると、IAMによってバケットに対するすべてのアクセスを制御することができます。
ACL（Access Control Lists）モデル：Google Cloud Storageで使用される古いアクセス制御モデルで、バケットやオブジェクト単位でアクセス権を指定します。このモデルでは、ひとつひとつのオブジェクトに対してアクセス権を個別に設定することが可能です。
正解についての説明：
（選択肢）
・バケットのアクセス制御モデルを変更します
この選択肢が正解の理由は以下の通りです。
Google Cloud Storageには、バケットに対するアクセス制御を管理する2つのモデルが存在します。それらはACL（Access Control Lists）と統一バケットレベルのアクセスポリシーです。通常、ログシンクなどのサービスは特定のバケットにアクセスし、データをエクスポートするためにACLを利用します。しかし、統一バケットレベルのアクセスポリシーが有効化されていると、ACLは無効となりエラーメッセージが表示されます。
したがって、問題を解決するためにはバケットのアクセス制御モデルを元に戻す、つまり統一バケットレベルのアクセスポリシーからACLに切り替える必要があります。これによりログシンクは再びバケットにアクセスでき、エラーが解消されます。
不正解についての説明：
選択肢：シンクを正しいバケットの宛先で更新します
この選択肢が正しくない理由は以下の通りです。
問題は、シンクがアクセスポリシーをサポートしていないことであり、シンクの宛先を正しいバケットに更新することで解決するものではありません。正解はバケットのアクセス制御モデルを変更することで、これはバケットレベルのアクセスポリシーに適応させる意味があります。
選択肢：roles/logging.logWriterアイデンティティおよびIAMロールを、ログシンクのアイデンティティのバケットに追加します
この選択肢が正しくない理由は以下の通りです。
特定のアイデンティティにroles/logging.logWriterを追加すると、そのアイデンティティはロギングデータを任意の場所に書き込むことができますが、今回のエラーはバケットレベルのアクセスポリシーがサポートされていないため発生しています。
したがって、アクセス制御モデルを変更することで問題を解決する必要があります。
選択肢：roles/logging.bucketWriterアイデンティティおよびIAMロールを、ログシンクのアイデンティティのバケットに追加します
この選択肢が正しくない理由は以下の通りです。
エラーメッセージが指しているのは"バケットレベルのアクセスポリシー"の問題であり、単にIAMロールを追加するだけでは解決しません。バケットのアクセス制御モデルを変更してバケットレベルのアクセスポリシーを変更する必要があります。
参考リンク：
https://cloud.google.com/storage/docs/uniform-bucket-level-access
https://cloud.google.com/logging/docs/export/configure_export_v2
https://cloud.google.com/storage/docs/access-control/using-iam-permissions
</div></details>

### Q.  問題38: 未回答
あなたのチームは、指定されたCompute Engine仮想マシンインスタンスから指定されたCloud Storageバケットへのデータ転送を認証するためにサービスアカウントを使用しています。エンジニアが誤ってサービスアカウントを削除してしまい、アプリケーションの機能が壊れてしまいました。セキュリティを損なうことなく、アプリケーションをできるだけ早く復旧させたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、エンジニアが誤ってサービスアカウントを削除し、その結果アプリケーションの機能が破壊されてしまったシチュエーションを前提としています。復旧のための選択肢を見るときは、セキュリティを損なわない方法でアプリケーションをできるだけ早く復旧させることを目指しています。選択肢を評価する際には、復旧速度とセキュリティのバランスを適切に維持する方法を探すことが重要です。
基本的な概念や原則：
サービスアカウント：特定のアプリケーションやインスタンスに連携し、Google Cloud APIを使用するためのIDです。個々のサービスがどのリソースにアクセスし、どの種類のアクションを実行できるかを制御するために使用します。
undeleteコマンド：削除したサービスアカウントを復元するためのコマンドです。サービスアカウントが暗号化キーを使って暗号化されていたデータにアクセスするための許可を持っていた場合、復元は特に重要です。
セキュリティ：Google Cloudでは、認証、認可、監査に基づくセキュリティモデルが採用されています。適切なセキュリティ対策が取られていないと、データの漏洩や不正アクセスが発生する可能性があります。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。Compute Engineインスタンスは、サービスアカウントを利用してGoogle CloudのAPIへアクセスできます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データはバケットと呼ばれるコンテナに格納され、各ファイルはそれぞれ一意のURLを持ちます。バケットへのアクセス制御はIAMポリシーやバケットポリシーで管理できます。
正解についての説明：
（選択肢）
・削除されたサービスアカウントを復元するために、undeleteコマンドを使用します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、誤って削除されたサービスアカウントを復元する手段としてundeleteコマンドを提供しています。サービスアカウントが削除されても、その削除から30日間はこのコマンドを用いて元に戻すことが可能です。これによって、迅速にアプリケーションの機能を復旧させることができます。
また、新たにサービスアカウントを作成し直す必要がないため、設定ミスによる新たなセキュリティリスクを生じさせることなく、アプリケーションの復旧が可能となります。これらのメリットから、問題の状況に対して"削除されたサービスアカウントを復元するために、undeleteコマンドを使用する"が最適な対応となります。
不正解についての説明：
選択肢：Cloud Storageバケットの認証を一時的に無効にします
この選択肢が正しくない理由は以下の通りです。
Cloud Storageバケットの認証を一時的に無効にすると、データのセキュリティが損なわれる可能性があります。
代わりに、削除されたサービスアカウントを復元するためのundeleteコマンドを使用することで、セキュリティを維持しつつアプリケーションの機能を復旧することが可能です。
選択肢：削除したサービスアカウントと同じ名前で新しいサービスアカウントを作成します
この選択肢が正しくない理由は以下の通りです。
同じ名前の新しいサービスアカウントを作成したとしても、以前のサービスアカウントとは異なる新しいID及びキーペアが生成され、以前と同じ機能は復元できません。正解は削除されたサービスアカウントの復元で、これなら以前と同じアクセス権が保証されます。
選択肢：別の既存のサービスアカウントの権限を更新し、その資格情報をアプリケーションに提供します
この選択肢が正しくない理由は以下の通りです。
別の既存のサービスアカウントの権限を更新すると、そのサービスアカウントが他の用途で使用されていた場合、予期しない副作用を引き起こす可能性があります。
一方で、削除されたサービスアカウントを復元するundeleteコマンドを使用すると、瞬時に以前と同じ設定でアプリケーションを復旧できます。
参考リンク：
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/service-accounts#undeleting
</div></details>

### Q.  問題39: 未回答
Compute Engineでホストされている公開アプリケーションで、ユーザーから障害が報告されています。これは、ファイアウォールルールの最近の変更が原因だと思われます。今後は、ファイアウォールルールが正しく機能しているかどうかをテストする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute Engineで動作する公開アプリケーションに対するユーザーからの障害報告と、それがファイアウォールルールの変更によるものという事情を考慮する必要があります。また、この問題からはファイアウォールルールが正しく機能しているかどうか証明するための手段を求めるものと理解できます。選択肢から選ぶ際は、Google Cloud特有の監視ツールやログ分析方法が適用可能かどうか、そしてそれが対象となるファイアウォールルールの調査に有効であるかどうかを重視して検討するべきです。
基本的な概念や原則：
ファイアウォールルールログ：Compute Engineのインスタンスに適用されたファイアウォールルールを記録するロギング機能です。ルールが正しく機能しているかの確認や、問題解析に活用できます。
ログエクスプローラ：Google Cloud上の様々なサービスからのログデータを検索、表示、分析するためのツールです。ログの視覚化やフィルタリングが可能です。
踏み台ホスト：セキュリティの観点から、直接公開ネットワークからアクセスできないホストへのアクセスを仲介するサーバーのことです。
ネットワークトラフィックアナライザー：ネットワークトラフィックの監視や分析を行うためのツールです。リクエストの送信元・送信先、ポート番号など詳細な情報を取得できます。
VPCフローログ：VPCネットワークのネットワークフロー情報をキャプチャし、ログを生成する機能です。フローログはネットワークパフォーマンスの監視やセキュリティ分析に使用されます。
正解についての説明：
（選択肢）
・変更された最新のルールのファイアウォールルールログを有効にします。ログエクスプローラーを使用して、ルールが正しく機能しているかどうかを分析します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudのファイアウォールルールには、それぞれを追跡し分析するためのロギング機能が含まれています。
したがって、ファイアウォールルールを修正した後に、それらのルールのログを有効にすることで、そのルールが期待通りに動作するかどうかを直接確認することができます。この方法は、障害が発生した場合に問題の特定と解決に効果的です。
次に、ログエクスプローラーを使用すると、ログ情報をフィルタリング、ソーティング、分析することが可能です。これはGoogle Cloudの中心的なログ分析ツールで、ログデータの視覚化と理解を助けます。これにより、ファイアウォールルールが正しく動作しているかどうかを評価し、問題があれば修正するための必要な情報を得ることができます。
したがって、正しきルールの動作をテストするための最適な方法は、ファイアウォールルールのログを有効にし、ログエクスプローラーでその動作を分析することです。
不正解についての説明：
選択肢：VPC内の踏み台ホストに接続します。ネットワークトラフィックアナライザーを使って、どの時点でリクエストがブロックされているかを調べてください
この選択肢が正しくない理由は以下の通りです。
VPC内の踏み台ホストに接続しネットワークトラフィックアナライザーを使用する方法は可能ですが、必要な分析を行うためには時間と専門的な技術が必要となります。
それに対して、ファイアウォールルールログを有効にしログエクスプローラーを使用することで、より直接的で効率的にルールの動作を分析することが可能です。
選択肢：本番前環境では、すべてのファイアウォールルールを個別に無効にして、どれがユーザートラフィックをブロックしているかを判断します
この選択肢が正しくない理由は以下の通りです。
本番前の環境で全てのファイアウォールルールを無効にすると、保護するべきシステムが露出する危険性があるため安全性に問題があります。対してファイアウォールルールログを有効にすることでルールの影響を確認でき、安全に問題を診断できます。
選択肢：VPCでVPCフローログを有効にします。ログエクスプローラーを使用して、ルールが正しく機能しているかどうかを分析します
この選択肢が正しくない理由は以下の通りです。
VPCフローログは、VPCネットワーク内でのIPトラフィックをキャプチャし、ネットワークのパフォーマンス、監視、セキュリティ、コンプライアンスの分析などのために利用する機能ですが、特定のファイアウォールルールが正しく機能しているかどうかをテストするためには不十分です。
一方、ファイアウォールルールログを有効にすると、特定のファイアウォールルールによって許可または拒否されたトラフィックを確認できるため、ルールが正しく機能しているかどうかを詳細に分析することができます。
参考リンク：
https://cloud.google.com/network-connectivity/docs/firewall-insights/using-fw-insights
https://cloud.google.com/network-connectivity/docs/firewall-logging
https://cloud.google.com/compute/docs/instances/connecting-advanced#third_party_tools
</div></details>

### Q.  問題40: 未回答
あなたの会社には300人のエンジニアがいます。同社は、開発環境プロジェクトと本番環境プロジェクトで、異なるレベルのアクセス権を付与し、ユーザー間のIAM権限を効率的に管理したいと考えています。
これらの要件を満たすために、取るべき2つの手順はどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のエンジニアに対して異なるプロジェクトで異なるアクセス権を効率的に管理する方法を問われています。根本的な課題は、300人のエンジニア間でIAM権限を容易に管理することであり、個々のユーザーへの権限を直接割り当てるのではなく、一括で管理できるソリューションを考えることが求められています。さらに、開発環境と本番環境で異なるレベルのアクセス権を制御する必要があるため、これらの環境を区別する方法を示す解決策も選択肢として検討するべきです。
基本的な概念や原則：
フォルダ：Google Cloud Resource Managerで提供される、プロジェクトとリソースの集合を表します。IAMポリシーを一元管理するための階層構造を提供します。
Googleグループ：特定のユーザーグループに権限を一括付与したり、コミュニケーションを行うためのGoogle Workspaceの機能です。
IAM（Identity and Access Management）：Google Cloudのセキュリティモデルの一部であり、認証（ユーザーが誰であるか確認）と認可（何を行うことが許可されているか）の制御を提供します。
VPCネットワーク：仮想プライベートクラウド（VPC）ネットワークは、Google Cloud内でプライベートネットワークを提供するものであり、プロジェクトのリソース間の通信を制御します。これ自体がIAM権限の管理に直接寄与するものではありません。
組織ポリシー：Google Cloudリソースに対する特定の規定を定義します。ポリシー制約は、特定のリソースで何ができるかを規定するもので、特定の環境全体のIAM権限を一元管理するものではありません。
プロジェクト：Google Cloudでは、リソースを組織化し管理するための基本的な単位です。しかし、各エンジニアリングユーザーにIAM権限を各プロジェクトごとに個別に付与するのは、管理コストが高くなる可能性があります。
正解についての説明：
（選択肢）
・開発環境と本番環境それぞれにフォルダを作成します
・エンジニアリングチーム用のGoogleグループを作成し、フォルダレベルで権限を割り当てます
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudでは、リソース階層構造の一部としてフォルダを使用することができます。フォルダは、より広範な制御を可能にするために、プロジェクトを主題別または環境別（開発と本番など）に編成します。
したがって、開発環境と本番環境それぞれにフォルダを作成することで、これらの環境のリソースに対するアクセス制御を短縮および簡素化できます。
また、Googleグループを使用すると、一連のユーザーに対する一貫したポリシー管理が可能になります。つまり、エンジニアリングチーム全体を単一のグループとして管理し、必要に応じてIAM権限を割り当てることで、一貫性のあるアクセス制御を維持できると同時に、権限管理の効率性も向上します。これらの概念を組み合わせることで、エンジニアリングチームのメンバーが開発環境と本番環境のプロジェクトに対して適切なアクセス権を持つことが可能になります。
不正解についての説明：
選択肢：環境ごとに複数のVPCネットワークを持つプロジェクトを作成します
この選択肢が正しくない理由は以下の通りです。
本問題の要求はIAM権限の効率的な管理であり、それへの対応策として環境ごとにVPCネットワークを複数持つプロジェクトを作成する措置は直接関連しません。
一方、フォルダを作成し、グループに権限を割り当てることで、権限管理を効率化することが可能となります。
選択肢：フォルダ環境ごとに組織ポリシー制約を作成します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約を作ることは、設問にある開発環境と本番環境で異なるレベルのアクセス権を付与し、ユーザー間のIAM権限を効率的に管理する目的を直接的には達成しません。この目的のためには、フォルダレベルで適切な権限を割り当てることが重要であり、これは組織ポリシー制約の作成ではなく、利用者のグルーピングと適切な権限の割り当てといった操作が必須となります。
選択肢：環境ごとにプロジェクトを作成し、各エンジニアリングユーザーにIAM権限を付与します
この選択肢が正しくない理由は以下の通りです。
環境ごとにプロジェクトを作成し、各エンジニアリングユーザーにIAM権限を付与するアプローチは、管理作業が大変になる上に効率的な管理手法とは言えません。一方で正解の選択肢のようにフォルダとGoogleグループを利用することで、大量のユーザーを効率的に管理できます。
参考リンク：
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://cloud.google.com/iam/docs/groups-best-practices
https://cloud.google.com/resource-manager/docs/access-control-proj
</div></details>

### Q.  問題41: 未回答
ある組織がアプリケーションホスティングサービスにGoogle Cloudを採用し、Cloud Identityアカウントのパスワード要件を設定するためのガイダンスが必要です。
Identityアカウントのパスワード要件を設定するためのガイダンスが必要です。この組織には、従業員のパスワードは最小文字数でなければならないというパスワードポリシー要件があります。
この組織が新しい要件を通知するために使用できるCloud Identityパスワードガイドラインはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudのIdentityアカウントのパスワード設定に関する規定を理解する必要があります。組織はすでに従業員のパスワードについて最小文字数の要件を設定していますが、その要件を満たすことが可能かどうかは問題文からは明らかではありません。したがって、解答する際にはCloud Identityが設定可能なパスワードの最小文字数の制限を踏まえる必要があります。
基本的な概念や原則：
Cloud Identity：Google Cloudの統合アイデンティティ管理システムです。ユーザーの認証とアクセス管理を一元化し、セキュリティとコンプライアンスの維持を支援します。
パスワードポリシー：安全なパスワード作成と管理をガイドするルールや要件のセットです。これは、パスワードの最小または最大長さ、特殊文字や数字の使用など、特有のパスワードの特性を規定するかもしれません。
Cloud Identityのパスワードポリシー：Cloud Identityでは、パスワードの最小長さを8文字に設定することが推奨されています。これは、パスワードのセキュリティを確保するための基本的なガイダンスです。
セキュリティ：システムとデータの保護を確保するための一連の原則、手段、技術です。これには、パスワードポリシー、アクセス制御、暗号化といった要素が含まれます。
コンプライアンス：法令、規則、ポリシー、スタンダードに準拠していることです。コンプライアンスの違反は、法的な罰則やビジネス上のリスクを招く可能性があります。
正解についての説明：
（選択肢）
・パスワードの最小文字数を8文字に設定します
この選択肢が正解の理由は以下の通りです。
Google CloudのCloud Identityでは、パスワードの最小文字数を8文字に設定することが推奨されています。これは、安全性と利用者の使いやすさを両立するための基準となっています。パスワードが短すぎるとセキュリティリスクが上がりますが、逆に長すぎると利用者の利便性が損なわれます。そのため、適切な長さとして8文字が推奨されているのです。
従って、組織がパスワードポリシーを設定する際には、このガイドラインに従うことが望ましいのです。Cloud Identityの機能を最大限に生かしながら、同時に企業のセキュリティ要件も満たすことができます。
不正解についての説明：
選択肢：パスワードの最小文字数を10文字に設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Identityのパスワードポリシーでは、パスワードの最小文字数は8文字と定められています。そのため、10文字という設定は可能ではありません。この要求を満たすためには、パスワードの最小文字数を8文字に設定する必要があります。
選択肢：パスワードの最小文字数を12文字に設定します
この選択肢が正しくない理由は以下の通りです。
Google CloudのIdentityパスワードポリシーでは、パスワードの最小文字数は8文字と規定されており、12文字に設定することはできません。
従って、適切なパスワード設定は"パスワードの最小文字数を8文字に設定します"が正しいガイドラインとなります。
選択肢：パスワードの最小文字数を6文字に設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Identityのパスワードポリシーでは、パスワードの最小文字数は8文字となっており、6文字に設定することはできません。そのため、パスワードの最小文字数を6文字に設定する選択肢は適用できません。
参考リンク：
https://cloud.google.com/identity/docs/how-to/setup-password-policies
https://cloud.google.com/identity/docs/concepts/identity-fundamentals
https://support.google.com/a/answer/91555?hl=en
</div></details>

### Q.  問題42: 未回答
Google CloudからオンプレミスのSIEMシステムにGoogle Cloud Operation Suiteのログを確実に配信するにはどうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud Operation SuiteのログをオンプレミスのSIEMシステムに確実に配信する方法について問われています。具体的な手段として4つの選択肢が提示されますが、解決策を選ぶ際には、Google Cloudのロギング機能とデータのエクスポートインポートに関する理解が必要です。また、SIEMシステムとの間でどのようにデータをやり取りすることが可能か、実現性と効率性にも注意しなければなりません。
基本的な概念や原則：
組織ログシンク：Google Cloudのログエクスポート機能を利用し、全プロジェクトや特定プロジェクトのログを一箇所に集約し、ストレージサービスや外部のSIEMシステムに送信します。
Cloud Pub/Sub：リアルタイムのメッセージングサービスで、別個のシステム間でメッセージを交換するための中間システムを提供します。
Dataflow：大規模なデータ処理ワークロードに対するストリームとバッチ処理の両方を提供するフルマネージドサービスです。取り扱うデータ量に応じて自動的にスケーリングします。
SIEMシステム：セキュリティ情報およびイベント管理（SIEM）システムは、セキュリティ情報やイベントをリアルタイムで分析し、アラートを提供するシステムです。
Google Cloud Operation Suiteのログ：Google Cloudプロジェクトで発生するログデータのこと。システムの運用状況やエラー情報などが記録されます。
正解についての説明：
（選択肢）
・組織ログシンクを構成して、ログをCloud Pub/Subトピックにエクスポートし、Dataflow経由でSIEMに送信します
この選択肢が正解の理由は以下の通りです。
まず、組織ログシンクを使用することで、Google Cloudのさまざまなプロジェクトから生成されるログを集約的に管理・エクスポートすることができます。これによって、一元的なログ出力管理を実現でき、確実にオペレーションスイートのログがSIEMシステムに届く確率を高めることができます。
次に、Cloud Pub/Subトピックへのエクスポートを選んだ理由は、リアルタイムでのメッセージ配信とスケーラビリティの面で優れています。Pub/Subは大量のログデータでも容易に処理でき、リアルタイム性を確保します。
最後に、Dataflowは、大量のデータをリアルタイムに処理するためのフルマネージドサービスで、データ変換やフィルタリングなど、必要なデータ処理を行うことができます。これにより、必要なログデータだけをSIEMシステムに送信することが可能となります。以上の理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：すべてのログをsyslogなどの既存のプロトコルでSIEMシステムに送信します
この選択肢が正しくない理由は以下の通りです。
Google Cloudからのログをsyslogなどの既存のプロトコルで直接SIEMシステムに送信することはできません。Google CloudではログはPub/Subトピックにエクスポートする形で提供されます。そのため、正解の選択肢のようにPub/Subにエクスポート後、Dataflowを使用してSIEMシステムに送信することが必要です。
選択肢：すべてのプロジェクトがすべてのログを共通のBigQuery DataSetにエクスポートし、SIEMシステムから照会されるように設定します
この選択肢が正しくない理由は以下の通りです。
BigQueryにログをエクスポートし、SIEMシステムから照会する方法は、ログの閲覧や分析には便利ですが、ログをオンプレミスのSIEMシステムに"確実に配信"するという要件を満たしません。
一方、Cloud Pub/SubトピックにエクスポートしてDataflow経由でSIEMに送信する方法は、ロギングデータをオンプレミスのSIEMシステムへリアルタイムで配信します。
選択肢：Google Cloud RESTful JSON APIからすべてのログをリアルタイムでクエリするためのSIEM用コネクタを構築します
この選択肢が正しくない理由は以下の通りです。
APIからすべてのログをリアルタイムでクエリすることは効率的ではなく、大量のリソースを消費する可能性があります。
一方、組織ログシンクを使用してCloud Pub/Subトピックにエクスポートし、Dataflow経由でSIEMに送信する方が、大量のログを効率的に配信できます。
参考リンク：
https://cloud.google.com/pubsub/docs
https://cloud.google.com/logging/docs/export
https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming#cloudpubsubsubscriptiontobigquery
</div></details>

### Q.  問題43: 未回答
あなたは、IAM（Identity and Access Management）管理者として管理するプロジェクトで実行される、規制対象のワークロードのプロジェクトオーナーです。今度の監査では、アクセスレビューの証跡を提出する必要があります。
どのツールを使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、IAM（Identity and Access Management）に関連したツールの機能に対する理解が必要です。特にアクセスレビューの証跡を提出するために必要なツールを選択する問題です。選択肢に含まれる各ツールが提供する機能と、問題文で求められている要件を照らし合わせて、最も適したものを選ぶことが求められています。
基本的な概念や原則：
Policy Analyzer：Google CloudのIAMポリシーを可視化し分析するツールです。ポリシーの理解と管理を助け、不要なアクセス権の特定や監某のための文書化を可能にします。
IAM（Identity and Access Management）：ユーザーやサービスアカウントの権限、アクセスレベルを管理するためのツールです。プロジェクトやリソースへのアクセスを細かく制御できます。
監査：セキュリティ上の問題や不適切なアクセスを検出し、規制の遵守を確認するためのプロセスです。
IAM Recommender：現在の使用状況に基づいてIAMポリシーの改善を提案するGoogle Cloudのツールです。
Policy Simulator：現在または提案中のIAMポリシー変更の影響をシミュレーションするツールです。アクセス状況の変更を予測できます。
正解についての説明：
（選択肢）
・Policy Analyzer
この選択肢が正解の理由は以下の通りです。
Policy Analyzerは、Google CloudのIdentity and Access Management（IAM）ポリシーを検査し、誰がどのリソースに対してどのような権限を持っているかを可視化するツールです。Policy Analyzerは予定された変更の影響を理解したり、特定のユーザーやサービスアカウントの特定のリソースへのアクセスを確認したりするために使用します。
また、このツールはユーザーやグループ、サービスアカウントが保持している特定の権限とロールを分析して、IAMポリシーをより適切に整理するのを助けます。
したがって、規制対象のワークロードのアクセスレビューの証跡を提出する必要があるときには、Policy Analyzerがその目的を達成するための適切なツールと言えます。
不正解についての説明：
選択肢：Policy Trouble Simulator
この選択肢が正しくない理由は以下の通りです。
Policy Trouble Simulatorというツールは存在しません。正解はPolicy Analyzerで、これはIAMポリシーを理解し、検証し、管理するためのGoogle Cloudのツールです。よって、アクセスレビューの証跡を提出する際にはPolicy Analyzerを使用すべきです。
選択肢：IAM Recommender
この選択肢が正しくない理由は以下の通りです。
IAM RecommenderはIAMポリシーの改善提案を行うツールであり、既存のアクセス証跡を提出する目的には適合していません。
一方、Policy AnalyzerはIAMポリシーのアクセスレベルを分析しレビューできるので、アクセスレビューの証拠提出に適しています。
選択肢：Policy Simulator
この選択肢が正しくない理由は以下の通りです。
Policy Simulatorは主にIAMポリシーの変更をシミュレートしてその影響を予測するためのツールであり、過去のアクセスレビューの証拠を提供するためのものではありません。
一方、Policy AnalyzerはIAMのアクセス許可を分析し、確認するためのツールで、アクセスレビューの証跡を提出するために適しています。
参考リンク：
https://cloud.google.com/iam/docs/policy-analyzer
https://cloud.google.com/iam/docs/managing-policies#analyzing_permissions
https://support.google.com/cloud/answer/10324190
</div></details>

### Q.  問題44: 未回答
あなたは、Google Kubernetes Engine（GKE）上の本番クラスターにコンテナ化されたアプリケーションをデプロイするためのCI/CDパイプラインをセットアップしています。既知の脆弱性を持つコンテナがデプロイされないようにする必要があります。ソリューションには以下の要件があります：
- クラウドネイティブであること
- コスト効率が高いこと
- 運用上のオーバーヘッドを最小限に抑えること
この要件を満たすために、どの方法を使うべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Kubernetes Engine（GKE）上にデプロイする際に、脆弱性を持つコンテナがデプロイされないようなCI/CDパイプラインをセットアップする方法が求められています。与えられた要件としては、クラウドネイティブなソリューションであること、コスト効率が高いこと、運用上のオーバーヘッドを最小限に抑えることが求められています。したがって、これらの要求に適合するGoogle Cloudのサービスや特性を検討し、脆弱性の分析や防止策が統合された効率的なCI/CDパイプラインを設計するためのソリューションを選択することが求められています。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：Google CloudのマネージドKubernetesサービスです。アプリケーションのデプロイ、スケーリング、運用をシンプルに、また効率的に行うことができます。
CI/CDパイプライン：継続的インテグレーション（CI）と継続的デリバリー（CD）を組み合わせた開発プロセスです。コードの変更を自動的にビルド、テスト、デプロイすることで、高速かつ安定したソフトウェアリリースを支援します。
Cloud Source Repositories：Google CloudのプライベートGitリポジトリです。ソースコードを安全にホストし、Google Cloudの他のプロダクトと統合することができます。
Cloud Build：Google Cloudのサービスで、ソースコードからコンテナイメージをビルドし、パッケージ化することができます。CI/CDパイプラインとしても使用できます。
コンテナ脆弱性診断：コンテナイメージが脆弱性を持つかどうかを評価するプロセスです。不適切なコンテナのデプロイを防ぐために使用されます。
バイナリ認証：Google Cloudのバイナリ認証では、デプロイ前にコンテナイメージの信頼性を保証します。認証のないイメージのデプロイを防止できます。
Cloud Function：Google Cloudのサーバーレス実行環境です。特定のイベントに対して自動的にトリガーされる小さな単一用途関数を作成し、実行することができます。
正解についての説明：
（選択肢）
・Cloud Source Repositoriesリポジトリのコンテナテンプレートへの変更を監視するCloud Buildパイプラインを作成します。ビルドの続行を許可する前に、コンテナ脆弱性診断の結果を分析するステップを追加します
・CI/CDパイプラインで、脆弱性が見つかっていない場合にコンテナイメージに認証を追加します。バイナリ認証ポリシーを使用して、クラスター内で認証のないコンテナのデプロイをブロックします
この選択肢が正解の理由は以下の通りです。
まず、Cloud Buildを用いて継続的デリバリーパイプラインを作成すると、Cloud Source Repositoriesにあるコンテナテンプレートの変更を監視し、予め設定したトリガーが発火した際にビルドプロセスを自動的に開始できます。コンテナの脆弱性診断の結果を分析するステップを追加することで、脆弱性をいち早く見つけ出し、それに対する対策を講じることができます。
次に、バイナリ認証ポリシーを利用することで、システムに問題のないコンテナイメージのみがデプロイされる状態を保持することができます。CI/CDパイプライン時に、脆弱性が見つからない場合にのみコンテナイメージに認証を追加することで、既知の脆弱性を持つコンテナがデプロイされるのを防ぐことができます。
以上の理由から、結果としてクラウドネイティブで高いコスト効率を持ち、運用上のオーバーヘッドを最小限に抑えることができ、要件を満たす適切な解答となります。
不正解についての説明：
選択肢：Google CloudのオペレーションスイートのログイベントをトリガーとするCloud Functionを使用して、Container Registryのコンテナイメージを自動的にスキャンします
この選択肢が正しくない理由は以下の通りです。
この手法は受動的で、脆弱性を持つコンテナがデプロイされるのを防ぐよりも、問題が発生した後で対処することに重きを置いています。しかし、問題は脆弱性を持つコンテナがデプロイされないようにすることにあります。
したがって、問題に対する有効な解決策ではありません。
選択肢：Compute Engineインスタンスのcronジョブを使用して、既知の脆弱性について既存のリポジトリをスキャンし、非準拠のコンテナイメージが見つかった場合にアラートを発生させます
この選択肢が正しくない理由は以下の通りです。
Compute Engineインスタンスのcronジョブを使用した手法は、クラウドネイティブの冗長性やスケーラビリティが制限され、効率的なコスト管理も困難です。
また、非準拠のコンテナイメージが見つかった時点でアラートを出すだけであり、これを防止する具体的な手段が提供されていません。
選択肢：GKEにJenkinsをデプロイし、CI/CDパイプラインを構成してコンテナをContainer Registryにデプロイします。コンテナをクラスターにデプロイする前に、コンテナイメージを検証するステップを追加します
この選択肢が正しくない理由は以下の通りです。
JenkinsをGKE上にデプロイすると管理オーバーヘッドが増大するからです。
また、Jenkinsの設定やメンテナンスのための追加コストが発生します。
それに対して、正解はクラウドネイティブで効率的なサービスを使用しており、運用のオーバーヘッドを最小限に抑えています。
参考リンク：
https://cloud.google.com/build/docs/automating-builds/build-repos-from-source
https://cloud.google.com/binary-authorization/docs
https://cloud.google.com/container-analysis/docs/getting-started
</div></details>

### Q.  問題45: 未回答
gcloudコマンドラインツールを使用して、サードパーティのシングルサインオン（SSO）SAML IDプロバイダを使用して認証を行いたいとします。
サードパーティのIDプロバイダ（IdP）で認証がサポートされていることを確認するために、どのオプションが必要ですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、サードパーティのシングルサインオン（SSO）SAML IDプロバイダを利用してgcloudコマンドラインツールで認証を行いたいという具体的な要求があるため、選択肢を見たときには、その要求にどの選択肢が最適に対応するのかを考えることが求められます。ここでは、SAMLとIDプロバイダがキーワードとなります。また、2つ選択するという指定があるので、全選択肢を見て選び出す必要があるという点にも注意しましょう。
基本的な概念や原則：
サードパーティIdPとしてのSSO SAML：サードパーティのシングルサインオン（SSO）サービスを使用してGoogle Cloudのリソースにアクセスするための設定です。SAML（Security Assertion Markup Language）は、データの認証と承認を交換するためのオープンスタンダードです。
OpenID Connect：ユーザー認証のためのオープンスタンダードです。IDトークンと標準的なJWT（JSON Web Tokens）を使用してユーザー情報を提供します。
Identity Platform：Google CloudのカスタマーやエンドユーザーのためのIdentity and Access Management（IAM）サービスで、B2BやB2C環境でのユーザー認証をサポートしています。
Identity-Aware Proxy：Google Cloud環境内のリソースへのアクセスをセキュアに管理できるサービスです。VPNの必要性を排除し、アクセスコントロールと認証を提供します。
Cloud Identity：Google CloudのIDaaS（Identity as a Service）、つまり、クラウドベースのIdentity and Access Managementサービスです。ユーザー、アプリケーション、およびデバイスの管理を可能にします。
正解についての説明：
（選択肢）
・サードパーティIdPとしてのSSO SAML
・OpenID Connect
この選択肢が正解の理由は以下の通りです。
まず、SSO SAMLは広く採用されている認証標準であり、一度認証することで指定したアプリケーション間で同じログイン情報を使用できるようにするものです。これはサードパーティのIDプロバイダを使用した認証であり、gcloudコマンドラインツールでの認証においてもサポートされています。これにより、ユーザは一度の認証で複数のサービスにアクセスすることができ、ユーザ体験を改善します。
また、OpenID Connectもまた、一般的な認証プロトコルで、認証とID情報の伝送に使用されます。これもまたgcloudコマンドラインツールでの認証においてはサポートされており、ユーザーの認証状態やプロフィール情報を提供します。
したがって、サードパーティのIDプロバイダがSSO SAMLとOpenID Connectをサポートしている場合、それらはgcloudコマンドラインツールとともに使用することで認証を行うことができます。
不正解についての説明：
選択肢：Identity Platform
この選択肢が正しくない理由は以下の通りです。
Identity Platformは、Google Cloud内でユーザー認証とアイデンティティ管理を提供するサービスですが、サードパーティのシングルサインオン（SSO）SAML IDプロバイダとしての機能は提供していません。
また、gcloudコマンドラインツールの認証に使用するのではなく、アプリケーションレベルでの認証とアイデンティティ管理に使用されます。
選択肢：Identity-Aware Proxy
この選択肢が正しくない理由は以下の通りです。
Identity-Aware ProxyはGoogle Cloudリソースへのセキュアなアクセスを管理するツールであり、サードパーティのIDプロバイダによる認証の検証には使用されません。適切な認証を構成するためには、SSO SAMLやOpenID Connectのような認証プロトコルのサポートが必要です。
選択肢：Cloud Identity
この選択肢が正しくない理由は以下の通りです。
Cloud IdentityはGoogleのIdentity as a Service（IDaaS）ソリューションですが、ここではサードパーティのIdPを使用する認証が求められています。SSO SAMLとOpenID ConnectはサードパーティIdPで一般的にサポートされている認証標準であるため、これらが正解となります。
参考リンク：
https://cloud.google.com/sdk/gcloud/reference/auth/login
https://cloud.google.com/identity/saml
https://openid.net/connect/
</div></details>

### Q.  問題46: 未回答
あなたは、ワークロードを保護し、会社でセキュリティ侵害が疑われる場合のアラートを受信するために、Security Command Center（SCC）を使用しています。暗号通貨マイニングソフトウェアを検出する必要があります。
どのSCCサービスを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社が使用しているSecurity Command Center（SCC）サービスの中から、特定のセキュリティ問題、つまり暗号通貨マイニングソフトウェアを検出するための最適なサービスを選ぶことが求められています。選択肢を検討する際には、それぞれのサービスがどのような脅威や脆弱性を検出するためのものかを理解し、その中から暗号通貨マイニングソフトウェアの検出に最適なものを選びます。
基本的な概念や原則：
Security Command Center（SCC）：Google Cloudのセキュリティとデータリスクプラットフォームで、コンテンツ、アセット、サービスの使用状況を網羅的に理解することができます。
Virtual Machine Threat Detection：Google CloudのSecurity Command Centerの一部で、仮想マシンに対する脅威（例えば暗号通貨マイニングソフトウェアなど）を検出するためのサービスです。
Container Threat Detection：Google CloudのSecurity Command Centerの一部で、コンテナ化されたアプリケーションに対する脅威を検出します。しかし、仮想マシンに対する脅威を検出するためにはVirtual Machine Threat Detectionを使用することが適切です。
Rapid Vulnerability Detection：脆弱性の発見と修正を迅速に行うためのサービスです。脅威検出よりも、事前の防御に注目しています。
Web Security Scanner：公開Webアプリケーションの脆弱性を自動的に走査するサービスです。公開Webアプリケーションに特化しています。
正解についての説明：
（選択肢）
・Virtual Machine Threat Detection
この選択肢が正解の理由は以下の通りです。
まず、Virtual Machine Threat Detectionは、Security Command Centerの一部として提供されます。このサービスは、Google Cloud上の仮想マシン（VM）で実行されている可能性のある悪意のある行為や不審な動作を検出する機能を備えているため、暗号通貨マイニングソフトウェアのような不正なソフトウェアの挙動を検出するのに適しています。
また、このサービスはリアルタイムのアラートを提供します。これが重要なことは、通常、暗号通貨マイニングソフトウェアは検出されるとすぐに操作を停止し、あたかも不正な活動がなかったかのように動作するからです。Virtual Machine Threat Detectionを使用すれば、そのような不正な行為を即座に捉え、対策を講じることができます。以上の理由から、暗号通貨マイニングソフトウェアを検出するにはVirtual Machine Threat Detectionを使用すべきです。
不正解についての説明：
選択肢：Container Threat Detection
この選択肢が正しくない理由は以下の通りです。
Container Threat Detectionは、サービス名にも表れているように、セキュリティ上の脅威を検出するためのコンテナ特化型のサービスです。この設問の目的は暗号通貨マイニングソフトウェアを検出することであり、その検出にはVirtual Machine Threat Detectionが適しています。
選択肢：Rapid Vulnerability Detection
この選択肢が正しくない理由は以下の通りです。
Rapid Vulnerability Detectionは弱点を素早く見つけるためのものであり、暗号通貨マイニングソフトウェアの検出には特化していません。
一方、Virtual Machine Threat Detectionは仮想マシン上の脅威、特に暗号通貨マイニングソフトウェアなどの検出に特化しています。
選択肢：Web Security Scanner
この選択肢が正しくない理由は以下の通りです。
Web Security ScannerはWebアプリケーションの脆弱性を検出するためのツールであり、暗号通貨マイニングソフトウェアを検出するという要求には対応していません。その代わりに、Virtual Machine Threat Detectionが暗号通貨マイニングソフトウェアなどの脅威を検出するために設計されています。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-threat-detection-overview
https://cloud.google.com/security-command-center/docs/how-to-use-threat-detection
https://cloud.google.com/security-command-center/docs/how-to-use-virtual-machine-threat-detection
</div></details>

### Q.  問題47: 未回答
ある顧客の社内セキュリティチームが、Cloud Storage上のデータを暗号化するための独自の暗号鍵を管理する必要があり、顧客提供の暗号鍵（CSEK）を使用することを決定しました。
チームはこのタスクをどのように完了すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、社内セキュリティチームがCloud Storageへのデータ暗号化の為に独自の暗号鍵を管理したいという要件に対して、どのアクションが正しいかを理解することが求められています。正解選択肢を選ぶためには、Google Cloud StorageとCSEK（Customer-Supplied Encryption Keys）の概念と用途を理解した上で、Google Cloud上でオブジェクトの暗号化とアップロードをどのように行うべきかを考えることが重要です。
基本的な概念や原則：
顧客提供の暗号鍵（CSEK）：ユーザーが管理する独自の暗号鍵で、Google Cloud上のデータを暗号化する際に使用します。
gsutil：Google Cloud Storageをコマンドラインから操作するためのツールで、オブジェクトのアップロードやダウンロードなどが可能です。
暗号化：データの秘匿化を行うためのプロセスで、特定の暗号鍵を使用して元のデータを解読不能な形式に変換します。
Cloud Storage：Google Cloud上で提供されるオブジェクトストレージサービスです。データを安全に保存し、グローバルなスケールで高速にアクセス可能です。
Google Cloud Console：Google Cloudのリソースやサービスを管理するためのウェブベースのインターフェースです。暗号鍵の生成などはここでは行えません。
正解についての説明：
（選択肢）
・gsutilコマンドラインツールを使ってオブジェクトをCloud Storageにアップロードし、暗号化キーの場所を指定します
この選択肢が正解の理由は以下の通りです。
まず、顧客提供の暗号鍵（CSEK）は、ユーザーが自身の暗号キーを生成・管理し、それを使ってGoogle Cloud Storage内のデータを暗号化する機能です。これにより、ユーザーは自身の暗号鍵の管理によりデータの安全性を確保できます。このCSEKへの指定はgsutilコマンドラインツールを通じて行うことができます。
また、gsutilはCloud Storageのインターフェースになりますから、データをアップロードする際に、独自の暗号化キーを指定することで、そのデータが暗号化されて保存されます。ここで重要なのは、この暗号化キーの場所を指定するという部分で、暗号化キーはその際にCloud Storageにアップロードするデータと一緒に渡されますが、Google Cloudには保存されません。
よって、オフサイトで管理される独自の暗号鍵を扱いながら、gsutilを使うことで顧客が完全にキーの管理を手元に保てるため、この選択肢が適切な答えとなります。
不正解についての説明：
選択肢：暗号化キーをCloud Storageバケットにアップロードし、同じバケットにオブジェクトをアップロードします
この選択肢が正しくない理由は以下の通りです。
暗号化キーをCloud Storageバケットにアップロードするのは安全でなく、推奨されません。なぜなら、そのキー自体が十分に保護されず漏洩する可能性があります。正しい方法は、gsutilを使用してオブジェクトをアップロードし、暗号化キーの場所を指定することです。
選択肢：Google Cloud Consoleで暗号化キーを生成し、指定したキーを使ってオブジェクトをCloud Storageにアップロードします
この選択肢が正しくない理由は以下の通りです。
Google Cloud Consoleでは独自の暗号鍵を生成できないため、顧客提供の暗号鍵（CSEK）を用いるためにはConsoleではなく、gsutilコマンドラインツールでオブジェクトをアップロードし暗号化キーの場所を指定する必要があります。
選択肢：オブジェクトを暗号化し、gsutilコマンドラインツールまたはGoogle Cloud Consoleを使用してオブジェクトをCloud Storageにアップロードします
この選択肢が正しくない理由は以下の通りです。
オブジェクトを暗号化してからCloud Storageにアップロードするという選択は、Google Cloud ConsoleでCSEKを使用するオプションが利用できないからです。正しい手順では、gsutilを用いてオブジェクトをアップロードし、暗号化キーの場所を指定することで、CSEKの管理が可能になります。
参考リンク：
https://cloud.google.com/storage/docs/encryption/customer-supplied-keys
https://cloud.google.com/storage/docs/gsutil
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題48: 未回答
あなたは、組織のGoogle Cloud環境のSecurity Command Centerの設定を任されています。セキュリティチームは、組織のコンピュート環境における潜在的な暗号マイニングに関するアラートと、セキュリティに影響を与える一般的なGoogle Cloudの誤設定に関するアラートを受信する必要があります。
これらのアラートを構成するために、どのSecurity Command Centerの機能を使用する必要がありますか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud環境のSecurity Command Centerの設定に関する知識が要求されています。特に、セキュリティチームが要求する特定のアラート、すなわち潜在的な暗号マイニングについてのアラートと、一般的なGoogle Cloudの誤設定に関するアラートを構成することが求められています。このシナリオを解決するために、Security Command Centerの何らかの特定の機能を使用する必要があるので、Google Cloudのセキュリティ関連の機能について理解していることが重要となります。選択肢を見るときは、それらが出題のシナリオと一致するかどうかを注意深く確認してください。
基本的な概念や原則：
Event Threat Detection：Google Cloudのログデータを分析するSecurity Command Centerの機能で、潜在的なセキュリティ脅威や不審な行動を自動的に検出しアラートを発します。この機能を使用すると、暗号マイニングといった特定の脅威に対するアラートを構成することができます。
Security Health Analytics：Google Cloud環境の設定を自動的に確認し、可能性のあるセキュリティ上の問題を識別するSecurity Command Centerの機能です。設定エラーや誤設定、ベストプラクティスの遵守状況について報告します。
Container Threat Detection：Google Kubernetes Engine（GKE）上で動作するコンテナに対する脅威を検出する機能です。ただし、一般的なGoogle Cloudの誤設定や暗号マイニングに対する検出は含まれません。
Cloud Data Loss Prevention：機密データの検出、分類、保護のためのサービスです。データ損失や準拠違反を予防しますが、特定の脅威を検出する機能は含まれません。
Google Cloud Armor：Google Cloudのアプリケーションやサービスに対する攻撃を防ぐためのネットワークセキュリティサービスです。DDoS攻撃などの脅威を検出・阻止しますが、一般的な誤設定や暗号マイニングに対する検出機能は含まれません。
正解についての説明：
（選択肢）
・Event Threat Detection
・Security Health Analytics
この選択肢が正解の理由は以下の通りです。
まず、"Event Threat Detection"（ETD）は、Google Cloud内のリアルタイムのログデータを分析し、セキュリティインシデントや脅威を検出するためのSecurity Command Centerの一部です。ETDは、公開されたIAM権限、不正な出入りなど様々な種類の脅威、そして特にここで重要なのは、暗号マイニングなどの不審なアクティビティを自動的に検出します。
次に、"Security Health Analytics"（SHA）は、組織のGoogle Cloud環境の様々な設定に対するベストプラクティスへの準拠を自動的に確認し、セキュリティ設定の誤りを発見してそれらに対するアラートを生成するためのツールです。具体的には、IAMポリシー、ネットワーク設定、ストレージ設定など、Google Cloudの多くのサービスに関連する設定の誤りを特定します。
したがって、これらの機能を用いてセキュリティチームは潜在的な暗号マイニングに関するアラートと、一般的なGoogle Cloudの誤設定に関するアラートを受信することが可能となります。
不正解についての説明：
選択肢：Container Threat Detection
この選択肢が正しくない理由は以下の通りです。
Container Threat Detectionは、Google Kubernetes Engineクラスターで動作しているコンテナに対する脆弱性の検知を提供する機能であり、暗号マイニングや一般的な誤設定に関するアラートの設定には用いられません。反対に、Event Threat Detectionは潜在的な暗号マイニング活動の検知、Security Health AnalyticsはGoogle Cloudの誤設定を検知するために使用します。
選択肢：Cloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Preventionは、機密データが漏えいしないかを監視するための機能です。しかし、問題で求められているのは潜在的な暗号マイニングに関するアラートとGoogle Cloudの誤設定に関するアラートです。これらはEvent Threat DetectionとSecurity Health Analyticsの機能を使用することで設定することができます。
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは、Google Cloudロードバランサーに導入されたコンテンツデリバリーネットワークを保護し、DDLアタックなどのセキュリティリスクから保護するためのサービスです。しかし、この要件は誤設定と暗号マイニングの検出のためのアラートが中心なので、Google Cloud Armorでは対応できません。
一方、Event Threat DetectionとSecurity Health Analyticsではこれらの要求を満たせます。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-security-sources#threat_detection
https://cloud.google.com/security-command-center/docs/concepts-security-health-analytics
https://cloud.google.com/security-command-center/docs/how-to-notifications-and-alerts
</div></details>

### Q.  問題49: 未回答
ある顧客は、Google Cloud上でホストされているCRMのウェブインターフェイスに、従業員のモバイル端末からアクセスできるようにしたいと考えています。このCRMには、企業ネットワーク上の人しかアクセスできません。顧客はインターネット経由で利用できるようにしたいと考えています。あなたのチームは、アプリケーションの前に二要素認証をサポートする認証レイヤーを必要としています。
これらの要件を満たすために、顧客はどのGoogle Cloudサービスを導入すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客が目指す目標と具体的な要件を理解し、どのGoogle Cloudサービスがそれらを満たすか判断する能力が試されています。特に注目すべきは、ウェブインターフェイスに外部からアクセス可能にするというニーズと、二要素認証をサポートする認証レイヤーが必要であるという要件です。これらを満たし、同時に適切なセキュリティを維持できるGoogle Cloudサービスを選択することが求められています。
基本的な概念や原則：
Cloud Identity-Aware Proxy（IAP）：Google Cloud上のアプリケーションとリソースへのセキュアなアクセスを制御するサービスです。ユーザーとリソース間の通信を中継し、アイデンティティとコンテキストに基づいてアクセスを管理します。
二要素認証：認証時に2つ以上の異なる要素（知識、所有、生体認証）を要求し、より強固なセキュリティを提供する方法です。Cloud IAPは二要素認証をサポートします。
Cloud Armor：Google Cloudの分散型デニーアルオブサービス（DDoS）防御とウェブアプリケーションファイアウォール（WAF）のサービスです。Cloud IAPとは異なり、認証やアクセス制御は提供していません。
Cloud Endpoints：Google Cloud上でAPIを開発、デプロイ、管理するためのツールです。リクエストの認証やトラフィックの監視を行いますが、特定のアプリケーションへの認証レイヤーの追加はサポートしていません。
Cloud VPN：企業ネットワークとGoogle Cloud上のVPCネットワークを安全に接続するためのサービスです。二要素認証の提供はしていません。
正解についての説明：
（選択肢）
・Cloud Identity-Aware Proxy
この選択肢が正解の理由は以下の通りです。
まず、Cloud Identity-Aware Proxy（IAP）は、Google Cloud上にホストされたアプリケーションへのセキュアなアクセスを提供するサービスです。これにより、ユーザーはインターネット経由でCRMにアクセスでき、企業ネットワークから離れた場所でもアプリケーションにアクセスできます。これは、モバイル端末からCRMにアクセスする要件を満たします。
さらに、IAPは認証と認可を管理し、アクセスを試みる個々のユーザーを特定します。ユーザーとサービス間の通信は、Googleのインフラを介してセキュアに行われます。IAPは、Identity Platformと統合されており、二要素認証を含む強力な認証オプションを提供します。これにより、顧客のセキュリティ要件である二要素認証のサポートも満たされます。
したがって、Cloud Identity-Aware Proxyは、顧客の要件を満たす最適なGoogle Cloudサービスと言えます。
不正解についての説明：
選択肢：Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Cloud Armorは主にDDoS攻撃やSQLインジェクション等のウェブ攻撃からアプリケーションを保護する機能を提供するもので、二要素認証の機能は提供していません。
それに対して、Cloud Identity-Aware Proxyはアプリケーションへのアクセスを認証・認可し、二要素認証もサポートしており、要件に合致します。
選択肢：Cloud Endpoints
この選択肢が正しくない理由は以下の通りです。
Cloud EndpointsはAPIの開発、デプロイ、保護、スケーリングに使用しますが、二要素認証のレイヤーの提供が主な目的ではありません。
一方、Cloud Identity-Aware Proxyはアプリケーションへの認証およびアクセスを管理し、二要素認証をサポートします。
選択肢：Cloud VPN
この選択肢が正しくない理由は以下の通りです。
Cloud VPNは企業のネットワークとGoogle Cloudのネットワークを接続するためのサービスで、二要素認証やユーザーの認証レイヤーを提供するものではありません。
一方、Cloud Identity-Aware Proxyはアプリケーションへのアクセスを制御し、二要素認証をサポートしているため、この要件に適しています。
参考リンク：
https://cloud.google.com/iap/docs
https://cloud.google.com/identity-platform/docs/web/mfa
https://support.google.com/a/answer/6197438?hl=en
</div></details>

### Q.  問題50: 未回答
Cloud Data Loss Prevention（Cloud DLP）APIの導入が社内で進むにつれ、コスト削減のために利用を最適化する必要が出てきました。Cloud DLPの対象データはCloud StorageとBigQueryに保存されます。保存場所とリージョンはリソース名のサフィックスとして識別されます。
どのコスト削減オプションを推奨しますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Data Loss Prevention（Cloud DLP）APIの導入が進み、コスト削減のために利用を最適化する必要がある状況に対して、どのコスト削減のオプションを選択すべきかを問っています。特に、"Cloud DLPの対象データはCloud StorageとBigQueryに保存され、この保存場所とリージョンはリソース名のサフィックスとして識別される"という情報に注目する必要があります。そのため、選択肢を見る時には、Cloud DLPがCloud StorageやBigQueryにデータをどのように保存するか、どのような手段でコスト削減を行えるか、そしてそれが設問の条件と照らし合わせて適合するかを確認しながら選ぶべきです。
基本的な概念や原則：
Cloud Data Loss Prevention（Cloud DLP）：感度が高い情報を識別、マスク、保護するためのGoogle Cloudのサービスです。コスト最適化のためにデータのサンプリングやスキャン範囲の制限が可能です。
Cloud Storage：大量データの保管に対応したオブジェクトストレージサービスです。世界中のどこからでもデータにアクセスすることができます。
BigQuery：大規模データセットの高速分析のためのフルマネージド、サーバーレス、高耐久性のデータウェアハウスです。
rowsLimit：Cloud DLPでデータをサンプリングする際に利用する設定です。指定した行数を上限にしてスキャンを行います。
bytesLimitPerFile：Cloud DLPでデータをサンプリングする際に利用する設定です。指定したバイト数を上限にしてスキャンを行います。
CloudStorageRegexFileSet：Cloud Storage内の特定のファイルセットを指定するための設定です。これにより、必要なデータのみをスキャンすることでコストを削減できます。
リージョン：地理的に近いデータセンターからサービスを提供するための設定です。リージョンを最適に管理することで、データ転送量やレイテンシを削減し、コストを抑えることが可能です。
正解についての説明：
（選択肢）
・rowsLimitとbytesLimitPerFileを使用してデータをサンプリングし、CloudStorageRegexFileSetを使用してスキャンを制限します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Data Loss Prevention（Cloud DLP）APIは、顧客が持つ機密データや個人情報データを識別し、分類し、保護するためのAPIサービスです。これはトラフィックとストレージの使用量に連動してコストが発生するため、対象データ量を増やすと、それに伴ってコストも増加します。
正解選択肢の"rowsLimit"と"bytesLimitPerFile"を使用する方法は、スキャンする対象データの量を制限することでコストを最適化するアプローチです。
また、"CloudStorageRegexFileSet"を用いることで、スキャンするファイル群を正規表現を用いて詳細に制御できます。
以上から、非必要なスキャンを削減しコストを最適化するためには、"rowsLimit"、"bytesLimitPerFile"、"CloudStorageRegexFileSet"の利用を推奨することが適切と判断されます。
不正解についての説明：
選択肢：米国外でホストされているBigQueryデータには適切なrowsLimit値を設定し、マルチリージョンのCloud Storageバケットには適切なbytesLimitPerFile値を設定します
この選択肢が正しくない理由は以下の通りです。
この選択肢はコスト削減の観点からは正しいかもしれませんが、Cloud DLPの効率的な使用を最適化するだけでなく、データ保護も重要です。正解の選択肢はデータサンプリングを提案しており、これによりコスト削減だけでなくデータ保護も実現できます。つまり、適切なrowsLimit値とbytesLimitPerFile値を設定することだけでは充分ではないのです。
選択肢：米国外でホストされているBigQueryデータには適切なrowsLimit値を設定し、マルチリージョンのCloud Storageバケットでは変換単位を最小化します
この選択肢が正しくない理由は以下の通りです。
BigQueryデータのホスト国ではなく、データのサンプリングとスキャン範囲の制限など、データ自体の管理に注目するべきです。
また、マルチリージョンのCloud Storageバケットで変換単位を最小化すると、コスト削減よりもむしろパフォーマンス等が低下する可能性があります。
選択肢：FindingLimitsとTimespanContfigを使ってデータをサンプリングし、変換単位を最小化します
この選択肢が正しくない理由は以下の通りです。
FindingLimitsとTimespanContfigはCloud DLPに存在しないパラメータです。
したがって、コスト削減オプションとしては適切ではありません。
一方、rowsLimitとbytesLimitPerFileを使用してデータをサンプリングし、CloudStorageRegexFileSetを使用してスキャンを制限することは、コスト削減の有効な手段です。
参考リンク：
https://cloud.google.com/dlp/docs/concepts-limits
https://cloud.google.com/dlp/docs/inspecting-storage
https://cloud.google.com/dlp/docs/samples/dlp-inspect-file-regexp-sample
</div></details>


## 4

### Q.  問題1: 未回答
あるマネージャーが、コストを最小限に抑えながら、セキュリティイベントログを2年間保持し始めたいと考えています。あなたは、適切なログエントリを選択するフィルタを作成します。
ログをどこにエクスポートしますか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、コスト低減とセキュリティイベントログの保持の両方を同時に達成する適切なログエクスポート先を選ぶことが求められています。2年間のログを保持するという長期の要件と、コストを最小限に抑えるという制約があるため、その中で最もコスト効率の良いストレージソリューションを選択することが重要です。また、適用可能なデータ保持ポリシーやアクセス制御も考慮に入れる必要があります。
基本的な概念や原則：
Cloud Storage：Google Cloudの耐久性とスケーラビリティを備えたオブジェクトストレージサービスです。低コストなアーカイブオプションが提供され、長期間のデータ保管に適しています。
セキュリティイベントログ：システムやアプリケーションのセキュリティに関連する活動を記録したものです。監査やトラブルシューティングのために利用されます。
フィルタ：特定の条件を満たすデータを選択するためのルールまたはパラメータです。ログエントリの選択に利用されます。
BigQuery：Google Cloudのフルマネージドなビッグデータ分析サービスです。リアルタイム分析が可能で、大量のデータを高速に処理します。ただし、コストはCloud Storageよりも高いです。
ロギング：システムやアプリケーションの活動を追跡するための情報のレコードです。オペレーションスイートのロギングは、リアルタイムでの追跡やアラートに主に利用されます。
Cloud Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。データをストリーミングし、リアルタイムに処理するケースに最も適しています。
正解についての説明：
（選択肢）
・Cloud Storageバケット
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageは長期間のデータ保管に適しています。マネージャーがセキュリティイベントログを2年間保持したいという要件を満たす点で有利です。
また、データの維持期間が長い場合、コストが重要な要素となります。Cloud Storageはコスト効率が高く、量の多いデータを格納するのに適しています。
さらに、Cloud Storageには強力なセキュリティ機能があり、ログデータの外部からのアクセスを効果的に制御できます。このため、セキュリティイベントログというセキュリティ上重要な情報を格納するのに適しています。
したがって、コストを最小限に抑えつつもセキュリティイベントログを2年間保持したいというこのシナリオにおいて、Cloud Storageバケットは適切な選択となります。
不正解についての説明：
選択肢：BigQueryデータセット
この選択肢が正しくない理由は以下の通りです。
BigQueryデータセットにログをエクスポートするとコストが高くなります。コストを最小限に抑えるためには、ストレージコストが低いCloud Storageバケットを用いたログのエクスポートが適しています。
選択肢：オペレーションスイートのロギング
この選択肢が正しくない理由は以下の通りです。
オペレーションスイートのロギングは、短期間のログデータの保持と分析に用いられますが、デフォルトでは最大で30日間しかログを保持できません。長期間、特に2年間のセキュリティイベントログを保持するためには、コストを最小限にする観点からもCloud Storageバケット使用が適しています。
選択肢：Cloud Pub/Subトピック
この選択肢が正しくない理由は以下の通りです。
Cloud Pub/Subトピックはリアルタイムのメッセージングとストリーミングのためのサービスであり、長期間のログ保持には適していません。
一方、Cloud Storageバケットはコスト効率が高く、長期間のデータ保管に適しています。
参考リンク：
https://cloud.google.com/logging/docs/storage
https://cloud.google.com/storage/docs
https://cloud.google.com/logging/docs/export/aggregated_exports
</div></details>

### Q.  問題2: 未回答
あなたの組織の顧客は、契約書と運転免許証をスキャンし、Cloud Storageのウェブポータルにアップロードする必要があります。12か月以上前のファイルから、個人を特定できる情報（PII）をすべて削除する必要があります。また、保管目的で匿名化されたファイルをアーカイブする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、リテンション期間が終了した個人を特定できる情報（PII）を削除し、匿名化したデータの保管を実現することが求められています。このため、データ非識別化技術を使いつつ、アーカイブ処理に適したGoogle Cloudのサービスを選ぶことが問題の解答に至る鍵となります。問題文からは、PIIを非識別化する必要があること、そしてそれらのファイルを新しいストレージに保存するという情報が得られます。これらの要件をしっかり理解することが、問題解決のための正しいGoogle Cloudサービスを選択する上で重要となります。
基本的な概念や原則：
Cloud Storage：Google Cloudの持続的なデータ保管サービスです。バケット内にデータを安全に保存し、任意の場所からアクセスすることができます。
Cloud Data Loss Prevention（DLP）：感度の高いデータや個人を特定できる情報（PII）を検出、非識別化、保護するためのGoogle Cloudのサービスです。
検査ジョブ：Cloud DLPにおけるデータセットのスキャン操作です。特定のデータに存在する潜在的な機密情報を特定するために使用します。
非識別化：個々のデータ要素が特定の個人を識別するのを防ぐためにデータを変更するプロセスです。これにより、データの有用性を維持しつつプライバシーが保護されます。
アーカイブ：長期間データを保管するための低コストなストレージオプションです。アクセス頻度が低いデータに適しています。
Cloud Key Management Service（KMS）：暗号鍵の作成、使用、管理、および破棄を行うGoogle Cloudのサービスです。しかし、データ自体を非識別化することはできません。
正解についての説明：
（選択肢）
・Cloud Data Loss Prevention（DLP）検査ジョブを作成し、12ヶ月以上前に作成されたファイルのPIIを非識別化し、別のCloud Storageバケットにアーカイブします。元のファイルを削除します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Data Loss Prevention（DLP）は、個人を特定できる情報（PII）を発見、非識別化し、保護できるGoogle Cloudのサービスです。このため、急務となっている12ヶ月以上前の情報を非識別化するためにDLPは適用されます。作成した検査ジョブによってPII情報が非識別化され、その結果は別のCloud Storageバケットに安全にアーカイブされます。
さらに、検査ジョブ作成の後、元のファイルの削除が要求されています。本件の要件と互換性が高いのは、DLPの特定の情報を検出し、マスクまたは非表示にする機能およびCloud Storageバケット間でのデータの操作が容易な性質ゆえです。そのマネージャーブルで柔軟性のある性質により、Cloud DLPとCloud Storageは、このような運用要件を満たすのに最適な選択肢となります。
不正解についての説明：
選択肢：PIIを削除し、ファイルをArchiveストレージクラスに移動するCloud Storageバケット内のファイルのTTL（Time To Live）を12ヶ月に設定します
この選択肢が正しくない理由は以下の通りです。
TTLはCloud Storageでの直接的な機能ではなく、Cloud StorageではPIIの削除などの特定の操作を実行するためにこれを使用することはできません。PIIを非識別化するためにはCloud DLPのようなサービスが必要です。
選択肢：Cloud StorageバケットのAutoclass機能を設定し、PIIを非識別化します。12ヶ月以上前のファイルをアーカイブします。元のファイルを削除します
この選択肢が正しくない理由は以下の通りです。
まず、Cloud StorageのAutoclassという機能は存在しません。そのため、ファイルのPIIを非識別化するためには、Cloud DLPのような専用のツールを使用する必要があります。
また、この選択肢ではファイルの非識別化や削除などのプロセスを自動化する手段が明示されていません。
これに対して正解の選択肢は、Cloud DLPを用いて自動的にPIIを非識別化し、元のファイルを削除することを提案しています。
選択肢：Cloud Key Management Service（KMS）のローテーション期間を12カ月に設定し、PIIを含むCloud Storageファイルの暗号鍵を非識別化します。オリジナルの鍵を削除します
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Service（KMS）はデータの暗号化と復号化を行うサービスであり、個人情報（PII）の特定や非識別化は行いません。そのため、ローテーション期間を設定しても12カ月後にPIIを削除することはできないため、この課題を解決する適切な選択肢ではありません。
参考リンク：
https://cloud.google.com/dlp/docs/creating-job-triggers
https://cloud.google.com/dlp/docs/deidentify-sensitive-data
https://cloud.google.com/storage/docs/bucket-archiving-classes
</div></details>

### Q.  問題3: 未回答
あなたの会社では、セキュリティチームとネットワークエンジニアリングチームが、VPC内およびVPC間のすべてのネットワーク異常、VMからVMへの内部トラフィック、インターネット上のエンドロケーションとVM間のトラフィック、VMから本番のGoogle Cloudサービスへのトラフィックを特定する必要があります。
この要件を満たすために、どの方法を使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、VPC内やVPC間、VM間の各種トラフィックの特定が必要であるという状況を対象としています。重要な要点は、単なるロギングや一般的なネットワークの分析ではなく、特定のネットワーク異常や特定のトラフィックをキャプチャするというニーズがあるということです。したがって、選択肢を評価する際には、各トラフィックフローの詳細な分析と識別が可能なツールやサービスに焦点を当てるべきです。
基本的な概念や原則：
Packet Mirroring：Google Cloud上でネットワークトラフィックを複製し、異常検出やパフォーマンス監視に利用できる機能です。VPC内、VPC間、VM間、インターネット上、VMとGoogle Cloudサービス間のトラフィックも検出可能です。
組織ポリシー：Google Cloudのリソースに対するロールベースのアクセス制御の一部です。組織レベルで一貫した制御を提供しますが、ネットワーク異常の特定には用いられません。
VPCフローログ：VPCネットワーク内のIPトラフィックをキャプチャし、ログに記録する機能です。しかし、この機能はネットワーク全体の異常に対してではなく、特定のサブネットでのトラフィックに対して有効化されます。
Cloud Audit Logs：Google Cloudリソースの行動や変更を追跡・ロギングするサービスです。異常ネットワークトラフィックの追跡には直接使われません。
正解についての説明：
（選択肢）
・Packet Mirroringのポリシーを設定します
この選択肢が正解の理由は以下の通りです。
Packet MirroringはGoogle Cloudの特性の一つで、特定のトラフィック（VPC内、VPC間、インターネット上のエンドロケーションと仮想マシン（VM）間のトラフィックやVMからGoogle Cloudのサービスへのトラフィックなど）を複製し、指定した収集ポイントに送信する機能を提供します。これにより、セキュリティチームとネットワークエンジニアリングチームは、移動中の情報の詳細を理解し、必要に応じて異常を特定することができます。異常検知、アプリケーションパフォーマンスのモニタリング、障害検出、セキュリティ監視などに役立ちます。
したがって、Packet Mirroringのポリシーを設定することは、これらの要件を満たす最も適切な手段と言えます。
不正解についての説明：
選択肢：組織ポリシーの制約を定義します
この選択肢が正しくない理由は以下の通りです。
組織ポリシーの制約は、リソースに設定するGoogle Cloudポリシーを定義し、リソースの管理を集中化することを目的としています。しかし、ネットワーク異常の検出や特定のトラフィックの特定には使用できません。
一方、Packet Mirroringはネットワークトラフィックを複製し監視するための機能で、要件を満たします。
選択肢：サブネットでVPCフローログを有効にします
この選択肢が正しくない理由は以下の通りです。
VPCフローログを有効化すると、IPレベルのトラフィックの流れを追跡できますが、これは個々のパケットの詳細な情報を提供しません。その点で、Packet Mirroringは特定の流れを複製し、より深く検査する手段を提供するため、ネットワーク異常や特定のトラフィックを詳細に把握するためには有用です。
選択肢：Cloud Audit Logsの監視と分析を使用します
この選択肢が正しくない理由は以下の通りです。
Cloud Audit Logsは主にGoogle CloudのAPI呼び出しなどを記録し、ユーザーやサービスアカウントによる活動の監視と追跡を目的としています。
それに対し、要件はネットワーク異常やトラフィックの特定という点に集中していて、Packet Mirroringのポリシーを設定することでこれらを満たすことができます。
参考リンク：
https://cloud.google.com/vpc/docs/packet-mirroring
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/logging/docs/audit
</div></details>

### Q.  問題4: 未回答
あなたの会社は最近、サービスアカウントキーの使用を最小限に抑えるセキュリティポリシーを発表しました。オンプレミスのWindowsベースのアプリケーションがGoogle Cloud APIと相互作用しています。オンプレミスのIDプロバイダーとワークロードIDフェデレーション（WIF）を実装する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミスのWindowsベースのアプリケーションがGoogle Cloud APIと相互作用できるようにするため、また、サービスアカウントキーの使用を最小限に抑えるセキュリティポリシーを遵守するための適切な手順を問われています。オンプレミスのIDプロバイダーとワークロードIDフェデレーションを使用する要件があります。ここでは、Active Directoryフェデレーションサービス（ADFS）またはOpenID Connect（OIDC）を使用したフェデレーションの設定方法を必要としますが、どのように設定すればセキュリティポリシーに適合するかを正しく理解することが求められています。
基本的な概念や原則：
サービスアカウント：Google CloudのAPIとのやり取りを行うための特殊なアカウントです。ワークロードがGoogleのサービスと相互作用するために使用します。
Active Directoryフェデレーションサービス（ADFS）：企業のActive DirectoryとCloudサービスの間のフェデレーション認証を実現するWindows Server機能です。ユーザーは一度ログインすれば社内外のさまざまなサービスをシームレスに利用できます。
ワークロードIDプール：ワークロード（オンプレミスやクラウドのアプリケーションやVMなど）がGoogleのサービスと直接やり取りできるように認証と認可を行う仕組みです。
サービスアカウントの偽装：特定のサービスアカウントの権限を引き継いで操作を行う機能です。偽装することで、そのサービスアカウントが持つ権限でAPIを利用できます。
OpenID Connect（OIDC）：ユーザー認証情報を交換するためのシンプルな識別層で、OAuth 2.0プロトコルを拡張しています。ただし、Google CloudではADFSが推奨されます。
セキュリティポリシー：組織のセキュリティ要件を明確に定義した文書です。このケースでは、サービスアカウントキーの使用を制限するというポリシーが適用されています。
プリンシパル：セキュリティモデルにおける行動主体で、エンティティ（ユーザー、サービスアカウントなど）のことを指します。プリンシパルは特定の権限と関連付けられ、アクセス制御の対象となります。
正解についての説明：
（選択肢）
・企業のActive Directoryフェデレーションサービス（ADFS）でワークロードIDプールを設定します。プール内のプリンシパルにGoogle Cloudサービスアカウントを偽装させるルールを設定します
この選択肢が正解の理由は以下の通りです。
まず、企業のActive Directoryフェデレーションサービス（ADFS）は一般的にオンプレミス環境で使用されるIDプロバイダーであり、Windowsベースのアプリケーションと互換性が高いです。これはWindowsベースのアプリケーションのIDフェデレーションの要件を満たします。
また、ワークロードIDプールの設定は、Google Cloud APIでの認証を行うためのものであり、これはワークロードIDフェデレーション（WIF）の実装条件を満たします。
さらに、プリンシパル（ユーザーやサービス）にGoogle Cloudサービスアカウントを偽装させるルールを設定することで、安全かつ効率的にGoogle Cloud APIを使用できます。
そして、最も重要な点として、サービスアカウントキーの使用を最小限に抑えることが可能なため、会社のセキュリティポリシーに適合しています。これによって、セキュリティリスクが低減され、安心してGoogle Cloud APIを利用できます。
不正解についての説明：
選択肢：企業のActive Directoryフェデレーションサービス（ADFS）でワークロードIDプールを設定します。プール内のすべてのプリンシパルをGoogle Cloudサービスアカウントになりすます
この選択肢が正しくない理由は以下の通りです。
全てのプリンシパルをGoogle Cloudサービスアカウントになりすますと、セキュリティポリシーの目的である"サービスアカウントキーの使用を最小限に抑える"の達成が難しくなります。
正解の選択肢のように、対象となるプリンシパルにのみ偽装させるルールを設定することで、セキュリティを確保しながら要件を満たすことができます。
選択肢：同じマシン上でOpenID Connect（OIDC）サービスを使用してワークロードIDプールをセットアップします。プール内のプリンシパルにGoogle Cloudサービスアカウントを偽装させるルールを設定します
この選択肢が正しくない理由は以下の通りです。
同じマシン上でOpenID Connect（OIDC）サービスを使用してワークロードIDプールを設定すると言っているが、OpenID Connectは認証フレームワークであり、ユーザーのIDをフェデレーションするためのフレームワークではないからです。この要件では、企業のActive Directoryフェデレーションサービス（ADFS）を使用する方が、一貫性のある権限の制御やポリシー適用を実現できます。
選択肢：同じマシン上でOpenID Connect（OIDC）サービスを使用してワークロードIDプールをセットアップします。プール内のすべてのプリンシパルをGoogle Cloudサービスアカウントになりすます
この選択肢が正しくない理由は以下の通りです。
企業が既にActive Directoryフェデレーションサービス（ADFS）を使用しているので、新たにOpenID Connect（OIDC）サービスをセットアップするのは冗長であり、また、構成や管理の面で追加の工数が必要となります。既存のADFSを利用することで、新規のセットアップ作業を削減し、必要なフェデレーションを維持することができます。
参考リンク：
https://cloud.google.com/iam/docs/workload-identity-federation
https://cloud.google.com/iam/docs/impersonating-service-accounts
https://cloud.google.com/docs/authentication/production#auth-cloud-implicit-python
</div></details>

### Q.  問題5: 未回答
あなたはセキュリティチームの一員で、プロジェクトAのCloud StorageバケットがプロジェクトBからしか読み取れないようにしたいと考えています。また、ユーザーが正しい認証情報を持っていても、Cloud Storageバケット内のデータにネットワーク外のCloud Storageバケットからアクセスしたり、Cloud Storageバケットにコピーしたりできないようにしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ある特定のプロジェクト間だけでCloud Storageバケットへのアクセスを制限し、それ以外からのアクセスやデータのコピーを防ぐ方法を求められています。問題のキーは、Cloud Storageバケットへのアクセスをどう制限し、また制限範囲をどのように設定すべきかです。セキュリティの観点から、ネットワーク外からの不正なアクセスを防ぐ必要があるという前提も理解しておくと良いでしょう。それぞれの選択肢がその要件をどのように満たすかを評価していきます。
基本的な概念や原則：
VPC Service Controls：Google Cloud上の資源に対する信頼できないネットワークからのデータエクストリームのリスクを軽減します。これにより、セキュリティ境界を設定し、その境界を越えたデータ流出を防止できます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。高い耐久性とスケーラビリティを備えています。
VPC：Virtual Private Cloud（VPC）は、Google Cloud上で定義されたプライベートネットワークスペースで、Google Cloudのリソースを仮想ネットワーク上に配置できます。
ドメイン制限共有：特定のドメイン内からのリクエストだけを許可し、他のドメインからのリクエストをブロックする機能です。ただし、これはCloud Storageバケット間の通信には適用できません。
プライベートアクセス：VPCネットワークのリソースがGoogle Cloudのサービスへの非インターネットルートを使用することを可能にします。しかし、これはプロジェクト間の通信の制御には使用できません。
VPCピアリング：VPCネットワークを相互に接続する機能で、異なるプロジェクト間や異なる組織間でもネットワークトラフィックがGoogleのネットワーク内を通過します。この機能を使用しても、Cloud Storageバケットのアクセス制御は行えません。
ファイアウォールルール：VPCネットワーク内外からのネットワークトラフィックを制御する機能です。ただし、Cloud Storageバケットに対するアクセス権を制限するためには、VPC Service Controlsを使用する必要があります。
正解についての説明：
（選択肢）
・VPC Service Controlsを有効にし、プロジェクトAとBで境界を作成し、Cloud Storageサービスを含めます
この選択肢が正解の理由は以下の通りです。
まず、VPC Service ControlsはGoogle Cloudのサービスを仮想的な境界で囲むことができ、境界外からのデータアクセスを制御する機能を提供します。これにより、プロジェクトAとBの間で境界を作成することで、その他のプロジェクトからのアクセスを防止することが可能となります。これは、プロジェクトAのCloud Storageバケットに対するデータの読取りをプロジェクトBからのみに限定したいという要件を満たします。
また、VPC Service Controlsはユーザーが正しい認証情報を持っていても、ネットワーク外のCloud StorageバケットからCloud Storageバケット内のデータにアクセスしたり、そこへコピーしたりすることを防止します。これにより、インターネット越しにデータを取り出されるリスクを減らすことができます。
したがって、VPC Service Controlsを有効にし、プロジェクトAとBで境界を作成し、Cloud Storageサービスを含めることが、この問題の要件を満たす最善の方法です。
不正解についての説明：
選択肢：Cloud Storageバケットで、ドメイン制限共有組織ポリシーとバケットポリシーのみを有効にします
この選択肢が正しくない理由は以下の通りです。
ドメイン制限共有組織ポリシーやバケットポリシーだけでは、データアクセスを制限するためのネットワークの境界を作成することはできません。VPC Service Controlsを使用することで、ネットワークの境界を作成し、Cloud Storageバケットへのアクセスを制限することが可能となります。
選択肢：厳密なファイアウォールルールでプロジェクトAとBのネットワークでプライベートアクセスを有効にし、ネットワーク間の通信を許可します
この選択肢が正しくない理由は以下の通りです。
ファイアウォールルールとプライベートアクセスはネットワークレベルでの制御であり、Cloud Storageのバケットへの特定の種類のアクセス制限（データエクスフィルトレーション）を行う能力はありません。
それに対して、VPC Service ControlsはGoogle Cloudサービスに対するアクセス制限を可能にします。
選択肢：プロジェクトAとBのネットワーク間でVPCピアリングを有効化し、厳格なファイアウォールルールでネットワーク間の通信を許可します
この選択肢が正しくない理由は以下の通りです。
VPCピアリングはプロジェクト間のネットワーク接続を設定しますが、Cloud Storageバケットへのアクセス制御を行う機能はありません。
一方、VPC Service Controlsはサービス間のデータ漏洩を防止するためのサービスであり、この問題の要件を満たすための最適な選択肢です。
参考リンク：
https://cloud.google.com/storage/docs/vpc-service-controls
https://cloud.google.com/vpc-service-controls/docs/overview
https://cloud.google.com/storage/docs/access-control/
</div></details>

### Q.  問題6: 未回答
PCI DSS要件を満たすために、顧客はすべての送信トラフィックが許可されていることを確認したいと考えています。
追加的な代替コントロールなしでこの要件を満たすクラウドオファリングはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、PCI DSS要件を満たすために許可されている送信トラフィックを確認するために使用できるクラウドオファリングを特定するよう求められています。注意すべきは、"追加的な代替コントロールなしで"という表現であり、これにより提供された選択肢の中から何も追加しなくてもPCI DSS要件を満たせることが明確であるサービスのみを選ぶべきであることが解ります。選択肢を見るとき、そのクラウドオファリングが通常どのような機能や制御を提供しているかをよく理解していることが重要です。
基本的な概念や原則：
PCI DSS：クレジットカード情報を扱うすべての企業が遵守する必要があるセキュリティ標準です。データを保護し、カードホルダーの情報を盗難から守るための広範囲な要件を提供します。
Compute Engine：Google Cloudの仮想マシンを提供するIaaSサービスです。全ての送信トラフィックを許可し、ユーザーがネットワークの設定やセキュリティの制御を持つことができます。
Google Kubernetes Engine（GKE）：Google Cloudのコンテナ化されたアプリケーションを管理し、運用するためのPaaSサービスです。送信トラフィックの許可と管理に柔軟性を持たせることが可能です。
App Engine：Google CloudのフルマネージドなPaaSサービスで、アプリケーション開発、デプロイ、スケーリングを簡素化します。送信トラフィックの制御が限定的で、全てのトラフィックを許可する設定が困難です。
Cloud Functions：Google CloudのFaaS（Function as a Service）で、イベント駆動のワークロードを運用します。全ての送信トラフィックの許可は難しく、主にステートレスな関数の実行に使用されます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。全ての送信トラフィックを許可することは基本的に不可能で、データを保存、取得するためのサービスです。
正解についての説明：
（選択肢）
・Compute Engine
・Google Kubernetes Engine
この選択肢が正解の理由は以下の通りです。
まず、Compute EngineはGoogle CloudのIaaSサービスで、ユーザーは自分で許可されたトラフィックをコントロールすることが可能です。
したがって、Compute EngineはPCI DSS要件を満たすためのセキュリティ制御を提供します。
また、Google Kubernetes Engine（GKE）はコンテナ化されたアプリケーションを管理するためのプラットフォームであり、ネットワークポリシーを設定することで送信トラフィックの制御が可能です。これにより、PCI DSSの要件を満たすことができます。両サービスともに、セキュリティの管理とコントロールが高度にカスタマイズ可能であり、すべての送信トラフィックが許可されていることを確認する要件を満たすことが可能です。
不正解についての説明：
選択肢：App Engine
この選択肢が正しくない理由は以下の通りです。
App EngineはフルマネージドなPaaSであり、基礎的なネットワーク設定は完全にGoogleによりコントロールされています。
したがって、ユーザーは送信トラフィックを直接管理または監視することができません。
一方、Compute EngineやGoogle Kubernetes EngineはIaaS、CaaSオファリングであり、送信トラフィックの管理が可能です。
選択肢：Cloud Functions
この選択肢が正しくない理由は以下の通りです。
Cloud FunctionsはFaaS、つまりFunction as a Serviceであり、ユーザはサーバ管理やトラフィック管理について制御することができません。これは、PCI DSS準拠のために送信トラフィックを管理する必要がある企業にとっては適切ではありません。
これに対し、Compute EngineやGoogle Kubernetes Engineでは、送信トラフィックを管理することができます。
選択肢：Cloud Storage
この選択肢が正しくない理由は以下の通りです。
Cloud Storageはデータを保存するためのサービスであり、送信トラフィックの制御はその主要な機能ではありません。
一方、Compute EngineやGoogle Kubernetes Engineはネットワーク設定が可能で、送信トラフィックを許可する設定を行うことができます。
参考リンク：
https://cloud.google.com/compute/docs/vpc
https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview
https://www.pcisecuritystandards.org/documents/PCI_DSS_v3-2-1.pdf
</div></details>

### Q.  問題7: 未回答
会社で承認されたコンピュートイメージを、イメージリポジトリとして使用されている1つのGoogle Cloudプロジェクトに保存しています。このプロジェクトはVPC Service Controlsで保護され、組織内の他のプロジェクトとともに境界内に存在します。これにより、他のプロジェクトはイメージリポジトリプロジェクトからイメージをデプロイできます。あるチームが、外部のGoogle Cloudの組織に保存されているサードパーティのディスクイメージをデプロイすることが必要になりました。ディスクイメージを境界にデプロイできるように、ディスクイメージへの読み取りアクセスを許可する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudのVPC Service Controlsを使用して、一つの境界に囲まれたプロジェクトから別のGoogle Cloudの組織に保管されたディスクイメージへの読み取りアクセスを許可する方法を問われています。そのためには、VPC Service Controlsにおけるエグレス（出口）ルールに関する知識が必要です。また、囲いの更新（境界の更新）を行う場合、設定すべきフィールドやパラメーターについて理解していなければなりません。
基本的な概念や原則：
VPC Service Controls：Google Cloudのサービスとデータへのアクセスを制限してデータ漏洩やデータ移動を防ぐためのサービスです。
境界：VPC Service Controlsで設定するもので、特定のGoogle Cloudリソースへのアクセスを規制する範囲を定義します。
egressToフィールド：境界の設定に使用され、境界の外側への出力トラフィック（egress）を指定します。
egressFromフィールド：境界の設定に使用され、境界の内側からの出力トラフィック（egress）を指定します。
compute.googleapis.com：Compute Engine APIのサービス名であり、このAPIを通じてCompute Engineのリソースを操作することができます。
正解についての説明：
（選択肢）
・1. 境界を更新します
2. 外部Google Cloudプロジェクト番号を許可されたリソースとして含めるようにegressToフィールドを構成し、serviceNameをcompute.googleapis.comに設定します
3. egressFromフィールドを構成して、identityTypeをANY_IDENTITYに設定します
この選択肢が正解の理由は以下の通りです。
まず、VPC Service Controlsは、もしディスクイメージが境界（perimeter）の外にあるGoogle Cloudのプロジェクトにある場合、そのリソースにアクセスできないうように制限しています。そのため、特定の外部リソースへのアクセスを許可するためには、そのリソースを持つプロジェクトのプロジェクト番号を境界のegressToフィールドに追加する必要があります。serviceNameをcompute.googleapis.comに設定するのは、Disk ImagesはCompute Engineの一部であるためです。
次に、egressFromフィールドを構成してANY_IDENTITYを指定することで、境界内の任意のIDエンティティ（例えばユーザーやサービスアカウントなど）がegressToで指定したリソースにアクセスできるようになります。これにより、他のプロジェクトがイメージリポジトリプロジェクトからイメージをデプロイできるようになります。
したがって、境界を更新し、適切にegressToとegressFromを設定することで、サードパーティのディスクイメージへの読み取りアクセスを許可し、ディスクイメージを境界内にデプロイできるようにすることができます。
不正解についての説明：
選択肢：組織ポリシーconstraints/compute.trustedImageProjectsを使用して、外部プロジェクトを許可します
この選択肢が正しくない理由は以下の通りです。
compute.trustedImageProjectsポリシーは主に自分の組織のプロジェクトで使用されるイメージのソースを制御するためのもので、他の組織とのディスクイメージのアクセスには適用できません。そのため、VPC Service Controls境界のegressToとegressFromフィールドを更新して外部プロジェクトへのアクセスを許可するのが適切です。
選択肢：1. 境界を更新します
2. ingressFromフィールドを構成して、identityTypeをANY_IDENTITYに設定します
3. 外部Google Cloudプロジェクト番号を許可されたリソースとして含めるようにingressToフィールドを構成し、serviceNameをcompute.googleapis.comに設定します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsでデータを境界外に送信するためには、egressToとegressFromフィールドを設定します。そのため、ingressFromとingressToフィールドを設定することにより、境界外からの接続の許可が行われますが、この場合は境界外にデータを送信することが目的です。この選択肢はブロックしたい逆の方向についての設定になってしまいます。
選択肢：1. 境界を更新します
2. egressToフィールドを構成して、identityTypeをANY_IDENTITYに設定します
3. 外部Google Cloudプロジェクト番号を許可されたリソースとして含めるようにegressFromフィールドを構成し、serviceNameをcompute.googleapis.comに設定します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsの設定において、egressToフィールドは出力トラフィックの宛先を指定しますが、egressFromフィールドは出力トラフィックの源を指定します。
したがって、外部のGoogle Cloudプロジェクト番号を許可されたリソースとして含めることは、egressToフィールドで設定するべきです。不正解の選択肢は、これらのフィールドの使い方を誤解しています。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs
https://cloud.google.com/vpc-service-controls/docs/perimeter-configuration
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
</div></details>

### Q.  問題8: 未回答
あなたの会社は臨床試験を実施しており、BigQueryに保存されている最近の試験結果を分析する必要があります。薬を服用した間隔には、開始日と中止日が含まれています。間隔データは分析にとって重要ですが、特定の日付は特定のバッチを特定し、バイアスを引き起こす可能性があります。各行の開始日と終了日を難読化し、間隔データを保持する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、プライバシー保護とデータ分析の両方のニーズを満たす必要があります。特に、日付情報を難読化することでプライバシーを保護する一方で、間隔データを保持することで分析可能性を維持しなければなりません。提示された選択肢を見る際には、これらの要件を全て満たす解決策を選択する必要があります。具体的には、日付を難読化する手法として適切なものは何か、そしてその手法が間隔データを保持することが可能なのか、という2つの観点を考慮して見るべきです。
基本的な概念や原則：
日付シフト：個人情報を保護するために日付値をランダムにシフトする技術です。開始日と終了日間の間隔は保持しながら、個々の日付の特定性を難読化します。使用する際は、被験者の固有IDをコンテキストとして設定する必要があります。
固有ID：データセットの各エントリーを一意に識別するための識別子です。このIDを利用して、データの一貫性を確保しつつも、特定の個人を特定できないようにすることができます。
TimePartConfig：日付データから特定の部分（年、月、日など）を抽出するために使用される設定です。これを使用して日付データを操作することは可能ですが、クリニカルデータに対するシフトの要件を満たすためには不適切です。
ビケット：データを管理するための論理的なユニットです。ビケットへの値のシフトは、データの一貫性を維持しながら値を難読化するための方法です。ただし、クリニカルデータのように日付間の間隔を保持する必要がある場合には不適切です。
フォーマット保持暗号化（FPE）：データの形式を保持しながらデータを暗号化する技術です。FFX（Feistel Finite Set Encryption）はその一つです。これはデータの保護に役立ちますが、日付データの間隔を保持しながら特定性を難読化するためには不適切です。
正解についての説明：
（選択肢）
・被験者の固有IDをコンテキストに設定し、日付シフトを使用します
この選択肢が正解の理由は以下の通りです。
本問の要件は、個々の患者の薬物服用期間（開始日と終了日）を維持しつつ、特定の日付を匿名化（難読化）することです。Google Cloudで提供する日付シフトは、それぞれの被験者に対して一定のシフトを提供し、特定の日付を匿名化しつつ同一患者内での日付間隔を保持する機能です。
被験者の固有IDをコンテキストとして設定することにより、同一被験者に対する日付シフトは一貫したものとなります。つまり、特定の被験者の薬物服用期間は原実データと同じ間隔を保ちながら、特定の日付が匿名化されるため、要件を満たすことができます。
この機能は、治験データのプライバシーを守りつつ、重要な分析（薬物服用期間など）を妨げないという研究者にとって重要な課題を解決します。以上の理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：各日付フィールドからTimePartConfigを使用して日付を抽出し、ランダムな月と年を追加します
この選択肢が正しくない理由は以下の通りです。
各日付フィールドからTimePartConfigを使用して日付を抽出し、ランダムな月と年を追加します、という方法では日付間隔が保持されません。
一方、被験者の固有IDをコンテキストに設定し、日付シフトを使用すると、日付間隔は保持されつつ、特定の日付は難読化されるため要件に適合します。
選択肢：バケットを使用して、初期値に基づいて所定の日付に値をシフトします
この選択肢が正しくない理由は以下の通りです。
バケットを使用して初期値に基づいて日付をシフトすると、開始日と終了日の関係性や間隔が保持されない可能性があります。正解の日付シフトは個々の被験者の固有IDをコンテキストに設定し、開始日と終了日の間隔を保持しつつも難読化を可能にします。
選択肢：フォーマット保持暗号化（FPE）のFFXモードを使用し、データの一貫性を維持します
この選択肢が正しくない理由は以下の通りです。
フォーマット保持暗号化（FPE）のFFXモードは、データの元の形式を保持しつつ暗号化を行いますが、日付の間隔情報を保持できません。
それに対して、日付シフトは特定の日付を難読化しつつ、日付間隔の情報を保持することが可能であり、この問題の要件を正確に満たします。
参考リンク：
https://cloud.google.com/bigquery/docs/tokenizing-data
https://cloud.google.com/bigquery/docs/reference/standard-sql/date_functions
https://cloud.google.com/blog/products/data-analytics/tips-for-using-the-bigquery-data-transfer-service
</div></details>

### Q.  問題9: 未回答
あなたの組織はActive Directoryを使用しており、SAML（Security Assertion Markup Language）を構成したいと考えています。すべてのユーザーにシングルサインオン（SSO）を設定し、実施する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Active Directoryを利用した状況でのSAMLを用いたシングルサインオン（SSO）の実装方法について問われています。重要なのは、正しいSAMLの構成方法と特性を理解し、それを用いてSSOの設定を行うことが求められています。その一方で、OpenID Connectに関する選択肢や、適切とは言えないSAML構成やプロファイル管理について述べられている選択肢等は注意が必要です。問題文の条件に対して最も適合する方法を選ぶ際に、SAMLとActive Directory、そしてSSOの概念とそれぞれの特性を念頭に置いて解答を行います。
基本的な概念や原則：
Active Directory：マイクロソフトが提供するディレクトリサービスで、ユーザーアカウントやコンピュータなどのリソースを一元的に管理します。
SAML（Security Assertion Markup Language）：セキュリティ情報を表現するためのXMLベースの標準で、認証、認可、アサーションを提供します。
シングルサインオン（SSO）：一度のログインで複数の異なるシステムやサービスにアクセスできる認証方法です。
SAMLプロファイル：SAMLを用いた認証やアサーションの適用ルールを定義したものです。
X.509証明書：公開鍵暗号方式におけるデジタル署名や暗号化を行うためのソフトウェア証明書です。
IdP（Identity Provider）：ユーザーのIDやパスワードなど、個々のユーザーの識別情報を管理する仕組みやその提供者のことです。
エンティティIDとACS URL：SAML認証において、サービスを一意に識別するエンティティIDと認証応答を受け取るサービスのURL（ACS URL）の設定が必要です。
正解についての説明：
（選択肢）
・1. 新しいSAMLプロファイルを作成します
2. サインインページとサインアウトページのURLを入力します
3. X.509証明書をアップロードします
4. IdPでエンティティIDとACS URLを構成します
この選択肢が正解の理由は以下の通りです。
まず、SAMLの設定は複数の手続きに分かれますが、この選択肢はその手続きを総合的にカバーしています。新しいSAMLプロファイルを作成することは、シングルサインオン環境を構築する最初のステップです。
次に、サインインページとサインアウトページのURLを入力することで、ユーザーが可視化するログインとログアウトのロールを果たすページを設定します。
そして、X.509証明書をアップロードすることによって、認証のためのキーペアを提供します。これは、システムが相互認証を確立し、安全な通信を確保するため必要ます。
最後に、IdP（Identity Provider）でエンティティIDとACS（Assertion Consumer Service）URLを構成する事で、SAMLプロファイルのアイデンティティプロバイダとしてActive Directoryの資格情報を使用する設定が完了します。これにより、ユーザーはActive Directoryの資格情報を使用してシングルサインオンが可能となります。
不正解についての説明：
選択肢：1. Active Directory（AD）テナントでOpenID Connect（OIDC）の前提条件を構成します
2. ADドメインを確認します
3. どのユーザーがSAMLを使用するかを決定します
4. 事前構成されたプロファイルを、選択した組織単位（OU）およびグループに割り当てます
この選択肢が正しくない理由は以下の通りです。
OpenID Connect（OIDC）は主に認証を提供し、SAMLは認証だけでなく認可も行うため、問題で要求されているSSOを実施するにはSAMLの設定が必要です。
したがって、OIDCの前提条件を構成するという選択肢はこの問題の解決策としては不適切です。
選択肢：1. 新しいSAMLプロファイルを作成します
2. X.509証明書をアップロードします
3. パスワード変更URLを有効にします
4. IdPでエンティティIDとACS URLを構成します
この選択肢が正しくない理由は以下の通りです。
不正解の選択肢は、サインインページとサインアウトページのURLを入力するステップを含めていません。これはSAML SSOの設定において重要なステップであり、ユーザーが該当URLで認証を受けられるようにする必要があります。
また、パスワード変更URLを有効にするステップはSAML SSOの設定とは関連がありません。このためこの選択肢は不適切です。
選択肢：1. SAMLプロファイルの割り当てを管理します
2. Active Directory（AD）テナントでOpenID Connect（OIDC）を有効にします
3. ドメインを確認します
この選択肢が正しくない理由は以下の通りです。
特に、Active DirectoryのテナントでOpenID Connectを有効にする設定は不適切で、SAMLとOpenID Connectは異なる認証フレームワークであり交換可能ではありません。要件がSAMLの設定を求めているため、この選択肢に含まれるOpenID Connectの設定は必要ありません。
参考リンク：
https://cloud.google.com/identity/saml
https://cloud.google.com/identity/docs/how-to/setup-sso
https://support.google.com/a/answer/60224?hl=en
</div></details>

### Q.  問題10: 未回答
あなたの会社では、従業員が個人所有のコンピュータを使ってGoogle Cloudコンソールにアクセスしています。Google Cloudコンソールにアクセスできるのは、ユーザーが会社から発行されたデバイスのみであることを確認し、有効な企業証明書を持っていることを確認する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、企業のデバイスと証明書を用いたアクセス制限がテーマとなります。従業員が個人所有のコンピュータからGoogle Cloudコンソールにアクセスすることが前提となっていますが、アクセス可能なのは企業から発行のデバイスと特定の証明書を持つ人物のみとなるべきです。このような要件を満たすことが目標となるため、選択肢を判断する際には、これらの制限を実現するための適切なGoogle Cloudの機能を選択する必要があります。
基本的な概念や原則：
BeyondCorp Enterprise：Google Cloudのゼロトラストアクセスソリューションです。ユーザー、デバイス、アプリケーションのコンテキストに基づくセキュリティー決定を可能にします。
アクセスポリシー：特定のリソースへのアクセスを制御するためのルールの集合です。BeyondCorp Enterpriseでは、企業証明書などのデバイス情報を元にしたアクセスポリシーを作成することができます。
アクセスバインディング：アクセスポリシーを特定のリソースに対して適用するための設定です。BeyondCorp Enterpriseでは、作成したアクセスポリシーを利用してアクセスバインディングを作成します。
ゼロトラストアクセス：すべてのアクセスを信頼しないというセキュリティーモデルです。アクセスするたびに認証と認可を強制します。
VPCファイアウォール：仮想プライベートクラウド（VPC）のネットワークトラフィックを制御する機能です。ただし、デバイス証明書の検証には使用できません。
IAM（Identity and Access Management）条件付きポリシー：特定の条件を満たす場合にのみアクセス許可を付与するためのポリシーです。しかし、デバイス証明書の検証には、直接使用することはできません。
正解についての説明：
（選択肢）
・BeyondCorp Enterpriseにアクセスポリシーを実装し、デバイス証明書を検証します。作成したアクセスポリシーでアクセスバインディングを作成します
この選択肢が正解の理由は以下の通りです。
まず、BeyondCorp EnterpriseはGoogle Cloudのゼロトラストアクセス管理ソリューションであり、特定のユーザーが特定のデバイスから特定のアプリケーションにアクセスできるようにするためのアクセスポリシーを設定することが可能です。このアクセスポリシーではデバイス証明書の検証も可能で、従業員が会社から発行されたデバイスかどうか、さらにそのデバイスが有効な証明書を保持しているかどうかをチェックします。
次に、BeyondCorp Enterpriseを使って作成したアクセスポリシーを用いてアクセスバインディングを作成することで、特定のユーザーまたはユーザーグループが指定されたリソースに対するアクセスを制御します。これにより、個人所有のコンピュータからの不適切なGoogle Cloudコンソールへのアクセスを防ぐことができます。
以上の理由から、BeyondCorp Enterpriseにアクセスポリシーを実装し、デバイス証明書を検証してアクセスバインディングを作成することが適切です。
不正解についての説明：
選択肢：VPCファイアウォールポリシーを実装します。パケット検査を有効にし、デバイス証明書を検証して確認するための許可ルールを作成します
この選択肢が正しくない理由は以下の通りです。
VPCファイアウォールポリシーがデバイス証明書の検証を行う機能はありません。
また、パケット検査を用いても、ユーザーデバイスの検証といった目的を達成することは出来ません。
一方、BeyondCorp Enterpriseはユーザーやデバイスに対するセキュリティポリシーを柔軟に適用できるため、この要件を達成するには適しています。
選択肢：アクセスコンテキストから証明書を検証する組織ポリシーを導入します
この選択肢が正しくない理由は以下の通りです。
組織ポリシーはリソースの使用を規制しますが、特定のデバイスからのアクセス制限や証明書の検証等、ユーザーやデバイスの認証・認可を行う機能はありません。
それに対して、BeyondCorp Enterpriseはアクセスコンテキストに基づいてポリシーを適用し、企業証明書の検証を通してアクセス制御が可能です。
選択肢：デバイス証明書を検証するために、IAM（Identity and Access Management）条件付きポリシーを実装します
この選択肢が正しくない理由は以下の通りです。
IAMの条件付きポリシーでは、ユーザーやサービスアカウントに角度からアクセス制御を行うためのルールを作成しますが、デバイス証明書の検証はサポートしていません。
これに対して、BeyondCorp Enterpriseはユーザーだけでなくデバイスに基づくアクセス制御を行う機能を提供しています。
参考リンク：
https://cloud.google.com/beyondcorp-enterprise/docs/access-policies-introduction
https://cloud.google.com/identity-aware-proxy/docs/device-policy
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations
</div></details>

### Q.  問題11: 未回答
サードパーティのIDプロバイダ（IdP）からCloud IdentityにIDを同期する予定です。一部の従業員が会社のメールアドレスを使用して、Googleサービスにアクセスするためのコンシューマアカウントを設定していることがわかりました。これらのコンシューマアカウントの構成、セキュリティ、およびライフサイクルを組織が確実に管理できるようにする必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、サードパーティのIDプロバイダからCloud IdentityにIDを同期する際に、どのようにコンシューマアカウントを管理すべきかを問いています。この問題に対しては、既存のコンシューマアカウントの管理方法と、それを組織の管理下に置く方法について理解する必要があります。キーポイントは、従業員が会社のメールアドレスを使用してGoogleサービスにアクセスするコンシューマアカウントの管理です。そのため、答えはそれらのアカウントを組織が確実に管理するための最も効果的な方法に導かれます。
基本的な概念や原則：
Cloud Identity：Google CloudのID管理システムです。ユーザー、グループ、アプリケーションの認証、承認、管理が可能です。
IDプロバイダ（IdP）：ユーザーの認証情報を管理するサービスです。SAMLやOpenID Connectといった認証プロトコルを使用して、ユーザーのIDを検証します。
コンシューマアカウント：個々のユーザーが個人用途で作成するGoogleアカウントです。これに対して、組織がユーザー用に作成するアカウントをエンタープライズアカウントと呼びます。
移管ツール：Google Workspaceの管理者が未管理のGoogleアカウントを該当する組織に移管するためのツールです。
Google Cloud Directory Sync（GCDS）：Google Workspaceと既存のLDAPディレクトリの間でユーザー、グループ、組織単位を同期するツールです。ただし管理されていない消費者アカウントの移行には適していません。
アカウントの照合：Cloud IdentityとIdP間でアカウントの存在を比較し、不一致を調整する行為です。存在するアカウントの一致を確認し、必要に応じてアカウントを移管または削除します。
正解についての説明：
（選択肢）
・Cloud Identityには存在するがサードパーティのIdPには存在しないアカウントを照合します
・移管ツールを使用して、企業の従業員を招待し、管理されていないコンシューマーアカウントを企業ドメインに移管します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Identityは、企業がユーザーの認証とアクセス管理を行うためのサービスです。サードパーティのIdPからCloud IdentityへのID同期を行うことで、企業はIDを一元管理できるようになります。一部の従業員が自身の企業のメールアドレスでGoogleサービスにアクセスするための個人アカウントを設定している場合、それらのアカウントは企業の管理下にないため、それらのアカウントのセキュリティとライフサイクルを管理できません。そこで、Cloud Identityには存在するがサードパーティのIdPには存在しないアカウントを照合することが求められます。これにより、そのような個人アカウントを特定できます。
次に、それらの個人アカウントを企業の管理下に置くためには移管が必要です。Googleは"移管ツール"を提供しており、これを使用して管理されていないコンシューマアカウントを企業ドメインに移管します。このツールを使用することで、管理されていないコンシューマアカウントの所有者である従業員に移管を求める招待が送られ、その結果これらのアカウントを企業が管理することが可能となります。これにより、従業員が企業ドメインでGoogleのサービスに利用しているアカウントの持つ構成、セキュリティ、とライフサイクルを確実に管理することができます。
不正解についての説明：
選択肢：企業の従業員に、管理されていない消費者アカウントの削除を義務付けます
この選択肢が正しくない理由は以下の通りです。
単に従業員に消費者アカウントの削除を義務付けることでは、アカウントの構成、セキュリティ、ライフサイクルを企業が確実に管理するという要件は満たされません。
また、それは利便性や生産性の低下を引き起こす可能性があるため、企業の利益には繋がりません。
選択肢：IDを同期する前に、サードパーティIdPで管理されていないコンシューマアカウントを削除します
この選択肢が正しくない理由は以下の通りです。
コンシューマアカウントを削除すると、そのアカウントに関連付けられた全てのデータとサービスも削除されてしまうため、その後の管理が不可能となるからです。正解選択肢のように移管ツールを使ってアカウントを移管すれば、アカウントとそれに関連するデータを維持したままで組織の管理下に置くことが可能です。
選択肢：Google Cloud Directory Sync（GCDS）を使用して、管理されていない消費者アカウントの電子メールをユーザーエイリアスとして移行します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Directory Sync（GCDS）は基本的にIDの同期のみを行うツールであり、コンシューマアカウントの管理やセキュリティ、ライフサイクルを制御することはできません。そのため、GCDSを用いた方法では要件を満たすことはできません。
参考リンク：
https://cloud.google.com/identity/docs/account-transfer/intro
https://cloud.google.com/identity/docs/how-to/manage-users
https://support.google.com/a/answer/6335621
</div></details>

### Q.  問題12: 未回答
アプリケーションログを、管理者とアナリストの両方がアクセス可能な共有Cloud Storageバケットにバックアップしています。アナリストは、個人を特定できる情報（PII）を含むログにアクセスできません。PIIを含むログファイルは、管理者のみがアクセスできる別のバケットに保存する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、アプリケーションログを安全に管理し、個人を特定できる情報（PII）のアクセス権を制限する方法を問われています。重要なポイントは、管理者とアナリストの両方がアクセス可能な共有バケットと、管理者のみがアクセス可能な別のバケットの二つを適切に利用することです。また、PIIが含まれているかどうかを判定するためのロジックが必要です。これらの要素を踏まえて、適切なGoogle Cloudのサービスを選択し、その設定や動作を理解する必要があります。
基本的な概念や原則：
Cloud Storageバケット：Google Cloudのオブジェクトストレージサービスで、大量の非構造化データを保存し、取り出すことができます。安全性とスケーラビリティを備えています。
Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。フルマネージドのサービスで、メッセージのパブリッシュとサブスクライブを行うことができます。
Cloud Functions：Google Cloudのサーバーレス実行環境です。特定のイベントに応じて短期間のコードスニペットを実行します。
Cloud Data Loss Prevention（DLP）：Google Cloudのデータ保護サービスです。機密データや個人を特定可能な情報（PII）を自動的に検出、分類、非表示化します。
個人を特定可能な情報（PII）：個々の人を直接または間接に特定可能な情報のことです。適切な取り扱いと保護が法律で求められています。
アクセス管理：特定のユーザーやグループがリソースに対して持つパーミッションを制御することです。Google CloudではIAMによる細かなアクセス制御が可能です。
オブジェクトライフサイクル管理：Cloud Storageでデータの保存期間や状態を自動管理する設定のことです。特定の条件に合致したオブジェクトを自動的に削除するなど、コストとデータ管理を最適化します。
正解についての説明：
（選択肢）
・Pub/SubとCloud Functionsを使って、ファイルが管理者のバケットにアップロードされるたびにCloud Data Loss Preventionスキャンをトリガします。スキャンでPIIが検出されなかった場合は、共有Cloud Storageバケットにオブジェクトを移動させます
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Pub/Subは、アプリケーション間でメッセージの送受信を行うことができます。クラウドバケットで新たなログファイルがアップロードされると、そのイベントをトリガーにPub/Subがメッセージを生成します。このメッセージはCloud Functionsを起動します。Cloud Functionsは、Cloud Data Loss Prevention APIと連携し、PIIを含む可能性のある新規ログファイルをスキャンします。
Cloud Data Loss Prevention APIは、PIIを検出する機能を提供します。スキャンが完了し、PIIが検出されなかった場合、ファイルは共有バケットに移動されます。これにより、管理者とアナリストの両方が安全にアクセスできるようになります。
一方で、PIIが検出された場合、ファイルは元の管理者のバケットに残し、安全性を確保します。
したがって、Pub/Sub、Cloud Functions、Data Loss Prevention APIを使用することで、セキュリティを保ちながらも特定の情報に基づいてデータを適切な場所にルーティングする要件を満たすことが可能となります。
不正解についての説明：
選択肢：ログを共有バケットと管理者のみがアクセス可能なPIIを含むバケットの両方にアップロードします。Cloud Data Loss Prevention APIを使用して、ジョブのトリガーを作成します。共有バケットからPIIを含むファイルを削除するようにトリガーを設定します
この選択肢が正しくない理由は以下の通りです。
ログを最初に両方のバケットにアップロードすると、アナリストがPIIを含むログに一時的にでもアクセスできる可能性があります。これは要件に違反します。既存のファイルをスキャンして削除するよりも、PIIを含む可能性のあるファイルをまず別のバケットにアップロードし、その後でPIIが含まれていないと確認した上で共有バケットに移動するのが適切です。
選択肢：共有バケット上で、PIIを含むオブジェクトを削除するようにオブジェクトライフサイクル管理を設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Storageのオブジェクトライフサイクル管理は、オブジェクトのバージョン管理やストレージクラスの変更など、特定の条件に基づいて行われます。しかし、特定の情報（この場合はPII）を含むファイルを自動的に識別し、削除する機能は提供していません。近年の正解と比較すると、PIIを正確に検出して適切に分類する能力に欠けています。
選択肢：共有バケット上で、PIIがアップロードされたときのみトリガーされるCloud Storageトリガーを設定します。Cloud Functionsを使ってトリガーを捕捉し、PIIを含むファイルを削除します
この選択肢が正しくない理由は以下の通りです。
この選択肢ではPIIを含むファイルが単に削除されますが、実際にはそのファイルは管理者のみがアクセス可能なバケットに保存される必要があります。
また、Cloud StorageトリガーがPIIを直接検出する機能はないため、PIIの検出はCloud Functionsだけに頼ることができません。
参考リンク：
https://cloud.google.com/storage/docs/using-pubsub-notification
https://cloud.google.com/dlp/docs/quickstart-client-libraries
https://cloud.google.com/functions/docs/calling/pubsub
</div></details>

### Q.  問題13: 未回答
あなたの会社の最高情報セキュリティ責任者（CISO）は、会社のグローバル展開計画に影響する規制要件のため、ビジネスデータを特定の場所に保存しなければならないという要件を作成しました。この要件を実施するための詳細を検討した結果、以下のことが判明しました：
- 対象サービスはGoogle Cloud Data Residency Termsに含まれています。
- ビジネスデータは、同じ組織内の特定の場所に保存され続けます。
- フォルダ構造には、複数のデータ保存場所が含まれる可能性があります。
あなたはリソースロケーションの制限組織ポリシー制約を使用する予定です。
リソース階層のどのレベルで制約を設定する必要がありますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのデータ保管に関する規制要件が提示され、その対応策としてリソースの位置を制約する必要がある状況を想定しています。求められているのは、リソースロケーションの制約をどの階層レベルで設定すべきかということです。問題文で提供される情報の中には、データ保管の場所が特定の場所に限定され、その要件がGoogle Cloud Data Residency Termsにかかるサービスに影響を与え、また、同一組織の内部でのデータ移動も規制されるという事項が含まれています。これらの情報を基に適切な制約の設定レベルを選択することが求められています。
基本的な概念や原則：
リソースロケーションの制限組織ポリシー制約：Google Cloudリソースが特定の地理的ロケーションに存在することを保証するための制約です。これを使用すると、特定のリージョンまたはゾーンにリソースの作成を制限することができます。
プロジェクト：Google Cloudリソースを整理し、アクセスを制御するための単位です。特定の場所に関連するリソースは同じプロジェクト内に存在すべきです。
フォルダ：Google Cloudのリソース階層における組織単位の一部です。フォルダには複数のプロジェクトを含めることが可能で、階層化のために使用されます。
リソース：Google Cloudの各サービスや機能として存在するエンティティです。インスタンス、データベース、ストレージバケットなどが該当します。
組織：Google Cloudのリソースを管理するための最上位の単位です。組織全体でポリシーを適用したり、アクセスを制御したりするために使用されます。
正解についての説明：
（選択肢）
・プロジェクト
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの組織ポリシーサービスを利用すると、組織の要件に従ってリソースの設置場所を制限することが可能になります。組織ポリシーの制約は、組織、フォルダ、プロジェクトのいずれのレベルでも設定できます。しかし、問題の状況では、同じ組織内でビジネスデータの保存場所が異なる可能性があり、フォルダ内には複数のデータ保存場所が含まれる可能性が示されています。これにより、組織レベルまたはフォルダレベルで制約を設定すると、すべてのプロジェクトが同じ制約を受け、必要な柔軟性が失われる可能性があります。そのため、プロジェクトレベルで制約を設定することが最善の解答となります。それぞれのプロジェクトで異なる保存場所を持つことが可能になり、規制要件に準拠しつつ、適切な場所にデータを保存するための柔軟性を確保できます。
不正解についての説明：
選択肢：フォルダ
この選択肢が正しくない理由は以下の通りです。
フォルダレベルでの制約設定は可能ですが、ビジネスデータが同じ組織内の特定の場所に保存され続けるという要件を満たさない可能性があります。フォルダ内には複数のプロジェクトや別のフォルダが含まれる可能性があり、その中に異なるデータ保存場所が含まれている場合もあります。そのため、より細かい制御を可能にするプロジェクトレベルでの制約設定が適切です。
選択肢：リソース
この選択肢が正しくない理由は以下の通りです。
リソース階層では、リソースロケーションの制限組織ポリシー制約を設定することはできません。プロジェクトレベルで制約を設定することが求められており、これにより取り扱いデータの地理的な保存場所を制御することが可能となります。
選択肢：組織
この選択肢が正しくない理由は以下の通りです。
制約を組織レベルで設定すると、全てのプロジェクトとフォルダに制約が適用されます。しかし問題文には、特定の場所にデータを保存し続ける必要があるとあり、フォルダ内には複数のデータ保存場所が含まれる可能性があるため、組織レベルで設定すると、必要な柔軟性を失ってデータの保存場所を細かく制御することができません。よって、制約はプロジェクトレベルで設定するのが適切です。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/resource-manager/docs/creating-managing-policy
https://cloud.google.com/resource-manager/docs/creating-managing-organization
</div></details>

### Q.  問題14: 未回答
ある顧客のデータサイエンスグループは、アナリティクスのワークロードにGoogle Cloudを使用したいと考えています。会社のポリシーでは、すべてのデータは会社が所有し、すべてのユーザー認証は独自のSAML（Security Assertion Markup Language）2.0アイデンティティプロバイダ（IdP）を経由する必要があります。インフラストラクチャオペレーション担当のシステムエンジニアが、顧客のクラウドIDをセットアップしようとして、顧客のドメインがすでにG Suiteで使用されていることに気づきました。
混乱を最小限に抑えるために正しい方法はどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、クラウドIDのセットアップを行いたい顧客の既存のドメインがG Suiteで既に使用されているという状況に対処する最適な手段を問われています。認証については、すべてのユーザー認証が独自のSAML 2.0アイデンティティプロバイダを経由すること、また、データの所有権も会社にあるという要件があります。そのため、既存のシステムとの統合や既存環境の利用可能性、およびデータとユーザー認証のリスクを適切に管理することが重要です。選択肢の評価に際しては、この状況における混乱の最小化、しっかりとした認証およびデータ所有の確保が重視されます。
基本的な概念や原則：
Google Cloud：Googleが提供するクラウドサービスの総称で、アワードウィニングなサービスとインフラストラクチャを用いて仮想マシン、データベース、ストレージ、ネットワーキングなどを提供します。
SAML 2.0：セキュリティ認証に関するオープンスタンダードの一つです。SAML 2.0では一度認証されたユーザーについて、その認証情報を異なるサービス間で共有することができます。これにより単一サインオン（SSO）の実現が可能となります。
アイデンティティプロバイダ（IdP）：ユーザーの認証情報及び属性の提供者のことです。IdPは認証と認可のパラメータをコントロールするためのインフラストラクチャを提供します。
Googleマネージドサービス：Googleが提供するサービスの中で、利用者が基本的な設定などをし、後はGoogleが管理・運用を行ってくれるサービスのことです。
ドメイン名：インターネット上で利用されるコンピューターやネットワークを識別するための名前です。これにより、ユーザーはIPアドレスを直接覚える必要がなく、ドメイン名を利用して目的のネットワークにアクセスできます。
G Suite：Googleが企業向けに提供しているクラウド型オフィス環境のことで、現在はGoogle Workspaceという名称です。メール、カレンダー、文書作成・編集、オンラインストレージなど、業務で必要とされる機能を一通り提供しています。
Cloud Identity：Google CloudのIdentity and Access Management（IAM）プラットフォームです。ユーザー、アプリケーション、サービスがGoogle Cloudのリソースに安全にアクセスするための方法を提供します。
正解についての説明：
（選択肢）
・顧客の管理者にGoogleマネージドサービスの他の利用方法を確認し、既存の特権管理者と連携します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudを使用する前提として、既存のドメインがG Suiteで使用されている場合は、そのドメインの管理者と連携して進めていくことが一般的です。これは、Google Cloud上の各種リソースにアクセスする際にG Suiteのアカウントが使用されるため、既存のアカウント管理体制に影響を与えないようにするためです。
したがって、まず顧客の管理者と連携し、Googleマネージドサービス（GMS）の他の利用法を確認することが重要です。
また、アイデンティティプロバイダ（IdP）を持つ顧客の認証要件も満たすために、G SuiteとSAML 2.0 IdPの連携についても考慮が必要です。これらの連携を適切に行うことで、既存の認証体制を崩すことなくGoogle Cloudの導入と利用が可能となります。
不正解についての説明：
選択肢：Googleサポートに連絡し、新しいCloud Identityドメインでドメイン名を使用するためのドメイン争奪プロセスを開始します
この選択肢が正しくない理由は以下の通りです。
Google Cloudでは、ドメイン争奪プロセスというものは存在せず、既にG Suiteで使用されているドメインを新しいCloud Identityドメインで使用することは不可能です。理想的な解決策は既存のG Suite管理者と連携し、既存のドメインを効果的に管理することです。
選択肢：新しいドメイン名を登録し、新しいCloud Identityドメインに使用します
この選択肢が正しくない理由は以下の通りです。
新しいドメイン名を登録し、新しいCloud Identityドメインに使用すると、独自のIdPを通じたユーザー認証の会社方針に反する可能性があります。
また、このアプローチは既存のG Suite使用状況や管理者と同期していないため、混乱を増幅する可能性があります。正解の選択肢では、既存の特権管理者と協力して情報共有を行い、混乱を最小限に抑えます。
選択肢：データサイエンスマネージャーのアカウントを既存のドメインの特権管理者としてプロビジョニングするようGoogleに依頼します
この選択肢が正しくない理由は以下の通りです。
Googleはユーザーアカウントのプロビジョニングを手動で行うサービスを提供していません。既存の特権管理者との連携を通じて内部的な管理変更が必要です。既存の管理者の承認なしにロールの変更を求めるのは不適切です。
参考リンク：
https://cloud.google.com/iam/docs/using-saml-to-enable-federated-sso
https://cloud.google.com/identity/docs/how-to/setup#authenticating_users_with_federated_sso
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#identity
</div></details>

### Q.  問題15: 未回答
あなたの会社はSparkとHadoopのジョブにCloud Dataprocを使用しています。Cloud Dataprocで使用される永続ディスクに使用される対称暗号化キーの作成、ローテーション、破棄ができるようにしたいと考えています。暗号化キーはクラウドに保存したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Dataprocで使用される永続ディスクに使われる暗号化キーの作成、ローテーション、破棄をどのように行うべきかという課題に焦点を当てています。また、その暗号化キーはクラウドに保存したいという要件もあります。クラウドに保存し、管理する暗号化キーとして選択肢にあげられているものが正しいかどうかを注意深く考えることが求められます。
基本的な概念や原則：
Cloud Dataproc：Google CloudのマネージドSparkとHadoopサービスです。データの分析や処理、機械学習のタスク等に利用します。
Cloud Key Management Service：Google Cloudで対象鍵の管理を行うためのマネージドサービスです。暗号化キーの作成、使用、ローテーション、破棄が行えます。
データ暗号化鍵（DEK）：データそのものを暗号化するためのキーです。直接データを暗号化・復号化するために使用されます。
鍵暗号化キー（KEK）：他の暗号キー（特にDEK）を暗号化するために使用されるキーです。暗号キーの暗号化やキーのライフサイクル管理に使用します。
顧客が提供する暗号化キー：顧客が自分で制御したい場合に使う、顧客自身が生成と管理を行う暗号化キーです。しかし、すべての管理責任が顧客にあるため、専門的な知識が必要となります。
正解についての説明：
（選択肢）
・Cloud Key Management Serviceを使用して、データ暗号化鍵（DEK）を管理します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Key Management Service（KMS）は、仮想マシンや永続ディスクなどのGoogle Cloudのリソースで用いられる秘密鍵（対称暗号化キー）を生成、使用、管理、ローテーション、そして破棄することを可能にするサービスです。これはクエスチョンで述べられた暗号化キーのライフサイクルの管理が必要とされている点に直接対応しています。
また、Cloud KMSはクラウド上で鍵を保存するため、クエスチョンにおいて暗号化キーの保存場所がクラウドであるべきと要求されている要件も満たします。
したがって、Cloud KMSを使用してデータ暗号化鍵（DEK）を管理することが最適な解決策と言えます。ただし、暗号化における基本的な概念として、データ暗号化鍵（DEK）が実際にデータの暗号化と復号化に使用され、鍵暗号化鍵（KEK）がDEKを保護するために使用されることを理解することは重要です。
不正解についての説明：
選択肢：鍵暗号化キー（KEK）を管理するために、Cloud Key Management Serviceを使用します
この選択肢が正しくない理由は以下の通りです。
誤った選択肢は、永続ディスクに使用される暗号化キー自体（DEK）を管理することではなく、別の暗号化キー（KEK）を管理することを提案しています。
一方、正解の選択肢は直接的にデータ暗号化鍵（DEK）の管理を提案しているため、問題の要件を満たします。
選択肢：データ暗号化キー（DEK）の管理には、顧客が提供する暗号化キーを使用します
この選択肢が正しくない理由は以下の通りです。
顧客が提供する暗号化キーを使用する方法では、要件で明示されているように暗号化キーの作成、ローテーション、破棄をクラウドで行うことができません。
一方で、Cloud Key Management Serviceを使用すれば、これらの暗号化キーのライフサイクルの管理を効率的にクラウド上で行うことが可能です。
選択肢：暗号化キー（KEK）の管理には、顧客が提供する暗号化キーを使用します
この選択肢が正しくない理由は以下の通りです。
顧客が提供する暗号化キーを使用するという提案はクラウドに暗号化キーを保存する要件を満たしません。
一方、Cloud Key Management ServiceはDEKの作成、ローテーション、破棄を可能にし、これらのキーをGoogle Cloud内で保存できます。
参考リンク：
https://cloud.google.com/security-key-management
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/security
https://cloud.google.com/kms/docs/creating-keys
</div></details>

### Q.  問題16: 未回答
あるウェブサイト制作会社は最近、すべての顧客サイトをApp Engineに移行しました。一部のサイトはまだ進行中であり、どの場所からでも顧客と従業員のみが閲覧できるようにする必要があります。
進行中のサイトへのアクセスを制限するソリューションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、App Engine上のウェブサイトに対するアクセス制限の設定方法について理解する必要があります。問題文のウェブサイトは"まだ進行中であり、どの場所からでも顧客と従業員のみが閲覧できるようにする必要がある"と明示しています。この特定の状況に対応する適切なソリューションを選択するためには、Google Cloudの各機能がどのように動作し、それらが提供するセキュリティレベルを基本的に理解する必要があります。
基本的な概念や原則：
Cloud Identity-Aware Proxy（IAP）：Google Cloudのアプリケーションへの安全なアクセスを提供するサービスです。IAPは、ユーザーとサービス間のTLS接続を確立し、ユーザーがサービスにアクセスする前に認証と承認を行います。
Googleグループ：一部のユーザーに共通のアクセス権を付与するための仮想グループのことです。Googleグループを使用することで、特定のgoogleアプリケーションへの複数のユーザーへのアクセスを簡単に制御することができます。
App Engine：フルマネージドのサーバーレスアプリケーションプラットフォームです。App Engineでは、デプロイからスケーリングまでのインフラストラクチャの管理をGoogle Cloudが行い、開発者はコードの実行に専念することができます。
App Engineファイアウォール：App Engineでホストされるアプリケーションに対する特定のIPアドレス範囲からのアクセスを受け入れるか拒否するルールを定義できますが、限定的な使用ケースとなります。
Cloud VPN：オンプレミスネットワークとGoogle Cloud VPCネットワークの間で暗号化されたIPsec接続を確立するサービスですが、一部のウェブサイトを特定のユーザーに制限するためのソリューションとしては不適切です。
正解についての説明：
（選択肢）
・Cloud Identity-Aware Proxy（IAP）を有効にし、顧客と従業員のユーザーアカウントを含むGoogleグループへのアクセスを許可します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのIdentity-Aware Proxy（IAP）を利用すれば、公開したくないWebアプリケーションに対して特定のユーザーやGoogleグループからのアクセスのみを許可することが可能です。つまり、この問題の状況では進行中のウェブサイトをセキュアに保持しつつ、必要な顧客や従業員だけがアクセスすることが許可されます。
また、IAPはApp Engineと直接統合されているので、特別なコードの変更を必要とせずにセキュリティを確保できます。これは、ウェブアプリケーションの移行とセキュリティ強化を両立するために最適な選択となっています。
したがって、Cloud Identity-Aware Proxy（IAP）を有効にし、顧客と従業員のユーザーアカウントを含むGoogleグループへのアクセスを許可することで、必要な要件を満たすことができます。
不正解についての説明：
選択肢：顧客と従業員のユーザーアカウントを含む.htaccessファイルをApp Engineにアップロードします
この選択肢が正しくない理由は以下の通りです。
App Engineは.htaccessファイルの使用をサポートしていません。アクセス制御を実現するためには、Cloud Identity-Aware Proxy（IAP）を使用して特定のGoogleグループにアクセス制限を設定する方法が適しています。
選択肢：顧客と従業員のネットワークからのアクセスを許可し、その他のすべてのトラフィックを拒否するApp Engineファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
App EngineのファイヤーウォールルールはIPアドレスに基づいて制御を行うため、顧客や従業員が動的なIPアドレスを持っている場合、アクセス制御が困難になります。
それに対して、Cloud Identity-Aware Proxy（IAP）はユーザーアカウントをもとにアクセス制御を行うため、IPアドレスに関係なく制御を行うことが可能です。
選択肢：Cloud VPNを使用して、関連するオンプレミスネットワークと企業のGoogle Cloud仮想プライベートクラウド（VPC）ネットワークとの間にVPN接続を作成します
この選択肢が正しくない理由は以下の通りです。
Cloud VPNはオンプレミスネットワークとGoogle Cloud VPCネットワークとの間にVPN接続を作成するもので、ウェブアプリケーションのユーザー認証やアクセス制御を行う機能を持ちません。そのため、進行中のサイトへのアクセスを指定のユーザーグループに限定する要件を満たしません。
それに対して、Cloud Identity-Aware Proxyはアクセス制御と認証を管理できます。
参考リンク：
https://cloud.google.com/iap/docs/app-engine-quickstart
https://cloud.google.com/appengine/docs/standard/python/config/appref
https://cloud.google.com/appengine/docs/standard/python/security-controls
</div></details>

### Q.  問題17: 未回答
先週、ある企業がBigQueryにログを書き込む新しいApp Engineアプリケーションをデプロイしました。プロジェクトでは他のワークロードは実行されていません。BigQueryに書き込まれたすべてのデータが、App Engineデフォルトサービスアカウントを使用して行われたことを検証する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のサービスアカウントを使用したBigQueryへのデータ書き込みを確認するという要件が課題となっています。ここでは2つの重要な要素、ログ分析のスキルとGoogle Cloudの監視ツールの理解が問われます。課題の解決に向けて、Cloud Loggingを適切に使用し、特定のフィルタリングや操作を行うことで確認を進めます。選択肢からは、多くの選択肢がCloud Loggingを使用していることから、Google Cloudの監視・ログツールを適切に理解し使いこなすことが大切です。
基本的な概念や原則：
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションやシステムから生成されるログデータを一元的に管理し、分析と監視を行います。
BigQuery挿入ジョブ：BigQueryへのデータの追加や更新を行う操作です。Cloud Loggingを使用して行ったオペレーションの詳細を確認することが可能です。
App Engineデフォルトサービスアカウント：App Engineアプリケーションで自動的に作成されるサービスアカウントです。アプリケーションがGoogle Cloud APIを認証して使用するために使用されます。
Cloud IAM：Google Cloudの認証・認可を行うサービスです。ユーザーやサービスアカウントに対してロールやパーミッションを付与し、リソースへのアクセスを制御します。
BigQuery：Google Cloudのフルマネージド、サーバーレス、ハイスケーラビリティのデータウェアハウスサービスです。大量のデータに対する高速な分析クエリを実行することが可能です。
App Engine：Google Cloudのフルマネージドなサーバーレスアプリケーションプラットフォームです。アプリケーションの開発、デプロイ、スケーリングを効率的に行うことが可能です。
正解についての説明：
（選択肢）
・1. Cloud Loggingを使用し、BigQuery挿入ジョブでフィルタします
2. 認証フィールドのApp Engineデフォルトサービスアカウントに一致する電子メールアドレスをクリックします
3. "一致するエントリを非表示"をクリックします
4. 結果のリストが空であることを確認します
この選択肢が正解の理由は以下の通りです。
まず、Cloud LoggingはGoogle Cloudのログデータを保存、検索、分析できるサービスで、BigQueryへのデータ書き込み操作のロギングもサポートしています。そのため、BigQueryへのデータ書き込みが行われたときに、それを記録し確認するための最適なツールです。
次に、Cloud Loggingではログ中の特定のフィールドにフィルタを適用してログを検索することができます。ここでは、App Engineデフォルトサービスアカウントによる操作を調べるため、認証フィールドにフィルターを適用しています。
さらに、フィルタにマッチするエントリを非表示にすることで、どの操作がApp Engineデフォルトサービスアカウントによって行われたのかを明確にすることができます。リストが空であれば、すべての操作が該当のサービスアカウントによって行われたことを意味します。
この選択肢は、特定のサービスアカウントによる操作を確認し、それが想定通りに実行されているかを検証することを可能にするため、要件を満たしています。
不正解についての説明：
選択肢：1. Cloud Loggingを使用し、BigQuery挿入ジョブでフィルタします
2. 認証フィールドのApp Engineデフォルトサービスアカウントに一致する電子メールアドレスをクリックします
3. "一致するエントリを表示"をクリックします
4. 結果のリストが空であることを確認します
この選択肢が正しくない理由は以下の通りです。
"一致するエントリを表示"を選択して結果のリストが空だと、そのサービスアカウントでのBigQuery挿入が1つも行われていないことを示します。検証したいのは"すべてのデータがデフォルトサービスアカウントを通じて書き込まれた"ことなので、"一致するエントリを非表示"にするべきです。
選択肢：1. BigQueryで、関連するデータセットを選択します
2. App Engineデフォルトサービスアカウントが、データセットに書き込みできる唯一のアカウントであることを確認します
この選択肢が正しくない理由は以下の通りです。
BigQueryのデータセットの権限設定を確認することで、サービスアカウントが書き込み可能であることは確認できますが、すでに存在するデータが該当サービスアカウントを用いて書き込まれたことを検証するのは不可能です。
それに対して、正解はCloud Loggingを用いて具体的な操作ログを確認するため、要求が満たせます。
選択肢：1. プロジェクトの"Identity and Access Management（IAM）"セクションに移動します
2. App Engineデフォルトサービスアカウントが、BigQueryに書き込みできるロールを持つ唯一のアカウントであることを検証します
この選択肢が正しくない理由は以下の通りです。
IAMポリシーを確認するのではなく、Cloud LoggingでBigQueryの挿入ジョブを直接調査することで、実際の書き込みがApp Engineデフォルトサービスアカウントによって行われたかどうかを検証することが可能です。IAMの確認は、アカウントが適切な権限を持っていることを確認するのに役立ちますが、それが実際にデータ書き込みを行ったかどうかの確証は得られません。
参考リンク：
https://cloud.google.com/logging/docs/view/overview
https://cloud.google.com/bigquery/docs/reference/auditlogs
https://cloud.google.com/iam/docs/granting-changing-revoking-access
</div></details>

### Q.  問題18: 未回答
あなたの会社はGoogle Cloudに移行しようとしています。まず、Google Cloud Directory Sync（GCDS）を使用してユーザーを同期する予定です。一部の従業員は、GCDS以外で作成した会社のメールアドレスを使用してGoogle Cloudアカウントを作成済みです。また、Cloud Identityでユーザを作成する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudに移行する際のユーザーアカウント管理について考察します。既にGoogle Cloudアカウントを持っている従業員と、新たにCloud Identityで作成するユーザーという2つのケースが存在します。GCDSを使用してユーザーを同期する予定ですが、一部の従業員はすでにGCDS以外でアカウントを作成しているため、これらのユーザーをどのように扱うのかが問われています。選択肢は、GCDSの設定やユーザー移行ツールの使用に関連していますが、最も適切な措置を選ぶためには、既存ユーザーのアカウントと新規ユーザーのアカウント管理のバランスを維持することが条件となります。
基本的な概念や原則：
Google Cloud Directory Sync（GCDS）：オンプレミスのLDAPディレクトリサービスとGoogle Cloud Identityのユーザー、グループ、およびその他のデータを同期するツールです。ローカルのディレクトリチェンジをGoogle Cloudに反映します。
管理されていないユーザー：Google Cloudサービスを使用するために、あるドメインのメールアドレスを使用して作成されましたが、そのドメインの管理下にないユーザーのことです。
転送ツール：Google Cloudでは、非管理ユーザーを対象のドメインの管理下に移行するための転送ツールが提供されています。
Cloud Identity：Google CloudのIdentity-as-a-Service（IDaaS）です。ユーザー管理およびエンドポイント管理を一体化します。
Admin SDK：Google Cloudの管理者向けAPIを提供するツールです。Directory APIを含み、ユーザー、グループ、ドメインなどの管理作業を行います。
正解についての説明：
（選択肢）
・管理されていないユーザーを移行するために、転送ツールを使用します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、管理されていないユーザーアカウント（GCDS以外で作成されたもの）を組織のGoogleワークスペースに移行するための方法として、転送ツールを提供しています。これにより、組織全体で一元的な管理が可能になり、データのセキュリティを確保することができます。
また、適切なアクセス権の管理も行うことができます。
Google Cloud Directory Sync（GCDS）は、オンプレミスのディレクトリとGoogle Cloud Identityでユーザーを同期するためのツールです。ただし、すでにGoogle Cloudのアカウントを持っているユーザーをGCDSで同期しようとすると、"既存のアカウントがある"というエラーメッセージが表示されるかもしれません。
したがって、すでに作成済みのアカウントをうまく管理下に置くためには、転送ツールを使用してこれらの既存ユーザーを移行すべきです。この操作により、既存のGoogle Cloudアカウントが組織のGoogleワークスペースに統合され、効率的なユーザー管理が実現します。
不正解についての説明：
選択肢：GCDSを設定し、GCDS検索ルールを使用してこれらのユーザーを同期します
この選択肢が正しくない理由は以下の通りです。
GCDS検索ルールを使用してユーザーを同期すると、既存のGoogle Cloudアカウントは無視され、新たなアカウントが作成されます。既存のアカウントを含めるためには、転送ツールを使用して管理されていないユーザーを移行する必要があります。
選択肢：既存のGoogle Cloudユーザーを識別し、Admin SDKを呼び出すカスタムスクリプトを作成します：Directory APIを呼び出してアカウントを転送します
この選択肢が正しくない理由は以下の通りです。
Admin SDKを使用してカスタムスクリプトを作成しDirectory APIを呼び出してアカウントを転送する方法は手間がかかり、管理の負担が増す可能性があります。
それに対して、転送ツールを使用することで、効率的に管理されていないユーザーを移行することが可能になります。
選択肢：GCDSを設定し、GCDSの除外ルールを使用して、ユーザーがサスペンドされないようにします
この選択肢が正しくない理由は以下の通りです。
GCDSの除外ルールは特定のユーザーを同期対象から除外する機能ですが、それはすでに会社のメールアドレスでGoogle Cloudアカウントを作成している従業員が管理対象になる問題を解決しません。正解は彼らのアカウントを管理対象にするために転送ツールを使用することです。
参考リンク：
https://cloud.google.com/identity/docs/transfer-tool
https://cloud.google.com/identity/docs/how-to/setup#setting_up_gcds
https://support.google.com/a/answer/1041297?hl=en
</div></details>

### Q.  問題19: 未回答
ある顧客が、Compute Engine上でホストされているERPシステムにCloud Identity-Aware Proxyを実装しています。セキュリティチームは、ERPシステムがCloud Identity-Aware Proxyからのトラフィックのみを受け入れるように、セキュリティレイヤーを追加したいと考えています。
これらの要件を満たすために、顧客は何をすべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Identity-Aware ProxyがCompute EngineによってホストされるERPシステムへの接続を管理するように、指定されたセキュリティレイヤーをどのように追加すべきかを特定する必要があります。選択肢を検討する際は、Cloud Identity-Aware Proxyがどのように動作し、それがセキュリティレイヤーとしてどのように機能するかを理解する必要があります。それにより、ERPシステムがどのHTTPリクエストヘッダーの検証を確認すべきかを判断することができます。
基本的な概念や原則：
Cloud Identity-Aware Proxy（IAP）：Google Cloudのサービスで、内部のWebアプリケーションへの安全なアクセスを提供します。VPNやネットワークレベルのファイアウォールの代替となります。
Compute Engine：Google Cloudのサービスの1つで、仮想マシンを作成し、実行する事ができます。
HTTPヘッダーの検証：入力として受け取るHTTP要求ヘッダーの内容を検証します。エンドポイントのセキュリティを強化するための一般的なテクニックです。
ERPシステム：企業の全ての主要なビジネスプロセスを統合・管理するためのソフトウェアシステムです。
JWT（JSON Web Token）：ロールや特性を表すためのJSON形式のオブジェクト。OAuthなどの認証・認可フローで利用されます。
x-forwarded-forヘッダー：HTTPリクエストのヘッダに追加され、クライアントのIPアドレス情報を示す規格。プロキシサーバーやロードバランサーを経由した場合に利用されます。
正解についての説明：
（選択肢）
・ERPシステムがHTTP要求のIDヘッダーを検証できることを確認します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Identity-Aware Proxy（IAP）は、Google Cloudのアプリケーションにアクセスする前にユーザーの認証と認可を実行するツールです。IAPを使用すると、公開場所にあるアプリケーションに対するVPN接続を無くすことが可能になります。
IAPがユーザーを認証すると、それが透明であるために、続いてアプリケーションに送られるHTTP要求ヘッダーに認証情報が追加されます。
したがって、アプリケーションがこのヘッダーを検証することで、送られてきた要求がIAPからと確認できるようになります。
したがって、ERPシステムがこのIDヘッダーを検証できると、Cloud IAPからのトラフィックのみを受け入れられるようになります。これによりセキュリティチームは求めていたセキュリティレイヤーを追加することが可能となります。というわけで、この選択肢が正解となります。
不正解についての説明：
選択肢：ERPシステムがHTTP要求でJWTアサーションを検証できることを確認します
この選択肢が正しくない理由は以下の通りです。
Cloud Identity-Aware Proxy（IAP）はヘッダーを利用して認証を行いますが、JWTアサーションではなくIDヘッダーを使用します。そのため、ERPシステムがHTTP要求のJWTアサーションを検証できることはIAPの導入には不要です。
対照的に、正解はIDヘッダーの検証能力を強調し、IAPが使用する認証手法に直接対応しています。
選択肢：ERPシステムがHTTP要求のx-forwarded-forヘッダーを検証できることを確認します
この選択肢が正しくない理由は以下の通りです。
x-forwarded-forヘッダーは、クライアントのIPアドレス情報を含むが、トラフィックがCloud Identity-Aware Proxyから来たことを確証する情報は含まれません。
一方、IDヘッダーはCloud Identity-Aware Proxyからのトラフィックを確認するために使用することができます。
選択肢：ERPシステムが、HTTPリクエスト内のユーザー一意識別子ヘッダーを検証できることを確認します
この選択肢が正しくない理由は以下の通りです。
Cloud Identity-Aware Proxyを用いる場合、個々のユーザー識別子ではなく、IDヘッダーを検証することで、リクエストがCloud Identity-Aware Proxyから来ているかを確認することが求められています。よって、ユーザー一意識別子ヘッダーの検証は求められていません。
参考リンク：
https://cloud.google.com/iap/docs/enabling-compute-howto
https://cloud.google.com/iap/docs/signed-headers-howto
https://cloud.google.com/compute/docs/ip-addresses#reservedaddress
</div></details>

### Q.  問題20: 未回答
標準的なネットワーク階層を使用しながら、デフォルトでクライアントIPを維持するために、どのタイプのロードバランサーを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ロードバランサーの種類とそれぞれの機能に関する理解が求められています。特に、デフォルトでクライアントIPを維持するロードバランサーのタイプを選ぶことが問われています。問題文を理解するためには、各ロードバランサーがどのように動作し、それぞれがどのようなネットワーク階層で動くのか、またどのロードバランサーがクライアントIPを維持可能なのか、を把握する必要があります。
基本的な概念や原則：
TCP/UDPネットワークロードバランサー：パケットレベルのロードバランサーであり、リッチなルーティング機能と高いパフォーマンスを提供します。デフォルトでクライアントIPを維持します。
SSLプロキシロードバランサー：SSL（HTTPS）トラフィックのロードバランサーで、SSLオフロード能力を提供します。クライアントIPを維持しないことがあります。
TCPプロキシロードバランサー：TCP（またはSSL）トラフィックのロードバランサーで、迅速なオープンコネクションを提供します。こちらもクライアントIPを維持しないことがあります。
内部TCP/UDPロードバランサー：VPCネットワーク内部にあるインスタンス間でトラフィックをバランスします。クライアントIPの維持が特例となります。
正解についての説明：
（選択肢）
・TCP/UDPネットワーク
この選択肢が正解の理由は以下の通りです。
まず、TCP/UDPネットワークロードバランサーは、トラフィックをバックエンドサーバーに分散するために、トランスポート層（L4）レベルでロードバランスを行います。このレベルで動作するため、クライアントのIPアドレスが変更されずに保持されます。これは特に、クライアントのIPアドレスを維持する必要があるケース、たとえば特定のIPからのリクエストを特定のサーバにルーティングしたいといった場合に有用です。
また、TCP/UDPネットワークロードバランサーは、デフォルトで典型的なネットワーク階層（つまり、マルチレイヤーネットワークトポロジ）で動作します。これにより、ネットワーク設計と管理が容易になり、スムーズな運用が可能となります。
したがって、標準的なネットワーク階層を維持しながらクライアントIPを保持するためには、TCP/UDPネットワークロードバランサーを使用すべきです。
不正解についての説明：
選択肢：SSLプロキシ
この選択肢が正しくない理由は以下の通りです。
SSLプロキシロードバランサーは、クライアントIPアドレスを元の形で維持することができません。クライアントのIPアドレスを保持しながら標準的なネットワーク階層を使用するために、TCP/UDPネットワークロードバランサーが適切な選択肢となります。
選択肢：TCPプロキシ
この選択肢が正しくない理由は以下の通りです。
TCPプロキシロードバランサーはクライアントのIPを維持しません。クライアントからの接続を受け取り、バックエンドインスタンスに転送するときに新しいTCPセッションを開始します。
これに対して、TCP/UDPネットワークロードバランサーはクライアントのIPを維持します。
選択肢：内部TCP/UDP
この選択肢が正しくない理由は以下の通りです。
内部TCP/UDPロードバランサーは特定の状況下でクライアントIPを維持しますが、一般的にはプロキシモードで動作し、クライアントIPを維持しません。しかし正解のTCP/UDPネットワークロードバランサーはパケットに対して直接操作を行うため、デフォルトでクライアントIPを維持します。
参考リンク：
https://cloud.google.com/load-balancing/docs/network
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
</div></details>

### Q.  問題21: 未回答
Google Cloudリソースへの直接アクセスが必要な開発者や運用スタッフそれぞれに、Google Cloudの企業ユーザーアカウントを提供する必要があります。
企業ポリシーでは、サードパーティのID管理プロバイダでユーザーIDを管理し、シングルサインオンを活用する必要があります。あなたは、かなりの数のユーザーが個人的なGoogleアカウントに会社ドメインのメールアドレスを使用していることを知り、Googleが推奨するプラクティスに従って、既存の管理対象外のユーザーを管理対象アカウントに変更する必要があります。
あなたが取るべき2つのアクションはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの企業ユーザーアカウントの設定方法とユーザー管理に関する要求が課せられています。主に注目すべきは"サードパーティのID管理プロバイダでユーザーIDを管理したい"、"シングルサインオンを活用したい"、"個人的なGoogleアカウントに会社ドメインのメールアドレスを使用しているユーザーが問題"であるというポイントです。これらに対応するために、Google Cloudの機能だけでなく、その外部との連携や同期が重要です。また、すでに存在する個人アカウントの扱いも考慮する必要があります。それらを解決する方法として、適切なGoogle Cloudのツールの選択が求められています。
基本的な概念や原則：
Google Cloud Directory Sync：Google Cloudのサービスで、企業のローカルID管理システムをCloud IdentityやG Suiteと同期できます。企業の既存のユーザー管理基盤を活用して、ユーザーアカウントを効率的に管理できます。
Cloud Identity：Google CloudのIDとアクセス管理サービスです。企業はこのサービスを利用して、ユーザーアカウントのライフサイクルを管理したり、デバイスのアクセスを制御したりできます。
Transfer Tool for Unmanaged Users（TTUU）：クラウドIDやG Suiteが所有するドメインと同じドメインを使用している未管理のGoogleアカウントを管理対象アカウントに移行させるGoogleのツールです。
シングルサインオン：複数のシステムやサービスを同じ認証情報で利用できるようにする技術です。1つのログイン操作で複数のシステムにアクセスできるため、ユーザー体験の改善やセキュリティ強化に効果的です。
サードパーティのID管理プロバイダ：IDと認証を提供する外部サービスのことであり、多くの企業では既存のITインフラストラクチャと統合するために利用しています。
管理対象アカウントと未管理アカウント：Google Cloudでは、企業が管理するアカウント（管理対象アカウント）と、企業が管理しない個々のユーザーが自分で管理するアカウント（未管理アカウント）との間で区別します。
正解についての説明：
（選択肢）
・Google Cloud Directory Syncを使用して、ローカルのID管理システムをCloud Identityに同期します
・Transfer Tool for Unmanaged Users（TTUU）を使用して、競合するアカウントを持つユーザーを見つけ、個人のGoogleアカウントを移行するよう依頼します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Directory Syncを使用することで、ローカルに存在するユーザーID管理システムとCloud Identityを同期することができます。これにより、企業ポリシーに従い、Google Cloudの企業ユーザーアカウントを提供することの準備が整います。つまり、サードパーティのID管理プロバイダで管理されているユーザーIDをGoogle CloudのCloud Identityに取り込むことで、ユーザーがGoogle Cloudリソースへ直接アクセスするための管理アカウントの提供が可能となります。
次に、Transfer Tool for Unmanaged Users（TTUU）は、Googleが推奨するツールで、すでに個人Googleアカウントを使用しているユーザーのアカウントを管理対象アカウントに移行するためのものです。このツールを通じて、競合するアカウントを持つユーザーを特定し、個人のGoogleアカウントから管理下のアカウントへの移行を依頼することができます。これにより、既存の管理対象外のユーザーを管理対象アカウントに変更する作業が効率的に行えます。
不正解についての説明：
選択肢：Google管理コンソールを使用して、どの管理対象ユーザーがリカバリメールに個人アカウントを使用しているかを確認します
この選択肢が正しくない理由は以下の通りです。
Google管理コンソールは、ユーザーがリカバリメールに個人アカウントを使用しているか確認する機能を持っていません。それよりも、TTUUを用いて管理対象ユーザーを特定し、そのアカウントを移行させるよう依頼するのが適切なアクションです。
選択肢：管理するGoogleアカウントにユーザーを追加し、ユーザーに個人アカウントに関連付けられたメールアドレスを変更させます
この選択肢が正しくない理由は以下の通りです。
個人アカウントとは別に新しい管理対象のアカウントを作成し、ユーザーにメールアドレスを変更させることは煩雑であり、不必要な手間をかけることになります。
また、Googleの推奨するプラクティスにも従っていません。TTUUを使用すれば、操作が簡略化され、ユーザーは権限を失うことなくアカウントを移行できます。
選択肢：全従業員にメールを送り、個人用Googleアカウントに会社のメールアドレスを使用しているユーザーには、個人用アカウントを直ちに削除するよう要請します
この選択肢が正しくない理由は以下の通りです。
全従業員にメールを送り、個人用Googleアカウントを直ちに削除するよう要請すると変更は即時的でコントロールが難しいです。
一方、TTUUを使用すると既存ユーザーの管理対象への移行がスムーズに行えます。これはGoogleの推奨するプラクティスでもあります。
参考リンク：
https://cloud.google.com/identity/docs/how-to/setup#connecting_to_your_ldap_directory
https://cloud.google.com/identity/docs/troubleshooting-common-sso
https://support.google.com/a/answer/106368?hl=en
</div></details>

### Q.  問題22: 未回答
あなたの会社のセキュリティチームは、元従業員が過去2ヶ月の間にサービスアカウントキーを使用してGoogle Cloudリソースに不正アクセスしたと考えています。不正アクセスを確認し、ユーザーアクティビティを特定する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、不正アクセスの確認とユーザーアクティビティの特定という二つの要件を満たすために、Google Cloud上のどの機能をどのように活用すべきかを問われています。不正アクセスの確認とは、サービスアカウントキーを使った特定のアクションの証拠を検出することを指すでしょう。また、ユーザーアクティビティを特定するとは、特定のユーザーの操作またはパターンを把握することを意味します。この二つの要件を考慮に入れつつ、選択肢を評価することが求められます。
基本的な概念や原則：
ログエクスプローラ：Google Cloudが記録したログを検索、分析、視覚化するツールです。ユーザーやサービスのアクティビティを追跡して詳細な情報を得ることができます。
サービスアカウントキー：Google CloudのAPIを使用するための認証情報です。サービスアカウントを表すために使用され、不正に使用された場合はセキュリティの問題となります。
Security Health Analytics：Google Cloudのセキュリティスコアカードと総合的な脅威レポートを提供するツールです。各プロジェクトのセキュリティポスチャを改善するための推奨行動を提供しますが、個々のユーザーアクティビティの追跡には使用されません。
Cloud Monitoring：Google Cloud上のアプリケーションとサービスのパフォーマンスを監視するツールです。活動ログをフィルタリングする能力がありますが、詳細なユーザーアクティビティの追跡には適していません。
Cloud Data Loss Prevention API：情報の機密性を保つためのツールです。感慣性情報を自動的に識別、分類、調整しますが、ユーザーアクティビティの追跡用途には使用されません。
正解についての説明：
（選択肢）
・ログエクスプローラを使用して、ユーザーのアクティビティを検索します
この選択肢が正解の理由は以下の通りです。
Google Cloudのログエクスプローラは、Google Cloudの各種サービスやアプリケーションから生成されるログを一元管理し、検索、フィルタリング、可視化するための強力なツールです。Google Cloudに保存されたログデータを高速に検索し、ログデータから具体的なユーザーアクティビティを特定することが可能です。
したがって、過去の操作ログを検索して、特定のユーザーアクティビティがサービスアカウントキーを使用して不正にアクセスを試みたかどうかを特定できます。
さらに、詳細なフィルタリング機能を用いて特定の期間や特定のユーザーの行動に焦点を当てることも可能なため、探索範囲を過去2ヶ月間に限定し、元従業員の操作を特定することが可能です。このため、この問題の要件を満たすためには、ログエクスプローラを使用してユーザーのアクティビティを検索するのが適切です。
不正解についての説明：
選択肢：Security Health Analyticsを使用して、ユーザーのアクティビティを判断します
この選択肢が正しくない理由は以下の通りです。
Security Health Analyticsは、脆弱性や不適切な設定を検出し、リスク評価と対策の推奨を提供するサービスで、特定のユーザーのアクティビティの詳細な監視・追跡は目的に適っていません。
一方、ログエクスプローラは、ユーザーやサービスの具体的なアクティビティログを検索・分析するためのツールであり、不正アクセスの確認や特定のユーザーアクティビティの特定に適切です。
選択肢：Cloud Monitoringコンソールを使用して、ユーザー別に監査ログをフィルタリングします
この選択肢が正しくない理由は以下の通りです。
Cloud Monitoringコンソールは基本的にシステムメトリクスの監視と警告のためのものであり、ユーザー別に監査ログをフィルタリングする能力はありません。
一方で、ログエクスプローラはGoogle Cloudのログデータを検索、フィルタリング、表示できるため、ユーザーのアクティビティ特定に適しています。
選択肢：Cloud Data Loss Prevention APIを使用して、Cloud Storageのログを照会します
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Prevention APIは、機密データが露出していないかチェックするためのもので、ユーザーのアクティビティを追跡するためのものではありません。
一方、ログエクスプローラはログを検索し、特定のユーザーのアクティビティを追跡するために使用できます。
したがって、ログエクスプローラを使用するほうが要件に適しています。
参考リンク：
https://cloud.google.com/logging/docs/using-logs-explorer
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/security-command-center/docs/concepts-security-health-analytics
</div></details>

### Q.  問題23: 未回答
セキュリティチームは、ユーザが管理する鍵が誤って管理され、漏洩するリスクを減らしたいと考えています。そのためには、開発者が組織内のプロジェクト用にユーザ管理サービスアカウントキーを作成できないようにする必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、開発者がユーザ管理のサービスアカウントキーを作成できないようにする方法を選択することが求められています。そのため問題文の要件に基づいて、選択肢を見ていきましょう。選択肢には色々な管理方法や設定変更が提案されていますが、目的はユーザ管理のサービスアカウントキーの作成を防ぐことであるため、それを直接的に達成できる選択肢を選ぶことが大切です。
基本的な概念や原則：
組織ポリシー：Google Cloud上の組織に対する特定の制約を設定するためのものです。ポリシーレベルで管理し、ロールベースのアクセス制御を提供します。
サービスアカウントキー：サービスアカウントを認証するために使用され、ユーザーによって手動で作成・管理されます。ユーザー管理のサービスアカウントキーは、誤管理によるリスクがあります。
Secret Manager：Google Cloudで機密情報を安全に管理するサービスです。ただし、サービスアカウントキーの作成自体を制限する機能はありません。
iam.serviceAccounts.getAccessTokenパーミッション：サービスアカウントからアクセストークンを取得する権限です。ただし、サービスアカウントキーの作成を制限する機能はありません。
正解についての説明：
（選択肢）
・組織ポリシーを有効にして、サービスアカウントキーが作成されないようにします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudでは、組織ポリシーを用いて特定のクラウドリソースに対するアクセス制限を行うことができます。サービスアカウントキーの作成を制限するために、組織ポリシーを適切に設定することで可能となります。そのため、組織全体でサービスアカウントキーの作成を禁止するために、この機能を有効にするのが適切です。
さらに、組織ポリシーによる制限は、開発者が誤って認証情報を管理し難く、鍵の漏洩リスクを効果的に軽減できます。開発者が所有権を持つサービスアカウントの管理を正しく行うことは困難であり、独自の鍵を生成・管理することはセキュリティ上のリスクを高まらせます。そのため、サービスアカウントキーの作成を組織ポリシーで制限することは、セキュリティを保つ上で効果的な策と言えます。
不正解についての説明：
選択肢：Secret Managerを設定してサービスアカウントキーを管理します
この選択肢が正しくない理由は以下の通りです。
Secret Managerは秘密情報の保管・管理をするためのサービスであり、ユーザがサービスアカウントキーを作成することを直接制限する機能は持っていません。
対照的に、組織ポリシーを有効にすることでキーの作成を直接禁止することが可能です。
選択肢：組織ポリシーを有効にして、サービスアカウントを作成できないようにします
この選択肢が正しくない理由は以下の通りです。
サービスアカウントそのものを作成できないようにすると、管理の範囲が広すぎてしまい、開発者がアプリケーションを運用する上で必要な一部のサービスアカウントの使用を防いでしまいます。
一方、正解の選択肢では、ユーザ管理のサービスアカウントキーのみの作成を制限するので、適切なセキュリティ対策を講じつつ、アプリケーションの運用も可能にします。
選択肢：ユーザーからiam.serviceAccounts.getAccessTokenパーミッションを削除します
この選択肢が正しくない理由は以下の通りです。
iam.serviceAccounts.getAccessTokenパーミッションを削除すると、ユーザはサービスアカウントからアクセストークンを取得することはできなくなりますが、サービスアカウントキーの作成は可能なままです。
一方、組織ポリシーを有効にしてサービスアカウントキーの作成を禁止すると直接的に問題を解決できます。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題24: 未回答
一般的に、アプリケーションは多くの場合、ビルド時や実行時にシークレットへのアクセスを必要とします。Google Cloud上でこれらのシークレットを管理する管理者は、Google Cloudプロジェクト内で"誰が、いつ、どこで、何をしたか"を追跡したいと考えています。
管理者が探している情報を提供する2つのログストリームはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudプロジェクトに関するログ管理の問いが挙げられています。"誰が、いつ、どこで、何をしたか"という4つの質問が指摘されている点を重視する必要があります。ここでは、シークレットの管理と、それに関連するユーザーアクティビティとデータアクセスの追跡に注目し、適切なログストリームを選択することが重要です。選択肢にはさまざまなログのタイプが挙げられていますが、問題文が求めている情報を正確に捕捉できるタイプを選んでください。
基本的な概念や原則：
管理者の活動ログ：Google Cloud上で行われた管理タスクに関するログです。管理者が実行したアクション（誰が、何を、いつしたか）に関する詳細情報を追跡します。
データアクセスログ：Google Cloudサービスがユーザーデータにアクセスする際（どこで、何がアクセスされたか）に生成されるログです。これには、API呼び出しやGoogle Cloud Consoleの操作などが含まれます。
システムイベントログ：Google Cloudサービスがシステムイベントを生成した際のログです。このログは、システムレベルでのアクティビティに関する情報を提供します。ただし、"誰が、いつ、どこで、何をしたか"についての詳細な情報は提供しません。
VPCフローログ：VPCネットワークのIPトラフィックに関するログです。これには、送信元と送信先IP、パケットサイズ、インスタンスIDなどの情報が含まれます。しかし、"誰が、いつ、どこで、何をしたか"に関する情報は含まれていません。
エージェントログ：エージェントが生成したログです。これは、特定のアプリケーションやサービスに特化した詳細情報を提供するために使用されますが、"誰が、いつ、どこで、何をしたか"に関する情報を直接提供するものではありません。
正解についての説明：
（選択肢）
・管理者の活動ログ
・データアクセスログ
この選択肢が正解の理由は以下の通りです。
まず、管理者の活動ログはGoogle Cloud上での管理者の操作を記録します。これにはプロジェクトの設定変更、リソースの作成や削除、他のユーザーへの権限の付与などが含まれます。このログは、"誰が何をしたか"を明らかにするために必要です。
次に、データアクセスログはユーザーがGoogle Cloudのリソースに対して行った読み取り、書き込み、または更新の操作を記録します。ただし、これは管理者が明示的に有効化しなければならないオプションのログです。これらのログは"何を、いつ、どこで、誰がしたか"を特定するために有効です。
したがって、これらの二つのログストリームを適切に使用し、監視することで、Google Cloud上でシークレットを管理する際のアクセス情報を詳細に追跡し、問題の特定や将来の不正アクセスの防止に役立てることができます。
不正解についての説明：
選択肢：システムイベントログ
この選択肢が正しくない理由は以下の通りです。
システムイベントログはGoogle Cloudのバックエンドシステムによる操作に関するログであり、管理者による操作やデータへのアクセスに関する情報は含まれません。
一方、管理者の活動ログやデータアクセスログは"誰が、いつ、どこで、何をしたか"についての詳細な情報を提供します。
選択肢：VPCフローログ
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフロー情報を提供しますが、"誰が、いつ、どこで、何をしたか"という詳細なアクセス情報を提供するものではありません。
一方、管理者の活動ログやデータアクセスログはこの要求を満たすために適切なログストリームとなります。
選択肢：エージェントログ
この選択肢が正しくない理由は以下の通りです。
エージェントログはGoogle Cloudのリソースを監視するためのものであり、誰が何をしたかなどの操作履歴を追跡する情報は含まれません。
これに対し、管理者の活動ログやデータアクセスログはユーザーの操作やデータへのアクセスを記録するため、求めている情報を提供します。
参考リンク：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/audit-logging
https://cloud.google.com/security-command-center/docs/concepts-logging-and-notifications
</div></details>

### Q.  問題25: 未回答
共有VPCに接続されたCompute EngineインスタンスとBigQueryデータセット間のアクセス拒否エラーのトラブルシューティングを行っています。データセットは、VPC Service Controls境界によって保護されたプロジェクトに存在します。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの共有VPC、Compute Engineインスタンス、BigQueryデータセットとVPC Service Controlsに関連するエラーハンドリングの知識が求められます。ここでの課題は、VPC Service Controls境界によって保護されたプロジェクト内のデータセットに共有VPCを通じてアクセスしたいというものです。選択肢を選ぶ際には、VPC Service Controlsの設定と、それがどのように共有VPCと他のGoogle Cloudサービスとの連携に影響を与えるか、を理解しておくことが重要です。
基本的な概念や原則：
共有VPC：Google Cloudのネットワークリソースを複数のプロジェクト間で共有するための機能です。ホストプロジェクトのネットワークを共有し、サービスプロジェクトのインスタンスで使用します。
VPC Service Controls：Google Cloudサービス間のデータの流れを制御するセキュリティ境界を設定する機能です。境界内のリソースへのアクセスを制限します。
ホストプロジェクト：共有VPCを持つプロジェクトです。このホストプロジェクトのネットワークをサービスプロジェクトが共有します。
サービスプロジェクト：共有VPCを使用するプロジェクトです。ホストプロジェクトからネットワークを共有します。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。柔軟な仮想マシンの設定と自動スケーリングが可能です。
BigQuery：Google Cloudの大規模データ分析サービスです。高速なSQLクエリを実行し、ビッグデータの分析を容易にします。
正解についての説明：
（選択肢）
・共有VPCを含むホストプロジェクトをサービス境界へ追加します
この選択肢が正解の理由は以下の通りです。
共有VPCを使用すると、複数のプロジェクト間でネットワークリソースを統一的に管理できます。このネットワークは一つのホストプロジェクトで定義され、他のサービスプロジェクトから利用されます。これにより、ネットワークの設定やポリシーを一元的に制御できます。
一方、VPC Service ControlsはGoogle Cloudのサービスに対するデータの流れを制御するためのセキュリティ対策の一つで、一定の範囲（サービス境界）を設定し、その範囲内からのデータアクセスのみを許可することができます。
共有VPCを含むホストプロジェクトがVPC Service Controlsのサービス境界に含まれていないと、そのネットワークからは境界によって保護されたリソースへのアクセスが拒否されます。
したがって、アクセス拒否エラーを解消するためには、共有VPCを含むホストプロジェクトをVPC Service Controlsのサービス境界に追加する必要があります。そうすることで、共有VPCからのデータアクセスが許可され、エラーは解消されます。
不正解についての説明：
選択肢：Compute Engineインスタンスが存在するサービスプロジェクトをサービス境界に追加します
この選択肢が正しくない理由は以下の通りです。
サービスプロジェクトをサービス境界に追加しても、共有VPCが保護されません。
それに対して、ホストプロジェクトを境界に追加すると、共有VPC全体が保護され、接続されたインスタンスからBigQueryデータセットにアクセスできます。
選択肢：Compute Engineインスタンスが存在するサービスプロジェクトと、Shared VPCを含むホストプロジェクトの間に、サービス境界を作成します
この選択肢が正しくない理由は以下の通りです。
サービス境界はプロジェクト間のデータ流れを制限するもので、Compute EngineインスタンスとShared VPC間に新たに境界を作ると、それらのコミュニケーションをさらに阻む可能性があります。正解は共有VPCを含むホストプロジェクトを境界に追加して、BigQueryデータセットとのアクセスを許可することです。
選択肢：Compute Engineインスタンスが存在するサービスプロジェクトと、保護されたBigQueryデータセットを含む境界との間に境界ブリッジを作成します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsは、サービスとデータ間の適切な流れを管理するために導入されたものであり、一方で存在しない概念である"境界ブリッジ"を作成することはできません。正しい対策は、共有VPCを含むホストプロジェクト全体をVPC Service Controls境界に追加することです。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/set-up-private-connectivity
https://cloud.google.com/vpc-service-controls/docs/perimeters
https://cloud.google.com/bigquery/docs/datasets-access-controls
</div></details>

### Q.  問題26: 未回答
データ所在地の要件として、Google Clouds Secret Managerのシークレットがeurope-west1とeurope-west4にのみペイロードを持つようにします。シークレットは両方のリージョンで高度に利用可能でなければなりません。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud Secret Managerのシークレットが特定のリージョンに限定され、そのリージョンでも高可用性を確保する必要があるという要件を満たすためにはどのようにすべきかについて問われています。知っておくべきは、Google Cloud Secret Managerはシークレットのデータ所在地管理という観点からユーザーが管理するレプリケーションポリシーを提供しており、これにより特定のリージョンのみでシークレットを保持することが可能な点です。また、高可用性についても考慮しなければならないという要件があるため、単純に特定のリージョンに限定するだけではなく、選択するレプリケーションポリシーは高可用性を確保するものであるべきだということも理解しておく重要です。
基本的な概念や原則：
Secret Manager：Google Cloudのシークレット管理サービスです。APIキーやパスワードなどのシークレット情報を安全に保存、管理することができます。
ユーザーが管理するレプリケーションポリシー：シークレットがレプリケーションされる具体的なリージョンをユーザーが指定するタイプのレプリケーションポリシーです。データ所在地の要件に対応できます。
自動レプリケーションポリシー：シークレットがGoogle Cloudの全リージョンに自動的にレプリケーションされるタイプのポリシーです。特定のリージョンの選択はできません。
Terraform：インフラストラクチャをコードとして定義し、管理するためのツールです。多数のクラウドサービスに対応していますが、シークレットのレプリケーションポリシーの設定には直接使用できません。
組織ポリシー：Google Cloudリソースに対する制約を定義するためのポリシーです。一定のルールを組織全体に適用することができます。しかし、シークレットの特定のリージョンへのレプリケーションを直接制約することはできません。
正解についての説明：
（選択肢）
・ユーザーが管理するレプリケーションポリシーでシークレットを作成し、準拠したロケーションのみを選択します
この選択肢が正解の理由は以下の通りです。
Secret Managerにはユーザー管理のレプリケーションポリシーがあります。これは、シークレットとそれらのレプリカが作成および保存されるリージョンを細かく指定することを可能にします。europe-west1とeurope-west4のような特定のリージョンにシークレットを制限したいときには、このレプリケーションポリシーを使用することで、シークレットのペイロードをそれらのリージョンにのみ持たせることができます。
また、この方法を使用すれば、これらのリージョン内でシークレットが高度に可用性を持つことを保証できます。というのも、シークレットとそれらのレプリカはそれぞれのリージョン内で自動的に複製され、冗長性が提供されます。それゆえ、特定のリージョンにデータの所在地を制限しつつ高可用性を確保するためには、ユーザーが管理するレプリケーションポリシーでシークレットを作成し、準拠したロケーションのみを選択するのが最適な方法となります。
不正解についての説明：
選択肢：自動レプリケーションポリシーでシークレットを作成し、準拠したロケーションのみを選択します
この選択肢が正しくない理由は以下の通りです。
自動レプリケーションポリシーを使用するとシークレットは全てのリージョンに自動的にレプリケートされるため、指定した"europe-west1"および"europe-west4"以外のリージョンにもペイロードが保存されてしまうため、この要件を満たすことができません。なお、ユーザーが管理するレプリケーションポリシーを使用すれば特定のリージョンのみを対象としたシークレットの作成が可能です。
選択肢：Terraformを使って2つのシークレットを作成し、1つはeurope-west1に、もう1つはeurope-west4に置きます
この選択肢が正しくない理由は以下の通りです。
Terraformを使って2つのシークレットを別々に作成すると、それらは独立したシークレットとなり、リージョン間の同期が自動的に行われません。そのため、一方のリージョンでシークレットが更新された場合、それが他のリージョンに反映されないため、高度に利用可能であるとは言えません。
一方、ユーザーが管理するレプリケーションポリシーでは、同一のシークレットが複数のリージョンにレプリケーションされ、必要なデータ所在地の要件を満たしながら高可用性を保てます。
選択肢：シークレットを自動複製ポリシーで作成し、コンプライアンスに準拠していない場所でのシークレット作成を拒否する組織ポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
シークレットを自動複製ポリシーで作成すると、Googleが管理するリージョンにデータが複製されますが、それはユーザーの要件である特定のリージョン（europe-west1とeurope-west4）に限定されません。
一方、ユーザーが管理するレプリケーションポリシーを使用すれば、シークレットを特定のリージョンにのみ保持することが可能です。
参考リンク：
https://cloud.google.com/secret-manager/docs/configuring-replication
https://cloud.google.com/secret-manager/docs/locations
https://www.terraform.io/docs/providers/google/r/secret_manager_secret.html
</div></details>

### Q.  問題27: 未回答
あなたは会社のインシデント対応計画を策定しています。Google Cloud環境におけるデプロイの問題をレビューし調査する際に、DevOpsチームが使用するアクセス戦略を定義する必要があります。主な要件は2つあります：
- 最小特権アクセスを常に強制します。
- DevOpsチームは、デプロイの問題が発生している間だけ、必要なリソースにアクセスできなければなりません。
Googleが推奨するベストプラクティスに従いつつ、どのようにアクセスを許可すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud環境でDevOpsチームがデプロイの問題を調査するためのアクセス戦略を定義する情境が設けられています。必要なのは、"最小特権"の原則に基づきつつ、問題発生時のみ必要なリソースへのアクセスを許可する戦略を策定することです。つまり、全面的なアクセスや不必要な特権を持たせる方法は避け、適切な範囲での権限管理が求められます。また、Googleのベストプラクティスを考慮に入れつつ、適切なIAM（Role-based access control）の設定を選ぶことが重要です。
基本的な概念や原則：
最小特権の原則：必要最小限の権限のみをユーザーやシステムに与えるというセキュリティの原則です。無駄な権限を与えることで生じるリスクを軽減します。
特権のエスカレーション：一時的に必要な権限を付与するための制御です。問題が発生した際に、必要な作業を行うためだけに一時的に権限を上げることがあります。
IAM（Identity and Access Management）：Google Cloudの認証と認可を管理するサービスです。ユーザーやサービスアカウントに対し、リソースへのアクセスをコントロールするロールを割り当てます。
IAMロール：Google Cloudのリソースへの特定の操作権限を集約したものです。プリデファインドロールとカスタムロールがあります。
カスタムIAMロール：必要な権限を独自に集約したIAMロールです。アクセスの粒度を細かく調整できます。
サービスアカウント：アプリケーションがGoogle Cloudリソースとやり取りするための特別なタイプのGoogleアカウントです。サービスアカウントはIAMの認証および認可の対象となります。
Project Viewer IAMロール：プロジェクト全体のリソースを閲覧可能なIAMロールです。一部の操作や書き込み権限などは制限されています。
正解についての説明：
（選択肢）
・リスト/ビュー権限を制限したカスタムIAMロールを作成し、DevOpsチームに割り当てます
この選択肢が正解の理由は以下の通りです。
最小特権アクセスとは、アクセス必要なリソースに対する権限のみをユーザーに付与することを指します。この考え方はセキュリティを強化し、要件を達成する上で非常に重要です。Google Cloudでは、この原則に基づきIAMのロールをカスタマイズすることができます。
したがって、デプロイの問題が発生しているときにのみ、限定的なリスト/ビュー権限をDevOpsチームに割り当てるカスタムIAMロールを作成すれば、要件達成に対して最適な戦略となります。ユーザーが必要なリソースにだけアクセスできるようにすることで、セキュリティリスクを最小限に抑えつつ作業の効率性を維持することが可能となります。
不正解についての説明：
選択肢：Project Viewer IAMロールをDevOpsチームに割り当てます
この選択肢が正しくない理由は以下の通りです。
Project Viewer IAMロールは、プロジェクト全体の閲覧権限を提供します。これは最小特権原則に反しており、DevOpsチームがデプロイの問題解決のために必要とする特定のリソースへのアクセスよりも広範な権限を付与することになります。
選択肢：サービスアカウントを作成し、Project Owner IAMロールを付与します。このサービスアカウントのService Account UserロールをDevOpsチームに与えます
この選択肢が正しくない理由は以下の通りです。
サービスアカウントへのProject Owner IAMロールの付与は、最小特権アクセスの原則に反するため不適切です。
また、DevOpsチームが必要なリソースにのみ限定的なアクセスを持つ設定ではありません。これに比べると、カスタムIAMロールは必要なリソースにピンポイントで制限された権限を設定する事が可能です。
選択肢：サービスアカウントを作成し、限定的なリスト/ビュー権限を付与します。このService Account UserロールをDevOpsチームに与えます
この選択肢が正しくない理由は以下の通りです。
サービスアカウントはアプリケーションに特化した認証の手段で、DevOpsチームのユーザーアクセス管理には適切ではありません。
また、DevOpsチームがサービスアカウントを使う場合、最小特権の原則の適用が難しくなります。
これに対し、IAMロールは特定の権限を持つユーザーに割り当て、調査やレビュー時に限定的なアクセスを提供することが可能です。
参考リンク：
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/iam/docs/creating-custom-roles
https://cloud.google.com/iam/docs/granting-changing-revoking-access
</div></details>

### Q.  問題28: 未回答
あなたはBigQueryの機密性の高いデータを保護する責任があります。業務チームはこのデータにアクセスする必要がありますが、プライバシー規制を考慮し、メールアドレスや名前などの機密フィールドを読み取れないようにしたいと考えています。これらの特定の機密フィールドは、人事チームのみが知る必要がある場合にのみ利用できるようにする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、BigQueryの機密性の高いデータを管理するプロセスを理解するための情報が必要となります。プライバシー規制と人事チームのみが必要とする情報へのアクセス制限の要件から、特定のフィールドに対する保護措置が必要であり、読み取りを制限しながらデータの使用を可能にする必要があります。これら要件から考えると、データを保護しつつ特定のユーザーのみがアクセス可能な方法を選択するという視点で進めるべきです。そこで、Google Cloudのサービスの中でデータの利用と保護を適切にバランスさせるものを選ぶことが重要となります。
基本的な概念や原則：
BigQuery：大量のデータを迅速に分析するためのGoogle Cloudのフルマネージドなビッグデータ分析サービスです。
Cloud Data Loss Prevention（DLP）API：データを検査し、削除、マスク、トークン化などの操作を介して機密情報を保護するGoogle Cloudのサービスです。
トークン化：元の情報とは別の一意の代替情報に置き換えることで、データの機密性を保護する手法です。トークン化したデータは、元の形式に戻すための適切な権限がなければ解読できません。
データマスキング：機密情報の一部または全体を遮蔽または変更することで、データの機密性を保護する手法です。データマスキングは一方向で、元の形式に戻すことはできません。
データの再編集：データを新しい形式に組み替えることで、個別の情報を匿名化し、機密情報を保護する手法です。
データ検査：データに含まれる機密情報を検出するプロセスです。DLP機能の一部として、機密データを見つけ、保護策を施すために使用されます。
正解についての説明：
（選択肢）
・Cloud Data Loss Prevention APIを使用して仮名化のためのトークン化を実行し、そのデータを後で使用するためにBigQueryに保存します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Data Loss Prevention（DLP）APIは、機密性の高い情報を自動的に検出、分類、そしてマスキングすることができるGoogle Cloudのサービスです。仮名化の一環としてトークン化を行うことにより、個々の機密フィールド（例えばメールアドレスや名前など）を元の値から識別不可能な値に置き換えることができます。こうすることで、業務チームが依然として必要なデータにアクセスしつつ、機密情報を保護することが可能となります。
さらに、必要となった場合にのみ人事チームが元の情報にアクセスできるようにするためには、DLP APIが生成したトークンと元のデータの対応関係を管理することが必要です。これにより、特定のユーザーがトークンを元のデータに逆変換する権限を与えることができます。
そして、そのデータをBigQueryに保存することで、すべてのデータは一箇所で管理され、アクセス制御と分析が容易になります。以上の理由から、この選択肢が最適な解決策といえます。
不正解についての説明：
選択肢：Cloud Data Loss Prevention APIを使用してデータマスキングを実行し、そのデータを後で使用できるようにBigQueryに保存します
この選択肢が正しくない理由は以下の通りです。
データマスキングはデータの一部を隠しますが、元の値を復元できる保証がないため、人事チームがのちにソースデータにアクセスする必要があるこのシナリオには適していません。それに比べて、トークン化は元の値の復元を可能にします。
選択肢：Cloud Data Loss Prevention APIを使用してデータの再編集を実行し、そのデータを後で使用できるようにBigQueryに保存します
この選択肢が正しくない理由は以下の通りです。
データの再編集は情報を無作為な値に置き換えますが、元の情報に戻すことはできません。しかし、要件では人事チームが元の情報にアクセスできる必要があるため、再編集ではなく仮名化のためのトークン化を行うべきです。
選択肢：Cloud Data Loss Prevention APIを使用してデータ検査を実行し、そのデータを後で使用できるようにBigQueryに保存します
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Prevention APIを使用してデータ検査を行うと、そのデータから機密情報を見つけてマークすることはできますが、仮名化のトークン化を行わないため、機密データを読み取れないようにする要件を満たすことはできません。
参考リンク：
https://cloud.google.com/dlp/docs/tokenization
https://cloud.google.com/bigquery/docs/column-level-security-intro
https://cloud.google.com/bigquery/docs/best-practices-security-controls
</div></details>

### Q.  問題29: 未回答
ある組織の典型的なネットワークとセキュリティのレビューは、アプリケーションのトランジットルート、リクエスト処理、ファイアウォールルールの分析で構成されています。開発チームは、このような完全なレビューのオーバーヘッドなしに新しいアプリケーションをデプロイできるようにしたいと考えています。
あなたはこの組織にどのように助言すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、開発チームがアプリケーションをデプロイする際にネットワークとセキュリティのレビューのオーバーヘッドを減らす方法について問われています。ここで重要なのは、選択肢が提示するソリューションがネットワークとセキュリティの管理をどの程度自動化し、レビューの負荷やエラーを減らすかです。また、開発チームの生産性と継続的なデリバリーを確保しながらも、セキュリティとコンプライアンスの要件を満たすソリューションを選ぶことが重要です。
基本的な概念や原則：
インフラストラクチャアズコード（IaC）：ソフトウェアのプロビジョニングと管理を自動化するための手法です。コードによりインフラストラクチャを定義・管理することで、開発とオペレーションズの間のギャップを埋めます。
CI/CDパイプライン：継続的インテグレーション（CI）と継続的デリバリ（CD）を組み合わせた開発プロセスです。新しいコードの変更を自動的にビルド、テスト、デプロイすることで、開発の効率とアプリケーションの信頼性を向上させます。
静的解析：プログラムが実行される前にコードを検査し、エラーや問題点を識別する手法です。CI/CDパイプライン内で適用されることが多く、問題を初期段階で検出・修正することを可能にします。
ポリシーの強制：組織のガバナンスやコンプライアンスポリシーを強制的に適用する手法です。IaCと組み合わせることで、自動化されたポリシー管理を実現します。
Forseti：Google Cloudの環境全体にわたるセキュリティポリシーとデータのガバナンスを管理するオープンソースツールです。
VPCトラフィック：Virtual Private Cloud（VPC）内でのネットワークトラフィックです。安全性を維持しながら、アプリケーション間での通信を可能にします。
正解についての説明：
（選択肢）
・Infrastructure as Codeの使用を義務付け、CI/CDパイプラインで静的解析を行い、ポリシーを実施します
この選択肢が正解の理由は以下の通りです。
まず、"Infrastructure as Code"の使用は開発チームによる新しいアプリケーションのデプロイを自動化し、そして確実に行うことを可能にします。比較的一貫した環境を提供し、手動操作によるエラーや誤解を軽減します。
次に、CI/CDパイプラインを用いて静的解析を行うことで、組織のネットワークとセキュリティのレビュープロセスを自動化することができます。このステップではコードのリクエスト処理、トランジットルート、ファイアウォールルールについて自動的に分析し、問題や欠陥を早期に発見して修正します。
最後に、ポリシーの実施により、Infrastructure as Codeのプロセスで定義された要件が適切に遵守され、セキュリティとその他の基準が維持されることを確認します。
以上の組み合わせによりこの選択肢が適切になります。開発チームが新しいアプリケーションを迅速かつ効率的にデプロイすることを可能にする一方で、組織のセキュリティとネットワークの基準を遵守します。
不正解についての説明：
選択肢：Forsetiとファイアウォールフィルターを併用することで、本番環境での不要なコンフィギュレーションを検出することができます
この選択肢が正しくない理由は以下の通りです。
Forsetiとファイアウォールフィルターの併用は不要なコンフィギュレーションを検出する一方で、新しいアプリケーションをデプロイするオーバーヘッドを軽減する効果は限定的です。
一方、Infrastructure as CodeをCI/CDパイプラインで静的解析するアプローチは、安全性を維持しつつ実装のオーバーヘッドを軽減します。
選択肢：すべてのVPCトラフィックを顧客が管理するルーター経由でルーティングし、本番環境における悪意のあるパターンを検出します
この選択肢が正しくない理由は以下の通りです。
すべてのVPCトラフィックを顧客が管理するルーター経由でルーティングすることは、セキュリティチェックを行うための一つの手段ではありますが、これだけでは新しいアプリケーションのデプロイのオーバーヘッドを解消しません。
それに対して、Infrastructure as CodeとCI/CDパイプラインの採用は、新しいアプリケーションのデプロイを自動化し、セキュリティチェックも自動で行うことができ、オーバーヘッドを大幅に削減します。
選択肢：本番アプリケーションはすべてオンプレミスで実行します。開発者はGoogle Cloudを開発およびQAプラットフォームとして自由に使えるようにします
この選択肢が正しくない理由は以下の通りです。
開発者がGoogle Cloudを開発およびQAプラットフォームとして自由に使えるようにするだけでは、ネットワークとセキュリティのレビューのオーバーヘッドを削減することはできません。ただし、Infrastructure as Codeを使用し、CI/CDパイプラインで静的解析を行うとポリシーを自動的に実施できるため、レビューのオーバーヘッドが削減できます。
参考リンク：
https://cloud.google.com/architecture/devops/devops-tech-infrastructure-as-code
https://cloud.google.com/security-command-center/docs/concepts-security-sources-forseti
https://cloud.google.com/vpc/docs/firewalls
</div></details>

### Q.  問題30: 未回答
組織のゼロトラスト戦略の一環として、Identity-Aware Proxy（IAP）を使用して複数のアプリケーションを保護しています。セキュリティ情報とイベント管理（SIEM）システムにログを取り込み、侵入の可能性を警告する必要があります。
どのログを分析すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ゼロトラスト戦略を実行するためのIdentity-Aware Proxy（IAP）と、侵入可能性を警告するためのセキュリティ情報とイベント管理（SIEM）システムのログの統合に焦点を当てています。正しいログを選択するためには、各ログが提供する情報とその目的について理解することが重要です。選択肢を検討する際には、侵入可能性を警告するために最も適したログとして、最も関連性の高いログを選ぶことが求められます。
基本的な概念や原則：
Identity-Aware Proxy（IAP）：Google Cloud上のアプリケーションとリソースへの安全なアクセスを提供するサービスです。VPNやファイアウォールの代わりに使用できます。
ゼロトラスト戦略：信頼とアクセスを前提とせず、すべてのユーザーとデバイスを潜在的に不安全とするセキュリティ戦略です。最小限の権限を与え、継続的な認証と承認を要求します。
データアクセス監査ログ：Google Cloudサービスが提供するデータを読み取ったり、書き込んだり、修正したりしたときに記録されるログです。セキュリティ上の脅威を監視するために使用されます。
SIEMシステム：セキュリティ情報とイベント管理を行うシステムです。セキュリティ関連のログとイベントを集約し、解析して警告を出すなどの機能を持ちます。
管理者の活動監査ログ：Google Cloudプロジェクトで管理者が行った操作を記録するログです。主に管理者周りの監視やトラブルシューティングに使用されます。
ポリシー拒否の監査ログ：ポリシーが適用されてアクションが拒否された場合に記録されるログです。不正なアクセスや操作を防ぐために使用されます。
Cloud Identityユーザーログイベント：Cloud Identityでのユーザーのログイベントを記録したものです。ユーザーベースの監視や分析に使用されます。
正解についての説明：
（選択肢）
・データアクセス監査ログ
この選択肢が正解の理由は以下の通りです。
Identity-Aware Proxy（IAP）は、Google Cloudリソースへのアクセスを制御するのに使われます。ユーザーまたはサービスがリソースにアクセスを試みたときに、IAPはそのアクセス試行を記録します。データアクセス監査ログは、これらのアクセス試行を詳細に捉える一方で、リソースへの読み取り、書き込み、更新操作も記録します。監査ログはリソースの変更などの重要なイベントをトラックし、異常行動や不適切なアクセスを特定するのに役立ちます。
したがって、SIEMシステムに取り込むために分析すべきログとして、データアクセス監査ログは有効で、侵入やその他のセキュリティ脅威の早期警告となる情報を提供します。これは、ゼロトラスト戦略を実装する上で極めて重要です。
不正解についての説明：
選択肢：ポリシー拒否の監査ログ
この選択肢が正しくない理由は以下の通りです。
ポリシー拒否の監査ログは、ある操作がGoogle CloudのIAMポリシーにより拒否された場合に生成されます。しかし、Identity-Aware Proxyの使用に関しては、データアクセス監査ログがもっと詳しい情報を提供します。これには認証や認可など、IAPの保護下にあるリソースへのアクセス試行に関する情報が含まれます。
選択肢：Cloud Identityユーザーログイベント
この選択肢が正しくない理由は以下の通りです。
Cloud Identityユーザーログイベントはユーザーの身元やログイン情報を追跡しますが、アプリケーションへのアクセスや侵入の可能性に関する直接的な情報は含まれません。
それに対して、データアクセス監査ログはユーザーやサービスがGoogle Cloudのデータにどのようにアクセスしたかの詳細な記録を提供し、侵入の検知に役立ちます。
選択肢：管理者の活動監査ログ
この選択肢が正しくない理由は以下の通りです。
管理者の活動監査ログは、Google Cloud上の管理者によるリソース操作などの活動を記録しますが、IAPを通じたアクセス情報は詳細に記録されません。
それに対して、データアクセス監査ログはIAPによるデータへのアクセスを詳細に記録するため、侵入の可能性を警告するのに必要なログを提供します。
参考リンク：
https://cloud.google.com/iap/docs/audit-log-howto
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/security-command-center/docs/how-to-use-security-sources#logging
</div></details>

### Q.  問題31: 未回答
脆弱性に対するパッチがリリースされ、DevOpsチームはGoogle Kubernetes Engine（GKE）で実行中のコンテナをアップデートする必要があります。
DevOpsチームはどのようにこれを達成すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、パッチのリリース後にGoogle Kubernetes Engine（GKE）で実行中のコンテナをアップデートするための最適な方法を尋ねています。ここで重要なのは、コンテナテクノロジーの原則とプラクティス、特にイミュータブルなインフラストラクチャの概念への理解です。実行中のコンテナに直接パッチを適用するのではなく、新しいコンテナイメージを構築してデプロイする適切な方法を探る必要があります。
基本的な概念や原則：
コンテナイメージ：アプリケーションとその依存関係をパッケージ化し、ランタイム環境を抽象化するための可搬性のあるエンティティです。これは更新やパッチを適用するために再構築され得ます。
Google Kubernetes Engine（GKE）：Google Cloud上でコンテナ化されたアプリケーションを実行するためのマネージド、収縮可能な環境の提供サービスです。
再デプロイ：新しいバージョンのアプリケーションまたはパッチの適用後に、アプリケーションまたはサービスを実行環境に戻す手続きです。
DevOps：開発と運用部門の間で効率的に協力して作業を進めるための哲学及びプラクティスです。"Dev"はソフトウェア開発、"Ops"はIT運用を表します。
Puppet、Chef：ITインフラストラクチャの自動化と管理を補助するツールです。ハードウェア構成やアプリケーション設定などの監視及び自動化に役立ちますしかし、実行中のコンテナにパッチをプッシュするのは推奨されません。
Container Registry：Dockerイメージのプライベートストレージとデリバリーサービスです。安全にイメージを保存、管理、デプロイできます。
正解についての説明：
（選択肢）
・アプリケーションコードを更新するかパッチを適用して、新しいイメージを構築し、再デプロイします
この選択肢が正解の理由は以下の通りです。
Google Kubernetes Engine（GKE）で運用するコンテナイメージは不変であり、直接更新またはパッチ適用を行うことは原則として行われません。その代わり、アプリケーションコードを更新したりパッチを適用したりした上で新しいイメージを構築することで、その修正を反映します。新しいイメージが構築されれば、それを基にコンテナを再デプロイすることで継続的にサービスを提供しながら更新が行われます。
これは、不変のインフラストラクチャの原則に基づくもので、一旦デプロイされたインフラストラクチャは変更せず、必要な変更がある場合は新たに構築するという考え方です。これにより、システムの信頼性を保ちつつ、脆弱性への対応や改善を迅速に行うことが可能となります。
不正解についての説明：
選択肢：PuppetまたはChefを使って、実行中のコンテナにパッチをプッシュします
この選択肢が正しくない理由は以下の通りです。
PuppetやChefは主にVMなどの伝統的なサーバ管理用のツールであり、コンテナのパッチ適用には適しません。正解の選択肢はイメージを更新して再デプロイすることで、これがコンテナの最善のパッチ適用手段です。
選択肢：自動アップグレードが有効になっていることを確認します。有効になっている場合、GoogleはGKEクラスター内のノードをアップグレードします
この選択肢が正しくない理由は以下の通りです。
自動アップグレードが有効になっていると、GKEクラスターのノードはGoogleによって更新されますが、これはノードのOSやKubernetes自体のアップデートを指します。アプリケーション内のコードやパッチの適用は含まれていません。そのため、新しいイメージを作成して再デプロイする必要があります。
選択肢：Container Registryでベースイメージが利用可能になったときに、自動的にアップグレードするようにコンテナを設定します
この選択肢が正しくない理由は以下の通りです。
Container Registryでベースイメージが利用可能になったときに自動的にアップグレードする設定は存在しません。実際には、アプリケーションコードを更新するかパッチを適用して新しいイメージを構築し、再デプロイする必要があります。これにより、安全な最新版のコンテナイメージに更新することが可能です。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps
https://cloud.google.com/kubernetes-engine/docs/concepts/node-auto-upgrades
https://cloud.google.com/container-registry/docs/managing-images
</div></details>

### Q.  問題32: 未回答
あなたは、Secret Managerに保存されている組織の秘密の新しいガバナンスモデルを設計しています。現在、本番用アプリケーションと非本番用アプリケーションのシークレットは、サービスアカウントを使用して保存され、アクセスされています。提案されたソリューションの要件は以下のとおりです。
- シークレットへのきめ細かなアクセス
- シークレットをラップする暗号化キーのローテーションスケジュールを制御できること
- 環境の分離を維持すること
- 管理を容易にすること
要件を満たすために、どのアプローチを取るべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudのSecret Managerを使用して、本番環境と非本番環境のシークレットのガバナンスモデルを設計する必要があります。制御できる暗号化キーのローテーション、環境の分離、管理の容易さを必要とするため、これらの要件を満たす要素を含む最適なアプローチを選択することが重要です。シークレットのアクセス制御と暗号化に関し、Identity and Access Management（IAM）、Google Cloudプロジェクト、暗号化キーの管理方法など、各要素のロールと機能の理解を期待されています。
基本的な概念や原則：
Secret Manager：シークレットの管理とアクセスを制御するGoogle Cloudのツールです。信頼性、スケーラビリティ、セキュリティを提供し、秘密データの暗号化と保管を行います。
Google Cloudプロジェクト：Google Cloudのリソースを組織化、管理するためのユニットです。プロジェクトは使用量の追跡、API利用の制御、アクセス許可など、リソースに対する全体的な設定を提供します。
Identity and Access Management（IAM）：Google Cloud環境へのアクセスを制御するツールです。指定したロールやポリシーに基づいて、特定のユーザーが行える操作を精密に定義します。
顧客管理の暗号化キー：キーの生成、保存、管理をユーザーが行う方式です。暗号化キーのライフサイクルを完全に制御でき、より高度なセキュリティ要件を満たします。
正解についての説明：
（選択肢）
・1.本番用と非本番用のシークレットを保存するために、別々のGoogle Cloudプロジェクトを使用します
2.プロジェクトレベルのIdentity and Access Management（IAM）バインディングを使用して、シークレットへのアクセス制御を実施します
3.顧客管理の暗号化キーを使用して秘密を暗号化します
この選択肢が正解の理由は以下の通りです。
まず、要件は環境の分離と管理の容易さを求めています。別々のGoogle Cloudプロジェクトを使用することで、本番用と非本番用のシークレットを物理的に分離し、これを制御することが可能になります。複数のプロジェクトを使用することで、それぞれの環境のリソースが互いに混在することがなくなり、管理が容易になります。
次に、プロジェクトレベルのIAMバインディングを使用することで、シークレットへのきめ細かなアクセス制御を実施することが可能です。特定のユーザーやサービスアカウントが本番用または非本番用のシークレットにどの程度アクセスできるかを細かく制御でき、シークレットのガバナンス強化に寄与します。
最後に、顧客管理の暗号化キーを使用して秘密を暗号化することで、シークレットをラップする暗号化キーのローテーションスケジュールを制御する手段を持つことができます。Googleがシークレット用のデフォルト暗号化キーを提供していますが、要件は独自のキーを制御できることを求めているため、提供された選択肢は要件を満たしています。
不正解についての説明：
選択肢：1.単一のGoogle Cloudプロジェクトを使用して、本番環境と非本番環境の両方のシークレットを保存します
2.シークレットレベルのIdentity and Access Management（IAM）バインディングを使用して、シークレットへのアクセス制御を実施します
3.Googleが管理する暗号化キーを使用して、シークレットを暗号化します
この選択肢が正しくない理由は以下の通りです。
単一のGoogle Cloudプロジェクトで本番環境と非本番環境のシークレットを保存すると、環境の分離要件が満たされません。
また、Googleが管理する暗号化キーを使用すると、秘密の暗号化キーのローテーションスケジュールを制御する能力が失われます。
これに対し、別々のプロジェクトと顧客管理暗号化キーを使用する正解選択肢はこれらの要件を満たします。
選択肢：1.本番用と非本番用のシークレットを保存するために、別々のGoogle Cloudプロジェクトを使用します
2.シークレットレベルのIdentity and Access Management（IAM）バインディングを使用して、シークレットへのアクセス制御を実施します
3.シークレットの暗号化には、Googleが管理する暗号化キーを使用します
この選択肢が正しくない理由は以下の通りです。
まず、シークレットレベルのIdentity and Access Management（IAM）バインディングはSecret Managerでは対応していません。提供されるのはプロジェクトレベルのIAMバインディングのみです。
また、要件にはシークレットをラップする暗号化キーのローテーションスケジュールを制御できることが含まれていますが、Googleが管理する暗号化キーはユーザーが直接制御できないため、この選択肢は要件を満たさないです。
選択肢：1.単一のGoogle Cloudプロジェクトを使用して、本番環境と非本番環境の両方のシークレットを保存します
2.プロジェクトレベルのIdentity and Access Management（IAM）バインディングを使用して、シークレットへのアクセス制御を実施します
3.顧客管理の暗号化キーを使用して秘密を暗号化します
この選択肢が正しくない理由は以下の通りです。
この選択肢では、本番と非本番のシークレットが同じプロジェクトに保存されているため、環境の分離が保たれていません。
それに対して、正解では本番と非本番のシークレットを別々のプロジェクトに保存することで、環境の分離を適切に行っています。
参考リンク：
https://cloud.google.com/secret-manager/docs
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://cloud.google.com/kms/docs/secret-management
</div></details>

### Q.  問題33: 未回答
あなたの組織は、CIS Google Cloud Computing Foundations Benchmark v1.3.0（CIS Google Cloud Foundation 1.3）に対して継続的に評価されることを望んでいます。コントロールの中には、組織と無関係なものもあり、評価の際に無視しなければなりません。関連するコントロールのみが評価されるように、自動化されたシステムまたはプロセスを作成する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、組織がCIS Google Cloud Computing Foundations Benchmarkに対して継続的に評価されることを望んでおり、その過程で無関係な評価を無視するような自動化システムを作成する方法を探しています。重要なことは、適切なGoogle Cloudのセキュリティツールを選択すること、そしてそれをどのように設定するかです。特定のツールが提供している機能を理解し、それらが組織のセキュリティ要件にどのように適合するかを検討することが必要です。これにより、適切な自動化プロセスを確立し、規範に準拠しつつ無関係なコントロールを無視することが可能になります。
基本的な概念や原則：
CIS Google Cloud Computing Foundations Benchmark：CIS（Center for Internet Security）によって提供される、Google Cloudのセキュリティ基準のセットです。これは、Google Cloudのセキュリティ設定を評価・強化するための最善の手法を提供します。
Security Command Center（SCC）：Google Cloudの統合されたリスク報告ダッシュボードで、Google Cloudの資産とデータを保護するための洞察とデータを提供します。セキュリティ調査結果をミュート（無視）することも可能です。
セキュリティ例外：セキュリティの評価プロセスで、特定の条件下で許可されるセキュリティルールの違反を指します。セキュリティ例外を適切にマークし、管理することは、全体的なセキュリティガバナンスの一部です。
CSVファイル：データを表形式で保存するためのプレーンテキスト形式の一種です。セキュリティ調査結果をエクスポートする際に用いられます。
外部監査：独立した第三者が組織のプロセス、システム、操作を審査し、その結果を報告することです。これにより、組織は潜在的なリスクを特定し、必要な改善を行うことができます。
正解についての説明：
（選択肢）
・Security Command Center（SCC）Premiumをアクティベートします。SCCでセキュリティ調査結果をミュートするルールを作成し、評価されないようにします
この選択肢が正解の理由は以下の通りです。
まず、Security Command Center（SCC）Premiumは、Google Cloudの脆弱性と脅威を継続的に表示し、分析するためのセキュリティ管理プラットフォームです。SCC Premiumの特徴の一つは、CIS Google Cloud Foundationの基準に対する修正可能なコントロールの評価を自動化する機能です。逆に言えば、これにより継続的な評価が可能となります。
また、SCCでは"ミュートのルール"を作成することが可能で、これにより特定のセキュリティ調査結果を評価から除外することができます。つまり、組織と無関係なコントロールを評価対象から除外する要件も満たされます。
このように、SCC Premiumをアクティベートし、ミュートのルールを作ることで、自動化されたシステムが関連するコントロールだけを評価し、無関係なものは評価から除外するという要件を満たすことが可能となります。
不正解についての説明：
選択肢：無関係なすべてのセキュリティ所見に、セキュリティ例外を示すタグと値をマークします。マークされた調査結果をすべて選択し、表示されるたびにコンソール上でミュートします。Security Command Center（SCC）Premiumをアクティブ化します
この選択肢が正しくない理由は以下の通りです。
Security Command Center（SCC）を使うのは適切ですが、組織が継続的に評価されることを望むため、その都度コンソール上で手動でミュートするという方法は効率的ではありません。自動化されたプロセスを作成するためには、SCCでミュートするルールを設定することが必要です。
選択肢：Security Command Center（SCC）からすべての調査結果をCSVファイルにダウンロードします。ファイル内のCIS Google Cloud Foundation 1.3の一部である調査結果をマークします。関連性がなく、会社のスコープ外のエントリは無視します
この選択肢が正しくない理由は以下の通りです。
CSVファイルへのダウンロードを用いた方法は、適切なセキュリティ調査結果の除外が自動化されていないため不適切です。自動化されたシステムやプロセスを求められる問題文の要求に対して、この手法は手動での作業が必要となります。
一方、SCC Premiumを用いる正解の選択肢では評価結果をミュートするルールを作成することで自動化が実現でき、問題文の要求を正確に満たしています。
選択肢：外部監査会社に、必要なCISベンチマークを含む独立した報告書の提出を依頼します。監査範囲において、一部の管理は不要であり、無視しなければならないことを明確にします
この選択肢が正しくない理由は以下の通りです。
外部監査会社に依頼することは自動化されたシステムまたはプロセスの作成とは言えず、自動化要件を満たしません。
また、この方法では継続的な評価が難しく、評価が関連するコントロールのみに限定される保証もありません。
それに対して、Security Command Centerでは、必要なベンチマークを自動化して継続的に評価し、特定の調査結果をミュートすることで、関連しない管理を排除することが可能です。
参考リンク：
https://cloud.google.com/security-command-center/docs/how-to-use-mute-findings
https://cloud.google.com/security-command-center/docs/concepts-security-command-center-overview
https://www.cisecurity.org/benchmark/google_cloud_computing_platform/
</div></details>

### Q.  問題34: 未回答
Google Cloudフットプリントのネットワークセグメンテーションを監査する必要があります。現在、本番環境と非本番環境のIaaS（Infrastructure-as-a-Service）環境を運用しています。すべてのVMインスタンスは、サービスアカウントをカスタマイズせずにデプロイされています。
カスタムネットワークのトラフィックを観察した結果、トラフィックを適切にセグメント化するためにタグベースのVPCファイアウォールルールが設定されているにもかかわらず、すべてのインスタンスが優先度1000で自由に通信できることに気づきました。この動作の最も考えられる理由は何ですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud環境におけるネットワークセグメンテーションの監査について考えます。異なる環境の仮想マシンが自由に通信できる、という状況が説明されています。問題のポイントは、VPCファイアウォールルールとネットワークタグの関係、そしてそれらの優先度について理解することです。VPCファイアウォールのルールは優先度に従って適用され、どのルールがどの仮想マシンに適用されるかを特定するためにネットワークタグが使用されることを鑑みると、問題を解くための解答選択肢を探す際に注意を払うべきポイントはこの二つです。
基本的な概念や原則：
ネットワークセグメンテーション：ネットワークトラフィックを異なる部分やセグメントに分割するセキュリティ戦略です。これにより、不正アクセスを防いだり、ネットワークの性能を向上させることができます。
サービスアカウント：Google Cloud上のアプリケーションに対して特定のロールや権限を付与するためのアカウントです。これにより、アプリケーションがGoogle Cloudのサービスに対して認証や認可を行うことができます。
タグベースのVPCファイアウォールルール：ネットワーク内のリソースにタグを付け、そのタグに基づいてファイアウォールルールを適用する方法です。これにより、ネットワークのセキュリティポリシーを柔軟に管理することができます。
VPC（Virtual Private Cloud）：Google Cloudの仮想プライベートネットワークサービスです。クラウド上でプライベートネットワーク環境を作成し、そのネットワーク内にあるリソース間の通信を管理することができます。
ファイアウォールルールの優先度：Google Cloud VPCでは、複数のファイアウォールルールがある場合、優先度の高いルール（数値が小さいほど高い）が先に適用されます。優先度が同じ場合、許可ルールが拒否ルールよりも先に適用されます。
正解についての説明：
（選択肢）
・すべてのVMインスタンスにそれぞれのネットワークタグがありません
・VPCファイアウォールルールが、同じサービスアカウントに基づくソース/ターゲット間のトラフィックを優先度999で許可しています
この選択肢が正解の理由は以下の通りです。
まず、"すべてのVMインスタンスにそれぞれのネットワークタグがありません"が重要です。たとえタグベースのVPCファイアウォールルールが設定されていても、それらのタグがVMインスタンスに適用されていなければ、それらのルールは機能しません。結果として、全てのVMインスタンスが自由に通信できてしまいます。つまり、各VMインスタンスに適切なネットワークタグを適用することが、トラフィックを適切にセグメント化するための必須要件となります。
次に、"VPCファイアウォールルールが、同じサービスアカウントに基づくソース/ターゲット間のトラフィックを優先度999で許可しています"も可能性のある問題です。確かに、すべてのVMインスタンスが同一のサービスアカウントでデプロイされていると、これらのインスタンス間のトラフィックは、同じサービスアカウントに基づくファイアウォールルールによって許可されます。このルールが優先度999で設定されていると、他の優先度1000のルールよりも優先され、これがすべてのインスタンスが自由に通信できる理由となります。
不正解についての説明：
選択肢：すべてのVMインスタンスは同じネットワークサブネットに存在します
この選択肢が正しくない理由は以下の通りです。
VMインスタンスが同じサブネットに存在していても、ファイアウォールルールが適用されるため、全てのインスタンスが自由に通信できるわけではありません。この選択肢は問題の事象と関連性が低く、正解の選択肢に比べて現象を説明する適切な理由とはなりません。
選択肢：すべてのVMインスタンスは同じネットワークルートで構成されています
この選択肢が正しくない理由は以下の通りです。
ネットワークルートは特定のIP範囲（または宛先）に向かうトラフィックの経路を決定しますが、トラフィックの許可や拒否、制御はVPCファイアウォールルールが担います。そのため同じネットワークルートを持つインスタンスでも、通信制限はファイアウォールルールにより異なります。
選択肢：VPCファイアウォールルールが、同じサービスアカウントに基づくソース/ターゲット間のトラフィックを優先度1001で許可しています
この選択肢が正しくない理由は以下の通りです。
VPCファイアウォールルールの優先度は数値が低いほど高くなります。つまり、優先度1000のルールよりも優先度1001のルールの方が優先度は低くなります。ですから、優先度1001のルールが設定されていても、すべてのインスタンスが自由に通信できるという状況を説明することはできません。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/vpc/docs/using-firewalls
https://cloud.google.com/vpc/docs/vpc-networks-and-firewalls#priority
</div></details>

### Q.  問題35: 未回答
ある企業がCompute Engine上でアプリケーションを実行しています。このアプリケーションにバグがあり、悪意のあるユーザーがスクリプトを繰り返し実行し、その結果、Compute Engineのインスタンスがクラッシュしてしまいました。バグは修正されましたが、このハッキングが再発した場合に備えて通知を受け取りたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、悪意のあるユーザーによって引き起こされる潜在的なハッキングを監視し、それに関する通知を受け取ることに焦点を当てています。アプリケーションがCompute Engine上で実行され、過去にバグによりインスタンスがクラッシュしたという事実が重要です。また、バグ自体は修正されたが、再発に備えて通知が必要だとの要件も考慮する必要があります。Google Cloud Operation Suite、Cloud Logging、BigQueryの各機能をどのように利用すればハッキングの再発を検知できるかを理解することが重要です。さらに、シナリオは悪意のあるユーザーのスクリプトの繰り返し実行を特定するための適切な監視と通知策を見つけることに集中しています。
基本的な概念や原則：
Google Cloud Operation Suite：Google Cloudのパフォーマンスと健全性を監視、診断、アラート設定、操作の最適化、分析、表示を行うための統合管理ツールです。
アラートポリシー：異常な事態や重要な状況が発生した際に、指定した通知チャンネルから通知を受け取るための設定です。
プロセスの健全性条件：システムやアプリケーションの健全性を監視するための条件設定です。異常値や閾値を指定して、標準外の状態やクラッシュを検知します。
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションやシステムから生成されるログデータを一元的に管理し、分析と監視を行います。
メトリクス：パフォーマンスや利用状況を測定、トラッキングするための指標です。Google Cloudでは、メトリクスに基づいて監視やアラート設定を行うことが可能です。
BigQuery：Google Cloudのフルマネージド型、サーバーレス型の大規模なデータウェアハウスサービスです。大量のデータのクエリ実行を高速かつ柔軟に行うことが可能です。
ログシンク：Google CloudのLoggingで使用され、ログエントリをエクスポートするための機能です。シンクは特定の種類のログを指定したCloud Storage、BigQuery、Pub/Subへエクスポートします。
正解についての説明：
（選択肢）
・プロセスの健全性条件を使用して、Google Cloud Operation Suiteでアラートポリシーを作成し、スクリプトの実行回数が必要な閾値未満であることを確認します。通知を有効にします
この選択肢が正解の理由は以下の通りです。
Google Cloudのオペレーションスイートは、ログ監視、エラーレポート、アラートポリシーなど、一連の監視ツールを提供しています。アラートポリシーは特定の条件が満たされたときに通知を行う仕組みであり、これを使用してスクリプトの繰り返し実行や、その結果となるCompute Engineのインスタンスのクラッシュのような異常状態を検知し、事前に対策を立てることが可能になります。健全性条件を設定すれば、特定のプロセスや動作の状態を監視する事ができ、予期しない繰り返し実行が始まった際にすぐに検知し、通知を受け取ることができます。これにより、同様のハッキングが再発した場合も早期発見し迅速に対応することができます。
不正解についての説明：
選択肢：Google Cloud Operation Suiteで、CPU使用率メトリクスを使用してアラートポリシーを作成します。閾値を80%に設定し、CPU使用率がこの80%を超えた場合に通知されるようにします
この選択肢が正しくない理由は以下の通りです。
CPU使用率の高さは、アプリケーションに問題があることを必ずしも示しません。CPU使用率が80％を超えることは、アプリケーションが活発に動作しているだけかもしれません。ここでは特定のスクリプトの実行回数によるクラッシュを検知することが求められており、そのためにはプロセスの健全性条件を用いてアラートポリシーを作成する方が適しています。
選択肢：Cloud Loggingにスクリプトのすべての実行をログします。Cloud Loggingでログにユーザー定義のメトリックを作成し、メトリックを表示するGoogle Cloud Operation SuiteDashboardを作成します
この選択肢が正しくない理由は以下の通りです。
ダッシュボードはリアルタイムの監視に役立ちますが、特定の不正行為が再発した際の自動的な通知の提供はできません。通知を得るためにはCloud Operation Suiteのアラートポリシーが必要です。
選択肢：スクリプトの実行ごとにCloud Loggingにログを記録します。BigQueryをログシンクとして設定し、特定の時間枠内の実行回数をカウントするBigQueryスケジュールクエリを作成します
この選択肢が正しくない理由は以下の通りです。
BigQueryでログの解析を行うのは時間がかかり、クラッシュが起きてからの対応になってしまいます。対照的にGoogle Cloud Operation Suiteを使用すると、異常な状態が発生した瞬間に通知を受け取ることが可能なため、事前に問題を検知し対応することができます。
参考リンク：
https://cloud.google.com/monitoring/alerts/using-alerting-policies
https://cloud.google.com/logging/docs/logs-based-metrics
https://cloud.google.com/logging/docs/export/bigquery
</div></details>

### Q.  問題36: 未回答
Cloud Run上でアプリケーションを実行しています。脆弱性スキャンのためにコンテナ分析をすでに有効にしています。しかし、デプロイされるアプリケーションを制御できないことを懸念しています。信頼できるコンテナイメージのみがCloud Run上にデプロイされるようにしなければなりません。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Run上で稼働するアプリケーションが信頼できるコンテナイメージのみを使用するように保証する方法が求められています。この問題の特徴として、複数の方策が存在する可能性と、各方策がどのように組織やシステム全体に影響を及ぼすかを考慮する必要があります。特に、バイナリ認証の概念を理解し、それがどのようにCloud Runやプロジェクト全体に影響を与えるかをよく把握することが必要です。それらを考慮して各選択肢を評価することで、最適な解答を見つけることができます。
基本的な概念や原則：
Cloud Run：Google Cloudのフルマネージドな実行環境で、コンテナベースのアプリケーションをサーバーレス環境で実行します。インフラストラクチャの管理を必要とせず、要求に応じて自動的にスケーリングします。
コンテナ分析：Google Cloudのサービスで、コンテナイメージの脆弱性を解析します。このサービスにより、開発者はコンテナイメージのセキュリティ情報を見つけ、理解、対応することができます。
バイナリ認証：Google Cloudのセキュリティ機能で、特定のソースからのみコンテナイメージをデプロイするためのポリシーを適用します。
組織ポリシー制約：Google Cloudの機能で、組織全体に対する規則や制約を設定します。これにより、特定のリソースの使用を制限したり、特定の機能の許可を管理したりできます。
Kubernetesクラスター：Kubernetesはコンテナ化されたアプリケーションのデプロイ、スケーリング、運用を自動化するオープンソースのプラットフォームです。クラスターは、コンテナアプリケーションを実行するための複数のノードから成るリソース群です。
Cloud Run breakglass：バイナリ認証に関する例外を設定するGoogle Cloudの機能です。正式なバイナリ認証に従うのではなく、イメージをデプロイする際の緊急措置として利用されます。
正解についての説明：
（選択肢）
・既存のCloud Runサービスでバイナリ認証を有効にします
・組織ポリシー制約constraints/compute.trustedImageProjectsを、信頼されたコンテナイメージを含むプロジェクトのリストに設定します
この2つの選択肢が正解の理由は以下の通りです。
まず、"既存のCloud Runサービスでバイナリ認証を有効にする"選択肢が優れている理由は、バイナリ認証を通じてGoogle Cloud上でデプロイされるコンテナイメージが信頼できるものであることを確認できるからです。バイナリ認証は、信頼できるデジタル署名が付いているイメージのみがデプロイされるようにする機能で、これにより不正や破損したイメージがシステム上で実行されるリスクが減少します。
次に、"組織ポリシー制約constraints/compute.trustedImageProjectsを、信頼されたコンテナイメージを含むプロジェクトのリストに設定する"選択肢が優れている理由は、この制約を使用することで組織レベルで信頼できるコンテナイメージの源を制御できるからです。これにより、Cloud Run上でデプロイするイメージが信頼できるプロジェクトからのものであることを保証できます。
この2つの選択肢を合わせることで、より強固なアプリケーションのデプロイ制御を実現できます。
不正解についての説明：
選択肢：組織ポリシー制約constraints/run.allowedBinaryAuthorizationPoliciesを、許可されるバイナリ認証ポリシー名のリストに設定します
この選択肢が正しくない理由は以下の通りです。
答えになっている選択肢は実際のGoogle Cloudの組織ポリシーに存在しますが、不正解の選択肢は存在しない組織ポリシー制約を端的に指定しています。
従って、そのようなポリシーを設定することは不可能となります。
選択肢：既存のKubernetesクラスターでバイナリ認証を有効にします
この選択肢が正しくない理由は以下の通りです。
問題文ではCloud Run上でアプリケーションが実行されているので、Kubernetesクラスターでのバイナリ認証は関連がありませんし、それによってCloud Runのコンテナイメージの信頼性を保証することはできません。
選択肢：Cloud Run breakglassを使用して、デフォルトでバイナリ認証ポリシーを満たすイメージをデプロイします
この選択肢が正しくない理由は以下の通りです。
Cloud Run breakglassはGoogle Cloudのサービスではないため、効果的なコンテナイメージ管理方法とは言えません。既存のCloud Runサービスでバイナリ認証を有効にし、組織ポリシー制約を設定する方が効果的です。
参考リンク：
https://cloud.google.com/binary-authorization/docs/using-binary-authorization
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/run/docs/configuring/container-images
</div></details>

### Q.  問題37: 未回答
あなたは会社のセキュリティ管理者です。Cloud Storageのバケットに3,000のオブジェクトがあります。あなたは各オブジェクトへのアクセスを個別に管理したくありません。
また、オブジェクトのアップロード者が常にオブジェクトを完全にコントロールできるようにしたくありません。しかし、Cloud Audit Logsを使ってバケットへのアクセスを管理したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud Storageのアクセス管理とオブジェクトのコントロールに関する要件を理解することが求められています。3000のオブジェクトを個別に管理したくなく、またアップローダが全てのオブジェクトを完全にコントロールすることを避けたいとの要件から、ユーザーアクセス管理（IAM）とバケットレベルのアクセス制御に的を絞って考えるべきです。さらに、Cloud Audit Logsを使ってバケットへのアクセスを追跡したいという点からも、IAMと組み合わせた管理策を探す方向が適切でしょう。
基本的な概念や原則：
統一アクセス：Google Cloud Storageのバケット内の全オブジェクトに対して一貫したアクセス制御を行うための機能です。個々のオブジェクトのアクセス権限を個別に管理せず、バケット全体として一括して管理します。
IAM：Google CloudのIdentity and Access Management（IAM）サービスです。ロールの割り当てを通じて、ユーザーやサービスアカウントへのリソースへのアクセスを制御します。
Cloud Audit Logs：Google Cloudのサービスが生成するログです。クレジットカードのトランザクションログのように、Cloudサービスの活動を記録します。
Access Control Lists（ACL）：ネットワーク、ファイル、その他のリソースへのアクセスを制御するための方法です。これはオブジェクトレベルでのアクセス制御を可能にします。ただし、このケースでは、ACLは推奨されない方法です。
allUsers：Cloud Storageで使用される特殊なエンティティで、オブジェクトまたはバケットに対するパブリックアクセスを許可します。このケースでは、allUsersに権限を設定すると、全てのユーザーがアクセスすることが可能になります。
正解についての説明：
（選択肢）
・Cloud Storageのバケットにバケットレベルの統一アクセスを設定し、IAMを使ってユーザーのアクセスを管理します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Storageのバケットレベルのアクセス制御を使用すると、3000のオブジェクトそれぞれに個別のアクセス管理を行う必要がなくなり、大量のオブジェクトに対する一元的なアクセス制御が可能になります。これにより、大量のオブジェクトに対する一括管理が容易になります。
また、バケットレベルのアクセス制御を設定すれば、オブジェクトのアップロード者がオブジェクトを完全にコントロールすることは防げます。なぜなら、オブジェクトレベルでのアクセス制御ではなく、バケット全体に対するアクセス制御になるからです。
さらに、IAMを利用しユーザのアクセスを管理すれば、Cloud Audit Logsでアクセス履歴をトラッキングし管理することができます。
したがって、この選択肢が正解となります。
不正解についての説明：
選択肢：allUsersのスコープにOWNER権限を持つACLを設定します
この選択肢が正しくない理由は以下の通りです。
allUsersのスコープにOWNER権限を持つACLを設定すると全てのユーザーがオブジェクトを完全にコントロールできるようになり、オブジェクトのアップロード者がオブジェクトを完全にコントロールすることを防げません。
これに対し、正解の選択肢はIAMを使ってユーザーのアクセスを管理し、バケットレベルの統一アクセスを設定することで要件を満たします。
選択肢：allUsersのスコープにREADER権限を持つACLを設定します
この選択肢が正しくない理由は以下の通りです。
allUsersのスコープにREADER権限を持つACLを設定すると、全てのユーザーがオブジェクトに対して読取りアクセス権を持つことになるため、個別のアクセス制御ができません。
逆に、統一アクセス管理をバケットレベルで設定すれば個別に管理する必要なく安全にアクセスを制御できます。
選択肢：デフォルトのバケットACLを設定し、IAMを使ってユーザーのアクセスを管理します
この選択肢が正しくない理由は以下の通りです。
デフォルトのバケットACLを設定しても、オブジェクトのアップロード者がオブジェクトを完全にコントロールできる状況を改善できません。セキュリティ面を考慮すると、正解の選択肢であるバケットレベルの統一アクセス設定が適しています。これにより、オブジェクトへの個別のアクセス設定を管理する手間を省くとともに、アップロード者のオブジェクトに対する全面的なコントロールを防ぐことができます。
参考リンク：
https://cloud.google.com/storage/docs/uniform-bucket-level-access
https://cloud.google.com/iam/docs/overview
https://cloud.google.com/logging/docs/audit
</div></details>

### Q.  問題38: 未回答
あなたは、一般データ保護規則（GDPR）に準拠したいと考えています。DevOpsチームがヨーロッパリージョンでのみGoogle Cloudリソースを作成できるようにしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudリソースのリージョナルな制限に関して理解が必要となります。具体的には、DevOpsチームがヨーロッパリージョンのみでリソースを作成できるように制限する方法を選択します。言い換えれば、正しい解答を見つけるためには、Google Cloudのリージョン制限方法、特に組織ポリシーに関する知識が必要となります。また、一般データ保護規則（GDPR）の要件に対する考慮も必然と関わってきます。
基本的な概念や原則：
GDPR（General Data Protection Regulation）：EUのデータ保護法規。EU内のすべての個人データのプライバシーと保護を規定しています。
組織ポリシー：特定のリソースの使用を制御するための、Google Cloudのプレビルトルールです。組織全体で一貫した制御を適用することが可能です。
"Google Cloud - Resource Location Restriction"制約：リソースの地理的ロケーションを制限するための組織ポリシー。特定のリージョンまたはゾーンでのみリソースの作成を許可することが可能です。
Identity-Aware Proxy（IAP）：Google Cloudサービスへのセキュアなアクセスを提供するツールです。ユーザーとアプリケーション間のトラフィックを管理し、認証と認可を行います。
Access Context Manager：Google Cloudサービスに対するアクセスをコントロールするためのサービス。ユーザーのアクセス状況を制御しますが地理的ロケーションを制限する機能は提供していません。
IAMカスタムロール：特定のユーザーに対して、特定のリソースへのアクセス権限をカスタムに制限できますが、地理的ロケーションによるリソース作成を制限する機能は提供していません。
正解についての説明：
（選択肢）
・Google Cloudの組織ノードで、組織ポリシー制約"Google Cloud - Resource Location Restriction"を使用します
この選択肢が正解の理由は以下の通りです。
Google Cloudの組織ポリシーサービスが提供する"Resource Location Restriction"という制約を使用することで、リソースの作成場所を限定的なリージョンやゾーンに制限することができます。組織ポリシーを適用するレベル（例えば組織全体、フォルダ、プロジェクト）でこの制約を設定することで、DevOpsチームが特定のリージョンでのみリソースを作成できるように制御することができます。この問題のシナリオでは、GDPR準拠のためにヨーロッパリージョンでのみリソースを作成したいと考えているため、"Resource Location Restriction"を用いてヨーロッパリージョンにリソースの場所を制限することで、この要件を満たすことができます。
不正解についての説明：
選択肢：Identity-Aware Proxy（IAP）とAccess Context Managerを使用して、Google Cloudリソースの場所を制限します
この選択肢が正しくない理由は以下の通りです。
Identity-Aware Proxy（IAP）とAccess Context Managerは、ユーザーやサービスのアクセス制限を設定するためのものであり、リソースの作成場所に制限を設ける機能は提供していません。
一方で、正解の組織ポリシー制約"Google Cloud - Resource Location Restriction"はリソースの作成場所を制限するための機能を提供します。
選択肢：Google Cloudの組織ノードの組織ポリシー制約"リソースサービスの使用を制限する"を使用します
この選択肢が正しくない理由は以下の通りです。
"リソースサービスの使用を制限する"制約は、特定のサービスの使用を許可または禁止するためのもので、リージョンによるリソースの制限には適していません。
一方、"Google Cloud - Resource Location Restriction"制約はリソースの作成場所を制限できるため、正解選択肢として適切です。
選択肢：Identity and Access Management（IAM）カスタムロールを使用して、DevOpsチームがヨーロッパリージョンでしかリソースを作成できないようにします
この選択肢が正しくない理由は以下の通りです。
カスタムロールを用いたIAMは認証や認可の管理に使われますが、特定のリージョンでしかリソースを作成できないように制限することはできません。
一方で、組織ポリシー制約 "Google Cloud - Resource Location Restriction" を使用すると、特定のリージョンでのリソース作成を制限することが可能です。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/resource-manager/docs/creating-managing-policy
https://cloud.google.com/compliance/geographic-specificities
</div></details>

### Q.  問題39: 未回答
エンベロープ暗号化を使ってデータを暗号化する手順は次のうちどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、エンベロープ暗号化におけるデータ暗号化の手順を問われています。エンベロープ暗号化の概念を理解しておくことが重要で、具体的にはデータ暗号化キー（DEK）とキー暗号化キー（KEK）がどのように使われるかを把握することが求められます。また、暗号化の順序やプロセスも理解することが求められ、それが選択肢となっています。したがって、選択肢より暗号化の適切な手順を見逃さないように注意することが重要です。
基本的な概念や原則：
エンベロープ暗号化：二つの鍵を使用する暗号化方式です。データ暗号化キー（DEK）でデータを直接暗号化し、キー暗号化キー（KEK）でDEKを暗号化（ラップ）します。
データ暗号化キー（DEK）：エンベロープ暗号化でデータを直接暗号化するときに使用する鍵です。一般にローカルで生成され、そのデータの暗号化と復号に使用されます。
キー暗号化キー（KEK）：エンベロープ暗号化でDEKを暗号化（ラップ）するときに使用する鍵です。安全に保管され、DEKの暗号化と復号に使用されます。
鍵の生成：DEKとKEKは通常別々に生成され、それぞれ異なる暗号化作業に使用されます。
データの暗号化：DEKを使用して直接データを暗号化します。この時点でDEKは平文状態です。
鍵のラップ：KEKを使用してDEKを暗号化（ラップ）します。これによりDEKは暗号文となり、安全に保存できます。
データと鍵の保存：暗号化されたデータとラップされたDEKは両方とも安全に保存されます。DEKはデータの復号に必要で、データと一緒に保存されます。
正解についての説明：
（選択肢）
・- データ暗号化キー（DEK）をローカルで生成します
- DEKを使用してデータを暗号化します
- キー暗号化キー（KEK）を使用してDEKをラップします
- 暗号化されたデータとラップされたDEKを保存します
この選択肢が正解の理由は以下の通りです。
エンベロープ暗号化は、データの安全性を確保するための一般的なパターンで、DEKとKEKの2つのキーを使用して、データを保護します。まず、DEKをローカルで生成します。これは実際にデータを暗号化し復号するために使用されます。
次に、このDEKを使用して実際のデータを暗号化します。こうすることで、データそのものが暗号化され、保護されます。しかし、DEK自体も保護する必要があります。これをKEKを使用してDEKをラップ（暗号化）します。KEKは通常、信頼性の高いキーマネージメントシステムで管理されます。
最後に、暗号化されたデータとラップされたDEKを保存します。これにより、データとDEKの両方が安全に保護されます。この手順に従うことで、データやキーが漏洩した場合でも、適切なキーがなければデータを復号化することはできません。
不正解についての説明：
選択肢：- データ暗号化キー（DEK）をローカルで生成します
- キー暗号化キー（KEK）を使用してDEKをラップします
- DEKを使用してデータを暗号化します
- 暗号化されたデータとラップされたDEKを保存します
この選択肢が正しくない理由は以下の通りです。
不正解の選択肢の手順は正解の選択肢の手順と比べて、DEKを使用してデータを暗号化することがKEKを使用してDEKをラップする後に来ています。しかし、エンベロープ暗号化では、初めにDEKを使用してデータを暗号化し、次にKEKを使用してDEKをラップするべきというのが正しい順序です。これが不正解の選択肢が相応しくない理由です。
選択肢：- キー暗号化キー（KEK）をローカルで生成します
- KEKを使用してデータ暗号化キー（DEK）を生成します
- DEKを使用してデータを暗号化します
- 暗号化されたデータとラップされたDEKを保存します
この選択肢が正しくない理由は以下の通りです。
エンベロープ暗号化では通常、データ暗号化キー（DEK）がローカルで生成されますが、この選択肢ではキー暗号化キー（KEK）がローカルで生成されています。
さらに、KEKを使用してDEKを生成するという手順は誤っています。正しくはDEKを使ってデータを暗号化し、その後KEKを使用してDEKをラップするという手順を踏むため、その部分が誤っています。
選択肢：- キー暗号化キー（KEK）をローカルで生成します
- データ暗号化キー（DEK）をローカルで生成します
- KEKを使用してデータを暗号化します
- 暗号化されたデータとラップされたDEKを保存します
この選択肢が正しくない理由は以下の通りです。
エンベロープ暗号化ではデータ暗号化キー（DEK）がデータを暗号化し、キー暗号化キー（KEK）がDEKをラップします。しかし、不正解の選択肢ではKEKがデータを暗号化しており、これはエンベロープ暗号化の原則に反しています。
参考リンク：
https://cloud.google.com/kms/docs/envelope-encryption
https://cloud.google.com/security-key-management
https://csrc.nist.gov/publications/detail/sp/800-57-part-1/rev-5/final
</div></details>

### Q.  問題40: 未回答
Google Cloudにユーザーを移行しています。エンドポイントデバイス上のGoogle WebおよびGoogle Cloud CLI SDKセッションでCookieリプレイ攻撃が発生しています。このような脅威のリスクを減らす必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudとWebサービスのセッションにおけるcookieリプレイ攻撃のリスクを減少する手段を理解することが求められています。ここでは共通のセッション管理の手法として、セッションの制御を短い時間に設定することは有効な一つの手法であることに気付く必要があります。理解すべき特殊な点は、Google Cloudには独自の再認証ポリシーがあり、これもセッション持続時間の一部と考えられるので、これを短く設定するのも効果的です。
基本的な概念や原則：
Googleのセッション制御：Google Cloudのセッション管理機能です。定義された期間経過後にセッションを終了し、再認証を要求することで、セキュリティを強化します。
再認証ポリシー：特定のGoogle Cloudサービスや操作に対して再度認証を必要とするポリシーです。不正なセッション利用を防ぎます。
Cookieリプレイ攻撃：攻撃者がユーザーのCookieを盗んでそのセッションを利用するセキュリティ攻撃です。セッション管理の強化により防ぐことが可能です。
OAuth 2.0：APIへの安全なアクセスを認証するためのオープンスタンダードです。アクセストークンの有効期間は一部のリスクを軽減するものの、Cookieリプレイ攻撃を完全に防ぐわけではありません。
サードパーティのIDプロバイダ：Google Cloud以外のサービスを使用して認証を行うことができますが、これだけではCookieリプレイ攻撃を防止するための包括的なソリューションではありません。
2段階認証：アカウントへのアクセスを保護するための追加のセキュリティレイヤーです。セキュリティキー認証を含むことがありますが、これだけではCookieリプレイ攻撃を防ぐことはできません。
正解についての説明：
（選択肢）
・Googleのセッション制御を短時間に設定します
・Google Cloudサービスの再認証ポリシーを短い期間に設定します
この選択肢が正解の理由は以下の通りです。
まず、"Googleのセッション制御を短時間に設定します"という選択肢が適切なのは、クッキーリプレイ攻撃は既存のセッションを利用して不正する攻撃方法であり、セッションの有効期間を短く設定することで攻撃者が利用できる時間を制限することができるからです。つまり、セッションが早く終了すれば、攻撃者がクッキーを利用して不正にアクセスできる機会が減少します。
次に、"Google Cloudサービスの再認証ポリシーを短い期間に設定します"という選択肢が適切なのは、再認証ポリシーを短い時間に設定することでユーザーが定期的に認証を再行うよう強制することができ、これによりクッキーリプレイ攻撃のリスクを低減させることができるからです。定期的な再認証により、攻撃者が既存のユーザーセッションを盗用して不正にアクセスする機会が減るため、セキュリティを強化することができます。
不正解についての説明：
選択肢：OAuth 2.0アクセストークンの有効期間を短くする組織ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloudでは、OAuth 2.0アクセストークンの有効期間を直接短く設定するような組織ポリシーの設定は存在しません。
一方で、Googleのセッション制御やGoogle Cloudサービスの再認証ポリシーは直接ユーザーセッションの安全性に対して効果をもたらし、Cookieリプレイ攻撃のリスクを減らすことが可能です。
選択肢：セッション管理機能を持つサードパーティのIDプロバイダを構成します
この選択肢が正しくない理由は以下の通りです。
サードパーティのIDプロバイダを使用しても、Google WebやGoogle Cloud CLI SDKセッションのCookieリプレイ攻撃のリスクは必ずしも軽減されません。
それに対して、Googleのセッション制御やGoogle Cloudサービスの再認証ポリシーを短い期間に設定することは、不正なセッション使用の可能性を直接制限する対策となります。
選択肢：2段階認証でセキュリティキー認証を強制します
この選択肢が正しくない理由は以下の通りです。
2段階認証でセキュリティキー認証を強制するアプローチは、初回の認証を強化するものですが、すでにセッションが開始され、クッキーが生成された状態でのリプレイ攻撃には効果的ではないです。
それに対して、セッション制御や再認証ポリシーを短い期間に設定することで、セッションの有効期間を短くし、攻撃のリスクを減らすことができます。
参考リンク：
https://cloud.google.com/identity-platform/docs/session-management
https://cloud.google.com/docs/authentication
https://support.google.com/a/answer/9368756
</div></details>

### Q.  問題41: 未回答
あなたは会社のセキュリティ管理者です。開発チームは、"implementation"フォルダの下に複数のGoogle Cloudプロジェクトを作成し、開発、ステージング、本番の各ワークロードに使用しています。あなたは、セキュリティ境界を設定することで、悪意のある内部関係者や侵害されたコードによるデータの流出を防ぎたいと考えています。しかし、プロジェクト間の通信は制限したくありません。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、セキュリティ管理者として、内部のリスク要素からGoogle Cloudプロジェクトを保護し、同時にプロジェクト間の通信を制限しない方法を求められています。求められているのは、データの流出を防ぐセキュリティ境界の設定と、それに対応する監視システムの構築です。"implementation"フォルダを通じて新しいプロジェクトを追加するたびに、適切にそのプロジェクトがセキュリティ境界に含まれるようなシステムが期待されています。具体的には、Infrastructure-as-CodeツールやGoogle Cloudの監視ツールを活用することによって、上記の要件が満たされる方法を考える必要があります。
基本的な概念や原則：
単一のサービス境界設定：複数のプロジェクトまたはリソースに同一のセキュリティ設定を適用することです。一貫したセキュリティポリシーを維持しつつ、プロジェクト間の通信を可能にします。
Infrastructure-as-Code：ソフトウェアを使用してインフラストラクチャを自動的にプロビジョニング・管理する手法です。Terraformなどのツールが使われます。
Google Cloud Operation Suite：Google Cloudのログ、メトリクス、トレースデータを統合的に管理・監視するためのツールセットです。
Cloud Pub/Sub：Google Cloudのリアルタイムメッセージングサービスで、イベント駆動型のシステムやストリーム処理のワークロードをサポートします。
Cloud Function：Google Cloudのサーバーレス実行環境で、特定のイベントに応じてコードを自動的に実行します。
共有VPC：複数のGoogle Cloudプロジェクト間でネットワークリソースを共有するためのサービスです。
Access Context Manager：Google Cloudのサービスで、組織のデータへのアクセスを管理し、ユーザーの認証情報やネットワーク情報に基づいたアクセスポリシーを定義します。
正解についての説明：
（選択肢）
・Infrastructure-as-Codeソフトウェアツールを使って単一のサービス境界を設定し、Google Cloud Operation SuiteとCloud Pub/Subを使って "implementation"フォルダを監視するCloud Functionをデプロイします。この関数は、、新しいプロジェクトがフォルダに追加されたことをトリガーに、、Terraformを実行して新しいプロジェクトを関連する境界に追加します
この選択肢が正解の理由は以下の通りです。
まず、Infrastructure-as-Codeソフトウェアツール、この場合Terraformを使用して単一のサービス境界を設定することで、構成の一貫性を確保し、間違いを減らし、セキュリティを強化できます。これにより、発生する各種イベントに対応するための基盤を確保することができます。
次に、Google Cloud Operation SuiteとCloud Pub/Subを使用することで、リアルタイムで"implementation"フォルダを監視し、新しいプロジェクトが追加されたときに通知を受け取ることが可能です。これは、新たに必要となるセキュリティ設定を即時に行うために不可欠であり、潜在的な脅威からの保護を強化します。
最後に、これらの監視機能がトリガーとなってCloud Functionが起動し、新たに作成されたプロジェクトを元のサービス境界に自動的に追加します。これにより、新しくプロジェクトが追加された場合でも、迅速かつ確実にそのプロジェクトをセキュリティ境界に組み込むことが可能となります。これらが協働することで、データの流出を防ぐことが可能になり、プロジェクト間の通信を妨げることなくセキュリティを確保できます。
不正解についての説明：
選択肢：共有VPCを使用してすべてのプロジェクト間の通信を可能にし、ファイアウォールルールを使用してデータの流出を防ぐ
この選択肢が正しくない理由は以下の通りです。
共有VPCはプロジェクト間の通信を可能にしますが、セキュリティ境界の設定やデータの流出防止には対応していません。ファイアウォールルールによる保護も侵害されたコードの流出には限定的で不十分です。
一方、正解ではInfrastructure-as-CodeツールとCloud Functionを用い、フォルダの監視と境界設定を自動化しています。
選択肢：Access Context Managerでアクセスレベルを作成してデータの流出を防ぎ、プロジェクト間の通信には共有VPCを使用します
この選択肢が正しくない理由は以下の通りです。
Access Context Managerはユーザーやデータのアクセスを制御するツールで、事前に設定したセキュリティポリシーに基づいてアクセスを許可または拒否します。しかし、これは内部関係者や侵害されたコードによるデータの流出を防ぐための手段ではありません。
また、共有VPCはプロジェクト間のネットワーク接続を可能にしますが、セキュリティ境界を設定する目的とは異なります。
選択肢：Infrastructure-as-Codeソフトウェアツールを使って、dev、staging、prodの3つの異なるサービス境界を設定し、Google Cloud Operation SuiteとCloud Pub/Subを使って "implementation"フォルダを監視するCloud Functionをデプロイします。この関数は、、新しいプロジェクトがフォルダに追加されたことをトリガーに、、Terraformを実行して新しいプロジェクトをそれぞれの境界に追加します
この選択肢が正しくない理由は以下の通りです。
プロジェクト間の通信制限を避けつつセキュリティを確保したい場合、異なるサービス境界を設定するとその目的に反します。個々のサービス境界ではなく、単一のサービス境界を作成することで、プロジェクト間の通信を自由に保ちつつ、全体的なセキュリティを担保することが可能となります。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/create-service-perimeters
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://www.terraform.io/docs/providers/google/r/google_folder.html
</div></details>

### Q.  問題42: 未回答
ある会社は、Google Cloudの異なるリージョンに冗長化されたメールサーバーを持っており、場所に基づいて顧客を最も近いメールサーバーにルーティングしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのリージョン間での冗長化されたメールサーバーの使用法を問われています。それらのサーバーへの顧客のルーティングは、顧客の位置に基づいて最も近いメールサーバーに向けられるべきです。問題解決においてキーポイントは、どのようにしてトラフィックをうまくルーティングし、それに適したGoogle Cloudの負荷分散のタイプを選択できるかを理解することです。この場合、メールサーバーが使用する特定のポート番号にも注意が必要です。
基本的な概念や原則：
TCPプロキシ負荷分散：指定したTCPトラフィック（SMTP、MySQLなど）を複数のバックエンドサービスに分散するための負荷分散方法です。顧客の場所に基づいて最寄りのバックエンドにトラフィックをルーティングします。
グローバル負荷分散：Google Cloudのフロントエンド設定にて、トラフィックを複数のリージョンに分散することができる機能です。
ネットワークロードバランサー：ユーザーのトラフィックに基づいて、バックエンドへのトラフィックを分散させるGoogle Cloudの負荷分散サービスです。ただし、便宜上キャラの視点からサービスへのトラフィックをルーティングするため、設問の要件を満たしません。
HTTP(S)ロードバランサー：クライアントからのHTTP(S)トラフィックをバックエンドサービスに分散するためのロードバランサーです。リージョナルに配置されたバックエンドサービスへのルーティングに利用されますが、メールサーバーへのトラフィックには不適切です。
Cloud CDN：コンテンツ配信ネットワーク（CDN）サービスで、ユーザーの近くにコンテンツをキャッシュします。HTTP(S)ロードバランサーと連携して動作しますが、メールサーバーのトラフィックには不適切です。
正解についての説明：
（選択肢）
・TCPプロキシ負荷分散を、ポート995をリッスンするグローバル負荷分散サービスとして設定します
この選択肢が正解の理由は以下の通りです。
まず、TCPプロキシ負荷分散は、Google Cloud内の全体的なネットワークに対して、受信したTCPトラフィックを複数のリージョンにあるバックエンドサービスに分散させることができます。これは、最も近いメールサーバーに顧客をルーティングする要件に対応しています。
さらに、TCPプロキシ負荷分散は、クライアントの接続要求をバックエンドで最も可能性が高い空き容量を持ったサーバに自動的にルーティングします。これにより、負荷をきちんと分散させ、ほぼ全てのリクエストに対して予測可能な性能を提供します。
なお、ポート995は一般的に、メールサーバーとの間で暗号化されたPOP3通信を行うために使われます。
したがって、このポートをリッスンするグローバル負荷分散サービスを設定することは、さまざまなリージョンに分散されたメールサーバーの負荷を均等に分散させるために適切です。
不正解についての説明：
選択肢：TCPポート995をリッスンするネットワークロードバランサーを作成し、場所に基づいてトラフィックを転送する転送ルールを設定します
この選択肢が正しくない理由は以下の通りです。
ネットワークロードバランサーは地域ベースの負荷分散であり、顧客を"最も近い"メールサーバーにルーティングすることはできません。
それに対し、TCPプロキシ負荷分散はグローバル負荷分散で、ユーザーを最も近いサーバーに自動的にルーティングできます。
選択肢：HTTP(S)ロードバランサーでクロスリージョンロードバランシングを使い、トラフィックを最も近いリージョンにルーティングします
この選択肢が正しくない理由は以下の通りです。
HTTP(S)ロードバランサーはWebベースのアプリケーションでの使用が主目的であり、メールサーバーで必要とされるTCPレベルの負荷分散に対応していません。対してTCPプロキシ負荷分散はTCPレベルでの負荷分散を可能にし、メールサーバーのようなユースケースに適しています。
選択肢：Cloud CDNを使用して、クライアントのIPアドレスに基づいて最も近いオリジンメールサーバーにメールトラフィックをルーティングします
この選択肢が正しくない理由は以下の通りです。
Cloud CDNはウェブコンテンツを高速に配信するためのサービスであり、メールトラフィックのルーティングには設計されていません。
一方、TCPプロキシ負荷分散はリージョンをまたいで負荷分散し、顧客を最も近いサーバーにルーティングする能力があります。
参考リンク：
https://cloud.google.com/load-balancing/docs/tcp
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
</div></details>

### Q.  問題43: 未回答
オンプレミスのActive DirectoryサービスからGoogle CloudのIAM権限を一元管理したいと考えています。ADのグループメンバーシップで権限を管理したいと考えています。
これらの要件を満たすために、チームは何をすべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミスのActive DirectoryからGoogle CloudのIAMへの一元管理について理解しなければなりません。特にActive DirectoryのグループメンバーシップによるIAM権限の管理が要件となっています。そのため、選択肢を考慮する際には、機能がグループベースのIAM権限管理をサポートしているかを重視すべきです。単にユーザー認証やインターフェースの提供が可能な機能ではなく、具体的なグループ管理機能が求められている点に留意しましょう。
基本的な概念や原則：
Cloud Directory Sync：Google Cloudのサービスで、Microsoft Active Directoryまたは任意のLDAPディレクトリとGoogle Cloud Identityプラットフォームを同期させることが可能です。
IAMパーミッション：Google Cloudのリソースに対するアクセス権を制御する権利です。特定のユーザ、グループ、サービスアカウントに対して設定することができます。
Active Directory：Microsoftが提供するディレクトリサービスです。ユーザーやグループの認証、権限管理などを一元的に行うことが可能です。
SAML 2.0：セキュリティアサーションマークアップランゲージ（SAML）は、ユーザーアカウントの認証情報と承認情報を安全に交換するためのオープンスタンダードです。
Cloud Identity and Access Management API：Google Cloudのアクセス制御を管理するためのAPIサービスです。
Admin SDK：Google Cloudの管理機能を利用するためのSDKです。様々な管理タスクを自動化することが可能です。
正解についての説明：
（選択肢）
・Cloud Directory Syncを設定してグループを同期し、グループにIAMパーミッションを設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Directory SyncはオンプレミスのActive DirectoryとGoogle Cloudのディレクトリを同期させるためのツールです。これを使ってActive Directoryのユーザー、グループ、およびその他のデータをGoogle Cloud Identityに比照して同期することができます。これにより、既存のActive Directoryのグループメンバーシップ情報をベースに、Google Cloudでのアクセス制御を一元的に行うことができます。
次に、同期したグループに対してIAMパーミッションを設定することで、ユーザーのGoogle Cloud内でのアクセス権を管理できます。IAMでは、特定のリソースへのアクセス許可を組織内のユーザー、グループ、サービスアカウントに割り当てることができます。そのため、Active Directoryのグループメンバーシップに基づいて、Google Cloudのリソースへのアクセス権を設定することが可能となります。
したがって、これらの機能を利用することで、オンプレミスのActive DirectoryからGoogle CloudのIAM権限への一元管理が実現できます。
不正解についての説明：
選択肢：SAML 2.0シングルサインオン（SSO）を設定し、グループにIAMパーミッションを割り当てます
この選択肢が正しくない理由は以下の通りです。
SAML 2.0 SSO設定は認証処理を目的としており、Active DirectoryとGoogle CloudのIAM権限の一元管理に直接寄与しません。一方正解のCloud Directory SyncではActive Directoryのグループ構成をGoogle Cloudに同期でき、権限管理の一元化を実現します。
選択肢：Active DirectoryからグループとIAMアクセス許可を作成するために、Cloud Identity and Access Management APIを使用します
この選択肢が正しくない理由は以下の通りです。
Cloud Identity and Access Management APIは、IAMリソースを管理するためのツールではありますが、Active Directoryから直接グループやIAMアクセス権を作成する機能はありません。
一方、Cloud Directory SyncはActive DirectoryのグループをGoogle Cloudと同期するために必要なツールで、グループに対するIAMパーミッションの設定が可能です。よって、この問題の要件を満たすためにはCloud Directory Syncを使用するのが適しています。
選択肢：Admin SDKを使用して、Active Directoryからグループを作成し、IAMパーミッションを割り当てます
この選択肢が正しくない理由は以下の通りです。
Admin SDKは、Google Workspaceのユーザー、グループ、ドメインなどを管理するためのツールで、オンプレミスのActive Directoryサービスからの同期はできません。
それに対して、Cloud Directory Syncを使用するとActive Directory内のユーザーやグループをGoogle Cloudに同期することが可能です。
参考リンク：
https://cloud.google.com/identity/docs/manage-identity-sync-gsuite-directory
https://cloud.google.com/iam/docs/overview
https://ldap.com/the-ldap-protocol/
</div></details>

### Q.  問題44: 未回答
顧客がアプリケーションをApp Engineにデプロイし、Open Web Application Security Project（OWASP）の脆弱性をチェックする必要があります。
そのためには、どのサービスを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客の要件とGoogle Cloudの各サービスの機能を理解することが求められています。問題文で示されているOWASPの脆弱性チェックのニーズと各選択肢で提供される機能を関連付けることが必要です。具体的には、OWASPの脆弱性チェックができるサービスを選択することが求められています。そのためには、各サービスが具体的に何を提供し、それが顧客の要件にどのように適合するかを理解することが重要です。
基本的な概念や原則：
Web Security Scanner：Google Cloudの持つ自動化されたウェブアプリケーションセキュリティスキャンサービスです。アプリケーションに存在する脆弱性を発見し、レポートします。
Open Web Application Security Project（OWASP）：ウェブアプリケーションのセキュリティ課題にリスクベースのアプローチを提供するコミュニティプロジェクトです。脆弱性のチェックリストなどが公開されています。
App Engine：Google Cloudのフルマネージド型サーバーレスプラットフォームです。アプリケーションを容易に開発・デプロイできるようにします。
Cloud Armor：Google CloudのWebアプリケーションファイアウォール（WAF）とDDoS防御ソリューションを提供しますが、脆弱性のチェックは行いません。
Google Cloud Audit Logs：Google Cloudリソースの監査ログを提供しますが、アプリケーションレベルの脆弱性のチェックは行いません。
Anomaly Detection：異常検知サービスですが、特定の脆弱性のチェックは行いません。
正解についての説明：
（選択肢）
・Web Security Scanner
この選択肢が正解の理由は以下の通りです。
Web Security ScannerはGoogle Cloudのサービスで、Open Web Application Security Project（OWASP）の脆弱性を検出するために使用されます。この機能は、App EngineやGoogle Kubernetes Engine（GKE）、Compute Engineなど、Google Cloud上で展開されたWebアプリケーションの脆弱性スキャンを支援します。具体的には、Web Security Scannerはクロスサイトスクリプティング、Flashインジェクション、混乱したアクセス制御などのようないくつかの共通のWebアプリケーションのセキュリティイシューを検出する能力があります。
したがって、アプリケーションがApp Engineにデプロイされ、OWASPの脆弱性チェックが必要な場合、Web Security Scannerはこの要件を満たす適切な選択となります。
不正解についての説明：
選択肢：Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Cloud ArmorはOWASPの脆弱性をチェックするツールではなく、主にDDoS攻撃の防衛とWAF（Web Application Firewall）のロールを果たします。
OWASPの脆弱性チェックには、Web Security Scannerを利用すべきで、このサービスはWebアプリケーションの共通の脆弱性を自動的にチェックします。
選択肢：Google Cloud Audit Logs
この選択肢が正しくない理由は以下の通りです。
Google Cloud Audit Logsは、ユーザーアクティビティ、管理アクティビティ、データアクセスなどのGoogle Cloudリソースの利用状況を追跡するためのもので、OWASPの脆弱性を検査するためのサービスではありません。
それに対して、Web Security Scannerは、App Engine、Compute Engine、GKE等にデプロイされたWebアプリケーションのOWASPの脆弱性をスキャンするためのサービスです。
選択肢：Anomaly Detection
この選択肢が正しくない理由は以下の通りです。
Anomaly Detectionは異常検知を行うサービスであり、OWASPの脆弱性チェックには向いていません。
一方、Web Security Scannerは、Webアプリケーションの脆弱性をチェックするためのサービスであり、OWASPの要件に対応しています。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/appengine/docs/standard
https://owasp.org/www-project-top-ten/
</div></details>

### Q.  問題45: 未回答
エンベロープ暗号化を活用し、アプリケーション層でデータを暗号化するために、Googleが推奨するプラクティスに従う必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、エンベロープ暗号化という高度なセキュリティ概念をGoogle Cloud環境でどのように実装すれば良いのかを尋ねています。ここで重要なのは、データ暗号化キー（DEK）とキー暗号化キー（KEK）の扱い方を理解することです。エンベロープ暗号化のプロセスは、データをDEKで暗号化し、そのDEK自体をKEKで暗号化することで、2つのキーによりデータのセキュリティを高めるというものです。ただし、安全なストレージの観点から、暗号化されたDEKと暗号化されたデータ本体のみを保存し、原始的なKEKは保存してはならないという点に注意が必要です。また、DEKはローカル、KEKはクラウドKMSで生成されるという点にも注目が必要です。
基本的な概念や原則：
エンベロープ暗号化：二重のキーを使用してデータを保護する暗号化方法です。データ暗号化キー（DEK）がデータ自体を暗号化し、キー暗号化キー（KEK）がDEKを暗号化します。
データ暗号化キー（DEK）：エンベロープ暗号化の一部として使用されるキーで、データ自体を暗号化するために使用されます。
キー暗号化キー（KEK）：エンベロープ暗号化の一部として使用されるキーで、データ暗号化キー（DEK）を暗号化するために使用されます。
クラウドKMS：Google Cloudのキーマネージメントサービスです。暗号化キーの生成、使用、管理、ローテーション、削除を管理します。
ローカル生成とクラウド生成：暗号化キーを生成する場所によって、キーの管理や配置が異なります。ローカルで生成すると、完全なコントロールが可能ですが、管理が複雑になる可能性があります。クラウドで生成すると、クラウドプロバイダーによる管理が可能ですが、クラウドプロバイダーへの信頼が必要です。
キーの保存と活用：暗号化したデータと暗号化したDEKを保存することで、データの機密性を高め、キーの安全な管理を支えます。一方、KEKを保存すると、DEKを解読する能力が漏洩するリスクが高まります。
正解についての説明：
（選択肢）
・ローカルでデータ暗号化キー（DEK）を生成してデータを暗号化し、クラウドKMSで新しいキー暗号化キー（KEK）を生成してDEKを暗号化します。暗号化されたデータと暗号化されたDEKの両方を保存します
この選択肢が正解の理由は以下の通りです。
まず、エンベロープ暗号化は、一つの秘密鍵（データ暗号化キー、DEK）を使ってデータを暗号化し、それをさらに別の秘密鍵（キー暗号化キー、KEK）を使って暗号化するという方法を指します。これは、データとキーの管理を分離し、より高度なセキュリティを提供します。
一般的に、DEKは直接的なデータの暗号化に使用され、DEK自体はKEKによって保護されます。ここでの重要な部分は、DEKとKEKの生成と使用です。この選択肢では、DEKはローカル（アプリケーション側）で生成され、データの暗号化に使われます。
一方、KEKはGoogle CloudのKey Management Service（KMS）で生成され、DEKの暗号化に使用されます。セキュリティ上の理由から、これらの暗号化キーは作成場所から離れた場所で管理すべきです。つまり、この場合、ローカルで生成されたDEK（暗号化された）と、KMSで生成されたKEKという構成が適切なプラクティスであると言えます。
最後に、この選択肢が正解となるもう一つの重要な要素は、暗号化されたデータと暗号化されたDEKを両方保存する点です。これにより、将来データを復号化するための必要な情報が保存されます。以上の要素が全て揃っているため、この選択肢が最も適切な解答となります。
不正解についての説明：
選択肢：ローカルでデータ暗号化キー（DEK）を生成してデータを暗号化し、クラウドKMSで新しいキー暗号化キー（KEK）を生成してDEKを暗号化します。暗号化されたデータとKEKの両方を保存します
この選択肢が正しくない理由は以下の通りです。
KEK（キー暗号化キー）は、DEK（データ暗号化キー）を安全に保存するために使用されます。KEK自体を暗号化されたデータと一緒に保存すると、データの暗号化とデータへのアクセス制御が弱くなり、セキュリティリスクとなります。正しくは、暗号化されたDEKとデータ自体を保存します。
選択肢：データを暗号化するためにクラウドKMSで新しいデータ暗号化キー（DEK）を生成し、キーを暗号化するためにローカルでキー暗号化キー（KEK）を生成します。暗号化されたデータと暗号化されたDEKの両方を保存します
この選択肢が正しくない理由は以下の通りです。
クラウドKMSで新しいデータ暗号化キー（DEK）を生成すると、DEKがクラウド上で明示的に表示され、それ自体が露出のリスクが増えます。そのため、Googleの推奨するプラクティスとは異なります。
それに対して、ローカルでDEKを生成し、クラウドKMSでキー暗号化キー（KEK）を生成すると、DEKの露出リスクが軽減され、安全性が向上します。
選択肢：データを暗号化するためにクラウドKMSで新しいデータ暗号化キー（DEK）を生成し、キーを暗号化するためにローカルでキー暗号化キー（KEK）を生成します。暗号化されたデータとKEKの両方を保存します
この選択肢が正しくない理由は以下の通りです。
KEKはデータの暗号化キー（DEK）を保護するために使われるものであるため、KEKは安全な場所、つまりここではクラウドKMSで生成されなければなりません。このため、ローカルでKEKを生成する方法は適切ではありません。
参考リンク：
https://cloud.google.com/kms/docs/envelope-encryption
https://cloud.google.com/kms/docs/encrypt-decrypt
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題46: 未回答
あなたは会社のセキュリティ管理者です。Cloud IAMのLDAPディレクトリからメールアドレスを持つすべてのセキュリティグループを同期したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud IAM上のLDAPディレクトリからセキュリティグループを同期する方法が尋ねられています。同期対象はメールアドレスを持つセキュリティグループであり、まずはそれが問題のキーポイントとなります。また同期方法については一方向か双方向か明確にされていないため、それに対する理解も重要です。また、不正解の選択肢に示されているような、誤った同期方法や不適切な属性に基づく同期には注意が必要です。正解選択肢と不正解選択肢を比較しながら、要件に最も適合する方法を選ぶことが求められています。
基本的な概念や原則：
Cloud IAM：Google CloudのIdentity and Access Managementサービスです。ユーザーやサービスアカウントの権限を制御し、リソースへのアクセスを管理します。
LDAPディレクトリ：Lightweight Directory Access Protocol（LDAP）のディレクトリは、メールアドレスなどの情報を持つユーザーやグループの情報を格納します。
Google Cloud Directory Sync：Google Cloud Directory Sync（GCDS）は、LDAPディレクトリからGoogle Cloud Identityへユーザーやグループを同期するツールです。
LDAP検索ルール：LDAPのディレクトリ情報を検索するための規則や条件を定めます。指定した属性（例えばメールアドレス）にマッチするデータを探すことができます。
一方向同期：一方のソースからもう一方のデスティネーションへのデータ同期を指します。ソースの変更はデスティネーションに伝播しますが、その逆はありません。
双方向同期：2つのシステム間でデータの変更が双方向に同期されることを指します。一方のシステムでの変更が他方のシステムにも反映され、その逆も同じです。
Google Cloud Identity：Google Cloud Identityは、ユーザーとアプリケーションがGoogle Cloudリソースに安全にアクセスできるようにする統合IDサービスです。
正解についての説明：
（選択肢）
・一方向同期を容易にするために、ユーザーのメールアドレスを属性として持つLDAP検索ルールを使用してセキュリティグループを同期するようにGoogle Cloud Directory Syncを設定します
この選択肢が正解の理由は以下の通りです。
Google Cloud Directory Sync（GCDS）は、既存のLDAPディレクトリ（例えば、Microsoft Active Directoryなど）とGoogle Cloud Identityのユーザー、グループ、および組織単位を同期するためのツールです。GCDSは一方向の同期しか行えないため、LDAPディレクトリの情報をCloud Identityへ複製することになります。LDAPのセキュリティグループをGCDSで同期するために、LDAP検索ルールを利用します。この検索ルールでは、ユーザーのメールアドレスを属性として保持することで、目的のユーザーの情報を特定し、適切に操作できることが求められます。このようにGCDSを設定することで、Cloud IAMのLDAPディレクトリからメールアドレスを持つすべてのセキュリティグループを効率的に同期することが可能です。
不正解についての説明：
選択肢：双方向同期を容易にするために、ユーザーのメールアドレスを属性として持つLDAP検索ルールを使用してセキュリティグループを同期するようにGoogle Cloud Directory Syncを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Directory Sync（GCDS）は、Google CloudとLDAPディレクトリとの間で一方向同期のみをサポートします。そのため、双方向同期を設定するという指示は、GCDSの仕様に反します。一方向同期であれば、設定や管理が容易であり、要件も満たすことができます。
選択肢：管理ツールを使って、メールアドレス属性に基づいたサブセットを同期します。Googleドメインにグループを作成します。Googleドメインで作成されたグループは、自動的に明示的なGoogle Cloud Identity and Access Management（IAM）ロールを持ちます
この選択肢が正しくない理由は以下の通りです。
Googleドメインで作成されたグループが自動的に明示的なGoogle Cloud Identity and Access Management（IAM）ロールを持つ、という記述は誤りです。IAMロールは手動で付与されるべきであり、自動的に付与されるものではありません。
選択肢：管理ツールを使用して、グループオブジェクトのクラス属性に基づいてサブセットを同期します。Googleドメインにグループを作成します。Googleドメインで作成されたグループは、自動的に明示的なGoogle Cloud Identity and Access Management（IAM）ロールを持ちます
この選択肢が正しくない理由は以下の通りです。
Googleドメインで作成されたグループは自動的にGoogle Cloud IAMロールを持つわけではありません。ロール付与は手動で設定する必要があります。
正解の選択肢のように、Google Cloud Directory Syncを使用してLDAPディレクトリからユーザー情報を同期する方が適切です。
参考リンク：
https://cloud.google.com/identity/docs/manage-groups
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-configuring-provisioning-and-single-sign-on
https://ldap.com/
</div></details>

### Q.  問題47: 未回答
あるエンジニアリングチームが、インターネット上で公開されるウェブアプリケーションを立ち上げようとしています。Webアプリケーションは複数のGoogle Cloudリージョンでホストされ、URLリクエストに基づいてそれぞれのバックエンドに誘導されます。
あなたのチームは、アプリケーションをインターネット上に直接公開することを避け、悪意のある特定のIPアドレスリストからのトラフィックを拒否したいと考えています。
これらの要件を満たすために、あなたのチームはどのソリューションを実装すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ウェブアプリケーションを公開するときのセキュリティに焦点を当てています。具体的には、公開を直接インターネット上に行うのではなく、特定の悪意のあるIPアドレスからのトラフィックを拒否する方法について問われています。この問題を解く上で重要なのは、各サービスが提供する機能とその特性を理解していることです。それにより、回答選択肢中から要件を満たす最適なソリューションを正確に選び出せます。
基本的な概念や原則：
Cloud Armor：Google Cloudのアプリケーションやサービスを保護するためのDDoS防御サービスです。特定のIPアドレスからのトラフィックを拒否することができます。
ネットワークロードバランサー：Google Cloudのロードバランサーの一つで、広範で複雑な通信を管理し、予測可能で低遅延のトラフィックを提供するロードバランサーです。
SSLプロキシロードバランサー：Google Cloudのロードバランサーの一つで、SSL間の安全なトラフィックの透過性を提供します。
NATゲートウェイ：プライベートネットワークからインターネットに接続するためのサービスで、トラフィック源のIPアドレスをマスクします。
正解についての説明：
（選択肢）
・Cloud Armor
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud ArmorはWebアプリケーションのセキュリティとDDoS保護を提供するサービスであり、ロードバランサーレイヤーに適用されます。これは、悪意のあるトラフィックや特定のIPアドレスリストからのトラフィックを拒否する、いわゆるIPブラックリスト機能を提供します。これにより、攻撃に対してアプリケーションを守るために求められていた機能が実装できます。
また、Cloud ArmorはHTTP(S)ロードバランサーを介してトラフィックをフィルタリングするため、複数のリージョンでホストされるウェブアプリケーションのターゲットトラフィックを効果的に制御することができます。これにより、アプリケーションからのURLリクエストに基づいてバックエンドに誘導する要求も満たせます。
したがって、Cloud Armorはインターネット上に公開するウェブアプリケーションのセキュリティを確保し、特定のIPからのトラフィックを足止めする要件を満たす最適な選択肢です。
不正解についての説明：
選択肢：ネットワークロードバランサー
この選択肢が正しくない理由は以下の通りです。
ネットワークロードバランサーはトラフィックを複数のリージョンに分散させる機能を提供しますが、特定のIPアドレスからのトラフィックをブロックするようなセキュリティ機能は提供しておりません。
一方、Cloud Armorはトラフィックのフィルタリングとブロックが可能で、悪意のあるIPアドレスからのトラフィックを防ぐことができます。
選択肢：SSLプロキシロードバランサー
この選択肢が正しくない理由は以下の通りです。
SSLプロキシロードバランサーはSSLトラフィックのバランシングを行いますが、悪意のある特定のIPアドレスリストからのトラフィックを拒否する機能は含まれていません。
それに対して、Cloud ArmorはIPブラックリストやホワイトリストを設定し、特定のIPからのトラフィックを制御することが可能です。
選択肢：NATゲートウェイ
この選択肢が正しくない理由は以下の通りです。
NATゲートウェイは主にプライベートなネットワークからの送信元IPアドレスを変更する機能に役立つもので、受信トラフィックのフィルタリングや特定のIPアドレスからのトラフィックを拒否するといったセキュリティ対策の機能を持ちません。
一方、Cloud Armorは特定のIPアドレスからのトラフィックを拒否するなどのセキュリティ設定を行うことが可能です。
参考リンク：
https://cloud.google.com/armor
https://cloud.google.com/load-balancing/docs/ssl
https://cloud.google.com/load-balancing/docs/network
</div></details>

### Q.  問題48: 未回答
組織のインフラをGoogle Cloudに移行する際、多数のユーザがGoogle Cloud Consoleにアクセスする必要があります。アイデンティティ管理チームはユーザーを管理する確立された方法を既に持っており、既存のSSOパスワードと共に既存のActive DirectoryまたはLDAPサーバーを使い続けたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミスのアイデンティティ管理システム（Active DirectoryやLDAP）を維持しながら、Google Cloud環境への多数のユーザアクセスを管理する方法を問われています。問題文の情報から、既存のSSOパスワードを使用したいとの要件と、ユーザ管理の方法が確立されているとの事情が明らかになります。この複雑な状況を理解し、既存のアイデンティティ管理システムとGoogle Cloudの間の適切な同期・認証機構を選択することが重要となります。
基本的な概念や原則：
Google Cloud Directory Sync：Google Cloudのサービスで、ユーザー、グループ、Google Workspaceアカウントなどの情報をオンプレミスのLDAPサーバーから同期することができます。
Active Directory（AD）：Microsoftが提供するディレクトリサービスで、ユーザー、グループ、コンピュータなどの情報を一元管理できます。
LDAP（Lightweight Directory Access Protocol）：インターネットプロトコルの一つで、ディレクトリサービスの情報を問い合わせ、操作するためのプロトコルです。
SSO（Single Sign-On）：一度のログイン認証で複数のシステムやサービスを利用できるようにする技術です。
Kerberos：ネットワーク認証プロトコルで、ユーザーとサービス間の認証を管理します。しかし、Googole Cloud Consoleへのダイレクトなサインインはサポートしていません。
OpenID Connect（OIDC）：一種のSSO技術で、Google Cloud Consoleへのログインに使用する認証トークンを生成します。これはユーザーが独自のIdPを使用してGoogle Cloud Consoleにログインする方法と異なります。
正解についての説明：
（選択肢）
・Google Cloud Directory Syncを使用して、Googleドメインのデータを既存のActive DirectoryまたはLDAPサーバーと同期します
この選択肢が正解の理由は以下の通りです。
Google Cloud Directory Sync（GCDS）は、オンプレミスのLDAPサーバーやActive DirectoryとG Suiteとのユーザー情報の同期を実現するツールです。これにより、ユーザーは自身の既存のアカウント資格情報を使用してGoogle Cloud Consoleにアクセスできます。ユーザーがすでにActive DirectoryまたはLDAPを使用している場合、GCDSはその既存のユーザー管理環境を維持しつつ、新たなインフラストラクチャへの移行をスムーズに行うのに適しています。
また、同期することでローカルシステムとクラウドシステム間で一貫性を保つことができ、管理作業の手間を省くことができます。なお、既存のSSOパスワードを用いて認証したい場合、別途SSO設定が必要となる点は留意が必要です。
不正解についての説明：
選択肢：Googleドメインのデータを既存のActive DirectoryやLDAPサーバーと手動で同期します
この選択肢が正しくない理由は以下の通りです。
手動での同期は大量のユーザーデータの管理には効率が悪く、誤りを引き起こす可能性もあります。Google Cloud Directory Syncを使用すると自動的に同期が行え、効率的に信頼性の高い同期作業が達成できます。
選択肢：ユーザーは、オンプレミスのKerberos準拠のIDプロバイダの認証情報を使用して、Google Cloud Consoleに直接サインインします
この選択肢が正しくない理由は以下の通りです。
Google Cloud Consoleへの直接のサインインは既存のActive DirectoryやLDAPサーバーとの統合を提供しません。
一方、Google Cloud Directory Syncは既存のActive DirectoryまたはLDAPサーバーとGoogleのユーザーデータを同期することで、要件を満たします。
選択肢：ユーザーはOpenID（OIDC）互換のIdPを使ってサインインし、認証トークンを受け取り、そのトークンを使ってGoogle Cloud Consoleにログインします
この選択肢が正しくない理由は以下の通りです。
OIDCを使用してユーザーがサインインし、トークンでGoogle Cloud Consoleにログインする手段は、ユーザーのActive DirectoryやLDAPサーバーとGoogleドメイン間の同期を確立する手段ではありません。
また、これは既存のSSOパスワードを活用する要求を満たしていません。
参考リンク：
https://cloud.google.com/solutions/federating-Google Cloud-with-active-directory-integrating
https://cloud.google.com/identity/docs/manage-resources
https://support.google.com/a/answer/106368?hl=en
</div></details>

### Q.  問題49: 未回答
セキュアなコンテナイメージを作成するとき、可能であれば、どの2つの項目をビルドに組み込むべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、セキュアなコンテナイメージを作成する際のベストプラクティスを理解することが求められます。選択肢から2つを選ぶ問題なので、全ての選択肢を注意深く考慮したうえで、どれが最もセキュアなコンテナ作成に対する推奨事項であるかを判断する必要があります。これには、不必要なツールの除去や単一のアプリをパッケージ化するという一般的なセキュリティ概念が関係してきます。
基本的な概念や原則：
単一のアプリをコンテナとしてパッケージ化：コンテナの一つのロールごとに一つのコンテナを使用する原則です。これにより、セキュリティが強化され、独立性と可搬性が向上します。
不要なツールの削除：コンテナイメージから必要ないソフトウェアやツールを削除することで、アタックサーフェスを減らし、セキュリティを向上させます。
PID 1の実行：Linux内でプロセスID 1（PID 1）として実行されるプロセスは、システム内で他の全てのプロセスの親となるため、潜在的なセキュリティリスクを持つことがあります。
パブリックコンテナイメージ：一般的に公開されているコンテナイメージは、使用前にその安全性をチェックすることが重要です。不明確なソースからのイメージには潜在的なセキュリティリスクがあります。
コンテナ画像レイヤー：多くのレイヤーを使用して機密情報を隠すという行為は、セキュリティ上望ましくないとされています。適切なセキュリティ対策を通じて情報を保護するべきです。
正解についての説明：
（選択肢）
・単一のアプリをコンテナとしてパッケージ化します
・アプリに必要のない不要なツールを削除します
この選択肢が正解の理由は以下の通りです。
まず、コンテナイメージに単一のアプリをパッケージ化することは、コンテナの基本的な原則です。コンテナは軽量で独立した運用が可能なため、1つのコンテナに1つのアプリケーションを配置することで、そのアプリケーションのライフサイクルを管理しやすくなります。
また、他のアプリケーションとコンテナを独立させることで、セキュリティも向上します。
次に、アプリに必要のない不要なツールを削除することも、セキュアなコンテナイメージ作成の重要な要素です。冗長なツールやソフトウェアが存在すると、それらが予期しないセキュリティリスクとなる可能性があります。特に、不必要なネットワークサービスやデーモンは、リモートからの攻撃を可能にする潜在的な脆弱性となり得ます。これらを削除することで、攻撃面を最小限に抑え、セキュリティを高めることが可能となります。
不正解についての説明：
選択肢：アプリがPID 1として実行されていないことを確認します
この選択肢が正しくない理由は以下の通りです。
通常、コンテナ内の主要なプロセスはPID 1（プロセスID 1）として実行されます。これは、コンテナがOSを模倣し、その主要プロセスがOSの初期プロセスとして機能するためです。問題の目的と合わないため、この選択肢は不正解です。
選択肢：アプリのベースイメージとしてパブリックコンテナイメージを使用します
この選択肢が正しくない理由は以下の通りです。
パブリックコンテナイメージをベースとして使用すると、予期せぬセキュリティリスクが含まれる可能性があります。不要なツールの削除や単一のアプリのパッケージ化と比べ、セキュアなコンテナイメージ作成には適しません。
選択肢：多くのコンテナ画像レイヤーを使用して、機密情報を隠します
この選択肢が正しくない理由は以下の通りです。
多くのコンテナ画像レイヤーを使用して機密情報を隠すという考え方自体がセキュリティにおける抜本的な解決策ではありません。機密情報は元々BE含めないか、セキュアな手段（秘密情報管理ツール等）で管理すべきです。
一方、正解の選択肢は不必要な脆弱性を最小化する原則に基づいています。
参考リンク：
https://cloud.google.com/container-registry/docs/managed-base-images
https://cloud.google.com/build/docs/building/containers
https://cloud.google.com/solutions/best-practices-for-building-containers
</div></details>

### Q.  問題50: 未回答
ある顧客は、攻撃者がドメイン/IPをハイジャックし、中間者攻撃によってユーザーを悪意のあるサイトにリダイレクトするのを防ぐ必要があります。
この顧客が使用すべきソリューションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のセキュリティ脅威、具体的にはドメイン/IPのハイジャックと中間者攻撃を防ぐためのソリューションを選ぶことが求められています。そのため、選択肢の各ソリューションがどのようなセキュリティ問題に対処するもので、それぞれがどのように機能するのかを理解していることが重要です。また、問題文の状況と各選択肢が対応するセキュリティ問題を照らし合わせ、一致するものを見つけることが必要です。
基本的な概念や原則：
DNSSEC（Domain Name System Security Extensions）：DNS応答の真正性と完全性を検証するための拡張プロトコルです。ユーザーが意図したWebサイトに安全にナビゲートできるようにします。
中間者攻撃：攻撃者が通信の両端点になりすますことで、通信を盗聴したり、改ざんしたりする種類の攻撃です。DNSSECはこの種の攻撃からの保護を提供します。
VPCフローログ：ネットワークフローデータをキャプチャし、Google Cloud上のVirtual Private Cloud（VPC）ネットワークのトラフィックに関するインサイトを提供するサービスです。
Cloud Armor：Google Cloud上のアプリケーションに対する分散型サービス妨害（DDoS）攻撃やウェブ攻撃から保護するためのサービスです。
Cloud Identity-Aware Proxy：Google Cloud上のアプリケーションへのアクセスを制御するためのサービスです。使用者のアイデンティティとコンテキストを確認して、セキュアなアクセスを保証します。
正解についての説明：
（選択肢）
・DNSSEC
この選択肢が正解の理由は以下の通りです。
DNSSEC（Domain Name System Security Extensions）は、DNSレコードの改ざんを防ぎ、ユーザーが悪意のあるサイトに誘導されるのを防ぐためのプロトコルです。中間者攻撃は、攻撃者が通信を傍受し、送信者と受信者の間に入る攻撃の一つです。DNSSECがなければ、攻撃者はエンドユーザーを誤ったサイトに誘導することができます。しかし、DNSSECを適用すると、DNSレスポンスが改ざんされていないことを確認するデジタル署名が追加されます。その結果、攻撃者はドメインまたはIPをハイジャックし、ユーザーを別の目的地にリダイレクトすることができなくなります。そのため、この問題文の顧客が求めているセキュリティの要件を満たす最適な解決策はDNSSECとなります。
不正解についての説明：
選択肢：VPCフローログ
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフローのデータをキャプチャし、ネットワークのトラフィックパターンを分析する機能であり、ドメインやIPのハイジャック、中間者攻撃を防ぐ機能はありません。
一方、DNSSECはDNS応答の改ざんを防ぐもので、この問題の要件を満たします。
選択肢：Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Cloud Armorは主にDDoS攻撃などのウェブ攻撃からアプリケーションを保護するためのサービスであり、ドメイン/IPのハイジャックや中間者攻撃から保護する機能はありません。
一方、DNSSECはDNSスプーフィングや中間者攻撃を防ぐためのプロトコルで、この問題の要件を満たすソリューションです。
選択肢：Cloud Identity-Aware Proxy
この選択肢が正しくない理由は以下の通りです。
Cloud Identity-Aware Proxyは認証と承認を強化するためのサービスであり、あくまでアクセス制御を担うものです。反対にDNSSECはドメイン名の信頼性を保証するための技術であり、ドメインやIPがハイジャックされて中間者攻撃を受けることを防ぐのに対応するため、この問題の要件を満たします。
参考リンク：
https://cloud.google.com/dns/docs/dnssec
https://cloud.google.com/armor/docs/security-policy-concepts
https://cloud.google.com/iap/docs/concepts-overview
</div></details>

## 5

### Q.  問題1: 未回答
組織でBigQuery分析データウェアハウスを管理しています。すべての顧客のデータを共通のテーブルに保持する一方で、行と列の権限に基づいてクエリアクセスを制限したいと考えています。クエリ以外の操作はサポートしていません。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、BigQuery分析データウェアハウスの管理と、顧客のデータアクセス制限に関する要件が提示されています。顧客が共通のテーブル内のデータにクエリを実行しますが、それぞれのクエリアクセスは行と列の権限に基づいて制限されるべきで、クエリ以外の操作はサポートされません。この要件を満たすために選ぶべき選択肢は、行レベルと列レベルのアクセス制御の設定方法に基づいています。BigQueryのセキュリティ機能とその適切な利用に理解が必要です。
基本的な概念や原則：
BigQuery：Google Cloudのフルマネージド、サーバーレス、高度にスケーラブルなエンタープライズデータウェアハウスです。大規模な分析ワークロードに対応し、SQLクエリを使用してデータを照会することができます。
行レベルのアクセスポリシー：特定の行へのアクセスを制限するように設定したポリシーです。フィルタ式を使って、どのユーザーがどの行にアクセスできるかを制御します。
列レベルのポリシータグ：特定の列へのアクセスを制限するためのポリシーです。データカテゴリや機密度などに基づいて、どのユーザーがどの列にアクセスできるかを制御します。
Cloud Key Management Service（KMS）：Google Cloudの暗号化キー管理システムで、データの暗号化と復号を行います。ただし、列レベルのアクセス制限には適していません。
データマスキング：特定のデータを非表示にするプロセスです。しかし、BigQueryでは直接的なデータマスキング機能は提供していません。
正解についての説明：
（選択肢）
・フィルタ式をFALSEに設定してクエリを実行したときに、結果データを制限する行レベルのアクセスポリシーを作成します
・列レベルのポリシータグを作成して、クエリ実行時に列へのアクセスを制御します
この選択肢が正解の理由は以下の通りです。
まず、"フィルタ式をFALSEに設定してクエリを実行したときに、結果データを制限する行レベルのアクセスポリシーを作成します"は、BigQueryの行レベルセキュリティを活用した制御方法で、フィルタ式がFALSEと評価される行はクエリの結果から除外されます。これにより、特定のユーザーが特定の行にアクセスすることを制限することができます。
また、"列レベルのポリシータグを作成して、クエリ実行時に列へのアクセスを制御します"は、BigQueryの列レベルセキュリティを実現する手段であり、ポリシータグを用いてアクセスを制御することで、特定のユーザーが特定の列にアクセスすることを制限します。
したがって、これらのアプローチは、共通のテーブルに保持された顧客データへのクエリアクセスを制限するための適切な手段です。
不正解についての説明：
選択肢：フィルタ式をTRUEに設定してクエリを実行したときに、結果データを制限する行レベルのアクセスポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
フィルタ式をTRUEに設定すると、すべての行が条件に一致するため、特定のユーザーのアクセス制限が行われず、結果として行レベルのアクセスポリシーが効果的に作成できないからです。
一方、フィルタ式をFALSEに設定すると、クエリによってアクセスが制限されるため、特定の行へのアクセス制限が可能となります。
選択肢：Cloud Key Management Service（KMS）でAEAD（Authenticated Encryption with Associated Data）機能を使用して列レベルの暗号化を構成し、クエリ実行時に列へのアクセスを制御します
この選択肢が正しくない理由は以下の通りです。
BigQueryでは、Cloud KMSのAEAD機能を使用した列レベルの暗号化はサポートしていないため、これはアクセス制限の手段として使用できません。代わりに列レベルのアクセス制限には、列レベルのポリシータグを使用します。
選択肢：動的なデータマスキングルールを構成して、クエリ実行時に列へのアクセスを制御します
この選択肢が正しくない理由は以下の通りです。
動的なデータマスキングルールはBigQueryでは直接サポートされておらず、列アクセスを制御するのに柔軟性が欠けています。その代わりに列レベルのポリシータグが正確なアクセス制御を提供します。
参考リンク：
https://cloud.google.com/bigquery/docs/row-level-security-intro
https://cloud.google.com/bigquery/docs/column-level-security-intro
https://cloud.google.com/bigquery/docs/best-practices-access-control
</div></details>

### Q.  問題2: 未回答
あなたは、現在の保守契約が切れる前に、会社のデータセンターからGoogle Cloudにレガシーアプリケーションを移行するタスクを引き受けています。アプリケーションがどのポートを使用しているのかわからず、確認できるドキュメントもありません。この状況で、環境を危険にさらすことなく移行を完了したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ドキュメンテーションが不十分で、アプリケーションがどのポートを使用しているのか分からないレガシーアプリケーションのGoogle Cloudへの移行が課題となっています。適切な移行戦略とネットワーク管理の手法を選択する必要があります。注目すべきは"リフト＆シフト"アプローチ、カスタムネットワーク、VPCファイアウォールルールの使用、VPCフローログの使用、アプリケーションのリファクタリング、Cloud Functionsなどです。これらの要素を理解し、それぞれの選択肢が移行タスクと保全の要件をどの程度満たすかを考察することが求められています。
基本的な概念や原則：
リフト＆シフト：既存のアプリケーションをそのままクラウド環境に移行する方法です。アプリケーションの構造を変更せず、早期の実装が可能ですが、クラウド環境の特性を十分に活かすことが難しい場合もあります。
VPC（Virtual Private Cloud）：Google Cloud上で定義可能な、プライベートな仮想ネットワーク環境です。VPC内では、ユーザーが設定したネットワークのルールに基づいてリソース間の通信が管理されます。
VPCファイアウォールルール：VPC内において、特定の通信を許可したり、拒否したりするためのルールを定義します。これによりアプリケーションのセキュリティを強化することができます。
VPCフローログ：VPCネットワークの流入・流出トラフィックのログです。これにより、不正なトラフィックを検出したり、パフォーマンスの問題を診断したりすることが可能です。
適切なトラフィックの確認：アプリケーションが正しく動作するために必要なネットワーク通信を確認します。これにはVPCファイアウォールルールやVPCフローログが利用されます。
アプリケーションリファクタリング：既存のアプリケーションを改良し、新しいアーキテクチャーやプラットフォームに適応させる作業のことです。これによりクラウドの特性をより活かすことが可能になりますが、実装には時間とコストが必要です。
マイクロサービスアーキテクチャ：アプリケーションを小さな独立したサービスに分けるアーキテクチャのことです。各マイクロサービスは独自のプロセスとデータストレージを持ち、APIを介して他のサービスとやりとりします。これにより、開発と運用のフレキシビリティが向上します。
正解についての説明：
（選択肢）
・"リフト＆シフト"アプローチを採用して、アプリケーションを分離プロジェクトに移行します。VPCファイアウォールルールを使用して、すべての内部TCPトラフィックを有効にします。VPCフローログを使用して、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正解の理由は以下の通りです。
まず、リフト＆シフトとは、既存のサービスをそのままクラウドに移行する戦略です。この方法を使用すると、アプリケーションの変更が最小限になり、移行の複雑性とリスクが軽減されます。
次に、VPCファイアウォールルールを使用して、すべての内部TCPトラフィックを有効にすると、アプリケーションが必要とするすべてのポートを開放できます。これにより、アプリケーションが正常に機能することが確認できます。ただし、この方法を使用すると、アプリケーションが必要とするすべてのTCPトラフィックが許可され、セキュリティ上のリスクが発生する可能性があります。そのため、VPCフローログを使用して、アプリケーションが正常に機能するためにどのトラフィックを許可すべきかを判断することが重要です。フローログにより、リアルタイムでネットワークフローデータをキャプチャし、分析することができます。これにより、不要なポートを特定し、それらを閉じることでセキュリティを強化することが可能となります。
不正解についての説明：
選択肢："リフト＆シフト"アプローチを採用して、カスタムネットワークでアプリケーションを分離プロジェクトに移行します。VPC内のすべてのトラフィックを無効にし、ファイアウォールログを調べて、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正しくない理由は以下の通りです。
VPC内のすべてのトラフィックを無効にすると、レガシーアプリケーションの機能が全て停止してしまうためです。正解の選択肢では一時的に全てのTCPトラフィックを許可し、実際のトラフィックを見てから制限する方法を選んでいます。
選択肢：アプリケーションを、GKEクラスター内のマイクロサービスアーキテクチャにリファクタリングします。ファイアウォールルールを使用して、クラスターの外部からのすべてのトラフィックを無効にします。VPCフローログを使用して、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正しくない理由は以下の通りです。
アプリケーションをマイクロサービスアーキテクチャにリファクタリングすることは時間がかかり、アプリケーションがどのポートを使用しているかわからないという問題を解決しません。
また、保守契約が切れる前に移行を完了するという要件に対して、リファクタリングは現実的な解決策ではありません。
選択肢：アプリケーションを、分離されたプロジェクトのCloud Functionsでホストされるマイクロサービスアーキテクチャにリファクタリングします。ファイアウォールルールを使用して、プロジェクトの外部からのすべてのトラフィックを無効にします。VPCフローログを使用して、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正しくない理由は以下の通りです。
リファクタリングは、アプリケーションのコードの構造を改変するプロセスであり、時間と労力がかかるため、現在の保守契約が切れる前に移行を完了するという要件を満たすのが困難です。
また、使用するポートが不明な場合、リファクタリングはリスクが高いため、ここでの最適な解決策は"リフト＆シフト"アプローチです。
参考リンク：
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/architecture/vm-migration-validation-with-Google Cloud-migration-landing-zone
</div></details>

### Q.  問題3: 未回答
ある企業がGoogle Cloud上にアプリケーションをデプロイしています。会社のポリシーでは、少なくとも2つの地理的ロケーションにデータを自動的に複製できるソリューションを使用して長期データを保存する必要があります。
どのストレージソリューションの使用が許可されていますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、データの地理的冗長性を持つ特定のストレージソリューションについて問われています。企業のポリシーから、求められるソリューションは少なくとも2つの地理的なロケーションでデータを保存する機能が必要で、それが自動的に行われる必要があることを理解することが重要です。選択肢の中からこの要件を満たすストレージソリューションを選びましょう。
基本的な概念や原則：
Cloud BigQuery：Google Cloudの高度なデータ分析ワーケハウスサービス。複数の地域にまたがってデータを保存することが可能です。大規模なデータセットに対する分析をリアルタイムで行うことが可能で、長期データの保存にも対応しています。
Compute Engine SSDディスク：Google CloudのCompute Engineで使用するためのSSDストレージ。高性能な読み書き速度を提供しますが、単一の地域でのみ存続します。
Compute Engine Persistent Disk：Google CloudのCompute Engineで使用するための高性能ストレージ。SSDディスクとは異なり、データは耐久性がありますが、単一の地域でのみ存続します。
Cloud Bigtable：Google CloudのNoSQL Big Dataデータベースサービス。大規模な分析と操作ワークロードに対応できますが、データは指定した単一の地域に保存されます。
正解についての説明：
（選択肢）
・Cloud BigQuery
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのBigQueryは高性能のデータウェアハウスであり、その特性として自動的なデータレプリケーションと災害復旧が提供されています。BigQueryは独自のネットワークインフラストラクチャを使用してデータをGoogle内部の複数の物理的な場所に分散保存することで、データの堅牢性と耐久性を確保します。これにより、データセットの一部が何らかの理由で使用できなくなった場合でも、データの利用が可能となります。
また、BigQueryは長期データの保存に利用可能であり、大量の生データをリアルタイムに追加及び更新できます。そのため、企業の要件である複数の地理的ロケーションにデータを自動複製し、長期データを保存するというポリシーを満たすことが可能です。
したがって、BigQueryはこのシナリオにおいて適切なソリューションと考えられます。
不正解についての説明：
選択肢：Cloud Bigtable
この選択肢が正しくない理由は以下の通りです。
Cloud Bigtableは単一リージョン内での複製が可能な高性能NoSQLデータベースであり、データを少なくとも2つの地理的ロケーションに自動的に複製する要件を満たせません。
それに対して、Cloud BigQueryはデフォルトでリージョン間ののデータ複製を提供します。
選択肢：Compute Engine SSDディスク
この選択肢が正しくない理由は以下の通りです。
Compute Engine SSDディスクは単一のゾーンまたはリージョンにデータを保存し、自動的に複数の地理的ロケーションにデータを複製する機能を持たないため、適用できません。
一方、Cloud BigQueryは自動的にデータを複製し、複数地域に保存することが可能です。
選択肢：Compute Engine Persistent Disk
この選択肢が正しくない理由は以下の通りです。
Compute Engine Persistent Diskは単一の地理的ロケーションにデータを保存します。これは、少なくとも2つの地理的ロケーションにデータを複製するポリシーに反します。
一方、Cloud BigQueryはデータの自動的な地理的な冗長性を提供します。
参考リンク：
https://cloud.google.com/bigquery/docs/locations
https://cloud.google.com/bigtable/docs/replication
https://cloud.google.com/compute/docs/disks#repds
</div></details>

### Q.  問題4: 未回答
あなたの会社はGoogle Cloudを使用しており、一般に公開されているネットワーク資産があります。あなたは、最小限の時間で、ソフトウェアツールを使用して、これらの資産を発見し、これらの資産のセキュリティ監査を実行したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、公開されているネットワーク資産の発見とセキュリティ監査の実行が求められています。また、最小限の時間で、ソフトウェアツールを用いてこれを行いたいとの要件があります。したがって、選択肢を見る際には、公開されているネットワーク資産の特定とその監査が可能なツールを提供するオプションを探し、かつそれが最小限の時間で実行可能であるかどうかを評価する必要があります。
基本的な概念や原則：
Cloud Asset Inventory：Google CloudのリソースとIAMポリシーを検索、分析、監視するためのサービスです。リソース設定の変更を追跡したり、自動的に情報を取得したりすることができます。
ネットワークセキュリティスキャナー：Google Cloud上のネットワークリソースの脆弱性を定期的にスキャンし、潜在的な問題を報告するツールです。
ソフトウェアツールによるセキュリティ監査：ソフトウェアツールを使用して、脆弱性や潜在的な脅威を発見し、評価するためのプロセスです。これにはネットワークスキャン、構成管理、ログ分析などが含まれます。
プラットフォームセキュリティスキャナ：特定のプラットフォームや技術を対象としたセキュリティスキャナーです。特定の脆弱性を特定し、修正の推奨を提供します。
外部資産：企業のデジタルフットプリントの一部で、企業が所有するが直接管理していない資産のことを指します。これには、パートナーやサプライヤーが管理するウェブサイトやCloud Storage、IPアドレスなどが含まれます。
正解についての説明：
（選択肢）
・Cloud Asset Inventoryを使用してすべての外部資産を特定し、それらに対してネットワークセキュリティスキャナーを実行します
この選択肢が正解の理由は以下の通りです。
まず、要件は資産の発見とセキュリティ監査を最小限の時間で実行することを求めています。そのためには、Cloud Asset Inventoryとネットワークセキュリティスキャナーの組み合わせが最も適しています。
Cloud Asset Inventoryは、Google Cloudのすべての資産に関する情報のスナップショットや履歴を提供するサービスで、これによりあなたの会社の公開されているネットワーク資産を素早く特定できます。公開情報の範囲は広く、ストレージバケットやデータベースインスタンス、仮想マシンなど、Google Cloudのサービスに関連するあらゆる情報を含んでいます。
一方、ネットワークセキュリティスキャナーは、指定したネットワーク資産に対するセキュリティ脆弱性の検査を行うツールです。これらの資産に対してセキュリティスキャンを実施することで、可能な攻撃経路を特定し、それを是正する対策を講じることが可能となります。
したがって、この選択肢が最も効率的に要件を満たす方法と言えるでしょう。
不正解についての説明：
選択肢：組織内のすべてのインスタンスでプラットフォームセキュリティスキャナを実行します
この選択肢が正しくない理由は以下の通りです。
プラットフォームセキュリティスキャナを全インスタンスで実行する方法では、公開されているネットワーク資産を迅速に特定できず効率が悪いです。
一方、Cloud Asset Inventoryを使うと、外部資産を効率的に特定でき、その上でネットワークセキュリティスキャナを実行できます。
選択肢：Googleが承認したセキュリティベンダーに監査を依頼します
この選択肢が正しくない理由は以下の通りです。
Googleが承認したセキュリティベンダーに監査を依頼する方法は最小限の時間でセキュリティ監査を行うという要件に反します。それは、外部のベンダーと連携し、監査を実施するための時間とコーディネーションが必要になるからです。対象的に、Cloud Asset Inventoryとネットワークセキュリティスキャナーを使えば短時間で自動的に資産を発見し、セキュリティ監査を実行することが可能です。
選択肢：保留中の監査についてGoogleに通知し、スキャンを実行する前に確認を待ちます
この選択肢が正しくない理由は以下の通りです。
監査の実行についてGoogleに通知し、確認を待つという選択肢は、自社ネットワークのセキュリティ監査をGoogleが直接行うという誤解に基づいています。
逆に、Cloud Asset Inventoryとネットワークセキュリティスキャナーは、自社で迅速にネットワーク資産の検出と監査を行うツールです。
参考リンク：
https://cloud.google.com/asset-inventory/docs/overview
https://cloud.google.com/security-command-center/docs/concepts-overview
https://nmap.org/book/man.html
</div></details>

### Q.  問題5: 未回答
あなたは会社の開発チームに所属しています。あなたは、GKE上のステージングでホストされているウェブアプリケーションが、入力されたデータを最初に適切に検証することなく、ウェブページにユーザデータを動的に取り込んでいることに気づきました。このため、攻撃者は実運用環境において、被害者ユーザのブラウザで不正なコマンドを実行したり、任意のコンテンツを表示したりできる可能性があります。
この脆弱性をどのように防ぎ、修正すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ウェブアプリケーションのセキュリティ脆弱性に対処するための最適な方法を問います。具体的な脆弱性としてクロスサイトスクリプティング（XSS）が挙げられています。適切な手段を選択するためには、この脆弱性がどのような挙動をもたらすのか、どのように防ぐことができるのかを理解する必要があります。また選択肢からは、攻撃のシミュレーション、IPに基づくフィルタリング、HTTPSロードバランサーやCloud Armorの使用、古いライブラリの確認等、複数の防御手段が示されています。課題はこれらの中から、XSS攻撃に最も効果的な対策を選ぶことです。
基本的な概念や原則：
GKE（Google Kubernetes Engine）：Google CloudのマネージドKubernetesサービスです。コンテナ化されたアプリケーションをデプロイ、スケール、更新するための環境を提供します。
Web Security Scanner：Google Cloudの自動化されたスキャナーで、Webアプリケーションの脆弱性を探すツールです。クロスサイトスクリプティング（XSS）や、SQLインジェクションなどの一般的な脆弱性を検出することができます。
エスケープ処理：潜在的な攻撃コードが含まれる可能性があるデータを安全な形式に変換するプロセスです。これにより、攻撃者が意図しないコードを実行するのを防ぐことができます。
Cloud Identity-Aware Proxy（IAP）：Google Cloudのサービスで、アプリケーションへのアクセスをセキュアに管理します。しかし、ユーザーデータの検証またはエスケープ処理を自動的に提供するものではありません。
Cloud Armor：Google Cloudのサービスで、DDoS攻撃などの一般的なWeb攻撃を防ぐ機能を提供します。しかし、クライアントサイドの脆弱性（例えば、XSS）を防ぐことはできません。
HTTPSロードバランサー：HTTPSトラフィックを複数のバックエンドサービスに分散するGoogle Cloudのサービスです。セキュリティを強化するために使用することができますが、XSS攻撃を防ぐ機能は提供していません。
ライブラリの保護されたバージョン：セキュリティパッチが当てられ、脆弱性が修正されているライブラリのバージョンです。これを使用することで、一部のセキュリティリスクを軽減することができますが、ユーザーデータのエスケープ処理を自動的に提供するわけではありません。
正解についての説明：
（選択肢）
・ステージングでWeb Security Scannerを使ってXSSインジェクション攻撃をシミュレートし、コンテキストの自動エスケープをサポートするテンプレートシステムを使います
この選択肢が正解の理由は以下の通りです。
まず、Web Security ScannerはGoogle Cloudが提供するセキュリティ診断ツールで、Webアプリケーションの脆弱性を特定できる機能があります。該当のウェブアプリケーションがユーザデータを検証せずに動的に取り込んでいると問題文にあるので、このツールを使用して異常があるかどうかを確認し、特にXSS（クロスサイトスクリプティング）攻撃をシミュレートします。これにより、擬似的に攻撃を行い、その対策をあらかじめ検討することができます。
また、コンテキストの自動エスケープをサポートするテンプレートエンジンの使用は、入力値がウェブページに反映される際に、その値がコードとして実行されることを防ぎます。利用者による入力がそのままHTMLなどのコードやデータとして扱われることで生じる脆弱性、XSS攻撃の対策となります。これにより、攻撃者が不正なコマンドを実行することや、任意のコンテンツを表示する手段を取り除き、セキュリティの強化に寄与します。
不正解についての説明：
選択肢：IPアドレスまたはエンドユーザーデバイスの属性に基づくCloud Identity-Aware Proxy（IAP）を使用して、脆弱性を防止および修正します
この選択肢が正しくない理由は以下の通りです。
Cloud IAPは認証と認可を提供してアクセスを制御することに役立つサービスですが、クロスサイトスクリプティング（XSS）といったウェブページ内部での不正なコマンドの実行を防止する機能はありません。
これに対して、Web Security ScannerはXSS等の脆弱性を検出し、テンプレートシステムは不正なコードの実行を防ぐための解決策です。
選択肢：HTTPSロードバランサーをセットアップし、本番環境にCloud Armorを使用して潜在的なXSS攻撃を防ぐ
この選択肢が正しくない理由は以下の通りです。
HTTPSロードバランサーとCloud Armorを導入すると、一部のセキュリティリスクは軽減されるかもしれませんが、この設定ではXSS攻撃からの防御に特化していません。
一方、Web Security Scannerを使用すると、XSSインジェクション攻撃をシミュレートし、その脆弱性を具体的に特定することが可能となります。
選択肢：Web Security Scannerを使用して、コード内の古いライブラリの使用を検証し、含まれるライブラリの保護されたバージョンを使用します
この選択肢が正しくない理由は以下の通りです。
古いライブラリの使用を検証し、保護されたバージョンを使用することは一般的に良いセキュリティ対策ですが、これだけでは具体的な問題、つまりユーザデータの適切な検証とXSS攻撃の防止に直接対処していません。
正解の選択肢は、問題の具体的な脆弱性を対象にした手段を提供しています。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/appengine/docs/standard/python3/using-templates
https://owasp.org/www-community/attacks/xss/
</div></details>

### Q.  問題6: 未回答
あなたは、ブートディスクのソースとして使用できるイメージを制限したいと考えています。これらのイメージは専用のプロジェクトに保存されます。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のプロジェクトに保管されているイメージだけがブートディスクのソースとして利用可能にするためにどの方法が適しているかを問われています。そのため、組織ポリシーサービスやリソースマネージャーといったGoogle Cloudの管理ツールを使った対策の理解が必要です。特に、制約とその設定方法を理解することが重要です。計算機能に影響を与える制約に関連した選択肢を適切に評価する必要があります。
基本的な概念や原則：
組織ポリシーサービス：Google Cloudの組織ポリシーの管理を行うサービスです。組織のリソースに対する特定の制約を設定し、コンプライアンスを維持するのに役立ちます。
compute.trustedImageProjects制約：ブートディスクのソースとして使えるイメージを制限するための制約です。この制約を使用すると、特定のプロジェクトからのイメージのみを許可することができます。
許可操作：組織ポリシーサービスで使用できる操作の一つです。特定のリソースやアクションの実行を許可することができます。
ホワイトリスト：許可される要素のリストです。セキュリティコンテキストでは、特定のユーザー、IPアドレス、プログラムなど、特権を付与する要素のリストを作成します。
リソースマネージャー：Google Cloudのリソースを組織やプロジェクトレベルで管理するサービスです。アクセス権限やポリシーの設定などを行うことができます。
"Compute Image User"ロール：Compute Engineの特定のイメージを使用してインスタンスを作成する権限を持つロールです。
正解についての説明：
（選択肢）
・組織ポリシーサービスを使用して、組織レベルでcompute.trustedimageProjects制約を作成します。許可操作のホワイトリストとして、信頼されたプロジェクトをリストします
この選択肢が正解の理由は以下の通りです。
ブートディスクのソースとして使用できるイメージを制限するという目的に直接対応する手段として、組織ポリシーサービスが挙げられます。組織ポリシーサービスは、Google Cloudリソースの開発および運用に対する一連の典型的な制約を提供します。その中でも、compute.trustedImageProjects制約は、特定のプロジェクトからのイメージのみを信頼し、それをブートディスクのソースとして使用することを許容する制約になります。この制約により、組織全体でブートディスク作成に使用されるイメージのソースを制御することが可能になり、不適切なイメージからのブートディスク作成を抑止することができます。
したがって、この要件を満たすためには、組織ポリシーサービスを使用して、組織レベルでcompute.trustedImageProjects制約を作成し、許可操作のホワイトリストとして、信頼されたプロジェクトをリストするのが最適な解答となります。
不正解についての説明：
選択肢：組織ポリシーサービスを使用して、組織レベルでcompute.trustedimageProjects制約を作成します。拒否操作の例外として、信頼済みプロジェクトをリストします
この選択肢が正しくない理由は以下の通りです。
信頼済みのプロジェクトを拒否操作の例外としてリストするという考え方は誤っています。信頼済みのプロジェクトは許可するもので、許可操作のホワイトリストに追加すべきです。拒否操作の例外に追加すると、重要なプロジェクトが誤ってブロックされるリスクがあります。
選択肢：リソースマネージャーで、信頼できるプロジェクトのプロジェクト権限を編集します。組織をロール"Compute Image User"を持つメンバーとして追加します
この選択肢が正しくない理由は以下の通りです。
リソースマネージャーで信頼できるプロジェクトのプロジェクト権限を編集しても、特定のイメージの使用を制限することはできません。
それに対して、組織ポリシーサービスを使用すれば、compute.trustedimageProjects制約を作成し、特定のプロジェクトのイメージのみを許可操作のホワイトリストに追加できるため、要求を満たします。
選択肢：リソースマネージャーで、組織の権限を編集します。プロジェクトIDをロール"Compute Image User"を持つメンバーとして追加します
この選択肢が正しくない理由は以下の通りです。
リソースマネージャーで権限を編集し、プロジェクトIDを"Compute Image User"ロールを持つメンバーとして追加すると、そのメンバーは指定したプロジェクトのイメージにアクセスできます。しかし、これではブートディスクのソースとして使用できるイメージを制限するという要件に対応できません。
一方、組織ポリシーサービスを使って制約を作成すると、特定のプロジェクトだけがブートディスクのソースとして使用できるイメージを提供できるため、要件通りの制限が可能になります。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
https://cloud.google.com/compute/docs/access/iam
</div></details>

### Q.  問題7: 未回答
あなたはある組織のセキュリティチームのメンバーです。あなたのチームには、Webアプリケーションやデータ処理システムとともに、クレジットカード決済処理システムを含むGoogle Cloudプロジェクトが1つあります。あなたは、PCI監査基準の対象となるシステムの範囲を縮小したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、あなたが組織のセキュリティチームの一員として、PCI監査基準への対応とそれに伴うシステム範囲の縮小を考えています。公式な監査基準が関与している場合、その基準の主な目標と原則を理解しておくことが重要です。選択肢を評価する際には、特にPCI DSS（クレジットカード情報のセキュリティ基準）と関連する選択肢に対して注意深く検討するために、PCI監査の目的と要件に基づいて最適なセキュリティコントロールを選択することを心掛けてください。
基本的な概念や原則：
Google Cloudプロジェクト：Google Cloud上でリソースを管理するための主要な組織単位です。各プロジェクトは独立した設定、IAMポリシー、ネットワーキングなどを持つことができます。
PCI認証：クレジットカード情報の安全性を確保するための国際的な規格です。取引量に応じたレベルがあり、各レベルには特定の要求事項が定められています。
カード会員データ環境：クレジットカードデータを含む、あらゆる人、プロセス、技術の環境のことです。PCI監査では、これらの環境が厳しく監査されます。
多要素認証：ユーザーの身元を確認するために二つ以上の検証方法を使用するアクセス管理システムです。セキュリティレベルを向上させますが、PCI認証の範囲を縮小するわけではありません。
PA-DSS：クレジットカード業界が決定したソフトウェアのセキュリティ基準です。しかし、これが準拠しているだけではPCI監査の範囲を縮小するわけではありません。
VPN：インターネット上の公開ネットワークを利用しながら、プライベートネットワーク同様に安全に通信するための技術です。しかし、これを使用してもPCI監査の範囲を縮小するわけではありません。
正解についての説明：
（選択肢）
・カード会員データ環境を別のGoogle Cloudプロジェクトに移動します
この選択肢が正解の理由は以下の通りです。
セキュリティのベストプラクティスとして、特定の敏感情報（例えば、ここではクレジットカードデータ）を含むシステムは、他のシステムから分離・切り離すことが推奨されます。ここでは、PCI監査基準の対象となるシステムを、他のWebアプリケーションやデータ処理システムと物理的に分離することで、監査の範囲を縮小し、管理を容易にし、セキュリティリスクを最小限に抑えることができます。Google Cloudのプロジェクトは、リソースの組織化と分離を可能にする機能を提供し、このアプローチを容易にします。
したがって、カード会員データ環境を別のGoogle Cloudプロジェクトに移動することは、監査基準を満たすための適切な方法となります。
不正解についての説明：
選択肢：ウェブアプリケーションの管理者アクセスには多要素認証を使用します
この選択肢が正しくない理由は以下の通りです。
ウェブアプリケーションの管理者アクセスに多要素認証を使用することは、一般的なセキュリティ強化策ではありますが、PCI監査基準の対象範囲を縮小する目的には直接貢献しません。
一方、カード会員データを別のGoogle Cloudプロジェクトに移動することで、対象となるシステムの範囲が限定され、監査対象を縮小することが可能となります。
選択肢：PA-DSSに準拠していることが証明されたアプリケーションのみを使用します
この選択肢が正しくない理由は以下の通りです。
PA-DSSに準拠していることが証明されたアプリケーションのみを使用することは良いセキュリティプラクティスではありますが、それ自体ではPCI監査基準の対象となるシステムの範囲を縮小するものではありません。
それに対して、カード会員データ環境を別のGoogle Cloudプロジェクトに移動することで、監査範囲を限定できます。
選択肢：オフィスとクラウド環境間のすべての接続にVPNを使用します
この選択肢が正しくない理由は以下の通りです。
オフィスとクラウド環境間の接続にVPNを使用するのはセキュリティを高める手段の一つではありますが、これがPCI監査基準の対象となるシステムの範囲を縮小する直接的な効果はありません。
それに対して、カード会員データ環境を別のGoogle Cloudプロジェクトに移動することで、監査対象範囲を明確に分離、縮小できます。
参考リンク：
https://cloud.google.com/resource-manager/docs/creating-managing-projects
https://cloud.google.com/compliance/offerings#card_payment
https://cloud.google.com/solutions/pci-dss-compliance-in-Google Cloud
</div></details>

### Q.  問題8: 未回答
ある顧客が、マネージドインスタンスグループ（MIG）を使用して、センシティブなワークロードをCompute Engineベースのクラスターに移行したいと考えています。ジョブは大量に発生し、迅速に完了する必要があります。また、鍵のライフサイクルを管理できることが必要です。
この顧客の要件を満たすために、クラスター上のどのブートディスク暗号化ソリューションを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客がCompute Engineベースのクラスターにセンシティブなワークロードを移行する際、速度の速さと暗号化キーのライフサイクルの管理が必要と述べています。そのため、Compute Engineベースのクラスターに移行する際に適切な暗号化ソリューションを選ぶ必要があります。選択肢を検討する際には、それぞれが速度とキーのライフサイクル管理にどのように対応しているかを見極めることが必要となります。
基本的な概念や原則：
Cloud Key Management Service（KMS）：Google Cloudの秘密鍵管理サービスです。ユーザーは自分で暗号化キーを管理し、そのライフサイクルを制御することができます。
顧客管理の暗号化キー（CMEK）：Cloud KMSで生成と管理される暗号化キーです。ユーザーは自分で鍵のライフサイクルを管理することができ、一部またはすべてのデータを特定の鍵で暗号化して保管できます。
顧客指定の暗号化キー（CSEK）：ユーザーが明示的に提供するキーで、特定の一部のデータを保護します。Google概念内において、このキーは課質者のローカル環境に保存され、Google自体がこれらの登録キーを知らないとされています。
マネージドインスタンスグループ（MIG）：Compute Engineの一部で、指定した数の一貫性のあるVMインスタンスを作成し、管理する機能です。大量のジョブを迅速に完了させるためのスケーリングに役立ちます。
ブートディスク暗号化：センシティブなデータを保護するためのセキュリティ対策です。ブート可能なディスクドライブ上のすべてのデータを暗号化して、不正なアクセスからデータを守ります。
正解についての説明：
（選択肢）
・Cloud Key Management Service（KMS）を利用した顧客管理の暗号化キー（CMEK）を使用します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Key Management Service（KMS）を使用することで、顧客自身が鍵のライフサイクルを完全に管理することができます。これにより、鍵の生成、使用、ローテーション、そして廃棄までの各ステージを厳細にコントロールすることが可能になります。この柔軟性は、センシティブなワークロードを扱う顧客が適切なセキュリティ対策を確保する上で重要です。
そして、顧客管理の暗号化キー（CMEK）を使用することで、ブートディスクのデータを安全に暗号化可能です。これはユーザーがGoogle Cloud上で生成し、管理可能な暗号化キーであり、Compute Engineベースのクラスターのデータ保護に役立ちます。以上から、顧客が必要とするセキュリティ要件と、高速なワークロード処理の需要を両立するために、Cloud KMSとCMEKの組み合わせが最適であると言えます。
不正解についての説明：
選択肢：顧客指定の暗号化キー（CSEK）を使用します
この選択肢が正しくない理由は以下の通りです。
CSEK（顧客指定の暗号化キー）は、セキュリティが高い反面、鍵のライフサイクル管理を顧客自身が行う必要があり、これは手間がかかります。
一方、Cloud KMSを利用したCMEK（顧客管理の暗号化キー）は、Google Cloud上で鍵のライフサイクル管理が可能なため、この問題の要件をより効果的に満たします。
選択肢：デフォルトでの暗号化を使用します
この選択肢が正しくない理由は以下の通りです。
デフォルトの暗号化では、鍵のライフサイクルを自身で管理することは不可能です。要件である"鍵のライフサイクルを管理できる"という点を満たせません。
それに対して、Cloud KMSを使用したCMEKは、暗号化キーのライフサイクルを顧客が管理できるため、問題の要求を満たします。
選択肢：Google Cloudに転送する前にファイルを事前暗号化し、分析に利用します
この選択肢が正しくない理由は以下の通りです。
ファイルを事前に暗号化する方法では、クラスター上のブートディスクの暗号化に直接対応できず、また、鍵のライフサイクル管理も提供できません。
一方、Cloud KMSを利用するとCMEKを使ってディスクの暗号化が可能であり、鍵のライフサイクル管理も可能となります。
参考リンク：
https://cloud.google.com/compute/docs/instances/encrypt-disks-with-cmek
https://cloud.google.com/kms/docs
https://cloud.google.com/compute/docs/instances/create-start-instance#starting_an_instance_with_encryption_key
</div></details>

### Q.  問題9: 未回答
あなたは、2つのネットワークセグメントを設定する必要があります。1つは信頼できないサブネット、もう1つは信頼できるサブネットです。2つのネットワークセグメント間のすべてのトラフィックを検査するように、次世代ファイアウォール（NGFW）などの仮想アプライアンスを構成したいと考えています。トラフィックを検査するにはネットワークをどのように設計すればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ネットワークセキュリティと隔離を強化するためのGoogle Cloudのネットワーク設計について問われています。2つの異なる信頼レベルのネットワークセグメントの間でトラフィックを検査するための仮想アプライアンスの設置が必要なシナリオです。この要件を満たすためには、各ネットワークセグメントを正しく定義し、それぞれに対して適切なアクセスポリシーを適用するネットワーク設計を理解することが重要です。また、仮想アプライアンスの配置とその接続方法にも注意を払う必要があります。これらの要素を考慮に入れ、四つの選択肢から最も適切なネットワーク設計を選ぶことが求められています。
基本的な概念や原則：
VPCネットワーク：Google Cloudの仮想プライベートクラウド（VPC）ネットワークは、仮想ネットワークリソースであり、物理的なプロセスをシミュレートするのに役立ちます。これは各プロジェクトのプライベートIPアドレススペースとなります。
サブネット：VPCネットワーク内のIPアドレス範囲。サブネットを用いることでネットワーク空間を区切ることができます。
次世代ファイアウォール （NGFW）：トラフィックの内容に基づいてパケットを許可またはブロックするための高度なセキュリティ機能を備えたファイアウォールの一種です。
仮想アプライアンス：ソフトウェアバージョンのネットワークアプライアンス（ファイアウォール、VPNデバイスなど）のことです。
複数のネットワークインターフェイス：物理デバイスまたは仮想アプライアンスが複数のネットワークに同時に接続するための方式です。
VPCピアリング：2つのVPCネットワーク間でトラフィックをプライベートに交換するための接続です。
カスタムルート：特定のデスティネーションへのネットワークトラフィックのパスを制御するのに使用されるネットワークルートです。
正解についての説明：
（選択肢）
・1. 2つのVPCネットワークをセットアップします。1つは信頼できるネットワーク、もう1つは信頼できないネットワークです
2. 複数のネットワークインターフェイスを使用して仮想アプライアンスを構成し、各インターフェイスがVPCネットワークの1つに接続されます
この選択肢が正解の理由は以下の通りです。
VPCネットワークを2つ設定することで、信頼できるネットワークと信頼できないネットワークが物理的に分離され、それぞれが個別のネットワーク空間を占有します。これによって、2つのネットワーク間のセキュリティを大幅に向上させることが出来ます。これは、一部の組織では信頼されたネットワークのセキュリティ確保が最優先課題となり、あらゆる予防措置を導入することが求められるので重要です。
また、複数のネットワークインターフェースを使用して仮想アプライアンスを構成することで、1つの信頼されたVPCネットワークからもう1つのVPCネットワークへ向かうすべてのネットワークトラフィックを検査できます。これによって、立たされたセキュリティポリシーに従い、要求に対する回答や、その逆のトラフィックを詳細に検査することができます。これは、侵入検知・防止システム（IDS/IPS）などのセキュリティ監視機能を実装するのに適しています。特に、次世代ファイヤーウォール（NGFW）などの仮想アプライアンスは、複数のネットワークインターフェースを持つことが一般的で、この要件を満たす設定が可能です。
不正解についての説明：
選択肢：1. 2つのサブネット（1つは信頼できるサブネット、もう1つは信頼できないサブネット）を持つ1つのVPCをセットアップします
2. 仮想アプライアンスを指すすべてのトラフィック（0.0.0.0/0）のカスタムルートを構成します
この選択肢が正しくない理由は以下の通りです。
同一のVPC内のサブネット間では直接トラフィックを送受信できますが、NGFWで検査するためには別々のネットワークが必要です。
したがって、1つのVPC内に2つのサブネットを作成すると、全てのトラフィックがNGFWを経由するわけではないため、必要なセキュリティ要件が満たされません。
選択肢：1. 2つのサブネット（1つは信頼できるサブネット、もう1つは信頼できないサブネット）を持つ1つのVPCをセットアップします
2. 仮想アプライアンスを指すすべてのRFC1918サブネットのカスタムルートを構成します
この選択肢が正しくない理由は以下の通りです。
2つのサブネットを1つのVPCで設定すると、信頼できないサブネットと信頼できるサブネット間の通信が自由になってしまいます。仮想アプライアンスがネットワーク間の全てのトラフィックを検査するためには、これらのネットワークは分離されていなければならず、正解選択肢のように2つの独立したVPCを設定するべきです。
選択肢：1. 2つのVPCネットワーク（1つは信頼できるネットワーク、もう1つは信頼できないネットワーク）をセットアップし、相互にピアリングします
2. 仮想アプライアンスを指す各ネットワーク上にカスタムルートを構成します
この選択肢が正しくない理由は以下の通りです。
VPCネットワーク間のピアリングはトラフィックを中継する能力がないため、仮想アプライアンス経由のトラフィック検査を設定することはできません。正解では各ネットワークインターフェイスがアプライアンスを経由し、トラフィックを検査できるようにします。
参考リンク：
https://cloud.google.com/vpc/docs/vpc-peering
https://cloud.google.com/vpc/docs/using-vpc
https://cloud.google.com/network-connectivity/docs/vpn/concepts/topologies#multiple-vpc-networks
</div></details>

### Q.  問題10: 未回答
ある組織が、現在のオンプレミス生産性ソフトウェアシステムからG Suiteに移行しようとしています。以前のオンプレミスシステムでは、地域の規制機関によって義務付けられたネットワークセキュリティ管理が行われていました。同組織のリスクチームは、G Suiteでもネットワークセキュリティ管理が維持され、有効であることを確認したいと考えています。この移行をサポートするセキュリティアーキテクトは、組織とGoogle Cloudとの間の新しい責任共有モデルの一部として、ネットワークセキュリティ管理が確実に実施されるようにすることを求められています。
どのようなソリューションが要件を満たすのに役立ちますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、組織がオンプレミスシステムからG Suiteへの移行を検討しているケースが提示されています。セキュリティアーキテクトは、地域の規制に対応したネットワークセキュリティ管理が維持されるように要求されています。問題文の情報を解釈すると、G SuiteというSaaS製品を適用することで、それ自体がビルトインのセキュリティソリューションを持つと思われます。これは、Googleが提供するクラウドサービスの一部としての責任を理解して選択肢を見ることが重要です。その上で、各選択肢のG Suiteとの統合と規制への対応を評価し、適切な答えを選ぶべきです。
基本的な概念や原則：
G Suite：Googleが提供するクラウドベースのビジネス向けプロダクトスイートです。メール、カレンダー、ドキュメント作成、ストレージなどのサービスを提供しています。
オンプレミスシステム：企業が自社の施設内などに設置する形で情報システムを運用する方式のことです。全ての管理と保守が自分たちの責任となります。
ネットワークセキュリティ管理：ネットワーク内のユーザーやシステム、データなどを保護するための施策や戦略です。"ファイアウォールルール"などを確認して適切に設定し、不正アクセスやデータ漏洩などを防ぎます。
責任共有モデル：クラウドサービスのセキュリティ面での責任を、サービス提供者と利用者で分担する考え方です。サービス提供者と利用者がどの部分について責任を持つかはサービスによります。
ビルトインセキュリティ：ソフトウェア、ハードウェア、システムの設計段階から組み込まれるセキュリティ機能のことで、G SuiteなどのSaaS製品には基本として含まれています。
SaaS製品：サービスとして提供されるソフトウェアのことで、インフラやハードウェアについてはサービス提供者が管理し、ユーザーはアプリケーションを利用するだけです。
Cloud Armor：Google Cloudの分散型サービス拒否（DDoS）攻撃、SQLインジェクションなどのWeb攻撃からアプリケーションを保護するセキュリティサービスです。一方、G SuiteなどのSaaS製品はセキュリティが組み込まれているため、Cloud Armorをセットアップする必要はありません。
正解についての説明：
（選択肢）
・ネットワークセキュリティはビルトインソリューションであり、G SuiteのようなSaaS製品にはGoogleのクラウド責任があります
この選択肢が正解の理由は以下の通りです。
まず、Googleの責任共有モデルでは、Googleはデータセンターやネットワークといったインフラストラクチャーレベルのセキュリティを担当します。つまり、Googleはそのネットワークとデータセンターのセキュリティに対し完全な責任を負うため、組織自体がネットワークセキュリティ管理のために別途労力を割く必要はありません。
また、G SuiteはSaaS（Software as a Service）製品であり、これによりユーザーはアプリケーションレベルのセキュリティに専念できます。そのため、ネットワークセキュリティはGoogleが担当することで確保されます。
さらに、GoogleのSaaS製品は、ビルトインのセキュリティソリューションを採用しています。これにより、独自のセキュリティ対策を設定することなく、ネットワークを安全にすることが可能となります。これらの要素が組み合わさって、選択肢のソリューションは、地域の規制に対するネットワークセキュリティ管理の要件を満たす適切な選択肢となります。
不正解についての説明：
選択肢：ファイアウォールルールが必要なコントロールに適合していることを確認します
この選択肢が正しくない理由は以下の通りです。
G SuiteはSaaS製品であり、そのセキュリティ設定はGoogleが管理します。オンプレミス環境と同じように、ユーザーが制御できるなどといったファイアウォールルールを設定することは出来ないからです。そのため、この選択肢はこのシナリオには適していません。
選択肢：Cloud Armorをセットアップして、G Suiteのネットワークセキュリティコントロールが管理できるようにします
この選択肢が正しくない理由は以下の通りです。
Cloud Armorは、主にGoogle Cloudのアプリケーションに対するDDoS攻撃やWEB攻撃を防ぐためのセキュリティサービスですが、G Suiteに適用することはできません。G Suiteのネットワークセキュリティ管理はGoogleが担当し、Cloud Armorを使って追加で設定する必要はありません。
選択肢：仮想プライベートクラウド（VPC）ネットワークを構築し、関連規則に従ってネットワークセキュリティを管理します
この選択肢が正しくない理由は以下の通りです。
VPCネットワークの構築と管理は、ネットワークのインフラストラクチャレベルでのセキュリティを提供しますが、G SuiteのようなSaaS製品はそのネットワークセキュリティがGoogleによって既に管理されています。
したがって、この選択肢は冗長であり、G Suiteの利用において必要以上の作業となります。
参考リンク：
https://cloud.google.com/security
https://cloud.google.com/docs/security/best-practices
https://support.google.com/a/answer/7587183?hl=en
</div></details>

### Q.  問題11: 未回答
あるデータベース管理者が、Cloud SQLインスタンス内で悪意のあるアクティビティが行われていることに気づきました。データベース管理者は、リソースの構成またはメタデータを読み取るAPI呼び出しを監視したいと考えています。データベース管理者はどのログを確認すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud SQLインスタンスでの悪意のあるアクティビティを検出するための適切なログタイプを特定する必要があります。問題文のキーワードは"リソースの構成またはメタデータを読み取るAPI呼び出し"です。データベース管理者が監視したいのは読取り操作、つまりデータへのアクセスです。そのため、四つの選択肢の中からリソースへのアクセスに関連するログを選ぶことが重要です。
基本的な概念や原則：
データアクセスログ：Google Cloud上のリソースへの読み書きアクセスを記録するログです。このログは、消費されたリソースに基づいて課金され、リソースの内容や属性を表示します。
管理者活動ログ：Google Cloudサービスの管理操作を記録するログです。これには、リソースの作成、変更、削除など、大部分の書き込み操作が含まれます。
システムイベントログ：Google Cloudのインフラストラクチャサービスがシステムイベントを記録するログです。これには、スケジュールされたメンテナンスなど、ユーザーが直接制御できないイベントが含まれます。
アクセスの透明性ログ：Google Cloudのエンジニアやサポートスタッフが顧客データにアクセスした時のログです。これには、アクセス時間、アクセス理由、アクセスしたデータの場所や種類などの情報が含まれます。
正解についての説明：
（選択肢）
・データアクセス
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、監視やログの分析にCloud Audit Logsを使用します。Cloud Audit Logsには管理活動ログとデータアクセスログの2つの主要な種類があります。管理活動ログはAPI呼び出しや、ユーザーアクティビティなどの管理操作を記録します。一方でデータアクセスログはリソースの読み取り、書き込み、更新操作を記録します。
したがって、データベース管理者がCloud SQLインスタンス内での悪意のあるアクティビティを調査したい場合、それがリソースの構成またはメタデータの読み取りに関連していると仮定すると、データアクセスログを確認することが適切です。
不正解についての説明：
選択肢：管理者活動
この選択肢が正しくない理由は以下の通りです。
管理者活動のログは、リソースの作成、変更、削除など、Google Cloudのリソースまたはサービスを管理する操作を監視します。しかし、問題の要件はAPIの読み取り操作の監視であり、これはデータアクセスのログの範囲に含まれるため、管理者活動のログでは要件を満たせません。
選択肢：システムイベント
この選択肢が正しくない理由は以下の通りです。
システムイベントログは、リソースのライフサイクルイベントの監視に用いられますが、リソースの構成やメタデータを読み取るAPI呼び出しの監視には不適切です。反対に、データアクセスログはAPI呼び出しを監視するためのものです。
選択肢：アクセスの透明性
この選択肢が正しくない理由は以下の通りです。
アクセスの透明性はGoogleの管理者によるアクセスを追跡するためのものであり、Cloud SQLインスタンスにおけるユーザーのアクションを監視することはできません。
一方、データアクセスログはリソースの構成やメタデータの読み取りを確認できます。
参考リンク：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/auditing
https://cloud.google.com/sql/docs/mysql/admin-api/logging
</div></details>

### Q.  問題12: 未回答
コンプライアンス上の理由から、組織は範囲内のPCI Kubernetesポッドが"範囲内の"ノードのみに存在することを確認する必要があります。これらのノードには"スコープ内の"ポッドのみを含める必要があります。
組織はこの目標をどのように達成すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のノードでのみ特定のKubernetesポッドを実行する必要があるシナリオが設定されています。また、これらのノードにはこれらの特定のポッドのみが存在できると明記されています。これらの要件を満たすために、Kubernetesの仕組みや概念を理解し、適切な選択肢を選ぶことが求められます。選択肢を評価する時には、ノード制御とポッドのスケジューリングに関連する解決策を探し、組織がポッドが特定のノードに限定されていることを確実に保証できることを確認してください。
基本的な概念や原則：
Kubernetesのテイント（Taint）：ノードが特定のポッドのスケジューリングを受け付けないように設定する機能です。特定のロールや制限のあるノードへのポッドのスケジューリングを制御できます。
Kubernetesの許容範囲（Toleration）：テイントが設定されたノード上でポッドが実行できるようにする設定です。ポッドが特定のテイントを持つノードにスケジュールされるための条件を設定できます。
nodeSelector：Kubernetesの機能で、ポッドが特定のノード上で実行されるように指定できます。ノードに付けられたラベルと一致するポッドのみがそのノード上でスケジュールされます。
ノードプール：特定の設定或いは機能を持つノードの集合のことです。ノードプールを作成することで、特定のワークロードを特定のノード群にスケジュールすることが可能になります。
ポッドセキュリティポリシー：Kubernetesのセキュリティ設定の一つで、特定のポッドが実行するにあたり必要な権限や設定を管理します。
名前空間：Kubernetesクラスター内のリソースを論理的にグループ化したものです。名前空間を設定することで、リソースの管理やアクセス制御を柔軟に行うことができます。
正解についての説明：
（選択肢）
・ラベルinscope: trueを使用してノードにテイントを配置し、NoScheduleとポッド構成で一致する許容範囲を設定します
この選択肢が正解の理由は以下の通りです。
まず、Kubernetesにはノードを制御するための仕組みである"テイントとトレランス"があります。"テイント（Taint）"はノードに設定できるマーカーで、テイントが設定されたノードには指定したトレランス（tolerance）を持つポッドしかスケジュールされません。これにより、"範囲内の"ノードには"範囲内の"ポッドだけを配置するという要件を満たすことができます。
この設問の場合、"inscope: true"というラベルを使ってノードにテイントを配置し、"NoSchedule"を設定します。これにより、このラベルのテイントを許容する設定を持つポッド以外、新規のポッドがスケジュールされないように制御します。すなわち、"範囲内の"ポッドのみが"範囲内の"ノードにスケジュールされるため、コンプライアンスを満たすことが可能となります。
また、これにより予期しないポッドが"範囲内の"ノードに配置されることを防ぎ、セキュリティも確保することができます。
不正解についての説明：
選択肢：inscope: trueというラベルの付いたノードのみを使用するように、nodeSelectorフィールドをポッド構成に追加します
この選択肢が正しくない理由は以下の通りです。
nodeSelectorフィールドをポッド構成に追加すれば、"範囲内の"ノードが"範囲内の"PCI Kubernetesポッドにのみ使用されることを保証できますが、"範囲内の"ノードには"範囲内の"ポッドのみを含めるという要件を満たすことはできません。
これに対して、ノードにテイントを配置し、許容範囲を設定することで、ノードとポッドの両方で範囲制限が可能となります。
選択肢：ラベルinscope: trueを使用してノードプールを作成し、そのラベルが付いているノード上でのみポッドの実行を許可するポッドセキュリティポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
ノードプールを作成し、ポッドセキュリティポリシーを適用する方法では、特定のノードにポッドがスケジュールされることを保証することはできません。
それに対して、正解のテイントと許容範囲を使用する方法はノードの選択性を提供し、"範囲内の"ノードに対して制御を行うことができます。
選択肢：名前空間"in-scope-pci"内のスコープ内のすべてのポッドを実行します
この選択肢が正しくない理由は以下の通りです。
名前空間"in-scope-pci"内でスコープ内のすべてのポッドを実行する事は、ポッドがスコープ内のノードに限定される保証を与えません。
一方、正解ではテイントと許容範囲を使用して、スコープ内のポッドが特定のノードにしかスケジュールされない事を確認しています。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/node-taints
https://cloud.google.com/kubernetes-engine/docs/concepts/pod-security-policies
https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
</div></details>

### Q.  問題13: 未回答
Cloud External Key Managerを使用して、Google Cloudの特定のBigQueryデータを暗号化するための暗号化キーを作成する必要があります。最初にどの手順を実行する必要がありますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudのBigQueryデータの暗号化に使用するためのキーを作成するよう求められています。具体的には、Cloud External Key Managerを用いたキーの作成手順について問われています。この問題を解く際には、Google Cloudの様々なサービスとその機能、特にCloud External Key Managerの機能と使い方を理解していることが重要で、それぞれの選択肢が指示する手順が、Cloud External Key Managerを使った適切なキー作成手順と一致するかどうかを慎重に見極める必要があります。
基本的な概念や原則：
Cloud External Key Manager（Cloud EKM）：Google Cloudのサービスの一つで、顧客管理の暗号化キー（CMK）の使用を可能にします。Cloud EKMを使用すると、Google Cloudのサービスに対して外部（サードパーティ）の鍵管理システムで管理されたキーを用いた暗号化を行うことができます。
Google Cloudプロジェクト：Google Cloudのすべてのリソースを管理するための組織単位。
一意の統一リソース識別子（URI）：リソースに一意にアクセスするための識別子。暗号化キーなどのリソースを指定する際に使用します。
鍵管理パートナーシステム：Google Cloud以外の暗号化キーを管理するシステム。Cloud EKMを使用してGoogle Cloudサービスからアクセスすることができます。
Cloud Key Management Service（Cloud KMS）：Google Cloudの暗号化キー管理サービス。自身のキーリングと暗号キーを作成および管理することができますが、Cloud EKMで使用するキーはGoogle Cloudプロジェクトで作成または指定する必要があります。
正解についての説明：
（選択肢）
・1.Google Cloudプロジェクトで、一意の統一リソース識別子（URI）を持つキーを作成するか、既存のキーを使用します
2.Google Cloudプロジェクトで、サポートされている外部の鍵管理パートナーシステムへのアクセスを許可します
この選択肢が正解の理由は以下の通りです。
まず、Cloud External Key Manager（EKM）は、自身で管理する暗号化キーを使用して、Google Cloudのデータを保護するためのサービスです。このサービスを使用するためには、一意のURIを持つキーの作成が最初のステップとして必要です。このキーはGoogle Cloudプロジェクト内で管理され、BigQueryデータの暗号化に使用されます。
続いて、外部の鍵管理パートナーシステムへのアクセスを許可することで、このキーを外部の鍵管理システムで管理することができます。Google Cloudは多くの主要な鍵管理パートナーとの統合をサポートしているので、この手順によりCloud EKMを有効に活用できます。
したがって、これらの手順はBigQueryデータの暗号化キーを作成し、それをCloud External Key Managerを通じて管理するための適切な手順となります。
不正解についての説明：
選択肢：1.Cloud Key Management Service（Cloud KMS）で、一意の統一リソース識別子（URI）を持つ鍵を作成するか、既存の鍵を使用します
2.Cloud KMSで、Google Cloudプロジェクトにキーを使用するためのアクセス権を付与します
この選択肢が正しくない理由は以下の通りです。
Cloud KMSはGoogle Cloud内部のキー管理システムで、External Key Managerは外部のキーマネージメントシステムとの連携を実現します。
したがって、Cloud KMSで鍵を作成・管理するのではなく、外部のキーマネージメントシステムで行う必要があります。
選択肢：1.サポートされている外部鍵管理パートナーシステムにおいて、一意の統一リソース識別子（URI）を持つ既存の鍵を作成または使用します
2.外部鍵管理パートナーシステムで、この鍵にGoogle Cloudプロジェクトを使用するためのアクセス権を付与します
この選択肢が正しくない理由は以下の通りです。
Google Cloudにおいて必要な設定を行い、その上でキーを作成するため、最初にGoogle Cloudプロジェクトで一意のURIを持つキーを作成または使用し、次にサポートされている外部の鍵管理パートナーシステムへのアクセスを許可する必要があります。
また、不正解の選択肢は最初から外部システムでの操作を行ってしまっています。
選択肢：1.Cloud Key Management Service（Cloud KMS）で、一意の統一リソース識別子（URI）を持つ外部鍵を作成します
2.Cloud KMSで、Google Cloudプロジェクトにキーを使用するためのアクセス権を付与します
この選択肢が正しくない理由は以下の通りです。
Cloud External Key Managerは外部の鍵管理システムで暗号化キーを管理するため、Cloud Key Management Serviceでキーを作成する必要はありません。
さらに、Google Cloudプロジェクトでキーへのアクセスを許可することが必要であり、Cloud KMSで設定するのは不適切です。
参考リンク：
https://cloud.google.com/bigquery/docs/encryption-customer-managed-keys
https://cloud.google.com/ekm/docs
https://cloud.google.com/kms/docs/external-key-managers
</div></details>

### Q.  問題14: 未回答
あなたの会社は、顧客の年齢層に応じて、クレジットスコアを向上させるためにどのような商品を構築できるかを判断したいと考えています。そのためには、会社のバンキングアプリのユーザー情報と、第三者から受け取った顧客のクレジットスコアデータを結合する必要があります。この生データを使用すればこのタスクを完了できますが、機密データを暴露することになり、新たなシステムに伝播する可能性があります。
このリスクには、データベース全体の参照整合性を維持しながら、Cloud Data Loss Preventionを使用して非識別化とトークン化で対処する必要があります。
これらの要件を満たすには、どの暗号トークン形式を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題は、データの暗号化方式を選択することが求められています。必要な要素は、参照整合性を維持しつつ、データを非識別化・トークン化することです。そのため選択肢を考える際には、データ非識別化と参照整合性維持の両方を達成できる暗号化形式を選ぶべきです。また、このケースでは生データの情報を保護するために、暗号トークン形式に特定の要件が求められていることに注意深く対応する必要があります。
基本的な概念や原則：
Cloud Data Loss Prevention（DLP）：データ保護のためのGoogle Cloudのサービスです。機密データの発見、分類、保護を自動化します。
非識別化：個人を特定できる情報を削除または変換することです。プライバシーとセキュリティを向上させるために使用されます。
トークン化：機密データをデータベースやファイル内の非機密要素に置き換えるプロセスです。オリジナルデータは別の場所に保存され、元に戻すためのトークンが提供されます。
決定論的暗号化：同じ入力値に対して常に同じ暗号文を生成する暗号化手法です。文脈やパターン分析で情報を推測できるリスクがありますが、参照整合性を保つ上で有用です。
安全なキーベースのハッシュ：一方向性のあるハッシュアルゴリズムで、元のデータを特定できない形でデータを変換します。しかし、参照整合性を維持することはできません。
フォーマット保持暗号化：データを暗号化しながらも、元のデータ形式を保持する暗号化手法です。しかし、参照整合性を維持する機能はありません。
暗号ハッシュ：一方向性のあるハッシュアルゴリズムで、元のデータを特定できない形でデータを変換します。参照整合性を維持することはできません。
正解についての説明：
（選択肢）
・決定論的暗号化
この選択肢が正解の理由は以下の通りです。
まず、決定論的暗号化は一貫性を保証する暗号化方式です。同じ入力値に対しては常に同じ暗号文が生成されます。これは、参照整合性の維持に重要です。参照整合性とは、データベース内の様々な部分で、同じ値が正確かつ一貫して引用されることを保証する仕組みです。データベース全体で一貫性を保つためには、同じ値が同じ暗号文に変換される暗号方式が必要となるため、決定論的暗号化が適しています。
また、Cloud Data Loss Preventionは、データの非識別化とトークン化を行うためのサービスで、決定論的暗号化をサポートしています。これにより、個人を特定できる情報を保護しつつ、データの分析や処理を可能にします。
したがって、機密データが新たなシステムに伝播するリスクを軽減するためには、決定論的暗号化が適しています。
不正解についての説明：
選択肢：安全なキーベースのハッシュ
この選択肢が正しくない理由は以下の通りです。
安全なキー基のハッシュを使用した場合、元のデータを復元することができません。ですが、問題要件は参照整合性を維持しながら非識別化を行うことを求めています。これは、ハッシュ関数ではなく、元のデータを復元可能な決定論的暗号化の特性が必要とされているためです。
選択肢：フォーマット保持暗号化
この選択肢が正しくない理由は以下の通りです。
フォーマット保持暗号化は元のデータ型や長さを保持しますが、それ自体は参照整合性を確保できません。決定論的暗号化を用いると、同じ平文に対しては常に同じ暗号文を生成します。これがデータベース全体の参照整合性を維持できます。
選択肢：暗号ハッシュ
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュは一方向の関数であり、変換後に元のデータに戻すことができません。このため、データ全体の参照整合性を維持するという要件を満たすことができません。
それに対して、決定論的暗号化は同じ入力から同じ暗号文を生成し、暗号文から元のデータを復元できるため、参照整合性を維持することが可能です。
参考リンク：
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/dlp/docs/deidentify-sensitive-data
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題15: 未回答
組織のGoogle CloudインスタンスのPCIコンプライアンスを評価したいと考えています。Google固有のコントロールを特定する必要があります。
情報を見つけるには、どのドキュメントを確認する必要がありますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudインスタンスのPCIコンプライアンスに焦点を当てています。組織がGoogle Cloud内で適用するべき具体的なPCIコンプライアンスに関連するGoogle固有のコントロールを特定したいと考えています。ここで重要なのは、Google Cloud環境における責任の分担を理解することで、選択肢からはGoogle Cloud固有のガイダンスとセキュリティ関連の情報を提供するものを選ぶことが求められています。また、Google Cloud特有の情報提供源を探すことが重要で、一般的なPCIコンプライアンスガイドよりもGoogle Cloudに特化したリソースを重視すべきです。
基本的な概念や原則：
Google Cloud：顧客責任マトリックス：Google Cloudにおけるセキュリティコントロールと関連する責任の分配を明示したドキュメントです。事業者とGoogleがそれぞれ持つ責任を理解するために重要です。
PCIコンプライアンス：クレジットカード情報の安全性を保証するための国際基準です。PCI DSS（Payment Card Industry Data Security Standard）という規格に準拠していることが求められます。
PCI DSS：クレジットカード情報を取り扱う企業が遵守すべき国際的なセキュリティ基準です。盗難や漏洩を防ぐための技術的、運用的要件を定めています。
PCI SSCクラウドコンピューティングガイドライン：PCI SSS（Payment Card Industry Security Standards Council）が提供する、クラウド環境でのPCI DSS準拠についてのガイドラインです。
Compute Engineの製品ドキュメント：Google Compute Engineに関する公式のドキュメンテーションです。プロダクトの使用方法や仕様について詳細な情報を提供しています。
正解についての説明：
（選択肢）
・Google Cloud：顧客責任マトリックス
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの顧客責任マトリックスは、Google Cloudの製品とサービスにおけるセキュリティとコンプライアンスの責任を明確に示すための公式ドキュメントです。これには、Google Cloudのインフラストラクチャ、製品、サービスに関するコントロールと、顧客が実装すべきコントロールの詳細な情報が含まれています。
したがって、PCIコンプライアンスを評価したい場合、このマトリックスを参照すれば、Googleが担当する部分と顧客が負うべき責任を理解することができます。
さらに、Google Cloudの顧客責任マトリックスは、特定の規制基準、たとえばPCI DSSなどに対してどのようなコントロールが必要かという詳細なガイダンスも提供しています。そのため、組織がGoogle CloudインスタンスのPCIコンプライアンスを評価するためには、このマトリックスを確認することが最適と言えます。
不正解についての説明：
選択肢：PCI DSSの要件とセキュリティ評価手順
この選択肢が正しくない理由は以下の通りです。
PCI DSSの要件とセキュリティ評価手順は、基本的なPCIコンプライアンスに必要なセキュリティ要件と手順を指摘しますが、これはGoogle Cloud特有のコントロールを特定する目的には合致しません。
対照的に、Google Cloud：顧客責任マトリックスはGoogle Cloudの標準と共有責任モデルを明示的に解説します。
選択肢：PCI SSCクラウドコンピューティングガイドライン
この選択肢が正しくない理由は以下の通りです。
PCI SSCクラウドコンピューティングガイドラインは一般的なクラウドサービスのコンプライアンスガイドラインを提供しますが、Google Cloud特有のコントロールについては明確に示されていません。
これに対して、Google Cloud：顧客責任マトリックスはGoogle Cloud特有のセキュリティとコンプライアンスのロールと責任を明確に示しています。
選択肢：Compute Engineの製品ドキュメント
この選択肢が正しくない理由は以下の通りです。
Compute Engineの製品ドキュメントでは特定の製品に関する説明や設定方法が記載されていますが、Google固有のPCIコンプライアンスに関する情報は含まれていません。
それに対して、"Google Cloud：顧客責任マトリックス"では、クラウドサービスのコンプライアンスを特定できるため正解です。
参考リンク：
https://cloud.google.com/docs/security/compliance/customer-responsibility
https://cloud.google.com/security/compliance/pci-dss
https://cloud.google.com/compute/docs
</div></details>

### Q.  問題16: 未回答
あなたは、Google Cloudで一般データ保護規則（GDPR）に準拠したいと考えています。そのために、EUにおけるデータレジデンシーと運用主権を導入する必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud上で一般データ保護規則（GDPR）に準拠し、データのレジデンシーと運用主権をEU内で保持する方法を問われています。問題文からは、データの物理的な配置の制限とGoogle Cloudのサービスによるデータへのアクセス制限が必要と読み取れます。ここで注意するのは、データ保護規則への準拠には、単にデータの所在地を管理するだけでなく、データへのアクセス管理も含まれるということです。これを念頭に置きながら、各選択肢を慎重に評価する必要があります。
基本的な概念や原則：
GDPR（General Data Protection Regulation）：ヨーロッパ連合におけるデータ保護とプライバシーに関する規則です。個人データの処理と移動を厳格に制御しています。
データレジデンシー：データが物理的に保存される位置（つまり、特定の国や地域）を指します。多くの法域では、特定の種類のデータ（特に個人データ）はそのリージョン内でのみ処理または保存する必要があります。
運用主権：システムの運用に対する制御や管理権を持つことを指します。通常、システムの所有者や管理者が運用主権を持ちます。
Organization Policy Service：Google Cloudの組織全体にポリシー制限を設定するためのサービスです。
Resource Locations Constraint：Organization Policy Serviceの機能で、リソースの物理的な場所を制限できます。
Key Access Justifications：Google Cloudの機能で、Google社員のアクセスを事前に定義された属性（国籍、ロケーション等）に基づいて制限します。
Cloud IDS/IDフェデレーション/VPCフローログ：これらのサービスや機能は、ネットワークのログ、監視、またはアクセス制御などの目的で使用されますが、データレジデンシーや運用主権を保証する具体的な機能はありません。
正解についての説明：
（選択肢）
・Organization Policy Serviceの "resource locations constraint"を使用して、新しいリソースの物理的な場所を制限します
・Key Access Justificationsを使用して、国籍や地理的ロケーションなど、事前に定義された属性に基づいてGoogle Cloudのサービスのアクセスを制限します
この選択肢が正解の理由は以下の通りです。
まず、一つ目の選択肢のOrganization Policy Serviceの "resource locations constraint"を使用することは、データの物理的な場所をEU内に制限するのに適しています。これはGDPRにおけるデータレジデンシー、つまりデータが特定の地理的な領域内に保管されていることを保証するための要件を満たします。
次に、二つ目の選択肢であるKey Access Justificationsを使用することで、Google Cloudのサービスのアクセスを事前に定義された属性、例えば国籍や地理的ロケーションなどに基づいて制限することができます。これはGDPRにおける運用主権、つまり誰がデータにアクセスできるかを制御することを可能にします。
これらの選択肢は、Google CloudでGDPRに準拠するための主要な要件を満たすことができます。
したがって、正答となります。
不正解についての説明：
選択肢：Cloud IDSを使用して、EU内のサーバー間と各階層間のトラフィックを可視化し、VPC内およびVPC間の通信を監視します
この選択肢が正しくない理由は以下の通りです。
Cloud IDSはトラフィックを可視化し、監視するためのツールですが、それ自体ではGDPRの要件であるデータレジデンシーと運用主権を確保するための機能を提供していません。
したがって、この問題の要件を直接満たす選択肢ではありません。
選択肢：IDフェデレーションを使用して、EU域外からのGoogle Cloudリソースへのアクセスを制限します
この選択肢が正しくない理由は以下の通りです。
IDフェデレーションを使用すると認証と認可を管理することができますが、それ自体はデータレジデンシーや運用主権を保証するものではありません。
また、GDPRの準拠のためには、物理的なデータの場所を制限するとともに、不適切なアクセスを制限する措置が必要で、IDフェデレーションだけでは足りません。
選択肢：VPCフローログを使用して、EU内のVPC内およびVPC間のトラフィックを監視します
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークのトラフィックパターンを監視するためのツールで、データの物理的な場所を制限したり、Google Cloudのサービスのアクセスを制限したりする機能はありません。これらの要件を満たすためには、Organization Policy ServiceやKey Access Justificationsが必要です。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-resource-locations
https://cloud.google.com/kms/docs/key-access-justifications
https://cloud.google.com/compliance/gdpr
</div></details>

### Q.  問題17: 未回答
ある組織は、従業員の異常値を特定し、収入格差を是正するために、賞与報酬の経年変化を追跡したいと考えています。このタスクは、個人の重要な報酬データを公開することなく実行されなければならず、異常値を特定するために元に戻すことができなければなりません。
どのCloud Data Loss Prevention APIの機能を使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社が従業員の賞与報酬のパターンを追跡しながら、個人情報のアウトプットを避けるためにどのCloud Data Loss Prevention APIの機能を使うべきかを問います。選択肢に挙げられているAPIの各機能は異なる種類の保護を提供しますが、要求される特性である"元に戻すことができる"点に焦点を当てる必要があります。選択肢の中でどの機能がこの条件を満たすのか、それぞれの機能がどのようにデータを処理するのかを理解することが重要です。
基本的な概念や原則：
フォーマット保持暗号化：Cloud DLPの機能の一つで、データを元に戻すことが可能な形式で保護します。元のデータと同じ形式を維持するため、一部のデータ分析操作を暗号化されたデータに対して実行することが可能です。
暗号ハッシュ：データを固定長の一意な文字列に変換しますが、元に戻すことが不可能な形式で保護します。
秘匿化：一部のデータを隠し、データを元戻しできないようにします。データの一部を保持しながら、情報の機密性を保護します。
一般化：個々のデータポイントをより大きなカテゴリーに置き換えることで、データの詳細度を低下させます。これによりデータの特定性が薄れ、プライバシー保護に貢献します。
Cloud Data Loss Prevention API：機密データの検出、クラス分類、保護（非可逆的および可逆的脱識別化）を行うためのサービスです。
正解についての説明：
（選択肢）
・フォーマット保持暗号化
この選択肢が正解の理由は以下の通りです。
フォーマット保持暗号化（FPE）は、Cloud Data Loss Prevention（DLP）APIの一部です。ここでは機密データをより無害な形式に変換しながら、データの元の詳細と有用性を維持します。FPEはテキストデータを他のテキストデータに変換しますが、変換後の値は元の値と同じフォーマットを保持します。
したがって、データの構造と有用性を維持したままで、機密データを安全に保護することができます。このため、フォーマット保持暗号化は、個々の重要な報酬データを保護しつつ、賞与報酬の経年変化を追跡する組織にとって最適な方法です。
さらに、FPEの結果は逆行できるため、必要に応じて元のデータに戻すことが可能です。これは異常値を特定する際に非常に役立ちます。
不正解についての説明：
選択肢：暗号ハッシュ
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュ機能を使用した場合、元のデータへ戻すことができません。これは、組織が異常値を特定するために必要な期待の動作とは異なります。
それに対して、フォーマット保持暗号化はデータを暗号化しつつも、元の形式を保持することができ、必要に応じて復号化することが可能です。
選択肢：秘匿化
この選択肢が正しくない理由は以下の通りです。
秘匿化はデータを隠蔽する一方で、元のデータに戻す機能を持っていません。問題文では異常値を特定するために元のデータに戻すことができなければならないとあります。
それに対して、フォーマット保持暗号化は元のデータ形式を保持しつつ暗号化し、復元が可能な形式に変換します。
選択肢：一般化
この選択肢が正しくない理由は以下の通りです。
一般化によるデータ変換は一方向であり、元の情報に戻すことができないため、異常値を特定する目的には適合しません。
一方、フォーマット保持暗号化は元のデータ形式を保ったままの暗号化を提供し、必要に応じて復元することが可能なため、情報の秘匿と利用の両立を達成できます。
参考リンク：
https://cloud.google.com/dlp/docs/concepts-format-preserving-encryption
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/solutions/masking-sensitive-data-using-cloud-dlp
</div></details>

### Q.  問題18: 未回答
Compute Engineインスタンス上で実行されているアプリケーションが、Cloud Storageバケットからデータを読み取る必要があります。あなたのチームは、Cloud Storageバケットがグローバルに読み取り可能であることを許可しておらず、最小特権の原則を確保したいと考えています。
あなたのチームの要件を満たすオプションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute EngineインスタンスがCloud Storageバケットからデータを読み取る際に最小特権の原則を保つ方法が求められています。問題文から、このバケットがグローバルに読み取り可能であることは許可されていないことがわかります。そのため、データアクセスを限定し、セキュリティを確保しながらどのようにインスタンスでバケットのデータ読み取りを行うかがポイントとなります。また、最小特権の原則の規則を理解していることも非常に重要で、不要なアクセス権を減らし、制限を強化する適切なソリューションを見つけることが求められます。
基本的な概念や原則：
Compute Engine：Google Cloudの仮想マシン（VM）を提供するインフラストラクチャas aサービス（IaaS）です。仮想マシンが実行される場所（データセンター）を選択でき、OSやその他のソフトウェアをインストール、実行できます。
Cloud Storage：Google Cloudのスケーラブルで耐久性の高いオブジェクトストレージです。任意の種類の非構造化データ（写真、ビデオ、バックアップ、ログファイルなど）を保存、取得できます。
サービスアカウント：アプリケーションや仮想マシンなど、Google Cloudのリソースに対するアクセスを制御するためのアカウントです。各サービスアカウントには一意の電子メールアドレスが割り当てられています。
読み取り専用アクセス：特定のリソースへの読み取りのみ可能なアクセス権限です。データの変更、削除、追加などは不可能です。
最小特権の原則：セキュリティの基本原則で、個々のユーザーやプログラムに、そのタスクを遂行するために必要最小限の権限とアクセスのみを付与する常識です。
ACL（Access Control Lists）: リソースへのアクセスを制御するための一連の許可ルールです。特定のユーザーやサービスアカウントがデータに対して何をして良いかを定義します。ネットワークやファイルシステムなどで広く使用されています。
Cloud KMS：Googleのキーマネージメントサービスで、暗号キーを作成、管理します。このキーは、Cloud StorageやBigQueryなど他のGoogle Cloudサービスでデータを暗号化するために使用できます。
正解についての説明：
（選択肢）
・Cloud Storageバケットへの読み取り専用アクセス権を持つサービスアカウントを使用して、インスタンスメタデータから認証情報を取得します
この選択肢が正解の理由は以下の通りです。
まず、サービスアカウントはGoogle Cloud上でアプリケーションに対するセキュアな識別と認証を提供する重要な仕組みであり、特定のアクセス権を持つことができます。この場合、読み取り専用アクセス権を持つサービスアカウントを使用すれば、最小特権の原則を満たしつつ、アプリケーションがCloud Storageバケットからデータを適切に読み取ることが可能となります。
次に、インスタンスメタデータから認証情報を取得することにより、Compute Engineインスタンスがサービスアカウントに自動的に認証されるように設定することが可能です。そのため、これはセキュリティの観点からも望ましい方法であり、設定管理の複雑さも少なくなります。
さらに、Cloud Storageバケットの公開が認められていない場合でも、正認のサービスアカウントを用いることで安全にアクセスが制御できるため、要件を満たしていると言えます。
不正解についての説明：
選択肢：Compute EngineインスタンスのIPアドレスからの読み取り専用アクセスを許可し、アプリケーションが認証情報なしでバケットから読み取ることを許可するCloud Storage ACLを作成します
この選択肢が正しくない理由は以下の通りです。
最小特権の原則を確保したい場合、IPアドレスからの読み取りアクセスの許可では原則が満たされません。IPアドレスは個別のアプリケーションやユーザーにリンクされていないため、サービスアカウントを使用して特定の資格情報を持つアクセスを管理するのは効果的でありません。
選択肢：Cloud Storageバケットに読み取り専用でアクセスできるサービスアカウントを使用し、Compute Engineインスタンス上のアプリケーションのconfigにサービスアカウントの認証情報を保存します
この選択肢が正しくない理由は以下の通りです。
認証情報をアプリケーションのconfigに直接保存することは、最小特権の原則に反します。
また、この方法は認証情報が漏洩するリスクがあります。正解の選択肢と比べると、インスタンスメタデータから認証情報を取得する方がセキュリティが高いです。
選択肢：Cloud KMSを使ってCloud Storageバケット内のデータを暗号化し、アプリケーションがKMSキーでデータを復号化できるようにします
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Service（KMS）はデータの暗号化と復号化に使用されますが、アクセス制御を実装するためのものではありません。そのため、この方法ではアプリケーションがCloud Storageバケットのデータを読み取るための最小特権の原則を守ることができません。
参考リンク：
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/storage/docs/access-control/iam-permissions
https://cloud.google.com/compute/docs/storing-retrieving-metadata
</div></details>

### Q.  問題19: 未回答
セキュリティ脆弱性評価を完了した後、クラウド管理者がGoogle Cloud CLIセッションを何日も開いたままにしていることを知りました。これらのセッションを最小限の期間に設定することで、これらのオープンセッションを悪用する攻撃者のリスクを減らす必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのセキュリティ設定に関連した問題が提示されています。特に、クラウド管理者が開いたままにしているGoogle Cloud CLIセッションの厳密な制御に関する解決策について求められています。そのため、選択肢を評価する際には、Google Cloudの認証とセッションの管理に関連する各設定やポリシーを理解した上で、具体的な時間制限の設定により開かれたセッションを最小限に維持する解決策を選択することが重要です。
基本的な概念や原則：
Google Cloud Session Control：Google Cloudのユーザーおよびサービスアカウントのセッションの有効期間を制御する機能です。再認証頻度の設定により、セキュリティリスクを管理します。
再認証頻度：ユーザーが一度認証した後、引き続きセッションが有効であることを証明するために再度認証する必要がある頻度のことです。この頻度を高く設定することで、無許可のアクセスリスクを下げることができます。
組織ポリシー：Google Cloudでリソースの使用を制御するためのルールです。特定の制約を設定して、リソースの使用方法を規定します。
constraints/iam.allowServiceAccountCredentialLifetimeExtension：この組織ポリシー制約を使用して、サービスアカウントの資格情報の有効期限を超えて延長可能かどうかを制御します。
constraints/iam.serviceAccountKeyExpiryHours：この組織ポリシー制約を使用して、サービスアカウントキーの有効期限を制御します。
正解についての説明：
（選択肢）
・Google Cloud Session Controlの再認証頻度を1時間に設定します
この選択肢が正解の理由は以下の通りです。
Google Cloud Session Controlは、ユーザーセッションの再認証の頻度を設定するための機能です。これを使用して再認証頻度を1時間に設定することで、CLIセッションが何日も開いたままになることを防げます。再認証が要求されると、ユーザーは再度クレデンシャルを提供し、その認証情報が現在も有効であることを確認する必要があります。これにより、攻撃者が不適切にオープンセッションを利用するリスクを軽減できます。なぜなら、攻撃者がセッションを乗っ取りたいと思っても、1時間ごとに再認証が求められるため、そのセッションを長時間保持することは難しくなるからです。
したがって、Google Cloud Session Controlの再認証頻度を1時間に設定することは、セキュリティ上の理由からオープンセッションの期間を最小限に抑えるのに役立ちます。
不正解についての説明：
選択肢：Google Cloud Session Controlのセッション時間を1時間に設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Session Controlでは"セッション時間"を設定することはできません。正しくは"再認証頻度"を設定します。再認証頻度は、指定した時間ごとにユーザーに再ログインを求める機能で、これによって無期限に開かれたセッションを防ぎます。
選択肢：組織ポリシー制約constraints/iam.allowServiceAccountCredentialLifetimeExtensionを1時間に設定します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約constraints/iam.allowServiceAccountCredentialLifetimeExtensionは、サービスアカウントの資格情報の有効期間を制御します。しかしながら、CLIセッションの有効期間や再認証頻度の設定はGoogle Cloud Session Controlで行います。この選択肢はCLIセッションの管理とは無関係ため不正解です。
選択肢：組織ポリシー制約constraints/iam.serviceAccountKeyExpiryHoursを1時間に設定し、inheritFromParentをfalseに設定します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約constraints/iam.serviceAccountKeyExpiryHoursはサービスアカウントキーの有効期限を制御しますが、これはGoogle Cloud CLIセッションの持続時間を管理するものではありません。
正解の選択肢は、Google Cloud Session Controlの再認証頻度を1時間に設定することで、CLIセッションの持続期間を最小限に抑えることができます。
参考リンク：
https://cloud.google.com/iam/docs/configuring-reauthentication
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/sdk/gcloud/reference/auth/login
</div></details>

### Q.  問題20: 未回答
あなたの会社のメッセージングアプリは、FIPS 140-2に準拠するために、Google Cloudのコンピュートおよびネットワークサービスを使用することを決定しました。メッセージングアプリのアーキテクチャには、Compute Engineインスタンスのクラスターを制御するManaged Instance Group（MIG）が含まれています。インスタンスは、データキャッシングにローカルSSDを使用し、インスタンス間の通信にUDPを使用しています。アプリ開発チームは、標準に準拠するために必要な変更を行うことを望んでいます。
要件を満たすために、どのオプションを推奨しますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、FIPS 140-2への準拠という制約の下でGoogle Cloudのコンピュートおよびネットワークサービスを使用したメッセージングアプリケーションを設計する問題に取り組んでいます。要件には、キャッシュストレージとインスタンス間通信の暗号化も含まれています。したがって問題を解くためには、FIPS 140-2に準拠した暗号化技術やプロトコルについて理解する必要があります。また、UDPやローカルSSDの使用についても、これらの技術が準拠を満たすためにどのように利用され、あるいは変更されるべきかを評価することが求められます。このような観点から選択肢を読み解くことで、最も適切な解決策を選ぶことができます。
基本的な概念や原則：
FIPS 140-2：アメリカ国立標準技術研究所（NIST）が定めるセキュリティ要件です。暗号化モジュールがFIPS 140-2に準拠しているかを評価する基準として使用されます。
Compute Engine：Google CloudのインフラストラクチャAs-a-Service（IaaS）です。仮想マシンをデプロイと管理するためのサービスです。
Managed Instance Group（MIG）：Compute Engineインスタンスのグループを管理するための仕組みです。自動スケーリング、ローリングアップデート、自動ヒーリングなどをサポートしています。
BoringCrypto：Googleが開発したFIPS 140-2に準拠した暗号化ライブラリです。Googleのプロダクトで使用される暗号化演算の信頼性を向上するために開発されました。
ローカルSSD：Compute Engineインスタンスに直接接続された、高速で一時的なブロックストレージです。主に高いIOPS（Internet Operations Per Second）と低い遅延を必要とするアプリケーションに使用されます。
UDP通信：インターネット通信プロトコルの一つです。TCPとは異なり、通信の確認を行わないため、速度は速いものの信頼性が低いとされています。
ディスク暗号化：データを盗難や漏洩から保護するために、データを暗号化することです。顧客管理キーやGoogle-managed Keyを使用してディスク暗号化を行うことができます。
正解についての説明：
（選択肢）
・BoringCryptoモジュールを使用して、すべてのキャッシュストレージとVM間通信を暗号化します
この選択肢が正解の理由は以下の通りです。
まず、BoringCryptoモジュールはGoogleが提供するFIPS 140-2に準拠した暗号化モジュールで、必要なセキュリティ標準を満たす能力があります。すべてのキャッシュストレージとVM間通信を暗号化することは、FIPS 140-2の要求を満たす最善の手段となります。
また、BoringCryptoモジュールはCompute Engine上で動作し、ローカルSSDのデータキャッシングやUDPを使用したインスタンス間の通信など、既存のアーキテクチャの要素に影響を与えない暗号化ソリューションを提供します。これはアプリ開発者が必要としている準拠のための変更を最小限に抑えられる点で非常に重要です。
したがって、この選択肢が最適な解決策となります。
不正解についての説明：
選択肢：MIGが使用するインスタンステンプレートのディスク暗号化を顧客管理キーに設定し、インスタンス間のすべてのデータ転送にBoringSSLを使用します
この選択肢が正しくない理由は以下の通りです。
まず、ディスク暗号化を顧客管理キーに設定してもキャッシュストレージ自体の暗号化は行われないため、FIPS 140-2の要件を満たしません。
また、BoringSSLはFIPS 140-2準拠ではないため、正しくないです。正解のBoringCryptoはFIPS 140-2認定を持っています。
選択肢：アプリのインスタンス間通信をUDPからTCPに変更し、クライアントのTLS接続でBoringSSLを有効にします
この選択肢が正しくない理由は以下の通りです。
UDPからTCPへの変更とクライアントのTLS接続でのBoringSSLの有効化はデータの送受信を暗号化するために役立ちますが、これはデータのインスタンス間通信のみに影響し、データキャッシングに使用されるローカルSSDの暗号化には関わりません。
一方、BoringCryptoモジュールを使用すれば、キャッシュストレージとVM間通信の両方を暗号化するため、FIPS 140-2の要件をより全面的に満たすことができます。
選択肢：MIGが使用するインスタンステンプレートのディスク暗号化をGoogle-managed Keyに設定し、すべてのインスタンス間通信でBoringSSLライブラリを使用します
この選択肢が正しくない理由は以下の通りです。
まず、Google-managed Keyではなく、BoringCryptoがFIPS 140-2に準拠しています。
さらに、BoringSSLはFIPS 140-2に準拠していないため、これを使用することはFIPS要件を満たすことができません。この要件を満たすためには、FIPS 140-2に準拠した暗号化モジュールを使用するべきです。
参考リンク：
https://cloud.google.com/security/fips
https://cloud.google.com/compute/docs/disks#encryption
https://cloud.google.com/compute/docs/instances/encrypt-instance-communication
</div></details>

### Q.  問題21: 未回答
あなたは、規制の厳しい業界のミッションクリティカルなワークロードを管理しています。このワークロードは、エンドポイントコンピュータからCloud Storageにアップロードされた後の機密データの分析と処理にCompute Engine VMを使用しています。コンプライアンスチームは、このワークロードが機密データのデータ保護要件を満たしていないことを検出しました。データ保護要件は以下の通りです：
- データ暗号化キー（DEK）をGoogle Cloud境界外で管理します。
- サードパーティプロバイダを通じて暗号化キーを完全に管理します。
- 機密データをCloud Storageにアップロードする前に暗号化します。
- Compute Engine VMでの処理中に機密データを復号化します。
- Compute EngineVMで使用中のメモリ内の機密データを暗号化します。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudを使用して、機密データの保護を強く規制された業界で実施するための最適なソリューションを特定することが求められています。問題文から、データ暗号化キーはGoogle Cloud外部で管理する必要があり、データはCloud Storageにアップロードする前に暗号化し、Compute Engine VMで処理中はメモリ内のデータは暗号化されたままであることが要求されています。これを達成するための最適なサービスや構成を選択するためには、Google Cloudの暗号化周りの機能やサービスを理解していることが重要です。また、選択肢の中にはほぼ同じ動作をするものがありますが、細かい要件に注意してそれぞれの違いを理解することが必要です。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、大量の不構造化データを保存・取得することが可能です。データは自動的に暗号化されますが、より高いセキュリティ要件を満たすためのキー管理オプションも提供されています。
Cloud External Key Manager：Google Cloudのサービスで、Google Cloud外部のキーマネージメントシステムを使ってGoogle Cloudリソースの暗号キーを管理します。これにより、ユーザーはキーの完全なコントロールを保持しながら、Google Cloudの強力なデータ保護機能を利用できます。
Compute Engine VM：Google Cloudの仮想マシンサービスです。高度なカスタマイズが可能であり、各種ワークロードに対応します。
Confidential VM：Google Cloudのサービスで、メモリ内データの暗号化を提供します。これにより、稼働中のVMで機密データが保護されます。
Customer Managed Encryption Keys：ユーザーがGoogle Cloudで暗号化キーを生成、管理する方法です。しかし、完全なキー管理をサードパーティに委託する要件を満たすには不十分です。
VPC Service Controls：Google Cloudのサービス、データへのアクセスを制御するセキュリティ機能です。しかし、これによって暗号化キーの管理やデータの暗号化・復号化は実現できません。
正解についての説明：
（選択肢）
・機密データがCloud Storageにアップロードされる前に暗号化し、機密データがVMにダウンロードされた後に復号化するようにCloud External Key Managerを構成します
・機密データにアクセスするために、Compute EngineVMをConfidential VMに移行します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのExternal Key Managerは、Google Cloudの外部にある鍵管理システムから暗号化キーを使用することを可能にします。これにより、データ暗号化キーの管理をGoogle Cloudの外で行うという要件を満たすことができます。
さらに、クライアント側の暗号化を通じて、データがCloud Storageにアップロードされる前に暗号化され、VMでダウンロードされた後に復号化されるように設定できます。これにより、二つめの要件であるサードパーティプロバイダを通じて暗号化キーを完全に管理することも可能になります。またGoogle CloudのExternal Key Managerを使えば、クライアント側で暗号化されたデータをGoogle Cloud上で復号化して処理するという機能もあります。これにより、四つ目の要件であるCompute Engine VMでの処理中に機密データを復号化するという要件も満たすことができます。
次に、Google CloudのConfidential VMsは、メモリ暗号化技術を利用してメモリ内のデータを暗号化します。これにより、Compute EngineVMで使用中のメモリ内の機密データの暗号化という要件を満たすことができます。Confidential VMsは、データを保護しながら、パフォーマンスを犠牲にすることなくワークロードを実行することができるため、規制の厳しい業界のミッションクリティカルなワークロードに対応するには最適な選択と言えます。
不正解についての説明：
選択肢：Customer Managed Encryption Keysを設定して、機密データをCloud Storageにアップロードする前に暗号化し、機密データをVMにダウンロードした後に復号化します
この選択肢が正しくない理由は以下の通りです。
Customer Managed Encryption KeysはGoogle Cloud内で管理されるため、データ暗号化キー（DEK）をGoogle Cloud境界外で管理するというデータ保護要件を満たしません。
したがって、サードパーティプロバイダを通じて暗号化キーを完全に管理する、という要件も満たせません。
これに対し、Cloud External Key Managerを使用すれば、Google Cloud境界外で暗号化キーの管理が可能となります。
選択肢：機密データにアクセスするためのConfidential VMを作成します
この選択肢が正しくない理由は以下の通りです。
単にConfidential VMを作成するだけでは十分な保護は実現できません。Cloud External Key Managerを用いてDEKをGoogle Cloud外で管理し、それを用いてデータを暗号化、復号化する処理が必要となります。
選択肢：既存のCompute Engine VMとCloud StorageバケットにまたがるVPC Service Controlsサービス境界を作成します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsは、データの流出を防ぐためにGoogle Cloudサービスとのデータ交換を制御するのに有効ですが、その機能自体はデータ暗号化やキー管理に関連しません。
したがって、機密データの保護要件を満たすための適切な解決策とは言えません。
参考リンク：
https://cloud.google.com/security-key-management/external-key-manager
https://cloud.google.com/compute/confidential-vm/docs
https://cloud.google.com/storage/docs/encryption/customer-managed-keys
</div></details>

### Q.  問題22: 未回答
オンプレミスのデータウェアハウスをBigQuery、Cloud SQL、Cloud Storageに移行しようとしています。データウェアハウスのセキュリティサービスを構成する必要があります。会社のコンプライアンスポリシーにより、データウェアハウスは以下の要件を満たす必要があります：
- 暗号鍵の完全なライフサイクル管理により、静止状態のデータを保護します。
- データ管理とは別の鍵管理プロバイダーを導入します。
- すべての暗号化キー要求を可視化します。
データウェアハウスの実装にはどのようなサービスを含めるべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のコンプライアンスポリシーと互換性のある、適切なデータウェアハウスのセキュリティ策を選択することが求められています。具体的な要件は暗号鍵のライフサイクル管理、別の鍵管理プロバイダーの導入、そしてすべての暗号化キー要求の可視化です。これらを満たすための提供サービスの特性を理解し、選択肢から正しい組み合わせを選ぶことが必要です。
基本的な概念や原則：
Key Access Justifications：Googleが顧客のデータをアクセスした理由を説明するための機能です。すべての暗号化キー要求を可視化し、より詳細なデータアクセス制御を可能にします。
Cloud External Key Manager（EKM）：Google Cloud外部で暗号化キーを管理するサービスです。データ管理と鍵管理を分離し、静止状態のデータの保護を強化します。
顧客管理の暗号化キー（CMEK）：Google Cloud上で顧客が自身で暗号キーを作成し管理する機能です。暗号キーのライフサイクルを顧客がコントロールします。
顧客指定の暗号化キー（CSEK）：Google Cloudのリソースを暗号化する際に顧客が指定した暗号化キーを使用する機能です。暗号キーの管理を顧客が担当します。
Access Transparency and Approval：Googleのエンジニアやサポートスタッフが顧客のデータにアクセスする際の透明性を提供し、必要に応じてそのアクセスを承認または拒否することが可能にする機能です。
正解についての説明：
（選択肢）
・Key Access Justifications
・Cloud External Key Manager
この選択肢が正解の理由は以下の通りです。
まず、"Key Access Justifications"は、暗号化キーのアクセス要求の可視化に重要なロールを果たします。この機能は、Google Cloudにおけるキーの使用要求を明確に表示し、それが許可される理由や許可を求める要求元を識別することを可能にします。これにより、暗号化キー使用の監視と管理が可能となり、すべての暗号化キー要求の可視化という要件を満たします。
次に、"Cloud External Key Manager"は、Google Cloud外部で暗号化キーのライフサイクルを管理するためのサービスです。つまり、キー管理をデータ管理とは別のプロバイダーに委託しました。これにより、静止状態のデータの完全な保護と暗号鍵の完全なライフサイクル管理が可能となります。External Key Managerは、暗号鍵の全ライフサイクルを管理し、データ保護要件の満足度を高めるための最良の選択となります。
これら2つのサービスを使用することにより、静止状態のデータの保護、鍵管理の独立性、暗号化キー要求の可視化という3つの重要なコンプライアンス要件を満たすことができます。
不正解についての説明：
選択肢：顧客管理の暗号化キー
この選択肢が正しくない理由は以下の通りです。
"顧客管理の暗号化キー"ではデータ管理と鍵管理を別々のプロバイダーで行うという要件を満たしません。一方"Cloud External Key Manager"は外部の鍵管理システムを使用でき、また"Key Access Justifications"は鍵要求の可視化を可能にします。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キー（CSEK）を使用しても、暗号鍵の完全なライフサイクル管理や別の鍵管理プロバイダーの導入という要件には対応できません。反対に、Cloud External Key Managerを用いると、外部の鍵管理サービスを利用でき、Key Access Justificationsは鍵要求の可視化を提供します。
選択肢：Access Transparency and Approval
この選択肢が正しくない理由は以下の通りです。
Access Transparency and Approvalでは鍵の管理や可視化は提供されないため不適切です。
その一方で、Cloud External Key Managerは外部鍵の管理を、Key Access Justificationsは暗号化キー要求の可視化を可能にするので正解です。
参考リンク：
https://cloud.google.com/security-key-management
https://cloud.google.com/kms/docs/external-key-manager
https://cloud.google.com/bigquery/docs/encryption-key-management
</div></details>

### Q.  問題23: 未回答
あなたは、機密データの暗号化キーの管理について懸念しているクライアントと仕事をしています。このクライアントは、暗号化キーが暗号化されるデータと同じクラウドサービスプロバイダ（CSP）に暗号化キーを保存したくないと考えています。
このクライアントにどのGoogle Cloud暗号化ソリューションを勧めるべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客の特定の要望に基づいたGoogle Cloudの暗号化ソリューションを選択することが求められています。顧客は暗号化キーをデータと同じクラウドサービスプロバイダ（CSP）に保存したくないとの要望を出しています。したがって、選択肢を検討する際は、これらの要望を満足するソリューションを選ぶべきです。これは、クラウドプロバイダがキーを管理するデフォルトの暗号化ソリューションだけでなく、キーの外部管理を可能にするソリューションも考慮に入れることを意味します。
基本的な概念や原則：
顧客指定の暗号化キー（CSEK）：Google Cloudのストレージ製品で使用するエンクリプションキーを顧客が直接管理・提供する方式です。この方式では、キーはGoogle Cloud外部で管理され、データは顧客が指定したキーで暗号化されます。
Cloud External Key Manager（Cloud EKM）：Cloud EKMは、Google Cloudのリソースを、外部のキーマネージメントシステムから直接制御できるようにするサービスです。それにより、データの暗号化キーをGoogle Cloudとは別の場所で保存、管理できます。
Googleのデフォルト暗号化：Google Cloudのすべてのデータはデフォルトで暗号化されますが、この方式では、キー管理はGoogleが行い、キーはGoogle Cloud内部で管理されます。
Secret Manager：Google Cloudのセキュアで堅牢なサービスで、保護すべき秘密データのストレージと管理を提供します。しかし、暗号化キー自体の管理ではなく、APIキーやパスワードなどの秘密情報全般の管理を主に扱います。
顧客管理の暗号化キー（CMEK）：Cloud KMSを使用して作成、ローテーション、自動的に破棄するキーを指定してGoogle Cloudのデータを暗号化する方法です。この方式では、キーの管理は顧客が行いますが、キー自体はGoogle Cloud内部に保存されます。
正解についての説明：
（選択肢）
・顧客指定の暗号化キー
・Cloud External Key Manager
この選択肢が正解の理由は以下の通りです。
顧客指定の暗号化キー（CSEK）は、Google Cloud環境内のデータを保護するために顧客が提供および管理するキーで、Googleが保持しません。しかし、CSEKは暗号化されるデータと同じCSP、つまりGoogle Cloudにキーを保存する必要がありますが、キーの管理はクライアント側が行います。これはクライアントの要求に一部適合しています。
さらに、Cloud External Key Manager（EKM）は、Google Cloudの外部で暗号化キーを管理するためのサービスです。これにより、クライアントはキーを任意の第三者CSPに保存し、管理することが可能となります。この機能がクライアントの要望、つまり暗号化キーを暗号化されるデータと同じCSPに保存したくないとの要望に合致します。
したがって、顧客指定の暗号化キーとCloud External Key Managerの両方がクライアントの要望を満たす適切な選択肢となります。
不正解についての説明：
選択肢：Googleのデフォルト暗号化
この選択肢が正しくない理由は以下の通りです。
Googleのデフォルト暗号化では、キー管理はGoogleが行い、暗号化キーはGoogle Cloud上に保存されます。クライアントが暗号化キーを他のCSPに保存したいと考えているため、このオプションはクライアントの要件を満たしません。
選択肢：Secret Manager
この選択肢が正しくない理由は以下の通りです。
Secret Managerは秘密情報（パスワードやAPIキーなど）の安全な管理とアクセスを提供しますが、暗号化キーの管理機能は提供していません。
それに対して、顧客指定の暗号化キーとCloud External Key Managerは両方とも客観的な暗号化キーの管理を支援します。
選択肢：顧客管理の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客管理の暗号化キーはGoogle Cloud自体で管理されるため、暗号化データと同じプロバイダで鍵を保存することになってしまいます。
それに対し、顧客指定の暗号化キーとCloud External Key Managerは両方ともキーの管理をクライアント自身が行う設定を可能にします。
参考リンク：
https://cloud.google.com/kms/docs/external-key-manager
https://cloud.google.com/kms/docs/csek
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題24: 未回答
組織のGoogle Cloud VMは、外部ユーザー向けのウェブサービスをホストするために、パブリックIPアドレスで構成されたインスタンステンプレートを介してデプロイされます。VMは、VM用のカスタムShared VPCを1つ含むホスト（VPC）プロジェクトにアタッチされたサービスプロジェクトに常駐しています。あなたは、外部ユーザーへのサービスを継続しながら、VMのインターネットへの露出を減らすように求められました。あなたはすでに、マネージドインスタンスグループ（MIG）を起動するために、パブリックIPアドレス構成なしでインスタンステンプレートを再作成しました。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、外部ユーザー向けのウェブサービスをホストしているGoogle Cloud VMのインターネットへの露出を減らす必要があります。VMはカスタムShared VPCを1つ含むホストプロジェクトにサービスプロジェクトという形でアタッチされています。ここで注意しなければならないのは、システムがインターネットに露出することを減らすためだけでなく、同時に外部ユーザーへのサービス継続も求められているという点です。そして、パブリックIPアドレス無しでインスタンステンプレートを再作成し、マネージドインスタンスグループ（MIG）を起動するまでのタスクは完了しています。問題の鍵は、これらの情報を考慮して、MIGのインターネットへの露出の度合いを最小限に抑えつつ、外部ユーザーへのサービスは続行するための方法を選択することです。
基本的な概念や原則：
インスタンステンプレート：Compute Engineのインスタンスを作成するための設定が保存されたテンプレートです。一度作成した設定を再利用することで一貫性と作業効率を向上させます。
Shared VPC：Google Cloud上の複数のプロジェクト間で仮想ネットワークリソース（VPCネットワーク、サブネット、IPアドレス）を共有できる機能です。これにより、セキュリティとネットワーク管理が一元化され、分散リソースの対応が可能になります。
マネージドインスタンスグループ（MIG）：Compute Engineのインスタンスを自動的に管理する機能です。スケールアップやスケールダウン、負荷分散などを自動的に行うことができます。
HTTP(S)ロードバランサー：HTTP/HTTPSトラフィックを複数のインスタンスに分散する機能です。これにより、高負荷状況でも安定したサービス提供が可能になります。
Cloud NAT：Google CloudのNAT（Network Address Translation）ゲートウェイです。プライベートアドレスからパブリックアドレスへの変換機能を提供しますが、インターネットからの直接的なアクセスを可能にするものではありません。
正解についての説明：
（選択肢）
・MIGをバックエンドとするサービスプロジェクトに、外部のHTTP(S)ロードバランサーをデプロイします
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのHTTP(S)ロードバランサーは、インターネットからのトラフィックを特定のバックエンド（このケースではMIG）に分散するロールを果たします。これにより、VMのインターネットへの露出は大幅に減少し、それでも外部ユーザーからのアクセスが可能となります。ロードバランサー自体がインターネットに公開され、外部トラフィックを想定通りにルーティングします。
また、MIGをバックエンドに設定することで、MIG内のインスタンスへのトラフィックを効率的にバランスさせることができます。これにより、高い堅牢性と性能を維持しながら、外部のウェブサービスを提供することが可能となります。
さらに、改めてパブリックIPアドレスを割り当てない新しいインスタンステンプレートを作成したことで、VMのインターネットへの露出は更に軽減されます。この要件に対する最善のソリューションと評価されます。
不正解についての説明：
選択肢：MIGのサービスプロジェクトにCloud NATゲートウェイをデプロイします
この選択肢が正しくない理由は以下の通りです。
Cloud NATゲートウェイは、外部への露出を減らすのではなく、プライベートインスタンスに対してアウトバウンド通信の設定を提供します。つまり、本質的に内部から外部への接続を管理し、外部ユーザーからのアクセスを制御するものではありません。
対照的に、HTTP(S)ロードバランサーでは公開サービスへの外部ユーザーのアクセスを制御しつつ、VMの直接的なインターネット接続を防げるため、適切な選択肢となります。
選択肢：MIGのホスト（VPC）プロジェクトにCloud NATゲートウェイをデプロイします
この選択肢が正しくない理由は以下の通りです。
Cloud NATゲートウェイは、VMがインターネットと通信するためのプライベートIPアドレスを提供しますが、外部ユーザーがサービスにアクセスするためのポート付き公開IPアドレスは提供しません。上記の要件は、サービスのアクセスを維持しつつ、VMのインターネット露出を減らすことなので、Cloud NATだけでは不十分です。
選択肢：MIGをバックエンドとするホスト（VPC）プロジェクトに、外部のHTTP(S)ロードバランサーをデプロイします
この選択肢が正しくない理由は以下の通りです。
VMがサービスプロジェクトに存在するため、サービスプロジェクトにロードバランサーを配置するのが適切です。ホストプロジェクトにロードバランサーを配置した場合、外部ユーザーに対するサービスを継続できない可能性があります。
参考リンク：
https://cloud.google.com/compute/docs/instance-templates
https://cloud.google.com/load-balancing/docs/https
https://cloud.google.com/nat/docs/overview
</div></details>

### Q.  問題25: 未回答
あなたは最近、会社のGoogle Cloud導入をサポートするネットワーキングチームに加わりました。あなたには、ファイアウォールルールの構成に慣れ、ネットワーキングとGoogle Cloudの経験に基づいた推奨事項を提供することが任されています。
優先順位の高い、または等しい他のファイアウォールルールの属性と重複しているファイアウォールルールを検出するために、どの製品を推奨すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのネットワーキングとセキュリティに関する知識が求められています。具体的には、ファイアウォールルールの重複を検出するためのツールや製品を理解する必要があります。問題文中には重複するファイアウォールルールを特定する必要があると述べられており、その目的を達成するために最適な製品を選択することが求められています。したがって、各選択肢が具体的にどのような機能を提供し、それが問題の要件にどの程度適合するかを考慮する必要があります。
基本的な概念や原則：
ファイアウォールインサイト：Google Cloudの機能の一つで、ファイアウォールルールの分析と最適化を支援します。他のファイアウォールルールとの重複や未使用のルールを特定できます。
Security Command Center：Google Cloudのセキュリティ管理プラットフォームで、組織全体の脅威と脆弱性を一元的に表示・管理することができます。ただし、ファイアウォールルールの重複を特定する機能はありません。
ファイアウォールルールのログ：ファイアウォールルールがトラフィックを許可または拒否した際のログです。ルールの効果を確認するために利用しますが、ルールの重複を特定する機能はありません。
VPCフローログ：VPCネットワーク上のIPトラフィックの詳細な情報を提供するログです。ネットワーク監視やトラフィック分析、トラフィックエンジニアリングに有用ですが、ファイアウォールルールの重複を特定する機能はありません。
正解についての説明：
（選択肢）
・ファイアウォールインサイト
この選択肢が正解の理由は以下の通りです。
ファイアウォールインサイトは、Google Cloud上で構成されたファイアウォールルールやその関連情報の解析を行い、複雑なネットワーキング環境を可視化し、調整します。具体的には、ファイアウォールルール間での重複を検出したり、不要なルールや潜在的な誤設定を特定したりといった詳細な分析が可能です。これは、新しくチームに加わったあなたが、ファイアウォールルールの構成に慣れるための重要なツールとなります。
また、ファイアウォールインサイトを使用することで、ネットワーキングに関する洞察や推奨事項をチームに提供することが可能になります。そのため、このシナリオにおいては、"ファイアウォールインサイト"が最も適した製品ととなります。
不正解についての説明：
選択肢：Security Command Center
この選択肢が正しくない理由は以下の通りです。
Security Command Centerは、Google Cloudリソースの脆弱性、誤設定などを検出できますが、特に"ファイアウォールルールが重複している"ことを特定的に検出する機能はありません。
一方、ファイアウォールインサイトはGoogle Cloud内のネットワークトラフィックとファイアウォールルールを分析し、ルールの重複などを明確に識別できるので正解です。
選択肢：ファイアウォールルールのログ
この選択肢が正しくない理由は以下の通りです。
ファイアウォールルールのログはルールが適用された際のアクティビティを表しますが、ルールの重複検出機能はありません。
一方、ファイアウォールインサイトはルールの衝突分析や重複検出機能を持つため問題の要件を満たします。
選択肢：VPCフローログ
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフローの情報を収集し分析するためのサービスですが、ファイアウォールルールの属性やそれらが重複するかどうかを自動的に検出する機能は有していません。
一方、ファイアウォールインサイトはファイアウォールルールの検証と最適化を支援するサービスで、重複するルールの検出が可能です。
参考リンク：
https://cloud.google.com/network-intelligence-center/docs/firewall-insights/overview
https://cloud.google.com/network-intelligence-center/docs/firewall-insights/how-to
https://cloud.google.com/network-intelligence-center
</div></details>

### Q.  問題26: 未回答
あなたはCompute Engineのディスク上のデータを、Cloud Key Management Service（KMS）が管理するキーで静止時に暗号化したいと考えています。これらのキーに対するCloud IdentityおよびIAMのパーミッションは、すべてのキーに対して同じである必要があるため、グループ化された方法で管理する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute Engineのディスク上のデータをCloud Key Management Service（KMS）で静止時に暗号化する方法と、そのキーへのパーミッションをグループ化された方法で管理する方法が求められています。重要な要件としては、すべてのキーに対してパーミッションが同じである必要があり、これらのパーミッションを一括で管理したいという点が挙げられます。したがって、各キーを個別に管理するのではなく、キーのグループ（KeyRing）単位でパーミッションを制御する方法を選びます。その際、キー単位ではなくKeyRingレベルでIAMパーミッションを管理する点に注意しなければなりません。
基本的な概念や原則：
Compute Engine：Google Cloudのインフラストラクチャで、仮想マシンを実行する環境を提供します。高パフォーマンスネットワーキングと自動的なスケーリングが可能です。
Cloud Key Management Service（KMS）：Google Cloudの暗号キー管理サービスです。自分でキーを管理するか、Googleにキーの生成や管理を任せることができます。
KeyRing：Cloud KMSのリソースで、暗号キーの論理的なグループです。一つのKeyRingは複数の暗号キーを持ち、それらをまとめて管理することが可能です。
IAMパーミッション：Google CloudのIdentity and Access Management（IAM）における、特定のユーザーやグループに付与できるアクセス制御です。コードやデータの閲覧、編集、実行などを許可、制限することが可能です。
静止時暗号化：データが保存されている状態（つまり、データが動いていない状態）でデータを暗号化することです。ハードドライブやリムーバブルメディアなどが対象となります。
永続ディスク：Compute Engine上で使用されるブロックストレージです。インスタンスとは独立して存在し、インスタンスが削除されてもデータは保持されます。
正解についての説明：
（選択肢）
・すべての永続ディスクとこのKeyRing内のすべてのKeyについて、単一のKeyRingを作成します。KeyRingレベルでIAMパーミッションを管理します
この選択肢が正解の理由は以下の通りです。
Cloud KMSでは、複数の暗号キー（CryptoKeys）を管理するためのコンテナとしてKeyRingを提供しています。各KeyRingは、異なるCryptoKeyをグループ化して一元化し、より効率的なアクセス制御を実現します。
本問題の要件では、すべてのキーに対して同一のIAMパーミッションが求められています。
したがって、各キーに対して別々にパーミッションを付与するのではなく、それら全てを含む単一のKeyRingを作成し、このKeyRingレベルでIAMパーミッションを管理することで、一括でアクセス制御を行うことが可能になります。これは管理コストを削減し、一貫したパーミッション管理を実現します。
さらに、このアプローチはすべての永続ディスクの暗号化にも適用可能で、統一されたセキュリティポリシーを維持しながらデータを保護することができます。
不正解についての説明：
選択肢：すべての永続ディスクとこのKeyRing内のすべてのKeyについて、単一のKeyRingを作成します。KeyレベルでIAMパーミッションを管理します
この選択肢が正しくない理由は以下の通りです。
問題の要件では、すべてのキーに対して同一のIAMパーミッションを適用することが必要とされています。しかし、この選択肢ではKeyレベルでのIAMパーミッション管理を提案しており、これは個々のキーに対して異なるIAMパーミッションを設定することを意味します。これは要件と矛盾しているため、この選択肢は不正解です。
選択肢：永続ディスクごとにKeyRingを作成し、各KeyRingに1つのKeyを含めます。KeyレベルでIAMパーミッションを管理します
この選択肢が正しくない理由は以下の通りです。
要件はすべてのキーに対するIAMパーミッションが同じであることを指定しているのに対し、この選択肢は永続ディスクごとにKeyRingを作成し、各KeyRingに1つのKeyを含めることを提案しています。このアプローチは、各キーに個別の管理要件を持たせることを意味し、要件とは一致しません。
選択肢：永続ディスクごとにKeyRingを作成し、各KeyRingに1つのKeyを含めます。KeyRingレベルでIAMパーミッションを管理します
この選択肢が正しくない理由は以下の通りです。
設問の要求はすべてのキーに対してパーミッションが同じであることであり、異なるKeyRingに区分して設置すると管理が煩雑になる可能性があります。
逆に、単一のKeyRingを用いることで管理が一元化され、求められる要件に適合します。
参考リンク：
https://cloud.google.com/kms/docs/encrypting-disks
https://cloud.google.com/iam/docs/granting-roles-to-service-accounts
https://cloud.google.com/compute/docs/disks/customer-supplied-encryption
</div></details>

### Q.  問題27: 未回答
Compute Engine上でホストされているWebアプリケーションをデプロイしています。ビジネス要件として、アプリケーションのログを12年間保存し、データをヨーロッパの境界内に保存することが義務付けられています。あなたは、オーバーヘッドを最小限に抑え、費用対効果の高いストレージソリューションを実装したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute EngineでホストされるWebアプリケーションのログをヨーロッパ内に12年間保存することと、オーバーヘッドを最小限に抑え費用対効果を高めることが求められています。つまり、ログの保存場所、保存期間、費用や効率性といった要素に注目する必要があります。これらの要素に基づいて、ログの保存に最適なGoogle Cloudのストレージソリューションを選択します。アプリケーションコードの変更や、Google Cloudの異なるサービスを利用することの影響も考慮し、最適な解決策を選択することが問われています。
基本的な概念や原則：
Cloud Storage：Google Cloudのデータ保存サービスです。グローバルで、ローカルで、地域で保存できます。大量のデータを安全かつ耐久性高く保存でき、ロギングにも適しています。
リージョン：Google Cloudのデータを物理的に保管する地域のことです。リージョンの選択によりデータの住所や住所の範囲が決まります。
Google Cloudの操作組：Google Cloudの監視、トラブルシューティング、アプリケーションパフォーマンス管理を統合する一連のツールです。
Cloud Logging：Google Cloudの操作スイート内の一部で、アプリケーションとシステムからのログを収集、分析、エクスポートするサービスです。
Pub/Subトピック：Google Cloud Pub/Subにおけるエンドポイントで、パブリッシャーがメッセージを送信する場所です。
操作スイートのログバケット：ログデータを保存するためのオペレーションスイートの機能です。各バケットは特定の場所にデータを保存し、一定期間データを保存することができます。
カスタム保存ポリシー：ログバケットに格納されるログデータの保持期間を設定するためのポリシーです。これは特定のコンプライアンス要件を満たすために使われます。
正解についての説明：
（選択肢）
・europe-west1リージョンにログを保存するCloud Storageバケットを作成します。アプリケーションコードを変更して、ログをバケットに直接送信し、効率を高めます
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageは長期間のデータ保管に適したコスト効率の高いストレージオプションを提供しており、アプリケーションログの永続的な保存を行うために理想的です。12年という長期間のログ保管を求められている要件を効果的に満たします。
さらに、Google Cloud Storageはリージョナルなデータ格納に対応しています。そのため、"データをヨーロッパの境界内に保存する"という要件も満たせるわけです。この選択肢では、europe-west1リージョンにバケットを作成することでこの要件を満たすことができます。
そして、アプリケーションコードを変更してログをバケットに直接送信することで、ログの流れを最適化し、オーバーヘッドを最小限に押さえることができます。これは、パフォーマンスとコスト効率を改善するために重要なステップです。結果として、この選択肢は全ての要件を最適化した形で満たすため、正解となります。
不正解についての説明：
選択肢：Compute EngineインスタンスがGoogle CloudのオペレーションスイートCloud Loggingエージェントを使用し、アプリケーションログをeurope-west1リージョンのカスタムログバケットに送信するように設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Loggingエージェントを使用する場合、ログの送信にオーバーヘッドがかかります。そのため、オーバーヘッドを最小限に抑えるというビジネス要件を満たすことができません。
また、直接Cloud Storageにログを保存することで効率が良くなるため、コスト対効果に優れています。
選択肢：Pub/Subトピックを使用して、アプリケーションログをeurope-west1リージョンのCloud Storageバケットに転送します
この選択肢が正しくない理由は以下の通りです。
Pub/Subトピックを使用すると、ログデータの転送にオーバーヘッドが発生します。正解の選択肢と比べて、ログデータを直接Cloud Storageバケットに送信する方が効率的で、コストも少なく抑えられます。
選択肢：europe-west1リージョンのGoogle Cloudのオペレーションスイートのログバケットに、12年間のカスタム保存ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのオペレーションスイート（旧Google Cloud Operation Suite）の保存期間は最大で30日間であり、カスタム保存ポリシーを用いてそれ以上延ばすことができません。そのため、要件である12年間のログ保存を満たすことができません。
参考リンク：
https://cloud.google.com/storage/docs/creating-buckets
https://cloud.google.com/storage/docs/locations
https://cloud.google.com/compute/docs/instances/create-start-instance
</div></details>

### Q.  問題28: 未回答
多国籍企業の事業部門がGoogle Cloudにサインアップし、ワークロードをGoogle Cloudに移行し始めた。その事業部門は、何百ものプロジェクトを持つ組織リソースでCloud Identityドメインを作成します。
あなたのチームはこのことに気づき、ドメインリソースの権限管理と監査を引き継ぎたいと考えています。
この要件を満たすには、どのタイプのアクセスを付与すべきですか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のビジネスユニットがGoogle Cloudに移行を開始し、あなたのチームがドメインリソースの権限管理と監査を担当したいと考えているという状況が示されています。選択肢の中から、この要件を満たすために必要なアクセスレベルを正確に選択することが求められています。特に、ドメインリソース全体の管理と監査に必要なアクセス権とは何かを理解することが重要です。選択肢から適切なロールを洗い出すためには、Google Cloudの権限モデルと各ロールがどのようなアクセスを付与するのかを把握していることが必要です。
基本的な概念や原則：
Organization Administrator：Google Cloudの組織全体のアクセスと操作管理を提供します。組織やプロジェクトを作成し、それらに対するアクセス制限やアクセスレベルを定義できます。
Cloud Identityドメイン：Google Cloudのユーザとグループ管理を提供します。Identity and Access Management（IAM）の一部として機能し、ユーザとグループがCloud Identity Aware ProxyまたはCloud Identity Platform APIといったGoogle Cloudのリソースにアクセスするための認証を提供します。
Identity and Access Management（IAM）：ユーザとサービスアカウントへのロールベースのアクセス制御の提供し、Google Cloudリソースへのアクセスを管理します。IAMポリシーは誰が（Identity）、何を（Role）、どこで（Resource）行うことができるかを定義します。
Security Reviewer：特定のリソースに対するアクセス権限を監査するためのロールです。全組織的な権限管理には適しません。
Organization Role Administrator：組織レベルの角色を作成、変更、削除するためのロールです。全組織のリソースへのアクセス権限の設定には適しません。
Organization Policy Administrator：組織ポリシーの作成、変更、適用を行うロールです。これは組織全体のリソースに対するアクセス制御よりも、特定のリソースの使用ポリシーを定義する働きをします。
正解についての説明：
（選択肢）
・Organization Administrator
この選択肢が正解の理由は以下の通りです。
Organization Administratorのロールは、Google Cloudでの組織全体のリソース管理を効果的に制御できる最高レベルのアクセス権限を持っています。このロールが付与されると、ユーザーは組織全体のリソースに対して管理と監査の操作を実行できます。具体的には、組織のリソース階層構造のセットアップ、IAMポリシーの管理、組織設定の更新など、組織全体に関連するアクションを管理することが可能になります。これにより、その組織ダメイン内で利用されているプロジェクトやその他のリソースについて、統一した規模での管理と監視が可能となります。
したがって、Cloud Identityドメインの権限管理と監査を引き継ぎたいと考えるあなたのチームには、Organization Administratorのアクセス権限が最適となります。
不正解についての説明：
選択肢：Security Reviewer
この選択肢が正しくない理由は以下の通りです。
Security ReviewerはIAMロールの一部で、権限の監査は可能ですが、権限管理や設定の機能はありません。
一方、Organization Administratorは、ドメインリソース全体の権限管理と監査が可能で、要件を満たす全機能を提供します。
選択肢：Organization Role Administrator
この選択肢が正しくない理由は以下の通りです。
Organization Role Administratorの権限を付与されると、そのユーザーは組織全体のロールを管理できますが、それはドメインリソースの管理や監査を直接的に手助けするものではありません。Organization Administratorの権限を持つユーザーの方が、組織全体のすべてのGoogle Cloudリソースを管理できるため必要なタスクを実行することが可能です。
選択肢：Organization Policy Administrator
この選択肢が正しくない理由は以下の通りです。
Organization Policy Administratorの権限ではポリシーの設定や更新が可能ですが、ドメインリソースの全体的な権限管理や監査を行うために必要なOrganization Administratorの権限を持っているわけではありません。なので、組織全体のリソースを管理するためには、Organization Administratorの権限が必要です。
参考リンク：
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://cloud.google.com/resource-manager/docs/access-control-org
https://cloud.google.com/resource-manager/docs/creating-managing-organization
</div></details>

### Q.  問題29: 未回答
アプリケーションとリソースにアクセス制御ポリシーを適用するために、どのGoogle Cloudサービスを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、適切なアクセス制御ポリシーを適用するためのGoogle Cloudのサービス選択の課題に取り組んでいます。選択肢から判断すべき主要な観点は、それらのサービスが提供する具体的な機能と、問題文中で述べられた要件との対応関係です。課題はアクセス制御ポリシーを適用するという点であり、これに応じたサービスを選択することが求められます。この視点から選択肢を評価することで、最も適切な選択肢に辿り着きます。
基本的な概念や原則：
Identity-Aware Proxy：Google Cloudの認証と認可を行うためのサービスです。アプリケーションやリソースのアクセス制御ポリシーの適用と管理を行うことができます。
Cloud NAT：Google Cloud上での中継ネットワーキングを提供するサービスです。プライベートネットワークからインターネットへの接続を可能にします。
Google Cloud Armor：Google Cloud上のアプリケーションを保護するためのDDoS防御サービスです。
Shielded VM：Google Cloud上で実行する仮想マシンに追加のセキュリティ保護を提供するサービスです。不正なソフトウェアや不正アクセスから保護します。
正解についての説明：
（選択肢）
・Identity-Aware Proxy
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのIdentity-Aware Proxy（IAP）は、GoogleのBeyondCorpセキュリティモデルを利用して、企業のアプリケーションやリソースへのセキュアなアクセスを提供します。IAPを使用すると、公開Webアプリケーションに対するアクセスを制御し、特定のGoogle Cloudのリソースへの認証済みユーザーまたはグループのアクセスを管理することができます。
また、VPNや物理的なデバイスなどを必要とせずに、リモートワークをしているユーザーがセキュアな環境でアクセスできるようにします。これにより、安全性を維持しつつ柔軟なアクセス制御を実現することができます。
したがって、アクセス制御ポリシーを適用するためには、Identity-Aware Proxyが適したサービスとなります。
不正解についての説明：
選択肢：Cloud NAT
この選択肢が正しくない理由は以下の通りです。
Cloud NATはプライベートなGoogle Cloudリソースからインターネットにアクセスするためのサービスであり、アクセス制御ポリシーを適用する機能はありません。
一方、Identity-Aware Proxyはアプリケーションやリソースへのアクセス制御のためのサービスで、適切な認証と認可を提供します。
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは、HTTP(S) ロードバランサーのトラフィックを保護する主にDDoS攻撃防止やWAFの機能を提供していますが、アプリケーションやリソースへのアクセス制御ポリシーを適用する機能は提供していません。
一方、Identity-Aware Proxyはリソースへのアクセス制御を行うためのサービスであり、適切な選択肢となります。
選択肢：Shielded VM
この選択肢が正しくない理由は以下の通りです。
Shielded VMはVMインスタンスの信頼性とセキュリティを向上させるサービスであり、アクセス制御ポリシーをアプリケーションやリソースに適用する機能を提供していません。
逆に、Identity-Aware Proxyはアクセス制御機能を提供し、ユーザーやグループに基づいてアプリケーションやリソースへのアクセスを制御します。
参考リンク：
https://cloud.google.com/iap/docs
https://cloud.google.com/armor/docs
https://cloud.google.com/compute/docs/shielded-vm
</div></details>
