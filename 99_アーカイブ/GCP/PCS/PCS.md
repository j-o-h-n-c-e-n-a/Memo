# 1
## 1

### Q.  問題6: 未回答
あなたのチームは、本番プロジェクトで稼働しているCompute EngineインスタンスがパブリックIPアドレスを持っていないことを確認したいと考えています。フロントエンドアプリケーションのCompute EngineインスタンスはパブリックIPを必要とします。プロダクトエンジニアは、リソースを変更するEditorロールを持っています。あなたのチームは、この要件を実施したいと考えています。
あなたのチームはどのようにこれらの要件を満たすべきですか？

1. 1つはパブリックIPを持つサブネット、もう1つはパブリックIPを持たないサブネットです
2. フロントエンドのCompute EngineインスタンスのパブリックIPのみを許可するように、組織ポリシーを設定します
3. Editorロールを削除し、エンジニアにCompute Admin IAMロールを付与します
4. 本番プロジェクトのVPCネットワークでプライベートアクセスを有効にします
<details><div>
    答え：2
この問題では、特定のCompute Engineインスタンスに対してのみパブリックIPアドレスを許可し、その他の場合では禁止する方法を考える必要があります。Compute Engineの扱いを理解して、公開しないようにするにはどうすればいいのか理解することが重要です。また、要件を達成するために組織ポリシーの設定が必要なことも理解しなければなりません。これにより、エンジニアがリソースを変更しながらも、フロントエンドのCompute Engineインスタンスが指定された要件を満たすことができるようになります。
基本的な概念や原則：
組織ポリシー：Google Cloudのリソースに対して一貫性のある管理を行えるようにするツールで、特定のリソースがどのように動作すべきかを定義します。
Compute Engineインスタンス：Google Cloudの仮想マシン（Virtual Machines）を指し、ユーザーはCompute Engineインスタンス上で自分のアプリケーションやウェブサイトを動作させることができます。
パブリックIP：インターネット上の任意の場所からアクセス可能なIPアドレス。Compute EngineのインスタンスにはパブリックIPを割り当てることができます。
VPCネットワーク：Virtual Private Cloud（VPC）ネットワークはGoogle Cloudの仮想ネットワークで、リソース（Compute Engineインスタンスなど）を論理的に分離し、ほかのネットワークから隔離します。
IAMロール：Google Cloud Identity and Access Management（IAM）のロールは特定の権限のセットで、ユーザーやサービスアカウントに割り当てることができます。ロールを使用して認可を行います。
サブネット：ネットワーク内の部分ネットワークで、ネットワークを独立したセグメントに分割する手段を提供します。一部がパブリックIPを持つ一方で、他部分はパブリックIPを持たないように設定することができます。
正解についての説明：
（選択肢）
・フロントエンドのCompute EngineインスタンスのパブリックIPのみを許可するように、組織ポリシーを設定します
この選択肢が正解の理由は以下の通りです。
組織ポリシーは、特定のリソースの使用を制限または制御するための仕組みであり、Google Cloudの特定の機能を許可または拒否することが可能です。この問題のシナリオでは、フロントエンドアプリケーションのCompute EngineインスタンスはパブリックIPを必要とする一方で、本番プロジェクトで稼働するCompute EngineインスタンスがパブリックIPを持っていないことを確認したいとの要件があります。この要件を満たすためには、パブリックIPをフロントエンドインスタンスだけに限定的に許可するように組織ポリシーを設定すれば良いのです。この方法により、プロダクトエンジニアがEditorロールを持っていても、許可されたインスタンス以外でパブリックIPを作成または使用することはできません。つまり、適切な組織ポリシーを設定することにより、要件通りの制御が可能となります。
不正解についての説明：
選択肢：本番プロジェクトのVPCネットワークでプライベートアクセスを有効にします
この選択肢が正しくない理由は以下の通りです。
本番プロジェクトのVPCネットワークでプライベートアクセスを有効化すると、パブリックIPなしでもGoogle Cloudサービスへアクセス可能になりますが、既存のCompute EngineインスタンスがパブリックIPを持っていないかの確認や、これ以上パブリックIPの追加を制限する機能はありません。一方正解の組織ポリシーを設定する方法で、特定のインスタンスのみパブリックIPの割り当てを許可するリソースを制御することが可能です。
選択肢：Editorロールを削除し、エンジニアにCompute Admin IAMロールを付与します
この選択肢が正しくない理由は以下の通りです。
Editorロールを削除し、エンジニアにCompute Admin IAMロールを付与しても、エンジニアはCompute EngineインスタンスにパブリックIPアドレスを持つ能力を引き続き持つため、問題の要件は満たせません。
逆に、組織ポリシーを設定することで、特定のCompute EngineインスタンスにパブリックIPの使用を制限することができます。
選択肢：1つはパブリックIPを持つサブネット、もう1つはパブリックIPを持たないサブネットです
この選択肢が正しくない理由は以下の通りです。
選択肢にあるサブネットを使った方法では、別々のサブネットに分けることでパブリックIPを制御しますが、それのみではEditorロールのエンジニアがリソース変更を防げません。
それに対して、組織ポリシーを使うとパブリックIPアドレスの許可制御をリソースレベルで強制し、適切なエンフォースメントが可能になります。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題7: 未回答
あなたは組織のCloud Identity管理者です。Google Cloud環境では、グループを使用してユーザー権限を管理します。各アプリケーションチームには専用のグループがあります。あなたのチームはこれらのグループを作成する責任を負い、アプリケーションチームはGoogle Cloudコンソールを使用してチームメンバーを自分で管理できます。アプリケーションチームが、組織内のユーザーのみをグループに追加できるようにする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. Cloud IdentityログをBigQueryにエクスポートします。グループに追加された外部メンバーのアラートを設定します。アラートがCloud Functionsインスタンスをトリガーして、グループから外部メンバーを削除します
2. 組織に所属するユーザープリンシパルにグループメンバーシップを制限する条件を含むアイデンティティおよびアクセス管理（IAM）ポリシーを設定します
3. Google Workspace Adminコンソールで関連するグループの設定を変更し、外部ユーザーをグループに追加できないようにします
4. スコープ内のグループへの組織外のプリンシパルの割り当てを拒否する、アイデンティティおよびアクセス管理（IAM）拒否ポリシーを定義します
<details><div>
    答え：3
この問題では、Google Cloudの環境において、各アプリケーションチームが組織内のユーザーだけをそのグループに追加できるように制限する方法を求められています。管理者の視点から設定を考える必要があり、アプリケーションチームがGoogle Cloudコンソールを用いて自身のチームメンバーを管理できている点に注目します。不正解の選択肢には複数の方法がありますが、組織内のユーザーだけをグループに追加できるように制限する方法として最も効率的な選択肢を選びます。この問題ではGoogle Cloudの知識はもちろん、グループ管理や権限管理の基本的な理解も必要です。
基本的な概念や原則：
Google Workspace Adminコンソール：Google Workspaceの管理者がユーザーやグループの設定を管理するためのツールです。各グループのポリシーを制御し、外部ユーザーのアクセスを許可または拒否することができます。
Cloud Identity：Google CloudのIdentity and Access Management（IAM）サービスです。組織のユーザーやグループ、サービスアカウントの管理を行うことができます。
Google Cloudコンソール：Google Cloudの各サービスをグラフィカルなインターフェースから管理できるツールです。ユーザーやチームはここから資源を作成、設定、管理することができます。
アイデンティティおよびアクセス管理（IAM）ポリシー：Google Cloud内のリソースへのアクセス制御を行うことができる仕組みです。しかし、特定のプリンシパルのグループメンバーシップを直接制限することはできません。
拒否ポリシー：IAMにおいて、特定のプリンシパルに対するリソースアクセスを拒否するルールを作成するための機能です。しかし、これは個々のグループに対する機能ではなく、リソース全体に適用されます。
Cloud Functions：Google Cloudのサーバーレス実行環境です。イベント駆動のコードを実行するためのサービスで、ログの監視やアラートの設定などに利用できます。
BigQuery：Google Cloudの大規模データ分析サービスです。ログデータの長期保存やアドホックなクエリ分析に適していますが、リアルタイムのアクセス制御には向いていません。
正解についての説明：
（選択肢）
・Google Workspace Adminコンソールで関連するグループの設定を変更し、外部ユーザーをグループに追加できないようにします
この選択肢が正解の理由は以下の通りです。
まず、Google Workspace Adminコンソールは、アカウントの全体的な管理を行うためのツールであり、ここから各種設定変更を行います。身内のユーザーだけをグループに追加したい場合、グループの設定を変更して、外部のユーザーがグループに追加できないように制限することができます。これにより、アプリケーションチームが自分たちのチームを管理する際に、自社のユーザーのみを対象にすることが保証されます。それにより、不適切なアクセス許可の付与または意図しない共有を防ぐことができます。
したがって、Google Workspace Adminコンソールでグループ設定を変更することは、この要件を満たす最適な方法となります。
不正解についての説明：
選択肢：組織に所属するユーザープリンシパルにグループメンバーシップを制限する条件を含むアイデンティティおよびアクセス管理（IAM）ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
IAMポリシーはリソースアクセスの権限を制御する目的のためのもので、組織内のユーザーが特定のグループに追加されるのを制限する目的のためのものではありません。そのため、このシナリオで提案されている要件を満たすためには適切な選択肢ではありません。
選択肢：スコープ内のグループへの組織外のプリンシパルの割り当てを拒否する、アイデンティティおよびアクセス管理（IAM）拒否ポリシーを定義します
この選択肢が正しくない理由は以下の通りです。
IAM拒否ポリシーはソースから宛先へのリクエストを制御し、特定のリソースに対するアクセスを無効にします。しかし、これはグループへのメンバーの追加を制御するものではなく、このシナリオには適していません。
それに対して、Google Workspace Adminコンソールのグループ設定を変更することで、特定のグループに外部ユーザーを追加することを制限することができます。
選択肢：Cloud IdentityログをBigQueryにエクスポートします。グループに追加された外部メンバーのアラートを設定します。アラートがCloud Functionsインスタンスをトリガーして、グループから外部メンバーを削除します
この選択肢が正しくない理由は以下の通りです。
まず、この方法は対症療法であり、予防的ではありません。問題の発生を防ぐのではなく、問題が発生した後に対応します。
また、この選択肢は管理が複雑で、外部ユーザーが一時的にアクセスできる窓が開く可能性があります。正解の選択肢では、設定変更により予め不正操作を防いでいるため、より適切です。
参考リンク：
https://cloud.google.com/identity/docs/how-to/setup#creating-groups-for-your-organization
https://cloud.google.com/identity/docs/managing-groups
https://support.google.com/a/answer/167097?hl=en
</div></details>

### Q.  問題9: 未回答
Google Cloud APIにアクセスする必要があるオンプレミスのホストがあります。これらのホスト間のプライベート接続を強制し、コストを最小限に抑え、運用効率を最適化する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. すべてのオンプレミスのトラフィックをIPsec VPNトンネル経由でGoogle Cloudにルーティングし、プライベートGoogleアクセスを有効にしたVPCに送信します
2. インターネットを通じて、オンプレミスとVPCのホスト間でVPCピアリングを設定します
3. ネットワーク経由でデータを送信する前に、Cloud Key Management Service（KMS）キーでデータを暗号化することをすべてのアプリケーションに義務付けるセキュリティポリシーを実施します
4. すべてのオンプレミスのトラフィックを、Cloud Interconnectまたはパートナーインターコネクトを経由して、プライベートGoogleアクセスが有効なVPCにGoogle Cloudにルーティングします
<details><div>
    答え：1
この問題では、オンプレミスのホストからGoogle Cloud APIにチャネルを通じて、プライベートにアクセスする方法が求められています。問題文から、プライバシーの強化、コスト削減、そして効率化が必須の要件となっています。そのため、適切なプライベート接続を設定し、トラフィックをルーティングするための最適なGoogle Cloudのサービスとその設定を選択することが求められます。これらの要件を考慮に入れ、実現可能な方法を選択肢から見つけることが重要です。
基本的な概念や原則：
IPsec VPNトンネル：オンプレミスのネットワークとGoogle Cloudのネットワークを安全に接続するための仮想プライベートネットワークです。
プライベートGoogleアクセス：VPCネットワークからGoogle CloudのAPIとサービスへのプライベートアクセスを提供します。パブリックインターネットを通さずにGoogleサービスに直接アクセスできます。
VPCピアリング：VPC間でネットワーク接続を直接設定し、ネットワークラウンドトリップディレイを分散させるサービスです。
Cloud Key Management Service：Google Cloudの暗号化キーの生成、使用、管理を提供するマネージドサービスです。しかし、ネットワーク層での暗号化を行いません。
Cloud Interconnect：Google Cloudとオンプレミスインフラストラクチャの間で専用のプライベート接続を提供するGoogle Cloudのサービスです。しかし、コストが発生します。
パートナーインターコネクト：サードパーティのサービスプロバイダーを経由してGoogle Cloudへの接続を提供するGoogle Cloudのサービスです。しかし、コストと運用効率に影響を与える可能性があります。
VPC：Google Cloudの仮想プライベートクラウド（VPC）は、Google Cloudリソースの論理的に隔離されたセクションを提供します。これによりユーザーは仮想ネットワークを定義できます。
正解についての説明：
（選択肢）
・すべてのオンプレミスのトラフィックをIPsec VPNトンネル経由でGoogle Cloudにルーティングし、プライベートGoogleアクセスを有効にしたVPCに送信します
この選択肢が正解の理由は以下の通りです。
まず、オンプレミスのホストからGoogle Cloud APIへのアクセスをプライベートな接続で強制するためには、VPNトンネルを利用するのが一般的です。IPsec VPNトンネルはオンプレミスとGoogle Cloud間に暗号化された通信経路を確立することが可能で、これによりデータの盗聴や改竄を防ぐことができます。
また、プライベートGoogleアクセスを有効にしたVPC（Virtual Private Cloud）にトラフィックを送信することで、Google Cloudの内部ネットワークを通じてGoogle APIに安全にアクセスすることが可能になります。これにより、パブリックインターネットを介さずにGoogle Cloudのリソースへのアクセスを保証することができ、セキュリティを強化することができます。
加えて、この方法はコストを最小限に抑える効果もあります。IPsec VPNは比較的低コストで設定・運用でき、プライベートGoogleアクセスを利用すればインターネット経由のデータ転送料を節約することができます。これらの要素が合わさり、運用効率を最適化する方法となります。
不正解についての説明：
選択肢：インターネットを通じて、オンプレミスとVPCのホスト間でVPCピアリングを設定します
この選択肢が正しくない理由は以下の通りです。
VPCピアリングはGoogle Cloud内のVPCネットワーク間での接続を可能にする機能であり、オンプレミス環境とVPC間の接続には使用できません。
それに対し、正解のIPsec VPNはオンプレミスとGoogle Cloud間の安全な接続を提供します。
選択肢：ネットワーク経由でデータを送信する前に、Cloud Key Management Service（KMS）キーでデータを暗号化することをすべてのアプリケーションに義務付けるセキュリティポリシーを実施します
この選択肢が正しくない理由は以下の通りです。
Cloud KMSを使用したデータの暗号化はセキュリティを強化する一方で、オンプレミスからGoogle Cloud APIへの接続をプライベートにすることは実現できません。
また、運用効率の最適化やコストの最小化にも寄与しないため、問題の要件を満たす解答とは言えません。
選択肢：すべてのオンプレミスのトラフィックを、Cloud Interconnectまたはパートナーインターコネクトを経由して、プライベートGoogleアクセスが有効なVPCにGoogle Cloudにルーティングします
この選択肢が正しくない理由は以下の通りです。
Cloud Interconnectやパートナーインターコネクトは、一度設定すれば堅牢な接続を提供しますが、その設定や維持にはそれなりの手間とコストがかかります。
一方、IPsec VPNトンネルは低コストで設定可能で、運用効率も高いため、このケースには最適です。
参考リンク：
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/vpn/docs/concepts/overview
https://cloud.google.com/vpc/docs/vpc-peering
</div></details>

### Q.  問題20: 未回答
あるアプリケーションをクラウドに移行しようとしています。アプリケーションはCloud Storageのバケットからデータを読み取る必要があります。現地の規制要件により、暗号化に使用するキーマテリアルを完全に管理下に置く必要があり、キーマテリアルにアクセスする正当な根拠が必要です。
この要件を満たすために、どうすればよいですか？

1. Cloud HSM（HSM）にバックアップされたカスタママネージド暗号化キーを使用して、Cloud Storageバケット内のデータを暗号化します。データアクセスログを有効にします
2. オンプレミス環境で鍵を生成し、オンプレミスで管理されているCloud HSM（HSM）に保管します。この鍵をCloud Key Management Service（KMS）の外部鍵として使用します。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムで不正アクセスを拒否するように設定します
3. Customer Managed Encryption Keysを使用してCloud Storageバケット内のデータを暗号化します。未承認グループに対してIAM拒否ポリシーを設定します
4. Cloud Storageバケットにデータをアップロードする前に、データを暗号化するキーをオンプレミス環境で生成します。鍵をCloud Key Management Service（KMS）にアップロードします。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムに不正アクセスを拒否させます

<details><div>
    答え：2
この問題では、アプリケーションがCloud Storageからデータを読取る際に、キーマテリアルを完全に管理下に置き、アクセスに正当性が必要という要件を満たす解決策を求められています。キーマテリアルの管理とアクセス正当性の確認の観点から考えると、オンプレミスで生成された鍵を使用し、Cloud HSMで保管し、アクセスが必要な場合は、Key Access Justificationsを有効にすることが考えられます。この観点を持つことにより、適切な解答を選択することが可能となります。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データの永続性、可用性、耐久性を高めるために利用します。
Cloud HSM：Google Cloudの暗号化キーサービスです。Cloud HSM（HSM）を利用して暗号化キーの生成、管理を行います。
Cloud Key Management Service（KMS）：Google Cloudの暗号鍵管理サービスです。暗号鍵を作成、使用、管理、回転、破棄、復元するためのフルマネージドサービスです。
Key Access Justifications：Google Cloudの原理でアクセスの正当性を追跡し、承認するための機能です。この機能を有効にすると、キーにアクセスするたびにその合理的な理由が文書化されます。
Customer Managed Encryption Keys：顧客が自身で管理・制御するための暗号化キーのことです。これを利用することで、ユーザー自身で暗号キーのライフサイクルの管理を行うことができます。
IAM拒否ポリシー：特定のユーザーやグループが特定のリソースにアクセスすることを拒否するためのIAMの設定です。
データアクセスログ：ユーザーがデータに対して行った操作の詳細を記録したログです。データへのアクセスを監査・監視するために利用します。
正解についての説明：
（選択肢）
・オンプレミス環境で鍵を生成し、オンプレミスで管理されているCloud HSM（HSM）に保管します。この鍵をCloud Key Management Service（KMS）の外部鍵として使用します。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムで不正アクセスを拒否するように設定します
この選択肢が正解の理由は以下の通りです。
まず、要件では暗号化キーやキーマテリアルを完全に管理すること、そしてキーマテリアルにアクセスする正当な根拠が必要であると述べています。そのため、まずオンプレミスの環境で鍵を生成し、そしてCloud HSMに保管することで、鍵の生成と保管を完全に制御下に置くことができます。
更に、生成された鍵をCloud KMSの外部鍵として使用することで、クラウド環境とオンプレミス環境間で鍵の操作が可能となり、Cloud Storageからデータを読み取るというアプリケーションの要求も適切に満たすことができます。
最後に、Key Access Justifications（KAJ）を有効化することで、鍵へのアクセスに正当な根拠が必要となり、外部鍵管理システムで不正アクセスを拒否するよう設定することで、キーマテリアルへのアクセス制御もしっかりと行うことができます。
複合的に、これらの処置を講じることで、規制要件を満たすとともに、クラウド移行という動きにも適応できるため、この選択肢が最も適切です。
不正解についての説明：
選択肢：Customer Managed Encryption Keysを使用してCloud Storageバケット内のデータを暗号化します。未承認グループに対してIAM拒否ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
Customer Managed Encryption Keysを使用したとしても、完全なキーマテリアルの管理を実現することは難しいです。
また、Key Access Justifications（KAJ）は使用されておらず、これによりキーマテリアルへの正当なアクセス根拠の要件を満たすことができません。正解の選択肢では、オンプレミスで管理されたキーとKAJを使用して完全な鍵管理と正当なアクセス根拠を確保しています。
選択肢：Cloud Storageバケットにデータをアップロードする前に、データを暗号化するキーをオンプレミス環境で生成します。鍵をCloud Key Management Service（KMS）にアップロードします。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムに不正アクセスを拒否させます
この選択肢が正しくない理由は以下の通りです。
現地の規制要件により、キーマテリアルを完全に管理下に置かなければならない状況で、鍵をCloud Key Management Service（KMS）にアップロードすると、鍵管理の完全なコントロールが喪失します。これに対して正解の選択肢では、鍵はオンプレミスのHSMで管理され、Cloud KMSは外部鍵としてそれを利用するだけになります。これが規制対策として相応しい選択となります。
選択肢：Cloud HSM（HSM）にバックアップされたカスタママネージド暗号化キーを使用して、Cloud Storageバケット内のデータを暗号化します。データアクセスログを有効にします
この選択肢が正しくない理由は以下の通りです。
Cloud HSMでバックアップされたカスタママネージド暗号化キーを使用すると、キーマテリアルの完全な管理が可能ですが、Key Access Justifications（KAJ）を用いたアクセス正当性の証明が利用できません。
正解の選択肢は、キーマテリアルの完全な管理とKAJを併用しているためより適しています。
参考リンク：
https://cloud.google.com/kms/docs/using-external-keys
https://cloud.google.com/storage/docs/encryption/using-customer-supplied-keys
https://cloud.google.com/kms/docs/key-access-justifications
</div></details>

### Q.  問題22: 未回答
あなたのチームは、ユーザーが組織内でプロジェクトを作成できないようにする必要があります。DevOpsチームだけが、要求者に代わってプロジェクトを作成できるようにする必要があります。
この要求を処理するために、あなたのチームはどの2つのタスクを実行する必要がありますか？（2つ選択）

1. 指定されたユーザーグループに、組織レベルでProject Editorロールを付与します
2. 組織レベルで、すべてのユーザーをProject Creatorロールから削除します
3. 指定されたDevOpsチームにBilling Account Creatorロールを付与します
4. 組織ポリシー制約を作成し、組織レベルで適用します
5. 組織レベルで、指定されたユーザーグループをProject Creatorロールに追加します
<details><div>
    答え：2,5
この問題では、プロジェクト作成の権限をDevOpsチームだけに絞り込むための適切な手段を理解しましょう。そのためには、アクセス制御とロールベースのアクセス制御（RBAC）についての理解が必要となります。組織内の全ユーザーからプロジェクト作成の権限を剥奪し、それを特定のユーザーグループ（この場合DevOpsチーム）だけに付与するという要求を満たすための適切なタスクを選択肢の中から選ぶ必要があります。
基本的な概念や原則：
Project Creatorロール：Google Cloud上で新たにプロジェクトを作成する権限を持つロールです。このロールを削除することで、特定のユーザーがプロジェクトを作成する能力を制限することができます。
組織レベルのIAMポリシー：全体の組織に対して権限を制御する仕組みです。特定のユーザーやグループに対して、Project Creatorロールなどの特定のロールを追加したり削除したりすることができます。
組織ポリシー：特定のGoogle Cloudリソースに対するアクセスや操作を管理するための仕組みです。しかし、このケースの要件（プロジェクト作成の制限）はIAMポリシーを通じて実現するほうが適切です。
Project Editorロール：既存のプロジェクトに対する全てのAPIの読み書き操作を許可するロールです。しかし、このケースでは新規プロジェクトの作成を制限するためには関連性がありません。
Billing Account Creatorロール：新たに課金アカウントを作成する権限を付与するロールですが、プロジェクト作成の制限とは直接関連がありません。
正解についての説明：
（選択肢）
・組織レベルで、すべてのユーザーをProject Creatorロールから削除します
・組織レベルで、指定されたユーザーグループをProject Creatorロールに追加します
この選択肢が正解の理由は以下の通りです。
まず、"組織レベルで、すべてのユーザーをProject Creatorロールから削除します"は適切です。これにより、基本的にはユーザーはプロジェクトの作成ができなくなります。これが問題の要求を満たしていることは明白です。
次に、"組織レベルで、指定されたユーザーグループをProject Creatorロールに追加します"も反対に、特定のユーザーグループ（この場合、DevOpsチーム）だけがプロジェクトを作成できるようにします。それは彼らがProject Creatorのロールを持つためです。これによってDevOpsチームだけが要求者に代わってプロジェクトを作成でき、問題の制約を満たしています。
よって、これら二つのタスクを組み合わせることで、問題で求められている条件を満たすことができます。これが適切な選択肢である理由です。
不正解についての説明：
選択肢：組織ポリシー制約を作成し、組織レベルで適用します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約を作成し、組織レベルで適用することはプロジェクトの作成防止に直接貢献しません。適切なアクションは、全てのユーザーをProject Creatorロールから削除し、特定のユーザーグループをProject Creatorロールに追加することで、プロジェクトの作成を制限します。
選択肢：指定されたユーザーグループに、組織レベルでProject Editorロールを付与します
この選択肢が正しくない理由は以下の通りです。
Project Editorロールはプロジェクトにリソースを追加、削除、変更する権限を持つが、新しいプロジェクトを作成する権限は含まれていません。この課題を解決するためには、Project Creatorロールを適切なユーザーグループに付与する必要があります。
選択肢：指定されたDevOpsチームにBilling Account Creatorロールを付与します
この選択肢が正しくない理由は以下の通りです。
Billing Account Creatorロールは、請求アカウントを作成する権限を与えるものであり、プロジェクトを作成する権限は含まれません。本問題の目的は、特定のユーザーグループだけがプロジェクトを作成できるように制限することであり、Billing Account Creatorロールの付与はその目的に対して効果的ではありません。
参考リンク：
https://cloud.google.com/resource-manager/docs/access-control-proj
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/resource-manager/docs/organization-policy/creating-managing-policies
</div></details>

### Q.  問題41: 未回答
個人を特定できる情報（PII）を含む機密性の高いBigQueryワークロードがあり、インターネットからアクセスできないようにしたいと考えています。データの流出を防ぐため、許可されたIPアドレスからのリクエストのみBigQueryテーブルへのクエリを許可する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. サービス境界を使用し、認可されたソースIPアドレスを条件としてアクセスレベルを作成します
2. Cloud Data Loss Prevention（DLP）とともに、リソースサービス利用制限組織ポリシー制約を使用します
3. グローバルHTTPSロードバランサーで、許可されたIPアドレスの許可リストを定義するGoogle Cloud Armorセキュリティポリシーを使用します
4. Cloud Data Loss Prevention（DLP）と共に、許可されたGoogle CloudAPIとサービスの組織ポリシー制約を使用します
<details><div>
    答え：1
この問題では、機密な情報を含むBigQueryワークロードのアクセス制御をどのように行うかということが問われています。特に、指定したIPアドレスからのリクエストのみを許可するという要件に重点を置くべきです。これにより、選択肢に含まれる各ツールやサービスがこの特定の要件に対してどのように対応できるかを理解し、最適な解決策を選択することが求められます。
基本的な概念や原則：
サービス境界：Google Cloudにおけるネットワークセキュリティ機能の一つで、特定のサービスへのアクセスを制限する機能です。境界を設定することで、特定のソースからの接続を制限したり、許可するIPアドレスを指定したりすることができます。
アクセスレベル：サービス境界の条件の一つで、指定されたIPアドレスや範囲からのリクエストを許可したり、特定のユーザーエージェントを必要としたりする状態を定義します。
Google Cloud Armor：Google Cloudのセキュリティサービスの一つで、グローバルHTTPSロードバランサーに対してセキュリティポリシーを適用する機能があります。しかし、BigQueryの制限には適していません。
Cloud Data Loss Prevention（DLP）：機密情報を特定、マスク、匿名化するためのツールです。PIIの保護には有用ですが、IPアドレスに基づいたアクセス制御には使用できません。
リソースサービス利用制限組織ポリシー制約：特定のサービスリソースの使用を制限するポリシーです。サービスの利用自体を制御しますが、IPアドレスに基づいたアクセス制御には使用できません。
正解についての説明：
（選択肢）
・サービス境界を使用し、認可されたソースIPアドレスを条件としてアクセスレベルを作成します
この選択肢が正解の理由は以下の通りです。
サービス境界は、Google Cloud上の特定のリソースへのネットワークアクセスを制御するためのポリシーベースのツールで、これにより各リソースへのアクセスを厳密に制御することが可能です。設問では、特定のIPアドレスからのアクセスのみBigQueryテーブルへのクエリを許可するような要求があったため、サービス境界を使用して、許可されたソースIPアドレスを条件としてアクセスレベルを作成することで、これを実現することができます。
また、サービス境界は、ネットワークとデータのセキュリティを強化するツールでもあります。BigQueryでは、PIIなどの機密性の高い情報を扱う場合、データの流出を防ぐための強固なセキュリティ対策が必要となります。この選択肢は、そのようなセキュリティ要件を確実に満たすための適切な解決策を示しています。
不正解についての説明：
選択肢：グローバルHTTPSロードバランサーで、許可されたIPアドレスの許可リストを定義するGoogle Cloud Armorセキュリティポリシーを使用します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは主にHTTP(S)負荷分散のトラフィックに対するセキュリティの提供に使用され、BigQueryサービス（非HTTP(S)ベース）へのアクセス制御には適していません。
一方、サービス境界は特定のサービスに対し制限を設ける能力があるため、正解となります。
選択肢：Cloud Data Loss Prevention（DLP）とともに、リソースサービス利用制限組織ポリシー制約を使用します
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Preventionは、データを保護し情報漏洩を防止するためのサービスですが、特定のIPアドレスからのリクエストだけを許可する機能は提供していません。
一方、サービス境界を使用しアクセスレベルを作成することで、認可されたソースIPアドレスからのみのアクセスを制限することが可能です。
選択肢：Cloud Data Loss Prevention（DLP）と共に、許可されたGoogle CloudAPIとサービスの組織ポリシー制約を使用します
この選択肢が正しくない理由は以下の通りです。
Cloud DLPと組織ポリシー制約はデータの流出や不適切なパブリックアクセスを防ぐためのツールではありますが、指定したIPアドレスからのリクエストだけを許可することは出来ません。
それに対して、サービス境界とアクセスレベルを使用すれば、許可したIPアドレスからのアクセスのみを許可することができます。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/create-manage-service-perimeters
https://cloud.google.com/access-context-manager/docs/overview
https://cloud.google.com/bigquery/docs/controlled-access
</div></details>

### Q.  問題42: 未回答
オンプレミス環境からBigQueryデータセットへの日々のETLプロセスにおいて、個人を特定できる機密情報（PII）がGoogle Cloud環境にインジェストされていることが判明しました。このデータを冗長化してPIIを難読化する必要がありますが、データ分析の目的で再識別化する必要があります。
どのコンポーネントをソリューションに使用するべきですか？（2つ選択）
1. 自動テキスト再編集機能を備えたCloud Data Loss Prevention
2. Cloud Key Management Service
3. Secret Manager
4. AES-SIVを用いた決定論的暗号化によるCloud Data Loss Prevention
5. 暗号ハッシュによるCloud Data Loss Prevention
<details><div>
    答え：2,4
この問題では、PII（特定可能な個人情報）の取り扱いを問われています。PIIは一度難読化（暗号化）が必要であり、同時に再識別化（復号化）も可能でなければなりません。その上で、適切なGoogle Cloudの機能やサービスを選択することが必要です。問題は2つの答えを求めており、選択肢にはCloud Key Management Service、Cloud Data Loss Preventionなど複数のサービスが提示されています。個々の選択肢が提供するサービスや機能を理解し、問題の要求を満たすものを選ぶことが求められます。
基本的な概念や原則：
Cloud Key Management Service：暗号キーを作成、使用、管理し、アクセスを制御するGoogle Cloudのインフラストラクチャです。キーのライフサイクルを管理する機能やキーのバージョニングを提供します。
決定論的暗号化：同じ平文が常に同じ暗号文になるような暗号方式です。個人を識別できる情報などを確実に難読化し、維持することができます。
Personal Identifiable Information（PII）：個々の人物を特定できる情報のことを指します。名前やメールアドレスなどが該当します。
Cloud Data Loss Prevention：機密データの検出、分類、保護を自動化するためのサービスです。暗号化や変換などを行ってデータの保護を支援します。
AES-SIV（Authenticated Encryption with Associated Data - Synthetic Initialization Vector）：暗号化とメッセージ認証コード生成を一度に行う暗号化方式の一つです。再識別が可能な暗号化を提供します。
正解についての説明：
（選択肢）
・Cloud Key Management Service
・AES-SIVを用いた決定論的暗号化によるCloud Data Loss Prevention
この選択肢が正解の理由は以下の通りです。
まず、Cloud Key Management Service（KMS）は、Google Cloud環境での暗号鍵の管理を容易にするためのサービスです。具体的には、暗号鍵の生成、使用、ローテーション、削除などを管理できます。これにより、データの冗長化などのセキュリティ上の要求を満たすことができます。
また、Google Cloudのデータ損失防止（DLP）APIは、個人を特定できる情報（PII）を自動的に検出、分類、難読化する機能を提供します。
そして、DLP APIはAES-SIVを使用した決定論的暗号化をサポートしており、同一の入力に対して常に同じ暗号文を生成します。これにより、データ分析を行う際に同じデータを再識別化することが可能になります。つまり、DLP APIのAES-SIVを使用した決定論的暗号化は、このケースの需要に適しています。
したがって、PIIを難読化しつつ、データ分析の目的で再識別化するためには、Cloud KMSとCloud DLPのAES-SIVを使用した決定論的暗号化の組み合わせが最適です。
不正解についての説明：
選択肢：Secret Manager
この選択肢が正しくない理由は以下の通りです。
Secret Managerは秘密情報の保存・管理を行うサービスであり、データの暗号化や難読化には使えません。
それに対して、Cloud Key Management Serviceは鍵の管理を、Cloud Data Loss PreventionはPIIの保護を行うため、このケースに適しています。
選択肢：暗号ハッシュによるCloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュによるCloud Data Loss Preventionはデータを難読化しますが一度ハッシュ化された情報は元に戻すことが出来ません。そのため再識別化が必要という要件を満たすことができません。
それに対して、AES-SIVを用いた決定論的暗号化は、一貫した暗号テキストを生成しつつ元の情報に戻すことが可能なため要件を満たします。
選択肢：自動テキスト再編集機能を備えたCloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
自動テキスト再編集機能を備えたCloud Data Loss Preventionは、機密情報を難読化するのに有用ですが、問題の要求である"データ分析の目的で再識別化する必要がある"という条件に合致しません。再編集したデータの再識別化はできません。
一方、AES-SIVを用いた決定論的暗号化は再識別が可能なため、この要件に適しています。
参考リンク：
https://cloud.google.com/kms
https://cloud.google.com/dlp/docs/concepts-deidentification#de-identification_in_the_dlp_api
</div></details>


## 2

### Q.  問題5: 未回答
あなたは、GDPRの要件に従って、設計によるデータ保護を実装しています。設計レビューの一環として、Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Subのワークロードを含むソリューションの暗号化キーを管理する必要があると言われました。
この実装では、どのオプションを選択すべきですか？
1. Cloud External Key Manager
2. 顧客管理の暗号化キー
3. 顧客指定の暗号化キー
4. Googleのデフォルト暗号化
<details><div>
    答え：1
この問題では、データ保護を実装する場面での暗号化キーの管理について読み解く必要があります。特にEUのGDPR要件に適合させることが重要な点で、Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Subのワークロードを含むソリューションに対して、どの暗号化キー管理オプションを選ぶべきかが問われています。ここでは、各選択肢が提供する暗号化キーの管理方法と、それがGDPR要件にどのように適合するかを理解することが重要です。
基本的な概念や原則：
Cloud External Key Manager：Google Cloudリソースへのアクセスの認証に使う暗号化キーを、Google Cloud外部で管理することが可能なサービスです。GDPRの要件など、特定の規制要件に対応が必要な場合に用いられます。
GDPR（General Data Protection Regulation）：EU圏の市民のデータを保護することを目的とした法律です。設計によるデータ保護（Privacy by Design）はこの中で求められる要件の一つです。
Privacy by Design：プロダクトやサービスの設計段階からプライバシー保護を取り入れるアプローチです。つまり、事前に、そしてデフォルトでプライバシーが保護されるような設計を行います。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。データの暗号化キーについては、Cloud External Key Managerを利用して管理することが可能です。
Google Kubernetes Engine：Google Cloudでコンテナのオーケストレーションを行うためのマネージドサービスです。こちらも暗号化キーの管理には、Cloud External Key Managerを利用することが可能です。
Cloud Storage：大規模なデータをストレージとして保存、取得できるGoogle Cloudのサービスです。データの暗号化キーについては、Cloud External Key Managerを использовать для управления。
BigQuery：大規模なデータ分析を行うGoogle Cloudのフルマネージドサービスです。データの暗号化キーについては、Cloud External Key Managerを использовать для управления。
正解についての説明：
（選択肢）
・Cloud External Key Manager
この選択肢が正解の理由は以下の通りです。
Google CloudのExternal Key Managerは、Google Cloudの資源上で暗号化されたデータのキーを外部で管理することを可能にします。これは、GDPRのような特定の規制に対処するための設計によるデータ保護を実現する上で非常に重要です。各種ワークロードに適用可能であり、Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Sub等が該当します。
External Key Managerは組織がGoogle Cloudに保存されているデータの暗号化キーを自身で制御でき、自身のデータセンター、オンプレミスデバイス、またはその他のクラウドプロバイダをキーストレージとして使用することが可能です。
External Key Managerと共に適切なアクセスポリシーを組み合わせることで、組織は自身のGDPRの要件を満たすための暗号化キーの管理を実現でき、データ保護を強化することができます。このような理由から、Cloud External Key Managerは適切な選択とされます。
不正解についての説明：
選択肢：顧客管理の暗号化キー
この選択肢が正しくない理由は以下の通りです。
"顧客管理の暗号化キー"だけでは、あいまいかつ明らかなサービスや手段を指していないため不適切です。
それに対して、Cloud External Key ManagerはGoogle Cloudで提供される明確なサービスであり、これを使うことでCompute Engine、GKE、Cloud Storage、BigQuery、Pub/Subなどのワークロードの暗号化キーを一元的に管理することが可能です。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キーは特定のサービス（Cloud Storageなど）でしか利用できません。
一方、Cloud External Key ManagerはCompute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Subといった複数のサービスに対応しており、より広範な暗号化キー管理が可能です。
選択肢：Googleのデフォルト暗号化
この選択肢が正しくない理由は以下の通りです。
Googleのデフォルト暗号化は、Googleが全ての管理を行うため、使用者自身が暗号化キーを管理することができません。これではGDPRの要件を満たすことが難しくなります。
一方、Cloud External Key Managerは、キーの管理を使用者自身が行えるため、GDPRの要件を満たすことが可能です。
参考リンク：
https://cloud.google.com/security-key-management
https://cloud.google.com/kms/docs/ekm
https://cloud.google.com/compute/docs/disks/customer-managed-encryption
</div></details>

### Q.  問題13: 未回答
あなたはセキュリティチームの一員で、漏洩したサービスアカウントキーを調査しています。あなたは、どの新しいリソースがサービスアカウントによって作成されたかを監査する必要があります。
この要件を満たすために、どうすればよいですか？
1. 管理者のアクティビティログを照会します
2. Access Transparencyのログを照会します
3. データアクセスのログを照会します
4. Google Cloud Operation Suite監視ワークスペースに問い合わせます
<details><div>
    答え：1
この問題では、特定のセキュリティ上の課題、つまりサービスアカウントキーの漏洩を調査する方法について問われています。具体的には、漏洩したサービスアカウントキーを用いて作成された新しいリソースを特定したいという状況です。したがって、サービスアカウントによるリソースの作成というアクションをトラッキング可能なGoogle Cloudの機能を選択肢から選ぶことが必要です。選択肢を見たときには、それぞれの特性と、それが特定のアクションをトラッキングできるかどうかを考慮することが重要です。
基本的な概念や原則：
管理者のアクティビティログ：Google Cloudにおける管理者の操作を記録するログです。サービスアカウントによって新しく作成されたリソースの監査に使用します。
データアクセスログ：Google Cloudのサービスがユーザーデータにアクセスする際の情報を記録するログです。サービスアカウントがリソースにアクセスしたデータの追跡に使われますが、新しいリソースの作成には使用しません。
Access Transparencyログ：Googleのサポートやエンジニアリングチームがユーザーデータにアクセスした際の詳細情報を提供するログです。Googleの職員が行った操作の可視化に使用します。
Google Cloud Operation Suite：ログ管理、監視、トレーシングなどの機能を提供するツールセットです。しかし、特定のサービスアカウントによって新しく作成されたリソースの監査には適していません。
正解についての説明：
（選択肢）
・管理者のアクティビティログを照会します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、管理者のアクティビティログという監査ログが提供されています。これはGoogle Cloud内のリソースに対する管理操作（作成や削除など）の詳細情報を記録します。そのため、サービスアカウントによってどのような新リソースが作成されたかを知りたい場合、管理者のアクティビティログを照会することで、それぞれの操作に対する詳細な情報を取得することが可能です。
また、活動ログはリソースを作成したユーザーやサービスアカウント、リソースの詳細、タイムスタンプなどのデータを提供します。これにより、特定のアカウントによって行われた操作の追跡や、何がいつ何によって変更されたのかを監査することが可能になります。
したがって、サービスアカウントキーの漏洩を調査し、新しいリソースの作成を監査する要件を満たすためには、管理者のアクティビティログの照会が効果的です。
不正解についての説明：
選択肢：データアクセスのログを照会します
この選択肢が正しくない理由は以下の通りです。
データアクセスのログは、Google Cloudのリソースに対する読み取りまたは書き込み操作を記録しますが、新しいリソースがサービスアカウントによって作成されたかどうかを追跡するためには不十分です。
対照的に、管理者のアクティビティログはCloudの管理活動、つまり、リソースの作成や変更などを追跡します。そのため、正確な監査には管理者のアクティビティログの照会が必要です。
選択肢：Access Transparencyのログを照会します
この選択肢が正しくない理由は以下の通りです。
Access TransparencyのログはGoogleの管理者によるアクセスを記録するためのもので、サービスアカウントによって新しく作成されたリソースの監査に用いるものではありません。この要件を満たすには、管理者のアクティビティログを照会することで、サービスアカウントによるリソースの操作をトレースできます。
選択肢：Google Cloud Operation Suite監視ワークスペースに問い合わせます
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite監視ワークスペースは主にインフラストラクチャの動作状況を監視しアラートを管理するためのツールであり、特定のサービスアカウントによって作成されたリソースの監査には対応していません。ただし、管理者のアクティビティログはGoogle Cloud上のあらゆる管理活動を監視、記録するため、サービスアカウントによるリソースの作成活動を照会するのに最も適しています。
参考リンク：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/logging/docs/audit/configure-data-access
</div></details>

### Q.  問題26: 未回答
あなたの所属するDevOpsチームはPackerを使用して、次のプロセスでCompute Engineイメージを構築します。
a. 一時的なCompute Engine VMを作成します。
b. Cloud StorageバケットからVMのファイルシステムにバイナリをコピーします。
c. VMのパッケージマネージャーを更新します。
d. 外部パッケージをインターネットからVMにインストールします。
セキュリティチームは、VM上のパブリックIPアドレスの使用を制限するために、組織ポリシーのconstraints/compute.vmExternalIpAccessを有効にしました。これに応じて、DevOpsチームはスクリプトを更新して、Compute Engine VM上のパブリックIPアドレスを削除しました。ただし、接続の問題によりビルドパイプラインが失敗します。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. Compute EngineVMと同じVPCおよびリージョンに、Cloud VPNトンネルをプロビジョニングします
2. インターネットからVMへのインバウンド接続を許可するために、アンマネージドインスタンスグループ内のVMでHTTPロードバランサーをプロビジョニングします
3. Compute Engine VMがデプロイされているサブネットで、プライベートGoogleアクセスを有効にします
4. Compute Engine VMと同じVPCおよびリージョンにCloud NATインスタンスをプロビジョニングします
5. VPCルートを更新して、インターネットとのトラフィックを許可します
<details><div>
    答え：3,4
この問題では、組織ポリシーで設定した外部IPアドレスへのアクセス制限により、ビルドプロセスが失敗してしまうDevOpsチームの対応策が求められています。ポイントとなるのは、パブリックIPへのアクセスを許可せずに、依然として外部からのパッケージインストールやCloud Storageバケットからのファイル転送などを維持する方法です。そのため、private IPを活用した接続手順や設定の確認、またNATやプライベートGoogleアクセスなどの機能を適切に利用することが重要となります。解答を選択する際は、これらの要素を理解し、各選択肢が提供する機能やその影響をきちんと評価することが求められます。
基本的な概念や原則：
Cloud NAT：Google CloudのマネージドNATサービスで、プライベートインターネットアクセスを提供します。特に、VPC内でのパブリックIPアドレスの使用を制限する場合に使用されます。
プライベートGoogleアクセス：Google Cloudサービスへのインターネットアクセスが制限されたインスタンスに対して、非公開IPアドレスを使用してGoogle Cloud APIとサービスにアクセスする機能です。
VPC：Google Cloudの仮想プライベートクラウド（VPC）ネットワークを構築、展開してホストするサービスで、プロジェクトのVMインスタンスに冗長性と規模の拡張性を提供します。
組織ポリシー：組織レベルで設定可能な制限や制約のことで、セキュリティ強化やコンプライアンスのために使用されます。
Packer：オープンソースのツールで、複数のプラットフォームに対するイメージを自動化的に作成します。スクリプトを用いて、一貫性のあるイメージ作成手順を定義することができます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、安全に大量のデータを保存し、世界中からアクセスすることができます。
正解についての説明：
（選択肢）
・Compute Engine VMと同じVPCおよびリージョンにCloud NATインスタンスをプロビジョニングします
・Compute Engine VMがデプロイされているサブネットで、プライベートGoogleアクセスを有効にします
この選択肢が正解の理由は以下の通りです。
まず、組織ポリシーでパブリックIPの使用を制限した場合、Compute Engine VMからインターネットへの直接的な接続ができなくなります。ここでCloud NATをプロビジョニングするという選択肢が有効となります。Cloud NATを使うと、Compute Engine VMがVPC内部から外部のインターネットに接続できるようになります。これにより、VMからの外部パッケージのインストールなどが可能となり、ビルドパイプラインが正常に動作するようになります。
次に、VMがデプロイされているサブネットでプライベートGoogleアクセスを有効にすることにより、VMは外部IPアドレスを持たないままでもGoogle Cloudのサービス（Cloud Storageなど）に接続できます。これにより、Cloud Storageバケットからのバイナリのコピーが失敗することなく実行できます。これら二点により、パブリックIPアドレスを使用することなく、ビルドパイプラインが問題なく実行できるようになります。
不正解についての説明：
選択肢：インターネットからVMへのインバウンド接続を許可するために、アンマネージドインスタンスグループ内のVMでHTTPロードバランサーをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
HTTPロードバランサーをプロビジョニングすることは、インターネットからのインバウンド接続を許可するものではありません。
また、この問題の要件は、VMからインターネットにアウトバウンド接続を行うことで、パブリックIPアドレスを使用せずにインターネットにパッケージをインストールすることです。これは、ロードバランサーでは解決できません。
選択肢：VPCルートを更新して、インターネットとのトラフィックを許可します
この選択肢が正しくない理由は以下の通りです。
VPCルートの更新は、パブリックIPアドレスがない場合でもインターネットと通信するための解決策ではありません。インターネットとの通信を許可するだけで、VMから外部パッケージをダウンロードできるようにはならず、要件とマッチしません。
選択肢：Compute EngineVMと同じVPCおよびリージョンに、Cloud VPNトンネルをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
Cloud VPNトンネルは、異なるネットワーク間の安全な接続を提供します。ただし、この問題はパブリックインターネットへの接続を解決する必要がありますし、Cloud VPNではその解決に不適で、Compute Engine VMが必要とするアクセスを提供しません。
それに対して、Cloud NATとプライベートGoogleアクセスはパブリックIP無しで外部パッケージをインターネットからインストールするための適切な解決策です。
参考リンク：
https://cloud.google.com/nat/docs/using-nat
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/compute/docs/ip-addresses#externaladdresses
</div></details>

### Q.  問題30: 未回答
セキュリティチームがファイアウォールルールなどのネットワークリソースを制御できるように、VPCを作成する必要があります。
ネットワークリソースの職務を分離できるようにするために、ネットワークをどのように構成すればよいですか？
1. セキュリティチームがファイアウォールルールを管理する共有VPCを設定し、サービスプロジェクトを通じて開発者とネットワークを共有します
2. 複数のVPCネットワークを設定し、ネットワークを接続するためにマルチNIC仮想アプライアンスを設定します
3. VPCネットワークピアリングを設定し、開発者が共有VPCとネットワークをピアリングできるようにします
4. プロジェクトにVPCを設定します。Compute Network Adminロールをセキュリティチームに割り当て、 Compute Adminロールを開発者に割り当てます
<details><div>
    答え：1
この問題では、ネットワークリソースに対する職務分離を達成するための最適な構成について考える必要があります。特に、セキュリティチームがネットワークリソースを制御でき、それと共に開発者もネットワークに対する作業が可能であるという要件に注目してください。選択肢を検討する際には、これらの要件を満たしつつ、適切な分離と管理が行える構成を選択することが求められます。
基本的な概念や原則：
共有VPC：Google Cloudの機能で、1つの "ホストプロジェクト" 内にVPCネットワークを作成し、同じGoogleCloudオーガニゼーション内の他の "サービスプロジェクト" とそのVPCネットワークを共有します。ファイアウォールルールやネットワークルーティングなどの中央管理を可能にします。
職務分離：セキュリティのベストプラクティスです。特定の任務や機能を複数の個々に分けることで、フラウドやエラーを防止します。
VPCネットワークピアリング：異なるVPCネットワーク間でトラフィックを私的に交換するための接続を設定する機能です。それらのネットワークは同じプロジェクト、または異なるプロジェクト内にあることができます。
マルチNIC仮想アプライアンス：複数のネットワークインターフェースカード（NIC）を備えた、特定のネットワーク機能（ファイアウォール、ロードバランサーなど）を提供するための仮想アプライアンスです。
Compute Network Adminロール：VPCリソースを含むネットワークリソースの管理を担当します。
Compute Adminロール：Compute Engineのリソース全体を管理します。
正解についての説明：
（選択肢）
・セキュリティチームがファイアウォールルールを管理する共有VPCを設定し、サービスプロジェクトを通じて開発者とネットワークを共有します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの共有VPCはネットワークリソースを複数のプロジェクト間で共有したい場合に有効な機能です。共有VPCを使用することで、一つのプロジェクト（この場合はセキュリティチームのプロジェクト）がネットワーク（例えばVPC内のサブネットやファイアウォールルール）を所有・管理し、そのネットワークの一部分を他のプロジェクト（例えば開発者のプロジェクト）に共有することが可能になります。ファイアウォールルールなどのネットワークリソースをセキュリティチームが一元的に管理できる一方で、開発者はそのネットワーク内で自身のアプリやサービスを動作させることができます。
また、職務分離も実現可能で、それぞれが必要なリソースに対する適切な権限を持つことができます。
したがって、これらの要件を見たとき、共有VPCを用いてVPCを設定し、サービスプロジェクトを通じて開発者とネットワークを共有することは最適な解決方法といえます。
不正解についての説明：
選択肢：複数のVPCネットワークを設定し、ネットワークを接続するためにマルチNIC仮想アプライアンスを設定します
この選択肢が正しくない理由は以下の通りです。
まず、複数のVPCネットワークとマルチNIC仮想アプライアンスを設定する方法は、リソースの分離と管理を行うための効果的な方法ではありません。仮想アプライアンスは通常、特定のネットワーク機能を提供するために使用されますが、ネットワークリソースの職務を分離するための効果的な手段とは言えません。
一方、共有VPCを設定することで、セキュリティチームがファイアウォールルールを一元的に管理し、開発者はそれを活用します。これにより正確な職務の分離が実現可能です。
選択肢：VPCネットワークピアリングを設定し、開発者が共有VPCとネットワークをピアリングできるようにします
この選択肢が正しくない理由は以下の通りです。
VPCネットワークピアリングを設定すると、各VPCが等しくネットワークリソースを制御でき、職務分離する目的に合致しません。
一方、共有VPCを設定すると、セキュリティチームがVPCの管理と制御を行い、開発者のプロジェクトとネットワークを明確に分けられます。
選択肢：プロジェクトにVPCを設定します。Compute Network Adminロールをセキュリティチームに割り当て、 Compute Adminロールを開発者に割り当てます
この選択肢が正しくない理由は以下の通りです。
VPCを各プロジェクトに設定し、Compute Network Adminロールをセキュリティチームに、Compute Adminロールを開発者に割り当てると、職務分離が上手く行われません。なぜなら、Compute Adminロールはファイアウォールルールを含むネットワークリソースの変更が許可されてしまうからです。
それに対して、共有VPCではネットワークリソースを制御できるのはセキュリティチームだけであり、職務分離を達成できます。
参考リンク：
https://cloud.google.com/vpc/docs/shared-vpc
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/vpc/docs/provisioning-shared-vpc
</div></details>

### Q.  問題43: 未回答
ある顧客が他社と共同でCompute Engine上にアプリケーションを構築しています。顧客は自社のGoogle Cloudの組織でアプリケーション層を構築し、他社は別のGoogle Cloudの組織でストレージ層を構築しています。これは3層のウェブアプリケーションです。アプリケーションの各部分間の通信は、どのような通信経路であっても公共のインターネットを通過してはなりません。
どの接続オプションを実装すべきですか？
1. VPCピアリング
2. Cloud VPN
3. Cloud Interconnect
4. 共有VPC
<details><div>
    答え：1
この問題は、Google Cloudの接続オプションに対する理解度を試している問題です。顧客と提携企業がそれぞれ異なるGoogle Cloudの組織でアプリケーションとストレージを構築している事実と、アプリケーション間の通信が公共インターネットを通過してはいけないという要件に注目してください。これらの要件を満たし、またGoogle Cloudの接続オプションが何を可能にするのかを理解することが求められます。
基本的な概念や原則：
VPCピアリング：異なるGoogle Cloudプロジェクト間や異なる組織間のVPCネットワークを接続するためのサービスです。公共のインターネットを経由せずに、他のネットワークへ安全に接続することが可能です。
Cloud VPN：公共インターネット上で暗号化された通信トンネルを確立するサービスです。使用すると、他のクラウドプロバイダーやオンプレミスネットワークとの間でセキュアな接続が可能となりますが、公共のインターネットを経由します。
Cloud Interconnect：Google Cloudとオンプレミスインフラや他のクラウドサービスとの間で高速な専用接続を提供するサービスです。しかし公共のインターネットを経由します。
共有VPC：複数のGoogle Cloudプロジェクト間で一つのVPCネットワークを共有するための設定です。リソースを一元管理し、ネットワーク管理を効率化することが可能です。しかし、異なる組織間の接続には使用できません。
正解についての説明：
（選択肢）
・VPCピアリング
この選択肢が正解の理由は以下の通りです。
VPCピアリングを使用すると、別々のGoogle Cloudの組織に存在するネットワーク間で通信が可能になります。この通信は完全にプライベートネットワーク内で行われ、公共のインターネットを介さずに行われます。そのため、これは問題において必要とされる条件を満たします。
また、VPCピアリングは低レイテンシでの通信を可能にし、ネットワーク間の帯域幅を最大限に活用します。これは、3層のウェブアプリケーションにおいて、アプリケーション層とストレージ層の間での高速な通信が必要となるため重要であり、VPCピアリングが最適な選択肢となります。
不正解についての説明：
選択肢：Cloud VPN
この選択肢が正しくない理由は以下の通りです。
Cloud VPNはインターネット上で暗号化されたトンネルを通じて通信が行われるため、公共のインターネットを通過してしまいます。これは問題文の要件では認められていません。
一方、VPCピアリングはネットワーク間の直接的な接続を可能にし、公共のインターネットを通過することなく通信が可能です。よって、不正解の選択肢は問題の要件に適合していません。
選択肢：Cloud Interconnect
この選択肢が正しくない理由は以下の通りです。
Cloud Interconnectは、オンプレミスとGoogle Cloud間の接続を提供し、公共のインターネットを経由せずに通信できますが、このケースは二つのGoogle Cloudの組織間の接続が求められています。
それに対し、VPCピアリングは二つのGoogle Cloudプロジェクト間のネットワーク接続を提供します。
選択肢：共有VPC
この選択肢が正しくない理由は以下の通りです。
共有VPCはFacebook社と同一のGoogle Cloudの組織内で複数のプロジェクトが同一のVPCネットワークを利用するための機能であり、別のGoogle Cloudの組織との間で利用することはできません。しかし、VPCピアリングは異なる組織間でも接続が可能で公共インターネットを回避できるため、要件を満たします。
参考リンク：
https://cloud.google.com/vpc/docs/vpc-peering
https://cloud.google.com/network-connectivity/docs/vpc-peering/how-to/setting-up-vpc-peering
https://cloud.google.com/architecture/building-internet-connectivity-for-private-vms
</div></details>

### Q.  問題47: 未回答
あなたの組織は、サードパーティ企業のCompute Engineインスタンス上で動作する金融サービスアプリケーションをホストしています。アプリケーションを使用するサードパーティ企業のサーバーも、別のGoogle Cloudの組織のCompute Engine上で実行されています。Compute Engineインスタンス間のセキュアなネットワーク接続を構成する必要があります。構成にあたっては、次の要件があります：
- ネットワーク接続が暗号化されている必要があります。
- サーバー間の通信は、プライベートIPアドレスを使用する必要があります。
この要件を満たすために、どうすればよいですか？
1. Compute EngineがホストするアプリケーションをAPIとして公開するApigeeプロキシを設定し、TLSで暗号化することで、サードパーティのみにアクセスを許可します
2. Compute Engineインスタンスの周囲にVPC Service Controlsの境界を設定し、アクセスレベルを介してサードパーティにアクセスを提供します
3. VPCファイアウォールルールによって制御される、組織のVPCネットワークとサードパーティーのVPCネットワーク間のCloud VPN接続を構成します
4. 組織のVPCネットワークとVPCファイアウォールルールで制御されるサードパーティーのVPCピアリング接続を設定します
<details><div>
    答え：3
この問題は、Google Cloud Compute Engine上で動作する異なる組織間でのセキュアなネットワーク接続の設定方法について問われています。要件として、ネットワーク接続の暗号化とプライベートIPアドレスの使用が必要であることが明示されています。以下にあげる選択肢から最適なものを選び、必要な構成を行います。VPCファイアウォールルールによって制御されるネットワーク接続、VPCピアリングの設定、VPC Service Controlsの境界設定、あるいはApigeeプロキシの設定等が考えられます。正解を選ぶためには、各選択肢がどのような機能を持ち、それが問題の要件を満たすか否かを理解することが重要です。
基本的な概念や原則：
VPC（Virtual Private Cloud）：Google Cloud上でプライベートな仮想ネットワークを作成し、そのネットワーク上でCompute Engineインスタンスなどを稼働させるためのサービスです。専用のIPアドレス範囲を持ち、自由に構成を設定できます。
Cloud VPN：Google Cloud上で仮想プライベートネットワーク（VPN）接続を作成するためのサービスです。VPN接続を使用すると、Google Cloudと他のネットワークをセキュアに接続することができます。通信は暗号化され、プライベートIPアドレスで行うことができます。
VPCファイアウォールルール：Google Cloud VPC内のリソースへのネットワークアクセスを制御するためのルールです。特定のネットワークトラフィックを許可または拒否できます。
VPCピアリング：2つのVPCネットワーク間を直接接続できるネットワークサービスです。通信はプライベートIPアドレスで行われ、ネットワーク遅延が少ないですが、通信は暗号化されません。
VPC Service Controls：Google Cloudサービスへのデータアクセスを管理および制限するツールです。しかし、Compute Engineインスタンス間のネットワーク通信の管理や暗号化には直接影響はありません。
Apigee：Google CloudのAPI管理プラットフォームです。APIに対するトラフィック管理、APIセキュリティ、APIモニタリングなどの機能を提供しますが、Compute Engineインスタンス間のセキュアなネットワーク接続の設定には直接利用できません。
正解についての説明：
（選択肢）
・VPCファイアウォールルールによって制御される、組織のVPCネットワークとサードパーティーのVPCネットワーク間のCloud VPN接続を構成します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのVPC（Virtual Private Cloud）ネットワークは、Compute Engineインスタンス間でプライベートIPアドレスを使用して通信を行うことを可能にします。これにより、サーバー間通信のプライベートIPアドレス使用の要件が満たされます。
次に、Cloud VPNはVPC間の安全な通信チャネルを提供するサービスで、IPSecプロトコルを使用してネットワークの通信を暗号化します。これにより、ネットワーク接続が暗号化される要件も満たされます。
最後に、VPCファイアウォールルールを用いて、VPCネットワーク間の通信の許可や拒否の制御が可能です。これにより、必要とされる安全なネットワーク接続を確保することができます。
したがって、正解はVPCファイアウォールルール制御の下でのCloud VPN接続の設定です。これにより、必要要件のすべてが満たされます。
不正解についての説明：
選択肢：組織のVPCネットワークとVPCファイアウォールルールで制御されるサードパーティーのVPCピアリング接続を設定します
この選択肢が正しくない理由は以下の通りです。
VPCピアリング接続は通信を暗号化しないため、要件に適合しません。
一方、Cloud VPN接続は通信を暗号化するため、こちらが適切な解決策です。VPCピアリングは、プライベートIPアドレスでの通信は可能ですが、暗号化という重要な要件を満たせないため不適切です。
選択肢：Compute Engineインスタンスの周囲にVPC Service Controlsの境界を設定し、アクセスレベルを介してサードパーティにアクセスを提供します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsはデータ漏洩を防ぐためのサービスで、特定のVPCリソースへのアクセスを管理しますが、Compute Engineインスタンス間の暗号化されたネットワーク接続の構成やプライベートIPアドレスを使用した通信の実現には向いていません。これらの要件はCloud VPN接続を通じて達成できます。
選択肢：Compute EngineがホストするアプリケーションをAPIとして公開するApigeeプロキシを設定し、TLSで暗号化することで、サードパーティのみにアクセスを許可します
この選択肢が正しくない理由は以下の通りです。
ApigeeプロキシはAPIのトラフィックを管理することが目的であり、Compute Engineインスタンス間のプライベートなネットワーク接続の設定には適していません。この要件は、VPCネットワーク間のCloud VPN接続が最適で、暗号化通信とプライベートIPアドレスの要件を満たします。
参考リンク：
https://cloud.google.com/vpn/docs/concepts/overview
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#secure_communications_between_vpcs
https://cloud.google.com/vpc/docs/vpc-peering
</div></details>

## 3
### Q.  問題1: 未回答
あなたの会社はITインフラの大半をGoogle Cloudに移行する予定です。既存のオンプレミスActive DirectoryをGoogle CloudのIDプロバイダーとして活用したいと考えています。オンプレミスのActive DirectoryとGoogle Cloudを統合し、アクセス管理を構成するために取るべき2つの手順はどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudと既存のオンプレミスActive Directoryを統合し、アクセス管理を構成する方法について求められています。ここで重要な点は、既存のActive DirectoryをGoogle CloudのIDプロバイダーとして活用する予定であるという条件です。この情報から、Active DirectoryとGoogle Cloudを連携させるための適切なGoogle Cloudのサービスや機能を理解し、選択肢から正しいものを選び出すことが必要になります。とくにCloud Identity、Google Cloud Directory Sync、Identity Platform、IAMロールやIAMグループなど、それぞれのロールと機能を理解する上での注意が求められます。
基本的な概念や原則：
Active Directory：Microsoftのディレクトリサービスで、オブジェクト（ユーザーやグループなど）を組織化し、管理します。ネットワーク上でのアクセス制御やユーザー認証を実現します。
Cloud Identity SAML統合：Google Cloudのサービスです。既存のActive DirectoryやLDAPサーバーとCloud Identityを統合します。ユーザーやグループのプロビジョニングを実現します。
Google Cloud Directory Sync：Google Cloud用のディレクトリ同期ツールです。既存のActive DirectoryやLDAPサーバーの情報をGoogle Cloudに同期します。
Identity Platform：Google Cloudの認証サービスです。ユーザーのサインアップ、サインイン、アカウントリカバリーなどの機能を提供します。
IAMロール：Google Cloudのアクセス制御概念です。特定のユーザーやグループがリソースに対して許可される操作を定義します。そのため一般的にはロールの作成はActive Directoryグループの作成では補完できません。
IAMグループ：Google Cloudのアクセス制御のための概念です。特定のユーザーやサービスアカウントをグループ化し、共通の権限を付与することが可能です。しかし、Active Directoryグループを直接作成したり、対応づける機能はありません。
正解についての説明：
（選択肢）
・Cloud Identity SAML統合を使って、Google Cloudにユーザとグループをプロビジョニングします
・Google Cloud Directory Syncをインストールし、Active DirectoryおよびCloud Identityに接続します
この選択肢が正解の理由は以下の通りです。
まず、"Cloud Identity SAML統合を使って、Google Cloudにユーザとグループをプロビジョニングします"は、Active Directory（IDプロバイダー）とGoogle Cloudの統合を可能にします。SAML（Security Assertion Markup Language）は、異なるセキュリティドメイン間で認証と承認情報を交換するための標準プロトコルです。Cloud Identity SAML統合を利用することでオンプレミスのActive Directoryからクラウドに認証情報を安全に受け渡すことが可能となります。
また、"Google Cloud Directory Syncをインストールし、Active DirectoryおよびCloud Identityに接続します"は、オンプレミスのActive DirectoryとGoogle Cloudの間に同期を行うことを可能にします。これにより、オンプレミスのActive Directoryで行われた変更（ユーザの追加や削除など）がGoogle Cloudにも反映されるため、一元的かつ効率的なアクセス管理を実現することができます。これら２つの手順により、オンプレミスのActive DirectoryとGoogle Cloudを連携させ、アクセス管理を効率的に行うことが可能となります。
不正解についての説明：
選択肢：Identity Platformを使用して、ユーザーとグループをGoogle Cloudにプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
Identity Platformはフェデレーションされたアイデンティティ、ユーザ管理、認証を提供するもので、オンプレミスのActive Directoryと直接連携する機能は提供していません。
一方、Cloud IdentityやGoogle Cloud Directory SyncはActive Directoryとの連携をサポートしており、アクセス管理の構成に適しています。
選択肢：各Active Directoryグループに対応する権限を持つIAM（Identity and Access Management）ロールを作成します
この選択肢が正しくない理由は以下のとおりです。
まず、Active Directoryグループに対応するIAMロールを作成しても、それ自体ではオンプレミスのActive DirectoryとGoogle Cloudの統合に貢献せず、必要なアクセス管理を構成できません。
代わりに、Google Cloud Directory Syncを使用してActive DirectoryとCloud Identityを連携したり、Cloud Identity SAML統合を使用してユーザとグループをプロビジョニングする必要があります。
選択肢：各Active Directoryグループに対応する権限を持つIAM（Identity and Access Management）グループを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloudでは、IAMグループは存在せず、IAMロールが提供されるのみです。Active Directoryのグループと対応付けるためには、Cloud IdentityやGoogle Cloud Directory Syncのようなツールを使用してユーザーやグループを同期させるべきです。
参考リンク：
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-synchronizing-user-accounts
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-configuring-single-sign-on
https://support.google.com/a/answer/106368?hl=en
</div></details>

### Q.  問題2: 未回答
Google Cloudリソースへのアクセスを必要とするGoogle Cloud外のアプリケーションを実行しています。ワークロードIDフェデレーションを使用して、外部のIDにIdentity and Access Management（IAM）ロールを付与し、サービスアカウントキーに関連するメンテナンスとセキュリティの負担を軽減しています。別のユーザーのIDを偽装してGoogle Cloudリソースに不正にアクセスしようとする試みから保護する必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud外部のアプリケーションのGoogle Cloudリソースへのアクセス管理について考える必要があります。そして、IDフェデレーションという概念を理解し、これを使用して不正アクセスから保護する措置を選択することが求められています。選択肢を見る際には、特にセキュリティの観点から不適切なアクセスの防止策を選ぶ必要があります。また、全ての解答が適切なセキュリティ対策である可能性はありますが、問題の文脈に最も適したものを2つ選ぶよう求められている点にも注意が必要です。
基本的な概念や原則：
ワークロードIDフェデレーション：Google Cloudの外部のIDをGoogle Cloudの認証に連携させる機能です。IDフェデレーションを使用すると、ワークロードがGoogle Cloudリソースにアクセスするために必要な認証情報を自動的に取得できます。
Identity and Access Management（IAM）：ユーザーやサービスアカウントが何を行うことができるかを制御するGoogle Cloudのツールです。ロールとポリシーを設定してリソースへのアクセスを管理します。
サービスアカウント：アプリケーションがGoogle Cloudサービスと通信するために使用する特殊なアカウントです。サービスアカウントキーは、認証と認可のための情報を保持しています。
専用のプロジェクト：特定の目的やロールに専用されたGoogle Cloudプロジェクトです。効果的なリソース管理とセキュリティ維持に役立ちます。
属性マッピング：ユーザーアイデンティティの属性からGoogle Cloudのロールやポリシーにマッピングするプロセスです。不変属性を使用すると、IDの偽装を防ぐことができます。
正解についての説明：
（選択肢）
・ワークロードIDプールとプロバイダの管理には、専用のプロジェクトを使用します
・属性マッピングで不変属性を使用します
この選択肢が正解の理由は以下の通りです。
まず、ワークロードIDフェデレーションの環境を管理するために、専用のプロジェクトを使用することは、セキュリティ管理に有益です。専用のプロジェクトを使用することで、適切なアクセス制御を保持し、不正アクセスのリスクを軽減することができます。
また、IDフェデレーションを専用のプロジェクトで分離することで、誤って設定を変更したり、不適切なアクセス許可を付与するリスクを軽減することができます。
次に、属性マッピングで不変属性を使用することは、ユーザのIDが偽装されるのを防ぐ効果的な手段です。不変属性は、ユーザのライフサイクル全体で変更されない属性を指します。これらの属性を使用してユーザを一意に識別することで、偽装やアイデンティティの混乱を防ぐことができます。
また、これにより、ユーザのアクセス制御と追跡が容易になり、一貫性のあるセキュリティポリシーの適用を支援します。
不正解についての説明：
選択肢：IAM APIのデータアクセスログを有効にします
この選択肢が正しくない理由は以下の通りです。
IAM APIのデータアクセスログを有効にすることは、Google Cloudリソースへのアクセスのログを取得するためのもので、不正アクセスを防止する機能ではありません。
一方、専用のプロジェクトを使用すると、管理が一元化され詐称のリスクを減らします。
また、属性マッピングで不変属性を使用すると、ユーザーIDが偽装されるリスクを最小限に抑えられます。
選択肢：サービスアカウントになりすますことのできる外部IDの数を制限します
この選択肢が正しくない理由は以下の通りです。
サービスアカウントになりすますことのできる外部IDの数を制限することは、IDを偽装しての不正アクセスを防ぐための直接的な策ではありません。
一方、不変属性を利用することや専用のプロジェクトを使用することで、ID管理の一貫性とセキュリティを確保し、不正アクセスを防ぐことが可能です。
選択肢：サービスアカウントがアクセスできるリソースを制限します
この選択肢が正しくない理由は以下の通りです。
サービスアカウントがアクセスできるリソースを制限することは良いセキュリティ対策であるものの、それは別のユーザーのIDを偽装しての不正アクセスを防ぐ対策ではありません。ワークロードIDプールとプロバイダの管理に専用のプロジェクトを使うことや、属性マッピングで不変属性を使うことで、不正なユーザーの認証対策を行なうことが可能です。
参考リンク：
https://cloud.google.com/iam/docs/workload-identity-federation
https://cloud.google.com/iam/docs/configuring-workload-identity-federation
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題3: 未回答
既存のVPC Service Controlsの境界を新しいアクセスレベルで更新したいと考えています。この変更で既存の境界が壊れるのを避け、オーバーヘッドを最小限に抑えながら、ユーザーへの混乱を最小限に抑える必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、VPC Service Controlsの境界を新しいアクセスレベルで更新する方法について問われていますが、その際に既存の境界が壊れることを避けることと、オーバーヘッドやユーザーの混乱を最小限に抑えることが要求されています。したがって、有効な解決策は、新しい変更が本当に機能するかどうかを確認しながら、段階的かつコントロールされた方法でこれらの更新を行います。また、選択肢を評価する際には、既存の環境に影響を与えることなく、新しいアクセスレベルをテストできる選択肢を選ぶことが重要です。
基本的な概念や原則：
VPC Service Controls：Google Cloudのサービスに対するネットワーク内のアクセスを制御し、データがGoogle Cloudプロジェクトの境界を越えて漏れることを防ぐ稼働環境セキュリティ対策です。
境界ドライランモード：指定されたVPC Service Controlsの境界について、詳細な監査ログの生成を含めて制約をシミュレートするモードです。実際の影響を確認しながら安全に変更をテストするために使用します。
アクセスレベル：Google Cloud Identity-Aware Proxyの機能で、ユーザーやデバイスのコンテキスト情報（位置、IPアドレス、デバイスセキュリティステータスなど）に基づいてクラウドリソースへのアクセスを制御する設定です。
ネットワークセキュリティ：ネットワーク内のアクセスとデータの移動を制御し、不正なアクセスやデータ漏洩を防ぐ技術的な対策や管理的な対策のことです。
監査ログ：システムやネットワークの操作履歴などを記録した情報です。セキュリティ監視や問題解析、性能分析などに使用されます。
正解についての説明：
（選択肢）
・境界のドライランモードを有効にします。新しいアクセスレベルを境界ドライラン構成に追加します。アクセスレベルの検証後、境界の設定を更新します
この選択肢が正解の理由は以下の通りです。
まず、VPC Service Controlsのドライランモードを有効にすることにより、新しいアクセスレベルが境界に影響を与えるであろうシナリオを、境界自体を変更せずにシミュレートすることができます。ドライランモードでは、新しいアクセスレベルが実際のトラフィックに対してどのように影響を与えるかを予測し、意図しない遮断や設定の不一致を防ぐことができます。これにより、既存の境界が壊れることのリスクを最小限に抑えることが可能です。
また、この新しいアクセスレベルは境界のドライラン構成中に追加されます。この段階では、アクセスレベルは境界に対して影響を与えませんが、その効果を見積もることができるのです。そのため、問題が検出された場合には適切に修正できるよう、事前の点検や修正の機会が得られます。
このようなプロセスを経ることで、ユーザーへの混乱を最小限に抑えつつ、オーバーヘッドも最小限に抑えることができます。
また、新しいアクセスレベルが問題なく機能することを確認した後、安全に境界の設定を更新することができます。
不正解についての説明：
選択肢：既存の境界の完全なレプリカを作成します。レプリカに新しいアクセスレベルを追加します。アクセスレベルの検証後、元の境界を更新します
この選択肢が正しくない理由は以下の通りです。
既存の境界の完全なレプリカを作成すると、導入のオーバーヘッドと混乱が増加します。
それに対して、ドライランモードでは、実際の影響を与えずに新しいアクセスレベルの効果を確認でき、オーバーヘッドとユーザーの混乱を最小限に抑えます。
選択肢：既存の境界と決して一致しない新しいアクセスレベルで境界を更新します。過度に寛容にならないように、新しいアクセスレベルを一度に1つの条件ずつ、希望する状態に一致するように更新します
この選択肢が正しくない理由は以下の通りです。
新しいアクセスレベルを1つずつ追加する方法は、オーバーヘッドの増加と混乱の原因になります。
一方、ドライランモードを用いると既存の境界を破壊することなく新しい設定を検証でき、ユーザーへの影響を最小限に抑えることができます。
選択肢：境界のドライランモードを有効にします。新しいアクセスレベルを境界構成に追加します。アクセスレベルの検証後、境界設定を更新します
この選択肢が正しくない理由は以下の通りです。
新しいアクセスレベルを直接境界構成に追加すると、アクセスレベルの影響が即時に反映され、既存の境界が壊れたりユーザーに混乱を招く可能性があります。
一方、正解では新しいアクセスレベルを"境界ドライラン構成"に追加しているため、影響を評価し確認後に正式な設定を更新できます。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/update-perimeter
https://cloud.google.com/access-context-manager/docs/manage-access-levels
https://cloud.google.com/vpc-service-controls/docs/dry-run-mode
</div></details>

### Q.  問題4: 未回答
あなたの組織は最近Security Command Center（SCC）の標準階層を有効にしました。しかしその後、いくつかのCloud Storageバケットが誤って一般公開されました。インシデントの影響を調査し、修復する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、公開されてしまったCloud Storageバケットの影響調査と再発防止に関してどのように対処すべきかが求められています。問題のポイントは公開されたバケットへのアクセスを制限し、それを維持することと、再発防止措置を講じることです。適切な組織のポリシーを適応し、不適切なアクセスを避けるにはどの措置が必要か選択肢の中から選ぶことが求められます。また、措置を講じた後の影響範囲の確認や記録の点も重要な部分として捉えて解答を選ぶべきです。
基本的な概念や原則：
Security Command Center（SCC）：Google Cloudのセキュリティとデータリスクのプラットフォームです。組織のリソースを保護するための洞察と通知を提供します。
Cloud Storageバケット：Google Cloudのオブジェクトストレージサービスです。大量の非構造化データを保存し、管理できます。
公開アクセス：Cloud Storageバケットのコンテンツが一般に公開され、認証なしでアクセスできる状態を指します。セキュリティ上のリスクが考えられるため、管理には注意が必要です。
組織ポリシー：Google Cloudのリソースに対する管理ポリシーの一種で、特定の制約を適用してリソースの使用を管理します。組織全体または特定のフォルダ、プロジェクトに適用できます。
storage.publicAccessPrevention：組織ポリシーの種類の一つで、Cloud Storageバケットに対する公開アクセスを制限することができます。このポリシーを強制することで、誤ってバケットを公開するリスクを軽減できます。
storage.uniformBucketLevelAccess：組織ポリシーの種類の一つで、バケット内のすべてのオブジェクトに対して一貫したアクセス制御を提供することができます。
VPC Service Controls：Google Cloudの仮想プライベートクラウド（VPC）サービスで、特定のサービスからのデータの出入りを制御する機能です。不正アクセスを防ぐための一つの手段です。
正解についての説明：
（選択肢）
・1. バケットの権限を変更してアクセスを制限します
2. バケットの使用ログをクエリして、データへの不正アクセスについて報告します
3. 組織ポリシーstorage.publicAccessPreventionを強制して回帰を回避します。
この選択肢が正解の理由は以下の通りです。
まず、公開されたCloud Storageバケットのアクセスを制限するために、そのバケットのパーミッションを変更する必要があります。これによって、不適切に公開されているデータへのアクセスを即座に停止し、インシデントの影響を最小限に抑えます。
次に、組織全体のポリシーであるstorage.publicAccessPreventionを実施することで、Cloud Storageバケットが誤って一般公開されることを防ぐことができます。このポリシーを適用することで、組織が保有するすべてのバケットに対する公開設定の変更を制限し、同じ問題が再発しないよう対策できます。以上の理由から、これらの手順はインシデントの影響を調査し、修復するのに適切な方法であると言えます。
不正解についての説明：
選択肢：1. すべてのユーザーにアクセスを許可するIdentity and Access Management（IAM）をバケットから削除します
2. 組織ポリシーstorage.uniformBucketLevelAccessを適用して回帰を防止します
3. データアクセスログをクエリして、不正アクセスについて報告します。
この選択肢が正しくない理由は以下の通りです。
storage.uniformBucketLevelAccessポリシーは、バケット全体に一貫したアクセス制御を提供する機能ですが、一般公開を防ぐ機能は提供しません。
それに対して、storage.publicAccessPreventionポリシーは、バケットの一般公開を直接防ぐため、ここでの要件には、公開アクセスの防止が必要なため正解となります。
選択肢：1. 権限を変更して、許可されたユーザーのアクセスを制限します
2. すべての実稼働プロジェクトの周囲にVPC Service Controls境界を適用し、不正なアクセスを直ちに阻止します
3. 管理者のアクティビティ監査ログを確認して、不正なアクセスについて報告します。
この選択肢が正しくない理由は以下の通りです。
まず、不正解の1番目の方法は正解の最初のステップと同じですが、2番目の手段が問題です。VPC Service ControlsはプロジェクトとVPCネットワークのリソースを保護する目的ではありますが、すでに公開されてしまったCloud Storageバケットのアクセス制限問題の解決には適していません。
また、正解の選択肢ではstorage.publicAccessPreventionポリシーを実施することで一般公開の設定を制限しますが、不正解の選択肢にはそのような手段が含まれていません。
選択肢：1. バケットの権限を変更してアクセスを制限します
2. バケットへの不正アクセスがないかデータアクセス監査ログを照会します
3. 設定ミスが修正されたら、Security Command Centerで検出結果をミュートします。
この選択肢が正しくない理由は以下の通りです。
ここで考慮すべき重要なポイントは、同様のインシデントを防ぐための戦略が含まれていないことです。選択肢からは、組織ポリシーのstorage.publicAccessPreventionを実施することによる再発防止の措置が欠けており、このため不適切です。
参考リンク：
https://cloud.google.com/security-command-center/docs
https://cloud.google.com/storage/docs/access-logs
https://cloud.google.com/storage/docs/using-public-access-prevention
</div></details>

### Q.  問題5: 未回答
あなたは会社のセキュリティ管理者で、Google Cloudのアクセス制御（識別、認証、承認）の管理を担当しています。
認証と認可を設定する際に従うべきGoogle推奨のベストプラクティスはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのアクセス制御に関するベストプラクティスについて理解することが求められます。セキュリティ管理者としてのロールを考慮に入れ、認証と認可に関する選択肢に焦点を当てていくことが重要です。また、単にGoogle Cloudのサービスを使用するだけでなく、セキュリティプラクティスに適した選択肢が最善の解答であるという観点も忘れないでください。
基本的な概念や原則：
SSO/SAML：シングルサインオン（SSO）は、複数のサービスへの認証を一度のログインで管理するテクノロジーです。SAML（Security Assertion Markup Language）は、セキュリティ情報を交換するための標準プロトコルで、SSOの実装によく使用されます。
Cloud Identity：Google CloudのIdentity and Access Management（IAM）の一部で、ユーザーの認証とライフサイクル管理を行うサービスです。SSO/SAMLと統合することにより、認証スキームのシームレスな統合が可能です。
事前定義されたロール：Google Cloud IAMでは、特定のサービスに対するアクセス権限が事前に定義されたロールとして提供されています。これにより、適切なアクセス制御とセキュリティが実現できます。
IAM（Identity and Access Management）：Google Cloudのユーザー管理とアクセス制御を担当するサービスです。セキュリティベストプラクティスに従い、適切なアクセス許可をユーザーに付与することが推奨されます。
正解についての説明：
（選択肢）
・ユーザー認証とユーザーライフサイクル管理のために、SSO/SAMLをCloud Identityと統合します
・事前に定義されたロールによるきめ細かなアクセスを提供します
この選択肢が正解の理由は以下の通りです。
まず、SSO/SAMLをCloud Identityと統合することでユーザー認証とユーザーライフサイクル管理を効果的に行うことができます。SSO（Single Sign-On）はユーザーが一度の認証で複数のシステムにアクセスできるようにするもので、SAML（Security Assertion Markup Language）はウェブブラウザを介してシングルサインオンを実現するフレームワークです。これをCloud Identityと統合することでユーザー認証を一元化し、セキュリティの管理を効率化することができます。
次に、事前に定義されたロールによるきめ細かなアクセスを提供することは、セキュリティのベストプラクティスの一つです。これは極小の権限しか持たないロールを個々のユーザーやサービスに割り当てることで、アクセス制御を強化し、潜在的な権限の乱用を防ぐ目的があります。特にGoogle Cloudでは、事前に定義されたロールを用いてユーザーやサービスのアクセスを制御していくのが推奨されています。これにより安全かつ効果的な認証・認可設定が可能となります。
不正解についての説明：
選択肢：Googleのデフォルトの暗号化を使用します
この選択肢が正しくない理由は以下の通りです。
Googleのデフォルトの暗号化はデータの保護に関する重要な側面ですが、ここで求められているのは"認証"と"認可"に関するベストプラクティスです。この選択肢は直接的なアクセス制御には関連していません。
一方、SSO/SAMLのCloud Identityとの統合と事前に定義されたロールによるアクセス提供は、アクセス制御の問題解決策として直接的かつ効果的です。
選択肢：Google Cloudにユーザーを手動で追加します
この選択肢が正しくない理由は以下の通りです。
Google Cloudに手動でユーザーを追加すると、一人ひとりの管理が手間になり、認証と認可の流れが複雑化します。これは、効率よく管理するためのベストプラクティスとは異なります。そのため、SSO/SAMLを用いてCloud Identityと統合することでユーザーライフサイクルを自動化管理し、効率性とセキュリティを確保するのが推奨されます。
選択肢：GoogleのIAM（Identity and Access Management）サービスを使用して、基本的なロールを持つユーザーをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
Google IAMを使用して基本的なロールを持つユーザーをプロビジョニングするという選択肢は、適切なアクセス管理のためのベストプラクティスではありません。基本的なロールを設定すると、ユーザーに必要以上の権限が与えられる可能性があるため、原則として最小権限の原則を遵守した事前定義されたロールによるアクセスを提供する方法が推奨されます。
参考リンク：
https://cloud.google.com/identity/saml
https://cloud.google.com/iam/docs/using-predefined-roles
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題6: 未回答
あなたの会社の新しいCEOは最近、会社の2つの部門を売却しました。あなたの会社の取締役は、これらの部門に関連するGoogle Cloudプロジェクトを新しい組織ノードに移行する手助けをするようあなたに依頼しました。この移行を行う前に必要な準備手順はどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudプロジェクトの組織ノードへの移行にどのような準備が必要かを理解することが求められています。既存のIDやIAMロールの移行と、VPC Service Controlsの境界からのプロジェクトの削除という明確な手順が示されています。選択肢を見る際は、既存の設定や構成を保ちつつ新しい組織ノードへの適切な移行を達成するものを選びます。さらに、互換性やセキュリティを維持し、新しい組織ノードのポリシーに準拠するものを選んでください。
基本的な概念や原則：
継承されたIDおよびIAMロール：Google Cloudのリソース階層において、特定のリソースに付与されたアクセス権限は、その下位のリソースにも継承されます。これにより、プロジェクトや組織全体での権限管理が可能になります。
VPC Service Controls：Google Cloudサービス間の通信を制御して、データ漏えいのリスクを軽減するためのサービスです。サービスパーリメーター（境界）を定義して、それを超えた通信を制限します。
移行プロジェクト：Google Cloud上での移行作業を管理するためのプロジェクトです。資源の移動や権限の付与など、移行に必要な操作がここで行われます。
組織ポリシー：Google Cloudのリソース階層全体で制御を設けるためのフレームワークです。特定の制約を定義して、それに沿ったリソース管理を強制することができます。
正解についての説明：
（選択肢）
・移行対象プロジェクトで継承されたIDおよびIAMロールを特定します
・VPC Service Controlsの境界およびブリッジから特定の移行プロジェクトを削除します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudプロジェクトを他の組織ノードに移行する際、継承されたIDおよびIdentity and Access Management（IAM）ロールを特定することは重要です。これによりアクセス管理が適切に行われ、誤ったアクセスや権限が発生する可能性を最小化します。また新しい組織に移行した後も適切な操作が実行できるようにするためには、それらのアクセス許可や権限が何であるかを明確に理解しておくことが求められます。
次に、VPC Service Controlsは、Google Cloudリソースが特定のVirtual Private Cloud（VPC）ネットワークやプロジェクトに制限されるようにするサービスです。移行対象のプロジェクトがVPC Service Controlsの境界に含まれている場合、そのプロジェクトを移行する前にこれを削除する必要があります。これにより、移行に伴うネットワークの接続問題やセキュリティの問題を防ぐことができるのです。
不正解についての説明：
選択肢：プロジェクトレベルのカスタムIDおよびIAMロールをすべて削除します
この選択肢が正しくない理由は以下の通りです。
プロジェクトレベルのカスタムIDおよびIAMロールをすべて削除する行為は、移行対象のプロジェクトの適切な運用を保証できない可能性があります。そのため、これらを特定する事が重要で、無条件に削除するのはリスクが高いです。
選択肢：組織ポリシーの継承を禁止します
この選択肢が正しくない理由は以下の通りです。
新しい組織ノードへのプロジェクト移行では、組織ポリシーの継承を禁止するのではなく、移行対象プロジェクトで継承されるIDおよびIAMロールと、VPC Service Controlsの境界およびブリッジの設定が必要です。組織ポリシーの継承を禁止することでは、これらの重要な事項が漏れてしまう可能性があります。
選択肢：移行するすべてのプロジェクト用に新しいフォルダを作成します
この選択肢が正しくない理由は以下の通りです。
新しいフォルダを作成するという手順は、移行のための直接的な準備ではなく、組織のリソース整理の一環であり、必須ではありません。
それに対して、IDやIAMロールの特定はアクセス権限を適切に移行するため、VPC Service Controlsの設定は移行によるセキュリティ影響を把握するため、といった準備が必要です。
参考リンク：
https://cloud.google.com/resource-manager/docs/project-migration
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/vpc-service-controls/docs/perimeters
</div></details>

### Q.  問題7: 未回答
Google Cloudコンソールのログインアクティビティイベントと、Google Cloudリソースの設定を変更するAPI呼び出しのセキュリティログをエクスポートし、監査する必要があります。エクスポートは以下の要件を満たす必要があります：
- Google Cloudの組織内のすべてのプロジェクトの関連ログをエクスポートします。
- ログをほぼリアルタイムで外部のSIEMにエクスポートします。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの全体的なログエクスポートおよび監査設定に関する理解が求められています。ここでの課題は、全てのプロジェクトのログをエクスポートし、それをほぼリアルタイムで外部のSIEMに転送することです。特定のパラメータやサービスの使用により、この要求を満たす適切な設定を検討する事が重要です。またSIEMでの対応についても考慮し、適切なフィールドの情報が収集できていることを確認する必要があります。
基本的な概念や原則：
ログエクスポート：Google Cloudのログ検索、分析、保存のための機能です。ログエクスポートを使用すると、Cloud LoggingのログをCloud Storage、BigQuery、またはCloud Pub/Subにエクスポートできます。
includeChildrenパラメータ：Google Cloudのログシンクにおけるパラメータで、これを使用すると親リソース（組織、フォルダ、プロジェクト）の全ての子リソースからログをエクスポートすることができます。
Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。大量のメッセージを生産者から消費者に信頼性高く、高速に送ることが可能です。
SIEM（セキュリティ情報およびイベント管理）：セキュリティ情報やイベントを収集、分析し、監視するシステムやソフトウェアのことです。異常行動やセキュリティ違反の検出に役立ちます。
AuthenticationInfoフィールド：ログエクスポートにおけるフィールドで、認証情報（誰が何をしたか）を含む情報が記録されます。これは、アクセス監査やセキュリティログの分析に重要です。
正解についての説明：
（選択肢）
・includeChildrenパラメータを使用して組織レベルでログシンクを作成し、宛先をPub/Subトピックに設定します
・SIEMが監査ログエントリのAuthenticationInfoフィールドを処理してID情報を収集することを確認します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudのログエクスポートでは、"includeChildren"パラメータを使用してログシンクを作成することにより、組織内のすべてのプロジェクトの関連ログを一度にエクスポートすることが可能になります。これらのログは、Google Cloud Pub/Subトピックにリアルタイムで送れます。Pub/Subトピックを利用することで、ログは指定されたトピックに発行され、Pub/Subからの引き出しはサブスクライバーによって行われます。結果として、これらのログは外部のSIEMシステム（セキュリティ情報およびイベント管理システム）にほぼリアルタイムでエクスポートできます。これにより、リアルタイムでログを監査するための要件が満たされます。
また、Google Cloudの監査ログエントリには様々なフィールドが含まれていますが、その中の"AuthenticationInfo"フィールドは誰が何をしたかといった重要な監査情報を含むため、SIEMがこのフィールドを処理してID情報を収集することが重要です。これにより、正確な監査が可能になります。
不正解についての説明：
選択肢：組織レベルでPub/Sub宛先のログシンクを作成します
この選択肢が正しくない理由は以下の通りです。
単純に"組織レベルでPub/Sub宛先のログシンクを作成します"だけでは、そのログシンクが実際に全てのプロジェクトの関連ログをエクスポートするように設定されていることは保証されません。includeChildrenパラメータを使用して確実にすべての子プロジェクトをカバーする設定が必要です。
選択肢：組織レベルでのデータアクセス監査ログを有効にして、すべてのプロジェクトに適用します
この選択肢が正しくない理由は以下の通りです。
監査ログの有効化は有効なセキュリティステップではありますが、それ自体ではログを外部のSIEMにエクスポートする要件を満たせません。ログエクスポートはログシンクを使用して設定する必要があります。
選択肢：管理コンソールでGoogle Workspaceの監査ログをGoogle Cloudと共有できるようにします
この選択肢が正しくない理由は以下の通りです。
Google Workspaceの監査ログをGoogle Cloudと共有することは、課題の要件に該当しません。ここでは、Google CloudのログインアクティビティとAPI呼び出しのセキュリティログのエクスポート、並びにリアルタイムでのSIEMへの送信が求められていますが、Google Workspaceのログの共有はこれとは別の機能です。
参考リンク：
https://cloud.google.com/logging/docs/export/configure_export_v2
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/pubsub/docs
</div></details>

### Q.  問題8: 未回答
サービスアカウントキーが、複数の公開コードリポジトリで公開されています。ログを確認したところ、そのキーが短命の認証情報を生成するために使用されていることに気づきました。そのサービスアカウントでのアクセスを直ちに削除する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、サービスアカウントキーのセキュリティ侵害に対する対応策を考える必要があります。この問題が要求しているのは、公開されてしまったサービスアカウントキーによる認証情報の生成を直ちに停止する方法です。したがって、各選択肢がこの要件を満たすかどうか、即時性と効果の観点から検討することが求められます。
基本的な概念や原則：
サービスアカウント：Google Cloud内で動作するアプリケーションの認証とアクセス許可に使用される特殊なGoogleアカウントです。コード内で認証するために用いられます。
サービスアカウントキー：サービスアカウントのIDと秘密鍵のペアです。アプリケーションがGoogle Cloud APIにアクセスする際の認証に使用されます。
短命の認証情報：一時的な認証手段で、一定時間後に期限切れとなる認証情報のことです。
サービスアカウントの削除：不正使用を防止するための最終手段で、特定のサービスアカウントを完全に削除します。
サービスアカウントキーの無効化：特定のサービスアカウントキーがGoogle Cloud APIにアクセスできないようにする措置です。ただし、既にキーを持っている者がいれば、新しい認証情報を生成できます。
正解についての説明：
（選択肢）
・侵害されたサービスアカウントを削除します
この選択肢が正解の理由は以下の通りです。
まず、サービスアカウントが危険にさらされた場合、セキュリティ対策として最も直接的で効果的なアクションはそのサービスアカウントを速やかに削除することです。その理由としては、そのサービスアカウントが公開状態であり、そのキーが不正に使われている可能性があります。サービスアカウントを削除することで、そのキーによる不正アクセスを直ちに停止することができます。この手段は即時性と確実性が求められる場合に特に有効です。
ただし、サービスアカウントの削除はそれが使われていたサービスに影響を及ぼす可能性があるので、削除する前にその影響範囲を把握しておく必要があります。
以上の事から、侵害されたサービスアカウントを速やかに削除するのが適切な対策となります。
不正解についての説明：
選択肢：漏洩したサービスアカウントキーを無効にします
この選択肢が正しくない理由は以下の通りです。
漏洩したサービスアカウントキーを無効にするだけでは、そのサービスアカウント自体が存在する限り、新たなキーを生成し、不正なアクセスを続行することが可能です。しかし、対して侵害されたサービスアカウントを削除することで、直ちにそのサービスアカウントからの全てのアクセスを停止し、問題を解決できます。
選択肢：サービスアカウントの認証情報が自動的に期限切れになるまで待ちます
この選択肢が正しくない理由は以下の通りです。
サービスアカウントの認証情報が自動的に期限切れになるまで待つという選択は、セキュリティに対するソフトな対策であり状況の深刻さを無視した行為です。公開されたキーを通じて不正なアクセスが可能な場合、時間が経過することは逆にリスクを増大させてしまいます。そのため、直ちにアクセス削除が必要であり、その目的を達するために侵害されたサービスアカウント自体を削除するのが最適な選択となります。
選択肢：漏洩したサービスアカウントキーを交換します
この選択肢が正しくない理由は以下の通りです。
サービスアカウントキーを交換すると、新しいキーが生成されますが、既存の公開リポジトリでは引き続き古いキーが使われる可能性があります。
それに対して、侵害されたサービスアカウントを削除すると、それにより生成されたすべての認証情報が無効化されるため、より安全です。
参考リンク：
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/iam/docs/granting-changing-revoking-access
</div></details>

### Q.  問題9: 未回答
ある組織のセキュリティとリスク管理チームは、Google Cloudで実行している特定の本番ワークロードの責任の所在とGoogleの責任の所在について懸念しています。彼らは、主にApp Engineを含むGoogle CloudのPaaS（Platform-as-a-Service）を使用してワークロードを実行しています。
App Engineを使用する場合、テクノロジースタックのどの領域に主な責任を負うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、PaaS（Platform-as-a-Service）ソリューションであるApp Engineを使用している組織のセキュリティ責任について考えるよう求められています。具体的には、テクノロジースタックのどの領域に主な責任を担うかを問われています。App Engineのシナリオでは、Googleとエンドユーザーの責任分担モデルを理解した上で、選択肢を評価することが求められます。他のCloudサービスとは異なり、PaaSではプロバイダーが多くのレイヤーの管理を引き受けますが、それでもユーザーの責任範囲として何が残るのか、それを見極める必要があります。
基本的な概念や原則：
PaaS（Platform-as-a-Service）：開発者がアプリケーションをビルド、デプロイ、運用管理するためのプラットフォームを提供するクラウドサービスです。ハードウェアやOS、データベース等のインフラ管理はクラウドプロバイダが担当します。
App Engine：Google CloudのフルマネージドのPaaSサービスです。開発者はアプリ開発に集中でき、インフラ管理の手間を減らすことができます。
XSSおよびSQLi攻撃：ウェブアプリケーション独自の脆弱性を悪用し、悪意のあるスクリプトを挿入したり、データベース操作を行ったりする攻撃方法です。アプリケーションのセキュリティ設計とコーディングが防御の主要な手段となります。
VPCフローログ：仮想プライベートクラウド（VPC）ネットワークのフローデータをキャプチャしてログに保存する機能です。これにより、ネットワークのトラフィックパターンを理解し、ネットワークパフォーマンスの問題をトラブルシューティングすることができます。
ゲストOSの更新とセキュリティパッチ管理：システムの安全性を保つために必要な業務です。しかし、PaaSサービスでは、これらはプロバイダの責任範囲内です。
保存データの暗号化：データを保護し、不許可のアクセスから安全に保つ方法です。PaaSサービスでは、これは通常、プロバイダが担当します。
正解についての説明：
（選択肢）
・XSSおよびSQLi攻撃からの防御
この選択肢が正解の理由は以下の通りです。
PaaS（Platform-as-a-Service）であるGoogle App Engineを使用する場合、インフラストラクチャやオペレーティングシステム、ランタイム環境などの管理はGoogleが行います。しかし、開発者や組織側が責任を持つべき箇所は、アプリケーションのコードとそのセキュリティです。XSS（クロスサイトスクリプティング）やSQLi（SQLインジェクション）攻撃はアプリケーションのセキュリティ脆弱性を突いたものであり、これらの防御は開発者の負担となります。
したがって、Google CloudのPaaSを使用している場合でも、アプリケーションの開発と運用には明確なセキュリティ対策が必要であり、それがこの選択肢が正解となる理由です。
不正解についての説明：
選択肢：VPCフローログの設定と監視
この選択肢が正しくない理由は以下の通りです。
Google CloudのPaaSサービスであるApp Engineは、ネットワークおよびインフラストラクチャの管理をGoogleが担当するので、ユーザーがVPCフローログの設定と監視の責任を持つ必要はありません。
それに対し、XSSやSQLi攻撃からの防御はユーザーのアプリケーションロジックと密接に関連するため、ユーザーの責任です。
選択肢：ゲストOSの最新アップデートとセキュリティパッチの管理
この選択肢が正しくない理由は以下の通りです。
App EngineはPaaSであり、プラットフォームの管理はGoogleによって行われます。
従って、ゲストOSのアップデートやセキュリティパッチの管理はGoogleの責任となります。
一方、XSSやSQLi攻撃からの防御はアプリケーションレベルの問題なので、依然としてユーザの責任となります。
選択肢：すべての保存データの暗号化
この選択肢が正しくない理由は以下の通りです。
App EngineはGoogle CloudのPaaSサービスであり、データの暗号化はGoogleの責任範囲になります。しかしXSSやSQLi攻撃からの防御は開発者のアプリケーション設計の範囲内で、その責任はユーザーにあります。
参考リンク：
https://cloud.google.com/appengine/docs/standard/security-roles
https://cloud.google.com/security/shared-responsibility
https://owasp.org/www-community/attacks/xss/
</div></details>

### Q.  問題10: 未回答
オンプレミスのインターネット接続を経由して、Google Cloudからインターネットに接続するすべてのトラフィックをルーティングします。この目標を安全かつ可能な限り高い帯域幅で達成したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミスとGoogle Cloud間のトラフィックルーティングと帯域幅の最適化に関連する理解が求められています。コンテクストに適した接続タイプと特定のネットワークトラフィック管理策を適用するための適切なGoogle Cloudのサービスや機能を識別することが重要です。また、オンプレミスのインターネット接続を利用する必要があり、Google Cloudからのインターネットへのトラフィックをオンプレミスのファイアウォールを通じて流すことを忘れないでください。
基本的な概念や原則：
Cloud Interconnect：オンプレミス環境とGoogle Cloudとの間で、高い帯域幅と低いネットワーク遅延を実現する接続サービスです。プライベート接続を通じてGoogleのネットワークと直接接続します。
ファイアウォール：ネットワークのセキュリティを高めるために設けられ、ネットワークとインターネットの間にあって不正アクセスを防ぐ機能です。ルールに基づいてネットワークトラフィックを制御します。
HA VPN：高い可用性を提供するGoogle CloudのVPN接続サービスです。冗長性があり、ミッションクリティカルなワークロードのデータ転送に適しています。
ルーティング：ネットワークトラフィックがネットワークのどの部分を通過するかを決定するプロセスです。ルーティングルールに基づき、パケットは宛先に適切なパスで送られます。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。カスタムルーティングを適用することも可能です。
正解についての説明：
（選択肢）
・Cloud Interconnectを設定し、オンプレミスのファイアウォールを介してトラフィックをルーティングします
この選択肢が正解の理由は以下の通りです。
まず、Cloud InterconnectはGoogle Cloudとオンプレミス環境との間で低レイテンシ、大容量、高信頼性の接続を提供します。これにより、ネットワークパフォーマンスの向上を期待でき、Google Cloudからインターネットへの全てのトラフィックのルーティングにおいて、高い帯域幅を確保できます。一般のインターネット接続よりもパフォーマンスが優れているため、ユーザーエクスペリエンスの向上に繋がります。
また、オンプレミスのネットワークとGoogle Cloudとの間に専用のプライベート接続を確立することで、安全性が向上します。この接続には、Googleのエッジネットワークが使用されます。このネットワークはパブリックインターネットから完全に分離されているため、セキュリティの観点からは有利です。
さらに、トラフィックをオンプレミスのファイアウォールを通過させることで、トラフィックの監視とフィルタリングが可能となり、セキュリティを強化できます。これによりGoogle Cloudからオンプレミスへの接続でも安全性が確保されます。
不正解についての説明：
選択肢：Google CloudへのHA VPN接続を作成します。デフォルトの0.0.0.0/0ルートを置き換えます
この選択肢が正しくない理由は以下の通りです。
HA VPN接続は高可用性のVPN接続を提供しますが、高帯域幅の接続は保証されません。
一方、Cloud InterconnectはGoogle Cloudとオンプレミス環境間で高速で安全な接続を提供するため、高帯域幅の要件を満たします。
選択肢：Compute EngineにルーティングVMを作成します。VMをネクストホップとしてデフォルトルートを設定します
この選択肢が正しくない理由は以下の通りです。
ルーティングVMを作成し、これをネクストホップとしてデフォルトルートを設定する手法は、VM上のルーティングを依存する形になり、VMのパフォーマンスや堅牢性に依存してしまいます。
これに対して、Cloud Interconnectを設定することで、Google Cloudとオンプレミスの間で高帯域、安定した接続を提供します。
選択肢：HA VPNでCloud Interconnectを設定します。デフォルトの0.0.0.0/0ルートをオンプレミスの宛先に置き換えます
この選択肢が正しくない理由は以下の通りです。
HA VPNはGoogle Cloud内の仮想プライベートネットワークとオンプレミスネットワークを接続する方法であり、高い帯域幅を要求する状況のためには適していません。
一方、Cloud Interconnectはプライベート接続を提供し、高いスループットを可能とします。
参考リンク：
https://cloud.google.com/interconnect/docs
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/network-connectivity/docs/interconnect/concepts/throughput
</div></details>

### Q.  問題11: 未回答
Google Cloudの組織では、Ownerロール（roles/owner）を持つGoogle Cloudプロジェクトを提供することで、管理機能を各チームに分散できます。この組織には何千ものGoogle Cloudプロジェクトが含まれています。Security Command Center Premiumで複数のOPEN_MYSQL_PORTが検出されました。あなたはガードレールを実施しており、これらのタイプの一般的な誤設定を防止する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、複数あるGoogle Cloudプロジェクトでのセキュリティの脆弱性、特にOPEN_MYSQL_PORTを検出し、これを防止するための"ガードレール"の実装方法について求められています。大量のプロジェクトを管理しており、分散した管理機能を提供する組織での対策が必要となります。そのため、全体的なセキュリティポリシーやファイアウォールの適用や設定を理解し、それらを組織全体に適用するための最適なアプローチを選択することが求められます。また、MySQLのポート公開問題を直接的に解決するための具体的な対策と、それらを実行する際の範囲や優先度の理解も重要です。
基本的な概念や原則：
Ownerロール：Google Cloudのロールの一つで、全リソースに対する全権限を持っています。そのため、このロールを持つユーザーはリソースの作成、削除、変更など様々な操作が可能です。
Security Command Center：Google Cloudのセキュリティとリスクデータを一元化し、可視化するプラットフォームです。誤設定や脅威、不審な活動を検出し、それらに対するレポートを提供します。
ファイアウォール：ネットワークのセキュリティを確保する仕組みの一つで、不正な通信や攻撃を防ぐために、通信の制限や遮断を行います。
階層ファイアウォールポリシー：Google Cloudの機能で、組織全体で適用したい設定を一箇所で管理することができます。組織、フォルダ、プロジェクトの階層を考慮した制御が可能です。
Google Cloud Armor：Google Cloudのセキュリティサービスで、WEBサービスへのDDoS攻撃や不正なアクセスを防ぐ機能を提供します。
仮想プライベートクラウド（VPC）：ユーザー専用のプライベートなネットワーク空間です。Google Cloud上で自身のクラウドネットワークを作成、管理できます。
正解についての説明：
（選択肢）
・内部IP範囲からの接続のみを許可するように、組織で設定された階層ファイアウォールポリシーを作成します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudは階層ファイアウォールポリシーを提供しており、これにより組織のネットワーク全体に対して一貫したセキュリティポリシーを適用することが可能となっています。この組織で設定された階層ファイアウォールポリシーは全てのプロジェクトに適用されるため、一括管理が可能となります。特に、問題となりやすいOPEN_MYSQL_PORT等の脆弱性を含む誤設定を防止するために有効な手段です。
また、内部IP範囲からの接続のみを許可するように設定することで、外部からの不正なアクセスを防止し、セキュリティを強化できます。
これらの主に2つの要点から、この選択肢は問題の要件を満たす最適な解答となります。
不正解についての説明：
選択肢：0.0.0.0/0からのトラフィックを拒否するように、組織で設定された階層ファイアウォールポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
全てのトラフィックを拒否する階層ファイアウォールポリシーを作成すると、一部の必要なサービスもブロックしてしまいます。
それに対して、内部IP範囲からの接続のみ許可する方が、必要なサービスへのアクセスは保ったまま安全性を確保できます。
選択肢：0.0.0.0/0からのトラフィックを拒否するGoogle Cloud Armorセキュリティポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloud ArmorはHTTP(S)トラフィックに対する保護を提供しますが、ここでの問題はMYSQL_PORTの誤設定です。そのためMYSQL_PORTの誤設定を検出し防止するために、階層ファイアウォールポリシーを用いる方が適切です。
選択肢：各仮想プライベートクラウド（VPC）に対して、優先度0で0.0.0.0/0からのトラフィックを拒否するファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
優先度0で0.0.0.0/0からのトラフィックを拒否するファイアウォールルールを各VPCに設定すると、すべてのトラフィックが完全にブロックされてしまいます。これは必要な通信までもを遮断してしまうため、安全にシステムを運用できません。そのため、特定のIP範囲からの接続のみを許可する方が適切です。
参考リンク：
https://cloud.google.com/network-connectivity/docs/hierarchical-firewall/overview
https://cloud.google.com/security-command-center/docs/concepts-security-command-center-overview
https://cloud.google.com/vpc/docs/firewalls
</div></details>

### Q.  問題12: 未回答
あなたは、Google Cloudへのデータ移行を計画している顧客と仕事をしています。あなたは、暗号化された鍵を管理する暗号化サービスを推奨する責任があります。以下の要件があります：
- マスターキーは少なくとも45日ごとにローテーションされる必要があります。
- マスターキーを保管するソリューションは、FIPS 140-2レベル3の認証を受けている必要があります。
- マスターキーは、冗長性のために米国内の複数のリージョンに保管されなければなりません。
これらの要件を満たすソリューションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの暗号化サービスを推奨する際に3つの要件を満たす必要があることが明示されています。キーのローテーション周期、認証、複数リージョンの利用という要件を果たすGoogle Cloudのサービスを選択肢から選ぶことが求められています。各選択肢がこれらの要件をどの程度満たしているかを理解し、最も要件に適合するサービスを選ぶことが肝心です。
基本的な概念や原則：
Cloud HSM：Google CloudのCloud HSM（HSM）サービスです。FIPS 140-2レベル3の認証を持っており、強力な暗号化キーの管理と操作を提供します。
FIPS 140-2：米国政府が承認した暗号モジュールセキュリティ標準です。レベル3は、物理的なタンパリングに対する保護を強化したレベルです。
顧客管理の暗号化キー：顧客が作成、管理する暗号化キーです。Google Cloudサービスの暗号化に使用されますが、キー自体の管理は顧客の責任となります。
Cloud Key Management Service（KMS）：暗号キーの生成、使用、管理、インポート、エクスポート、ローテーションを提供するフルマネージドサービスです。ただし、FIPS 140-2レベル3の認証はありません。
冗長性：システムの信頼性を向上させるための技術です。複数の要素が同じ作業を実行することにより、一部の要素が故障してもシステム全体が続行できるようにします。ここでは、キーを複数のリージョンに保管することが指示されています。
正解についての説明：
（選択肢）
・Cloud HSMによる顧客管理の暗号化キー
この選択肢が正解の理由は以下の通りです。
まず、Cloud HSMはGoogle Cloudの高度な鍵管理サービスで、これを使用することにより適切な周期でのキーローテーションが可能となります。すなわち、Cloud HSMは45日ごと（あるいはそれ以下の期間）のキーローテーションを実現・管理できます。
また、Cloud HSMはFIPS 140-2レベル3の認証を受けたCloud HSM（HSM）を提供します。これにより、顧客は自身の暗号化キーをセキュリティレベルが高い条件下で管理できることを保証できます。
さらに、Cloud HSMはGoogle Cloudの各リージョンで利用可能であり、ユーザーはデータの冗長性を保証するため、同じ鍵を複数のリージョンで使用することが可能です。具体的には、米国内の任意の複数のリージョンでHSMを展開し、同じ鍵を保存することができます。
以上の各要素が、Cloud HSMがこれらの特定の要件を満たす最適なソリューションである理由です。
不正解についての説明：
選択肢：Cloud Key Management Serviceによる顧客管理の暗号化鍵
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Service（KMS）はマスターキーのローテーションや複数リージョンでの保管をサポートしますが、FIPS 140-2レベル3の認証を受けていません。
一方、Cloud HSMはすべての要件を満たしており、特にFIPS 140-2レベル3の認証を受けています。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キー（CSEK）は顧客が完全に制御と管理を行い、Google Cloudは鍵を知らず、保存もしません。そのため、キーのローテーションや複数リージョンへの保管といった要件をクラウド側で制御することはできません。
これに対し、Cloud HSMはGoogle Cloud上でCloud HSMを使用し、キーの管理と冗長性を確保することが可能です。
選択肢：Googleが管理する暗号鍵
この選択肢が正しくない理由は以下の通りです。
Googleが管理する暗号鍵を使用すると、ユーザーは鍵のローテーションスケジュールや保存場所を制御することができません。
一方、Cloud HSMによる顧客管理の暗号化キーを使用すると、ユーザーは鍵のローテーションと保存場所を制御可能であり、FIPS 140-2レベル3の認証も受けています。
参考リンク：
https://cloud.google.com/kms/docs
https://cloud.google.com/hsm/docs
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題13: 未回答
あなたの組織は、機密性の高い医療情報を処理しています。仮想マシン（VM）の使用中にデータが暗号化されることを保証したいと考えています。組織全体に適用されるポリシーを作成する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、機密性の高い医療情報を処理するために、用途中のデータの暗号化を保証する方法について尋ねられています。そのため、仮想マシン（VM）の使用中にデータが暗号化されることを保証できる仕組みについて理解する必要があります。また、組織全体に適用可能なポリシーの作成も求められており、この点も考慮に入れる必要があります。選択肢を検討する際には、データの暗号化を可能にするテクノロジーとそれを組織全体に適用する方法に着目するべきです。
基本的な概念や原則：
Confidential VM：仮想マシン（VM）の使用中にデータを暗号化するGoogle Cloudのサービスです。医療情報など機密性の高いデータを処理する際に利用します。
組織ポリシー：Google Cloudのリソース管理のための機構です。組織全体に適用され、特定のリソースに対する行動を制限したり、特定の設定を強制することができます。
CMEK（customer-managed encryption keys）：顧客管理の暗号化キーのことです。暗号化キーのライフサイクル（作成、使用、破棄）を顧客側で管理することが可能です。
Cloud External Key Manager（EKM）：Google Cloud外部で暗号化キーを管理するサービスです。CMEKとは異なり、暗号化キーがGoogleのインフラストラクチャから完全に分離されます。
暗号化：データを安全に保護するために行われるプロセスです。暗号化されたデータは、適切な復号キーがなければ理解できない形に変わります。データの使用中の暗号化は、機密データの取り扱いにおいて重要です。
正解についての説明：
（選択肢）
・組織全体で作成されるすべてのVMリソースがConfidential VMインスタンスであることを保証する組織ポリシーを導入します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのConfidential VMは、データを使用中に暗号化する機能を提供します。つまり、データはプロセス中常に暗号化され、それがディスクに書き込まれる前に一時的に復号化されることはありません。これにより、仮想マシン（VM）使用中に機密性の高い医療情報が暗号化され続けることを保証することができます。
次に、ポリシーを組織全体に適用するためには、組織全体で作成されるすべてのVMリソースがConfidential VMインスタンスであることを要求する組織ポリシーを導入することが有効です。これにより、組織内のすべてのユーザーがこの暗号化ポリシーを順守することを確実にします。
したがって、医療情報を含むデータを取り扱う組織にとって、この選択肢は最も適切であると言えます。
不正解についての説明：
選択肢：組織全体で作成されたすべてのVMリソースが、CMEK（customer-managed encryption keys）保護を使用することを保証する組織ポリシーを導入します
この選択肢が正しくない理由は以下の通りです。
CMEK保護を使用するポリシーは確かにデータの暗号化を強制しますが、これはデータアットレスト（保存中）の暗号化です。
一方、問題文では使用中のVMデータの暗号化が求められており、これはConfidential VMインスタンスが提供するデータインユース（使用中）の暗号化を必要とします。
選択肢：組織全体で作成されたすべてのVMリソースがCloud External Key Manager（EKM）保護を使用することを保証する組織ポリシーを実装します
この選択肢が正しくない理由は以下の通りです。
Cloud EKMは暗号化キーの管理に利用されるサービスで、VMの利用中のデータ暗号化には直接関与しません。
一方、Confidential VMは使用中のデータが暗号化されることを保証し、その要件を直接満たします。
選択肢：Googleはデフォルトで使用中のデータを暗号化するので、何もする必要はありません
この選択肢が正しくない理由は以下の通りです。
Googleはデフォルトでデータを暗号化しますが、その暗号化は通常のデータ保護としてのもので、機密性が特に高い医療情報に対する特別な保護策とは異なります。Confidential VMではメモリデータ暗号化技術を使用して、使用中のデータをより高度に暗号化し、医療情報などの機密データの保護を強化します。
参考リンク：
- https://cloud.google.com/security/confidential-computing
- https://cloud.google.com/resource-manager/docs/creating-managing-organization
- https://cloud.google.com/compute/docs/instances/confidential-vm
</div></details>

### Q.  問題14: 未回答
あなたは、IPパケットデータに不正なコンテンツや悪意のあるコンテンツが含まれていないか検査する任務を与えられています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、IPパケットデータの検査方法について問われています。特に"不正なコンテンツや悪意のあるコンテンツ"の検査が求められているので、選択肢を見る際にはパケットレベルでの検査や分析が可能なソリューションである必要があります。また、この問題には具体的な技術やツールの名前がいくつか挙げられているので、それらの機能や用途について理解しておくことも重要です。
基本的な概念や原則：
Packet Mirroring：Google CloudのPacket Mirroringは、特定のVMインスタンスのネットワークトラフィックをミラーリングし、不正なトラフィックやセキュリティ攻撃を検出するために使用します。
VPCフローログ：仮想プライベートクラウド（VPC）ネットワーク内のパケットの送受信情報をロギングする機能です。ここから得られた情報はネットワークモニタリング、フォレンジックス、リアルタイムのセキュリティ分析に使用しますが、パケット内容そのものは取得できません。
Cloud Logging：Google Cloudのロギングサービスです。アプリケーションやシステムからのログデータを一元管理し、解析やアラート設定などが可能です。
Fluentd：オープンソースのデータコレクターです。ログデータを統合し、Google Cloudのような一元的なログ管理システムにデータを送信します。
Google Cloud Armor：Google Cloud上のアプリケーションのセキュリティを強化するサービスです。DDoS攻撃の防御やウェブアプリケーションファイアウォール機能などを提供します。
正解についての説明：
（選択肢）
・Packet Mirroringを使用して、特定のVMインスタンスとの間でトラフィックをミラーリングします。ミラーリングされたトラフィックを分析するセキュリティソフトウェアを使用して検査を実行します
この選択肢が正解の理由は以下の通りです。
Packet Mirroringを使用すれば、リアルタイムに特定のVMインスタンスとのパケット通信を複製し、ミラリングすることができます。これにより、その通信通路上でやりとりされる情報の内容を120％確認することが可能になります。すなわち、通信内容に変更を加えたり、通常の通信の流れを中断させることなく、通信内容に対して深く解析を施すことができます。
ここでの要点は、Packet Mirroringによってミラリングされた情報を解析するためのセキュリティソフトウェアを使用することです。このソフトウェアには、例えばIntrusion Detection System（IDS）やIntrusion Prevention System（IPS）、あるいはその他第三者製のネットワークセキュリティツールが含まれます。これらのツールはパケットレベルでの深部解析や内容確認を行うことで、不正なコンテンツや悪意のあるコンテンツを検出できる設計となっています。
したがって、Packet Mirroringとセキュリティソフトウェアを組み合わせて使用することで、IPパケットデータに不正なコンテンツや悪意のあるコンテンツが含まれていないか確認することができます。
不正解についての説明：
選択肢：VPC内のすべてのサブネットでVPCフローログを有効にします。Cloud Loggingを使用して、フローログのデータを検査します
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフローデータのログを収集・分析するサービスであり、IPパケットデータに含まれるコンテンツ自体を検査することはできません。対してPacket Mirroringは特定のVMとのトラフィックをミラーリングし、その内容をセキュリティソフトウェアで検査することが可能です。
選択肢：VPC内の各VMインスタンスにFluentdエージェントを設定します。Cloud Loggingを使ってログデータを検査します
この選択肢が正しくない理由は以下の通りです。
FluentdエージェントとCloud Loggingは主にログデータの収集と分析に利用されます。しかし、IPパケットデータの悪意のあるコンテンツを検知するには適さないため、この解答は不適切です。
それに対して、Packet Mirroringとセキュリティソフトウェアは、パケットレベルでのデータ検査を実現します。
選択肢：Google Cloud Armorのアクセスログを設定し、ログデータの検査を実行します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは主にHTTP(S)負荷分散のトラフィックを監視し、不正なアクセスを防止します。しかし、IPパケットデータの全体的な検査には向かないため、この要件を満たすのに適切ではありません。正解の選択肢では、Packet Mirroringを使用し、特定のVMとのトラフィックをミラーリングして、セキュリティソフトウェアで検査を行います。これにより、より正確なパケットレベルの検査が可能になります。
参考リンク：
https://cloud.google.com/traffic-director/docs/packet-mirroring
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/armor/docs/logging-and-monitoring
</div></details>

### Q.  問題15: 未回答
あなたの会社は、現在us-central-1のGoogle Cloudロードバランサーの後ろにデプロイされ、Standardティアネットワークを使用するように構成されているアプリケーションインスタンスグループを運営しています。インフラチームは、2つ目のGoogle Cloudリージョンであるus-east-2に拡張したいと考えています。両方のリージョンのインスタンスグループに新しいリクエストを配信するために、単一の外部IPアドレスを設定する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、現在のアプリケーションインスタンスグループがus-central-1のGoogle Cloudロードバランサーの後ろに配置され、新たにus-east-2にインスタンスグループを設定したいという状況です。そこで求められているのは、両方のリージョンのインスタンスグループに新しいリクエストを配信する方法で、特にその際単一の外部IPアドレスを設定する必要があります。この要件を満たすため、ネットワークの設定やロードバランサーの利用、VPN接続の作成など、さまざまなGoogle Cloudの機能や設定変更が考慮されます。適切なアプローチを見つけ出すためには、Google Cloudの各種サービスとそれらの設定変更がもたらす影響について理解を深める必要があります。
基本的な概念や原則：
ロードバランサー：トラフィックを複数のサーバーやリージョン間で自動的に分散させるネットワークデバイスです。これにより、各サーバーの負荷を均等にし、ネットワークパフォーマンスを向上させます。
Standardティアネットワーク：Google Cloudのネットワークオプションで、低コストなパフォーマンスを提供します。ただし、マルチリージョン配信には制限があります。
プレミアムティアネットワーク：Google Cloudの高性能ネットワークオプションです。マルチリージョン配信をサポートし、より優れたパフォーマンスを提供します。
インスタンスグループ：同じ設定の仮想マシンをグループ化したものです。ロードバランサーと共に使用すると、トラフィックを複数の仮想マシン間で分散させることが可能です。
ネットワークエンドポイントグループ：Google Cloudの機能で、ネットワークエンドポイント（特定のIPアドレスとポートの組み合わせ）をロジカルにグループ化します。これにより、エンドポイントへのトラフィックフローを制御できます。
静的外部IPアドレス：固定の公開IPアドレスです。インスタンスが停止または削除されても変わらず、アクセス先を一定に保つことができます。
Cloud VPN：Google Cloudの仮想プライベートネットワーク（VPN）接続機能です。異なるネットワーク間の安全な通信を可能にします。
正解についての説明：
（選択肢）
・ロードバランサーのフロントエンドの設定をプレミアムティアのネットワークを使うように変更し、新しいインスタンスグループを追加します
この選択肢が正解の理由は以下の通りです。
まず、プレミアムティアのネットワークを使用すると、Google Cloudが提供するグローバルネットワーク上でトラフィックがルーティングされます。これにより、複数の地域にまたがるリージョンを持つインスタンスグループに対して、単一の外部IPアドレスを用いてリクエストを配信することが可能になります。
一方、スタンダードティアのネットワークでは、トラフィックはリージョン内に限定されるため、複数のリージョン間での負荷分散を行うことはできません。
次に、新しいインスタンスグループを追加することで、新たにus-east-2リージョンに拡張されたインフラの配信先として認識させることができます。これにより、us-central-1とus-east-2の両リージョンで動作するインスタンスグループに、一括してリクエストが配信されるようになります。
したがって、この選択肢が最適です。
不正解についての説明：
選択肢：ロードバランサーのバックエンドの設定を、インスタンスグループの代わりにネットワークエンドポイントグループを使うように変更します
この選択肢が正しくない理由は以下の通りです。
ネットワークエンドポイントグループを使用する変更は、複数のリージョン間で単一の外部IPアドレスを設定する要件には寄与しません。
代わりに、ネットワークティアをプレミアムに変更し、新しいインスタンスグループを追加することで、世界中の任意の場所からのユーザが単一のIPアドレスを通じてアクセスできます。
選択肢：スタンダードティアのネットワークを使ってus-east-2に新しいロードバランサーを作成し、静的な外部IPアドレスを割り当てます
この選択肢が正しくない理由は以下の通りです。
新しいロードバランサーを作成した場合、それは追加の外部IPアドレスを必要とします。問題の要件は、単一の外部IPアドレスを使用することです。これはプレミアムティアのネットワークの複数リージョンをまたぐロードバランサーでのみ可能であり、新しいロードバランサーを作成することでは達成できません。
選択肢：2つのリージョン間でCloud VPN接続を作成し、Private Google Accessを有効にします
この選択肢が正しくない理由は以下の通りです。
Cloud VPN接続とPrivate Google Accessは、専用のIP接続を作成し、プライベートリソースへの安全なアクセスを提供しますが、それは単一の外部IPアドレスからどちらのリージョンにも新しいリクエストを分配するという要件とは関係ありません。これを実現するためには、プレミアムティアのネットワークを使用してロードバランサーを設定する必要があります。
参考リンク：
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address
</div></details>

### Q.  問題16: 未回答
組織は、Cloud IdentityとMicrosoft Active Directoryの同期とSAMLフェデレーションを実装しています。Google Cloudのユーザーアカウントが侵害されるリスクを軽減したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud IdentityとMicrosoft Active Directoryの同期とSAMLフェデレーションが既に実装されている前提の下、Google Cloudのユーザーアカウントが侵害されるリスクを軽減するための方法について問われています。強力なパスワードポリシーの設定と2段階認証の利用により、セキュリティリスクの軽減が可能です。ただし、Active DirectoryやCloud Identityに対するパスワードポリシーの設定の違いや、2段階認証の方法選択に注意を払う必要があります。
基本的な概念や原則：
Cloud Identity：Google CloudのIDaaS（Identity as a Service）です。ユーザーやグループ、アプリケーションなどを一元管理し、安全なアクセスとシングルサインオン（SSO）を実現します。
Microsoft Active Directory：Microsoftによるディレクトリ型のID管理サービスです。ユーザーの認証・認可を行い、ユーザーやコンピュータなどの情報を一元化して管理します。
SAMLフェデレーション：セキュリティアサートマークアップ言語（SAML）を使用して、異なるセキュリティドメイン間でのIDや認証情報を共有する仕組みです。
パスワードポリシー：パスワードの強度や有効期限、再利用の規則などを定義するためのポリシーです。適切なパスワードポリシーは、アカウント侵害のリスクを軽減します。
二段階認証：パスワードだけでなく、さらに何か（セキュリティキー、認証コードなど）を用いてユーザーを認証する方法です。アカウント侵害のリスクを軽減します。
セキュリティキー：二段階認証の一手段となる、物理的なセキュリティデバイスのことです。セキュリティキーを使用することで、認証手段の多様化を通じたセキュリティ強化が可能です。
シングルサインオン（SSO）：ユーザーが一度のログインで複数のシステムやサービスにアクセスできるようにする認証方式です。ユーザビリティの向上と管理コストの削減を実現します。
正解についての説明：
（選択肢）
・強力なパスワード設定でActive Directoryドメインのパスワードポリシーを作成し、Google Adminコンソールでセキュリティキーを使用してSSO（シングルサインオン）後の2段階認証を設定します
この選択肢が正解の理由は以下の通りです。
まず、Active Directoryの強力なパスワード設定により、ユーザーが安易なパスワードを設定し、それが原因でアカウントが侵害されるリスクを低減することができます。これにより、パスワードが強化され、初回の認証段階でアカウントが侵害される可能性が少なくなります。
次に、Google Adminコンソールでセキュリティキーを使用してSSO後の2段階認証を設定することで、ユーザーが認証された状態でSSOを通過した後でも、セキュリティキーを使用して認証を行う必要があります。これにより、ユーザーアカウントが侵害されるリスクをさらに軽減することができます。特に、SSOは便利ではありますが、SSOが侵害された場合には複数のサービスが危険に晒される可能性があるため、SSO後の2段階認証は非常に重要です。
不正解についての説明：
選択肢：強力なパスワード設定でCloud Identityパスワードポリシーを作成し、Google管理コンソールでセキュリティキーを使用して2段階認証を設定します
この選択肢が正しくない理由は以下の通りです。
組織はActive Directoryを使用しているので、パスワードポリシーはActive Directoryに設定すべきです。Cloud Identityではなく、Active Directoryでパスワードポリシーを強制することが重要です。この選択肢ではCloud Identityにパスワードポリシーを設定しているため、誤っています。
選択肢：強力なパスワード設定でCloud Identityパスワードポリシーを作成し、Google管理コンソールでテキストまたは電話による認証コードで2段階認証を設定します
この選択肢が正しくない理由は以下の通りです。
ここではフェデレーションとActive Directory同期が実装されているため、パスワードポリシーはActive Directoryで設定するのが最善です。
それに対し、この選択肢はCloud Identityでのパスワードポリシー設定を提案しており、フェデレーション環境に合っていません。
また、2段階認証のセキュリティは、セキュリティキーよりもテキストまたは電話による認証コードの方が低いため、リスクを軽減するという目的に対して不適切です。
選択肢：強力なパスワード設定でActive Directoryドメインのパスワードポリシーを作成し、Google Adminコンソールでテキストまたは電話による認証コードを使用したSSO（シングルサインオン）後の2段階認証を設定します
この選択肢が正しくない理由は以下の通りです。
テキストメッセージまたは電話による認証コードは、セキュリティキーに比べて侵害されるリスクが高いため、ユーザーアカウントのリスク軽減には不適切です。セキュリティキーは物理的なデバイスであり、侵害される可能性がずっと低いです。
参考リンク：
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-sso-saml
https://cloud.google.com/identity/docs/set-up-sso
https://support.google.com/a/answer/9176657?hl=en
</div></details>

### Q.  問題17: 未回答
ある組織が、オンプレミスにいくつかのミッションクリティカルなアプリケーションを維持しながら、アプリケーションをGoogle Cloudに移行しようとしています。この組織は、少なくとも50Gbpsの帯域幅でデータを転送する必要があります。
サイト間の安全な継続接続を確保するために、何を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、高帯域幅の安全な接続が必要なシナリオを説明しています。オンプレミスのミッションクリティカルなアプリケーションを維持しつつ、Google Cloudへのデータ転送が求められています。サイト間の継続的で安全な接続を求められているので、選択肢を見てどれが最大50Gbpsの帯域幅を提供し、一方から他方への安全な通信を確実にするかを判断する必要があります。選択肢の理解とその機能を理解することが重要です。
基本的な概念や原則：
Cloud Interconnect：Google Cloudと他のネットワーク間で、高容量・低遅延の接続を可能にするサービスです。50Gbps以上の帯域幅を持つ接続を提供します。
Cloud Router：Google Cloudのフルマネージドサービスで、ダイナミックルーティングのためにBGP（Border Gateway Protocol）を使用します。ただし、直接の接続帯域幅を提供するものではありません。
Cloud VPN：Google Cloudと他のネットワーク間にVPN（Virtual Private Network）を構築するサービスです。安全な接続を提供しますが、その帯域幅はCloud Interconnectほど大きくありません。
Partner Interconnect：Google Cloudとサービスプロバイダ間で接続を設定するサービスです。直接の接続を提供しますが、帯域幅はService Providerに依存します。
正解についての説明：
（選択肢）
・Cloud Interconnect
この選択肢が正解の理由は以下の通りです。
まず、Cloud InterconnectはGoogle Cloudとオンプレミスインフラストラクチャとの間で大規模なデータ転送を密に行うことが要求されるシチュエーションに適しています。Cloud Interconnectは低レイテンシ、高スループットの接続を提供し、特定の場合には最大200Gbpsの帯域幅をサポートします。これにより、50Gbpsの帯域幅要件をはるかに上回る能力を持っています。
さらに、Cloud Interconnectは安全な接続を提供します。物理的接続を通じてプライベートなネットワーク接続を確立することにより、データ転送中に外部のインターネットトラフィックが混在することを避けることができます。これにより、セキュリティリスクを低減し、データのプライバシーを保護します。
したがって、ミッションクリティカルなアプリケーションを維持する組織にとっては、サイト間の安全な継続接続を確保するために最適な選択肢となります。
不正解についての説明：
選択肢：Cloud Router
この選択肢が正しくない理由は以下の通りです。
Cloud Routerは主にネットワーク間のルーティング情報を交換するロールを持つものであり、帯域幅の指定は可能ではありません。
一方、Cloud InterconnectはオンプレミスとGoogle Cloud間の高速なプライベート接続を実現することが可能であり、50Gbpsの指定帯域幅も可能です。
選択肢：Cloud VPN
この選択肢が正しくない理由は以下の通りです。
Cloud VPNはサイト間の安全な接続は可能ですが最大スループットは4Gbpsまでであり、要件の50Gbpsの帯域幅を満たすことができません。
逆に、Cloud Interconnectは最大200Gbpsのスループットを提供し、要件を満たすことが可能です。
選択肢：Partner Interconnect
この選択肢が正しくない理由は以下の通りです。
Partner Interconnectはパートナーネットワークプロバイダを介した接続を提供しますが、ユーザーの制御範囲外であるため帯域幅の保証が難しいです。しかし、Cloud InterconnectはGoogle Cloud直結の高速なプライベート接続を提供し、50Gbpsの帯域幅要件を確実に満たすことができます。
参考リンク：
https://cloud.google.com/interconnect/docs/how-to/dedicated
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/interconnect/docs/concepts/overview
</div></details>

### Q.  問題18: 未回答
あなたは、厳しいデータ保護要件がある規制業界の組織に勤めています。その組織はクラウドにデータをバックアップしています。データプライバシー規制を遵守するため、このデータは特定の期間しか保存できず、特定の期間が過ぎると削除しなければなりません。
保管コストを最小限に抑えながら、この規制へのコンプライアンスを自動化したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、データ保護要件を満たしつつ保管コストを抑える手段を求めています。具体的には、バックアップデータの自動削除機能を持つストレージサービスを探すことが必要です。そのため、各選択肢が提供する機能を理解し、それが自動化の要件と互換性があるかを確認することが大切です。また、維持コストも視野に入れ、最もコスト効率の良いオプションを選ぶことが求められます。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、データバックアップ、アーカイブ、分析などの様々な用途に利用できます。データの耐久性と可用性が高いです。
オブジェクトライフサイクル管理：Cloud Storageバケットに保存されたデータオブジェクトの管理を自動化する機能です。特定の条件を満たしたオブジェクトを自動的に移行または削除できます。
永続ディスク：Google Cloudのブロックストレージサービスです。Compute Engineなどの仮想マシンと連携して利用します。
Cloud Bigtable：Google CloudのNoSQLビッグデータデータベースサービスです。読み込みと書き込みを高速に行うことができます。
BigQuery：Google Cloudの完全マネージド型エンタープライズデータウェアハウスです。大量のデータを高速に分析することができます。
正解についての説明：
（選択肢）
・データをCloud Storageバケットに保存し、バケットのオブジェクトライフサイクル管理機能を設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageは高いデータ耐久性とアクセス制御の設定が可能な優れたデータストレージサービスです。これは規制業界の組織とデータ保護要件を満たすのに適しています。しかし、問題の核心はデータが保存できる特定の期間とそれを自動化することです。それがまさにGoogle Cloud Storageのオブジェクトライフサイクル管理機能で実現可能となります。この機能を使用することで、データの保存期間や棚卸しコストについて自動的な管理を行うことができます。例えば、あらかじめ定められた期間が経過したデータを自動的に削除するルールを設定できます。これにより、データ保存の規制遵守が自動化され、適切なコンプライアンスを維持しながら、不要なデータの保管によるコスト増加も防ぐことができます。
不正解についての説明：
選択肢：データを永続ディスクに保存し、期限切れ時にディスクを削除します
この選択肢が正しくない理由は以下の通りです。
永続ディスクでデータを保存し、手動で期限切れになったディスクを削除することは、自動化の要件を満たしません。
一方、Cloud Storageバケットのオブジェクトライフサイクル管理機能を使用すると、データ保管の期間を指定し、その期間が過ぎると自動的にデータを削除することができるため、保管コストを最小限に抑えつつ規制へのコンプライアンスを自動化することが可能になります。
選択肢：Cloud Bigtableテーブルにデータを格納し、カラムファミリーに有効期限を設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Bigtableではカラムファミリーに有効期限を設定することはできますが、これはデータの自動削除を管理するためのものではなく、CellレベルのTTL（Time To Live）を設定するものです。
また、Bigtableは低コストなバックアップオプションではありません。
それに対して、Cloud Storageバケットのオブジェクトライフサイクル管理機能を設定することでデータの自動削除とコスト効率の高いデータ保管が可能になります。
選択肢：データをBigQueryのテーブルに保存し、テーブルの有効期限を設定します
この選択肢が正しくない理由は以下の通りです。
BigQueryのテーブル有効期限設定はユーザーがアクセスしない限り削除されるわけではないので、特定の期間が経ったら自動的に削除されるという要件を満たしません。
一方、Cloud Storageのオブジェクトライフサイクル管理機能を使用すれば、特定の期間が経過したデータを自動的に削除することが可能です。
参考リンク：
https://cloud.google.com/storage/docs/lifecycle
https://cloud.google.com/storage/docs/managing-lifecycles
https://cloud.google.com/storage/docs/creating-buckets
</div></details>

### Q.  問題19: 未回答
機密データを保護し、非機密データの鍵管理の複雑さを軽減する静止時暗号化戦略を実装する必要があります。ソリューションには以下の要件があります：
- 機密データの鍵ローテーションをスケジュールします。
- 機密データの暗号鍵をどの領域に保存するかを制御します。
- 機密データおよび非機密データの暗号化キーへのアクセス待ち時間を最小限に抑えます。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、機密データと非機密データを静止時に安全に暗号化しながら、鍵管理の複雑性を最小限に抑えるための戦略を決定することが求められています。要件によれば、機密データの鍵ローテーションをスケジュールし、どの領域に暗号鍵を保存するか制御する必要があり、暗号鍵へのアクセス待ち時間を最小限に抑える必要もあります。そのため、選択をする際はGoogle Cloudの各暗号化サービスがどのようにこれらの要件を満足するか、または満足しないかを理解することが重要です。また、これらの要件が同時に満たされる解決策を見つけることが求められています。
基本的な概念や原則：
Cloud Key Management Service（KMS）：暗号化キーを管理し、保管するためのフルマネージド型サービスです。鍵の生成、使用、回転、壊棄などを行うことができます。特定のデータへのアクセスをより厳密に制御するために利用されます。
Googleデフォルトの暗号化：Google Cloudでは、データはデフォルトで暗号化されます。これにより、特別な操作を行わなくてもデータの安全性を保つことができます。
鍵ローテーション：適切な時間間隔で暗号化キーを新しくすることです。これにより、同じ鍵が使われ続けて機密性が低下するのを防ぎます。
暗号鍵の保存領域の制御：タイプ、領域、保護レベルなど鍵の性質を元に保存場所を選択する必要があります。特定の領域に保存することで、データと鍵の両方に適切なアクセス制御を適用し、セキュリティを強化します。
Cloud External Key Manager：Google Cloud以外で暗号鍵を管理するためのサービスです。取り扱うデータがより高い機密性を必要とする場合や、特定のコンプライアンス要件を満たすために使用されます。
非機密データと機密データ：データの機密性により、どのような暗号化方法を取るかが異なります。非機密データはデフォルトの暗号化で保護し、機密データはより厳密な暗号化方法を用いることが一般的です。
正解についての説明：
（選択肢）
・非機密データはGoogleデフォルトの暗号化で暗号化し、機密データはCloud Key Management Serviceで暗号化します
この選択肢が正解の理由は以下の通りです。
まず、Googleデフォルトの暗号化は、セキュリティと使いやすさを両立しながら非機密データを自動的に暗号化します。この方式により、非機密データの鍵管理の複雑さが劇的に軽減され、ユーザーは変更や設定をする必要がなく、また待ち時間も発生しません。
一方、Cloud Key Management Serviceを使用すると、機密データの暗号鍵についてのより高いレベルの制御が可能になります。このサービスにより、ユーザーは暗号鍵のローテーションスケジュールを設定し、鍵を保存する地域を選択することができます。
したがって、この選択肢が提供する暗号化戦略は、指定された要件を満たし、機密データの保護と非機密データの鍵管理の簡素化を適切に提供します。
不正解についての説明：
選択肢：Cloud External Key Managerを使用して、機密性の低いデータと機密性の高いデータを暗号化します
この選択肢が正しくない理由は以下の通りです。
Cloud External Key Managerは機密データの鍵管理に役立つ一方で、非機密データの鍵管理の複雑さを増加させる可能性があり、また鍵アクセスの待ち時間も増大する可能性があります。このため、非機密データにはGoogleデフォルトの暗号化を用いるべきです。
選択肢：Cloud Key Management Serviceを使用して、機密性の低いデータと機密性の高いデータを暗号化します
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Serviceを非機密データにも使用すると、鍵管理の複雑さが増すため、要件を満たせません。非機密データの場合、Googleデフォルトの暗号化を用いることで鍵管理の手間を省くことができます。
選択肢：機密性の低いデータはGoogleデフォルトの暗号化で暗号化し、機密性の高いデータはCloud External Key Managerで暗号化します
この選択肢が正しくない理由は以下の通りです。
Cloud External Key Managerは、Google Cloud外部にキーを保管するためのものであり、キーへのアクセス待ち時間が増加し、質問の要件"暗号化キーへのアクセス待ち時間を最小限に抑えます"を満たしません。
一方、Cloud Key Management ServiceではキーはGoogle Cloud内に保存されるため、アクセス待ち時間が短くなります。
参考リンク：
https://cloud.google.com/kms/docs/encrypting-data
https://cloud.google.com/security/encryption-at-rest/default-encryption
https://cloud.google.com/kms/docs/rotating-keys
</div></details>

### Q.  問題20: 未回答
あなたは、Google Cloud内でアプリケーションデータ（転送中のデータ、使用中のデータ、および静止状態のデータを含む）のエンドツーエンドの暗号化を必要とするクライアントの相談を受けています。
これを達成するために、どのオプションを利用すべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud内でアプリケーションデータの全体的な暗号化について問われています。問題中には転送中のデータ、使用中のデータ、および静止状態のデータを暗号化する必要があると明記されます。エンドツーエンドのデータ暗号化を実現するために、全データのライフサイクル（作成、操作、休止）をカバーする選択肢を選ぶことが求められます。そして、ここでは2つの正解を選択するという条件も忘れてはいけません。
基本的な概念や原則：
Confidential Computing：Google Cloudのサービスで、データが転送中も、使用中も、静止状態でも暗号化され、機密性が保たれます。これにより、第三者やシステム管理者からの不正アクセスを防ぐことが可能です。
Istio：オープンソースのサービスメッシュで、マイクロサービス間の通信を管理、保護、監視することができます。エンドツーエンドの暗号化通信を実現します。
クライアント側の暗号化：データがGoogle Cloudに送信される前に、ユーザーのローカル環境でデータを暗号化する手法です。データの保護レベルを高めることができます。
External Key Manager：Google Cloudのリソースを暗号化するための鍵を、Googleのインフラストラクチャ外部で管理するサービスです。
顧客指定の暗号化キー：Google Cloud上のリソースを暗号化するための鍵を、顧客自身が生成し管理するサービスです。
Cloud HSM：Google CloudのCloud HSM（HSM）サービスで、暗号鍵の保護と管理を行うためのクラウドベースのサービスです。
正解についての説明：
（選択肢）
・Confidential ComputingとIstio
・クライアント側の暗号化
この選択肢が正解の理由は以下の通りです。
まず、Confidential ComputingはGoogle Cloud内でデータを扱う際に、それが使用中であっても暗号化されることを保証します。従来、データは転送中や静止状態では暗号化することができましたが、そのデータを処理するときにはデータを暗号化解除する必要がありました。しかし、Confidential Computingによりデータは使用中も暗号化され、データの使用中のセキュリティを保つことが可能になります。
次に、Istioはサービスメッシュとして機能し、ミドルウェアとして複数のマイクロサービス間での通信を制御します。これにより、アプリケーションのデータが転送中も保護されます。Istioは、通信内容の暗号化や認証、トラフィック制御などの機能を持ち、データを安全にやり取りすることが可能です。
最後に、クライアント側の暗号化は、データがクラウドに送られる前にすでに暗号化されている状態を指します。これにより、アップロードされるデータが静止状態のときも暗号化された状態を保つことができます。
これらの組み合わせにより、データが転送中、使用中、静止状態のいずれであっても、エンドツーエンドの暗号化を達成することが可能です。
不正解についての説明：
選択肢：External Key Manager
この選択肢が正しくない理由は以下の通りです。
External Key Managerは暗号化キーをGoogle Cloudの外部で管理するためのサービスで、それ自体がデータのエンドツーエンドの暗号化を提供するものではありません。
一方、Confidential ComputingとIstioはデータの暗号化を提供し、クライアント側の暗号化もエンドツーエンドの保護を提供します。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キーは静止状態のデータの暗号化に対するコントロールを提供しますが、転送中や使用中のデータに対する暗号化はサポートしていません。
一方、Confidential ComputingとIstio、クライアント側の暗号化はそれぞれ使用中、転送中、静止状態のデータの暗号化をサポートします。
選択肢：Cloud HSM
この選択肢が正しくない理由は以下の通りです。
Cloud HSMは強力なCloud HSMで、暗号鍵操作を安全に実行できますが、エンドツーエンドのデータ暗号化を自動的に提供するものではありません。
一方で、IstioとConfidential Computingは通信を保護し、クライアント側暗号化は使用中および静止状態のデータを保護します。
参考リンク：
https://cloud.google.com/security/confidential-computing
https://cloud.google.com/istio/docs/istio-on-gke/overview
https://cloud.google.com/kms/docs/encryption-at-rest-concepts
</div></details>

### Q.  問題21: 未回答
あなたの組織は新しいワークロードを取得しました。Webおよびアプリケーション（App）サーバーは、新しく作成されたカスタムVPC内のCompute Engine上で実行されます。あなたは、以下の要件を満たすセキュアなネットワーク通信ソリューションを構成する責任を負っています：
- Web層とApp層間の通信のみを許可します。
- Web層とApp層のオートスケール時に一貫したネットワークセキュリティを強制します。
- Compute Engineインスタンス管理者がネットワークトラフィックを変更できないようにする必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、新しいワークロードのためにCompute Engine上で実行されるWebサーバーとAppサーバー間の通信をセキュアに管理する方法について問われています。重要な要件として、Web層とApp層間の通信のみを許可し、ネットワークトラフィックの管理をCompute Engineインスタンスの管理者から制限する必要があります。これは、セキュリティの強化が求められており、各層の通信の許可や禁止を正確に管理して、オートスケール時にも一貫性のあるセキュリティを確保する必要があることを示しています。これを解決するためには、適切なサービスアカウントとVPCファイアウォールルールの設定が鍵となります。
基本的な概念や原則：
VPC（Virtual Private Cloud）：Google Cloud内で定義されたプライベートネットワーク空間です。VPCを利用することで、自分だけの分離されたネットワーク環境を作成し、ネットワークの設定や制御を柔軟に行うことができます。
Compute Engine：Google Cloudのインフラストラクチャインスタンスサービスです。仮想マシンを短時間や長時間、大量あるいは少量作成することができます。
サービスアカウント：Google CloudのAPIを使用するアプリケーションを認証するための特殊なアカウントです。サーバ間での認証や権限管理に使用されます。
インスタンステンプレート：Compute Engineの仮想マシンの設定を再利用し、新たなインスタンスを効率的に作成するためのテンプレートです。オートスケーリングなどのシナリオで構成の一貫性を保つために使用されます。
VPCファイアウォールルール：ネットワーク内のトラフィックのフィルタリングを行う際のルールを定義します。特定のネットワークやインスタンスに対して通信を許可または拒否する動作を制御するのに使用します。
ネットワークタグ：Google Cloudのリソースに紐づけることができるラベルのこと。ネットワークタグを利用し、ファイアウォールルールやルーティングルールに紐づけることで、柔軟なネットワークの管理が可能になります。
オートスケーリング：負荷に応じて自動的にリソース数を増減する機能です。コスト効率の改善やパフォーマンスの最適化に寄与します。
正解についての説明：
（選択肢）
・1.それぞれのサービスアカウントで構成されたインスタンステンプレートを使用して、WebサーバーとAppサーバーを再デプロイします
2.それぞれのサービスアカウントでターゲット/ソースを指定する許可VPCファイアウォールルールを作成します
この選択肢が正解の理由は以下の通りです。
まず、セキュリティを強化するためには、各層（Web層とApp層）で異なるサービスアカウントを使用することが推奨されます。サービスアカウントは、特定のリソース（このケースではCompute Engineインスタンス）に、そのリソースがアクセスできるリソースと操作の許可を与えることで、ロールベースのアクセス制御（RBAC）を実装します。この方法で、各インスタンステンプレートは特定のサービスアカウントを使用します。そのため、オートスケーリング時でもそれぞれのインスタンスは一貫したアクセス制御ポリシーを持つことになります。
次に、VPCファイアウォールルールを使用してWeb層とApp層間の通信だけを許可します。前述したサービスアカウントに基づいてファイアウォールルールを適用します。これにより、Compute Engineインスタンスの管理者がネットワークトラフィックを変更できないように制限し、ネットワークセキュリティを強制することができます。
不正解についての説明：
選択肢：1.実行中のすべてのWebサーバーとAppサーバーに、それぞれのネットワークタグを設定します
2.それぞれのネットワークタグでターゲット/ソースを指定する許可VPCファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
ネットワークタグを使用すると、Compute Engineインスタンスの管理者がルールを変更する可能性があるため、最終的にはセキュリティ要件を満たさない可能性があります。
一方、サービスアカウントを使用すると、インスタンスを管理する能力を限定し、セキュリティ要件を満たすことができます。
選択肢：1.実行中のすべてのWebサーバーとAppサーバーに、それぞれのサービスアカウントを設定します
2.それぞれのサービスアカウントでターゲット/ソースを指定する許可VPCファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
実行中のインスタンスにサービスアカウントを後から設定することはできません。新たにサービスアカウントを設定するためにはインスタンスを再デプロイする必要があります。それに対して正解の選択肢では、インスタンステンプレートを使用して新たにサービスアカウントを適用したインスタンスをデプロイする方法が示されており、要件を満たします。
選択肢：1.それぞれのネットワークタグで構成されたインスタンステンプレートを使用して、WebサーバーとAppサーバーを再デプロイします
2.それぞれのネットワークタグでターゲット/ソースを指定する許可VPCファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
ネットワークタグはCompute Engineインスタンス管理者によって変更が可能です。そのため、この選択肢では"Compute Engineインスタンス管理者がネットワークトラフィックを変更できないようにする"という要件を満たすことができません。
一方、正解の選択肢ではサービスアカウントはIAMロールにより権限が制御されるためこの要件を満たします。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/compute/docs/instances/service-accounts
https://cloud.google.com/compute/docs/instance-templates
</div></details>

### Q.  問題22: 未回答
ある企業が、ミッションクリティカルなアプリケーションのコンテナイメージでGoogle Kubernetes Engine（GKE）を使用しています。この企業は、既知のセキュリティ問題についてイメージをスキャンし、Google Cloudの外部に公開することなく、レポートをセキュリティチームと安全に共有したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ミッションクリティカルなアプリケーションのセキュリティを維持しつつ、セキュリティレポートを適切に共有する適切なGoogle Cloudの機能やサービスを選ぶことが求められています。問題指定から、コンテナイメージに対してスキャンを行う必要があり、結果を企業外部に公開せずにセキュリティチームと共有しなければならないことが分かります。したがって、コンテナ象限のセキュリティの最適な管理と、結果の適切なアクセス制御や共有が解答の鍵となります。それらを満たすための適切なGoogle Cloudサービスとその設定方法を選びましょう。
基本的な概念や原則：
Artifact Registry：Google Cloudの統合アーティファクト管理サービスです。Dockerイメージや他の種類のアーティファクトを安全に保存し、共有することができます。また、脆弱性スキャンも可能です。
Google Kubernetes Engine（GKE）：Google Cloudのマネージドサービスです。Kubernetesクラスターを管理し、ワークロードをデプロイ、スケーリング、更新するのを簡単にします。
Cloud Build：Google Cloudのビルドサービスです。ユーザーは、CI/CDパイプラインを使ってソースコードからコンテナイメージをビルドし、Artifact Registry等にプッシュすることができます。
Security Command Center：Google Cloudのセキュリティとリスク管理プラットフォームです。Google Cloudのリソースの脆弱性や脅威を検出し、リスクを可視化・評価することができます。
Container Threat Detection：Security Command Centerの機能で、Google Cloudにデプロイされたコンテナのランタイムセキュリティ問題を検出します。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。gsutilツールを使ってデータをアップロードダウンロードすることが可能です。
GitHub：ソースコードのバージョン管理と共有サービスです。外部サービスとしてセキュリティの管理が必要となります。
正解についての説明：
（選択肢）
・1. Artifact Registry設定で脆弱性スキャンを有効にします
2. Cloud Buildを使用してイメージをビルドします
3. 自動スキャンのためにイメージをArtifact Registryにプッシュします
4. Artifact Registryのレポートを表示します
この選択肢が正解の理由は以下の通りです。
Artifact Registryは、Google Cloudが提供するパッケージ管理サービスであり、コンテナイメージを含む多種多様なアーティファクトを保存、管理することが可能です。すべてのイメージは、保存される際に自動的に脆弱性スキャンされ、結果はレポートとして提供されます。これにより、セキュリティチームは常に最新のセキュリティ状況を確認することができます。このレポートは、Google Cloudの内部で生成・管理され、第三者に公開されることはありません。
また、Cloud Buildは継続的統合（CI）と継続的デプロイ（CD）のためのサービスであり、ここではミッションクリティカルなアプリケーションのイメージのビルドを行います。その後、ビルドしたイメージはArtifact Registryにプッシュされ、脆弱性スキャンが自動的に行われます。Artifact Registryを用いることによって、コンテナイメージの管理とセキュリティの課題を一元的に解決することが可能です。
不正解についての説明：
選択肢：1. Security Command CenterプレミアムレベルでContainer Threat Detectionを有効にします
2. サポートされているバージョンのGKEにないすべてのクラスターを、可能な最新のGKEバージョンにアップグレードします
3. Security Command Centerからの結果を表示して共有します
この選択肢が正しくない理由は以下の通りです。
Security Command CenterのContainer Threat Detectionはランタイムの脅威の検出に使用され、コンテナイメージの脆弱性スキャンには適していません。
また、GKEを最新バージョンにアップグレードすることでセキュリティ問題を解決するとは限らず、脆弱性を具体的にスキャンし、結果を共有する正解のセットとは異なるアプローチです。
選択肢：1. Cloud Buildのオープンソースツールを使用してイメージをスキャンします
2. gsutilを使用して、Cloud Storage内の一般にアクセス可能なバケットにレポートをアップロードします
3. スキャンレポートのリンクをセキュリティ部門と共有します
この選択肢が正しくない理由は以下の通りです。
まず、Cloud Storageの一般公開バケットにレポートをアップロードすると、外部からアクセス可能になり、セキュリティの観点から不適切です。
それに対して、正解の選択肢ではArtifact Registryを利用しているので、この問題は発生しません。
また、Cloud Buildのツールを使うとセキュリティスキャンの範囲が限定的になりますが、Artifact Registryを使うと広範な脆弱性スキャンが行えます。
選択肢：1. GitHubサブスクリプションを取得します
2. Cloud Buildでイメージをビルドし、自動スキャンのためにGitHubに保存します
3. GitHubからレポートをダウンロードし、セキュリティチームと共有します
この選択肢が正しくない理由は以下の通りです。
GitHubはGoogle Cloudプロダクトではなく、Google Cloud環境の外部に存在します。Google Cloudの外部にイメージを公開することなくセキュリティ問題についてスキャンし、レポートをセキュリティチームと共有したい企業の要件を満たすために、GitHubサブスクリプションを取得し、Cloud BuildでビルドしたイメージをGitHubに保存することは適切ではありません。
参考リンク：
https://cloud.google.com/artifact-registry/docs/container-analysis
https://cloud.google.com/container-analysis/docs/vulnerability-scanning
https://cloud.google.com/build/docs/building/build-containers
</div></details>

### Q.  問題23: 未回答
フロントエンドがサブネットAのマネージドインスタンスグループにデプロイされ、データレイヤーが同じVPC上のサブネットBにあるmysql Compute Engine仮想マシン（VM）に保存されているアプリケーションがあります。サブネットAとサブネットBには、他にもいくつかのCompute Engine VMがあります。アプリケーションのフロントエンドだけがポート3306でアプリケーションのmysqlインスタンスのデータにアクセスできるようにしたいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のアプリケーションのフロントエンドからデータレイヤーへのポート3306での通信を調整する方法について問われています。ここで重要なのは、フロントエンドとデータレイヤーが同一のVPC内の異なるサブネットに配置されているという状況と、フロントエンドだけがmysqlインスタンスのデータにアクセスできるようにしたいという要件です。これを達成するためには、適切なファイアウォールルールの設定が必要であり、Google Cloudのサービスアカウントを利用して通信を制限する方法を考える必要があります。この結果、サブネットやタグ指定ではなく、サービスアカウントを使用して特定の通信だけを許可する方法を選択することが必要になります。
基本的な概念や原則：
VPC（Virtual Private Cloud）：Google Cloud上で仮想的なプライベートネットワーク環境を構成する機能です。ネットワーク内でのリソースの通信を自由に設定することができます。
サブネット：VPC内のネットワークをさらに細かく分割したもので、異なるサブネット間通信は設定により制御可能です。
Compute Engine VM（Virtual Machine）：Google CloudのIaaS（Infrastructure as a Service）で提供される仮想マシンのサービスです。
マネージドインスタンスグループ：Compute Engine VMをグループ化し、スケーリングやバランシングなどの機能を一元管理できるサービスです。
ファイアウォールルール：ネットワークのセキュリティを管理するためのルールで、特定のポートやIP範囲からの通信を許可または拒否できます。
サービスアカウント：アプリケーションがGoogle Cloud APIを呼び出すための特殊なアカウントで、リソースへのアクセス権を制御するために使用されます。
タグ：Google Cloudリソースに追加できるメタデータの一種で、ファイアウォールルールやロードバランサーなどと組み合わせてリソースの管理を行うことができます。
正解についての説明：
（選択肢）
・ポート3306で、フロントエンドの固有サービスアカウントからmysql Compute Engine VMの固有サービスアカウントへの通信を許可するインバウンドファイアウォールルールを構成します
この選択肢が正解の理由は以下の通りです。
まず、構成で考慮すべきポイントはフロントエンドのインスタンスからmysql Compute Engine VMへの特定のポート（3306）を通じたアクセスの許可であり、この目的を達成する最も直接的で効果的な方法は、インバウンドファイアウォールルールの構成です。これにより、指定されたポートへの特定のサービスアカウントからの通信を正確に制御できます。
また、固有のサービスアカウントをフロントエンドとmysql Compute Engine VMに適応させることで、他のCompute Engine VMインスタンスからmysqlのデータにアクセスする可能性を大幅に減らし、アクセスを必要とする特定のインスタンスのみに限定できます。これにより、データのセキュリティとプライバシーが向上します。
したがって、この選択肢はアプリケーションの要求を満たし、データのアクセスを制限し、セキュリティを強化するための最適な解決策となります。
不正解についての説明：
選択肢：サブネットAのsrc IPレンジから、ポート3306のmysql Compute Engine VMに適用されるタグ "data-tag"への通信を許可するインバウンドファイアウォールルールを設定します
この選択肢が正しくない理由は以下の通りです。
サブネットAのsrc IPレンジは、フロントエンドだけでなく、そのサブネット内の他のVMも含まれるため、すべてのVMがmysqlインスタンスにアクセスできるようにします。これは問題の要件、すなわち"フロントエンドだけがmysqlインスタンスのデータにアクセスできるようにする" を満たしていません。指定の"固有のサービスアカウント"を使用した場合、特定のフロントエンドインスタンスのみがデータにアクセスできるように制御できます。
選択肢：data-tagでタグ付けされたCompute Engine VMから、fe-tagでタグ付けされた宛先のCompute Engine VMへの通信を許可するアウトバウンドファイアウォールルールを設定します
この選択肢が正しくない理由は以下の通りです。
アウトバウンドルールはインターネットや他のネットワークへの通信を制御しますが、ファイアウォールルールでは同一ネットワーク内のマシーン間通信の制御はできません。同一ネットワークのインスタンス間の通信を制御するために、インバウンドルールを設定する必要があります。
選択肢：fe-tagでタグ付けされたCompute Engine VMから、data-tagでタグ付けされた宛先のCompute Engine VMへの通信を許可するインバウンドファイアウォールルールを設定します
この選択肢が正しくない理由は以下の通りです。
タグベースのファイアウォールルールでは、特定のサービスやアプリケーション間の通信に限定することは困難です。サブネットAとBにいくつかのCompute Engine VMがある場合、他のVMも同じポートでの通信が可能になってしまいます。そのため、制限を強化するためには、特定のサービスアカウント間の通信を許可する設定が適しています。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/compute/docs/instances/managing-instance-access
https://cloud.google.com/iam/docs/understanding-service-accounts
</div></details>

### Q.  問題24: 未回答
ユーザーの代わりにユーザーのGoogle Driveにアクセスする必要がある、社内のApp Engineアプリケーションを作成しています。あなたの会社は、現在のユーザーの認証情報に依存したくありません。また、Googleが推奨するプラクティスにも従いたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ユーザーのGoogle DriveにアクセスするApp Engineアプリケーションを作成する際の認証に関する戦略を理解することが求められています。まず、現在のユーザーの認証情報に依存しない方法を探す必要があることと、Googleの推奨するプラクティスに従うことが要件となっています。したがって、この問題を解くためには、Googleの認証とアクセス制御に関する推奨するプラクティスとサービスアカウントについての理解が必要です。また、ユーザーのユーザーを偽装する方法やG Suiteドメイン全体の委任に関する知識も重要です。
基本的な概念や原則：
サービスアカウント：Google Cloudで使用される特殊な種類のアカウントで、あるアプリケーションが他のGoogle Cloudリソースと通信するために使用されます。
G Suiteドメイン全体の委任：Google Workspace（旧G Suite）のサービスアカウントが、特定のユーザーに代わって操作を実行する権限を得るための設定です。
ユーザー偽装（ユーザー代行）：サービスアカウントが特定のユーザーに代わって操作を実行することです。ユーザーの認証情報に依存せずに、ユーザーのデータに対するAPIのリクエストを行うことができます。
Service Account Userロール：サービスアカウントを代行してアクションを実行するための権限を持つロールです。
G Suite管理者アカウント：Google Workspaceの管理を担当するアカウントです。高い権限を持ち、組織全体の設定を変更することが可能です。
正解についての説明：
（選択肢）
・新しいサービスアカウントを作成し、G Suiteドメイン全体の委任を付与します。アプリケーションに、このアカウントを使用してユーザーを偽装させます
この選択肢が正解の理由は以下の通りです。
まず、Googleではサービスアカウントを使用してアプリケーションに認証と認可の情報を提供します。サービスアカウントは特定のアプリケーション名で、そのアプリケーションがGoogleサービスにアクセスするための認証情報を持つように設計されています。これにより、個々のユーザー認証情報に依存することなく、アプリケーションがGoogleサービスに安全にアクセスできます。そのため、この選択肢はユーザー認証情報に依存しない要件を満たすことができます。
また、ドメイン全体の委任を付与することで、App EngineアプリケーションがユーザーのGoogle Driveにアクセスするための権限を得ることができます。
最後に、ユーザーを偽装させることで、アプリケーションが特定のユーザーとして行動し、そのユーザーのGoogle Driveのデータにアクセスすることが可能になります。これらの理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：新しいサービスアカウントを作成し、すべてのアプリケーションユーザーにService Account Userロールを与えます
この選択肢が正しくない理由は以下の通りです。
すべてのアプリケーションユーザーにService Account Userロールを与えると、ユーザーはサービスアカウントを使用して資源にアクセスできますが、特定のユーザーとして偽装することはできません。
一方、G Suiteドメイン全体の委任を付与すれば、アプリケーションは特定のユーザーとして偽装でき、そのユーザーのDriveにアクセスできます。
選択肢：新しいサービスアカウントを作成し、すべてのアプリケーションユーザーをGoogleグループに追加します。このグループにService Account Userロールを与えます
この選択肢が正しくない理由は以下の通りです。
サービスアカウントを作成し、すべてのアプリケーションユーザーをGoogleグループに追加し、Service Account Userロールを与えるという方法は、ユーザーのGoogle Driveにアクセスするリソースレベルの委任を実現できません。
これに対し、正解の選択肢では、G Suiteドメイン全体の委任を使用してユーザーを偽装することで、ユーザーがアクセス権を持つ各リソースへのアクセスが可能になる解決策が提供されています。
選択肢：専用のG Suite管理者アカウントを使用し、このG Suite資格情報でアプリケーションの操作を認証します
この選択肢が正しくない理由は以下の通りです。
専用のG Suite管理者アカウントを使用する方法は、現在のユーザーの認証情報に依存するため、問題の要件を満たしません。
これに対して、サービスアカウントを使用しG Suiteドメイン全体の委任を付与することで、ユーザーの認証情報に依存せずにユーザーのGoogle Driveにアクセスすることが可能になります。
参考リンク：
https://cloud.google.com/iam/docs/understanding-service-accounts
https://cloud.google.com/iam/docs/impersonating-service-accounts
https://developers.google.com/identity/protocols/oauth2/service-account#delegatingauthority
</div></details>

### Q.  問題25: 未回答
IaaSのセキュリティ責任共有モデルでは、顧客はスタックのどの2つのレイヤーの責任を共有しますか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、IaaS（Infrastructure as a Service）のセキュリティ責任共有モデルに関して、どの2つのレイヤーにおいて顧客が責任を負うのかを特定する必要があります。IaaSサービス提供者と顧客との間でどのセキュリティ要素が共有され、一方でどの要素がサービスプロバイダーの責任であるのか、その知識を基に選択肢を評価します。また、IaaS環境において顧客が直接制御や管理しないものは、顧客責任の範囲外と捉えるべきです。
基本的な概念や原則：
IaaSのセキュリティ責任共有モデル：クラウドサービスプロバイダー（CSP）とお客様がセキュリティ責任を共有するモデルです。CSPは基盤のセキュリティ（物理的なデータセンターやネットワーク）を、お客様はそれ以外（採用したOSやアプリケーションのセキュリティ）を管理します。
ネットワークセキュリティ：ネットワーク内の情報資産を不正アクセスや脅威から守るための手段です。ファイアウォールの設定、NATの適用などが含まれます。
アクセスポリシー：特定のリソースへのアクセスを許可する、または拒否するための規則です。IAM（Identity and Access Management）ロールやポリシーを設定し、特定のユーザー、ユーザーグループ、またはサービスに対するアクセス権を制御します。
ハードウェア：IaaS上では、ハードウェアの管理はCSPが担当します。物理的なデバイスの管理、メンテナンス、更新を含みます。
ストレージ暗号化：ストレージに保存されるデータを暗号化し、不正利用や漏洩から保護する手段です。これもCSPの責任範囲内と考えることが多いです。
正解についての説明：
（選択肢）
・ネットワークセキュリティ
・アクセスポリシー
この選択肢が正解の理由は以下の通りです。
IaaS（Infrastructure as a Service）のセキュリティ責任共有モデルでは、基礎となる物理的なインフラストラクチャはプロバイダーによって管理されますが、コンピューティングリソースとその上で動作するアプリケーションに対するセキュリティは顧客の責任となります。これは、ネットワークセキュリティとアクセスポリシーの2つのレイヤーを含みます。
ネットワークセキュリティについては、顧客は自己のVMでのトラフィックの流れを管理・制御する責任があります。これには、ファイアウォールの設定やネットワークACLsなど、ネットワークレベルでのセキュリティ設定が含まれます。
また、アクセスポリシーについては、顧客は自身のリソースへのアクセスを適切に管理・制御する責任があります。これは誰が何を行うことができるかを定義するためのポリシーを設定することおよびその運用を含みます。
したがって、IaaSのセキュリティ責任共有モデルでは、ネットワークセキュリティとアクセスポリシーが顧客の共有責任となり、正解の選択肢となります。
不正解についての説明：
選択肢：ハードウェア
この選択肢が正しくない理由は以下の通りです。
IaaSのセキュリティ責任共有モデルでは、プロバイダがハードウェアについてのセキュリティを確保するのが一般的です。
一方、ネットワークセキュリティやアクセスポリシーは顧客の責任範囲であり、これらは顧客が設定や管理を行うべき項目です。
選択肢：ストレージの暗号化
この選択肢が正しくない理由は以下の通りです。
IaaSではプロバイダが基盤を提供し、その上で顧客がセキュリティ対策を行う必要がありますが、ストレージの暗号化は基盤の一部であり、プロバイダの責任範囲内です。ネットワークセキュリティやアクセスポリシーは顧客が設定する部分であり、これらの責任を顧客が共有します。
選択肢：ブート
この選択肢が正しくない理由は以下の通りです。
ブートは基本的なコンピューティングプロセスの一部で、オペレーティングシステムを起動するプロセスを指しますが、これはIaaSプロバイダが提供する範囲であり、顧客の責任範囲外です。
一方、ネットワークセキュリティとアクセスポリシーは、クラウドサービスを利用する上で顧客が設定し管理すべき項目であるため、IaaSのセキュリティ責任共有モデルに含まれます。
参考リンク：
https://cloud.google.com/security/foundation
https://cloud.google.com/iam/docs
https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html
</div></details>

### Q.  問題26: 未回答
Google Cloud上に多数のプライベート仮想マシンがあります。リモートからSSH（Secure Socket Shell）を使用してサーバーを管理する必要があります。あなたは、セキュリティとコスト効率を最適化する方法でサーバへのリモートアクセスを構成したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud上の仮想マシンに対しSSHを用いたリモートでの管理の実現手段を問われています。重要なのは、その手段がセキュリティとコスト効率の両面で最適化されていなければならないという点です。よって、選択肢を見る際には、それぞれがどのようにセキュリティを確保し、コスト面でどれだけ効率的かを考慮し、その中で最適と言える手段を選ぶべきです。
基本的な概念や原則：
Identity-Aware Proxy（IAP）：Google Cloudのサービスで、ユーザーの認証とコンテキストに基づくアクセス制御を提供します。VPNや専用のハードウェアなしで、安全なリモートアクセスを実現できます。
ファイアウォールルール：ネットワークの安全性を確保するための規則です。特定のIP範囲からのアクセスの許可や拒否を設定できます。
ロールベースのアクセス制御：特定のロールに基づいてユーザーやサービスへのアクセスを制御するセキュリティ戦略です。IAPで保護されたトンネルユーザーのロールを管理者に付与する事で、SSHアクセスを許可することができます。
サイト間VPN：2つのネットワーク間を安全に接続するための仮想的なプライベートネットワークです。しかし、設定が複雑でコストがかかるため、リモートアクセスの設定には最適化されていません。
パブリックIPアドレス：インターネット上で一意に識別可能なIPアドレスです。しかし、パブリックIPアドレスを持つサーバーインスタンスは、外部からの不正アクセスのリスクがあります。
ジャンプホスト：一般的には、他のすべてのマシンへのアクセスポイントとなる中間的なホストです。しかし、この方法は管理が難しく、セキュリティリスクが高まる可能性があります。
正解についての説明：
（選択肢）
・Identity-Aware Proxy（IAP）IP範囲からのアクセスを許可するファイアウォールルールを 作成します。IAPで保護されたトンネルユーザーのロールを管理者に付与します
この選択肢が正解の理由は以下の通りです。
まず、Identity-Aware Proxy（IAP）の使用は、SSH接続を通じて仮想マシンに安全にアクセスするための効果的な手段です。IAPはGoogle Cloud Identityと統合し、使用者の個々の認証と承認を実行します。これにより、公開サーバーやVPNへの依存を無くし、セキュリティ効率を向上させることが可能になります。
また、IAPへのアクセスを許可するファイアウォールルールを作成することで、信頼されたIP範囲からの接続のみを許可します。これにより不要なトラフィックを排除し、セキュリティが強化されます。
さらに、IAPで保護されたトンネルユーザーのロールを管理者に付与することで、リモートからのサーバー管理を効果的に実現します。これは、資格情報をマネージメントし、端末アクセスを管理者に制限することによってコスト効率とセキュリティをより一層最適化します。
不正解についての説明：
選択肢：企業ネットワークからGoogle Cloudへのサイト間VPNを作成します
この選択肢が正しくない理由は以下の通りです。
企業ネットワークからGoogle Cloudへのサイト間VPNを作成すると、セキュリティは確保できますが、コスト効率が低くなる可能性があります。
一方、Identity-Aware Proxy（IAP）を使用すれば、ユーザーやグループに基づいてアクセス制御を行うことができ、コスト効率も良好です。
選択肢：パブリックIPアドレスを持つサーバーインスタンスを構成します。企業IPからのトラフィックのみを許可するファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
パブリックIPアドレスを持つサーバーインスタンスはコストとセキュリティの面で不利で、静的なパブリックIPは料金が発生し、公開されるため攻撃の対象となり得ます。
一方、Identity-Aware Proxy（IAP）はGoogle Cloudの認証を使用するためセキュリティが強化されますし、クラウド内での通信は無料であるためコスト効率も高まります。
選択肢：パブリックIPを持つジャンプホストインスタンスを作成します。ジャンプホストから接続してインスタンスを管理します
この選択肢が正しくない理由は以下の通りです。
ジャンプホストを使用すると、セキュリティが低下し、不正なアクセスのリスクが増加します。
また、ジャンプホストには追加のコストがかかるため、コスト効率も低下します。
それに対して、IAPを使用すれば、追加のコストなしでセキュアなアクセスを実現でき、セキュリティとコスト効率を最適化します。
参考リンク：
https://cloud.google.com/iap/docs/using-tcp-forwarding
https://cloud.google.com/vpc/docs/using-firewalls
https://cloud.google.com/compute/docs/instances/connecting-advanced#identity-aware-proxy
</div></details>

### Q.  問題27: 未回答
ある企業が、専用サーバールームでワークロードを実行しています。これらのワークロードには、社内のプライベートネットワークからのみアクセスできる必要があります。あなたは、Google Cloudプロジェクト内のCompute Engineインスタンスからこれらのワークロードに接続する必要があります。
要件を満たすためにどの2つのアプローチを取ることができますか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、企業のローカルネットワークとGoogle Cloudプロジェクト間の接続方法について問われています。問題文のキーポイントは、社内ネットワークからのみアクセス可能である要請、そしてGoogle CloudのCompute Engineインスタンスを用いる要件です。各選択肢を見て、これらの特性と要件を満たすものを選ぶことが求められます。ただし、Google Cloudのネットワークの仕組みや各選択肢が何を意味するのか、よく理解していないと見当違いの選択肢を選ぶ可能性がありますので注意が必要です。
基本的な概念や原則：
Cloud VPN：Google Cloudとオンプレミスネットワーク間の安全な接続を提供するフルマネージドのIPsec VPNソリューションです。プライベートネットワークの拡張やハイブリッドクラウド設定に使用します。
Cloud Interconnect：Google Cloudと自社インフラストラクチャ間の専用の物理的接続を提供します。高スループットの要求に対応し、ネットワークの信頼性とパフォーマンスを向上させます。
共有VPC：複数のGoogle Cloudプロジェクト間で単一のVPCネットワークを共有する機能です。ただし、オンプレミスのプライベートネットワークとの接続には使用しません。
VPCピアリング：Google Cloudの異なるプロジェクト間や異なるVPCネットワーク間で通信を許可する機能です。ただし、オンプレミスのプライベートネットワークとの接続には使用しません。
Private Access：Google Cloudのサービスに対してVPCネットワークからプライベートIPアドレスを使用してアクセスする機能です。ただし、オンプレミスのプライベートネットワークとの接続には使用しません。
正解についての説明：
（選択肢）
・Cloud VPNでプロジェクトを構成します
・Cloud Interconnectでプロジェクトを構成します
この選択肢が正解の理由は以下の通りです。
まず、Cloud VPNはプライベートネットワークとGoogle Cloudとの間にVPN（仮想プライベートネットワーク）接続を確立するサービスであり、Compute Engineインスタンスから企業内部のプライベートネットワークに安全に接続するのに最適です。既存のネットワークとGoogle Cloudとを安全な接続でリンクし、仮想的に同一ネットワーク上にあるかのように操作できます。
したがって、Cloud VPNは社内のプライベートネットワークからのみアクセス可能なワークロードへの接続要件を満たします。
一方、Cloud Interconnectは、Google Cloudとオンプレミスのデータセンターまたは他のネットワーク間での大量のデータ通信を高速かつ安全に行うためのサービスで、専用の接続を提供します。Compute Engineインスタンスから社内のワークロードへの高速な接続が必要な場合には、Cloud Interconnectを使用します。つまり、Cloud Interconnectも同様に社内のプライベートネットワークからのみアクセス可能なワークロードへの接続要件を満たします。
したがって、これらの2つの選択肢が正解となります。
不正解についての説明：
選択肢：共有VPCでプロジェクトを構成します
この選択肢が正しくない理由は以下の通りです。
共有VPCは、同一組織内の複数のGoogle Cloudプロジェクト間でネットワークを共有するためのものであり、社内のプライベートネットワークとGoogle Cloudプロジェクト間の接続を担保する機能はありません。
それに対して、Cloud VPNやCloud Interconnectは社内ネットワークとGoogle Cloudとの安全な接続を提供します。
選択肢：VPCピアリングでプロジェクトを構成します
この選択肢が正しくない理由は以下の通りです。
VPCピアリングは、2つのGoogle Cloudプロジェクト間または同じプロジェクト内のVPCネットワーク間でネットワーク接続を行うためのサービスで、企業内部のプライベートネットワークとの接続には用いられません。要件のように社内ネットワークとGoogle Cloudをセキュアに接続するために、Cloud VPNやCloud Interconnectの使用が適切です。
選択肢：すべてのCompute EngineインスタンスをPrivate Accessで構成します
この選択肢が正しくない理由は以下の通りです。
Compute EngineのPrivate Access設定は、インスタンスがGoogle Cloud内のサービスとプライベートに通信できるようにするものであり、社内のプライベートネットワークとは接続できません。しかし、Cloud VPNやCloud Interconnectは直接企業のネットワークとGoogle Cloudを接続し、必要な通信要件を満たすことができます。
参考リンク：
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/network-connectivity/docs/interconnect/concepts/overview
https://cloud.google.com/vpc/docs/configure-private-google-access#gcloud
</div></details>

### Q.  問題28: 未回答
以前はGoogle Managed Encryption Keys（GMEK）を使用してCloud Storageにファイルを保存していましたが、最近社内ポリシーが更新され、Customer Managed Encryption Keys（CMEK）が必要になりました。最小限のコストで迅速かつ効率的にファイルを再暗号化する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、暗号化キーの管理方法の変更に伴うファイルの再暗号化作業について考える必要があります。元々Google Managed Encryption Keys（GMEK）で暗号化されたファイルを、Customer Managed Encryption Keys（CMEK）に変更して再暗号化を行うのですが、その際、最小限のコストで迅速かつ効率的な方法が求められています。選択肢を評価するときは、これらの要因を考慮に入れ、コストや作業時間を小さく抑えつつCMEKへの変更を確実に達成できる方法を選びましょう。
基本的な概念や原則：
Google Managed Encryption Keys（GMEK）：Google Cloudが管理する暗号化キーです。Cloud Storageはデフォルトでこの方式を利用してすべてのオブジェクトの暗号化を行います。
Customer Managed Encryption Keys（CMEK）：顧客がGoogle Cloud上で管理する暗号化キーです。自分の鍵を生成、管理し、顧客のデータを暗号化するために使用します。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データの保存、取得、共有を行うことができます。
オブジェクトの書き換え：Cloud Storage内のオブジェクトを変更する操作です。オブジェクトを違う暗号化方式で再暗号化する場合に使用します。
gsutil：Google Cloud Storageのコマンドラインツールです。ファイルのアップロード、ダウンロード、バケットの作成等、Cloud Storageの操作が可能です。
正解についての説明：
（選択肢）
・バケットの暗号化タイプをCMEKに変更し、オブジェクトを書き換えます
この選択肢が正解の理由は以下の通りです。
まず、Google Managed Encryption Keys（GMEK）をCustomer Managed Encryption Keys（CMEK）に変更するためには、まずバケットの暗号化タイプをCMEKに切り替える必要があります。暗号化タイプを変更した時点ではすでに保存されているオブジェクトの暗号化は変更されませんので、新たな鍵で再暗号化するにはそのオブジェクトを書き換える操作が必要となります。ただし、この書き換え操作は既存のデータに影響を与えるものではありません。つまり、オブジェクト自体を改ざんしたり、新規にアップロードしたりする必要はありません。
このように、暗号化タイプをCMEKに変更し、オブジェクトを書き換えることで、最小限のコストで、迅速かつ効率的に再暗号化を行うことが可能となります。
不正解についての説明：
選択肢：gsutilを使用して、キーファイルを指定して同じCloud Storageバケットにファイルを再アップロードします
この選択肢が正しくない理由は以下の通りです。
gsutilを使用して同じバケットにファイルを再アップロードすると、新たなストレージスペースが必要になり、これに伴うコストが発生します。
一方で、バケットの暗号化タイプをCMEKに変更し、オブジェクトを書き換える方法では、追加のストレージコストが発生しません。
選択肢：ローカルでファイルを暗号化し、gsutilを使って新しいバケットにファイルをアップロードします
この選択肢が正しくない理由は以下の通りです。
ローカルでファイルを暗号化して再アップロードする方法は、時間とリソースを大量に必要とし、コスト効率が悪いです。
対照的に、バケットの暗号化タイプをCMEKに変更し、オブジェクトを書き換える方法は、迅速かつ効率的にファイルを再暗号化できます。
選択肢：セカンダリーリージョンにあるCMEKが有効な新しいバケットにファイルをコピーします
この選択肢が正しくない理由は以下の通りです。
ファイルをセカンダリーリージョンの新しいCMEK有効バケットにコピーする方法では、データ転送にコストがかかります。
一方、正解の選択肢のバケットの暗号化タイプをCMEKに変更しオブジェクトを書き換える方法では、バケット内でのオペレーションは無料ですから最小コストで行えます。
参考リンク：
https://cloud.google.com/storage/docs/encryption/using-customer-managed-keys
https://cloud.google.com/storage/docs/encrypting-objects
https://cloud.google.com/storage/docs/gsutil/commands/rewrite
</div></details>

### Q.  問題29: 未回答
あなたの組織は、Cloud NATを通してインターネットにアクセスする仮想プライベートクラウド（VPC）内で、プライベートIPのみを持つ仮想マシン（VM）を運用しています。毎日、すべてのVMに重要なOSアップデートのパッチを適用し、サマリーレポートを提供する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、プライベートIPのみを持つ仮想マシン（VM）へのOSアップデートのパッチ適用とそのサマリーレポートの提供方法を尋ねています。仮想マシンがプライベートIPアドレスのみを持つという情報からネットワーク接続が限定されることが述べられています。したがって、インターネット接続がなくてもアップデートが可能な方法や、一つ一つのVMにログインすることなくパッチを適用できる、一括管理の効率的な方法が求められています。この点を踏まえ、選択肢を選ぶことが必要です。
基本的な概念や原則：
Cloud NAT：Google Cloudの仮想マシン（VM）やKubernetes EngineのポッドがプライベートIPからインターネットに接続するためのマネージドサービスです。公開アドレスを保持しないインスタンスからのアウトバウンド接続を可能にします。
仮想プライベートクラウド（VPC）：Google Cloud上で個別に分離された仮想ネットワーク環境です。VPC内では自由にサブネットを設定したり、ファイアウォールルールを適用したりすることができます。
VM Manager：Google Cloudのサービスで、OSパッチ管理を含む一連のワークロード管理タスクを自動化できます。管理下にあるVMに対して一元化されたOSパッチ管理を提供します。
OSパッチ管理：OSのセキュリティや機能改善を提供するための一連のアップデートプロセス。これには、パッチの選択、適用、テスト、および確認が含まれます。
Cloud Scheduler：Google Cloudのジョブスケジューラサービスです。定期的なタスクや一回限りのタスクを自動化することができます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データを格納し、必要に応じてアクセスするための安全な場所を提供します。
パブリックIP：インターネットから直接アクセス可能なIPアドレスです。Google Cloudでは、通常のトラフィック向けにIPアドレスを手動で割り当てることが可能です。
正解についての説明：
（選択肢）
・VM ManagerがVMにインストールされ、稼動していることを確認します。OSパッチ管理サービスで、重要なパッチでアップデートするパッチジョブを設定します
この選択肢が正解の理由は以下の通りです。
まず、重要なOSアップデートのパッチを毎日すべてのVMに適用するために、このプロセスを自動化する必要があります。Google CloudのVM Managerは、VM群全体のライフサイクル管理を自動化するためのサービスであり、これにはOSパッチの適用も含まれます。パッチ管理サービスは、重要なパッチでアップデートするジョブを設定する能力を持っているため、これによって毎日のパッチ適用要件を容易に満たすことができます。
さらに、VM ManagerはOSパッチの適用後に報告を生成する機能も持っているため、必須のサマリーレポートの提供も満たせます。
このように、VM Managerを利用することで設問の要件を全て満たすことができるため、この選択肢が正解となります。
不正解についての説明：
選択肢：アウトバウンドファイアウォールルールが送信トラフィックを許可していることを確認します。各VMにログインし、OS固有のアップデートコマンドを実行します。Cloud Schedulerジョブを構成して、重要なパッチを毎日アップデートするようにします
この選択肢が正しくない理由は以下の通りです。
個々のVMにログインしてOS固有のアップデートコマンドを実行するという提案は、管理作業が手動で大量であるという問題を引き起こします。反対に、VM Managerの使用はこれらの作業を自動化し、作業負荷を大幅に軽減します。
選択肢：最新のパッチをCloud Storageバケットにコピーします。各VMにログインし、パッチをバケットからダウンロードし、インストールします
この選択肢が正しくない理由は以下の通りです。
まず、各VMにログインしてパッチを手動でダウンロードし、インストールするのは効率的ではありません。
また、これは自動化の原則に反します。
それに対して、VM ManagerのOSパッチ管理サービスを使うと、パッチのアップデートを自動的に行いサマリーレポートも提供するため、要件を満たします。
選択肢：パブリックIPをVMに割り当てます。アウトバウンドファイアウォールルールが送信トラフィックを許可していることを確認します。各VMにログインし、アクティビティの少ない夜間にOSアップデートが有効になるように、毎日cronジョブを設定します
この選択肢が正しくない理由は以下の通りです。
まず、パブリックIPをVMに割り当てると、インターネット経由での直接的な接続が可能になり、セキュリティリスクが高まります。
また、手動でcronジョブを設定する管理工数は大きく、効率的な運用が困難です。適切なパッチ管理を行うには、自動化され、集中管理可能なツールであるVM Managerの使用が適しています。
参考リンク：
https://cloud.google.com/compute/docs/os-patch-management
https://cloud.google.com/nat/docs/overview
https://cloud.google.com/blog/products/identity-security/simplifying-cloud-operations-with-os-patch-management
</div></details>

### Q.  問題30: 未回答
あなたの組織は、インスタンスロギングデータをヨーロッパ内に保持する規制に準拠する必要があります。あなたのワークロードは、新しいプロジェクトでオランダのリージョンeurope-west4でホストされます。データを国内に保持するためにCloud Loggingを構成する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のリージョン内でロギングデータを保持する規制がある事業環境のセットアップを考慮することが求められています。組織のワークロードがホストされるのはeurope-west4リージョンであり、ロギングデータをこのリージョンで保持する必要があることに焦点を当てる必要があります。したがって、選択肢を評価するときは、Cloud Loggingの設定方法とそのデータの保存リージョンの管理方法に対する理解が必要です。
基本的な概念や原則：
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションとシステムのログデータを一元化し、ストレージ、分析、監視、アラートなどの機能を提供します。
ログバケット：Cloud Loggingでログデータを保存するためのコンテナです。バケットは地域を指定して作成でき、ログデータの保持ポリシーも設定できます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。ログデータのような非構造化データを保存、管理するのに利用します。ただし、Cloud Loggingのログはログバケットで直接管理されます。
ロギングシンク：特定のタイプのログエントリを収集して他のサービス（例えば、Cloud Storage）にエクスポートするための設定です。ただし、ログを特定の地域に保存するためには、その地域にログバケットを作成する必要があります。
gcloud CLI：Google Cloudをコマンドラインから操作するためのツールです。しかし、ロギングの保存リージョンはログバケット単位で設定され、gcloud CLIではなくCloud ConsoleまたはAPIから設定します。
組織ポリシー制約：Google Cloudのリソースに対する特定の制約を設定するためのポリシーです。例えば、リソースの場所を制制することができます。ただし、規制に準拠してログデータを特定の地域に保存するためには、その地域にログバケットを作成する必要があります。
正解についての説明：
（選択肢）
・europe-west4に新しいログバケットを作成し、Defaultバケットを新しいバケットにリダイレクトします
この選択肢が正解の理由は以下の通りです。
まず、Cloud Loggingではリージョンに拠点を置くログバケットを作成することができます。この機能を利用してeurope-west4に新しいログバケットを作成すれば、インスタンスロギングデータをヨーロッパ内に保持するという要件を満たすことが可能です。
また、デフォルトのログバケットを新しく作成したバケットにリダイレクトすることで、新規に生成されるログデータはすべてこの新しいバケットに格納され、既存のログはそのまま保持されます。これにより、今後のログデータも規制順守の観点から適切な場所に保持することが可能になります。以上の機能により、この選択肢は問題の要件を満たす最善の策となります。
不正解についての説明：
選択肢：組織ポリシー制約Google Cloud.resourceLocationsをeurope-west4に設定します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約Google Cloud.resourceLocationsをeurope-west4に設定することは、リソースの配置を制限するものであり、Cloud Loggingのロギングデータの地理的な配置を保証するものではありません。
それに対して、新しいログバケットをヨーロッパのリージョンで作成し、デフォルトのバケットをそちらにリダイレクトすることで、明確にログデータをヨーロッパ内で保持することが可能となります。
選択肢：ログシンクを設定して、すべてのログをeurope-west4のCloud Storageバケットにエクスポートします
この選択肢が正しくない理由は以下の通りです。
ログシンクを使用してすべてのログをeurope-west4のCloud Storageバケットにエクスポートする方法は、ログの保持リージョンを限定できますが、洗練されたログ管理や速やかなアクセスが必要な場合に適していません。
一方、europe-west4に新しいログバケットを作成し、Defaultバケットを新しいバケットにリダイレクトする方法は、Cloud Loggingのフル機能を利用しつつログを保持リージョンを制限できます。
選択肢：gcloud CLIのロギング設定の更新を使用して、ロギングの保存リージョンをeurope-west4に設定します
この選択肢が正しくない理由は以下の通りです。
gcloud CLIには、ロギングの保存リージョンを直接設定する機能は存在せず、ログバケットを特定のリージョンで作成し、Defaultバケットからリダイレクトすることでロギングデータを特定リージョン内に保持する必要があります。そのため、この方法は要件を満たしません。
参考リンク：
https://cloud.google.com/logging/docs/region-support
https://cloud.google.com/logging/docs/storage
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
</div></details>

### Q.  問題31: 未回答
あるDevOpsチームは、Google Kubernetes Engine上で実行する新しいコンテナを作成しています。アプリケーションはインターネットに接続されるため、コンテナの攻撃対象範囲を最小限に抑えたいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Kubernetes Engine（GKE）を使用して実行される新たなコンテナ作成という状況と、そのコンテナの攻撃対象範囲を最小限にするという要求に注目することが求められています。その要求を適切に満たすために、各選択肢がどのような作業を指しているかを理解し、それが問題で要求されている"攻撃対象範囲を最小限にする"という目的にどの程度寄与するかを評価することが重要です。
基本的な概念や原則：
ベースイメージ：コンテナを作成する際の基礎となるイメージです。最小限のOSと必要なソフトウェアを含むことが多いです。セキュリティを高めるためには、必要な機能のみを持つ小さなベースイメージを使用することが推奨されます。
コンテナ：複数のアプリケーションを分離して実行するための仮想化技術です。各コンテナは他のコンテナと独立して動作し、ホストOSのリソースを共有します。
Google Kubernetes Engine（GKE）：Google CloudのマネージドKubernetesサービスです。コンテナ化されたアプリケーションのデプロイ、スケーリング、管理を容易にします。
Cloud Build：Google CloudのCI/CDプラットフォームで、コードのビルド、テスト、デプロイを自動化します。ただし、コンテナの攻撃対象範囲を抑える具体的な機能は提供していません。
Artifact Registry：Google Cloudのアーティファクト管理サービスです。バージョン管理やアクセス制御などを実現しますが、コンテナの攻撃対象範囲を直接的に抑える機能は提供していません。
正解についての説明：
（選択肢）
・小さなベースイメージを使って小さなコンテナを作ります
この選択肢が正解の理由は以下の通りです。
小さなベースイメージを使ってコンテナを作成することは、コンテナの攻撃対象範囲を最小限に抑える優れた手段です。ベースイメージが小さいほど、イメージに含まれる不必要なソフトウェアやライブラリが減るため、それらを経由した攻撃のリスクが低下します。
また、ベースイメージが小さいということは、それに含まれるソフトウェアの数量も少なくなるため、存在する可能性のある脆弱性の数も減少します。
さらに、イメージが小さいと、適用する必要のあるセキュリティアップデートが少なくなるため、コンテナの維持管理も容易になります。こうした特性は、オンラインで公開されるアプリケーションのセキュリティを確保する上で非常に重要で、DevOpsチームが求めるインターネットなどの外部との接続に必要なセキュリティを提供します。
不正解についての説明：
選択肢：Cloud Buildを使ってコンテナイメージを構築します
この選択肢が正しくない理由は以下の通りです。
Cloud Buildを用いてコンテナイメージを構築することは、コンテナの攻撃対象範囲を最小限に抑える目的には寄与しません。それは単にイメージの構築手段であり、セキュリティ向上は主目的ではありません。
一方、小さなベースイメージを用いることは不要なパッケージを排除し、コンテナのサーフェスエリアを小さくすることに直接的に寄与します。
選択肢：Artifact Registryから使用されていないバージョンを削除します
この選択肢が正しくない理由は以下の通りです。
Artifact Registryから使用されていないバージョンを削除することは、ストレージ管理やバージョン管理を助けますが、コンテナの攻撃対象範囲を最小限に抑える目的には直接貢献しません。
一方、小さなベースイメージを用いると不要なソフトウェアやライブラリが排除され、攻撃対象範囲が縮小されます。
選択肢：継続的デリバリーツールを使ってアプリケーションをデプロイします
この選択肢が正しくない理由は以下の通りです。
継続的デリバリーツールを使うことは開発プロセスを高速化・自動化する利点がありますが、コンテナの攻撃対象範囲を最小限にするという目的には直接関連がありません。
一方、小さなベースイメージを使うことは不必要な機能やパッケージを減らし、攻撃対象を最小限に抑える効果があるため正解です。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/concepts/container-images
https://cloud.google.com/solutions/best-practices-for-building-containers
https://cloud.google.com/architecture/best-practices-for-operating-containers
</div></details>

### Q.  問題32: 未回答
あなたの組織は、仮想マシン（VM）をGoogle Cloudに移行しようとしています。プロジェクト全体で使用されるオペレーティングシステムイメージが信頼でき、セキュリティ要件を満たしていることを確認する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudに仮想マシン（VM）を移行しようと考えている組織がOSイメージに対する信頼性とセキュリティ要件をどのように確保すべきか尋ねています。各選択肢が推奨されるシチュエーションと、それらが要件にどのように対応するかを熟考することが重要です。また、留意点として、Google Cloudの具体的な機能とそれらが提供するセキュリティ対策を理解していることが求められます。
基本的な概念や原則：
組織ポリシー：Google Cloud上のリソースに対する制約を定義し、組織全体で一貫したルールを実施するための方法です。特定の種類のリソースがどの場所で作成できるか、特定のAPIがどのプロジェクトで利用できるかなどを制御します。
信頼されたイメージプロジェクト：信頼性とセキュリティが確保されたオペレーティングシステムイメージを提供するプロジェクトです。
ブートディスク：仮想マシン（VM）がブート（起動）する際に使用するディスクです。信頼性の高いイメージから作成されることで、特定のセキュリティ基準を満たすことができます。
Shielded VM：Google Cloudにおける仮想マシン（VM）のセキュリティ強化版です。信頼性の証明、安全なブート、BIOSの整合性を保証します。
Cloud Functions：Google Cloud上のサーバーレスコンピューティングサービスです。特定のイベントに応じて自動的に実行される関数を作成し、管理します。
一般的な脆弱性と暴露（CVE）：公開されているコンピューターセキュリティ脆弱性のデータベースです。セキュリティ監査、脆弱性管理、プロダクトのセキュリティ状態確認などに利用されます。
正解についての説明：
（選択肢）
・ブートディスクは、信頼されたイメージプロジェクトから派生したイメージからのみ作成できることを強制する組織ポリシーを実装します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、組織ポリシーの設定を通じて、特定の制約を適用することができます。ブートディスクの作成に関する制約は、"ブートディスクは信頼されたイメージプロジェクトから派生したイメージからのみ作成できることを強制する"という要件に対する解決策として適用可能です。これにより、組織全体で使用されるオペレーティングシステムイメージの信頼性とセキュリティ要件の確保が可能となります。組織ポリシーを適用することで、指定された信頼されたイメージプロジェクトから派生したイメージを使用しないVMの作成を遮断します。これにより、すべてのVMが定められたポリシーに一致した安全な状態で起動し、セキュリティ要件が維持されます。
不正解についての説明：
選択肢：すべてのプロジェクトでShielded VMサービスを有効にする組織ポリシー制約を実装し、信頼済みイメージリポジトリの使用を強制します
この選択肢が正しくない理由は以下の通りです。
Shielded VMサービスはVMのインテグリティを保証するロールを果たしますが、特定の信頼性が証明されたイメージリポジトリの使用を強制する機能はありません。それに対して正解の選択肢は特定のイメージプロジェクトからのみブートディスクを作成することを強制することで、信頼度とセキュリティ要件の確保を可能にします。
選択肢：信頼できるイメージリポジトリから新しい仮想マシンが作成されたときに自動的にトリガーされるCloud Functionsを実装します。イメージが非推奨でないことを確認します
この選択肢が正しくない理由は以下の通りです。
Cloud Functionsを用いてイメージのチェックを行う方法は、VMが既に作成されてからのチェックになるため、非推奨のイメージを使って作成が行われてしまった場合に対応が遅れ、セキュリティ要件を満たせない恐れがあります。
一方、組織ポリシーを用いて信頼されたイメージからのみブートディスクの作成を要求する方法は、事前に制限を行うことで、非推奨のイメージが使用されるリスクを事前に防ぎます。
選択肢：信頼できるイメージリポジトリに一般的な脆弱性と暴露（CVE）が存在しないことを検証するセキュリティスキャナを自動化します
この選択肢が正しくない理由は以下の通りです。
イメージリポジトリの脆弱性をスキャンすることは重要なセキュリティ慣行ですが、それだけでは問題の要件を満たしません。なぜならそれがプロジェクト全体で使用されるOSイメージが信頼できること、セキュリティ要件を満たすことを確認するという要件を直接的に担保するものではないからです。そのため、正解の選択肢のように組織ポリシーを実装して信頼されたイメージからしかブートディスクが作成できないことを強制する方が適切です。
参考リンク：
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/security-command-center/docs/concepts-security-sources-for-findings
</div></details>

### Q.  問題33: 未回答
Google Cloudを利用している組織で、ユーザが自分のバケット内のオブジェクトを外部に公開できないようにするセキュリティポリシーを適用する必要があります。現在、この組織にはバケットがありません。
この目標を最小の運用オーバーヘッドで達成するために、どのソリューションを実装すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudを利用する組織のセキュリティ要件を理解することが重要です。規定では、ユーザーは自分のバケット内のオブジェクトを外部に公開することができません。さらに、運用オーバーヘッドを最小限に抑える手段を求められています。したがって、選択肢を評価する際には、これらの要件を満たす最も効率的で直接的なソリューションを選択する必要があります。
基本的な概念や原則：
constraints/storage.publicAccessPrevention：Google Cloudの制約で、この設定を有効にするとバケットレベルで公開設定を無効化します。これにより、組織内の任意のユーザがバケット内のオブジェクトを公開することを制限します。
Cloud Functions：サーバーレス環境でコードを実行するGoogle Cloudのサービスです。イベント駆動型のアクションを実行できます。
VPC Service Controls：Google Cloudのサービスで、指定したサービスのデータの流れを制御します。これにより、データがプロジェクトまたは組織の信頼領域を離れないように制限することが可能です。
constraints/storage.uniformBucketLevelAccess：Google Cloudの制約で、この設定を有効にするとバケット内すべてのオブジェクトに対するACL（Access Control Lists）によるアクセス設定を無効化します。しかし、バケット全体の公開設定自体は無効化できません。
サービスアカウント：Google Cloudの認証・認可モデルの一部で、特定のサービスやアプリケーションがGoogle Cloudのリソースにアクセスするために使用されます。
正解についての説明：
（選択肢）
・組織レベルでconstraints/storage.publicAccessPrevention制約を有効にします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの組織ポリシーサービスはリソース階層全体にポリシーを適用する方法を提供します。その一つがpublicAccessPreventionという制約で、これはCloud Storageバケットでの公開アクセスを防止するための制限となります。
この制約を組織レベルで有効にすることで、組織内の全ての新規及び既存のバケットに対して一律に適用されます。これにより、個別にバケットの設定を変更せずとも一括で公開アクセスを制御することができます。これは運用オーバーヘッドを大幅に減らすことにつながります。
そのため、組織全体でオブジェクトの外部への公開を防ぐためには、組織レベルでconstraints/storage.publicAccessPrevention制約を有効にするのが最も効率的な解決策となります。
不正解についての説明：
選択肢：公開バケットを見つけて非公開にするCloud Functionを実行するcronジョブを毎時作成します
この選択肢が正しくない理由は以下の通りです。
Cronジョブを使って毎時Cloud Functionを実行する方法は、運用オーバーヘッドが増えるし、設定の遅延により短時間ではあるがデータ漏洩のリスクがあります。しかし、constraints/storage.publicAccessPrevention制約を有効化すると、ユーザが公開設定を試みても予防でき、運用オーバーヘッドも最小限にすることができます。
選択肢：組織レベルでのconstraints/storage.uniformBucketLevelAccess制約を有効にします
この選択肢が正しくない理由は以下の通りです。
constraints/storage.uniformBucketLevelAccess制約は、すべてのバケットに対して均一なバケットレベルのアクセスを強制するもので、オブジェクトの公開自体を制限するものではありません。対してconstraints/storage.publicAccessPrevention制約は、オブジェクトが外部に公開されるのを防ぐ制約で、今回の目標に適しています。
選択肢：バケットを含むプロジェクトのstorage.googleapis.comサービスを保護するVPC Service Controlsの境界を作成します。バケットを含む新しいプロジェクトを境界へ追加します
この選択肢が正しくない理由は以下の通りです。
VPC Service ControlsはAPIとサービスの保護を実現するものですが、ユーザーがバケット内のオブジェクトを外部に公開する行為自体を防ぐには不適切です。
一方、constraints/storage.publicAccessPrevention制約を有効にすることで、全てのバケットに対し外部公開を禁止するセキュリティポリシーを適用できます。
参考リンク：
https://cloud.google.com/storage/docs/public-access-prevention
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-public-access
https://cloud.google.com/storage/docs/uniform-bucket-level-access
</div></details>

### Q.  問題34: 未回答
ある顧客が、インターネットへのアクセスを制限する必要がある分析ワークロードをCompute Engine上で実行しています。
あなたのチームは、インターネットへのすべてのトラフィックを拒否（優先度1000）するためのアウトバウンドファイアウォールルールを作成しました。
Compute Engineインスタンスは、セキュリティアップデートを取得するためにパブリックリポジトリにアクセスする必要があります。
あなたのチームは何をすべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、インターネットへのアクセス制限が必要なCompute Engineインスタンスに対して、一部のセキュリティアップデート用のリポジトリだけアクセスを許可する必要があります。すでに優先度1000でインターネットへの全トラフィックを拒否するルールが存在するため、このルールより優先度が高くなければならないことに注意が必要です。優先度は数字が低いほど高くなります。これを踏まえて、適切な優先度を持つファイアウォールルールの作成方法を問題から導く必要があります。
基本的な概念や原則：
ファイアウォールルール：Google Cloudのネットワークセキュリティの一部で、特定の種類のトラフィック（プロトコル、ポート、ソースIP範囲、宛先IP範囲）を許可または拒否するための規則です。
優先度：Google Cloudファイアウォールルールの属性で、数値が小さいほど優先度が高いルールとなります。競合するルールがある場合、優先度が高い方が適用されます。
リポジトリへのアクセス：Google Cloud Compute Engineインスタンスがセキュリティアップデートを取得するために、インターネット上の公開リポジトリに接続することが必要です。
CIDRレンジ：IPアドレスの範囲を指定する方法の一つで、ネットワークやサブネットのサイズを効果的に指定できます。ファイアウォールルールでアクセスを許可または拒否するIPアドレス範囲を指定するために使用します。
ネットワークのアウトバウンド：システムから外部へのネットワークトラフィックを指します。インバウンドとは逆の方向のトラフィックです。
セキュリティアップデート：システムの脆弱性を修正するために配布されるアップデートで、定期的に適用することが推奨されます。
正解についての説明：
（選択肢）
・優先度1000未満のリポジトリのCIDRレンジへのトラフィックを許可するアウトバウンドファイアウォールルールを作成します
この選択肢が正解の理由は以下の通りです。
Google Cloudのファイアウォールルールは、優先度に基づいて評価され、数値が小さいほど優先度が高くなります。つまり、複数のルールがある場合、最も低い優先度値を持つルールが適用されます。すでに優先度1000でインターネットトラフィックを拒否するルールが作成されていますが、セキュリティアップデートのための特定のパブリックリポジトリへのアクセスが必要であるため、これらのリポジトリーへのアクセスを許可する新しいルールを作成する必要があります。この新しいルールの優先度は1000未満であるべきです。これにより、パブリックリポジトリへのトラフィックは新しく作成したルールによって許可され、それ以外のインターネットトラフィックは既存の優先度1000のルールによって拒否されます。これにより、必要な通信のみを確保しつつ全体のセキュリティを維持することが可能となります。
不正解についての説明：
選択肢：優先度1000以上のリポジトリのCIDRレンジへのトラフィックを許可するアウトバウンドファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのファイアウォールルールでは、優先度が低い方が先に適用されます。よって、優先度1000以上でアウトバウンドファイアウォールルールを作成しても、すでに優先度1000で全てのトラフィックを拒否するルールが存在するために無視されてしまいます。正解は優先度1000未満で設定し、適用されるようにすることです。
選択肢：優先度1000以上のリポジトリのホスト名へのトラフィックを許可するアウトバウンドファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのファイアウォールルールは数値の小さい優先度が高くなります。
従って、優先度1000以上のルールを作成しても、すでに定義されている優先度1000の全トラフィック拒否ルールより優先されません。これによりインスタンスはパブリックリポジトリにアクセスできず、セキュリティアップデートを取得することができません。
選択肢：優先度1000未満のリポジトリのホスト名へのトラフィックを許可するアウトバウンドファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのファイアウォールルールはホスト名に基づいてトラフフィックを許可または拒否することはできません。送信先や送信元のIPAddressまたはCIDRレンジに基づいて制御します。そのため、リポジトリホスト名へのトラフィックを許可するルールは作成できません。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/compute/docs/instances/connecting-advanced#firewallrules
https://cloud.google.com/compute/docs/instances/managing-instance-access#configure_firewall_rules
</div></details>

### Q.  問題35: 未回答
標準的なネットワーク階層を使用しながら、デフォルトでクライアントIPを維持するために、どのタイプのロードバランサーを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ロードバランサーの種類とそれぞれの機能に関する理解が求められています。特に、デフォルトでクライアントIPを維持するロードバランサーのタイプを選ぶことが問われています。問題文を理解するためには、各ロードバランサーがどのように動作し、それぞれがどのようなネットワーク階層で動くのか、またどのロードバランサーがクライアントIPを維持可能なのか、を把握する必要があります。
基本的な概念や原則：
TCP/UDPネットワークロードバランサー：パケットレベルのロードバランサーであり、リッチなルーティング機能と高いパフォーマンスを提供します。デフォルトでクライアントIPを維持します。
SSLプロキシロードバランサー：SSL（HTTPS）トラフィックのロードバランサーで、SSLオフロード能力を提供します。クライアントIPを維持しないことがあります。
TCPプロキシロードバランサー：TCP（またはSSL）トラフィックのロードバランサーで、迅速なオープンコネクションを提供します。こちらもクライアントIPを維持しないことがあります。
内部TCP/UDPロードバランサー：VPCネットワーク内部にあるインスタンス間でトラフィックをバランスします。クライアントIPの維持が特例となります。
正解についての説明：
（選択肢）
・TCP/UDPネットワーク
この選択肢が正解の理由は以下の通りです。
まず、TCP/UDPネットワークロードバランサーは、トラフィックをバックエンドサーバーに分散するために、トランスポート層（L4）レベルでロードバランスを行います。このレベルで動作するため、クライアントのIPアドレスが変更されずに保持されます。これは特に、クライアントのIPアドレスを維持する必要があるケース、たとえば特定のIPからのリクエストを特定のサーバにルーティングしたいといった場合に有用です。
また、TCP/UDPネットワークロードバランサーは、デフォルトで典型的なネットワーク階層（つまり、マルチレイヤーネットワークトポロジ）で動作します。これにより、ネットワーク設計と管理が容易になり、スムーズな運用が可能となります。
したがって、標準的なネットワーク階層を維持しながらクライアントIPを保持するためには、TCP/UDPネットワークロードバランサーを使用すべきです。
不正解についての説明：
選択肢：SSLプロキシ
この選択肢が正しくない理由は以下の通りです。
SSLプロキシロードバランサーは、クライアントIPアドレスを元の形で維持することができません。クライアントのIPアドレスを保持しながら標準的なネットワーク階層を使用するために、TCP/UDPネットワークロードバランサーが適切な選択肢となります。
選択肢：TCPプロキシ
この選択肢が正しくない理由は以下の通りです。
TCPプロキシロードバランサーはクライアントのIPを維持しません。クライアントからの接続を受け取り、バックエンドインスタンスに転送するときに新しいTCPセッションを開始します。
これに対して、TCP/UDPネットワークロードバランサーはクライアントのIPを維持します。
選択肢：内部TCP/UDP
この選択肢が正しくない理由は以下の通りです。
内部TCP/UDPロードバランサーは特定の状況下でクライアントIPを維持しますが、一般的にはプロキシモードで動作し、クライアントIPを維持しません。しかし正解のTCP/UDPネットワークロードバランサーはパケットに対して直接操作を行うため、デフォルトでクライアントIPを維持します。
参考リンク：
https://cloud.google.com/load-balancing/docs/network
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
</div></details>

### Q.  問題36: 未回答
あなたの組織は最近、Google Kubernetes Engineに新しいアプリケーションをデプロイしました。アプリケーションを保護するためにソリューションをデプロイする必要があります。ソリューションには以下の要件があります：
- スキャンを少なくとも週に1回実行すること
- クロスサイトスクリプティングの脆弱性を検出できること
- Googleアカウントを使用して認証できること
この要件を満たすために、どのソリューションを使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Kubernetes Engine上のアプリケーションを保護するためのソリューションの選択について考える必要があります。問題文の要件明確に把握し、それを満たすソリューションを選び出すことが求められます。定期的なスキャン、クロスサイトスクリプティングの脆弱性検出、Googleアカウントの使用という3つの要件を満たすソリューションを探し、選択することが重要です。選択肢の中から、具体的な要件を満たすものを探し出す際には、各ソリューションの機能や目的を正確に理解することが必要です。
基本的な概念や原則：
Web Security Scanner：Google Cloudの管理型脆弱性スキャンツールです。クロスサイトスクリプティングや他の一般的な脆弱性を検出し、ユーザーに対して警告を発することができます。
Googleアカウント認証：Googleのアカウントを用いたユーザーアクセスの認証メソッドです。これにより、Google Cloudのリソースへのアクセスが保護されます。
Google Cloud Armor：Google Cloud上で動作するビジネスクリティカルなアプリケーションを保護するためのスケーラブルな、マネージド型の分散デノサービスです。しかし、脆弱性スキャンは主な機能ではありません。
Security Health Analytics：Google Cloudのセキュリティ状況を監視し、分析するためのサービスです。一般的なベストプラクティスに基づく脆弱性検査を行いますが、クロスサイトスクリプティングの脆弱性を検出する機能は提供していません。
Container Threat Detection：Google Cloud上のコンテナを対象としたセキュリティ脅威を検出するためのサービスです。サービスは、不正な操作や既知の脅威についてリアルタイムで警告を発しますが、特定の脆弱性スキャン能力はありません。
正解についての説明：
（選択肢）
・Web Security Scanner
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのWeb Security Scannerは、アプリケーションで標準的な脆弱性、例えばクロスサイトスクリプティング（XSS）等を自動的に見つけ出すために設計されています。
したがって、これにより、クロスサイトスクリプティングの脆弱性を検出する要件を満たすことができます。
次に、Web Security Scannerは定期的なスキャンをスケジュールすることが可能です。これにより、スキャンを少なくとも週に1回実行するという要件に対応することができます。
最後に、Web Security ScannerはGoogle Cloud Consoleを通じて管理し、そこではGoogleアカウントが使用されます。これにより、Googleアカウントを使用して認証するという要件も満たします。
したがって、これらの要件全てを満たすために、Web Security Scannerが最適なソリューションとなります。
不正解についての説明：
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは主にDDoS攻撃防止やIPブロックなどのセキュリティポリシーやルールを設定し、トラフィックを制御することが主なロールで、特定の脆弱性スキャンなどは行いません。
それに対して、Web Security Scannerは週に一度のスキャンやクロスサイトスクリプティングの脆弱性を検出する機能を提供しているため、要件に適しています。
選択肢：Security Health Analytics
この選択肢が正しくない理由は以下の通りです。
Security Health Analyticsは、Google Cloudリソースの潜在的なセキュリティリスクを識別し対策するためのツールですが、特定の脆弱性、例えばクロスサイトスクリプティングを対象としたスキャンを提供はしていません。
一方、Web Security ScannerはWebアプリケーションの脆弱性を対象に定期的にスキャンする機能を提供しており、要件を満たします。
選択肢：Container Threat Detection
この選択肢が正しくない理由は以下の通りです。
Container Threat Detectionはコンテナ指向の異常や脅威を検出するものであり、特に脆弱性探知やクロスサイトスクリプティングの検出に特化していません。
一方で、Web Security Scannerはウェブアプリケーションの脆弱性、特にクロスサイトスクリプティングの検出に特化しています。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/armor/docs/security-policy-overview
https://cloud.google.com/kubernetes-engine/docs/concepts/security-overview
</div></details>

### Q.  問題37: 未回答
あなたは、アプリケーションログをCloud Storageにエクスポートしています。ログシンクが統一されたバケットレベルのアクセスポリシーをサポートしていないというエラーメッセージが表示されました。
このエラーはどのように解決すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Storageバケットに対するアクセス制御に焦点を当てています。具体的には、アプリケーションログのエクスポート中に見つかった特定のエラーに対処する方法が問われています。問題を解決するために、統一されたバケットレベルのアクセスポリシーという概念と、それがログシンクとどのように関連しているかをよく理解することが重要です。選択肢を評価するときには、に直接的な解決手段になりそうな選択肢に注目し、他の選択肢がこの具体的なエラーの解決に役立つかどうかを評価することが求められます。
基本的な概念や原則：
バケットレベルのアクセスポリシー：Google Cloud Storageバケットのアクセス制御を定義するためのポリシーです。特定のユーザーやサービスアカウントがバケット内のリソースに対して何をできるかを指定します。
ログシンク：Google Cloudのロギングシステムにおいて、ログエントリをエクスポートする先を指定する機能です。複数のデスティネーション（Cloud Storageバケット、BigQueryデータセット、Pub/Subトピックなど）を定義することができます。
統一モデル：Google Cloud Storageにおけるバケットとオブジェクトのアクセス制御について、IAMポリシーを使って管理する方法です。これは、"全バケットでIAMのみを使用する"というオプションで、このモデルを使用すると、IAMによってバケットに対するすべてのアクセスを制御することができます。
ACL（Access Control Lists）モデル：Google Cloud Storageで使用される古いアクセス制御モデルで、バケットやオブジェクト単位でアクセス権を指定します。このモデルでは、ひとつひとつのオブジェクトに対してアクセス権を個別に設定することが可能です。
正解についての説明：
（選択肢）
・バケットのアクセス制御モデルを変更します
この選択肢が正解の理由は以下の通りです。
Google Cloud Storageには、バケットに対するアクセス制御を管理する2つのモデルが存在します。それらはACL（Access Control Lists）と統一バケットレベルのアクセスポリシーです。通常、ログシンクなどのサービスは特定のバケットにアクセスし、データをエクスポートするためにACLを利用します。しかし、統一バケットレベルのアクセスポリシーが有効化されていると、ACLは無効となりエラーメッセージが表示されます。
したがって、問題を解決するためにはバケットのアクセス制御モデルを元に戻す、つまり統一バケットレベルのアクセスポリシーからACLに切り替える必要があります。これによりログシンクは再びバケットにアクセスでき、エラーが解消されます。
不正解についての説明：
選択肢：シンクを正しいバケットの宛先で更新します
この選択肢が正しくない理由は以下の通りです。
問題は、シンクがアクセスポリシーをサポートしていないことであり、シンクの宛先を正しいバケットに更新することで解決するものではありません。正解はバケットのアクセス制御モデルを変更することで、これはバケットレベルのアクセスポリシーに適応させる意味があります。
選択肢：roles/logging.logWriterアイデンティティおよびIAMロールを、ログシンクのアイデンティティのバケットに追加します
この選択肢が正しくない理由は以下の通りです。
特定のアイデンティティにroles/logging.logWriterを追加すると、そのアイデンティティはロギングデータを任意の場所に書き込むことができますが、今回のエラーはバケットレベルのアクセスポリシーがサポートされていないため発生しています。
したがって、アクセス制御モデルを変更することで問題を解決する必要があります。
選択肢：roles/logging.bucketWriterアイデンティティおよびIAMロールを、ログシンクのアイデンティティのバケットに追加します
この選択肢が正しくない理由は以下の通りです。
エラーメッセージが指しているのは"バケットレベルのアクセスポリシー"の問題であり、単にIAMロールを追加するだけでは解決しません。バケットのアクセス制御モデルを変更してバケットレベルのアクセスポリシーを変更する必要があります。
参考リンク：
https://cloud.google.com/storage/docs/uniform-bucket-level-access
https://cloud.google.com/logging/docs/export/configure_export_v2
https://cloud.google.com/storage/docs/access-control/using-iam-permissions
</div></details>

### Q.  問題38: 未回答
あなたのチームは、指定されたCompute Engine仮想マシンインスタンスから指定されたCloud Storageバケットへのデータ転送を認証するためにサービスアカウントを使用しています。エンジニアが誤ってサービスアカウントを削除してしまい、アプリケーションの機能が壊れてしまいました。セキュリティを損なうことなく、アプリケーションをできるだけ早く復旧させたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、エンジニアが誤ってサービスアカウントを削除し、その結果アプリケーションの機能が破壊されてしまったシチュエーションを前提としています。復旧のための選択肢を見るときは、セキュリティを損なわない方法でアプリケーションをできるだけ早く復旧させることを目指しています。選択肢を評価する際には、復旧速度とセキュリティのバランスを適切に維持する方法を探すことが重要です。
基本的な概念や原則：
サービスアカウント：特定のアプリケーションやインスタンスに連携し、Google Cloud APIを使用するためのIDです。個々のサービスがどのリソースにアクセスし、どの種類のアクションを実行できるかを制御するために使用します。
undeleteコマンド：削除したサービスアカウントを復元するためのコマンドです。サービスアカウントが暗号化キーを使って暗号化されていたデータにアクセスするための許可を持っていた場合、復元は特に重要です。
セキュリティ：Google Cloudでは、認証、認可、監査に基づくセキュリティモデルが採用されています。適切なセキュリティ対策が取られていないと、データの漏洩や不正アクセスが発生する可能性があります。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。Compute Engineインスタンスは、サービスアカウントを利用してGoogle CloudのAPIへアクセスできます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データはバケットと呼ばれるコンテナに格納され、各ファイルはそれぞれ一意のURLを持ちます。バケットへのアクセス制御はIAMポリシーやバケットポリシーで管理できます。
正解についての説明：
（選択肢）
・削除されたサービスアカウントを復元するために、undeleteコマンドを使用します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、誤って削除されたサービスアカウントを復元する手段としてundeleteコマンドを提供しています。サービスアカウントが削除されても、その削除から30日間はこのコマンドを用いて元に戻すことが可能です。これによって、迅速にアプリケーションの機能を復旧させることができます。
また、新たにサービスアカウントを作成し直す必要がないため、設定ミスによる新たなセキュリティリスクを生じさせることなく、アプリケーションの復旧が可能となります。これらのメリットから、問題の状況に対して"削除されたサービスアカウントを復元するために、undeleteコマンドを使用する"が最適な対応となります。
不正解についての説明：
選択肢：Cloud Storageバケットの認証を一時的に無効にします
この選択肢が正しくない理由は以下の通りです。
Cloud Storageバケットの認証を一時的に無効にすると、データのセキュリティが損なわれる可能性があります。
代わりに、削除されたサービスアカウントを復元するためのundeleteコマンドを使用することで、セキュリティを維持しつつアプリケーションの機能を復旧することが可能です。
選択肢：削除したサービスアカウントと同じ名前で新しいサービスアカウントを作成します
この選択肢が正しくない理由は以下の通りです。
同じ名前の新しいサービスアカウントを作成したとしても、以前のサービスアカウントとは異なる新しいID及びキーペアが生成され、以前と同じ機能は復元できません。正解は削除されたサービスアカウントの復元で、これなら以前と同じアクセス権が保証されます。
選択肢：別の既存のサービスアカウントの権限を更新し、その資格情報をアプリケーションに提供します
この選択肢が正しくない理由は以下の通りです。
別の既存のサービスアカウントの権限を更新すると、そのサービスアカウントが他の用途で使用されていた場合、予期しない副作用を引き起こす可能性があります。
一方で、削除されたサービスアカウントを復元するundeleteコマンドを使用すると、瞬時に以前と同じ設定でアプリケーションを復旧できます。
参考リンク：
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/service-accounts#undeleting
</div></details>

### Q.  問題39: 未回答
Compute Engineでホストされている公開アプリケーションで、ユーザーから障害が報告されています。これは、ファイアウォールルールの最近の変更が原因だと思われます。今後は、ファイアウォールルールが正しく機能しているかどうかをテストする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute Engineで動作する公開アプリケーションに対するユーザーからの障害報告と、それがファイアウォールルールの変更によるものという事情を考慮する必要があります。また、この問題からはファイアウォールルールが正しく機能しているかどうか証明するための手段を求めるものと理解できます。選択肢から選ぶ際は、Google Cloud特有の監視ツールやログ分析方法が適用可能かどうか、そしてそれが対象となるファイアウォールルールの調査に有効であるかどうかを重視して検討するべきです。
基本的な概念や原則：
ファイアウォールルールログ：Compute Engineのインスタンスに適用されたファイアウォールルールを記録するロギング機能です。ルールが正しく機能しているかの確認や、問題解析に活用できます。
ログエクスプローラ：Google Cloud上の様々なサービスからのログデータを検索、表示、分析するためのツールです。ログの視覚化やフィルタリングが可能です。
踏み台ホスト：セキュリティの観点から、直接公開ネットワークからアクセスできないホストへのアクセスを仲介するサーバーのことです。
ネットワークトラフィックアナライザー：ネットワークトラフィックの監視や分析を行うためのツールです。リクエストの送信元・送信先、ポート番号など詳細な情報を取得できます。
VPCフローログ：VPCネットワークのネットワークフロー情報をキャプチャし、ログを生成する機能です。フローログはネットワークパフォーマンスの監視やセキュリティ分析に使用されます。
正解についての説明：
（選択肢）
・変更された最新のルールのファイアウォールルールログを有効にします。ログエクスプローラーを使用して、ルールが正しく機能しているかどうかを分析します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudのファイアウォールルールには、それぞれを追跡し分析するためのロギング機能が含まれています。
したがって、ファイアウォールルールを修正した後に、それらのルールのログを有効にすることで、そのルールが期待通りに動作するかどうかを直接確認することができます。この方法は、障害が発生した場合に問題の特定と解決に効果的です。
次に、ログエクスプローラーを使用すると、ログ情報をフィルタリング、ソーティング、分析することが可能です。これはGoogle Cloudの中心的なログ分析ツールで、ログデータの視覚化と理解を助けます。これにより、ファイアウォールルールが正しく動作しているかどうかを評価し、問題があれば修正するための必要な情報を得ることができます。
したがって、正しきルールの動作をテストするための最適な方法は、ファイアウォールルールのログを有効にし、ログエクスプローラーでその動作を分析することです。
不正解についての説明：
選択肢：VPC内の踏み台ホストに接続します。ネットワークトラフィックアナライザーを使って、どの時点でリクエストがブロックされているかを調べてください
この選択肢が正しくない理由は以下の通りです。
VPC内の踏み台ホストに接続しネットワークトラフィックアナライザーを使用する方法は可能ですが、必要な分析を行うためには時間と専門的な技術が必要となります。
それに対して、ファイアウォールルールログを有効にしログエクスプローラーを使用することで、より直接的で効率的にルールの動作を分析することが可能です。
選択肢：本番前環境では、すべてのファイアウォールルールを個別に無効にして、どれがユーザートラフィックをブロックしているかを判断します
この選択肢が正しくない理由は以下の通りです。
本番前の環境で全てのファイアウォールルールを無効にすると、保護するべきシステムが露出する危険性があるため安全性に問題があります。対してファイアウォールルールログを有効にすることでルールの影響を確認でき、安全に問題を診断できます。
選択肢：VPCでVPCフローログを有効にします。ログエクスプローラーを使用して、ルールが正しく機能しているかどうかを分析します
この選択肢が正しくない理由は以下の通りです。
VPCフローログは、VPCネットワーク内でのIPトラフィックをキャプチャし、ネットワークのパフォーマンス、監視、セキュリティ、コンプライアンスの分析などのために利用する機能ですが、特定のファイアウォールルールが正しく機能しているかどうかをテストするためには不十分です。
一方、ファイアウォールルールログを有効にすると、特定のファイアウォールルールによって許可または拒否されたトラフィックを確認できるため、ルールが正しく機能しているかどうかを詳細に分析することができます。
参考リンク：
https://cloud.google.com/network-connectivity/docs/firewall-insights/using-fw-insights
https://cloud.google.com/network-connectivity/docs/firewall-logging
https://cloud.google.com/compute/docs/instances/connecting-advanced#third_party_tools
</div></details>

### Q.  問題40: 未回答
あなたの会社には300人のエンジニアがいます。同社は、開発環境プロジェクトと本番環境プロジェクトで、異なるレベルのアクセス権を付与し、ユーザー間のIAM権限を効率的に管理したいと考えています。
これらの要件を満たすために、取るべき2つの手順はどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のエンジニアに対して異なるプロジェクトで異なるアクセス権を効率的に管理する方法を問われています。根本的な課題は、300人のエンジニア間でIAM権限を容易に管理することであり、個々のユーザーへの権限を直接割り当てるのではなく、一括で管理できるソリューションを考えることが求められています。さらに、開発環境と本番環境で異なるレベルのアクセス権を制御する必要があるため、これらの環境を区別する方法を示す解決策も選択肢として検討するべきです。
基本的な概念や原則：
フォルダ：Google Cloud Resource Managerで提供される、プロジェクトとリソースの集合を表します。IAMポリシーを一元管理するための階層構造を提供します。
Googleグループ：特定のユーザーグループに権限を一括付与したり、コミュニケーションを行うためのGoogle Workspaceの機能です。
IAM（Identity and Access Management）：Google Cloudのセキュリティモデルの一部であり、認証（ユーザーが誰であるか確認）と認可（何を行うことが許可されているか）の制御を提供します。
VPCネットワーク：仮想プライベートクラウド（VPC）ネットワークは、Google Cloud内でプライベートネットワークを提供するものであり、プロジェクトのリソース間の通信を制御します。これ自体がIAM権限の管理に直接寄与するものではありません。
組織ポリシー：Google Cloudリソースに対する特定の規定を定義します。ポリシー制約は、特定のリソースで何ができるかを規定するもので、特定の環境全体のIAM権限を一元管理するものではありません。
プロジェクト：Google Cloudでは、リソースを組織化し管理するための基本的な単位です。しかし、各エンジニアリングユーザーにIAM権限を各プロジェクトごとに個別に付与するのは、管理コストが高くなる可能性があります。
正解についての説明：
（選択肢）
・開発環境と本番環境それぞれにフォルダを作成します
・エンジニアリングチーム用のGoogleグループを作成し、フォルダレベルで権限を割り当てます
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudでは、リソース階層構造の一部としてフォルダを使用することができます。フォルダは、より広範な制御を可能にするために、プロジェクトを主題別または環境別（開発と本番など）に編成します。
したがって、開発環境と本番環境それぞれにフォルダを作成することで、これらの環境のリソースに対するアクセス制御を短縮および簡素化できます。
また、Googleグループを使用すると、一連のユーザーに対する一貫したポリシー管理が可能になります。つまり、エンジニアリングチーム全体を単一のグループとして管理し、必要に応じてIAM権限を割り当てることで、一貫性のあるアクセス制御を維持できると同時に、権限管理の効率性も向上します。これらの概念を組み合わせることで、エンジニアリングチームのメンバーが開発環境と本番環境のプロジェクトに対して適切なアクセス権を持つことが可能になります。
不正解についての説明：
選択肢：環境ごとに複数のVPCネットワークを持つプロジェクトを作成します
この選択肢が正しくない理由は以下の通りです。
本問題の要求はIAM権限の効率的な管理であり、それへの対応策として環境ごとにVPCネットワークを複数持つプロジェクトを作成する措置は直接関連しません。
一方、フォルダを作成し、グループに権限を割り当てることで、権限管理を効率化することが可能となります。
選択肢：フォルダ環境ごとに組織ポリシー制約を作成します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約を作ることは、設問にある開発環境と本番環境で異なるレベルのアクセス権を付与し、ユーザー間のIAM権限を効率的に管理する目的を直接的には達成しません。この目的のためには、フォルダレベルで適切な権限を割り当てることが重要であり、これは組織ポリシー制約の作成ではなく、利用者のグルーピングと適切な権限の割り当てといった操作が必須となります。
選択肢：環境ごとにプロジェクトを作成し、各エンジニアリングユーザーにIAM権限を付与します
この選択肢が正しくない理由は以下の通りです。
環境ごとにプロジェクトを作成し、各エンジニアリングユーザーにIAM権限を付与するアプローチは、管理作業が大変になる上に効率的な管理手法とは言えません。一方で正解の選択肢のようにフォルダとGoogleグループを利用することで、大量のユーザーを効率的に管理できます。
参考リンク：
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://cloud.google.com/iam/docs/groups-best-practices
https://cloud.google.com/resource-manager/docs/access-control-proj
</div></details>

### Q.  問題41: 未回答
ある組織がアプリケーションホスティングサービスにGoogle Cloudを採用し、Cloud Identityアカウントのパスワード要件を設定するためのガイダンスが必要です。
Identityアカウントのパスワード要件を設定するためのガイダンスが必要です。この組織には、従業員のパスワードは最小文字数でなければならないというパスワードポリシー要件があります。
この組織が新しい要件を通知するために使用できるCloud Identityパスワードガイドラインはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudのIdentityアカウントのパスワード設定に関する規定を理解する必要があります。組織はすでに従業員のパスワードについて最小文字数の要件を設定していますが、その要件を満たすことが可能かどうかは問題文からは明らかではありません。したがって、解答する際にはCloud Identityが設定可能なパスワードの最小文字数の制限を踏まえる必要があります。
基本的な概念や原則：
Cloud Identity：Google Cloudの統合アイデンティティ管理システムです。ユーザーの認証とアクセス管理を一元化し、セキュリティとコンプライアンスの維持を支援します。
パスワードポリシー：安全なパスワード作成と管理をガイドするルールや要件のセットです。これは、パスワードの最小または最大長さ、特殊文字や数字の使用など、特有のパスワードの特性を規定するかもしれません。
Cloud Identityのパスワードポリシー：Cloud Identityでは、パスワードの最小長さを8文字に設定することが推奨されています。これは、パスワードのセキュリティを確保するための基本的なガイダンスです。
セキュリティ：システムとデータの保護を確保するための一連の原則、手段、技術です。これには、パスワードポリシー、アクセス制御、暗号化といった要素が含まれます。
コンプライアンス：法令、規則、ポリシー、スタンダードに準拠していることです。コンプライアンスの違反は、法的な罰則やビジネス上のリスクを招く可能性があります。
正解についての説明：
（選択肢）
・パスワードの最小文字数を8文字に設定します
この選択肢が正解の理由は以下の通りです。
Google CloudのCloud Identityでは、パスワードの最小文字数を8文字に設定することが推奨されています。これは、安全性と利用者の使いやすさを両立するための基準となっています。パスワードが短すぎるとセキュリティリスクが上がりますが、逆に長すぎると利用者の利便性が損なわれます。そのため、適切な長さとして8文字が推奨されているのです。
従って、組織がパスワードポリシーを設定する際には、このガイドラインに従うことが望ましいのです。Cloud Identityの機能を最大限に生かしながら、同時に企業のセキュリティ要件も満たすことができます。
不正解についての説明：
選択肢：パスワードの最小文字数を10文字に設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Identityのパスワードポリシーでは、パスワードの最小文字数は8文字と定められています。そのため、10文字という設定は可能ではありません。この要求を満たすためには、パスワードの最小文字数を8文字に設定する必要があります。
選択肢：パスワードの最小文字数を12文字に設定します
この選択肢が正しくない理由は以下の通りです。
Google CloudのIdentityパスワードポリシーでは、パスワードの最小文字数は8文字と規定されており、12文字に設定することはできません。
従って、適切なパスワード設定は"パスワードの最小文字数を8文字に設定します"が正しいガイドラインとなります。
選択肢：パスワードの最小文字数を6文字に設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Identityのパスワードポリシーでは、パスワードの最小文字数は8文字となっており、6文字に設定することはできません。そのため、パスワードの最小文字数を6文字に設定する選択肢は適用できません。
参考リンク：
https://cloud.google.com/identity/docs/how-to/setup-password-policies
https://cloud.google.com/identity/docs/concepts/identity-fundamentals
https://support.google.com/a/answer/91555?hl=en
</div></details>

### Q.  問題42: 未回答
Google CloudからオンプレミスのSIEMシステムにGoogle Cloud Operation Suiteのログを確実に配信するにはどうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud Operation SuiteのログをオンプレミスのSIEMシステムに確実に配信する方法について問われています。具体的な手段として4つの選択肢が提示されますが、解決策を選ぶ際には、Google Cloudのロギング機能とデータのエクスポートインポートに関する理解が必要です。また、SIEMシステムとの間でどのようにデータをやり取りすることが可能か、実現性と効率性にも注意しなければなりません。
基本的な概念や原則：
組織ログシンク：Google Cloudのログエクスポート機能を利用し、全プロジェクトや特定プロジェクトのログを一箇所に集約し、ストレージサービスや外部のSIEMシステムに送信します。
Cloud Pub/Sub：リアルタイムのメッセージングサービスで、別個のシステム間でメッセージを交換するための中間システムを提供します。
Dataflow：大規模なデータ処理ワークロードに対するストリームとバッチ処理の両方を提供するフルマネージドサービスです。取り扱うデータ量に応じて自動的にスケーリングします。
SIEMシステム：セキュリティ情報およびイベント管理（SIEM）システムは、セキュリティ情報やイベントをリアルタイムで分析し、アラートを提供するシステムです。
Google Cloud Operation Suiteのログ：Google Cloudプロジェクトで発生するログデータのこと。システムの運用状況やエラー情報などが記録されます。
正解についての説明：
（選択肢）
・組織ログシンクを構成して、ログをCloud Pub/Subトピックにエクスポートし、Dataflow経由でSIEMに送信します
この選択肢が正解の理由は以下の通りです。
まず、組織ログシンクを使用することで、Google Cloudのさまざまなプロジェクトから生成されるログを集約的に管理・エクスポートすることができます。これによって、一元的なログ出力管理を実現でき、確実にオペレーションスイートのログがSIEMシステムに届く確率を高めることができます。
次に、Cloud Pub/Subトピックへのエクスポートを選んだ理由は、リアルタイムでのメッセージ配信とスケーラビリティの面で優れています。Pub/Subは大量のログデータでも容易に処理でき、リアルタイム性を確保します。
最後に、Dataflowは、大量のデータをリアルタイムに処理するためのフルマネージドサービスで、データ変換やフィルタリングなど、必要なデータ処理を行うことができます。これにより、必要なログデータだけをSIEMシステムに送信することが可能となります。以上の理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：すべてのログをsyslogなどの既存のプロトコルでSIEMシステムに送信します
この選択肢が正しくない理由は以下の通りです。
Google Cloudからのログをsyslogなどの既存のプロトコルで直接SIEMシステムに送信することはできません。Google CloudではログはPub/Subトピックにエクスポートする形で提供されます。そのため、正解の選択肢のようにPub/Subにエクスポート後、Dataflowを使用してSIEMシステムに送信することが必要です。
選択肢：すべてのプロジェクトがすべてのログを共通のBigQuery DataSetにエクスポートし、SIEMシステムから照会されるように設定します
この選択肢が正しくない理由は以下の通りです。
BigQueryにログをエクスポートし、SIEMシステムから照会する方法は、ログの閲覧や分析には便利ですが、ログをオンプレミスのSIEMシステムに"確実に配信"するという要件を満たしません。
一方、Cloud Pub/SubトピックにエクスポートしてDataflow経由でSIEMに送信する方法は、ロギングデータをオンプレミスのSIEMシステムへリアルタイムで配信します。
選択肢：Google Cloud RESTful JSON APIからすべてのログをリアルタイムでクエリするためのSIEM用コネクタを構築します
この選択肢が正しくない理由は以下の通りです。
APIからすべてのログをリアルタイムでクエリすることは効率的ではなく、大量のリソースを消費する可能性があります。
一方、組織ログシンクを使用してCloud Pub/Subトピックにエクスポートし、Dataflow経由でSIEMに送信する方が、大量のログを効率的に配信できます。
参考リンク：
https://cloud.google.com/pubsub/docs
https://cloud.google.com/logging/docs/export
https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming#cloudpubsubsubscriptiontobigquery
</div></details>

### Q.  問題43: 未回答
あなたは、IAM（Identity and Access Management）管理者として管理するプロジェクトで実行される、規制対象のワークロードのプロジェクトオーナーです。今度の監査では、アクセスレビューの証跡を提出する必要があります。
どのツールを使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、IAM（Identity and Access Management）に関連したツールの機能に対する理解が必要です。特にアクセスレビューの証跡を提出するために必要なツールを選択する問題です。選択肢に含まれる各ツールが提供する機能と、問題文で求められている要件を照らし合わせて、最も適したものを選ぶことが求められています。
基本的な概念や原則：
Policy Analyzer：Google CloudのIAMポリシーを可視化し分析するツールです。ポリシーの理解と管理を助け、不要なアクセス権の特定や監某のための文書化を可能にします。
IAM（Identity and Access Management）：ユーザーやサービスアカウントの権限、アクセスレベルを管理するためのツールです。プロジェクトやリソースへのアクセスを細かく制御できます。
監査：セキュリティ上の問題や不適切なアクセスを検出し、規制の遵守を確認するためのプロセスです。
IAM Recommender：現在の使用状況に基づいてIAMポリシーの改善を提案するGoogle Cloudのツールです。
Policy Simulator：現在または提案中のIAMポリシー変更の影響をシミュレーションするツールです。アクセス状況の変更を予測できます。
正解についての説明：
（選択肢）
・Policy Analyzer
この選択肢が正解の理由は以下の通りです。
Policy Analyzerは、Google CloudのIdentity and Access Management（IAM）ポリシーを検査し、誰がどのリソースに対してどのような権限を持っているかを可視化するツールです。Policy Analyzerは予定された変更の影響を理解したり、特定のユーザーやサービスアカウントの特定のリソースへのアクセスを確認したりするために使用します。
また、このツールはユーザーやグループ、サービスアカウントが保持している特定の権限とロールを分析して、IAMポリシーをより適切に整理するのを助けます。
したがって、規制対象のワークロードのアクセスレビューの証跡を提出する必要があるときには、Policy Analyzerがその目的を達成するための適切なツールと言えます。
不正解についての説明：
選択肢：Policy Trouble Simulator
この選択肢が正しくない理由は以下の通りです。
Policy Trouble Simulatorというツールは存在しません。正解はPolicy Analyzerで、これはIAMポリシーを理解し、検証し、管理するためのGoogle Cloudのツールです。よって、アクセスレビューの証跡を提出する際にはPolicy Analyzerを使用すべきです。
選択肢：IAM Recommender
この選択肢が正しくない理由は以下の通りです。
IAM RecommenderはIAMポリシーの改善提案を行うツールであり、既存のアクセス証跡を提出する目的には適合していません。
一方、Policy AnalyzerはIAMポリシーのアクセスレベルを分析しレビューできるので、アクセスレビューの証拠提出に適しています。
選択肢：Policy Simulator
この選択肢が正しくない理由は以下の通りです。
Policy Simulatorは主にIAMポリシーの変更をシミュレートしてその影響を予測するためのツールであり、過去のアクセスレビューの証拠を提供するためのものではありません。
一方、Policy AnalyzerはIAMのアクセス許可を分析し、確認するためのツールで、アクセスレビューの証跡を提出するために適しています。
参考リンク：
https://cloud.google.com/iam/docs/policy-analyzer
https://cloud.google.com/iam/docs/managing-policies#analyzing_permissions
https://support.google.com/cloud/answer/10324190
</div></details>

### Q.  問題44: 未回答
あなたは、Google Kubernetes Engine（GKE）上の本番クラスターにコンテナ化されたアプリケーションをデプロイするためのCI/CDパイプラインをセットアップしています。既知の脆弱性を持つコンテナがデプロイされないようにする必要があります。ソリューションには以下の要件があります：
- クラウドネイティブであること
- コスト効率が高いこと
- 運用上のオーバーヘッドを最小限に抑えること
この要件を満たすために、どの方法を使うべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Kubernetes Engine（GKE）上にデプロイする際に、脆弱性を持つコンテナがデプロイされないようなCI/CDパイプラインをセットアップする方法が求められています。与えられた要件としては、クラウドネイティブなソリューションであること、コスト効率が高いこと、運用上のオーバーヘッドを最小限に抑えることが求められています。したがって、これらの要求に適合するGoogle Cloudのサービスや特性を検討し、脆弱性の分析や防止策が統合された効率的なCI/CDパイプラインを設計するためのソリューションを選択することが求められています。
基本的な概念や原則：
Google Kubernetes Engine（GKE）：Google CloudのマネージドKubernetesサービスです。アプリケーションのデプロイ、スケーリング、運用をシンプルに、また効率的に行うことができます。
CI/CDパイプライン：継続的インテグレーション（CI）と継続的デリバリー（CD）を組み合わせた開発プロセスです。コードの変更を自動的にビルド、テスト、デプロイすることで、高速かつ安定したソフトウェアリリースを支援します。
Cloud Source Repositories：Google CloudのプライベートGitリポジトリです。ソースコードを安全にホストし、Google Cloudの他のプロダクトと統合することができます。
Cloud Build：Google Cloudのサービスで、ソースコードからコンテナイメージをビルドし、パッケージ化することができます。CI/CDパイプラインとしても使用できます。
コンテナ脆弱性診断：コンテナイメージが脆弱性を持つかどうかを評価するプロセスです。不適切なコンテナのデプロイを防ぐために使用されます。
バイナリ認証：Google Cloudのバイナリ認証では、デプロイ前にコンテナイメージの信頼性を保証します。認証のないイメージのデプロイを防止できます。
Cloud Function：Google Cloudのサーバーレス実行環境です。特定のイベントに対して自動的にトリガーされる小さな単一用途関数を作成し、実行することができます。
正解についての説明：
（選択肢）
・Cloud Source Repositoriesリポジトリのコンテナテンプレートへの変更を監視するCloud Buildパイプラインを作成します。ビルドの続行を許可する前に、コンテナ脆弱性診断の結果を分析するステップを追加します
・CI/CDパイプラインで、脆弱性が見つかっていない場合にコンテナイメージに認証を追加します。バイナリ認証ポリシーを使用して、クラスター内で認証のないコンテナのデプロイをブロックします
この選択肢が正解の理由は以下の通りです。
まず、Cloud Buildを用いて継続的デリバリーパイプラインを作成すると、Cloud Source Repositoriesにあるコンテナテンプレートの変更を監視し、予め設定したトリガーが発火した際にビルドプロセスを自動的に開始できます。コンテナの脆弱性診断の結果を分析するステップを追加することで、脆弱性をいち早く見つけ出し、それに対する対策を講じることができます。
次に、バイナリ認証ポリシーを利用することで、システムに問題のないコンテナイメージのみがデプロイされる状態を保持することができます。CI/CDパイプライン時に、脆弱性が見つからない場合にのみコンテナイメージに認証を追加することで、既知の脆弱性を持つコンテナがデプロイされるのを防ぐことができます。
以上の理由から、結果としてクラウドネイティブで高いコスト効率を持ち、運用上のオーバーヘッドを最小限に抑えることができ、要件を満たす適切な解答となります。
不正解についての説明：
選択肢：Google CloudのオペレーションスイートのログイベントをトリガーとするCloud Functionを使用して、Container Registryのコンテナイメージを自動的にスキャンします
この選択肢が正しくない理由は以下の通りです。
この手法は受動的で、脆弱性を持つコンテナがデプロイされるのを防ぐよりも、問題が発生した後で対処することに重きを置いています。しかし、問題は脆弱性を持つコンテナがデプロイされないようにすることにあります。
したがって、問題に対する有効な解決策ではありません。
選択肢：Compute Engineインスタンスのcronジョブを使用して、既知の脆弱性について既存のリポジトリをスキャンし、非準拠のコンテナイメージが見つかった場合にアラートを発生させます
この選択肢が正しくない理由は以下の通りです。
Compute Engineインスタンスのcronジョブを使用した手法は、クラウドネイティブの冗長性やスケーラビリティが制限され、効率的なコスト管理も困難です。
また、非準拠のコンテナイメージが見つかった時点でアラートを出すだけであり、これを防止する具体的な手段が提供されていません。
選択肢：GKEにJenkinsをデプロイし、CI/CDパイプラインを構成してコンテナをContainer Registryにデプロイします。コンテナをクラスターにデプロイする前に、コンテナイメージを検証するステップを追加します
この選択肢が正しくない理由は以下の通りです。
JenkinsをGKE上にデプロイすると管理オーバーヘッドが増大するからです。
また、Jenkinsの設定やメンテナンスのための追加コストが発生します。
それに対して、正解はクラウドネイティブで効率的なサービスを使用しており、運用のオーバーヘッドを最小限に抑えています。
参考リンク：
https://cloud.google.com/build/docs/automating-builds/build-repos-from-source
https://cloud.google.com/binary-authorization/docs
https://cloud.google.com/container-analysis/docs/getting-started
</div></details>

### Q.  問題45: 未回答
gcloudコマンドラインツールを使用して、サードパーティのシングルサインオン（SSO）SAML IDプロバイダを使用して認証を行いたいとします。
サードパーティのIDプロバイダ（IdP）で認証がサポートされていることを確認するために、どのオプションが必要ですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、サードパーティのシングルサインオン（SSO）SAML IDプロバイダを利用してgcloudコマンドラインツールで認証を行いたいという具体的な要求があるため、選択肢を見たときには、その要求にどの選択肢が最適に対応するのかを考えることが求められます。ここでは、SAMLとIDプロバイダがキーワードとなります。また、2つ選択するという指定があるので、全選択肢を見て選び出す必要があるという点にも注意しましょう。
基本的な概念や原則：
サードパーティIdPとしてのSSO SAML：サードパーティのシングルサインオン（SSO）サービスを使用してGoogle Cloudのリソースにアクセスするための設定です。SAML（Security Assertion Markup Language）は、データの認証と承認を交換するためのオープンスタンダードです。
OpenID Connect：ユーザー認証のためのオープンスタンダードです。IDトークンと標準的なJWT（JSON Web Tokens）を使用してユーザー情報を提供します。
Identity Platform：Google CloudのカスタマーやエンドユーザーのためのIdentity and Access Management（IAM）サービスで、B2BやB2C環境でのユーザー認証をサポートしています。
Identity-Aware Proxy：Google Cloud環境内のリソースへのアクセスをセキュアに管理できるサービスです。VPNの必要性を排除し、アクセスコントロールと認証を提供します。
Cloud Identity：Google CloudのIDaaS（Identity as a Service）、つまり、クラウドベースのIdentity and Access Managementサービスです。ユーザー、アプリケーション、およびデバイスの管理を可能にします。
正解についての説明：
（選択肢）
・サードパーティIdPとしてのSSO SAML
・OpenID Connect
この選択肢が正解の理由は以下の通りです。
まず、SSO SAMLは広く採用されている認証標準であり、一度認証することで指定したアプリケーション間で同じログイン情報を使用できるようにするものです。これはサードパーティのIDプロバイダを使用した認証であり、gcloudコマンドラインツールでの認証においてもサポートされています。これにより、ユーザは一度の認証で複数のサービスにアクセスすることができ、ユーザ体験を改善します。
また、OpenID Connectもまた、一般的な認証プロトコルで、認証とID情報の伝送に使用されます。これもまたgcloudコマンドラインツールでの認証においてはサポートされており、ユーザーの認証状態やプロフィール情報を提供します。
したがって、サードパーティのIDプロバイダがSSO SAMLとOpenID Connectをサポートしている場合、それらはgcloudコマンドラインツールとともに使用することで認証を行うことができます。
不正解についての説明：
選択肢：Identity Platform
この選択肢が正しくない理由は以下の通りです。
Identity Platformは、Google Cloud内でユーザー認証とアイデンティティ管理を提供するサービスですが、サードパーティのシングルサインオン（SSO）SAML IDプロバイダとしての機能は提供していません。
また、gcloudコマンドラインツールの認証に使用するのではなく、アプリケーションレベルでの認証とアイデンティティ管理に使用されます。
選択肢：Identity-Aware Proxy
この選択肢が正しくない理由は以下の通りです。
Identity-Aware ProxyはGoogle Cloudリソースへのセキュアなアクセスを管理するツールであり、サードパーティのIDプロバイダによる認証の検証には使用されません。適切な認証を構成するためには、SSO SAMLやOpenID Connectのような認証プロトコルのサポートが必要です。
選択肢：Cloud Identity
この選択肢が正しくない理由は以下の通りです。
Cloud IdentityはGoogleのIdentity as a Service（IDaaS）ソリューションですが、ここではサードパーティのIdPを使用する認証が求められています。SSO SAMLとOpenID ConnectはサードパーティIdPで一般的にサポートされている認証標準であるため、これらが正解となります。
参考リンク：
https://cloud.google.com/sdk/gcloud/reference/auth/login
https://cloud.google.com/identity/saml
https://openid.net/connect/
</div></details>

### Q.  問題46: 未回答
あなたは、ワークロードを保護し、会社でセキュリティ侵害が疑われる場合のアラートを受信するために、Security Command Center（SCC）を使用しています。暗号通貨マイニングソフトウェアを検出する必要があります。
どのSCCサービスを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社が使用しているSecurity Command Center（SCC）サービスの中から、特定のセキュリティ問題、つまり暗号通貨マイニングソフトウェアを検出するための最適なサービスを選ぶことが求められています。選択肢を検討する際には、それぞれのサービスがどのような脅威や脆弱性を検出するためのものかを理解し、その中から暗号通貨マイニングソフトウェアの検出に最適なものを選びます。
基本的な概念や原則：
Security Command Center（SCC）：Google Cloudのセキュリティとデータリスクプラットフォームで、コンテンツ、アセット、サービスの使用状況を網羅的に理解することができます。
Virtual Machine Threat Detection：Google CloudのSecurity Command Centerの一部で、仮想マシンに対する脅威（例えば暗号通貨マイニングソフトウェアなど）を検出するためのサービスです。
Container Threat Detection：Google CloudのSecurity Command Centerの一部で、コンテナ化されたアプリケーションに対する脅威を検出します。しかし、仮想マシンに対する脅威を検出するためにはVirtual Machine Threat Detectionを使用することが適切です。
Rapid Vulnerability Detection：脆弱性の発見と修正を迅速に行うためのサービスです。脅威検出よりも、事前の防御に注目しています。
Web Security Scanner：公開Webアプリケーションの脆弱性を自動的に走査するサービスです。公開Webアプリケーションに特化しています。
正解についての説明：
（選択肢）
・Virtual Machine Threat Detection
この選択肢が正解の理由は以下の通りです。
まず、Virtual Machine Threat Detectionは、Security Command Centerの一部として提供されます。このサービスは、Google Cloud上の仮想マシン（VM）で実行されている可能性のある悪意のある行為や不審な動作を検出する機能を備えているため、暗号通貨マイニングソフトウェアのような不正なソフトウェアの挙動を検出するのに適しています。
また、このサービスはリアルタイムのアラートを提供します。これが重要なことは、通常、暗号通貨マイニングソフトウェアは検出されるとすぐに操作を停止し、あたかも不正な活動がなかったかのように動作するからです。Virtual Machine Threat Detectionを使用すれば、そのような不正な行為を即座に捉え、対策を講じることができます。以上の理由から、暗号通貨マイニングソフトウェアを検出するにはVirtual Machine Threat Detectionを使用すべきです。
不正解についての説明：
選択肢：Container Threat Detection
この選択肢が正しくない理由は以下の通りです。
Container Threat Detectionは、サービス名にも表れているように、セキュリティ上の脅威を検出するためのコンテナ特化型のサービスです。この設問の目的は暗号通貨マイニングソフトウェアを検出することであり、その検出にはVirtual Machine Threat Detectionが適しています。
選択肢：Rapid Vulnerability Detection
この選択肢が正しくない理由は以下の通りです。
Rapid Vulnerability Detectionは弱点を素早く見つけるためのものであり、暗号通貨マイニングソフトウェアの検出には特化していません。
一方、Virtual Machine Threat Detectionは仮想マシン上の脅威、特に暗号通貨マイニングソフトウェアなどの検出に特化しています。
選択肢：Web Security Scanner
この選択肢が正しくない理由は以下の通りです。
Web Security ScannerはWebアプリケーションの脆弱性を検出するためのツールであり、暗号通貨マイニングソフトウェアを検出するという要求には対応していません。その代わりに、Virtual Machine Threat Detectionが暗号通貨マイニングソフトウェアなどの脅威を検出するために設計されています。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-threat-detection-overview
https://cloud.google.com/security-command-center/docs/how-to-use-threat-detection
https://cloud.google.com/security-command-center/docs/how-to-use-virtual-machine-threat-detection
</div></details>

### Q.  問題47: 未回答
ある顧客の社内セキュリティチームが、Cloud Storage上のデータを暗号化するための独自の暗号鍵を管理する必要があり、顧客提供の暗号鍵（CSEK）を使用することを決定しました。
チームはこのタスクをどのように完了すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、社内セキュリティチームがCloud Storageへのデータ暗号化の為に独自の暗号鍵を管理したいという要件に対して、どのアクションが正しいかを理解することが求められています。正解選択肢を選ぶためには、Google Cloud StorageとCSEK（Customer-Supplied Encryption Keys）の概念と用途を理解した上で、Google Cloud上でオブジェクトの暗号化とアップロードをどのように行うべきかを考えることが重要です。
基本的な概念や原則：
顧客提供の暗号鍵（CSEK）：ユーザーが管理する独自の暗号鍵で、Google Cloud上のデータを暗号化する際に使用します。
gsutil：Google Cloud Storageをコマンドラインから操作するためのツールで、オブジェクトのアップロードやダウンロードなどが可能です。
暗号化：データの秘匿化を行うためのプロセスで、特定の暗号鍵を使用して元のデータを解読不能な形式に変換します。
Cloud Storage：Google Cloud上で提供されるオブジェクトストレージサービスです。データを安全に保存し、グローバルなスケールで高速にアクセス可能です。
Google Cloud Console：Google Cloudのリソースやサービスを管理するためのウェブベースのインターフェースです。暗号鍵の生成などはここでは行えません。
正解についての説明：
（選択肢）
・gsutilコマンドラインツールを使ってオブジェクトをCloud Storageにアップロードし、暗号化キーの場所を指定します
この選択肢が正解の理由は以下の通りです。
まず、顧客提供の暗号鍵（CSEK）は、ユーザーが自身の暗号キーを生成・管理し、それを使ってGoogle Cloud Storage内のデータを暗号化する機能です。これにより、ユーザーは自身の暗号鍵の管理によりデータの安全性を確保できます。このCSEKへの指定はgsutilコマンドラインツールを通じて行うことができます。
また、gsutilはCloud Storageのインターフェースになりますから、データをアップロードする際に、独自の暗号化キーを指定することで、そのデータが暗号化されて保存されます。ここで重要なのは、この暗号化キーの場所を指定するという部分で、暗号化キーはその際にCloud Storageにアップロードするデータと一緒に渡されますが、Google Cloudには保存されません。
よって、オフサイトで管理される独自の暗号鍵を扱いながら、gsutilを使うことで顧客が完全にキーの管理を手元に保てるため、この選択肢が適切な答えとなります。
不正解についての説明：
選択肢：暗号化キーをCloud Storageバケットにアップロードし、同じバケットにオブジェクトをアップロードします
この選択肢が正しくない理由は以下の通りです。
暗号化キーをCloud Storageバケットにアップロードするのは安全でなく、推奨されません。なぜなら、そのキー自体が十分に保護されず漏洩する可能性があります。正しい方法は、gsutilを使用してオブジェクトをアップロードし、暗号化キーの場所を指定することです。
選択肢：Google Cloud Consoleで暗号化キーを生成し、指定したキーを使ってオブジェクトをCloud Storageにアップロードします
この選択肢が正しくない理由は以下の通りです。
Google Cloud Consoleでは独自の暗号鍵を生成できないため、顧客提供の暗号鍵（CSEK）を用いるためにはConsoleではなく、gsutilコマンドラインツールでオブジェクトをアップロードし暗号化キーの場所を指定する必要があります。
選択肢：オブジェクトを暗号化し、gsutilコマンドラインツールまたはGoogle Cloud Consoleを使用してオブジェクトをCloud Storageにアップロードします
この選択肢が正しくない理由は以下の通りです。
オブジェクトを暗号化してからCloud Storageにアップロードするという選択は、Google Cloud ConsoleでCSEKを使用するオプションが利用できないからです。正しい手順では、gsutilを用いてオブジェクトをアップロードし、暗号化キーの場所を指定することで、CSEKの管理が可能になります。
参考リンク：
https://cloud.google.com/storage/docs/encryption/customer-supplied-keys
https://cloud.google.com/storage/docs/gsutil
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題48: 未回答
あなたは、組織のGoogle Cloud環境のSecurity Command Centerの設定を任されています。セキュリティチームは、組織のコンピュート環境における潜在的な暗号マイニングに関するアラートと、セキュリティに影響を与える一般的なGoogle Cloudの誤設定に関するアラートを受信する必要があります。
これらのアラートを構成するために、どのSecurity Command Centerの機能を使用する必要がありますか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud環境のSecurity Command Centerの設定に関する知識が要求されています。特に、セキュリティチームが要求する特定のアラート、すなわち潜在的な暗号マイニングについてのアラートと、一般的なGoogle Cloudの誤設定に関するアラートを構成することが求められています。このシナリオを解決するために、Security Command Centerの何らかの特定の機能を使用する必要があるので、Google Cloudのセキュリティ関連の機能について理解していることが重要となります。選択肢を見るときは、それらが出題のシナリオと一致するかどうかを注意深く確認してください。
基本的な概念や原則：
Event Threat Detection：Google Cloudのログデータを分析するSecurity Command Centerの機能で、潜在的なセキュリティ脅威や不審な行動を自動的に検出しアラートを発します。この機能を使用すると、暗号マイニングといった特定の脅威に対するアラートを構成することができます。
Security Health Analytics：Google Cloud環境の設定を自動的に確認し、可能性のあるセキュリティ上の問題を識別するSecurity Command Centerの機能です。設定エラーや誤設定、ベストプラクティスの遵守状況について報告します。
Container Threat Detection：Google Kubernetes Engine（GKE）上で動作するコンテナに対する脅威を検出する機能です。ただし、一般的なGoogle Cloudの誤設定や暗号マイニングに対する検出は含まれません。
Cloud Data Loss Prevention：機密データの検出、分類、保護のためのサービスです。データ損失や準拠違反を予防しますが、特定の脅威を検出する機能は含まれません。
Google Cloud Armor：Google Cloudのアプリケーションやサービスに対する攻撃を防ぐためのネットワークセキュリティサービスです。DDoS攻撃などの脅威を検出・阻止しますが、一般的な誤設定や暗号マイニングに対する検出機能は含まれません。
正解についての説明：
（選択肢）
・Event Threat Detection
・Security Health Analytics
この選択肢が正解の理由は以下の通りです。
まず、"Event Threat Detection"（ETD）は、Google Cloud内のリアルタイムのログデータを分析し、セキュリティインシデントや脅威を検出するためのSecurity Command Centerの一部です。ETDは、公開されたIAM権限、不正な出入りなど様々な種類の脅威、そして特にここで重要なのは、暗号マイニングなどの不審なアクティビティを自動的に検出します。
次に、"Security Health Analytics"（SHA）は、組織のGoogle Cloud環境の様々な設定に対するベストプラクティスへの準拠を自動的に確認し、セキュリティ設定の誤りを発見してそれらに対するアラートを生成するためのツールです。具体的には、IAMポリシー、ネットワーク設定、ストレージ設定など、Google Cloudの多くのサービスに関連する設定の誤りを特定します。
したがって、これらの機能を用いてセキュリティチームは潜在的な暗号マイニングに関するアラートと、一般的なGoogle Cloudの誤設定に関するアラートを受信することが可能となります。
不正解についての説明：
選択肢：Container Threat Detection
この選択肢が正しくない理由は以下の通りです。
Container Threat Detectionは、Google Kubernetes Engineクラスターで動作しているコンテナに対する脆弱性の検知を提供する機能であり、暗号マイニングや一般的な誤設定に関するアラートの設定には用いられません。反対に、Event Threat Detectionは潜在的な暗号マイニング活動の検知、Security Health AnalyticsはGoogle Cloudの誤設定を検知するために使用します。
選択肢：Cloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Preventionは、機密データが漏えいしないかを監視するための機能です。しかし、問題で求められているのは潜在的な暗号マイニングに関するアラートとGoogle Cloudの誤設定に関するアラートです。これらはEvent Threat DetectionとSecurity Health Analyticsの機能を使用することで設定することができます。
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは、Google Cloudロードバランサーに導入されたコンテンツデリバリーネットワークを保護し、DDLアタックなどのセキュリティリスクから保護するためのサービスです。しかし、この要件は誤設定と暗号マイニングの検出のためのアラートが中心なので、Google Cloud Armorでは対応できません。
一方、Event Threat DetectionとSecurity Health Analyticsではこれらの要求を満たせます。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-security-sources#threat_detection
https://cloud.google.com/security-command-center/docs/concepts-security-health-analytics
https://cloud.google.com/security-command-center/docs/how-to-notifications-and-alerts
</div></details>

### Q.  問題49: 未回答
ある顧客は、Google Cloud上でホストされているCRMのウェブインターフェイスに、従業員のモバイル端末からアクセスできるようにしたいと考えています。このCRMには、企業ネットワーク上の人しかアクセスできません。顧客はインターネット経由で利用できるようにしたいと考えています。あなたのチームは、アプリケーションの前に二要素認証をサポートする認証レイヤーを必要としています。
これらの要件を満たすために、顧客はどのGoogle Cloudサービスを導入すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客が目指す目標と具体的な要件を理解し、どのGoogle Cloudサービスがそれらを満たすか判断する能力が試されています。特に注目すべきは、ウェブインターフェイスに外部からアクセス可能にするというニーズと、二要素認証をサポートする認証レイヤーが必要であるという要件です。これらを満たし、同時に適切なセキュリティを維持できるGoogle Cloudサービスを選択することが求められています。
基本的な概念や原則：
Cloud Identity-Aware Proxy（IAP）：Google Cloud上のアプリケーションとリソースへのセキュアなアクセスを制御するサービスです。ユーザーとリソース間の通信を中継し、アイデンティティとコンテキストに基づいてアクセスを管理します。
二要素認証：認証時に2つ以上の異なる要素（知識、所有、生体認証）を要求し、より強固なセキュリティを提供する方法です。Cloud IAPは二要素認証をサポートします。
Cloud Armor：Google Cloudの分散型デニーアルオブサービス（DDoS）防御とウェブアプリケーションファイアウォール（WAF）のサービスです。Cloud IAPとは異なり、認証やアクセス制御は提供していません。
Cloud Endpoints：Google Cloud上でAPIを開発、デプロイ、管理するためのツールです。リクエストの認証やトラフィックの監視を行いますが、特定のアプリケーションへの認証レイヤーの追加はサポートしていません。
Cloud VPN：企業ネットワークとGoogle Cloud上のVPCネットワークを安全に接続するためのサービスです。二要素認証の提供はしていません。
正解についての説明：
（選択肢）
・Cloud Identity-Aware Proxy
この選択肢が正解の理由は以下の通りです。
まず、Cloud Identity-Aware Proxy（IAP）は、Google Cloud上にホストされたアプリケーションへのセキュアなアクセスを提供するサービスです。これにより、ユーザーはインターネット経由でCRMにアクセスでき、企業ネットワークから離れた場所でもアプリケーションにアクセスできます。これは、モバイル端末からCRMにアクセスする要件を満たします。
さらに、IAPは認証と認可を管理し、アクセスを試みる個々のユーザーを特定します。ユーザーとサービス間の通信は、Googleのインフラを介してセキュアに行われます。IAPは、Identity Platformと統合されており、二要素認証を含む強力な認証オプションを提供します。これにより、顧客のセキュリティ要件である二要素認証のサポートも満たされます。
したがって、Cloud Identity-Aware Proxyは、顧客の要件を満たす最適なGoogle Cloudサービスと言えます。
不正解についての説明：
選択肢：Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Cloud Armorは主にDDoS攻撃やSQLインジェクション等のウェブ攻撃からアプリケーションを保護する機能を提供するもので、二要素認証の機能は提供していません。
それに対して、Cloud Identity-Aware Proxyはアプリケーションへのアクセスを認証・認可し、二要素認証もサポートしており、要件に合致します。
選択肢：Cloud Endpoints
この選択肢が正しくない理由は以下の通りです。
Cloud EndpointsはAPIの開発、デプロイ、保護、スケーリングに使用しますが、二要素認証のレイヤーの提供が主な目的ではありません。
一方、Cloud Identity-Aware Proxyはアプリケーションへの認証およびアクセスを管理し、二要素認証をサポートします。
選択肢：Cloud VPN
この選択肢が正しくない理由は以下の通りです。
Cloud VPNは企業のネットワークとGoogle Cloudのネットワークを接続するためのサービスで、二要素認証やユーザーの認証レイヤーを提供するものではありません。
一方、Cloud Identity-Aware Proxyはアプリケーションへのアクセスを制御し、二要素認証をサポートしているため、この要件に適しています。
参考リンク：
https://cloud.google.com/iap/docs
https://cloud.google.com/identity-platform/docs/web/mfa
https://support.google.com/a/answer/6197438?hl=en
</div></details>

### Q.  問題50: 未回答
Cloud Data Loss Prevention（Cloud DLP）APIの導入が社内で進むにつれ、コスト削減のために利用を最適化する必要が出てきました。Cloud DLPの対象データはCloud StorageとBigQueryに保存されます。保存場所とリージョンはリソース名のサフィックスとして識別されます。
どのコスト削減オプションを推奨しますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Data Loss Prevention（Cloud DLP）APIの導入が進み、コスト削減のために利用を最適化する必要がある状況に対して、どのコスト削減のオプションを選択すべきかを問っています。特に、"Cloud DLPの対象データはCloud StorageとBigQueryに保存され、この保存場所とリージョンはリソース名のサフィックスとして識別される"という情報に注目する必要があります。そのため、選択肢を見る時には、Cloud DLPがCloud StorageやBigQueryにデータをどのように保存するか、どのような手段でコスト削減を行えるか、そしてそれが設問の条件と照らし合わせて適合するかを確認しながら選ぶべきです。
基本的な概念や原則：
Cloud Data Loss Prevention（Cloud DLP）：感度が高い情報を識別、マスク、保護するためのGoogle Cloudのサービスです。コスト最適化のためにデータのサンプリングやスキャン範囲の制限が可能です。
Cloud Storage：大量データの保管に対応したオブジェクトストレージサービスです。世界中のどこからでもデータにアクセスすることができます。
BigQuery：大規模データセットの高速分析のためのフルマネージド、サーバーレス、高耐久性のデータウェアハウスです。
rowsLimit：Cloud DLPでデータをサンプリングする際に利用する設定です。指定した行数を上限にしてスキャンを行います。
bytesLimitPerFile：Cloud DLPでデータをサンプリングする際に利用する設定です。指定したバイト数を上限にしてスキャンを行います。
CloudStorageRegexFileSet：Cloud Storage内の特定のファイルセットを指定するための設定です。これにより、必要なデータのみをスキャンすることでコストを削減できます。
リージョン：地理的に近いデータセンターからサービスを提供するための設定です。リージョンを最適に管理することで、データ転送量やレイテンシを削減し、コストを抑えることが可能です。
正解についての説明：
（選択肢）
・rowsLimitとbytesLimitPerFileを使用してデータをサンプリングし、CloudStorageRegexFileSetを使用してスキャンを制限します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Data Loss Prevention（Cloud DLP）APIは、顧客が持つ機密データや個人情報データを識別し、分類し、保護するためのAPIサービスです。これはトラフィックとストレージの使用量に連動してコストが発生するため、対象データ量を増やすと、それに伴ってコストも増加します。
正解選択肢の"rowsLimit"と"bytesLimitPerFile"を使用する方法は、スキャンする対象データの量を制限することでコストを最適化するアプローチです。
また、"CloudStorageRegexFileSet"を用いることで、スキャンするファイル群を正規表現を用いて詳細に制御できます。
以上から、非必要なスキャンを削減しコストを最適化するためには、"rowsLimit"、"bytesLimitPerFile"、"CloudStorageRegexFileSet"の利用を推奨することが適切と判断されます。
不正解についての説明：
選択肢：米国外でホストされているBigQueryデータには適切なrowsLimit値を設定し、マルチリージョンのCloud Storageバケットには適切なbytesLimitPerFile値を設定します
この選択肢が正しくない理由は以下の通りです。
この選択肢はコスト削減の観点からは正しいかもしれませんが、Cloud DLPの効率的な使用を最適化するだけでなく、データ保護も重要です。正解の選択肢はデータサンプリングを提案しており、これによりコスト削減だけでなくデータ保護も実現できます。つまり、適切なrowsLimit値とbytesLimitPerFile値を設定することだけでは充分ではないのです。
選択肢：米国外でホストされているBigQueryデータには適切なrowsLimit値を設定し、マルチリージョンのCloud Storageバケットでは変換単位を最小化します
この選択肢が正しくない理由は以下の通りです。
BigQueryデータのホスト国ではなく、データのサンプリングとスキャン範囲の制限など、データ自体の管理に注目するべきです。
また、マルチリージョンのCloud Storageバケットで変換単位を最小化すると、コスト削減よりもむしろパフォーマンス等が低下する可能性があります。
選択肢：FindingLimitsとTimespanContfigを使ってデータをサンプリングし、変換単位を最小化します
この選択肢が正しくない理由は以下の通りです。
FindingLimitsとTimespanContfigはCloud DLPに存在しないパラメータです。
したがって、コスト削減オプションとしては適切ではありません。
一方、rowsLimitとbytesLimitPerFileを使用してデータをサンプリングし、CloudStorageRegexFileSetを使用してスキャンを制限することは、コスト削減の有効な手段です。
参考リンク：
https://cloud.google.com/dlp/docs/concepts-limits
https://cloud.google.com/dlp/docs/inspecting-storage
https://cloud.google.com/dlp/docs/samples/dlp-inspect-file-regexp-sample
</div></details>


## 4

### Q.  問題1: 未回答
あるマネージャーが、コストを最小限に抑えながら、セキュリティイベントログを2年間保持し始めたいと考えています。あなたは、適切なログエントリを選択するフィルタを作成します。
ログをどこにエクスポートしますか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、コスト低減とセキュリティイベントログの保持の両方を同時に達成する適切なログエクスポート先を選ぶことが求められています。2年間のログを保持するという長期の要件と、コストを最小限に抑えるという制約があるため、その中で最もコスト効率の良いストレージソリューションを選択することが重要です。また、適用可能なデータ保持ポリシーやアクセス制御も考慮に入れる必要があります。
基本的な概念や原則：
Cloud Storage：Google Cloudの耐久性とスケーラビリティを備えたオブジェクトストレージサービスです。低コストなアーカイブオプションが提供され、長期間のデータ保管に適しています。
セキュリティイベントログ：システムやアプリケーションのセキュリティに関連する活動を記録したものです。監査やトラブルシューティングのために利用されます。
フィルタ：特定の条件を満たすデータを選択するためのルールまたはパラメータです。ログエントリの選択に利用されます。
BigQuery：Google Cloudのフルマネージドなビッグデータ分析サービスです。リアルタイム分析が可能で、大量のデータを高速に処理します。ただし、コストはCloud Storageよりも高いです。
ロギング：システムやアプリケーションの活動を追跡するための情報のレコードです。オペレーションスイートのロギングは、リアルタイムでの追跡やアラートに主に利用されます。
Cloud Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。データをストリーミングし、リアルタイムに処理するケースに最も適しています。
正解についての説明：
（選択肢）
・Cloud Storageバケット
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageは長期間のデータ保管に適しています。マネージャーがセキュリティイベントログを2年間保持したいという要件を満たす点で有利です。
また、データの維持期間が長い場合、コストが重要な要素となります。Cloud Storageはコスト効率が高く、量の多いデータを格納するのに適しています。
さらに、Cloud Storageには強力なセキュリティ機能があり、ログデータの外部からのアクセスを効果的に制御できます。このため、セキュリティイベントログというセキュリティ上重要な情報を格納するのに適しています。
したがって、コストを最小限に抑えつつもセキュリティイベントログを2年間保持したいというこのシナリオにおいて、Cloud Storageバケットは適切な選択となります。
不正解についての説明：
選択肢：BigQueryデータセット
この選択肢が正しくない理由は以下の通りです。
BigQueryデータセットにログをエクスポートするとコストが高くなります。コストを最小限に抑えるためには、ストレージコストが低いCloud Storageバケットを用いたログのエクスポートが適しています。
選択肢：オペレーションスイートのロギング
この選択肢が正しくない理由は以下の通りです。
オペレーションスイートのロギングは、短期間のログデータの保持と分析に用いられますが、デフォルトでは最大で30日間しかログを保持できません。長期間、特に2年間のセキュリティイベントログを保持するためには、コストを最小限にする観点からもCloud Storageバケット使用が適しています。
選択肢：Cloud Pub/Subトピック
この選択肢が正しくない理由は以下の通りです。
Cloud Pub/Subトピックはリアルタイムのメッセージングとストリーミングのためのサービスであり、長期間のログ保持には適していません。
一方、Cloud Storageバケットはコスト効率が高く、長期間のデータ保管に適しています。
参考リンク：
https://cloud.google.com/logging/docs/storage
https://cloud.google.com/storage/docs
https://cloud.google.com/logging/docs/export/aggregated_exports
</div></details>

### Q.  問題2: 未回答
あなたの組織の顧客は、契約書と運転免許証をスキャンし、Cloud Storageのウェブポータルにアップロードする必要があります。12か月以上前のファイルから、個人を特定できる情報（PII）をすべて削除する必要があります。また、保管目的で匿名化されたファイルをアーカイブする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、リテンション期間が終了した個人を特定できる情報（PII）を削除し、匿名化したデータの保管を実現することが求められています。このため、データ非識別化技術を使いつつ、アーカイブ処理に適したGoogle Cloudのサービスを選ぶことが問題の解答に至る鍵となります。問題文からは、PIIを非識別化する必要があること、そしてそれらのファイルを新しいストレージに保存するという情報が得られます。これらの要件をしっかり理解することが、問題解決のための正しいGoogle Cloudサービスを選択する上で重要となります。
基本的な概念や原則：
Cloud Storage：Google Cloudの持続的なデータ保管サービスです。バケット内にデータを安全に保存し、任意の場所からアクセスすることができます。
Cloud Data Loss Prevention（DLP）：感度の高いデータや個人を特定できる情報（PII）を検出、非識別化、保護するためのGoogle Cloudのサービスです。
検査ジョブ：Cloud DLPにおけるデータセットのスキャン操作です。特定のデータに存在する潜在的な機密情報を特定するために使用します。
非識別化：個々のデータ要素が特定の個人を識別するのを防ぐためにデータを変更するプロセスです。これにより、データの有用性を維持しつつプライバシーが保護されます。
アーカイブ：長期間データを保管するための低コストなストレージオプションです。アクセス頻度が低いデータに適しています。
Cloud Key Management Service（KMS）：暗号鍵の作成、使用、管理、および破棄を行うGoogle Cloudのサービスです。しかし、データ自体を非識別化することはできません。
正解についての説明：
（選択肢）
・Cloud Data Loss Prevention（DLP）検査ジョブを作成し、12ヶ月以上前に作成されたファイルのPIIを非識別化し、別のCloud Storageバケットにアーカイブします。元のファイルを削除します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Data Loss Prevention（DLP）は、個人を特定できる情報（PII）を発見、非識別化し、保護できるGoogle Cloudのサービスです。このため、急務となっている12ヶ月以上前の情報を非識別化するためにDLPは適用されます。作成した検査ジョブによってPII情報が非識別化され、その結果は別のCloud Storageバケットに安全にアーカイブされます。
さらに、検査ジョブ作成の後、元のファイルの削除が要求されています。本件の要件と互換性が高いのは、DLPの特定の情報を検出し、マスクまたは非表示にする機能およびCloud Storageバケット間でのデータの操作が容易な性質ゆえです。そのマネージャーブルで柔軟性のある性質により、Cloud DLPとCloud Storageは、このような運用要件を満たすのに最適な選択肢となります。
不正解についての説明：
選択肢：PIIを削除し、ファイルをArchiveストレージクラスに移動するCloud Storageバケット内のファイルのTTL（Time To Live）を12ヶ月に設定します
この選択肢が正しくない理由は以下の通りです。
TTLはCloud Storageでの直接的な機能ではなく、Cloud StorageではPIIの削除などの特定の操作を実行するためにこれを使用することはできません。PIIを非識別化するためにはCloud DLPのようなサービスが必要です。
選択肢：Cloud StorageバケットのAutoclass機能を設定し、PIIを非識別化します。12ヶ月以上前のファイルをアーカイブします。元のファイルを削除します
この選択肢が正しくない理由は以下の通りです。
まず、Cloud StorageのAutoclassという機能は存在しません。そのため、ファイルのPIIを非識別化するためには、Cloud DLPのような専用のツールを使用する必要があります。
また、この選択肢ではファイルの非識別化や削除などのプロセスを自動化する手段が明示されていません。
これに対して正解の選択肢は、Cloud DLPを用いて自動的にPIIを非識別化し、元のファイルを削除することを提案しています。
選択肢：Cloud Key Management Service（KMS）のローテーション期間を12カ月に設定し、PIIを含むCloud Storageファイルの暗号鍵を非識別化します。オリジナルの鍵を削除します
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Service（KMS）はデータの暗号化と復号化を行うサービスであり、個人情報（PII）の特定や非識別化は行いません。そのため、ローテーション期間を設定しても12カ月後にPIIを削除することはできないため、この課題を解決する適切な選択肢ではありません。
参考リンク：
https://cloud.google.com/dlp/docs/creating-job-triggers
https://cloud.google.com/dlp/docs/deidentify-sensitive-data
https://cloud.google.com/storage/docs/bucket-archiving-classes
</div></details>

### Q.  問題3: 未回答
あなたの会社では、セキュリティチームとネットワークエンジニアリングチームが、VPC内およびVPC間のすべてのネットワーク異常、VMからVMへの内部トラフィック、インターネット上のエンドロケーションとVM間のトラフィック、VMから本番のGoogle Cloudサービスへのトラフィックを特定する必要があります。
この要件を満たすために、どの方法を使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、VPC内やVPC間、VM間の各種トラフィックの特定が必要であるという状況を対象としています。重要な要点は、単なるロギングや一般的なネットワークの分析ではなく、特定のネットワーク異常や特定のトラフィックをキャプチャするというニーズがあるということです。したがって、選択肢を評価する際には、各トラフィックフローの詳細な分析と識別が可能なツールやサービスに焦点を当てるべきです。
基本的な概念や原則：
Packet Mirroring：Google Cloud上でネットワークトラフィックを複製し、異常検出やパフォーマンス監視に利用できる機能です。VPC内、VPC間、VM間、インターネット上、VMとGoogle Cloudサービス間のトラフィックも検出可能です。
組織ポリシー：Google Cloudのリソースに対するロールベースのアクセス制御の一部です。組織レベルで一貫した制御を提供しますが、ネットワーク異常の特定には用いられません。
VPCフローログ：VPCネットワーク内のIPトラフィックをキャプチャし、ログに記録する機能です。しかし、この機能はネットワーク全体の異常に対してではなく、特定のサブネットでのトラフィックに対して有効化されます。
Cloud Audit Logs：Google Cloudリソースの行動や変更を追跡・ロギングするサービスです。異常ネットワークトラフィックの追跡には直接使われません。
正解についての説明：
（選択肢）
・Packet Mirroringのポリシーを設定します
この選択肢が正解の理由は以下の通りです。
Packet MirroringはGoogle Cloudの特性の一つで、特定のトラフィック（VPC内、VPC間、インターネット上のエンドロケーションと仮想マシン（VM）間のトラフィックやVMからGoogle Cloudのサービスへのトラフィックなど）を複製し、指定した収集ポイントに送信する機能を提供します。これにより、セキュリティチームとネットワークエンジニアリングチームは、移動中の情報の詳細を理解し、必要に応じて異常を特定することができます。異常検知、アプリケーションパフォーマンスのモニタリング、障害検出、セキュリティ監視などに役立ちます。
したがって、Packet Mirroringのポリシーを設定することは、これらの要件を満たす最も適切な手段と言えます。
不正解についての説明：
選択肢：組織ポリシーの制約を定義します
この選択肢が正しくない理由は以下の通りです。
組織ポリシーの制約は、リソースに設定するGoogle Cloudポリシーを定義し、リソースの管理を集中化することを目的としています。しかし、ネットワーク異常の検出や特定のトラフィックの特定には使用できません。
一方、Packet Mirroringはネットワークトラフィックを複製し監視するための機能で、要件を満たします。
選択肢：サブネットでVPCフローログを有効にします
この選択肢が正しくない理由は以下の通りです。
VPCフローログを有効化すると、IPレベルのトラフィックの流れを追跡できますが、これは個々のパケットの詳細な情報を提供しません。その点で、Packet Mirroringは特定の流れを複製し、より深く検査する手段を提供するため、ネットワーク異常や特定のトラフィックを詳細に把握するためには有用です。
選択肢：Cloud Audit Logsの監視と分析を使用します
この選択肢が正しくない理由は以下の通りです。
Cloud Audit Logsは主にGoogle CloudのAPI呼び出しなどを記録し、ユーザーやサービスアカウントによる活動の監視と追跡を目的としています。
それに対し、要件はネットワーク異常やトラフィックの特定という点に集中していて、Packet Mirroringのポリシーを設定することでこれらを満たすことができます。
参考リンク：
https://cloud.google.com/vpc/docs/packet-mirroring
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/logging/docs/audit
</div></details>

### Q.  問題4: 未回答
あなたの会社は最近、サービスアカウントキーの使用を最小限に抑えるセキュリティポリシーを発表しました。オンプレミスのWindowsベースのアプリケーションがGoogle Cloud APIと相互作用しています。オンプレミスのIDプロバイダーとワークロードIDフェデレーション（WIF）を実装する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミスのWindowsベースのアプリケーションがGoogle Cloud APIと相互作用できるようにするため、また、サービスアカウントキーの使用を最小限に抑えるセキュリティポリシーを遵守するための適切な手順を問われています。オンプレミスのIDプロバイダーとワークロードIDフェデレーションを使用する要件があります。ここでは、Active Directoryフェデレーションサービス（ADFS）またはOpenID Connect（OIDC）を使用したフェデレーションの設定方法を必要としますが、どのように設定すればセキュリティポリシーに適合するかを正しく理解することが求められています。
基本的な概念や原則：
サービスアカウント：Google CloudのAPIとのやり取りを行うための特殊なアカウントです。ワークロードがGoogleのサービスと相互作用するために使用します。
Active Directoryフェデレーションサービス（ADFS）：企業のActive DirectoryとCloudサービスの間のフェデレーション認証を実現するWindows Server機能です。ユーザーは一度ログインすれば社内外のさまざまなサービスをシームレスに利用できます。
ワークロードIDプール：ワークロード（オンプレミスやクラウドのアプリケーションやVMなど）がGoogleのサービスと直接やり取りできるように認証と認可を行う仕組みです。
サービスアカウントの偽装：特定のサービスアカウントの権限を引き継いで操作を行う機能です。偽装することで、そのサービスアカウントが持つ権限でAPIを利用できます。
OpenID Connect（OIDC）：ユーザー認証情報を交換するためのシンプルな識別層で、OAuth 2.0プロトコルを拡張しています。ただし、Google CloudではADFSが推奨されます。
セキュリティポリシー：組織のセキュリティ要件を明確に定義した文書です。このケースでは、サービスアカウントキーの使用を制限するというポリシーが適用されています。
プリンシパル：セキュリティモデルにおける行動主体で、エンティティ（ユーザー、サービスアカウントなど）のことを指します。プリンシパルは特定の権限と関連付けられ、アクセス制御の対象となります。
正解についての説明：
（選択肢）
・企業のActive Directoryフェデレーションサービス（ADFS）でワークロードIDプールを設定します。プール内のプリンシパルにGoogle Cloudサービスアカウントを偽装させるルールを設定します
この選択肢が正解の理由は以下の通りです。
まず、企業のActive Directoryフェデレーションサービス（ADFS）は一般的にオンプレミス環境で使用されるIDプロバイダーであり、Windowsベースのアプリケーションと互換性が高いです。これはWindowsベースのアプリケーションのIDフェデレーションの要件を満たします。
また、ワークロードIDプールの設定は、Google Cloud APIでの認証を行うためのものであり、これはワークロードIDフェデレーション（WIF）の実装条件を満たします。
さらに、プリンシパル（ユーザーやサービス）にGoogle Cloudサービスアカウントを偽装させるルールを設定することで、安全かつ効率的にGoogle Cloud APIを使用できます。
そして、最も重要な点として、サービスアカウントキーの使用を最小限に抑えることが可能なため、会社のセキュリティポリシーに適合しています。これによって、セキュリティリスクが低減され、安心してGoogle Cloud APIを利用できます。
不正解についての説明：
選択肢：企業のActive Directoryフェデレーションサービス（ADFS）でワークロードIDプールを設定します。プール内のすべてのプリンシパルをGoogle Cloudサービスアカウントになりすます
この選択肢が正しくない理由は以下の通りです。
全てのプリンシパルをGoogle Cloudサービスアカウントになりすますと、セキュリティポリシーの目的である"サービスアカウントキーの使用を最小限に抑える"の達成が難しくなります。
正解の選択肢のように、対象となるプリンシパルにのみ偽装させるルールを設定することで、セキュリティを確保しながら要件を満たすことができます。
選択肢：同じマシン上でOpenID Connect（OIDC）サービスを使用してワークロードIDプールをセットアップします。プール内のプリンシパルにGoogle Cloudサービスアカウントを偽装させるルールを設定します
この選択肢が正しくない理由は以下の通りです。
同じマシン上でOpenID Connect（OIDC）サービスを使用してワークロードIDプールを設定すると言っているが、OpenID Connectは認証フレームワークであり、ユーザーのIDをフェデレーションするためのフレームワークではないからです。この要件では、企業のActive Directoryフェデレーションサービス（ADFS）を使用する方が、一貫性のある権限の制御やポリシー適用を実現できます。
選択肢：同じマシン上でOpenID Connect（OIDC）サービスを使用してワークロードIDプールをセットアップします。プール内のすべてのプリンシパルをGoogle Cloudサービスアカウントになりすます
この選択肢が正しくない理由は以下の通りです。
企業が既にActive Directoryフェデレーションサービス（ADFS）を使用しているので、新たにOpenID Connect（OIDC）サービスをセットアップするのは冗長であり、また、構成や管理の面で追加の工数が必要となります。既存のADFSを利用することで、新規のセットアップ作業を削減し、必要なフェデレーションを維持することができます。
参考リンク：
https://cloud.google.com/iam/docs/workload-identity-federation
https://cloud.google.com/iam/docs/impersonating-service-accounts
https://cloud.google.com/docs/authentication/production#auth-cloud-implicit-python
</div></details>

### Q.  問題5: 未回答
あなたはセキュリティチームの一員で、プロジェクトAのCloud StorageバケットがプロジェクトBからしか読み取れないようにしたいと考えています。また、ユーザーが正しい認証情報を持っていても、Cloud Storageバケット内のデータにネットワーク外のCloud Storageバケットからアクセスしたり、Cloud Storageバケットにコピーしたりできないようにしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ある特定のプロジェクト間だけでCloud Storageバケットへのアクセスを制限し、それ以外からのアクセスやデータのコピーを防ぐ方法を求められています。問題のキーは、Cloud Storageバケットへのアクセスをどう制限し、また制限範囲をどのように設定すべきかです。セキュリティの観点から、ネットワーク外からの不正なアクセスを防ぐ必要があるという前提も理解しておくと良いでしょう。それぞれの選択肢がその要件をどのように満たすかを評価していきます。
基本的な概念や原則：
VPC Service Controls：Google Cloud上の資源に対する信頼できないネットワークからのデータエクストリームのリスクを軽減します。これにより、セキュリティ境界を設定し、その境界を越えたデータ流出を防止できます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。高い耐久性とスケーラビリティを備えています。
VPC：Virtual Private Cloud（VPC）は、Google Cloud上で定義されたプライベートネットワークスペースで、Google Cloudのリソースを仮想ネットワーク上に配置できます。
ドメイン制限共有：特定のドメイン内からのリクエストだけを許可し、他のドメインからのリクエストをブロックする機能です。ただし、これはCloud Storageバケット間の通信には適用できません。
プライベートアクセス：VPCネットワークのリソースがGoogle Cloudのサービスへの非インターネットルートを使用することを可能にします。しかし、これはプロジェクト間の通信の制御には使用できません。
VPCピアリング：VPCネットワークを相互に接続する機能で、異なるプロジェクト間や異なる組織間でもネットワークトラフィックがGoogleのネットワーク内を通過します。この機能を使用しても、Cloud Storageバケットのアクセス制御は行えません。
ファイアウォールルール：VPCネットワーク内外からのネットワークトラフィックを制御する機能です。ただし、Cloud Storageバケットに対するアクセス権を制限するためには、VPC Service Controlsを使用する必要があります。
正解についての説明：
（選択肢）
・VPC Service Controlsを有効にし、プロジェクトAとBで境界を作成し、Cloud Storageサービスを含めます
この選択肢が正解の理由は以下の通りです。
まず、VPC Service ControlsはGoogle Cloudのサービスを仮想的な境界で囲むことができ、境界外からのデータアクセスを制御する機能を提供します。これにより、プロジェクトAとBの間で境界を作成することで、その他のプロジェクトからのアクセスを防止することが可能となります。これは、プロジェクトAのCloud Storageバケットに対するデータの読取りをプロジェクトBからのみに限定したいという要件を満たします。
また、VPC Service Controlsはユーザーが正しい認証情報を持っていても、ネットワーク外のCloud StorageバケットからCloud Storageバケット内のデータにアクセスしたり、そこへコピーしたりすることを防止します。これにより、インターネット越しにデータを取り出されるリスクを減らすことができます。
したがって、VPC Service Controlsを有効にし、プロジェクトAとBで境界を作成し、Cloud Storageサービスを含めることが、この問題の要件を満たす最善の方法です。
不正解についての説明：
選択肢：Cloud Storageバケットで、ドメイン制限共有組織ポリシーとバケットポリシーのみを有効にします
この選択肢が正しくない理由は以下の通りです。
ドメイン制限共有組織ポリシーやバケットポリシーだけでは、データアクセスを制限するためのネットワークの境界を作成することはできません。VPC Service Controlsを使用することで、ネットワークの境界を作成し、Cloud Storageバケットへのアクセスを制限することが可能となります。
選択肢：厳密なファイアウォールルールでプロジェクトAとBのネットワークでプライベートアクセスを有効にし、ネットワーク間の通信を許可します
この選択肢が正しくない理由は以下の通りです。
ファイアウォールルールとプライベートアクセスはネットワークレベルでの制御であり、Cloud Storageのバケットへの特定の種類のアクセス制限（データエクスフィルトレーション）を行う能力はありません。
それに対して、VPC Service ControlsはGoogle Cloudサービスに対するアクセス制限を可能にします。
選択肢：プロジェクトAとBのネットワーク間でVPCピアリングを有効化し、厳格なファイアウォールルールでネットワーク間の通信を許可します
この選択肢が正しくない理由は以下の通りです。
VPCピアリングはプロジェクト間のネットワーク接続を設定しますが、Cloud Storageバケットへのアクセス制御を行う機能はありません。
一方、VPC Service Controlsはサービス間のデータ漏洩を防止するためのサービスであり、この問題の要件を満たすための最適な選択肢です。
参考リンク：
https://cloud.google.com/storage/docs/vpc-service-controls
https://cloud.google.com/vpc-service-controls/docs/overview
https://cloud.google.com/storage/docs/access-control/
</div></details>

### Q.  問題6: 未回答
PCI DSS要件を満たすために、顧客はすべての送信トラフィックが許可されていることを確認したいと考えています。
追加的な代替コントロールなしでこの要件を満たすクラウドオファリングはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、PCI DSS要件を満たすために許可されている送信トラフィックを確認するために使用できるクラウドオファリングを特定するよう求められています。注意すべきは、"追加的な代替コントロールなしで"という表現であり、これにより提供された選択肢の中から何も追加しなくてもPCI DSS要件を満たせることが明確であるサービスのみを選ぶべきであることが解ります。選択肢を見るとき、そのクラウドオファリングが通常どのような機能や制御を提供しているかをよく理解していることが重要です。
基本的な概念や原則：
PCI DSS：クレジットカード情報を扱うすべての企業が遵守する必要があるセキュリティ標準です。データを保護し、カードホルダーの情報を盗難から守るための広範囲な要件を提供します。
Compute Engine：Google Cloudの仮想マシンを提供するIaaSサービスです。全ての送信トラフィックを許可し、ユーザーがネットワークの設定やセキュリティの制御を持つことができます。
Google Kubernetes Engine（GKE）：Google Cloudのコンテナ化されたアプリケーションを管理し、運用するためのPaaSサービスです。送信トラフィックの許可と管理に柔軟性を持たせることが可能です。
App Engine：Google CloudのフルマネージドなPaaSサービスで、アプリケーション開発、デプロイ、スケーリングを簡素化します。送信トラフィックの制御が限定的で、全てのトラフィックを許可する設定が困難です。
Cloud Functions：Google CloudのFaaS（Function as a Service）で、イベント駆動のワークロードを運用します。全ての送信トラフィックの許可は難しく、主にステートレスな関数の実行に使用されます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。全ての送信トラフィックを許可することは基本的に不可能で、データを保存、取得するためのサービスです。
正解についての説明：
（選択肢）
・Compute Engine
・Google Kubernetes Engine
この選択肢が正解の理由は以下の通りです。
まず、Compute EngineはGoogle CloudのIaaSサービスで、ユーザーは自分で許可されたトラフィックをコントロールすることが可能です。
したがって、Compute EngineはPCI DSS要件を満たすためのセキュリティ制御を提供します。
また、Google Kubernetes Engine（GKE）はコンテナ化されたアプリケーションを管理するためのプラットフォームであり、ネットワークポリシーを設定することで送信トラフィックの制御が可能です。これにより、PCI DSSの要件を満たすことができます。両サービスともに、セキュリティの管理とコントロールが高度にカスタマイズ可能であり、すべての送信トラフィックが許可されていることを確認する要件を満たすことが可能です。
不正解についての説明：
選択肢：App Engine
この選択肢が正しくない理由は以下の通りです。
App EngineはフルマネージドなPaaSであり、基礎的なネットワーク設定は完全にGoogleによりコントロールされています。
したがって、ユーザーは送信トラフィックを直接管理または監視することができません。
一方、Compute EngineやGoogle Kubernetes EngineはIaaS、CaaSオファリングであり、送信トラフィックの管理が可能です。
選択肢：Cloud Functions
この選択肢が正しくない理由は以下の通りです。
Cloud FunctionsはFaaS、つまりFunction as a Serviceであり、ユーザはサーバ管理やトラフィック管理について制御することができません。これは、PCI DSS準拠のために送信トラフィックを管理する必要がある企業にとっては適切ではありません。
これに対し、Compute EngineやGoogle Kubernetes Engineでは、送信トラフィックを管理することができます。
選択肢：Cloud Storage
この選択肢が正しくない理由は以下の通りです。
Cloud Storageはデータを保存するためのサービスであり、送信トラフィックの制御はその主要な機能ではありません。
一方、Compute EngineやGoogle Kubernetes Engineはネットワーク設定が可能で、送信トラフィックを許可する設定を行うことができます。
参考リンク：
https://cloud.google.com/compute/docs/vpc
https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview
https://www.pcisecuritystandards.org/documents/PCI_DSS_v3-2-1.pdf
</div></details>

### Q.  問題7: 未回答
会社で承認されたコンピュートイメージを、イメージリポジトリとして使用されている1つのGoogle Cloudプロジェクトに保存しています。このプロジェクトはVPC Service Controlsで保護され、組織内の他のプロジェクトとともに境界内に存在します。これにより、他のプロジェクトはイメージリポジトリプロジェクトからイメージをデプロイできます。あるチームが、外部のGoogle Cloudの組織に保存されているサードパーティのディスクイメージをデプロイすることが必要になりました。ディスクイメージを境界にデプロイできるように、ディスクイメージへの読み取りアクセスを許可する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudのVPC Service Controlsを使用して、一つの境界に囲まれたプロジェクトから別のGoogle Cloudの組織に保管されたディスクイメージへの読み取りアクセスを許可する方法を問われています。そのためには、VPC Service Controlsにおけるエグレス（出口）ルールに関する知識が必要です。また、囲いの更新（境界の更新）を行う場合、設定すべきフィールドやパラメーターについて理解していなければなりません。
基本的な概念や原則：
VPC Service Controls：Google Cloudのサービスとデータへのアクセスを制限してデータ漏洩やデータ移動を防ぐためのサービスです。
境界：VPC Service Controlsで設定するもので、特定のGoogle Cloudリソースへのアクセスを規制する範囲を定義します。
egressToフィールド：境界の設定に使用され、境界の外側への出力トラフィック（egress）を指定します。
egressFromフィールド：境界の設定に使用され、境界の内側からの出力トラフィック（egress）を指定します。
compute.googleapis.com：Compute Engine APIのサービス名であり、このAPIを通じてCompute Engineのリソースを操作することができます。
正解についての説明：
（選択肢）
・1. 境界を更新します
2. 外部Google Cloudプロジェクト番号を許可されたリソースとして含めるようにegressToフィールドを構成し、serviceNameをcompute.googleapis.comに設定します
3. egressFromフィールドを構成して、identityTypeをANY_IDENTITYに設定します
この選択肢が正解の理由は以下の通りです。
まず、VPC Service Controlsは、もしディスクイメージが境界（perimeter）の外にあるGoogle Cloudのプロジェクトにある場合、そのリソースにアクセスできないうように制限しています。そのため、特定の外部リソースへのアクセスを許可するためには、そのリソースを持つプロジェクトのプロジェクト番号を境界のegressToフィールドに追加する必要があります。serviceNameをcompute.googleapis.comに設定するのは、Disk ImagesはCompute Engineの一部であるためです。
次に、egressFromフィールドを構成してANY_IDENTITYを指定することで、境界内の任意のIDエンティティ（例えばユーザーやサービスアカウントなど）がegressToで指定したリソースにアクセスできるようになります。これにより、他のプロジェクトがイメージリポジトリプロジェクトからイメージをデプロイできるようになります。
したがって、境界を更新し、適切にegressToとegressFromを設定することで、サードパーティのディスクイメージへの読み取りアクセスを許可し、ディスクイメージを境界内にデプロイできるようにすることができます。
不正解についての説明：
選択肢：組織ポリシーconstraints/compute.trustedImageProjectsを使用して、外部プロジェクトを許可します
この選択肢が正しくない理由は以下の通りです。
compute.trustedImageProjectsポリシーは主に自分の組織のプロジェクトで使用されるイメージのソースを制御するためのもので、他の組織とのディスクイメージのアクセスには適用できません。そのため、VPC Service Controls境界のegressToとegressFromフィールドを更新して外部プロジェクトへのアクセスを許可するのが適切です。
選択肢：1. 境界を更新します
2. ingressFromフィールドを構成して、identityTypeをANY_IDENTITYに設定します
3. 外部Google Cloudプロジェクト番号を許可されたリソースとして含めるようにingressToフィールドを構成し、serviceNameをcompute.googleapis.comに設定します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsでデータを境界外に送信するためには、egressToとegressFromフィールドを設定します。そのため、ingressFromとingressToフィールドを設定することにより、境界外からの接続の許可が行われますが、この場合は境界外にデータを送信することが目的です。この選択肢はブロックしたい逆の方向についての設定になってしまいます。
選択肢：1. 境界を更新します
2. egressToフィールドを構成して、identityTypeをANY_IDENTITYに設定します
3. 外部Google Cloudプロジェクト番号を許可されたリソースとして含めるようにegressFromフィールドを構成し、serviceNameをcompute.googleapis.comに設定します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsの設定において、egressToフィールドは出力トラフィックの宛先を指定しますが、egressFromフィールドは出力トラフィックの源を指定します。
したがって、外部のGoogle Cloudプロジェクト番号を許可されたリソースとして含めることは、egressToフィールドで設定するべきです。不正解の選択肢は、これらのフィールドの使い方を誤解しています。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs
https://cloud.google.com/vpc-service-controls/docs/perimeter-configuration
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
</div></details>

### Q.  問題8: 未回答
あなたの会社は臨床試験を実施しており、BigQueryに保存されている最近の試験結果を分析する必要があります。薬を服用した間隔には、開始日と中止日が含まれています。間隔データは分析にとって重要ですが、特定の日付は特定のバッチを特定し、バイアスを引き起こす可能性があります。各行の開始日と終了日を難読化し、間隔データを保持する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、プライバシー保護とデータ分析の両方のニーズを満たす必要があります。特に、日付情報を難読化することでプライバシーを保護する一方で、間隔データを保持することで分析可能性を維持しなければなりません。提示された選択肢を見る際には、これらの要件を全て満たす解決策を選択する必要があります。具体的には、日付を難読化する手法として適切なものは何か、そしてその手法が間隔データを保持することが可能なのか、という2つの観点を考慮して見るべきです。
基本的な概念や原則：
日付シフト：個人情報を保護するために日付値をランダムにシフトする技術です。開始日と終了日間の間隔は保持しながら、個々の日付の特定性を難読化します。使用する際は、被験者の固有IDをコンテキストとして設定する必要があります。
固有ID：データセットの各エントリーを一意に識別するための識別子です。このIDを利用して、データの一貫性を確保しつつも、特定の個人を特定できないようにすることができます。
TimePartConfig：日付データから特定の部分（年、月、日など）を抽出するために使用される設定です。これを使用して日付データを操作することは可能ですが、クリニカルデータに対するシフトの要件を満たすためには不適切です。
ビケット：データを管理するための論理的なユニットです。ビケットへの値のシフトは、データの一貫性を維持しながら値を難読化するための方法です。ただし、クリニカルデータのように日付間の間隔を保持する必要がある場合には不適切です。
フォーマット保持暗号化（FPE）：データの形式を保持しながらデータを暗号化する技術です。FFX（Feistel Finite Set Encryption）はその一つです。これはデータの保護に役立ちますが、日付データの間隔を保持しながら特定性を難読化するためには不適切です。
正解についての説明：
（選択肢）
・被験者の固有IDをコンテキストに設定し、日付シフトを使用します
この選択肢が正解の理由は以下の通りです。
本問の要件は、個々の患者の薬物服用期間（開始日と終了日）を維持しつつ、特定の日付を匿名化（難読化）することです。Google Cloudで提供する日付シフトは、それぞれの被験者に対して一定のシフトを提供し、特定の日付を匿名化しつつ同一患者内での日付間隔を保持する機能です。
被験者の固有IDをコンテキストとして設定することにより、同一被験者に対する日付シフトは一貫したものとなります。つまり、特定の被験者の薬物服用期間は原実データと同じ間隔を保ちながら、特定の日付が匿名化されるため、要件を満たすことができます。
この機能は、治験データのプライバシーを守りつつ、重要な分析（薬物服用期間など）を妨げないという研究者にとって重要な課題を解決します。以上の理由から、この選択肢が正解となります。
不正解についての説明：
選択肢：各日付フィールドからTimePartConfigを使用して日付を抽出し、ランダムな月と年を追加します
この選択肢が正しくない理由は以下の通りです。
各日付フィールドからTimePartConfigを使用して日付を抽出し、ランダムな月と年を追加します、という方法では日付間隔が保持されません。
一方、被験者の固有IDをコンテキストに設定し、日付シフトを使用すると、日付間隔は保持されつつ、特定の日付は難読化されるため要件に適合します。
選択肢：バケットを使用して、初期値に基づいて所定の日付に値をシフトします
この選択肢が正しくない理由は以下の通りです。
バケットを使用して初期値に基づいて日付をシフトすると、開始日と終了日の関係性や間隔が保持されない可能性があります。正解の日付シフトは個々の被験者の固有IDをコンテキストに設定し、開始日と終了日の間隔を保持しつつも難読化を可能にします。
選択肢：フォーマット保持暗号化（FPE）のFFXモードを使用し、データの一貫性を維持します
この選択肢が正しくない理由は以下の通りです。
フォーマット保持暗号化（FPE）のFFXモードは、データの元の形式を保持しつつ暗号化を行いますが、日付の間隔情報を保持できません。
それに対して、日付シフトは特定の日付を難読化しつつ、日付間隔の情報を保持することが可能であり、この問題の要件を正確に満たします。
参考リンク：
https://cloud.google.com/bigquery/docs/tokenizing-data
https://cloud.google.com/bigquery/docs/reference/standard-sql/date_functions
https://cloud.google.com/blog/products/data-analytics/tips-for-using-the-bigquery-data-transfer-service
</div></details>

### Q.  問題9: 未回答
あなたの組織はActive Directoryを使用しており、SAML（Security Assertion Markup Language）を構成したいと考えています。すべてのユーザーにシングルサインオン（SSO）を設定し、実施する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Active Directoryを利用した状況でのSAMLを用いたシングルサインオン（SSO）の実装方法について問われています。重要なのは、正しいSAMLの構成方法と特性を理解し、それを用いてSSOの設定を行うことが求められています。その一方で、OpenID Connectに関する選択肢や、適切とは言えないSAML構成やプロファイル管理について述べられている選択肢等は注意が必要です。問題文の条件に対して最も適合する方法を選ぶ際に、SAMLとActive Directory、そしてSSOの概念とそれぞれの特性を念頭に置いて解答を行います。
基本的な概念や原則：
Active Directory：マイクロソフトが提供するディレクトリサービスで、ユーザーアカウントやコンピュータなどのリソースを一元的に管理します。
SAML（Security Assertion Markup Language）：セキュリティ情報を表現するためのXMLベースの標準で、認証、認可、アサーションを提供します。
シングルサインオン（SSO）：一度のログインで複数の異なるシステムやサービスにアクセスできる認証方法です。
SAMLプロファイル：SAMLを用いた認証やアサーションの適用ルールを定義したものです。
X.509証明書：公開鍵暗号方式におけるデジタル署名や暗号化を行うためのソフトウェア証明書です。
IdP（Identity Provider）：ユーザーのIDやパスワードなど、個々のユーザーの識別情報を管理する仕組みやその提供者のことです。
エンティティIDとACS URL：SAML認証において、サービスを一意に識別するエンティティIDと認証応答を受け取るサービスのURL（ACS URL）の設定が必要です。
正解についての説明：
（選択肢）
・1. 新しいSAMLプロファイルを作成します
2. サインインページとサインアウトページのURLを入力します
3. X.509証明書をアップロードします
4. IdPでエンティティIDとACS URLを構成します
この選択肢が正解の理由は以下の通りです。
まず、SAMLの設定は複数の手続きに分かれますが、この選択肢はその手続きを総合的にカバーしています。新しいSAMLプロファイルを作成することは、シングルサインオン環境を構築する最初のステップです。
次に、サインインページとサインアウトページのURLを入力することで、ユーザーが可視化するログインとログアウトのロールを果たすページを設定します。
そして、X.509証明書をアップロードすることによって、認証のためのキーペアを提供します。これは、システムが相互認証を確立し、安全な通信を確保するため必要ます。
最後に、IdP（Identity Provider）でエンティティIDとACS（Assertion Consumer Service）URLを構成する事で、SAMLプロファイルのアイデンティティプロバイダとしてActive Directoryの資格情報を使用する設定が完了します。これにより、ユーザーはActive Directoryの資格情報を使用してシングルサインオンが可能となります。
不正解についての説明：
選択肢：1. Active Directory（AD）テナントでOpenID Connect（OIDC）の前提条件を構成します
2. ADドメインを確認します
3. どのユーザーがSAMLを使用するかを決定します
4. 事前構成されたプロファイルを、選択した組織単位（OU）およびグループに割り当てます
この選択肢が正しくない理由は以下の通りです。
OpenID Connect（OIDC）は主に認証を提供し、SAMLは認証だけでなく認可も行うため、問題で要求されているSSOを実施するにはSAMLの設定が必要です。
したがって、OIDCの前提条件を構成するという選択肢はこの問題の解決策としては不適切です。
選択肢：1. 新しいSAMLプロファイルを作成します
2. X.509証明書をアップロードします
3. パスワード変更URLを有効にします
4. IdPでエンティティIDとACS URLを構成します
この選択肢が正しくない理由は以下の通りです。
不正解の選択肢は、サインインページとサインアウトページのURLを入力するステップを含めていません。これはSAML SSOの設定において重要なステップであり、ユーザーが該当URLで認証を受けられるようにする必要があります。
また、パスワード変更URLを有効にするステップはSAML SSOの設定とは関連がありません。このためこの選択肢は不適切です。
選択肢：1. SAMLプロファイルの割り当てを管理します
2. Active Directory（AD）テナントでOpenID Connect（OIDC）を有効にします
3. ドメインを確認します
この選択肢が正しくない理由は以下の通りです。
特に、Active DirectoryのテナントでOpenID Connectを有効にする設定は不適切で、SAMLとOpenID Connectは異なる認証フレームワークであり交換可能ではありません。要件がSAMLの設定を求めているため、この選択肢に含まれるOpenID Connectの設定は必要ありません。
参考リンク：
https://cloud.google.com/identity/saml
https://cloud.google.com/identity/docs/how-to/setup-sso
https://support.google.com/a/answer/60224?hl=en
</div></details>

### Q.  問題10: 未回答
あなたの会社では、従業員が個人所有のコンピュータを使ってGoogle Cloudコンソールにアクセスしています。Google Cloudコンソールにアクセスできるのは、ユーザーが会社から発行されたデバイスのみであることを確認し、有効な企業証明書を持っていることを確認する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、企業のデバイスと証明書を用いたアクセス制限がテーマとなります。従業員が個人所有のコンピュータからGoogle Cloudコンソールにアクセスすることが前提となっていますが、アクセス可能なのは企業から発行のデバイスと特定の証明書を持つ人物のみとなるべきです。このような要件を満たすことが目標となるため、選択肢を判断する際には、これらの制限を実現するための適切なGoogle Cloudの機能を選択する必要があります。
基本的な概念や原則：
BeyondCorp Enterprise：Google Cloudのゼロトラストアクセスソリューションです。ユーザー、デバイス、アプリケーションのコンテキストに基づくセキュリティー決定を可能にします。
アクセスポリシー：特定のリソースへのアクセスを制御するためのルールの集合です。BeyondCorp Enterpriseでは、企業証明書などのデバイス情報を元にしたアクセスポリシーを作成することができます。
アクセスバインディング：アクセスポリシーを特定のリソースに対して適用するための設定です。BeyondCorp Enterpriseでは、作成したアクセスポリシーを利用してアクセスバインディングを作成します。
ゼロトラストアクセス：すべてのアクセスを信頼しないというセキュリティーモデルです。アクセスするたびに認証と認可を強制します。
VPCファイアウォール：仮想プライベートクラウド（VPC）のネットワークトラフィックを制御する機能です。ただし、デバイス証明書の検証には使用できません。
IAM（Identity and Access Management）条件付きポリシー：特定の条件を満たす場合にのみアクセス許可を付与するためのポリシーです。しかし、デバイス証明書の検証には、直接使用することはできません。
正解についての説明：
（選択肢）
・BeyondCorp Enterpriseにアクセスポリシーを実装し、デバイス証明書を検証します。作成したアクセスポリシーでアクセスバインディングを作成します
この選択肢が正解の理由は以下の通りです。
まず、BeyondCorp EnterpriseはGoogle Cloudのゼロトラストアクセス管理ソリューションであり、特定のユーザーが特定のデバイスから特定のアプリケーションにアクセスできるようにするためのアクセスポリシーを設定することが可能です。このアクセスポリシーではデバイス証明書の検証も可能で、従業員が会社から発行されたデバイスかどうか、さらにそのデバイスが有効な証明書を保持しているかどうかをチェックします。
次に、BeyondCorp Enterpriseを使って作成したアクセスポリシーを用いてアクセスバインディングを作成することで、特定のユーザーまたはユーザーグループが指定されたリソースに対するアクセスを制御します。これにより、個人所有のコンピュータからの不適切なGoogle Cloudコンソールへのアクセスを防ぐことができます。
以上の理由から、BeyondCorp Enterpriseにアクセスポリシーを実装し、デバイス証明書を検証してアクセスバインディングを作成することが適切です。
不正解についての説明：
選択肢：VPCファイアウォールポリシーを実装します。パケット検査を有効にし、デバイス証明書を検証して確認するための許可ルールを作成します
この選択肢が正しくない理由は以下の通りです。
VPCファイアウォールポリシーがデバイス証明書の検証を行う機能はありません。
また、パケット検査を用いても、ユーザーデバイスの検証といった目的を達成することは出来ません。
一方、BeyondCorp Enterpriseはユーザーやデバイスに対するセキュリティポリシーを柔軟に適用できるため、この要件を達成するには適しています。
選択肢：アクセスコンテキストから証明書を検証する組織ポリシーを導入します
この選択肢が正しくない理由は以下の通りです。
組織ポリシーはリソースの使用を規制しますが、特定のデバイスからのアクセス制限や証明書の検証等、ユーザーやデバイスの認証・認可を行う機能はありません。
それに対して、BeyondCorp Enterpriseはアクセスコンテキストに基づいてポリシーを適用し、企業証明書の検証を通してアクセス制御が可能です。
選択肢：デバイス証明書を検証するために、IAM（Identity and Access Management）条件付きポリシーを実装します
この選択肢が正しくない理由は以下の通りです。
IAMの条件付きポリシーでは、ユーザーやサービスアカウントに角度からアクセス制御を行うためのルールを作成しますが、デバイス証明書の検証はサポートしていません。
これに対して、BeyondCorp Enterpriseはユーザーだけでなくデバイスに基づくアクセス制御を行う機能を提供しています。
参考リンク：
https://cloud.google.com/beyondcorp-enterprise/docs/access-policies-introduction
https://cloud.google.com/identity-aware-proxy/docs/device-policy
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations
</div></details>

### Q.  問題11: 未回答
サードパーティのIDプロバイダ（IdP）からCloud IdentityにIDを同期する予定です。一部の従業員が会社のメールアドレスを使用して、Googleサービスにアクセスするためのコンシューマアカウントを設定していることがわかりました。これらのコンシューマアカウントの構成、セキュリティ、およびライフサイクルを組織が確実に管理できるようにする必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、サードパーティのIDプロバイダからCloud IdentityにIDを同期する際に、どのようにコンシューマアカウントを管理すべきかを問いています。この問題に対しては、既存のコンシューマアカウントの管理方法と、それを組織の管理下に置く方法について理解する必要があります。キーポイントは、従業員が会社のメールアドレスを使用してGoogleサービスにアクセスするコンシューマアカウントの管理です。そのため、答えはそれらのアカウントを組織が確実に管理するための最も効果的な方法に導かれます。
基本的な概念や原則：
Cloud Identity：Google CloudのID管理システムです。ユーザー、グループ、アプリケーションの認証、承認、管理が可能です。
IDプロバイダ（IdP）：ユーザーの認証情報を管理するサービスです。SAMLやOpenID Connectといった認証プロトコルを使用して、ユーザーのIDを検証します。
コンシューマアカウント：個々のユーザーが個人用途で作成するGoogleアカウントです。これに対して、組織がユーザー用に作成するアカウントをエンタープライズアカウントと呼びます。
移管ツール：Google Workspaceの管理者が未管理のGoogleアカウントを該当する組織に移管するためのツールです。
Google Cloud Directory Sync（GCDS）：Google Workspaceと既存のLDAPディレクトリの間でユーザー、グループ、組織単位を同期するツールです。ただし管理されていない消費者アカウントの移行には適していません。
アカウントの照合：Cloud IdentityとIdP間でアカウントの存在を比較し、不一致を調整する行為です。存在するアカウントの一致を確認し、必要に応じてアカウントを移管または削除します。
正解についての説明：
（選択肢）
・Cloud Identityには存在するがサードパーティのIdPには存在しないアカウントを照合します
・移管ツールを使用して、企業の従業員を招待し、管理されていないコンシューマーアカウントを企業ドメインに移管します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Identityは、企業がユーザーの認証とアクセス管理を行うためのサービスです。サードパーティのIdPからCloud IdentityへのID同期を行うことで、企業はIDを一元管理できるようになります。一部の従業員が自身の企業のメールアドレスでGoogleサービスにアクセスするための個人アカウントを設定している場合、それらのアカウントは企業の管理下にないため、それらのアカウントのセキュリティとライフサイクルを管理できません。そこで、Cloud Identityには存在するがサードパーティのIdPには存在しないアカウントを照合することが求められます。これにより、そのような個人アカウントを特定できます。
次に、それらの個人アカウントを企業の管理下に置くためには移管が必要です。Googleは"移管ツール"を提供しており、これを使用して管理されていないコンシューマアカウントを企業ドメインに移管します。このツールを使用することで、管理されていないコンシューマアカウントの所有者である従業員に移管を求める招待が送られ、その結果これらのアカウントを企業が管理することが可能となります。これにより、従業員が企業ドメインでGoogleのサービスに利用しているアカウントの持つ構成、セキュリティ、とライフサイクルを確実に管理することができます。
不正解についての説明：
選択肢：企業の従業員に、管理されていない消費者アカウントの削除を義務付けます
この選択肢が正しくない理由は以下の通りです。
単に従業員に消費者アカウントの削除を義務付けることでは、アカウントの構成、セキュリティ、ライフサイクルを企業が確実に管理するという要件は満たされません。
また、それは利便性や生産性の低下を引き起こす可能性があるため、企業の利益には繋がりません。
選択肢：IDを同期する前に、サードパーティIdPで管理されていないコンシューマアカウントを削除します
この選択肢が正しくない理由は以下の通りです。
コンシューマアカウントを削除すると、そのアカウントに関連付けられた全てのデータとサービスも削除されてしまうため、その後の管理が不可能となるからです。正解選択肢のように移管ツールを使ってアカウントを移管すれば、アカウントとそれに関連するデータを維持したままで組織の管理下に置くことが可能です。
選択肢：Google Cloud Directory Sync（GCDS）を使用して、管理されていない消費者アカウントの電子メールをユーザーエイリアスとして移行します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Directory Sync（GCDS）は基本的にIDの同期のみを行うツールであり、コンシューマアカウントの管理やセキュリティ、ライフサイクルを制御することはできません。そのため、GCDSを用いた方法では要件を満たすことはできません。
参考リンク：
https://cloud.google.com/identity/docs/account-transfer/intro
https://cloud.google.com/identity/docs/how-to/manage-users
https://support.google.com/a/answer/6335621
</div></details>

### Q.  問題12: 未回答
アプリケーションログを、管理者とアナリストの両方がアクセス可能な共有Cloud Storageバケットにバックアップしています。アナリストは、個人を特定できる情報（PII）を含むログにアクセスできません。PIIを含むログファイルは、管理者のみがアクセスできる別のバケットに保存する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、アプリケーションログを安全に管理し、個人を特定できる情報（PII）のアクセス権を制限する方法を問われています。重要なポイントは、管理者とアナリストの両方がアクセス可能な共有バケットと、管理者のみがアクセス可能な別のバケットの二つを適切に利用することです。また、PIIが含まれているかどうかを判定するためのロジックが必要です。これらの要素を踏まえて、適切なGoogle Cloudのサービスを選択し、その設定や動作を理解する必要があります。
基本的な概念や原則：
Cloud Storageバケット：Google Cloudのオブジェクトストレージサービスで、大量の非構造化データを保存し、取り出すことができます。安全性とスケーラビリティを備えています。
Pub/Sub：Google Cloudのリアルタイムメッセージングサービスです。フルマネージドのサービスで、メッセージのパブリッシュとサブスクライブを行うことができます。
Cloud Functions：Google Cloudのサーバーレス実行環境です。特定のイベントに応じて短期間のコードスニペットを実行します。
Cloud Data Loss Prevention（DLP）：Google Cloudのデータ保護サービスです。機密データや個人を特定可能な情報（PII）を自動的に検出、分類、非表示化します。
個人を特定可能な情報（PII）：個々の人を直接または間接に特定可能な情報のことです。適切な取り扱いと保護が法律で求められています。
アクセス管理：特定のユーザーやグループがリソースに対して持つパーミッションを制御することです。Google CloudではIAMによる細かなアクセス制御が可能です。
オブジェクトライフサイクル管理：Cloud Storageでデータの保存期間や状態を自動管理する設定のことです。特定の条件に合致したオブジェクトを自動的に削除するなど、コストとデータ管理を最適化します。
正解についての説明：
（選択肢）
・Pub/SubとCloud Functionsを使って、ファイルが管理者のバケットにアップロードされるたびにCloud Data Loss Preventionスキャンをトリガします。スキャンでPIIが検出されなかった場合は、共有Cloud Storageバケットにオブジェクトを移動させます
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Pub/Subは、アプリケーション間でメッセージの送受信を行うことができます。クラウドバケットで新たなログファイルがアップロードされると、そのイベントをトリガーにPub/Subがメッセージを生成します。このメッセージはCloud Functionsを起動します。Cloud Functionsは、Cloud Data Loss Prevention APIと連携し、PIIを含む可能性のある新規ログファイルをスキャンします。
Cloud Data Loss Prevention APIは、PIIを検出する機能を提供します。スキャンが完了し、PIIが検出されなかった場合、ファイルは共有バケットに移動されます。これにより、管理者とアナリストの両方が安全にアクセスできるようになります。
一方で、PIIが検出された場合、ファイルは元の管理者のバケットに残し、安全性を確保します。
したがって、Pub/Sub、Cloud Functions、Data Loss Prevention APIを使用することで、セキュリティを保ちながらも特定の情報に基づいてデータを適切な場所にルーティングする要件を満たすことが可能となります。
不正解についての説明：
選択肢：ログを共有バケットと管理者のみがアクセス可能なPIIを含むバケットの両方にアップロードします。Cloud Data Loss Prevention APIを使用して、ジョブのトリガーを作成します。共有バケットからPIIを含むファイルを削除するようにトリガーを設定します
この選択肢が正しくない理由は以下の通りです。
ログを最初に両方のバケットにアップロードすると、アナリストがPIIを含むログに一時的にでもアクセスできる可能性があります。これは要件に違反します。既存のファイルをスキャンして削除するよりも、PIIを含む可能性のあるファイルをまず別のバケットにアップロードし、その後でPIIが含まれていないと確認した上で共有バケットに移動するのが適切です。
選択肢：共有バケット上で、PIIを含むオブジェクトを削除するようにオブジェクトライフサイクル管理を設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Storageのオブジェクトライフサイクル管理は、オブジェクトのバージョン管理やストレージクラスの変更など、特定の条件に基づいて行われます。しかし、特定の情報（この場合はPII）を含むファイルを自動的に識別し、削除する機能は提供していません。近年の正解と比較すると、PIIを正確に検出して適切に分類する能力に欠けています。
選択肢：共有バケット上で、PIIがアップロードされたときのみトリガーされるCloud Storageトリガーを設定します。Cloud Functionsを使ってトリガーを捕捉し、PIIを含むファイルを削除します
この選択肢が正しくない理由は以下の通りです。
この選択肢ではPIIを含むファイルが単に削除されますが、実際にはそのファイルは管理者のみがアクセス可能なバケットに保存される必要があります。
また、Cloud StorageトリガーがPIIを直接検出する機能はないため、PIIの検出はCloud Functionsだけに頼ることができません。
参考リンク：
https://cloud.google.com/storage/docs/using-pubsub-notification
https://cloud.google.com/dlp/docs/quickstart-client-libraries
https://cloud.google.com/functions/docs/calling/pubsub
</div></details>

### Q.  問題13: 未回答
あなたの会社の最高情報セキュリティ責任者（CISO）は、会社のグローバル展開計画に影響する規制要件のため、ビジネスデータを特定の場所に保存しなければならないという要件を作成しました。この要件を実施するための詳細を検討した結果、以下のことが判明しました：
- 対象サービスはGoogle Cloud Data Residency Termsに含まれています。
- ビジネスデータは、同じ組織内の特定の場所に保存され続けます。
- フォルダ構造には、複数のデータ保存場所が含まれる可能性があります。
あなたはリソースロケーションの制限組織ポリシー制約を使用する予定です。
リソース階層のどのレベルで制約を設定する必要がありますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのデータ保管に関する規制要件が提示され、その対応策としてリソースの位置を制約する必要がある状況を想定しています。求められているのは、リソースロケーションの制約をどの階層レベルで設定すべきかということです。問題文で提供される情報の中には、データ保管の場所が特定の場所に限定され、その要件がGoogle Cloud Data Residency Termsにかかるサービスに影響を与え、また、同一組織の内部でのデータ移動も規制されるという事項が含まれています。これらの情報を基に適切な制約の設定レベルを選択することが求められています。
基本的な概念や原則：
リソースロケーションの制限組織ポリシー制約：Google Cloudリソースが特定の地理的ロケーションに存在することを保証するための制約です。これを使用すると、特定のリージョンまたはゾーンにリソースの作成を制限することができます。
プロジェクト：Google Cloudリソースを整理し、アクセスを制御するための単位です。特定の場所に関連するリソースは同じプロジェクト内に存在すべきです。
フォルダ：Google Cloudのリソース階層における組織単位の一部です。フォルダには複数のプロジェクトを含めることが可能で、階層化のために使用されます。
リソース：Google Cloudの各サービスや機能として存在するエンティティです。インスタンス、データベース、ストレージバケットなどが該当します。
組織：Google Cloudのリソースを管理するための最上位の単位です。組織全体でポリシーを適用したり、アクセスを制御したりするために使用されます。
正解についての説明：
（選択肢）
・プロジェクト
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの組織ポリシーサービスを利用すると、組織の要件に従ってリソースの設置場所を制限することが可能になります。組織ポリシーの制約は、組織、フォルダ、プロジェクトのいずれのレベルでも設定できます。しかし、問題の状況では、同じ組織内でビジネスデータの保存場所が異なる可能性があり、フォルダ内には複数のデータ保存場所が含まれる可能性が示されています。これにより、組織レベルまたはフォルダレベルで制約を設定すると、すべてのプロジェクトが同じ制約を受け、必要な柔軟性が失われる可能性があります。そのため、プロジェクトレベルで制約を設定することが最善の解答となります。それぞれのプロジェクトで異なる保存場所を持つことが可能になり、規制要件に準拠しつつ、適切な場所にデータを保存するための柔軟性を確保できます。
不正解についての説明：
選択肢：フォルダ
この選択肢が正しくない理由は以下の通りです。
フォルダレベルでの制約設定は可能ですが、ビジネスデータが同じ組織内の特定の場所に保存され続けるという要件を満たさない可能性があります。フォルダ内には複数のプロジェクトや別のフォルダが含まれる可能性があり、その中に異なるデータ保存場所が含まれている場合もあります。そのため、より細かい制御を可能にするプロジェクトレベルでの制約設定が適切です。
選択肢：リソース
この選択肢が正しくない理由は以下の通りです。
リソース階層では、リソースロケーションの制限組織ポリシー制約を設定することはできません。プロジェクトレベルで制約を設定することが求められており、これにより取り扱いデータの地理的な保存場所を制御することが可能となります。
選択肢：組織
この選択肢が正しくない理由は以下の通りです。
制約を組織レベルで設定すると、全てのプロジェクトとフォルダに制約が適用されます。しかし問題文には、特定の場所にデータを保存し続ける必要があるとあり、フォルダ内には複数のデータ保存場所が含まれる可能性があるため、組織レベルで設定すると、必要な柔軟性を失ってデータの保存場所を細かく制御することができません。よって、制約はプロジェクトレベルで設定するのが適切です。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/resource-manager/docs/creating-managing-policy
https://cloud.google.com/resource-manager/docs/creating-managing-organization
</div></details>

### Q.  問題14: 未回答
ある顧客のデータサイエンスグループは、アナリティクスのワークロードにGoogle Cloudを使用したいと考えています。会社のポリシーでは、すべてのデータは会社が所有し、すべてのユーザー認証は独自のSAML（Security Assertion Markup Language）2.0アイデンティティプロバイダ（IdP）を経由する必要があります。インフラストラクチャオペレーション担当のシステムエンジニアが、顧客のクラウドIDをセットアップしようとして、顧客のドメインがすでにG Suiteで使用されていることに気づきました。
混乱を最小限に抑えるために正しい方法はどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、クラウドIDのセットアップを行いたい顧客の既存のドメインがG Suiteで既に使用されているという状況に対処する最適な手段を問われています。認証については、すべてのユーザー認証が独自のSAML 2.0アイデンティティプロバイダを経由すること、また、データの所有権も会社にあるという要件があります。そのため、既存のシステムとの統合や既存環境の利用可能性、およびデータとユーザー認証のリスクを適切に管理することが重要です。選択肢の評価に際しては、この状況における混乱の最小化、しっかりとした認証およびデータ所有の確保が重視されます。
基本的な概念や原則：
Google Cloud：Googleが提供するクラウドサービスの総称で、アワードウィニングなサービスとインフラストラクチャを用いて仮想マシン、データベース、ストレージ、ネットワーキングなどを提供します。
SAML 2.0：セキュリティ認証に関するオープンスタンダードの一つです。SAML 2.0では一度認証されたユーザーについて、その認証情報を異なるサービス間で共有することができます。これにより単一サインオン（SSO）の実現が可能となります。
アイデンティティプロバイダ（IdP）：ユーザーの認証情報及び属性の提供者のことです。IdPは認証と認可のパラメータをコントロールするためのインフラストラクチャを提供します。
Googleマネージドサービス：Googleが提供するサービスの中で、利用者が基本的な設定などをし、後はGoogleが管理・運用を行ってくれるサービスのことです。
ドメイン名：インターネット上で利用されるコンピューターやネットワークを識別するための名前です。これにより、ユーザーはIPアドレスを直接覚える必要がなく、ドメイン名を利用して目的のネットワークにアクセスできます。
G Suite：Googleが企業向けに提供しているクラウド型オフィス環境のことで、現在はGoogle Workspaceという名称です。メール、カレンダー、文書作成・編集、オンラインストレージなど、業務で必要とされる機能を一通り提供しています。
Cloud Identity：Google CloudのIdentity and Access Management（IAM）プラットフォームです。ユーザー、アプリケーション、サービスがGoogle Cloudのリソースに安全にアクセスするための方法を提供します。
正解についての説明：
（選択肢）
・顧客の管理者にGoogleマネージドサービスの他の利用方法を確認し、既存の特権管理者と連携します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudを使用する前提として、既存のドメインがG Suiteで使用されている場合は、そのドメインの管理者と連携して進めていくことが一般的です。これは、Google Cloud上の各種リソースにアクセスする際にG Suiteのアカウントが使用されるため、既存のアカウント管理体制に影響を与えないようにするためです。
したがって、まず顧客の管理者と連携し、Googleマネージドサービス（GMS）の他の利用法を確認することが重要です。
また、アイデンティティプロバイダ（IdP）を持つ顧客の認証要件も満たすために、G SuiteとSAML 2.0 IdPの連携についても考慮が必要です。これらの連携を適切に行うことで、既存の認証体制を崩すことなくGoogle Cloudの導入と利用が可能となります。
不正解についての説明：
選択肢：Googleサポートに連絡し、新しいCloud Identityドメインでドメイン名を使用するためのドメイン争奪プロセスを開始します
この選択肢が正しくない理由は以下の通りです。
Google Cloudでは、ドメイン争奪プロセスというものは存在せず、既にG Suiteで使用されているドメインを新しいCloud Identityドメインで使用することは不可能です。理想的な解決策は既存のG Suite管理者と連携し、既存のドメインを効果的に管理することです。
選択肢：新しいドメイン名を登録し、新しいCloud Identityドメインに使用します
この選択肢が正しくない理由は以下の通りです。
新しいドメイン名を登録し、新しいCloud Identityドメインに使用すると、独自のIdPを通じたユーザー認証の会社方針に反する可能性があります。
また、このアプローチは既存のG Suite使用状況や管理者と同期していないため、混乱を増幅する可能性があります。正解の選択肢では、既存の特権管理者と協力して情報共有を行い、混乱を最小限に抑えます。
選択肢：データサイエンスマネージャーのアカウントを既存のドメインの特権管理者としてプロビジョニングするようGoogleに依頼します
この選択肢が正しくない理由は以下の通りです。
Googleはユーザーアカウントのプロビジョニングを手動で行うサービスを提供していません。既存の特権管理者との連携を通じて内部的な管理変更が必要です。既存の管理者の承認なしにロールの変更を求めるのは不適切です。
参考リンク：
https://cloud.google.com/iam/docs/using-saml-to-enable-federated-sso
https://cloud.google.com/identity/docs/how-to/setup#authenticating_users_with_federated_sso
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#identity
</div></details>

### Q.  問題15: 未回答
あなたの会社はSparkとHadoopのジョブにCloud Dataprocを使用しています。Cloud Dataprocで使用される永続ディスクに使用される対称暗号化キーの作成、ローテーション、破棄ができるようにしたいと考えています。暗号化キーはクラウドに保存したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Dataprocで使用される永続ディスクに使われる暗号化キーの作成、ローテーション、破棄をどのように行うべきかという課題に焦点を当てています。また、その暗号化キーはクラウドに保存したいという要件もあります。クラウドに保存し、管理する暗号化キーとして選択肢にあげられているものが正しいかどうかを注意深く考えることが求められます。
基本的な概念や原則：
Cloud Dataproc：Google CloudのマネージドSparkとHadoopサービスです。データの分析や処理、機械学習のタスク等に利用します。
Cloud Key Management Service：Google Cloudで対象鍵の管理を行うためのマネージドサービスです。暗号化キーの作成、使用、ローテーション、破棄が行えます。
データ暗号化鍵（DEK）：データそのものを暗号化するためのキーです。直接データを暗号化・復号化するために使用されます。
鍵暗号化キー（KEK）：他の暗号キー（特にDEK）を暗号化するために使用されるキーです。暗号キーの暗号化やキーのライフサイクル管理に使用します。
顧客が提供する暗号化キー：顧客が自分で制御したい場合に使う、顧客自身が生成と管理を行う暗号化キーです。しかし、すべての管理責任が顧客にあるため、専門的な知識が必要となります。
正解についての説明：
（選択肢）
・Cloud Key Management Serviceを使用して、データ暗号化鍵（DEK）を管理します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Key Management Service（KMS）は、仮想マシンや永続ディスクなどのGoogle Cloudのリソースで用いられる秘密鍵（対称暗号化キー）を生成、使用、管理、ローテーション、そして破棄することを可能にするサービスです。これはクエスチョンで述べられた暗号化キーのライフサイクルの管理が必要とされている点に直接対応しています。
また、Cloud KMSはクラウド上で鍵を保存するため、クエスチョンにおいて暗号化キーの保存場所がクラウドであるべきと要求されている要件も満たします。
したがって、Cloud KMSを使用してデータ暗号化鍵（DEK）を管理することが最適な解決策と言えます。ただし、暗号化における基本的な概念として、データ暗号化鍵（DEK）が実際にデータの暗号化と復号化に使用され、鍵暗号化鍵（KEK）がDEKを保護するために使用されることを理解することは重要です。
不正解についての説明：
選択肢：鍵暗号化キー（KEK）を管理するために、Cloud Key Management Serviceを使用します
この選択肢が正しくない理由は以下の通りです。
誤った選択肢は、永続ディスクに使用される暗号化キー自体（DEK）を管理することではなく、別の暗号化キー（KEK）を管理することを提案しています。
一方、正解の選択肢は直接的にデータ暗号化鍵（DEK）の管理を提案しているため、問題の要件を満たします。
選択肢：データ暗号化キー（DEK）の管理には、顧客が提供する暗号化キーを使用します
この選択肢が正しくない理由は以下の通りです。
顧客が提供する暗号化キーを使用する方法では、要件で明示されているように暗号化キーの作成、ローテーション、破棄をクラウドで行うことができません。
一方で、Cloud Key Management Serviceを使用すれば、これらの暗号化キーのライフサイクルの管理を効率的にクラウド上で行うことが可能です。
選択肢：暗号化キー（KEK）の管理には、顧客が提供する暗号化キーを使用します
この選択肢が正しくない理由は以下の通りです。
顧客が提供する暗号化キーを使用するという提案はクラウドに暗号化キーを保存する要件を満たしません。
一方、Cloud Key Management ServiceはDEKの作成、ローテーション、破棄を可能にし、これらのキーをGoogle Cloud内で保存できます。
参考リンク：
https://cloud.google.com/security-key-management
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/security
https://cloud.google.com/kms/docs/creating-keys
</div></details>

### Q.  問題16: 未回答
あるウェブサイト制作会社は最近、すべての顧客サイトをApp Engineに移行しました。一部のサイトはまだ進行中であり、どの場所からでも顧客と従業員のみが閲覧できるようにする必要があります。
進行中のサイトへのアクセスを制限するソリューションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、App Engine上のウェブサイトに対するアクセス制限の設定方法について理解する必要があります。問題文のウェブサイトは"まだ進行中であり、どの場所からでも顧客と従業員のみが閲覧できるようにする必要がある"と明示しています。この特定の状況に対応する適切なソリューションを選択するためには、Google Cloudの各機能がどのように動作し、それらが提供するセキュリティレベルを基本的に理解する必要があります。
基本的な概念や原則：
Cloud Identity-Aware Proxy（IAP）：Google Cloudのアプリケーションへの安全なアクセスを提供するサービスです。IAPは、ユーザーとサービス間のTLS接続を確立し、ユーザーがサービスにアクセスする前に認証と承認を行います。
Googleグループ：一部のユーザーに共通のアクセス権を付与するための仮想グループのことです。Googleグループを使用することで、特定のgoogleアプリケーションへの複数のユーザーへのアクセスを簡単に制御することができます。
App Engine：フルマネージドのサーバーレスアプリケーションプラットフォームです。App Engineでは、デプロイからスケーリングまでのインフラストラクチャの管理をGoogle Cloudが行い、開発者はコードの実行に専念することができます。
App Engineファイアウォール：App Engineでホストされるアプリケーションに対する特定のIPアドレス範囲からのアクセスを受け入れるか拒否するルールを定義できますが、限定的な使用ケースとなります。
Cloud VPN：オンプレミスネットワークとGoogle Cloud VPCネットワークの間で暗号化されたIPsec接続を確立するサービスですが、一部のウェブサイトを特定のユーザーに制限するためのソリューションとしては不適切です。
正解についての説明：
（選択肢）
・Cloud Identity-Aware Proxy（IAP）を有効にし、顧客と従業員のユーザーアカウントを含むGoogleグループへのアクセスを許可します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのIdentity-Aware Proxy（IAP）を利用すれば、公開したくないWebアプリケーションに対して特定のユーザーやGoogleグループからのアクセスのみを許可することが可能です。つまり、この問題の状況では進行中のウェブサイトをセキュアに保持しつつ、必要な顧客や従業員だけがアクセスすることが許可されます。
また、IAPはApp Engineと直接統合されているので、特別なコードの変更を必要とせずにセキュリティを確保できます。これは、ウェブアプリケーションの移行とセキュリティ強化を両立するために最適な選択となっています。
したがって、Cloud Identity-Aware Proxy（IAP）を有効にし、顧客と従業員のユーザーアカウントを含むGoogleグループへのアクセスを許可することで、必要な要件を満たすことができます。
不正解についての説明：
選択肢：顧客と従業員のユーザーアカウントを含む.htaccessファイルをApp Engineにアップロードします
この選択肢が正しくない理由は以下の通りです。
App Engineは.htaccessファイルの使用をサポートしていません。アクセス制御を実現するためには、Cloud Identity-Aware Proxy（IAP）を使用して特定のGoogleグループにアクセス制限を設定する方法が適しています。
選択肢：顧客と従業員のネットワークからのアクセスを許可し、その他のすべてのトラフィックを拒否するApp Engineファイアウォールルールを作成します
この選択肢が正しくない理由は以下の通りです。
App EngineのファイヤーウォールルールはIPアドレスに基づいて制御を行うため、顧客や従業員が動的なIPアドレスを持っている場合、アクセス制御が困難になります。
それに対して、Cloud Identity-Aware Proxy（IAP）はユーザーアカウントをもとにアクセス制御を行うため、IPアドレスに関係なく制御を行うことが可能です。
選択肢：Cloud VPNを使用して、関連するオンプレミスネットワークと企業のGoogle Cloud仮想プライベートクラウド（VPC）ネットワークとの間にVPN接続を作成します
この選択肢が正しくない理由は以下の通りです。
Cloud VPNはオンプレミスネットワークとGoogle Cloud VPCネットワークとの間にVPN接続を作成するもので、ウェブアプリケーションのユーザー認証やアクセス制御を行う機能を持ちません。そのため、進行中のサイトへのアクセスを指定のユーザーグループに限定する要件を満たしません。
それに対して、Cloud Identity-Aware Proxyはアクセス制御と認証を管理できます。
参考リンク：
https://cloud.google.com/iap/docs/app-engine-quickstart
https://cloud.google.com/appengine/docs/standard/python/config/appref
https://cloud.google.com/appengine/docs/standard/python/security-controls
</div></details>

### Q.  問題17: 未回答
先週、ある企業がBigQueryにログを書き込む新しいApp Engineアプリケーションをデプロイしました。プロジェクトでは他のワークロードは実行されていません。BigQueryに書き込まれたすべてのデータが、App Engineデフォルトサービスアカウントを使用して行われたことを検証する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のサービスアカウントを使用したBigQueryへのデータ書き込みを確認するという要件が課題となっています。ここでは2つの重要な要素、ログ分析のスキルとGoogle Cloudの監視ツールの理解が問われます。課題の解決に向けて、Cloud Loggingを適切に使用し、特定のフィルタリングや操作を行うことで確認を進めます。選択肢からは、多くの選択肢がCloud Loggingを使用していることから、Google Cloudの監視・ログツールを適切に理解し使いこなすことが大切です。
基本的な概念や原則：
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションやシステムから生成されるログデータを一元的に管理し、分析と監視を行います。
BigQuery挿入ジョブ：BigQueryへのデータの追加や更新を行う操作です。Cloud Loggingを使用して行ったオペレーションの詳細を確認することが可能です。
App Engineデフォルトサービスアカウント：App Engineアプリケーションで自動的に作成されるサービスアカウントです。アプリケーションがGoogle Cloud APIを認証して使用するために使用されます。
Cloud IAM：Google Cloudの認証・認可を行うサービスです。ユーザーやサービスアカウントに対してロールやパーミッションを付与し、リソースへのアクセスを制御します。
BigQuery：Google Cloudのフルマネージド、サーバーレス、ハイスケーラビリティのデータウェアハウスサービスです。大量のデータに対する高速な分析クエリを実行することが可能です。
App Engine：Google Cloudのフルマネージドなサーバーレスアプリケーションプラットフォームです。アプリケーションの開発、デプロイ、スケーリングを効率的に行うことが可能です。
正解についての説明：
（選択肢）
・1. Cloud Loggingを使用し、BigQuery挿入ジョブでフィルタします
2. 認証フィールドのApp Engineデフォルトサービスアカウントに一致する電子メールアドレスをクリックします
3. "一致するエントリを非表示"をクリックします
4. 結果のリストが空であることを確認します
この選択肢が正解の理由は以下の通りです。
まず、Cloud LoggingはGoogle Cloudのログデータを保存、検索、分析できるサービスで、BigQueryへのデータ書き込み操作のロギングもサポートしています。そのため、BigQueryへのデータ書き込みが行われたときに、それを記録し確認するための最適なツールです。
次に、Cloud Loggingではログ中の特定のフィールドにフィルタを適用してログを検索することができます。ここでは、App Engineデフォルトサービスアカウントによる操作を調べるため、認証フィールドにフィルターを適用しています。
さらに、フィルタにマッチするエントリを非表示にすることで、どの操作がApp Engineデフォルトサービスアカウントによって行われたのかを明確にすることができます。リストが空であれば、すべての操作が該当のサービスアカウントによって行われたことを意味します。
この選択肢は、特定のサービスアカウントによる操作を確認し、それが想定通りに実行されているかを検証することを可能にするため、要件を満たしています。
不正解についての説明：
選択肢：1. Cloud Loggingを使用し、BigQuery挿入ジョブでフィルタします
2. 認証フィールドのApp Engineデフォルトサービスアカウントに一致する電子メールアドレスをクリックします
3. "一致するエントリを表示"をクリックします
4. 結果のリストが空であることを確認します
この選択肢が正しくない理由は以下の通りです。
"一致するエントリを表示"を選択して結果のリストが空だと、そのサービスアカウントでのBigQuery挿入が1つも行われていないことを示します。検証したいのは"すべてのデータがデフォルトサービスアカウントを通じて書き込まれた"ことなので、"一致するエントリを非表示"にするべきです。
選択肢：1. BigQueryで、関連するデータセットを選択します
2. App Engineデフォルトサービスアカウントが、データセットに書き込みできる唯一のアカウントであることを確認します
この選択肢が正しくない理由は以下の通りです。
BigQueryのデータセットの権限設定を確認することで、サービスアカウントが書き込み可能であることは確認できますが、すでに存在するデータが該当サービスアカウントを用いて書き込まれたことを検証するのは不可能です。
それに対して、正解はCloud Loggingを用いて具体的な操作ログを確認するため、要求が満たせます。
選択肢：1. プロジェクトの"Identity and Access Management（IAM）"セクションに移動します
2. App Engineデフォルトサービスアカウントが、BigQueryに書き込みできるロールを持つ唯一のアカウントであることを検証します
この選択肢が正しくない理由は以下の通りです。
IAMポリシーを確認するのではなく、Cloud LoggingでBigQueryの挿入ジョブを直接調査することで、実際の書き込みがApp Engineデフォルトサービスアカウントによって行われたかどうかを検証することが可能です。IAMの確認は、アカウントが適切な権限を持っていることを確認するのに役立ちますが、それが実際にデータ書き込みを行ったかどうかの確証は得られません。
参考リンク：
https://cloud.google.com/logging/docs/view/overview
https://cloud.google.com/bigquery/docs/reference/auditlogs
https://cloud.google.com/iam/docs/granting-changing-revoking-access
</div></details>

### Q.  問題18: 未回答
あなたの会社はGoogle Cloudに移行しようとしています。まず、Google Cloud Directory Sync（GCDS）を使用してユーザーを同期する予定です。一部の従業員は、GCDS以外で作成した会社のメールアドレスを使用してGoogle Cloudアカウントを作成済みです。また、Cloud Identityでユーザを作成する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudに移行する際のユーザーアカウント管理について考察します。既にGoogle Cloudアカウントを持っている従業員と、新たにCloud Identityで作成するユーザーという2つのケースが存在します。GCDSを使用してユーザーを同期する予定ですが、一部の従業員はすでにGCDS以外でアカウントを作成しているため、これらのユーザーをどのように扱うのかが問われています。選択肢は、GCDSの設定やユーザー移行ツールの使用に関連していますが、最も適切な措置を選ぶためには、既存ユーザーのアカウントと新規ユーザーのアカウント管理のバランスを維持することが条件となります。
基本的な概念や原則：
Google Cloud Directory Sync（GCDS）：オンプレミスのLDAPディレクトリサービスとGoogle Cloud Identityのユーザー、グループ、およびその他のデータを同期するツールです。ローカルのディレクトリチェンジをGoogle Cloudに反映します。
管理されていないユーザー：Google Cloudサービスを使用するために、あるドメインのメールアドレスを使用して作成されましたが、そのドメインの管理下にないユーザーのことです。
転送ツール：Google Cloudでは、非管理ユーザーを対象のドメインの管理下に移行するための転送ツールが提供されています。
Cloud Identity：Google CloudのIdentity-as-a-Service（IDaaS）です。ユーザー管理およびエンドポイント管理を一体化します。
Admin SDK：Google Cloudの管理者向けAPIを提供するツールです。Directory APIを含み、ユーザー、グループ、ドメインなどの管理作業を行います。
正解についての説明：
（選択肢）
・管理されていないユーザーを移行するために、転送ツールを使用します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、管理されていないユーザーアカウント（GCDS以外で作成されたもの）を組織のGoogleワークスペースに移行するための方法として、転送ツールを提供しています。これにより、組織全体で一元的な管理が可能になり、データのセキュリティを確保することができます。
また、適切なアクセス権の管理も行うことができます。
Google Cloud Directory Sync（GCDS）は、オンプレミスのディレクトリとGoogle Cloud Identityでユーザーを同期するためのツールです。ただし、すでにGoogle Cloudのアカウントを持っているユーザーをGCDSで同期しようとすると、"既存のアカウントがある"というエラーメッセージが表示されるかもしれません。
したがって、すでに作成済みのアカウントをうまく管理下に置くためには、転送ツールを使用してこれらの既存ユーザーを移行すべきです。この操作により、既存のGoogle Cloudアカウントが組織のGoogleワークスペースに統合され、効率的なユーザー管理が実現します。
不正解についての説明：
選択肢：GCDSを設定し、GCDS検索ルールを使用してこれらのユーザーを同期します
この選択肢が正しくない理由は以下の通りです。
GCDS検索ルールを使用してユーザーを同期すると、既存のGoogle Cloudアカウントは無視され、新たなアカウントが作成されます。既存のアカウントを含めるためには、転送ツールを使用して管理されていないユーザーを移行する必要があります。
選択肢：既存のGoogle Cloudユーザーを識別し、Admin SDKを呼び出すカスタムスクリプトを作成します：Directory APIを呼び出してアカウントを転送します
この選択肢が正しくない理由は以下の通りです。
Admin SDKを使用してカスタムスクリプトを作成しDirectory APIを呼び出してアカウントを転送する方法は手間がかかり、管理の負担が増す可能性があります。
それに対して、転送ツールを使用することで、効率的に管理されていないユーザーを移行することが可能になります。
選択肢：GCDSを設定し、GCDSの除外ルールを使用して、ユーザーがサスペンドされないようにします
この選択肢が正しくない理由は以下の通りです。
GCDSの除外ルールは特定のユーザーを同期対象から除外する機能ですが、それはすでに会社のメールアドレスでGoogle Cloudアカウントを作成している従業員が管理対象になる問題を解決しません。正解は彼らのアカウントを管理対象にするために転送ツールを使用することです。
参考リンク：
https://cloud.google.com/identity/docs/transfer-tool
https://cloud.google.com/identity/docs/how-to/setup#setting_up_gcds
https://support.google.com/a/answer/1041297?hl=en
</div></details>

### Q.  問題19: 未回答
ある顧客が、Compute Engine上でホストされているERPシステムにCloud Identity-Aware Proxyを実装しています。セキュリティチームは、ERPシステムがCloud Identity-Aware Proxyからのトラフィックのみを受け入れるように、セキュリティレイヤーを追加したいと考えています。
これらの要件を満たすために、顧客は何をすべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Identity-Aware ProxyがCompute EngineによってホストされるERPシステムへの接続を管理するように、指定されたセキュリティレイヤーをどのように追加すべきかを特定する必要があります。選択肢を検討する際は、Cloud Identity-Aware Proxyがどのように動作し、それがセキュリティレイヤーとしてどのように機能するかを理解する必要があります。それにより、ERPシステムがどのHTTPリクエストヘッダーの検証を確認すべきかを判断することができます。
基本的な概念や原則：
Cloud Identity-Aware Proxy（IAP）：Google Cloudのサービスで、内部のWebアプリケーションへの安全なアクセスを提供します。VPNやネットワークレベルのファイアウォールの代替となります。
Compute Engine：Google Cloudのサービスの1つで、仮想マシンを作成し、実行する事ができます。
HTTPヘッダーの検証：入力として受け取るHTTP要求ヘッダーの内容を検証します。エンドポイントのセキュリティを強化するための一般的なテクニックです。
ERPシステム：企業の全ての主要なビジネスプロセスを統合・管理するためのソフトウェアシステムです。
JWT（JSON Web Token）：ロールや特性を表すためのJSON形式のオブジェクト。OAuthなどの認証・認可フローで利用されます。
x-forwarded-forヘッダー：HTTPリクエストのヘッダに追加され、クライアントのIPアドレス情報を示す規格。プロキシサーバーやロードバランサーを経由した場合に利用されます。
正解についての説明：
（選択肢）
・ERPシステムがHTTP要求のIDヘッダーを検証できることを確認します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Identity-Aware Proxy（IAP）は、Google Cloudのアプリケーションにアクセスする前にユーザーの認証と認可を実行するツールです。IAPを使用すると、公開場所にあるアプリケーションに対するVPN接続を無くすことが可能になります。
IAPがユーザーを認証すると、それが透明であるために、続いてアプリケーションに送られるHTTP要求ヘッダーに認証情報が追加されます。
したがって、アプリケーションがこのヘッダーを検証することで、送られてきた要求がIAPからと確認できるようになります。
したがって、ERPシステムがこのIDヘッダーを検証できると、Cloud IAPからのトラフィックのみを受け入れられるようになります。これによりセキュリティチームは求めていたセキュリティレイヤーを追加することが可能となります。というわけで、この選択肢が正解となります。
不正解についての説明：
選択肢：ERPシステムがHTTP要求でJWTアサーションを検証できることを確認します
この選択肢が正しくない理由は以下の通りです。
Cloud Identity-Aware Proxy（IAP）はヘッダーを利用して認証を行いますが、JWTアサーションではなくIDヘッダーを使用します。そのため、ERPシステムがHTTP要求のJWTアサーションを検証できることはIAPの導入には不要です。
対照的に、正解はIDヘッダーの検証能力を強調し、IAPが使用する認証手法に直接対応しています。
選択肢：ERPシステムがHTTP要求のx-forwarded-forヘッダーを検証できることを確認します
この選択肢が正しくない理由は以下の通りです。
x-forwarded-forヘッダーは、クライアントのIPアドレス情報を含むが、トラフィックがCloud Identity-Aware Proxyから来たことを確証する情報は含まれません。
一方、IDヘッダーはCloud Identity-Aware Proxyからのトラフィックを確認するために使用することができます。
選択肢：ERPシステムが、HTTPリクエスト内のユーザー一意識別子ヘッダーを検証できることを確認します
この選択肢が正しくない理由は以下の通りです。
Cloud Identity-Aware Proxyを用いる場合、個々のユーザー識別子ではなく、IDヘッダーを検証することで、リクエストがCloud Identity-Aware Proxyから来ているかを確認することが求められています。よって、ユーザー一意識別子ヘッダーの検証は求められていません。
参考リンク：
https://cloud.google.com/iap/docs/enabling-compute-howto
https://cloud.google.com/iap/docs/signed-headers-howto
https://cloud.google.com/compute/docs/ip-addresses#reservedaddress
</div></details>

### Q.  問題20: 未回答
標準的なネットワーク階層を使用しながら、デフォルトでクライアントIPを維持するために、どのタイプのロードバランサーを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ロードバランサーの種類とそれぞれの機能に関する理解が求められています。特に、デフォルトでクライアントIPを維持するロードバランサーのタイプを選ぶことが問われています。問題文を理解するためには、各ロードバランサーがどのように動作し、それぞれがどのようなネットワーク階層で動くのか、またどのロードバランサーがクライアントIPを維持可能なのか、を把握する必要があります。
基本的な概念や原則：
TCP/UDPネットワークロードバランサー：パケットレベルのロードバランサーであり、リッチなルーティング機能と高いパフォーマンスを提供します。デフォルトでクライアントIPを維持します。
SSLプロキシロードバランサー：SSL（HTTPS）トラフィックのロードバランサーで、SSLオフロード能力を提供します。クライアントIPを維持しないことがあります。
TCPプロキシロードバランサー：TCP（またはSSL）トラフィックのロードバランサーで、迅速なオープンコネクションを提供します。こちらもクライアントIPを維持しないことがあります。
内部TCP/UDPロードバランサー：VPCネットワーク内部にあるインスタンス間でトラフィックをバランスします。クライアントIPの維持が特例となります。
正解についての説明：
（選択肢）
・TCP/UDPネットワーク
この選択肢が正解の理由は以下の通りです。
まず、TCP/UDPネットワークロードバランサーは、トラフィックをバックエンドサーバーに分散するために、トランスポート層（L4）レベルでロードバランスを行います。このレベルで動作するため、クライアントのIPアドレスが変更されずに保持されます。これは特に、クライアントのIPアドレスを維持する必要があるケース、たとえば特定のIPからのリクエストを特定のサーバにルーティングしたいといった場合に有用です。
また、TCP/UDPネットワークロードバランサーは、デフォルトで典型的なネットワーク階層（つまり、マルチレイヤーネットワークトポロジ）で動作します。これにより、ネットワーク設計と管理が容易になり、スムーズな運用が可能となります。
したがって、標準的なネットワーク階層を維持しながらクライアントIPを保持するためには、TCP/UDPネットワークロードバランサーを使用すべきです。
不正解についての説明：
選択肢：SSLプロキシ
この選択肢が正しくない理由は以下の通りです。
SSLプロキシロードバランサーは、クライアントIPアドレスを元の形で維持することができません。クライアントのIPアドレスを保持しながら標準的なネットワーク階層を使用するために、TCP/UDPネットワークロードバランサーが適切な選択肢となります。
選択肢：TCPプロキシ
この選択肢が正しくない理由は以下の通りです。
TCPプロキシロードバランサーはクライアントのIPを維持しません。クライアントからの接続を受け取り、バックエンドインスタンスに転送するときに新しいTCPセッションを開始します。
これに対して、TCP/UDPネットワークロードバランサーはクライアントのIPを維持します。
選択肢：内部TCP/UDP
この選択肢が正しくない理由は以下の通りです。
内部TCP/UDPロードバランサーは特定の状況下でクライアントIPを維持しますが、一般的にはプロキシモードで動作し、クライアントIPを維持しません。しかし正解のTCP/UDPネットワークロードバランサーはパケットに対して直接操作を行うため、デフォルトでクライアントIPを維持します。
参考リンク：
https://cloud.google.com/load-balancing/docs/network
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
</div></details>

### Q.  問題21: 未回答
Google Cloudリソースへの直接アクセスが必要な開発者や運用スタッフそれぞれに、Google Cloudの企業ユーザーアカウントを提供する必要があります。
企業ポリシーでは、サードパーティのID管理プロバイダでユーザーIDを管理し、シングルサインオンを活用する必要があります。あなたは、かなりの数のユーザーが個人的なGoogleアカウントに会社ドメインのメールアドレスを使用していることを知り、Googleが推奨するプラクティスに従って、既存の管理対象外のユーザーを管理対象アカウントに変更する必要があります。
あなたが取るべき2つのアクションはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの企業ユーザーアカウントの設定方法とユーザー管理に関する要求が課せられています。主に注目すべきは"サードパーティのID管理プロバイダでユーザーIDを管理したい"、"シングルサインオンを活用したい"、"個人的なGoogleアカウントに会社ドメインのメールアドレスを使用しているユーザーが問題"であるというポイントです。これらに対応するために、Google Cloudの機能だけでなく、その外部との連携や同期が重要です。また、すでに存在する個人アカウントの扱いも考慮する必要があります。それらを解決する方法として、適切なGoogle Cloudのツールの選択が求められています。
基本的な概念や原則：
Google Cloud Directory Sync：Google Cloudのサービスで、企業のローカルID管理システムをCloud IdentityやG Suiteと同期できます。企業の既存のユーザー管理基盤を活用して、ユーザーアカウントを効率的に管理できます。
Cloud Identity：Google CloudのIDとアクセス管理サービスです。企業はこのサービスを利用して、ユーザーアカウントのライフサイクルを管理したり、デバイスのアクセスを制御したりできます。
Transfer Tool for Unmanaged Users（TTUU）：クラウドIDやG Suiteが所有するドメインと同じドメインを使用している未管理のGoogleアカウントを管理対象アカウントに移行させるGoogleのツールです。
シングルサインオン：複数のシステムやサービスを同じ認証情報で利用できるようにする技術です。1つのログイン操作で複数のシステムにアクセスできるため、ユーザー体験の改善やセキュリティ強化に効果的です。
サードパーティのID管理プロバイダ：IDと認証を提供する外部サービスのことであり、多くの企業では既存のITインフラストラクチャと統合するために利用しています。
管理対象アカウントと未管理アカウント：Google Cloudでは、企業が管理するアカウント（管理対象アカウント）と、企業が管理しない個々のユーザーが自分で管理するアカウント（未管理アカウント）との間で区別します。
正解についての説明：
（選択肢）
・Google Cloud Directory Syncを使用して、ローカルのID管理システムをCloud Identityに同期します
・Transfer Tool for Unmanaged Users（TTUU）を使用して、競合するアカウントを持つユーザーを見つけ、個人のGoogleアカウントを移行するよう依頼します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Directory Syncを使用することで、ローカルに存在するユーザーID管理システムとCloud Identityを同期することができます。これにより、企業ポリシーに従い、Google Cloudの企業ユーザーアカウントを提供することの準備が整います。つまり、サードパーティのID管理プロバイダで管理されているユーザーIDをGoogle CloudのCloud Identityに取り込むことで、ユーザーがGoogle Cloudリソースへ直接アクセスするための管理アカウントの提供が可能となります。
次に、Transfer Tool for Unmanaged Users（TTUU）は、Googleが推奨するツールで、すでに個人Googleアカウントを使用しているユーザーのアカウントを管理対象アカウントに移行するためのものです。このツールを通じて、競合するアカウントを持つユーザーを特定し、個人のGoogleアカウントから管理下のアカウントへの移行を依頼することができます。これにより、既存の管理対象外のユーザーを管理対象アカウントに変更する作業が効率的に行えます。
不正解についての説明：
選択肢：Google管理コンソールを使用して、どの管理対象ユーザーがリカバリメールに個人アカウントを使用しているかを確認します
この選択肢が正しくない理由は以下の通りです。
Google管理コンソールは、ユーザーがリカバリメールに個人アカウントを使用しているか確認する機能を持っていません。それよりも、TTUUを用いて管理対象ユーザーを特定し、そのアカウントを移行させるよう依頼するのが適切なアクションです。
選択肢：管理するGoogleアカウントにユーザーを追加し、ユーザーに個人アカウントに関連付けられたメールアドレスを変更させます
この選択肢が正しくない理由は以下の通りです。
個人アカウントとは別に新しい管理対象のアカウントを作成し、ユーザーにメールアドレスを変更させることは煩雑であり、不必要な手間をかけることになります。
また、Googleの推奨するプラクティスにも従っていません。TTUUを使用すれば、操作が簡略化され、ユーザーは権限を失うことなくアカウントを移行できます。
選択肢：全従業員にメールを送り、個人用Googleアカウントに会社のメールアドレスを使用しているユーザーには、個人用アカウントを直ちに削除するよう要請します
この選択肢が正しくない理由は以下の通りです。
全従業員にメールを送り、個人用Googleアカウントを直ちに削除するよう要請すると変更は即時的でコントロールが難しいです。
一方、TTUUを使用すると既存ユーザーの管理対象への移行がスムーズに行えます。これはGoogleの推奨するプラクティスでもあります。
参考リンク：
https://cloud.google.com/identity/docs/how-to/setup#connecting_to_your_ldap_directory
https://cloud.google.com/identity/docs/troubleshooting-common-sso
https://support.google.com/a/answer/106368?hl=en
</div></details>

### Q.  問題22: 未回答
あなたの会社のセキュリティチームは、元従業員が過去2ヶ月の間にサービスアカウントキーを使用してGoogle Cloudリソースに不正アクセスしたと考えています。不正アクセスを確認し、ユーザーアクティビティを特定する必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、不正アクセスの確認とユーザーアクティビティの特定という二つの要件を満たすために、Google Cloud上のどの機能をどのように活用すべきかを問われています。不正アクセスの確認とは、サービスアカウントキーを使った特定のアクションの証拠を検出することを指すでしょう。また、ユーザーアクティビティを特定するとは、特定のユーザーの操作またはパターンを把握することを意味します。この二つの要件を考慮に入れつつ、選択肢を評価することが求められます。
基本的な概念や原則：
ログエクスプローラ：Google Cloudが記録したログを検索、分析、視覚化するツールです。ユーザーやサービスのアクティビティを追跡して詳細な情報を得ることができます。
サービスアカウントキー：Google CloudのAPIを使用するための認証情報です。サービスアカウントを表すために使用され、不正に使用された場合はセキュリティの問題となります。
Security Health Analytics：Google Cloudのセキュリティスコアカードと総合的な脅威レポートを提供するツールです。各プロジェクトのセキュリティポスチャを改善するための推奨行動を提供しますが、個々のユーザーアクティビティの追跡には使用されません。
Cloud Monitoring：Google Cloud上のアプリケーションとサービスのパフォーマンスを監視するツールです。活動ログをフィルタリングする能力がありますが、詳細なユーザーアクティビティの追跡には適していません。
Cloud Data Loss Prevention API：情報の機密性を保つためのツールです。感慣性情報を自動的に識別、分類、調整しますが、ユーザーアクティビティの追跡用途には使用されません。
正解についての説明：
（選択肢）
・ログエクスプローラを使用して、ユーザーのアクティビティを検索します
この選択肢が正解の理由は以下の通りです。
Google Cloudのログエクスプローラは、Google Cloudの各種サービスやアプリケーションから生成されるログを一元管理し、検索、フィルタリング、可視化するための強力なツールです。Google Cloudに保存されたログデータを高速に検索し、ログデータから具体的なユーザーアクティビティを特定することが可能です。
したがって、過去の操作ログを検索して、特定のユーザーアクティビティがサービスアカウントキーを使用して不正にアクセスを試みたかどうかを特定できます。
さらに、詳細なフィルタリング機能を用いて特定の期間や特定のユーザーの行動に焦点を当てることも可能なため、探索範囲を過去2ヶ月間に限定し、元従業員の操作を特定することが可能です。このため、この問題の要件を満たすためには、ログエクスプローラを使用してユーザーのアクティビティを検索するのが適切です。
不正解についての説明：
選択肢：Security Health Analyticsを使用して、ユーザーのアクティビティを判断します
この選択肢が正しくない理由は以下の通りです。
Security Health Analyticsは、脆弱性や不適切な設定を検出し、リスク評価と対策の推奨を提供するサービスで、特定のユーザーのアクティビティの詳細な監視・追跡は目的に適っていません。
一方、ログエクスプローラは、ユーザーやサービスの具体的なアクティビティログを検索・分析するためのツールであり、不正アクセスの確認や特定のユーザーアクティビティの特定に適切です。
選択肢：Cloud Monitoringコンソールを使用して、ユーザー別に監査ログをフィルタリングします
この選択肢が正しくない理由は以下の通りです。
Cloud Monitoringコンソールは基本的にシステムメトリクスの監視と警告のためのものであり、ユーザー別に監査ログをフィルタリングする能力はありません。
一方で、ログエクスプローラはGoogle Cloudのログデータを検索、フィルタリング、表示できるため、ユーザーのアクティビティ特定に適しています。
選択肢：Cloud Data Loss Prevention APIを使用して、Cloud Storageのログを照会します
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Prevention APIは、機密データが露出していないかチェックするためのもので、ユーザーのアクティビティを追跡するためのものではありません。
一方、ログエクスプローラはログを検索し、特定のユーザーのアクティビティを追跡するために使用できます。
したがって、ログエクスプローラを使用するほうが要件に適しています。
参考リンク：
https://cloud.google.com/logging/docs/using-logs-explorer
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/security-command-center/docs/concepts-security-health-analytics
</div></details>

### Q.  問題23: 未回答
セキュリティチームは、ユーザが管理する鍵が誤って管理され、漏洩するリスクを減らしたいと考えています。そのためには、開発者が組織内のプロジェクト用にユーザ管理サービスアカウントキーを作成できないようにする必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、開発者がユーザ管理のサービスアカウントキーを作成できないようにする方法を選択することが求められています。そのため問題文の要件に基づいて、選択肢を見ていきましょう。選択肢には色々な管理方法や設定変更が提案されていますが、目的はユーザ管理のサービスアカウントキーの作成を防ぐことであるため、それを直接的に達成できる選択肢を選ぶことが大切です。
基本的な概念や原則：
組織ポリシー：Google Cloud上の組織に対する特定の制約を設定するためのものです。ポリシーレベルで管理し、ロールベースのアクセス制御を提供します。
サービスアカウントキー：サービスアカウントを認証するために使用され、ユーザーによって手動で作成・管理されます。ユーザー管理のサービスアカウントキーは、誤管理によるリスクがあります。
Secret Manager：Google Cloudで機密情報を安全に管理するサービスです。ただし、サービスアカウントキーの作成自体を制限する機能はありません。
iam.serviceAccounts.getAccessTokenパーミッション：サービスアカウントからアクセストークンを取得する権限です。ただし、サービスアカウントキーの作成を制限する機能はありません。
正解についての説明：
（選択肢）
・組織ポリシーを有効にして、サービスアカウントキーが作成されないようにします
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudでは、組織ポリシーを用いて特定のクラウドリソースに対するアクセス制限を行うことができます。サービスアカウントキーの作成を制限するために、組織ポリシーを適切に設定することで可能となります。そのため、組織全体でサービスアカウントキーの作成を禁止するために、この機能を有効にするのが適切です。
さらに、組織ポリシーによる制限は、開発者が誤って認証情報を管理し難く、鍵の漏洩リスクを効果的に軽減できます。開発者が所有権を持つサービスアカウントの管理を正しく行うことは困難であり、独自の鍵を生成・管理することはセキュリティ上のリスクを高まらせます。そのため、サービスアカウントキーの作成を組織ポリシーで制限することは、セキュリティを保つ上で効果的な策と言えます。
不正解についての説明：
選択肢：Secret Managerを設定してサービスアカウントキーを管理します
この選択肢が正しくない理由は以下の通りです。
Secret Managerは秘密情報の保管・管理をするためのサービスであり、ユーザがサービスアカウントキーを作成することを直接制限する機能は持っていません。
対照的に、組織ポリシーを有効にすることでキーの作成を直接禁止することが可能です。
選択肢：組織ポリシーを有効にして、サービスアカウントを作成できないようにします
この選択肢が正しくない理由は以下の通りです。
サービスアカウントそのものを作成できないようにすると、管理の範囲が広すぎてしまい、開発者がアプリケーションを運用する上で必要な一部のサービスアカウントの使用を防いでしまいます。
一方、正解の選択肢では、ユーザ管理のサービスアカウントキーのみの作成を制限するので、適切なセキュリティ対策を講じつつ、アプリケーションの運用も可能にします。
選択肢：ユーザーからiam.serviceAccounts.getAccessTokenパーミッションを削除します
この選択肢が正しくない理由は以下の通りです。
iam.serviceAccounts.getAccessTokenパーミッションを削除すると、ユーザはサービスアカウントからアクセストークンを取得することはできなくなりますが、サービスアカウントキーの作成は可能なままです。
一方、組織ポリシーを有効にしてサービスアカウントキーの作成を禁止すると直接的に問題を解決できます。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題24: 未回答
一般的に、アプリケーションは多くの場合、ビルド時や実行時にシークレットへのアクセスを必要とします。Google Cloud上でこれらのシークレットを管理する管理者は、Google Cloudプロジェクト内で"誰が、いつ、どこで、何をしたか"を追跡したいと考えています。
管理者が探している情報を提供する2つのログストリームはどれですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudプロジェクトに関するログ管理の問いが挙げられています。"誰が、いつ、どこで、何をしたか"という4つの質問が指摘されている点を重視する必要があります。ここでは、シークレットの管理と、それに関連するユーザーアクティビティとデータアクセスの追跡に注目し、適切なログストリームを選択することが重要です。選択肢にはさまざまなログのタイプが挙げられていますが、問題文が求めている情報を正確に捕捉できるタイプを選んでください。
基本的な概念や原則：
管理者の活動ログ：Google Cloud上で行われた管理タスクに関するログです。管理者が実行したアクション（誰が、何を、いつしたか）に関する詳細情報を追跡します。
データアクセスログ：Google Cloudサービスがユーザーデータにアクセスする際（どこで、何がアクセスされたか）に生成されるログです。これには、API呼び出しやGoogle Cloud Consoleの操作などが含まれます。
システムイベントログ：Google Cloudサービスがシステムイベントを生成した際のログです。このログは、システムレベルでのアクティビティに関する情報を提供します。ただし、"誰が、いつ、どこで、何をしたか"についての詳細な情報は提供しません。
VPCフローログ：VPCネットワークのIPトラフィックに関するログです。これには、送信元と送信先IP、パケットサイズ、インスタンスIDなどの情報が含まれます。しかし、"誰が、いつ、どこで、何をしたか"に関する情報は含まれていません。
エージェントログ：エージェントが生成したログです。これは、特定のアプリケーションやサービスに特化した詳細情報を提供するために使用されますが、"誰が、いつ、どこで、何をしたか"に関する情報を直接提供するものではありません。
正解についての説明：
（選択肢）
・管理者の活動ログ
・データアクセスログ
この選択肢が正解の理由は以下の通りです。
まず、管理者の活動ログはGoogle Cloud上での管理者の操作を記録します。これにはプロジェクトの設定変更、リソースの作成や削除、他のユーザーへの権限の付与などが含まれます。このログは、"誰が何をしたか"を明らかにするために必要です。
次に、データアクセスログはユーザーがGoogle Cloudのリソースに対して行った読み取り、書き込み、または更新の操作を記録します。ただし、これは管理者が明示的に有効化しなければならないオプションのログです。これらのログは"何を、いつ、どこで、誰がしたか"を特定するために有効です。
したがって、これらの二つのログストリームを適切に使用し、監視することで、Google Cloud上でシークレットを管理する際のアクセス情報を詳細に追跡し、問題の特定や将来の不正アクセスの防止に役立てることができます。
不正解についての説明：
選択肢：システムイベントログ
この選択肢が正しくない理由は以下の通りです。
システムイベントログはGoogle Cloudのバックエンドシステムによる操作に関するログであり、管理者による操作やデータへのアクセスに関する情報は含まれません。
一方、管理者の活動ログやデータアクセスログは"誰が、いつ、どこで、何をしたか"についての詳細な情報を提供します。
選択肢：VPCフローログ
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフロー情報を提供しますが、"誰が、いつ、どこで、何をしたか"という詳細なアクセス情報を提供するものではありません。
一方、管理者の活動ログやデータアクセスログはこの要求を満たすために適切なログストリームとなります。
選択肢：エージェントログ
この選択肢が正しくない理由は以下の通りです。
エージェントログはGoogle Cloudのリソースを監視するためのものであり、誰が何をしたかなどの操作履歴を追跡する情報は含まれません。
これに対し、管理者の活動ログやデータアクセスログはユーザーの操作やデータへのアクセスを記録するため、求めている情報を提供します。
参考リンク：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/audit-logging
https://cloud.google.com/security-command-center/docs/concepts-logging-and-notifications
</div></details>

### Q.  問題25: 未回答
共有VPCに接続されたCompute EngineインスタンスとBigQueryデータセット間のアクセス拒否エラーのトラブルシューティングを行っています。データセットは、VPC Service Controls境界によって保護されたプロジェクトに存在します。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudの共有VPC、Compute Engineインスタンス、BigQueryデータセットとVPC Service Controlsに関連するエラーハンドリングの知識が求められます。ここでの課題は、VPC Service Controls境界によって保護されたプロジェクト内のデータセットに共有VPCを通じてアクセスしたいというものです。選択肢を選ぶ際には、VPC Service Controlsの設定と、それがどのように共有VPCと他のGoogle Cloudサービスとの連携に影響を与えるか、を理解しておくことが重要です。
基本的な概念や原則：
共有VPC：Google Cloudのネットワークリソースを複数のプロジェクト間で共有するための機能です。ホストプロジェクトのネットワークを共有し、サービスプロジェクトのインスタンスで使用します。
VPC Service Controls：Google Cloudサービス間のデータの流れを制御するセキュリティ境界を設定する機能です。境界内のリソースへのアクセスを制限します。
ホストプロジェクト：共有VPCを持つプロジェクトです。このホストプロジェクトのネットワークをサービスプロジェクトが共有します。
サービスプロジェクト：共有VPCを使用するプロジェクトです。ホストプロジェクトからネットワークを共有します。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。柔軟な仮想マシンの設定と自動スケーリングが可能です。
BigQuery：Google Cloudの大規模データ分析サービスです。高速なSQLクエリを実行し、ビッグデータの分析を容易にします。
正解についての説明：
（選択肢）
・共有VPCを含むホストプロジェクトをサービス境界へ追加します
この選択肢が正解の理由は以下の通りです。
共有VPCを使用すると、複数のプロジェクト間でネットワークリソースを統一的に管理できます。このネットワークは一つのホストプロジェクトで定義され、他のサービスプロジェクトから利用されます。これにより、ネットワークの設定やポリシーを一元的に制御できます。
一方、VPC Service ControlsはGoogle Cloudのサービスに対するデータの流れを制御するためのセキュリティ対策の一つで、一定の範囲（サービス境界）を設定し、その範囲内からのデータアクセスのみを許可することができます。
共有VPCを含むホストプロジェクトがVPC Service Controlsのサービス境界に含まれていないと、そのネットワークからは境界によって保護されたリソースへのアクセスが拒否されます。
したがって、アクセス拒否エラーを解消するためには、共有VPCを含むホストプロジェクトをVPC Service Controlsのサービス境界に追加する必要があります。そうすることで、共有VPCからのデータアクセスが許可され、エラーは解消されます。
不正解についての説明：
選択肢：Compute Engineインスタンスが存在するサービスプロジェクトをサービス境界に追加します
この選択肢が正しくない理由は以下の通りです。
サービスプロジェクトをサービス境界に追加しても、共有VPCが保護されません。
それに対して、ホストプロジェクトを境界に追加すると、共有VPC全体が保護され、接続されたインスタンスからBigQueryデータセットにアクセスできます。
選択肢：Compute Engineインスタンスが存在するサービスプロジェクトと、Shared VPCを含むホストプロジェクトの間に、サービス境界を作成します
この選択肢が正しくない理由は以下の通りです。
サービス境界はプロジェクト間のデータ流れを制限するもので、Compute EngineインスタンスとShared VPC間に新たに境界を作ると、それらのコミュニケーションをさらに阻む可能性があります。正解は共有VPCを含むホストプロジェクトを境界に追加して、BigQueryデータセットとのアクセスを許可することです。
選択肢：Compute Engineインスタンスが存在するサービスプロジェクトと、保護されたBigQueryデータセットを含む境界との間に境界ブリッジを作成します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsは、サービスとデータ間の適切な流れを管理するために導入されたものであり、一方で存在しない概念である"境界ブリッジ"を作成することはできません。正しい対策は、共有VPCを含むホストプロジェクト全体をVPC Service Controls境界に追加することです。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/set-up-private-connectivity
https://cloud.google.com/vpc-service-controls/docs/perimeters
https://cloud.google.com/bigquery/docs/datasets-access-controls
</div></details>

### Q.  問題26: 未回答
データ所在地の要件として、Google Clouds Secret Managerのシークレットがeurope-west1とeurope-west4にのみペイロードを持つようにします。シークレットは両方のリージョンで高度に利用可能でなければなりません。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud Secret Managerのシークレットが特定のリージョンに限定され、そのリージョンでも高可用性を確保する必要があるという要件を満たすためにはどのようにすべきかについて問われています。知っておくべきは、Google Cloud Secret Managerはシークレットのデータ所在地管理という観点からユーザーが管理するレプリケーションポリシーを提供しており、これにより特定のリージョンのみでシークレットを保持することが可能な点です。また、高可用性についても考慮しなければならないという要件があるため、単純に特定のリージョンに限定するだけではなく、選択するレプリケーションポリシーは高可用性を確保するものであるべきだということも理解しておく重要です。
基本的な概念や原則：
Secret Manager：Google Cloudのシークレット管理サービスです。APIキーやパスワードなどのシークレット情報を安全に保存、管理することができます。
ユーザーが管理するレプリケーションポリシー：シークレットがレプリケーションされる具体的なリージョンをユーザーが指定するタイプのレプリケーションポリシーです。データ所在地の要件に対応できます。
自動レプリケーションポリシー：シークレットがGoogle Cloudの全リージョンに自動的にレプリケーションされるタイプのポリシーです。特定のリージョンの選択はできません。
Terraform：インフラストラクチャをコードとして定義し、管理するためのツールです。多数のクラウドサービスに対応していますが、シークレットのレプリケーションポリシーの設定には直接使用できません。
組織ポリシー：Google Cloudリソースに対する制約を定義するためのポリシーです。一定のルールを組織全体に適用することができます。しかし、シークレットの特定のリージョンへのレプリケーションを直接制約することはできません。
正解についての説明：
（選択肢）
・ユーザーが管理するレプリケーションポリシーでシークレットを作成し、準拠したロケーションのみを選択します
この選択肢が正解の理由は以下の通りです。
Secret Managerにはユーザー管理のレプリケーションポリシーがあります。これは、シークレットとそれらのレプリカが作成および保存されるリージョンを細かく指定することを可能にします。europe-west1とeurope-west4のような特定のリージョンにシークレットを制限したいときには、このレプリケーションポリシーを使用することで、シークレットのペイロードをそれらのリージョンにのみ持たせることができます。
また、この方法を使用すれば、これらのリージョン内でシークレットが高度に可用性を持つことを保証できます。というのも、シークレットとそれらのレプリカはそれぞれのリージョン内で自動的に複製され、冗長性が提供されます。それゆえ、特定のリージョンにデータの所在地を制限しつつ高可用性を確保するためには、ユーザーが管理するレプリケーションポリシーでシークレットを作成し、準拠したロケーションのみを選択するのが最適な方法となります。
不正解についての説明：
選択肢：自動レプリケーションポリシーでシークレットを作成し、準拠したロケーションのみを選択します
この選択肢が正しくない理由は以下の通りです。
自動レプリケーションポリシーを使用するとシークレットは全てのリージョンに自動的にレプリケートされるため、指定した"europe-west1"および"europe-west4"以外のリージョンにもペイロードが保存されてしまうため、この要件を満たすことができません。なお、ユーザーが管理するレプリケーションポリシーを使用すれば特定のリージョンのみを対象としたシークレットの作成が可能です。
選択肢：Terraformを使って2つのシークレットを作成し、1つはeurope-west1に、もう1つはeurope-west4に置きます
この選択肢が正しくない理由は以下の通りです。
Terraformを使って2つのシークレットを別々に作成すると、それらは独立したシークレットとなり、リージョン間の同期が自動的に行われません。そのため、一方のリージョンでシークレットが更新された場合、それが他のリージョンに反映されないため、高度に利用可能であるとは言えません。
一方、ユーザーが管理するレプリケーションポリシーでは、同一のシークレットが複数のリージョンにレプリケーションされ、必要なデータ所在地の要件を満たしながら高可用性を保てます。
選択肢：シークレットを自動複製ポリシーで作成し、コンプライアンスに準拠していない場所でのシークレット作成を拒否する組織ポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
シークレットを自動複製ポリシーで作成すると、Googleが管理するリージョンにデータが複製されますが、それはユーザーの要件である特定のリージョン（europe-west1とeurope-west4）に限定されません。
一方、ユーザーが管理するレプリケーションポリシーを使用すれば、シークレットを特定のリージョンにのみ保持することが可能です。
参考リンク：
https://cloud.google.com/secret-manager/docs/configuring-replication
https://cloud.google.com/secret-manager/docs/locations
https://www.terraform.io/docs/providers/google/r/secret_manager_secret.html
</div></details>

### Q.  問題27: 未回答
あなたは会社のインシデント対応計画を策定しています。Google Cloud環境におけるデプロイの問題をレビューし調査する際に、DevOpsチームが使用するアクセス戦略を定義する必要があります。主な要件は2つあります：
- 最小特権アクセスを常に強制します。
- DevOpsチームは、デプロイの問題が発生している間だけ、必要なリソースにアクセスできなければなりません。
Googleが推奨するベストプラクティスに従いつつ、どのようにアクセスを許可すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud環境でDevOpsチームがデプロイの問題を調査するためのアクセス戦略を定義する情境が設けられています。必要なのは、"最小特権"の原則に基づきつつ、問題発生時のみ必要なリソースへのアクセスを許可する戦略を策定することです。つまり、全面的なアクセスや不必要な特権を持たせる方法は避け、適切な範囲での権限管理が求められます。また、Googleのベストプラクティスを考慮に入れつつ、適切なIAM（Role-based access control）の設定を選ぶことが重要です。
基本的な概念や原則：
最小特権の原則：必要最小限の権限のみをユーザーやシステムに与えるというセキュリティの原則です。無駄な権限を与えることで生じるリスクを軽減します。
特権のエスカレーション：一時的に必要な権限を付与するための制御です。問題が発生した際に、必要な作業を行うためだけに一時的に権限を上げることがあります。
IAM（Identity and Access Management）：Google Cloudの認証と認可を管理するサービスです。ユーザーやサービスアカウントに対し、リソースへのアクセスをコントロールするロールを割り当てます。
IAMロール：Google Cloudのリソースへの特定の操作権限を集約したものです。プリデファインドロールとカスタムロールがあります。
カスタムIAMロール：必要な権限を独自に集約したIAMロールです。アクセスの粒度を細かく調整できます。
サービスアカウント：アプリケーションがGoogle Cloudリソースとやり取りするための特別なタイプのGoogleアカウントです。サービスアカウントはIAMの認証および認可の対象となります。
Project Viewer IAMロール：プロジェクト全体のリソースを閲覧可能なIAMロールです。一部の操作や書き込み権限などは制限されています。
正解についての説明：
（選択肢）
・リスト/ビュー権限を制限したカスタムIAMロールを作成し、DevOpsチームに割り当てます
この選択肢が正解の理由は以下の通りです。
最小特権アクセスとは、アクセス必要なリソースに対する権限のみをユーザーに付与することを指します。この考え方はセキュリティを強化し、要件を達成する上で非常に重要です。Google Cloudでは、この原則に基づきIAMのロールをカスタマイズすることができます。
したがって、デプロイの問題が発生しているときにのみ、限定的なリスト/ビュー権限をDevOpsチームに割り当てるカスタムIAMロールを作成すれば、要件達成に対して最適な戦略となります。ユーザーが必要なリソースにだけアクセスできるようにすることで、セキュリティリスクを最小限に抑えつつ作業の効率性を維持することが可能となります。
不正解についての説明：
選択肢：Project Viewer IAMロールをDevOpsチームに割り当てます
この選択肢が正しくない理由は以下の通りです。
Project Viewer IAMロールは、プロジェクト全体の閲覧権限を提供します。これは最小特権原則に反しており、DevOpsチームがデプロイの問題解決のために必要とする特定のリソースへのアクセスよりも広範な権限を付与することになります。
選択肢：サービスアカウントを作成し、Project Owner IAMロールを付与します。このサービスアカウントのService Account UserロールをDevOpsチームに与えます
この選択肢が正しくない理由は以下の通りです。
サービスアカウントへのProject Owner IAMロールの付与は、最小特権アクセスの原則に反するため不適切です。
また、DevOpsチームが必要なリソースにのみ限定的なアクセスを持つ設定ではありません。これに比べると、カスタムIAMロールは必要なリソースにピンポイントで制限された権限を設定する事が可能です。
選択肢：サービスアカウントを作成し、限定的なリスト/ビュー権限を付与します。このService Account UserロールをDevOpsチームに与えます
この選択肢が正しくない理由は以下の通りです。
サービスアカウントはアプリケーションに特化した認証の手段で、DevOpsチームのユーザーアクセス管理には適切ではありません。
また、DevOpsチームがサービスアカウントを使う場合、最小特権の原則の適用が難しくなります。
これに対し、IAMロールは特定の権限を持つユーザーに割り当て、調査やレビュー時に限定的なアクセスを提供することが可能です。
参考リンク：
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/iam/docs/creating-custom-roles
https://cloud.google.com/iam/docs/granting-changing-revoking-access
</div></details>

### Q.  問題28: 未回答
あなたはBigQueryの機密性の高いデータを保護する責任があります。業務チームはこのデータにアクセスする必要がありますが、プライバシー規制を考慮し、メールアドレスや名前などの機密フィールドを読み取れないようにしたいと考えています。これらの特定の機密フィールドは、人事チームのみが知る必要がある場合にのみ利用できるようにする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、BigQueryの機密性の高いデータを管理するプロセスを理解するための情報が必要となります。プライバシー規制と人事チームのみが必要とする情報へのアクセス制限の要件から、特定のフィールドに対する保護措置が必要であり、読み取りを制限しながらデータの使用を可能にする必要があります。これら要件から考えると、データを保護しつつ特定のユーザーのみがアクセス可能な方法を選択するという視点で進めるべきです。そこで、Google Cloudのサービスの中でデータの利用と保護を適切にバランスさせるものを選ぶことが重要となります。
基本的な概念や原則：
BigQuery：大量のデータを迅速に分析するためのGoogle Cloudのフルマネージドなビッグデータ分析サービスです。
Cloud Data Loss Prevention（DLP）API：データを検査し、削除、マスク、トークン化などの操作を介して機密情報を保護するGoogle Cloudのサービスです。
トークン化：元の情報とは別の一意の代替情報に置き換えることで、データの機密性を保護する手法です。トークン化したデータは、元の形式に戻すための適切な権限がなければ解読できません。
データマスキング：機密情報の一部または全体を遮蔽または変更することで、データの機密性を保護する手法です。データマスキングは一方向で、元の形式に戻すことはできません。
データの再編集：データを新しい形式に組み替えることで、個別の情報を匿名化し、機密情報を保護する手法です。
データ検査：データに含まれる機密情報を検出するプロセスです。DLP機能の一部として、機密データを見つけ、保護策を施すために使用されます。
正解についての説明：
（選択肢）
・Cloud Data Loss Prevention APIを使用して仮名化のためのトークン化を実行し、そのデータを後で使用するためにBigQueryに保存します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Data Loss Prevention（DLP）APIは、機密性の高い情報を自動的に検出、分類、そしてマスキングすることができるGoogle Cloudのサービスです。仮名化の一環としてトークン化を行うことにより、個々の機密フィールド（例えばメールアドレスや名前など）を元の値から識別不可能な値に置き換えることができます。こうすることで、業務チームが依然として必要なデータにアクセスしつつ、機密情報を保護することが可能となります。
さらに、必要となった場合にのみ人事チームが元の情報にアクセスできるようにするためには、DLP APIが生成したトークンと元のデータの対応関係を管理することが必要です。これにより、特定のユーザーがトークンを元のデータに逆変換する権限を与えることができます。
そして、そのデータをBigQueryに保存することで、すべてのデータは一箇所で管理され、アクセス制御と分析が容易になります。以上の理由から、この選択肢が最適な解決策といえます。
不正解についての説明：
選択肢：Cloud Data Loss Prevention APIを使用してデータマスキングを実行し、そのデータを後で使用できるようにBigQueryに保存します
この選択肢が正しくない理由は以下の通りです。
データマスキングはデータの一部を隠しますが、元の値を復元できる保証がないため、人事チームがのちにソースデータにアクセスする必要があるこのシナリオには適していません。それに比べて、トークン化は元の値の復元を可能にします。
選択肢：Cloud Data Loss Prevention APIを使用してデータの再編集を実行し、そのデータを後で使用できるようにBigQueryに保存します
この選択肢が正しくない理由は以下の通りです。
データの再編集は情報を無作為な値に置き換えますが、元の情報に戻すことはできません。しかし、要件では人事チームが元の情報にアクセスできる必要があるため、再編集ではなく仮名化のためのトークン化を行うべきです。
選択肢：Cloud Data Loss Prevention APIを使用してデータ検査を実行し、そのデータを後で使用できるようにBigQueryに保存します
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Prevention APIを使用してデータ検査を行うと、そのデータから機密情報を見つけてマークすることはできますが、仮名化のトークン化を行わないため、機密データを読み取れないようにする要件を満たすことはできません。
参考リンク：
https://cloud.google.com/dlp/docs/tokenization
https://cloud.google.com/bigquery/docs/column-level-security-intro
https://cloud.google.com/bigquery/docs/best-practices-security-controls
</div></details>

### Q.  問題29: 未回答
ある組織の典型的なネットワークとセキュリティのレビューは、アプリケーションのトランジットルート、リクエスト処理、ファイアウォールルールの分析で構成されています。開発チームは、このような完全なレビューのオーバーヘッドなしに新しいアプリケーションをデプロイできるようにしたいと考えています。
あなたはこの組織にどのように助言すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、開発チームがアプリケーションをデプロイする際にネットワークとセキュリティのレビューのオーバーヘッドを減らす方法について問われています。ここで重要なのは、選択肢が提示するソリューションがネットワークとセキュリティの管理をどの程度自動化し、レビューの負荷やエラーを減らすかです。また、開発チームの生産性と継続的なデリバリーを確保しながらも、セキュリティとコンプライアンスの要件を満たすソリューションを選ぶことが重要です。
基本的な概念や原則：
インフラストラクチャアズコード（IaC）：ソフトウェアのプロビジョニングと管理を自動化するための手法です。コードによりインフラストラクチャを定義・管理することで、開発とオペレーションズの間のギャップを埋めます。
CI/CDパイプライン：継続的インテグレーション（CI）と継続的デリバリ（CD）を組み合わせた開発プロセスです。新しいコードの変更を自動的にビルド、テスト、デプロイすることで、開発の効率とアプリケーションの信頼性を向上させます。
静的解析：プログラムが実行される前にコードを検査し、エラーや問題点を識別する手法です。CI/CDパイプライン内で適用されることが多く、問題を初期段階で検出・修正することを可能にします。
ポリシーの強制：組織のガバナンスやコンプライアンスポリシーを強制的に適用する手法です。IaCと組み合わせることで、自動化されたポリシー管理を実現します。
Forseti：Google Cloudの環境全体にわたるセキュリティポリシーとデータのガバナンスを管理するオープンソースツールです。
VPCトラフィック：Virtual Private Cloud（VPC）内でのネットワークトラフィックです。安全性を維持しながら、アプリケーション間での通信を可能にします。
正解についての説明：
（選択肢）
・Infrastructure as Codeの使用を義務付け、CI/CDパイプラインで静的解析を行い、ポリシーを実施します
この選択肢が正解の理由は以下の通りです。
まず、"Infrastructure as Code"の使用は開発チームによる新しいアプリケーションのデプロイを自動化し、そして確実に行うことを可能にします。比較的一貫した環境を提供し、手動操作によるエラーや誤解を軽減します。
次に、CI/CDパイプラインを用いて静的解析を行うことで、組織のネットワークとセキュリティのレビュープロセスを自動化することができます。このステップではコードのリクエスト処理、トランジットルート、ファイアウォールルールについて自動的に分析し、問題や欠陥を早期に発見して修正します。
最後に、ポリシーの実施により、Infrastructure as Codeのプロセスで定義された要件が適切に遵守され、セキュリティとその他の基準が維持されることを確認します。
以上の組み合わせによりこの選択肢が適切になります。開発チームが新しいアプリケーションを迅速かつ効率的にデプロイすることを可能にする一方で、組織のセキュリティとネットワークの基準を遵守します。
不正解についての説明：
選択肢：Forsetiとファイアウォールフィルターを併用することで、本番環境での不要なコンフィギュレーションを検出することができます
この選択肢が正しくない理由は以下の通りです。
Forsetiとファイアウォールフィルターの併用は不要なコンフィギュレーションを検出する一方で、新しいアプリケーションをデプロイするオーバーヘッドを軽減する効果は限定的です。
一方、Infrastructure as CodeをCI/CDパイプラインで静的解析するアプローチは、安全性を維持しつつ実装のオーバーヘッドを軽減します。
選択肢：すべてのVPCトラフィックを顧客が管理するルーター経由でルーティングし、本番環境における悪意のあるパターンを検出します
この選択肢が正しくない理由は以下の通りです。
すべてのVPCトラフィックを顧客が管理するルーター経由でルーティングすることは、セキュリティチェックを行うための一つの手段ではありますが、これだけでは新しいアプリケーションのデプロイのオーバーヘッドを解消しません。
それに対して、Infrastructure as CodeとCI/CDパイプラインの採用は、新しいアプリケーションのデプロイを自動化し、セキュリティチェックも自動で行うことができ、オーバーヘッドを大幅に削減します。
選択肢：本番アプリケーションはすべてオンプレミスで実行します。開発者はGoogle Cloudを開発およびQAプラットフォームとして自由に使えるようにします
この選択肢が正しくない理由は以下の通りです。
開発者がGoogle Cloudを開発およびQAプラットフォームとして自由に使えるようにするだけでは、ネットワークとセキュリティのレビューのオーバーヘッドを削減することはできません。ただし、Infrastructure as Codeを使用し、CI/CDパイプラインで静的解析を行うとポリシーを自動的に実施できるため、レビューのオーバーヘッドが削減できます。
参考リンク：
https://cloud.google.com/architecture/devops/devops-tech-infrastructure-as-code
https://cloud.google.com/security-command-center/docs/concepts-security-sources-forseti
https://cloud.google.com/vpc/docs/firewalls
</div></details>

### Q.  問題30: 未回答
組織のゼロトラスト戦略の一環として、Identity-Aware Proxy（IAP）を使用して複数のアプリケーションを保護しています。セキュリティ情報とイベント管理（SIEM）システムにログを取り込み、侵入の可能性を警告する必要があります。
どのログを分析すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ゼロトラスト戦略を実行するためのIdentity-Aware Proxy（IAP）と、侵入可能性を警告するためのセキュリティ情報とイベント管理（SIEM）システムのログの統合に焦点を当てています。正しいログを選択するためには、各ログが提供する情報とその目的について理解することが重要です。選択肢を検討する際には、侵入可能性を警告するために最も適したログとして、最も関連性の高いログを選ぶことが求められます。
基本的な概念や原則：
Identity-Aware Proxy（IAP）：Google Cloud上のアプリケーションとリソースへの安全なアクセスを提供するサービスです。VPNやファイアウォールの代わりに使用できます。
ゼロトラスト戦略：信頼とアクセスを前提とせず、すべてのユーザーとデバイスを潜在的に不安全とするセキュリティ戦略です。最小限の権限を与え、継続的な認証と承認を要求します。
データアクセス監査ログ：Google Cloudサービスが提供するデータを読み取ったり、書き込んだり、修正したりしたときに記録されるログです。セキュリティ上の脅威を監視するために使用されます。
SIEMシステム：セキュリティ情報とイベント管理を行うシステムです。セキュリティ関連のログとイベントを集約し、解析して警告を出すなどの機能を持ちます。
管理者の活動監査ログ：Google Cloudプロジェクトで管理者が行った操作を記録するログです。主に管理者周りの監視やトラブルシューティングに使用されます。
ポリシー拒否の監査ログ：ポリシーが適用されてアクションが拒否された場合に記録されるログです。不正なアクセスや操作を防ぐために使用されます。
Cloud Identityユーザーログイベント：Cloud Identityでのユーザーのログイベントを記録したものです。ユーザーベースの監視や分析に使用されます。
正解についての説明：
（選択肢）
・データアクセス監査ログ
この選択肢が正解の理由は以下の通りです。
Identity-Aware Proxy（IAP）は、Google Cloudリソースへのアクセスを制御するのに使われます。ユーザーまたはサービスがリソースにアクセスを試みたときに、IAPはそのアクセス試行を記録します。データアクセス監査ログは、これらのアクセス試行を詳細に捉える一方で、リソースへの読み取り、書き込み、更新操作も記録します。監査ログはリソースの変更などの重要なイベントをトラックし、異常行動や不適切なアクセスを特定するのに役立ちます。
したがって、SIEMシステムに取り込むために分析すべきログとして、データアクセス監査ログは有効で、侵入やその他のセキュリティ脅威の早期警告となる情報を提供します。これは、ゼロトラスト戦略を実装する上で極めて重要です。
不正解についての説明：
選択肢：ポリシー拒否の監査ログ
この選択肢が正しくない理由は以下の通りです。
ポリシー拒否の監査ログは、ある操作がGoogle CloudのIAMポリシーにより拒否された場合に生成されます。しかし、Identity-Aware Proxyの使用に関しては、データアクセス監査ログがもっと詳しい情報を提供します。これには認証や認可など、IAPの保護下にあるリソースへのアクセス試行に関する情報が含まれます。
選択肢：Cloud Identityユーザーログイベント
この選択肢が正しくない理由は以下の通りです。
Cloud Identityユーザーログイベントはユーザーの身元やログイン情報を追跡しますが、アプリケーションへのアクセスや侵入の可能性に関する直接的な情報は含まれません。
それに対して、データアクセス監査ログはユーザーやサービスがGoogle Cloudのデータにどのようにアクセスしたかの詳細な記録を提供し、侵入の検知に役立ちます。
選択肢：管理者の活動監査ログ
この選択肢が正しくない理由は以下の通りです。
管理者の活動監査ログは、Google Cloud上の管理者によるリソース操作などの活動を記録しますが、IAPを通じたアクセス情報は詳細に記録されません。
それに対して、データアクセス監査ログはIAPによるデータへのアクセスを詳細に記録するため、侵入の可能性を警告するのに必要なログを提供します。
参考リンク：
https://cloud.google.com/iap/docs/audit-log-howto
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/security-command-center/docs/how-to-use-security-sources#logging
</div></details>

### Q.  問題31: 未回答
脆弱性に対するパッチがリリースされ、DevOpsチームはGoogle Kubernetes Engine（GKE）で実行中のコンテナをアップデートする必要があります。
DevOpsチームはどのようにこれを達成すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、パッチのリリース後にGoogle Kubernetes Engine（GKE）で実行中のコンテナをアップデートするための最適な方法を尋ねています。ここで重要なのは、コンテナテクノロジーの原則とプラクティス、特にイミュータブルなインフラストラクチャの概念への理解です。実行中のコンテナに直接パッチを適用するのではなく、新しいコンテナイメージを構築してデプロイする適切な方法を探る必要があります。
基本的な概念や原則：
コンテナイメージ：アプリケーションとその依存関係をパッケージ化し、ランタイム環境を抽象化するための可搬性のあるエンティティです。これは更新やパッチを適用するために再構築され得ます。
Google Kubernetes Engine（GKE）：Google Cloud上でコンテナ化されたアプリケーションを実行するためのマネージド、収縮可能な環境の提供サービスです。
再デプロイ：新しいバージョンのアプリケーションまたはパッチの適用後に、アプリケーションまたはサービスを実行環境に戻す手続きです。
DevOps：開発と運用部門の間で効率的に協力して作業を進めるための哲学及びプラクティスです。"Dev"はソフトウェア開発、"Ops"はIT運用を表します。
Puppet、Chef：ITインフラストラクチャの自動化と管理を補助するツールです。ハードウェア構成やアプリケーション設定などの監視及び自動化に役立ちますしかし、実行中のコンテナにパッチをプッシュするのは推奨されません。
Container Registry：Dockerイメージのプライベートストレージとデリバリーサービスです。安全にイメージを保存、管理、デプロイできます。
正解についての説明：
（選択肢）
・アプリケーションコードを更新するかパッチを適用して、新しいイメージを構築し、再デプロイします
この選択肢が正解の理由は以下の通りです。
Google Kubernetes Engine（GKE）で運用するコンテナイメージは不変であり、直接更新またはパッチ適用を行うことは原則として行われません。その代わり、アプリケーションコードを更新したりパッチを適用したりした上で新しいイメージを構築することで、その修正を反映します。新しいイメージが構築されれば、それを基にコンテナを再デプロイすることで継続的にサービスを提供しながら更新が行われます。
これは、不変のインフラストラクチャの原則に基づくもので、一旦デプロイされたインフラストラクチャは変更せず、必要な変更がある場合は新たに構築するという考え方です。これにより、システムの信頼性を保ちつつ、脆弱性への対応や改善を迅速に行うことが可能となります。
不正解についての説明：
選択肢：PuppetまたはChefを使って、実行中のコンテナにパッチをプッシュします
この選択肢が正しくない理由は以下の通りです。
PuppetやChefは主にVMなどの伝統的なサーバ管理用のツールであり、コンテナのパッチ適用には適しません。正解の選択肢はイメージを更新して再デプロイすることで、これがコンテナの最善のパッチ適用手段です。
選択肢：自動アップグレードが有効になっていることを確認します。有効になっている場合、GoogleはGKEクラスター内のノードをアップグレードします
この選択肢が正しくない理由は以下の通りです。
自動アップグレードが有効になっていると、GKEクラスターのノードはGoogleによって更新されますが、これはノードのOSやKubernetes自体のアップデートを指します。アプリケーション内のコードやパッチの適用は含まれていません。そのため、新しいイメージを作成して再デプロイする必要があります。
選択肢：Container Registryでベースイメージが利用可能になったときに、自動的にアップグレードするようにコンテナを設定します
この選択肢が正しくない理由は以下の通りです。
Container Registryでベースイメージが利用可能になったときに自動的にアップグレードする設定は存在しません。実際には、アプリケーションコードを更新するかパッチを適用して新しいイメージを構築し、再デプロイする必要があります。これにより、安全な最新版のコンテナイメージに更新することが可能です。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps
https://cloud.google.com/kubernetes-engine/docs/concepts/node-auto-upgrades
https://cloud.google.com/container-registry/docs/managing-images
</div></details>

### Q.  問題32: 未回答
あなたは、Secret Managerに保存されている組織の秘密の新しいガバナンスモデルを設計しています。現在、本番用アプリケーションと非本番用アプリケーションのシークレットは、サービスアカウントを使用して保存され、アクセスされています。提案されたソリューションの要件は以下のとおりです。
- シークレットへのきめ細かなアクセス
- シークレットをラップする暗号化キーのローテーションスケジュールを制御できること
- 環境の分離を維持すること
- 管理を容易にすること
要件を満たすために、どのアプローチを取るべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudのSecret Managerを使用して、本番環境と非本番環境のシークレットのガバナンスモデルを設計する必要があります。制御できる暗号化キーのローテーション、環境の分離、管理の容易さを必要とするため、これらの要件を満たす要素を含む最適なアプローチを選択することが重要です。シークレットのアクセス制御と暗号化に関し、Identity and Access Management（IAM）、Google Cloudプロジェクト、暗号化キーの管理方法など、各要素のロールと機能の理解を期待されています。
基本的な概念や原則：
Secret Manager：シークレットの管理とアクセスを制御するGoogle Cloudのツールです。信頼性、スケーラビリティ、セキュリティを提供し、秘密データの暗号化と保管を行います。
Google Cloudプロジェクト：Google Cloudのリソースを組織化、管理するためのユニットです。プロジェクトは使用量の追跡、API利用の制御、アクセス許可など、リソースに対する全体的な設定を提供します。
Identity and Access Management（IAM）：Google Cloud環境へのアクセスを制御するツールです。指定したロールやポリシーに基づいて、特定のユーザーが行える操作を精密に定義します。
顧客管理の暗号化キー：キーの生成、保存、管理をユーザーが行う方式です。暗号化キーのライフサイクルを完全に制御でき、より高度なセキュリティ要件を満たします。
正解についての説明：
（選択肢）
・1.本番用と非本番用のシークレットを保存するために、別々のGoogle Cloudプロジェクトを使用します
2.プロジェクトレベルのIdentity and Access Management（IAM）バインディングを使用して、シークレットへのアクセス制御を実施します
3.顧客管理の暗号化キーを使用して秘密を暗号化します
この選択肢が正解の理由は以下の通りです。
まず、要件は環境の分離と管理の容易さを求めています。別々のGoogle Cloudプロジェクトを使用することで、本番用と非本番用のシークレットを物理的に分離し、これを制御することが可能になります。複数のプロジェクトを使用することで、それぞれの環境のリソースが互いに混在することがなくなり、管理が容易になります。
次に、プロジェクトレベルのIAMバインディングを使用することで、シークレットへのきめ細かなアクセス制御を実施することが可能です。特定のユーザーやサービスアカウントが本番用または非本番用のシークレットにどの程度アクセスできるかを細かく制御でき、シークレットのガバナンス強化に寄与します。
最後に、顧客管理の暗号化キーを使用して秘密を暗号化することで、シークレットをラップする暗号化キーのローテーションスケジュールを制御する手段を持つことができます。Googleがシークレット用のデフォルト暗号化キーを提供していますが、要件は独自のキーを制御できることを求めているため、提供された選択肢は要件を満たしています。
不正解についての説明：
選択肢：1.単一のGoogle Cloudプロジェクトを使用して、本番環境と非本番環境の両方のシークレットを保存します
2.シークレットレベルのIdentity and Access Management（IAM）バインディングを使用して、シークレットへのアクセス制御を実施します
3.Googleが管理する暗号化キーを使用して、シークレットを暗号化します
この選択肢が正しくない理由は以下の通りです。
単一のGoogle Cloudプロジェクトで本番環境と非本番環境のシークレットを保存すると、環境の分離要件が満たされません。
また、Googleが管理する暗号化キーを使用すると、秘密の暗号化キーのローテーションスケジュールを制御する能力が失われます。
これに対し、別々のプロジェクトと顧客管理暗号化キーを使用する正解選択肢はこれらの要件を満たします。
選択肢：1.本番用と非本番用のシークレットを保存するために、別々のGoogle Cloudプロジェクトを使用します
2.シークレットレベルのIdentity and Access Management（IAM）バインディングを使用して、シークレットへのアクセス制御を実施します
3.シークレットの暗号化には、Googleが管理する暗号化キーを使用します
この選択肢が正しくない理由は以下の通りです。
まず、シークレットレベルのIdentity and Access Management（IAM）バインディングはSecret Managerでは対応していません。提供されるのはプロジェクトレベルのIAMバインディングのみです。
また、要件にはシークレットをラップする暗号化キーのローテーションスケジュールを制御できることが含まれていますが、Googleが管理する暗号化キーはユーザーが直接制御できないため、この選択肢は要件を満たさないです。
選択肢：1.単一のGoogle Cloudプロジェクトを使用して、本番環境と非本番環境の両方のシークレットを保存します
2.プロジェクトレベルのIdentity and Access Management（IAM）バインディングを使用して、シークレットへのアクセス制御を実施します
3.顧客管理の暗号化キーを使用して秘密を暗号化します
この選択肢が正しくない理由は以下の通りです。
この選択肢では、本番と非本番のシークレットが同じプロジェクトに保存されているため、環境の分離が保たれていません。
それに対して、正解では本番と非本番のシークレットを別々のプロジェクトに保存することで、環境の分離を適切に行っています。
参考リンク：
https://cloud.google.com/secret-manager/docs
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://cloud.google.com/kms/docs/secret-management
</div></details>

### Q.  問題33: 未回答
あなたの組織は、CIS Google Cloud Computing Foundations Benchmark v1.3.0（CIS Google Cloud Foundation 1.3）に対して継続的に評価されることを望んでいます。コントロールの中には、組織と無関係なものもあり、評価の際に無視しなければなりません。関連するコントロールのみが評価されるように、自動化されたシステムまたはプロセスを作成する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、組織がCIS Google Cloud Computing Foundations Benchmarkに対して継続的に評価されることを望んでおり、その過程で無関係な評価を無視するような自動化システムを作成する方法を探しています。重要なことは、適切なGoogle Cloudのセキュリティツールを選択すること、そしてそれをどのように設定するかです。特定のツールが提供している機能を理解し、それらが組織のセキュリティ要件にどのように適合するかを検討することが必要です。これにより、適切な自動化プロセスを確立し、規範に準拠しつつ無関係なコントロールを無視することが可能になります。
基本的な概念や原則：
CIS Google Cloud Computing Foundations Benchmark：CIS（Center for Internet Security）によって提供される、Google Cloudのセキュリティ基準のセットです。これは、Google Cloudのセキュリティ設定を評価・強化するための最善の手法を提供します。
Security Command Center（SCC）：Google Cloudの統合されたリスク報告ダッシュボードで、Google Cloudの資産とデータを保護するための洞察とデータを提供します。セキュリティ調査結果をミュート（無視）することも可能です。
セキュリティ例外：セキュリティの評価プロセスで、特定の条件下で許可されるセキュリティルールの違反を指します。セキュリティ例外を適切にマークし、管理することは、全体的なセキュリティガバナンスの一部です。
CSVファイル：データを表形式で保存するためのプレーンテキスト形式の一種です。セキュリティ調査結果をエクスポートする際に用いられます。
外部監査：独立した第三者が組織のプロセス、システム、操作を審査し、その結果を報告することです。これにより、組織は潜在的なリスクを特定し、必要な改善を行うことができます。
正解についての説明：
（選択肢）
・Security Command Center（SCC）Premiumをアクティベートします。SCCでセキュリティ調査結果をミュートするルールを作成し、評価されないようにします
この選択肢が正解の理由は以下の通りです。
まず、Security Command Center（SCC）Premiumは、Google Cloudの脆弱性と脅威を継続的に表示し、分析するためのセキュリティ管理プラットフォームです。SCC Premiumの特徴の一つは、CIS Google Cloud Foundationの基準に対する修正可能なコントロールの評価を自動化する機能です。逆に言えば、これにより継続的な評価が可能となります。
また、SCCでは"ミュートのルール"を作成することが可能で、これにより特定のセキュリティ調査結果を評価から除外することができます。つまり、組織と無関係なコントロールを評価対象から除外する要件も満たされます。
このように、SCC Premiumをアクティベートし、ミュートのルールを作ることで、自動化されたシステムが関連するコントロールだけを評価し、無関係なものは評価から除外するという要件を満たすことが可能となります。
不正解についての説明：
選択肢：無関係なすべてのセキュリティ所見に、セキュリティ例外を示すタグと値をマークします。マークされた調査結果をすべて選択し、表示されるたびにコンソール上でミュートします。Security Command Center（SCC）Premiumをアクティブ化します
この選択肢が正しくない理由は以下の通りです。
Security Command Center（SCC）を使うのは適切ですが、組織が継続的に評価されることを望むため、その都度コンソール上で手動でミュートするという方法は効率的ではありません。自動化されたプロセスを作成するためには、SCCでミュートするルールを設定することが必要です。
選択肢：Security Command Center（SCC）からすべての調査結果をCSVファイルにダウンロードします。ファイル内のCIS Google Cloud Foundation 1.3の一部である調査結果をマークします。関連性がなく、会社のスコープ外のエントリは無視します
この選択肢が正しくない理由は以下の通りです。
CSVファイルへのダウンロードを用いた方法は、適切なセキュリティ調査結果の除外が自動化されていないため不適切です。自動化されたシステムやプロセスを求められる問題文の要求に対して、この手法は手動での作業が必要となります。
一方、SCC Premiumを用いる正解の選択肢では評価結果をミュートするルールを作成することで自動化が実現でき、問題文の要求を正確に満たしています。
選択肢：外部監査会社に、必要なCISベンチマークを含む独立した報告書の提出を依頼します。監査範囲において、一部の管理は不要であり、無視しなければならないことを明確にします
この選択肢が正しくない理由は以下の通りです。
外部監査会社に依頼することは自動化されたシステムまたはプロセスの作成とは言えず、自動化要件を満たしません。
また、この方法では継続的な評価が難しく、評価が関連するコントロールのみに限定される保証もありません。
それに対して、Security Command Centerでは、必要なベンチマークを自動化して継続的に評価し、特定の調査結果をミュートすることで、関連しない管理を排除することが可能です。
参考リンク：
https://cloud.google.com/security-command-center/docs/how-to-use-mute-findings
https://cloud.google.com/security-command-center/docs/concepts-security-command-center-overview
https://www.cisecurity.org/benchmark/google_cloud_computing_platform/
</div></details>

### Q.  問題34: 未回答
Google Cloudフットプリントのネットワークセグメンテーションを監査する必要があります。現在、本番環境と非本番環境のIaaS（Infrastructure-as-a-Service）環境を運用しています。すべてのVMインスタンスは、サービスアカウントをカスタマイズせずにデプロイされています。
カスタムネットワークのトラフィックを観察した結果、トラフィックを適切にセグメント化するためにタグベースのVPCファイアウォールルールが設定されているにもかかわらず、すべてのインスタンスが優先度1000で自由に通信できることに気づきました。この動作の最も考えられる理由は何ですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud環境におけるネットワークセグメンテーションの監査について考えます。異なる環境の仮想マシンが自由に通信できる、という状況が説明されています。問題のポイントは、VPCファイアウォールルールとネットワークタグの関係、そしてそれらの優先度について理解することです。VPCファイアウォールのルールは優先度に従って適用され、どのルールがどの仮想マシンに適用されるかを特定するためにネットワークタグが使用されることを鑑みると、問題を解くための解答選択肢を探す際に注意を払うべきポイントはこの二つです。
基本的な概念や原則：
ネットワークセグメンテーション：ネットワークトラフィックを異なる部分やセグメントに分割するセキュリティ戦略です。これにより、不正アクセスを防いだり、ネットワークの性能を向上させることができます。
サービスアカウント：Google Cloud上のアプリケーションに対して特定のロールや権限を付与するためのアカウントです。これにより、アプリケーションがGoogle Cloudのサービスに対して認証や認可を行うことができます。
タグベースのVPCファイアウォールルール：ネットワーク内のリソースにタグを付け、そのタグに基づいてファイアウォールルールを適用する方法です。これにより、ネットワークのセキュリティポリシーを柔軟に管理することができます。
VPC（Virtual Private Cloud）：Google Cloudの仮想プライベートネットワークサービスです。クラウド上でプライベートネットワーク環境を作成し、そのネットワーク内にあるリソース間の通信を管理することができます。
ファイアウォールルールの優先度：Google Cloud VPCでは、複数のファイアウォールルールがある場合、優先度の高いルール（数値が小さいほど高い）が先に適用されます。優先度が同じ場合、許可ルールが拒否ルールよりも先に適用されます。
正解についての説明：
（選択肢）
・すべてのVMインスタンスにそれぞれのネットワークタグがありません
・VPCファイアウォールルールが、同じサービスアカウントに基づくソース/ターゲット間のトラフィックを優先度999で許可しています
この選択肢が正解の理由は以下の通りです。
まず、"すべてのVMインスタンスにそれぞれのネットワークタグがありません"が重要です。たとえタグベースのVPCファイアウォールルールが設定されていても、それらのタグがVMインスタンスに適用されていなければ、それらのルールは機能しません。結果として、全てのVMインスタンスが自由に通信できてしまいます。つまり、各VMインスタンスに適切なネットワークタグを適用することが、トラフィックを適切にセグメント化するための必須要件となります。
次に、"VPCファイアウォールルールが、同じサービスアカウントに基づくソース/ターゲット間のトラフィックを優先度999で許可しています"も可能性のある問題です。確かに、すべてのVMインスタンスが同一のサービスアカウントでデプロイされていると、これらのインスタンス間のトラフィックは、同じサービスアカウントに基づくファイアウォールルールによって許可されます。このルールが優先度999で設定されていると、他の優先度1000のルールよりも優先され、これがすべてのインスタンスが自由に通信できる理由となります。
不正解についての説明：
選択肢：すべてのVMインスタンスは同じネットワークサブネットに存在します
この選択肢が正しくない理由は以下の通りです。
VMインスタンスが同じサブネットに存在していても、ファイアウォールルールが適用されるため、全てのインスタンスが自由に通信できるわけではありません。この選択肢は問題の事象と関連性が低く、正解の選択肢に比べて現象を説明する適切な理由とはなりません。
選択肢：すべてのVMインスタンスは同じネットワークルートで構成されています
この選択肢が正しくない理由は以下の通りです。
ネットワークルートは特定のIP範囲（または宛先）に向かうトラフィックの経路を決定しますが、トラフィックの許可や拒否、制御はVPCファイアウォールルールが担います。そのため同じネットワークルートを持つインスタンスでも、通信制限はファイアウォールルールにより異なります。
選択肢：VPCファイアウォールルールが、同じサービスアカウントに基づくソース/ターゲット間のトラフィックを優先度1001で許可しています
この選択肢が正しくない理由は以下の通りです。
VPCファイアウォールルールの優先度は数値が低いほど高くなります。つまり、優先度1000のルールよりも優先度1001のルールの方が優先度は低くなります。ですから、優先度1001のルールが設定されていても、すべてのインスタンスが自由に通信できるという状況を説明することはできません。
参考リンク：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/vpc/docs/using-firewalls
https://cloud.google.com/vpc/docs/vpc-networks-and-firewalls#priority
</div></details>

### Q.  問題35: 未回答
ある企業がCompute Engine上でアプリケーションを実行しています。このアプリケーションにバグがあり、悪意のあるユーザーがスクリプトを繰り返し実行し、その結果、Compute Engineのインスタンスがクラッシュしてしまいました。バグは修正されましたが、このハッキングが再発した場合に備えて通知を受け取りたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、悪意のあるユーザーによって引き起こされる潜在的なハッキングを監視し、それに関する通知を受け取ることに焦点を当てています。アプリケーションがCompute Engine上で実行され、過去にバグによりインスタンスがクラッシュしたという事実が重要です。また、バグ自体は修正されたが、再発に備えて通知が必要だとの要件も考慮する必要があります。Google Cloud Operation Suite、Cloud Logging、BigQueryの各機能をどのように利用すればハッキングの再発を検知できるかを理解することが重要です。さらに、シナリオは悪意のあるユーザーのスクリプトの繰り返し実行を特定するための適切な監視と通知策を見つけることに集中しています。
基本的な概念や原則：
Google Cloud Operation Suite：Google Cloudのパフォーマンスと健全性を監視、診断、アラート設定、操作の最適化、分析、表示を行うための統合管理ツールです。
アラートポリシー：異常な事態や重要な状況が発生した際に、指定した通知チャンネルから通知を受け取るための設定です。
プロセスの健全性条件：システムやアプリケーションの健全性を監視するための条件設定です。異常値や閾値を指定して、標準外の状態やクラッシュを検知します。
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションやシステムから生成されるログデータを一元的に管理し、分析と監視を行います。
メトリクス：パフォーマンスや利用状況を測定、トラッキングするための指標です。Google Cloudでは、メトリクスに基づいて監視やアラート設定を行うことが可能です。
BigQuery：Google Cloudのフルマネージド型、サーバーレス型の大規模なデータウェアハウスサービスです。大量のデータのクエリ実行を高速かつ柔軟に行うことが可能です。
ログシンク：Google CloudのLoggingで使用され、ログエントリをエクスポートするための機能です。シンクは特定の種類のログを指定したCloud Storage、BigQuery、Pub/Subへエクスポートします。
正解についての説明：
（選択肢）
・プロセスの健全性条件を使用して、Google Cloud Operation Suiteでアラートポリシーを作成し、スクリプトの実行回数が必要な閾値未満であることを確認します。通知を有効にします
この選択肢が正解の理由は以下の通りです。
Google Cloudのオペレーションスイートは、ログ監視、エラーレポート、アラートポリシーなど、一連の監視ツールを提供しています。アラートポリシーは特定の条件が満たされたときに通知を行う仕組みであり、これを使用してスクリプトの繰り返し実行や、その結果となるCompute Engineのインスタンスのクラッシュのような異常状態を検知し、事前に対策を立てることが可能になります。健全性条件を設定すれば、特定のプロセスや動作の状態を監視する事ができ、予期しない繰り返し実行が始まった際にすぐに検知し、通知を受け取ることができます。これにより、同様のハッキングが再発した場合も早期発見し迅速に対応することができます。
不正解についての説明：
選択肢：Google Cloud Operation Suiteで、CPU使用率メトリクスを使用してアラートポリシーを作成します。閾値を80%に設定し、CPU使用率がこの80%を超えた場合に通知されるようにします
この選択肢が正しくない理由は以下の通りです。
CPU使用率の高さは、アプリケーションに問題があることを必ずしも示しません。CPU使用率が80％を超えることは、アプリケーションが活発に動作しているだけかもしれません。ここでは特定のスクリプトの実行回数によるクラッシュを検知することが求められており、そのためにはプロセスの健全性条件を用いてアラートポリシーを作成する方が適しています。
選択肢：Cloud Loggingにスクリプトのすべての実行をログします。Cloud Loggingでログにユーザー定義のメトリックを作成し、メトリックを表示するGoogle Cloud Operation SuiteDashboardを作成します
この選択肢が正しくない理由は以下の通りです。
ダッシュボードはリアルタイムの監視に役立ちますが、特定の不正行為が再発した際の自動的な通知の提供はできません。通知を得るためにはCloud Operation Suiteのアラートポリシーが必要です。
選択肢：スクリプトの実行ごとにCloud Loggingにログを記録します。BigQueryをログシンクとして設定し、特定の時間枠内の実行回数をカウントするBigQueryスケジュールクエリを作成します
この選択肢が正しくない理由は以下の通りです。
BigQueryでログの解析を行うのは時間がかかり、クラッシュが起きてからの対応になってしまいます。対照的にGoogle Cloud Operation Suiteを使用すると、異常な状態が発生した瞬間に通知を受け取ることが可能なため、事前に問題を検知し対応することができます。
参考リンク：
https://cloud.google.com/monitoring/alerts/using-alerting-policies
https://cloud.google.com/logging/docs/logs-based-metrics
https://cloud.google.com/logging/docs/export/bigquery
</div></details>

### Q.  問題36: 未回答
Cloud Run上でアプリケーションを実行しています。脆弱性スキャンのためにコンテナ分析をすでに有効にしています。しかし、デプロイされるアプリケーションを制御できないことを懸念しています。信頼できるコンテナイメージのみがCloud Run上にデプロイされるようにしなければなりません。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud Run上で稼働するアプリケーションが信頼できるコンテナイメージのみを使用するように保証する方法が求められています。この問題の特徴として、複数の方策が存在する可能性と、各方策がどのように組織やシステム全体に影響を及ぼすかを考慮する必要があります。特に、バイナリ認証の概念を理解し、それがどのようにCloud Runやプロジェクト全体に影響を与えるかをよく把握することが必要です。それらを考慮して各選択肢を評価することで、最適な解答を見つけることができます。
基本的な概念や原則：
Cloud Run：Google Cloudのフルマネージドな実行環境で、コンテナベースのアプリケーションをサーバーレス環境で実行します。インフラストラクチャの管理を必要とせず、要求に応じて自動的にスケーリングします。
コンテナ分析：Google Cloudのサービスで、コンテナイメージの脆弱性を解析します。このサービスにより、開発者はコンテナイメージのセキュリティ情報を見つけ、理解、対応することができます。
バイナリ認証：Google Cloudのセキュリティ機能で、特定のソースからのみコンテナイメージをデプロイするためのポリシーを適用します。
組織ポリシー制約：Google Cloudの機能で、組織全体に対する規則や制約を設定します。これにより、特定のリソースの使用を制限したり、特定の機能の許可を管理したりできます。
Kubernetesクラスター：Kubernetesはコンテナ化されたアプリケーションのデプロイ、スケーリング、運用を自動化するオープンソースのプラットフォームです。クラスターは、コンテナアプリケーションを実行するための複数のノードから成るリソース群です。
Cloud Run breakglass：バイナリ認証に関する例外を設定するGoogle Cloudの機能です。正式なバイナリ認証に従うのではなく、イメージをデプロイする際の緊急措置として利用されます。
正解についての説明：
（選択肢）
・既存のCloud Runサービスでバイナリ認証を有効にします
・組織ポリシー制約constraints/compute.trustedImageProjectsを、信頼されたコンテナイメージを含むプロジェクトのリストに設定します
この2つの選択肢が正解の理由は以下の通りです。
まず、"既存のCloud Runサービスでバイナリ認証を有効にする"選択肢が優れている理由は、バイナリ認証を通じてGoogle Cloud上でデプロイされるコンテナイメージが信頼できるものであることを確認できるからです。バイナリ認証は、信頼できるデジタル署名が付いているイメージのみがデプロイされるようにする機能で、これにより不正や破損したイメージがシステム上で実行されるリスクが減少します。
次に、"組織ポリシー制約constraints/compute.trustedImageProjectsを、信頼されたコンテナイメージを含むプロジェクトのリストに設定する"選択肢が優れている理由は、この制約を使用することで組織レベルで信頼できるコンテナイメージの源を制御できるからです。これにより、Cloud Run上でデプロイするイメージが信頼できるプロジェクトからのものであることを保証できます。
この2つの選択肢を合わせることで、より強固なアプリケーションのデプロイ制御を実現できます。
不正解についての説明：
選択肢：組織ポリシー制約constraints/run.allowedBinaryAuthorizationPoliciesを、許可されるバイナリ認証ポリシー名のリストに設定します
この選択肢が正しくない理由は以下の通りです。
答えになっている選択肢は実際のGoogle Cloudの組織ポリシーに存在しますが、不正解の選択肢は存在しない組織ポリシー制約を端的に指定しています。
従って、そのようなポリシーを設定することは不可能となります。
選択肢：既存のKubernetesクラスターでバイナリ認証を有効にします
この選択肢が正しくない理由は以下の通りです。
問題文ではCloud Run上でアプリケーションが実行されているので、Kubernetesクラスターでのバイナリ認証は関連がありませんし、それによってCloud Runのコンテナイメージの信頼性を保証することはできません。
選択肢：Cloud Run breakglassを使用して、デフォルトでバイナリ認証ポリシーを満たすイメージをデプロイします
この選択肢が正しくない理由は以下の通りです。
Cloud Run breakglassはGoogle Cloudのサービスではないため、効果的なコンテナイメージ管理方法とは言えません。既存のCloud Runサービスでバイナリ認証を有効にし、組織ポリシー制約を設定する方が効果的です。
参考リンク：
https://cloud.google.com/binary-authorization/docs/using-binary-authorization
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/run/docs/configuring/container-images
</div></details>

### Q.  問題37: 未回答
あなたは会社のセキュリティ管理者です。Cloud Storageのバケットに3,000のオブジェクトがあります。あなたは各オブジェクトへのアクセスを個別に管理したくありません。
また、オブジェクトのアップロード者が常にオブジェクトを完全にコントロールできるようにしたくありません。しかし、Cloud Audit Logsを使ってバケットへのアクセスを管理したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud Storageのアクセス管理とオブジェクトのコントロールに関する要件を理解することが求められています。3000のオブジェクトを個別に管理したくなく、またアップローダが全てのオブジェクトを完全にコントロールすることを避けたいとの要件から、ユーザーアクセス管理（IAM）とバケットレベルのアクセス制御に的を絞って考えるべきです。さらに、Cloud Audit Logsを使ってバケットへのアクセスを追跡したいという点からも、IAMと組み合わせた管理策を探す方向が適切でしょう。
基本的な概念や原則：
統一アクセス：Google Cloud Storageのバケット内の全オブジェクトに対して一貫したアクセス制御を行うための機能です。個々のオブジェクトのアクセス権限を個別に管理せず、バケット全体として一括して管理します。
IAM：Google CloudのIdentity and Access Management（IAM）サービスです。ロールの割り当てを通じて、ユーザーやサービスアカウントへのリソースへのアクセスを制御します。
Cloud Audit Logs：Google Cloudのサービスが生成するログです。クレジットカードのトランザクションログのように、Cloudサービスの活動を記録します。
Access Control Lists（ACL）：ネットワーク、ファイル、その他のリソースへのアクセスを制御するための方法です。これはオブジェクトレベルでのアクセス制御を可能にします。ただし、このケースでは、ACLは推奨されない方法です。
allUsers：Cloud Storageで使用される特殊なエンティティで、オブジェクトまたはバケットに対するパブリックアクセスを許可します。このケースでは、allUsersに権限を設定すると、全てのユーザーがアクセスすることが可能になります。
正解についての説明：
（選択肢）
・Cloud Storageのバケットにバケットレベルの統一アクセスを設定し、IAMを使ってユーザーのアクセスを管理します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Storageのバケットレベルのアクセス制御を使用すると、3000のオブジェクトそれぞれに個別のアクセス管理を行う必要がなくなり、大量のオブジェクトに対する一元的なアクセス制御が可能になります。これにより、大量のオブジェクトに対する一括管理が容易になります。
また、バケットレベルのアクセス制御を設定すれば、オブジェクトのアップロード者がオブジェクトを完全にコントロールすることは防げます。なぜなら、オブジェクトレベルでのアクセス制御ではなく、バケット全体に対するアクセス制御になるからです。
さらに、IAMを利用しユーザのアクセスを管理すれば、Cloud Audit Logsでアクセス履歴をトラッキングし管理することができます。
したがって、この選択肢が正解となります。
不正解についての説明：
選択肢：allUsersのスコープにOWNER権限を持つACLを設定します
この選択肢が正しくない理由は以下の通りです。
allUsersのスコープにOWNER権限を持つACLを設定すると全てのユーザーがオブジェクトを完全にコントロールできるようになり、オブジェクトのアップロード者がオブジェクトを完全にコントロールすることを防げません。
これに対し、正解の選択肢はIAMを使ってユーザーのアクセスを管理し、バケットレベルの統一アクセスを設定することで要件を満たします。
選択肢：allUsersのスコープにREADER権限を持つACLを設定します
この選択肢が正しくない理由は以下の通りです。
allUsersのスコープにREADER権限を持つACLを設定すると、全てのユーザーがオブジェクトに対して読取りアクセス権を持つことになるため、個別のアクセス制御ができません。
逆に、統一アクセス管理をバケットレベルで設定すれば個別に管理する必要なく安全にアクセスを制御できます。
選択肢：デフォルトのバケットACLを設定し、IAMを使ってユーザーのアクセスを管理します
この選択肢が正しくない理由は以下の通りです。
デフォルトのバケットACLを設定しても、オブジェクトのアップロード者がオブジェクトを完全にコントロールできる状況を改善できません。セキュリティ面を考慮すると、正解の選択肢であるバケットレベルの統一アクセス設定が適しています。これにより、オブジェクトへの個別のアクセス設定を管理する手間を省くとともに、アップロード者のオブジェクトに対する全面的なコントロールを防ぐことができます。
参考リンク：
https://cloud.google.com/storage/docs/uniform-bucket-level-access
https://cloud.google.com/iam/docs/overview
https://cloud.google.com/logging/docs/audit
</div></details>

### Q.  問題38: 未回答
あなたは、一般データ保護規則（GDPR）に準拠したいと考えています。DevOpsチームがヨーロッパリージョンでのみGoogle Cloudリソースを作成できるようにしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudリソースのリージョナルな制限に関して理解が必要となります。具体的には、DevOpsチームがヨーロッパリージョンのみでリソースを作成できるように制限する方法を選択します。言い換えれば、正しい解答を見つけるためには、Google Cloudのリージョン制限方法、特に組織ポリシーに関する知識が必要となります。また、一般データ保護規則（GDPR）の要件に対する考慮も必然と関わってきます。
基本的な概念や原則：
GDPR（General Data Protection Regulation）：EUのデータ保護法規。EU内のすべての個人データのプライバシーと保護を規定しています。
組織ポリシー：特定のリソースの使用を制御するための、Google Cloudのプレビルトルールです。組織全体で一貫した制御を適用することが可能です。
"Google Cloud - Resource Location Restriction"制約：リソースの地理的ロケーションを制限するための組織ポリシー。特定のリージョンまたはゾーンでのみリソースの作成を許可することが可能です。
Identity-Aware Proxy（IAP）：Google Cloudサービスへのセキュアなアクセスを提供するツールです。ユーザーとアプリケーション間のトラフィックを管理し、認証と認可を行います。
Access Context Manager：Google Cloudサービスに対するアクセスをコントロールするためのサービス。ユーザーのアクセス状況を制御しますが地理的ロケーションを制限する機能は提供していません。
IAMカスタムロール：特定のユーザーに対して、特定のリソースへのアクセス権限をカスタムに制限できますが、地理的ロケーションによるリソース作成を制限する機能は提供していません。
正解についての説明：
（選択肢）
・Google Cloudの組織ノードで、組織ポリシー制約"Google Cloud - Resource Location Restriction"を使用します
この選択肢が正解の理由は以下の通りです。
Google Cloudの組織ポリシーサービスが提供する"Resource Location Restriction"という制約を使用することで、リソースの作成場所を限定的なリージョンやゾーンに制限することができます。組織ポリシーを適用するレベル（例えば組織全体、フォルダ、プロジェクト）でこの制約を設定することで、DevOpsチームが特定のリージョンでのみリソースを作成できるように制御することができます。この問題のシナリオでは、GDPR準拠のためにヨーロッパリージョンでのみリソースを作成したいと考えているため、"Resource Location Restriction"を用いてヨーロッパリージョンにリソースの場所を制限することで、この要件を満たすことができます。
不正解についての説明：
選択肢：Identity-Aware Proxy（IAP）とAccess Context Managerを使用して、Google Cloudリソースの場所を制限します
この選択肢が正しくない理由は以下の通りです。
Identity-Aware Proxy（IAP）とAccess Context Managerは、ユーザーやサービスのアクセス制限を設定するためのものであり、リソースの作成場所に制限を設ける機能は提供していません。
一方で、正解の組織ポリシー制約"Google Cloud - Resource Location Restriction"はリソースの作成場所を制限するための機能を提供します。
選択肢：Google Cloudの組織ノードの組織ポリシー制約"リソースサービスの使用を制限する"を使用します
この選択肢が正しくない理由は以下の通りです。
"リソースサービスの使用を制限する"制約は、特定のサービスの使用を許可または禁止するためのもので、リージョンによるリソースの制限には適していません。
一方、"Google Cloud - Resource Location Restriction"制約はリソースの作成場所を制限できるため、正解選択肢として適切です。
選択肢：Identity and Access Management（IAM）カスタムロールを使用して、DevOpsチームがヨーロッパリージョンでしかリソースを作成できないようにします
この選択肢が正しくない理由は以下の通りです。
カスタムロールを用いたIAMは認証や認可の管理に使われますが、特定のリージョンでしかリソースを作成できないように制限することはできません。
一方で、組織ポリシー制約 "Google Cloud - Resource Location Restriction" を使用すると、特定のリージョンでのリソース作成を制限することが可能です。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/resource-manager/docs/creating-managing-policy
https://cloud.google.com/compliance/geographic-specificities
</div></details>

### Q.  問題39: 未回答
エンベロープ暗号化を使ってデータを暗号化する手順は次のうちどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、エンベロープ暗号化におけるデータ暗号化の手順を問われています。エンベロープ暗号化の概念を理解しておくことが重要で、具体的にはデータ暗号化キー（DEK）とキー暗号化キー（KEK）がどのように使われるかを把握することが求められます。また、暗号化の順序やプロセスも理解することが求められ、それが選択肢となっています。したがって、選択肢より暗号化の適切な手順を見逃さないように注意することが重要です。
基本的な概念や原則：
エンベロープ暗号化：二つの鍵を使用する暗号化方式です。データ暗号化キー（DEK）でデータを直接暗号化し、キー暗号化キー（KEK）でDEKを暗号化（ラップ）します。
データ暗号化キー（DEK）：エンベロープ暗号化でデータを直接暗号化するときに使用する鍵です。一般にローカルで生成され、そのデータの暗号化と復号に使用されます。
キー暗号化キー（KEK）：エンベロープ暗号化でDEKを暗号化（ラップ）するときに使用する鍵です。安全に保管され、DEKの暗号化と復号に使用されます。
鍵の生成：DEKとKEKは通常別々に生成され、それぞれ異なる暗号化作業に使用されます。
データの暗号化：DEKを使用して直接データを暗号化します。この時点でDEKは平文状態です。
鍵のラップ：KEKを使用してDEKを暗号化（ラップ）します。これによりDEKは暗号文となり、安全に保存できます。
データと鍵の保存：暗号化されたデータとラップされたDEKは両方とも安全に保存されます。DEKはデータの復号に必要で、データと一緒に保存されます。
正解についての説明：
（選択肢）
・- データ暗号化キー（DEK）をローカルで生成します
- DEKを使用してデータを暗号化します
- キー暗号化キー（KEK）を使用してDEKをラップします
- 暗号化されたデータとラップされたDEKを保存します
この選択肢が正解の理由は以下の通りです。
エンベロープ暗号化は、データの安全性を確保するための一般的なパターンで、DEKとKEKの2つのキーを使用して、データを保護します。まず、DEKをローカルで生成します。これは実際にデータを暗号化し復号するために使用されます。
次に、このDEKを使用して実際のデータを暗号化します。こうすることで、データそのものが暗号化され、保護されます。しかし、DEK自体も保護する必要があります。これをKEKを使用してDEKをラップ（暗号化）します。KEKは通常、信頼性の高いキーマネージメントシステムで管理されます。
最後に、暗号化されたデータとラップされたDEKを保存します。これにより、データとDEKの両方が安全に保護されます。この手順に従うことで、データやキーが漏洩した場合でも、適切なキーがなければデータを復号化することはできません。
不正解についての説明：
選択肢：- データ暗号化キー（DEK）をローカルで生成します
- キー暗号化キー（KEK）を使用してDEKをラップします
- DEKを使用してデータを暗号化します
- 暗号化されたデータとラップされたDEKを保存します
この選択肢が正しくない理由は以下の通りです。
不正解の選択肢の手順は正解の選択肢の手順と比べて、DEKを使用してデータを暗号化することがKEKを使用してDEKをラップする後に来ています。しかし、エンベロープ暗号化では、初めにDEKを使用してデータを暗号化し、次にKEKを使用してDEKをラップするべきというのが正しい順序です。これが不正解の選択肢が相応しくない理由です。
選択肢：- キー暗号化キー（KEK）をローカルで生成します
- KEKを使用してデータ暗号化キー（DEK）を生成します
- DEKを使用してデータを暗号化します
- 暗号化されたデータとラップされたDEKを保存します
この選択肢が正しくない理由は以下の通りです。
エンベロープ暗号化では通常、データ暗号化キー（DEK）がローカルで生成されますが、この選択肢ではキー暗号化キー（KEK）がローカルで生成されています。
さらに、KEKを使用してDEKを生成するという手順は誤っています。正しくはDEKを使ってデータを暗号化し、その後KEKを使用してDEKをラップするという手順を踏むため、その部分が誤っています。
選択肢：- キー暗号化キー（KEK）をローカルで生成します
- データ暗号化キー（DEK）をローカルで生成します
- KEKを使用してデータを暗号化します
- 暗号化されたデータとラップされたDEKを保存します
この選択肢が正しくない理由は以下の通りです。
エンベロープ暗号化ではデータ暗号化キー（DEK）がデータを暗号化し、キー暗号化キー（KEK）がDEKをラップします。しかし、不正解の選択肢ではKEKがデータを暗号化しており、これはエンベロープ暗号化の原則に反しています。
参考リンク：
https://cloud.google.com/kms/docs/envelope-encryption
https://cloud.google.com/security-key-management
https://csrc.nist.gov/publications/detail/sp/800-57-part-1/rev-5/final
</div></details>

### Q.  問題40: 未回答
Google Cloudにユーザーを移行しています。エンドポイントデバイス上のGoogle WebおよびGoogle Cloud CLI SDKセッションでCookieリプレイ攻撃が発生しています。このような脅威のリスクを減らす必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudとWebサービスのセッションにおけるcookieリプレイ攻撃のリスクを減少する手段を理解することが求められています。ここでは共通のセッション管理の手法として、セッションの制御を短い時間に設定することは有効な一つの手法であることに気付く必要があります。理解すべき特殊な点は、Google Cloudには独自の再認証ポリシーがあり、これもセッション持続時間の一部と考えられるので、これを短く設定するのも効果的です。
基本的な概念や原則：
Googleのセッション制御：Google Cloudのセッション管理機能です。定義された期間経過後にセッションを終了し、再認証を要求することで、セキュリティを強化します。
再認証ポリシー：特定のGoogle Cloudサービスや操作に対して再度認証を必要とするポリシーです。不正なセッション利用を防ぎます。
Cookieリプレイ攻撃：攻撃者がユーザーのCookieを盗んでそのセッションを利用するセキュリティ攻撃です。セッション管理の強化により防ぐことが可能です。
OAuth 2.0：APIへの安全なアクセスを認証するためのオープンスタンダードです。アクセストークンの有効期間は一部のリスクを軽減するものの、Cookieリプレイ攻撃を完全に防ぐわけではありません。
サードパーティのIDプロバイダ：Google Cloud以外のサービスを使用して認証を行うことができますが、これだけではCookieリプレイ攻撃を防止するための包括的なソリューションではありません。
2段階認証：アカウントへのアクセスを保護するための追加のセキュリティレイヤーです。セキュリティキー認証を含むことがありますが、これだけではCookieリプレイ攻撃を防ぐことはできません。
正解についての説明：
（選択肢）
・Googleのセッション制御を短時間に設定します
・Google Cloudサービスの再認証ポリシーを短い期間に設定します
この選択肢が正解の理由は以下の通りです。
まず、"Googleのセッション制御を短時間に設定します"という選択肢が適切なのは、クッキーリプレイ攻撃は既存のセッションを利用して不正する攻撃方法であり、セッションの有効期間を短く設定することで攻撃者が利用できる時間を制限することができるからです。つまり、セッションが早く終了すれば、攻撃者がクッキーを利用して不正にアクセスできる機会が減少します。
次に、"Google Cloudサービスの再認証ポリシーを短い期間に設定します"という選択肢が適切なのは、再認証ポリシーを短い時間に設定することでユーザーが定期的に認証を再行うよう強制することができ、これによりクッキーリプレイ攻撃のリスクを低減させることができるからです。定期的な再認証により、攻撃者が既存のユーザーセッションを盗用して不正にアクセスする機会が減るため、セキュリティを強化することができます。
不正解についての説明：
選択肢：OAuth 2.0アクセストークンの有効期間を短くする組織ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloudでは、OAuth 2.0アクセストークンの有効期間を直接短く設定するような組織ポリシーの設定は存在しません。
一方で、Googleのセッション制御やGoogle Cloudサービスの再認証ポリシーは直接ユーザーセッションの安全性に対して効果をもたらし、Cookieリプレイ攻撃のリスクを減らすことが可能です。
選択肢：セッション管理機能を持つサードパーティのIDプロバイダを構成します
この選択肢が正しくない理由は以下の通りです。
サードパーティのIDプロバイダを使用しても、Google WebやGoogle Cloud CLI SDKセッションのCookieリプレイ攻撃のリスクは必ずしも軽減されません。
それに対して、Googleのセッション制御やGoogle Cloudサービスの再認証ポリシーを短い期間に設定することは、不正なセッション使用の可能性を直接制限する対策となります。
選択肢：2段階認証でセキュリティキー認証を強制します
この選択肢が正しくない理由は以下の通りです。
2段階認証でセキュリティキー認証を強制するアプローチは、初回の認証を強化するものですが、すでにセッションが開始され、クッキーが生成された状態でのリプレイ攻撃には効果的ではないです。
それに対して、セッション制御や再認証ポリシーを短い期間に設定することで、セッションの有効期間を短くし、攻撃のリスクを減らすことができます。
参考リンク：
https://cloud.google.com/identity-platform/docs/session-management
https://cloud.google.com/docs/authentication
https://support.google.com/a/answer/9368756
</div></details>

### Q.  問題41: 未回答
あなたは会社のセキュリティ管理者です。開発チームは、"implementation"フォルダの下に複数のGoogle Cloudプロジェクトを作成し、開発、ステージング、本番の各ワークロードに使用しています。あなたは、セキュリティ境界を設定することで、悪意のある内部関係者や侵害されたコードによるデータの流出を防ぎたいと考えています。しかし、プロジェクト間の通信は制限したくありません。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、セキュリティ管理者として、内部のリスク要素からGoogle Cloudプロジェクトを保護し、同時にプロジェクト間の通信を制限しない方法を求められています。求められているのは、データの流出を防ぐセキュリティ境界の設定と、それに対応する監視システムの構築です。"implementation"フォルダを通じて新しいプロジェクトを追加するたびに、適切にそのプロジェクトがセキュリティ境界に含まれるようなシステムが期待されています。具体的には、Infrastructure-as-CodeツールやGoogle Cloudの監視ツールを活用することによって、上記の要件が満たされる方法を考える必要があります。
基本的な概念や原則：
単一のサービス境界設定：複数のプロジェクトまたはリソースに同一のセキュリティ設定を適用することです。一貫したセキュリティポリシーを維持しつつ、プロジェクト間の通信を可能にします。
Infrastructure-as-Code：ソフトウェアを使用してインフラストラクチャを自動的にプロビジョニング・管理する手法です。Terraformなどのツールが使われます。
Google Cloud Operation Suite：Google Cloudのログ、メトリクス、トレースデータを統合的に管理・監視するためのツールセットです。
Cloud Pub/Sub：Google Cloudのリアルタイムメッセージングサービスで、イベント駆動型のシステムやストリーム処理のワークロードをサポートします。
Cloud Function：Google Cloudのサーバーレス実行環境で、特定のイベントに応じてコードを自動的に実行します。
共有VPC：複数のGoogle Cloudプロジェクト間でネットワークリソースを共有するためのサービスです。
Access Context Manager：Google Cloudのサービスで、組織のデータへのアクセスを管理し、ユーザーの認証情報やネットワーク情報に基づいたアクセスポリシーを定義します。
正解についての説明：
（選択肢）
・Infrastructure-as-Codeソフトウェアツールを使って単一のサービス境界を設定し、Google Cloud Operation SuiteとCloud Pub/Subを使って "implementation"フォルダを監視するCloud Functionをデプロイします。この関数は、、新しいプロジェクトがフォルダに追加されたことをトリガーに、、Terraformを実行して新しいプロジェクトを関連する境界に追加します
この選択肢が正解の理由は以下の通りです。
まず、Infrastructure-as-Codeソフトウェアツール、この場合Terraformを使用して単一のサービス境界を設定することで、構成の一貫性を確保し、間違いを減らし、セキュリティを強化できます。これにより、発生する各種イベントに対応するための基盤を確保することができます。
次に、Google Cloud Operation SuiteとCloud Pub/Subを使用することで、リアルタイムで"implementation"フォルダを監視し、新しいプロジェクトが追加されたときに通知を受け取ることが可能です。これは、新たに必要となるセキュリティ設定を即時に行うために不可欠であり、潜在的な脅威からの保護を強化します。
最後に、これらの監視機能がトリガーとなってCloud Functionが起動し、新たに作成されたプロジェクトを元のサービス境界に自動的に追加します。これにより、新しくプロジェクトが追加された場合でも、迅速かつ確実にそのプロジェクトをセキュリティ境界に組み込むことが可能となります。これらが協働することで、データの流出を防ぐことが可能になり、プロジェクト間の通信を妨げることなくセキュリティを確保できます。
不正解についての説明：
選択肢：共有VPCを使用してすべてのプロジェクト間の通信を可能にし、ファイアウォールルールを使用してデータの流出を防ぐ
この選択肢が正しくない理由は以下の通りです。
共有VPCはプロジェクト間の通信を可能にしますが、セキュリティ境界の設定やデータの流出防止には対応していません。ファイアウォールルールによる保護も侵害されたコードの流出には限定的で不十分です。
一方、正解ではInfrastructure-as-CodeツールとCloud Functionを用い、フォルダの監視と境界設定を自動化しています。
選択肢：Access Context Managerでアクセスレベルを作成してデータの流出を防ぎ、プロジェクト間の通信には共有VPCを使用します
この選択肢が正しくない理由は以下の通りです。
Access Context Managerはユーザーやデータのアクセスを制御するツールで、事前に設定したセキュリティポリシーに基づいてアクセスを許可または拒否します。しかし、これは内部関係者や侵害されたコードによるデータの流出を防ぐための手段ではありません。
また、共有VPCはプロジェクト間のネットワーク接続を可能にしますが、セキュリティ境界を設定する目的とは異なります。
選択肢：Infrastructure-as-Codeソフトウェアツールを使って、dev、staging、prodの3つの異なるサービス境界を設定し、Google Cloud Operation SuiteとCloud Pub/Subを使って "implementation"フォルダを監視するCloud Functionをデプロイします。この関数は、、新しいプロジェクトがフォルダに追加されたことをトリガーに、、Terraformを実行して新しいプロジェクトをそれぞれの境界に追加します
この選択肢が正しくない理由は以下の通りです。
プロジェクト間の通信制限を避けつつセキュリティを確保したい場合、異なるサービス境界を設定するとその目的に反します。個々のサービス境界ではなく、単一のサービス境界を作成することで、プロジェクト間の通信を自由に保ちつつ、全体的なセキュリティを担保することが可能となります。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/create-service-perimeters
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://www.terraform.io/docs/providers/google/r/google_folder.html
</div></details>

### Q.  問題42: 未回答
ある会社は、Google Cloudの異なるリージョンに冗長化されたメールサーバーを持っており、場所に基づいて顧客を最も近いメールサーバーにルーティングしたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのリージョン間での冗長化されたメールサーバーの使用法を問われています。それらのサーバーへの顧客のルーティングは、顧客の位置に基づいて最も近いメールサーバーに向けられるべきです。問題解決においてキーポイントは、どのようにしてトラフィックをうまくルーティングし、それに適したGoogle Cloudの負荷分散のタイプを選択できるかを理解することです。この場合、メールサーバーが使用する特定のポート番号にも注意が必要です。
基本的な概念や原則：
TCPプロキシ負荷分散：指定したTCPトラフィック（SMTP、MySQLなど）を複数のバックエンドサービスに分散するための負荷分散方法です。顧客の場所に基づいて最寄りのバックエンドにトラフィックをルーティングします。
グローバル負荷分散：Google Cloudのフロントエンド設定にて、トラフィックを複数のリージョンに分散することができる機能です。
ネットワークロードバランサー：ユーザーのトラフィックに基づいて、バックエンドへのトラフィックを分散させるGoogle Cloudの負荷分散サービスです。ただし、便宜上キャラの視点からサービスへのトラフィックをルーティングするため、設問の要件を満たしません。
HTTP(S)ロードバランサー：クライアントからのHTTP(S)トラフィックをバックエンドサービスに分散するためのロードバランサーです。リージョナルに配置されたバックエンドサービスへのルーティングに利用されますが、メールサーバーへのトラフィックには不適切です。
Cloud CDN：コンテンツ配信ネットワーク（CDN）サービスで、ユーザーの近くにコンテンツをキャッシュします。HTTP(S)ロードバランサーと連携して動作しますが、メールサーバーのトラフィックには不適切です。
正解についての説明：
（選択肢）
・TCPプロキシ負荷分散を、ポート995をリッスンするグローバル負荷分散サービスとして設定します
この選択肢が正解の理由は以下の通りです。
まず、TCPプロキシ負荷分散は、Google Cloud内の全体的なネットワークに対して、受信したTCPトラフィックを複数のリージョンにあるバックエンドサービスに分散させることができます。これは、最も近いメールサーバーに顧客をルーティングする要件に対応しています。
さらに、TCPプロキシ負荷分散は、クライアントの接続要求をバックエンドで最も可能性が高い空き容量を持ったサーバに自動的にルーティングします。これにより、負荷をきちんと分散させ、ほぼ全てのリクエストに対して予測可能な性能を提供します。
なお、ポート995は一般的に、メールサーバーとの間で暗号化されたPOP3通信を行うために使われます。
したがって、このポートをリッスンするグローバル負荷分散サービスを設定することは、さまざまなリージョンに分散されたメールサーバーの負荷を均等に分散させるために適切です。
不正解についての説明：
選択肢：TCPポート995をリッスンするネットワークロードバランサーを作成し、場所に基づいてトラフィックを転送する転送ルールを設定します
この選択肢が正しくない理由は以下の通りです。
ネットワークロードバランサーは地域ベースの負荷分散であり、顧客を"最も近い"メールサーバーにルーティングすることはできません。
それに対し、TCPプロキシ負荷分散はグローバル負荷分散で、ユーザーを最も近いサーバーに自動的にルーティングできます。
選択肢：HTTP(S)ロードバランサーでクロスリージョンロードバランシングを使い、トラフィックを最も近いリージョンにルーティングします
この選択肢が正しくない理由は以下の通りです。
HTTP(S)ロードバランサーはWebベースのアプリケーションでの使用が主目的であり、メールサーバーで必要とされるTCPレベルの負荷分散に対応していません。対してTCPプロキシ負荷分散はTCPレベルでの負荷分散を可能にし、メールサーバーのようなユースケースに適しています。
選択肢：Cloud CDNを使用して、クライアントのIPアドレスに基づいて最も近いオリジンメールサーバーにメールトラフィックをルーティングします
この選択肢が正しくない理由は以下の通りです。
Cloud CDNはウェブコンテンツを高速に配信するためのサービスであり、メールトラフィックのルーティングには設計されていません。
一方、TCPプロキシ負荷分散はリージョンをまたいで負荷分散し、顧客を最も近いサーバーにルーティングする能力があります。
参考リンク：
https://cloud.google.com/load-balancing/docs/tcp
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
</div></details>

### Q.  問題43: 未回答
オンプレミスのActive DirectoryサービスからGoogle CloudのIAM権限を一元管理したいと考えています。ADのグループメンバーシップで権限を管理したいと考えています。
これらの要件を満たすために、チームは何をすべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミスのActive DirectoryからGoogle CloudのIAMへの一元管理について理解しなければなりません。特にActive DirectoryのグループメンバーシップによるIAM権限の管理が要件となっています。そのため、選択肢を考慮する際には、機能がグループベースのIAM権限管理をサポートしているかを重視すべきです。単にユーザー認証やインターフェースの提供が可能な機能ではなく、具体的なグループ管理機能が求められている点に留意しましょう。
基本的な概念や原則：
Cloud Directory Sync：Google Cloudのサービスで、Microsoft Active Directoryまたは任意のLDAPディレクトリとGoogle Cloud Identityプラットフォームを同期させることが可能です。
IAMパーミッション：Google Cloudのリソースに対するアクセス権を制御する権利です。特定のユーザ、グループ、サービスアカウントに対して設定することができます。
Active Directory：Microsoftが提供するディレクトリサービスです。ユーザーやグループの認証、権限管理などを一元的に行うことが可能です。
SAML 2.0：セキュリティアサーションマークアップランゲージ（SAML）は、ユーザーアカウントの認証情報と承認情報を安全に交換するためのオープンスタンダードです。
Cloud Identity and Access Management API：Google Cloudのアクセス制御を管理するためのAPIサービスです。
Admin SDK：Google Cloudの管理機能を利用するためのSDKです。様々な管理タスクを自動化することが可能です。
正解についての説明：
（選択肢）
・Cloud Directory Syncを設定してグループを同期し、グループにIAMパーミッションを設定します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Directory SyncはオンプレミスのActive DirectoryとGoogle Cloudのディレクトリを同期させるためのツールです。これを使ってActive Directoryのユーザー、グループ、およびその他のデータをGoogle Cloud Identityに比照して同期することができます。これにより、既存のActive Directoryのグループメンバーシップ情報をベースに、Google Cloudでのアクセス制御を一元的に行うことができます。
次に、同期したグループに対してIAMパーミッションを設定することで、ユーザーのGoogle Cloud内でのアクセス権を管理できます。IAMでは、特定のリソースへのアクセス許可を組織内のユーザー、グループ、サービスアカウントに割り当てることができます。そのため、Active Directoryのグループメンバーシップに基づいて、Google Cloudのリソースへのアクセス権を設定することが可能となります。
したがって、これらの機能を利用することで、オンプレミスのActive DirectoryからGoogle CloudのIAM権限への一元管理が実現できます。
不正解についての説明：
選択肢：SAML 2.0シングルサインオン（SSO）を設定し、グループにIAMパーミッションを割り当てます
この選択肢が正しくない理由は以下の通りです。
SAML 2.0 SSO設定は認証処理を目的としており、Active DirectoryとGoogle CloudのIAM権限の一元管理に直接寄与しません。一方正解のCloud Directory SyncではActive Directoryのグループ構成をGoogle Cloudに同期でき、権限管理の一元化を実現します。
選択肢：Active DirectoryからグループとIAMアクセス許可を作成するために、Cloud Identity and Access Management APIを使用します
この選択肢が正しくない理由は以下の通りです。
Cloud Identity and Access Management APIは、IAMリソースを管理するためのツールではありますが、Active Directoryから直接グループやIAMアクセス権を作成する機能はありません。
一方、Cloud Directory SyncはActive DirectoryのグループをGoogle Cloudと同期するために必要なツールで、グループに対するIAMパーミッションの設定が可能です。よって、この問題の要件を満たすためにはCloud Directory Syncを使用するのが適しています。
選択肢：Admin SDKを使用して、Active Directoryからグループを作成し、IAMパーミッションを割り当てます
この選択肢が正しくない理由は以下の通りです。
Admin SDKは、Google Workspaceのユーザー、グループ、ドメインなどを管理するためのツールで、オンプレミスのActive Directoryサービスからの同期はできません。
それに対して、Cloud Directory Syncを使用するとActive Directory内のユーザーやグループをGoogle Cloudに同期することが可能です。
参考リンク：
https://cloud.google.com/identity/docs/manage-identity-sync-gsuite-directory
https://cloud.google.com/iam/docs/overview
https://ldap.com/the-ldap-protocol/
</div></details>

### Q.  問題44: 未回答
顧客がアプリケーションをApp Engineにデプロイし、Open Web Application Security Project（OWASP）の脆弱性をチェックする必要があります。
そのためには、どのサービスを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客の要件とGoogle Cloudの各サービスの機能を理解することが求められています。問題文で示されているOWASPの脆弱性チェックのニーズと各選択肢で提供される機能を関連付けることが必要です。具体的には、OWASPの脆弱性チェックができるサービスを選択することが求められています。そのためには、各サービスが具体的に何を提供し、それが顧客の要件にどのように適合するかを理解することが重要です。
基本的な概念や原則：
Web Security Scanner：Google Cloudの持つ自動化されたウェブアプリケーションセキュリティスキャンサービスです。アプリケーションに存在する脆弱性を発見し、レポートします。
Open Web Application Security Project（OWASP）：ウェブアプリケーションのセキュリティ課題にリスクベースのアプローチを提供するコミュニティプロジェクトです。脆弱性のチェックリストなどが公開されています。
App Engine：Google Cloudのフルマネージド型サーバーレスプラットフォームです。アプリケーションを容易に開発・デプロイできるようにします。
Cloud Armor：Google CloudのWebアプリケーションファイアウォール（WAF）とDDoS防御ソリューションを提供しますが、脆弱性のチェックは行いません。
Google Cloud Audit Logs：Google Cloudリソースの監査ログを提供しますが、アプリケーションレベルの脆弱性のチェックは行いません。
Anomaly Detection：異常検知サービスですが、特定の脆弱性のチェックは行いません。
正解についての説明：
（選択肢）
・Web Security Scanner
この選択肢が正解の理由は以下の通りです。
Web Security ScannerはGoogle Cloudのサービスで、Open Web Application Security Project（OWASP）の脆弱性を検出するために使用されます。この機能は、App EngineやGoogle Kubernetes Engine（GKE）、Compute Engineなど、Google Cloud上で展開されたWebアプリケーションの脆弱性スキャンを支援します。具体的には、Web Security Scannerはクロスサイトスクリプティング、Flashインジェクション、混乱したアクセス制御などのようないくつかの共通のWebアプリケーションのセキュリティイシューを検出する能力があります。
したがって、アプリケーションがApp Engineにデプロイされ、OWASPの脆弱性チェックが必要な場合、Web Security Scannerはこの要件を満たす適切な選択となります。
不正解についての説明：
選択肢：Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Cloud ArmorはOWASPの脆弱性をチェックするツールではなく、主にDDoS攻撃の防衛とWAF（Web Application Firewall）のロールを果たします。
OWASPの脆弱性チェックには、Web Security Scannerを利用すべきで、このサービスはWebアプリケーションの共通の脆弱性を自動的にチェックします。
選択肢：Google Cloud Audit Logs
この選択肢が正しくない理由は以下の通りです。
Google Cloud Audit Logsは、ユーザーアクティビティ、管理アクティビティ、データアクセスなどのGoogle Cloudリソースの利用状況を追跡するためのもので、OWASPの脆弱性を検査するためのサービスではありません。
それに対して、Web Security Scannerは、App Engine、Compute Engine、GKE等にデプロイされたWebアプリケーションのOWASPの脆弱性をスキャンするためのサービスです。
選択肢：Anomaly Detection
この選択肢が正しくない理由は以下の通りです。
Anomaly Detectionは異常検知を行うサービスであり、OWASPの脆弱性チェックには向いていません。
一方、Web Security Scannerは、Webアプリケーションの脆弱性をチェックするためのサービスであり、OWASPの要件に対応しています。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/appengine/docs/standard
https://owasp.org/www-project-top-ten/
</div></details>

### Q.  問題45: 未回答
エンベロープ暗号化を活用し、アプリケーション層でデータを暗号化するために、Googleが推奨するプラクティスに従う必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、エンベロープ暗号化という高度なセキュリティ概念をGoogle Cloud環境でどのように実装すれば良いのかを尋ねています。ここで重要なのは、データ暗号化キー（DEK）とキー暗号化キー（KEK）の扱い方を理解することです。エンベロープ暗号化のプロセスは、データをDEKで暗号化し、そのDEK自体をKEKで暗号化することで、2つのキーによりデータのセキュリティを高めるというものです。ただし、安全なストレージの観点から、暗号化されたDEKと暗号化されたデータ本体のみを保存し、原始的なKEKは保存してはならないという点に注意が必要です。また、DEKはローカル、KEKはクラウドKMSで生成されるという点にも注目が必要です。
基本的な概念や原則：
エンベロープ暗号化：二重のキーを使用してデータを保護する暗号化方法です。データ暗号化キー（DEK）がデータ自体を暗号化し、キー暗号化キー（KEK）がDEKを暗号化します。
データ暗号化キー（DEK）：エンベロープ暗号化の一部として使用されるキーで、データ自体を暗号化するために使用されます。
キー暗号化キー（KEK）：エンベロープ暗号化の一部として使用されるキーで、データ暗号化キー（DEK）を暗号化するために使用されます。
クラウドKMS：Google Cloudのキーマネージメントサービスです。暗号化キーの生成、使用、管理、ローテーション、削除を管理します。
ローカル生成とクラウド生成：暗号化キーを生成する場所によって、キーの管理や配置が異なります。ローカルで生成すると、完全なコントロールが可能ですが、管理が複雑になる可能性があります。クラウドで生成すると、クラウドプロバイダーによる管理が可能ですが、クラウドプロバイダーへの信頼が必要です。
キーの保存と活用：暗号化したデータと暗号化したDEKを保存することで、データの機密性を高め、キーの安全な管理を支えます。一方、KEKを保存すると、DEKを解読する能力が漏洩するリスクが高まります。
正解についての説明：
（選択肢）
・ローカルでデータ暗号化キー（DEK）を生成してデータを暗号化し、クラウドKMSで新しいキー暗号化キー（KEK）を生成してDEKを暗号化します。暗号化されたデータと暗号化されたDEKの両方を保存します
この選択肢が正解の理由は以下の通りです。
まず、エンベロープ暗号化は、一つの秘密鍵（データ暗号化キー、DEK）を使ってデータを暗号化し、それをさらに別の秘密鍵（キー暗号化キー、KEK）を使って暗号化するという方法を指します。これは、データとキーの管理を分離し、より高度なセキュリティを提供します。
一般的に、DEKは直接的なデータの暗号化に使用され、DEK自体はKEKによって保護されます。ここでの重要な部分は、DEKとKEKの生成と使用です。この選択肢では、DEKはローカル（アプリケーション側）で生成され、データの暗号化に使われます。
一方、KEKはGoogle CloudのKey Management Service（KMS）で生成され、DEKの暗号化に使用されます。セキュリティ上の理由から、これらの暗号化キーは作成場所から離れた場所で管理すべきです。つまり、この場合、ローカルで生成されたDEK（暗号化された）と、KMSで生成されたKEKという構成が適切なプラクティスであると言えます。
最後に、この選択肢が正解となるもう一つの重要な要素は、暗号化されたデータと暗号化されたDEKを両方保存する点です。これにより、将来データを復号化するための必要な情報が保存されます。以上の要素が全て揃っているため、この選択肢が最も適切な解答となります。
不正解についての説明：
選択肢：ローカルでデータ暗号化キー（DEK）を生成してデータを暗号化し、クラウドKMSで新しいキー暗号化キー（KEK）を生成してDEKを暗号化します。暗号化されたデータとKEKの両方を保存します
この選択肢が正しくない理由は以下の通りです。
KEK（キー暗号化キー）は、DEK（データ暗号化キー）を安全に保存するために使用されます。KEK自体を暗号化されたデータと一緒に保存すると、データの暗号化とデータへのアクセス制御が弱くなり、セキュリティリスクとなります。正しくは、暗号化されたDEKとデータ自体を保存します。
選択肢：データを暗号化するためにクラウドKMSで新しいデータ暗号化キー（DEK）を生成し、キーを暗号化するためにローカルでキー暗号化キー（KEK）を生成します。暗号化されたデータと暗号化されたDEKの両方を保存します
この選択肢が正しくない理由は以下の通りです。
クラウドKMSで新しいデータ暗号化キー（DEK）を生成すると、DEKがクラウド上で明示的に表示され、それ自体が露出のリスクが増えます。そのため、Googleの推奨するプラクティスとは異なります。
それに対して、ローカルでDEKを生成し、クラウドKMSでキー暗号化キー（KEK）を生成すると、DEKの露出リスクが軽減され、安全性が向上します。
選択肢：データを暗号化するためにクラウドKMSで新しいデータ暗号化キー（DEK）を生成し、キーを暗号化するためにローカルでキー暗号化キー（KEK）を生成します。暗号化されたデータとKEKの両方を保存します
この選択肢が正しくない理由は以下の通りです。
KEKはデータの暗号化キー（DEK）を保護するために使われるものであるため、KEKは安全な場所、つまりここではクラウドKMSで生成されなければなりません。このため、ローカルでKEKを生成する方法は適切ではありません。
参考リンク：
https://cloud.google.com/kms/docs/envelope-encryption
https://cloud.google.com/kms/docs/encrypt-decrypt
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題46: 未回答
あなたは会社のセキュリティ管理者です。Cloud IAMのLDAPディレクトリからメールアドレスを持つすべてのセキュリティグループを同期したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud IAM上のLDAPディレクトリからセキュリティグループを同期する方法が尋ねられています。同期対象はメールアドレスを持つセキュリティグループであり、まずはそれが問題のキーポイントとなります。また同期方法については一方向か双方向か明確にされていないため、それに対する理解も重要です。また、不正解の選択肢に示されているような、誤った同期方法や不適切な属性に基づく同期には注意が必要です。正解選択肢と不正解選択肢を比較しながら、要件に最も適合する方法を選ぶことが求められています。
基本的な概念や原則：
Cloud IAM：Google CloudのIdentity and Access Managementサービスです。ユーザーやサービスアカウントの権限を制御し、リソースへのアクセスを管理します。
LDAPディレクトリ：Lightweight Directory Access Protocol（LDAP）のディレクトリは、メールアドレスなどの情報を持つユーザーやグループの情報を格納します。
Google Cloud Directory Sync：Google Cloud Directory Sync（GCDS）は、LDAPディレクトリからGoogle Cloud Identityへユーザーやグループを同期するツールです。
LDAP検索ルール：LDAPのディレクトリ情報を検索するための規則や条件を定めます。指定した属性（例えばメールアドレス）にマッチするデータを探すことができます。
一方向同期：一方のソースからもう一方のデスティネーションへのデータ同期を指します。ソースの変更はデスティネーションに伝播しますが、その逆はありません。
双方向同期：2つのシステム間でデータの変更が双方向に同期されることを指します。一方のシステムでの変更が他方のシステムにも反映され、その逆も同じです。
Google Cloud Identity：Google Cloud Identityは、ユーザーとアプリケーションがGoogle Cloudリソースに安全にアクセスできるようにする統合IDサービスです。
正解についての説明：
（選択肢）
・一方向同期を容易にするために、ユーザーのメールアドレスを属性として持つLDAP検索ルールを使用してセキュリティグループを同期するようにGoogle Cloud Directory Syncを設定します
この選択肢が正解の理由は以下の通りです。
Google Cloud Directory Sync（GCDS）は、既存のLDAPディレクトリ（例えば、Microsoft Active Directoryなど）とGoogle Cloud Identityのユーザー、グループ、および組織単位を同期するためのツールです。GCDSは一方向の同期しか行えないため、LDAPディレクトリの情報をCloud Identityへ複製することになります。LDAPのセキュリティグループをGCDSで同期するために、LDAP検索ルールを利用します。この検索ルールでは、ユーザーのメールアドレスを属性として保持することで、目的のユーザーの情報を特定し、適切に操作できることが求められます。このようにGCDSを設定することで、Cloud IAMのLDAPディレクトリからメールアドレスを持つすべてのセキュリティグループを効率的に同期することが可能です。
不正解についての説明：
選択肢：双方向同期を容易にするために、ユーザーのメールアドレスを属性として持つLDAP検索ルールを使用してセキュリティグループを同期するようにGoogle Cloud Directory Syncを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Directory Sync（GCDS）は、Google CloudとLDAPディレクトリとの間で一方向同期のみをサポートします。そのため、双方向同期を設定するという指示は、GCDSの仕様に反します。一方向同期であれば、設定や管理が容易であり、要件も満たすことができます。
選択肢：管理ツールを使って、メールアドレス属性に基づいたサブセットを同期します。Googleドメインにグループを作成します。Googleドメインで作成されたグループは、自動的に明示的なGoogle Cloud Identity and Access Management（IAM）ロールを持ちます
この選択肢が正しくない理由は以下の通りです。
Googleドメインで作成されたグループが自動的に明示的なGoogle Cloud Identity and Access Management（IAM）ロールを持つ、という記述は誤りです。IAMロールは手動で付与されるべきであり、自動的に付与されるものではありません。
選択肢：管理ツールを使用して、グループオブジェクトのクラス属性に基づいてサブセットを同期します。Googleドメインにグループを作成します。Googleドメインで作成されたグループは、自動的に明示的なGoogle Cloud Identity and Access Management（IAM）ロールを持ちます
この選択肢が正しくない理由は以下の通りです。
Googleドメインで作成されたグループは自動的にGoogle Cloud IAMロールを持つわけではありません。ロール付与は手動で設定する必要があります。
正解の選択肢のように、Google Cloud Directory Syncを使用してLDAPディレクトリからユーザー情報を同期する方が適切です。
参考リンク：
https://cloud.google.com/identity/docs/manage-groups
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-configuring-provisioning-and-single-sign-on
https://ldap.com/
</div></details>

### Q.  問題47: 未回答
あるエンジニアリングチームが、インターネット上で公開されるウェブアプリケーションを立ち上げようとしています。Webアプリケーションは複数のGoogle Cloudリージョンでホストされ、URLリクエストに基づいてそれぞれのバックエンドに誘導されます。
あなたのチームは、アプリケーションをインターネット上に直接公開することを避け、悪意のある特定のIPアドレスリストからのトラフィックを拒否したいと考えています。
これらの要件を満たすために、あなたのチームはどのソリューションを実装すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ウェブアプリケーションを公開するときのセキュリティに焦点を当てています。具体的には、公開を直接インターネット上に行うのではなく、特定の悪意のあるIPアドレスからのトラフィックを拒否する方法について問われています。この問題を解く上で重要なのは、各サービスが提供する機能とその特性を理解していることです。それにより、回答選択肢中から要件を満たす最適なソリューションを正確に選び出せます。
基本的な概念や原則：
Cloud Armor：Google Cloudのアプリケーションやサービスを保護するためのDDoS防御サービスです。特定のIPアドレスからのトラフィックを拒否することができます。
ネットワークロードバランサー：Google Cloudのロードバランサーの一つで、広範で複雑な通信を管理し、予測可能で低遅延のトラフィックを提供するロードバランサーです。
SSLプロキシロードバランサー：Google Cloudのロードバランサーの一つで、SSL間の安全なトラフィックの透過性を提供します。
NATゲートウェイ：プライベートネットワークからインターネットに接続するためのサービスで、トラフィック源のIPアドレスをマスクします。
正解についての説明：
（選択肢）
・Cloud Armor
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud ArmorはWebアプリケーションのセキュリティとDDoS保護を提供するサービスであり、ロードバランサーレイヤーに適用されます。これは、悪意のあるトラフィックや特定のIPアドレスリストからのトラフィックを拒否する、いわゆるIPブラックリスト機能を提供します。これにより、攻撃に対してアプリケーションを守るために求められていた機能が実装できます。
また、Cloud ArmorはHTTP(S)ロードバランサーを介してトラフィックをフィルタリングするため、複数のリージョンでホストされるウェブアプリケーションのターゲットトラフィックを効果的に制御することができます。これにより、アプリケーションからのURLリクエストに基づいてバックエンドに誘導する要求も満たせます。
したがって、Cloud Armorはインターネット上に公開するウェブアプリケーションのセキュリティを確保し、特定のIPからのトラフィックを足止めする要件を満たす最適な選択肢です。
不正解についての説明：
選択肢：ネットワークロードバランサー
この選択肢が正しくない理由は以下の通りです。
ネットワークロードバランサーはトラフィックを複数のリージョンに分散させる機能を提供しますが、特定のIPアドレスからのトラフィックをブロックするようなセキュリティ機能は提供しておりません。
一方、Cloud Armorはトラフィックのフィルタリングとブロックが可能で、悪意のあるIPアドレスからのトラフィックを防ぐことができます。
選択肢：SSLプロキシロードバランサー
この選択肢が正しくない理由は以下の通りです。
SSLプロキシロードバランサーはSSLトラフィックのバランシングを行いますが、悪意のある特定のIPアドレスリストからのトラフィックを拒否する機能は含まれていません。
それに対して、Cloud ArmorはIPブラックリストやホワイトリストを設定し、特定のIPからのトラフィックを制御することが可能です。
選択肢：NATゲートウェイ
この選択肢が正しくない理由は以下の通りです。
NATゲートウェイは主にプライベートなネットワークからの送信元IPアドレスを変更する機能に役立つもので、受信トラフィックのフィルタリングや特定のIPアドレスからのトラフィックを拒否するといったセキュリティ対策の機能を持ちません。
一方、Cloud Armorは特定のIPアドレスからのトラフィックを拒否するなどのセキュリティ設定を行うことが可能です。
参考リンク：
https://cloud.google.com/armor
https://cloud.google.com/load-balancing/docs/ssl
https://cloud.google.com/load-balancing/docs/network
</div></details>

### Q.  問題48: 未回答
組織のインフラをGoogle Cloudに移行する際、多数のユーザがGoogle Cloud Consoleにアクセスする必要があります。アイデンティティ管理チームはユーザーを管理する確立された方法を既に持っており、既存のSSOパスワードと共に既存のActive DirectoryまたはLDAPサーバーを使い続けたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、オンプレミスのアイデンティティ管理システム（Active DirectoryやLDAP）を維持しながら、Google Cloud環境への多数のユーザアクセスを管理する方法を問われています。問題文の情報から、既存のSSOパスワードを使用したいとの要件と、ユーザ管理の方法が確立されているとの事情が明らかになります。この複雑な状況を理解し、既存のアイデンティティ管理システムとGoogle Cloudの間の適切な同期・認証機構を選択することが重要となります。
基本的な概念や原則：
Google Cloud Directory Sync：Google Cloudのサービスで、ユーザー、グループ、Google Workspaceアカウントなどの情報をオンプレミスのLDAPサーバーから同期することができます。
Active Directory（AD）：Microsoftが提供するディレクトリサービスで、ユーザー、グループ、コンピュータなどの情報を一元管理できます。
LDAP（Lightweight Directory Access Protocol）：インターネットプロトコルの一つで、ディレクトリサービスの情報を問い合わせ、操作するためのプロトコルです。
SSO（Single Sign-On）：一度のログイン認証で複数のシステムやサービスを利用できるようにする技術です。
Kerberos：ネットワーク認証プロトコルで、ユーザーとサービス間の認証を管理します。しかし、Googole Cloud Consoleへのダイレクトなサインインはサポートしていません。
OpenID Connect（OIDC）：一種のSSO技術で、Google Cloud Consoleへのログインに使用する認証トークンを生成します。これはユーザーが独自のIdPを使用してGoogle Cloud Consoleにログインする方法と異なります。
正解についての説明：
（選択肢）
・Google Cloud Directory Syncを使用して、Googleドメインのデータを既存のActive DirectoryまたはLDAPサーバーと同期します
この選択肢が正解の理由は以下の通りです。
Google Cloud Directory Sync（GCDS）は、オンプレミスのLDAPサーバーやActive DirectoryとG Suiteとのユーザー情報の同期を実現するツールです。これにより、ユーザーは自身の既存のアカウント資格情報を使用してGoogle Cloud Consoleにアクセスできます。ユーザーがすでにActive DirectoryまたはLDAPを使用している場合、GCDSはその既存のユーザー管理環境を維持しつつ、新たなインフラストラクチャへの移行をスムーズに行うのに適しています。
また、同期することでローカルシステムとクラウドシステム間で一貫性を保つことができ、管理作業の手間を省くことができます。なお、既存のSSOパスワードを用いて認証したい場合、別途SSO設定が必要となる点は留意が必要です。
不正解についての説明：
選択肢：Googleドメインのデータを既存のActive DirectoryやLDAPサーバーと手動で同期します
この選択肢が正しくない理由は以下の通りです。
手動での同期は大量のユーザーデータの管理には効率が悪く、誤りを引き起こす可能性もあります。Google Cloud Directory Syncを使用すると自動的に同期が行え、効率的に信頼性の高い同期作業が達成できます。
選択肢：ユーザーは、オンプレミスのKerberos準拠のIDプロバイダの認証情報を使用して、Google Cloud Consoleに直接サインインします
この選択肢が正しくない理由は以下の通りです。
Google Cloud Consoleへの直接のサインインは既存のActive DirectoryやLDAPサーバーとの統合を提供しません。
一方、Google Cloud Directory Syncは既存のActive DirectoryまたはLDAPサーバーとGoogleのユーザーデータを同期することで、要件を満たします。
選択肢：ユーザーはOpenID（OIDC）互換のIdPを使ってサインインし、認証トークンを受け取り、そのトークンを使ってGoogle Cloud Consoleにログインします
この選択肢が正しくない理由は以下の通りです。
OIDCを使用してユーザーがサインインし、トークンでGoogle Cloud Consoleにログインする手段は、ユーザーのActive DirectoryやLDAPサーバーとGoogleドメイン間の同期を確立する手段ではありません。
また、これは既存のSSOパスワードを活用する要求を満たしていません。
参考リンク：
https://cloud.google.com/solutions/federating-Google Cloud-with-active-directory-integrating
https://cloud.google.com/identity/docs/manage-resources
https://support.google.com/a/answer/106368?hl=en
</div></details>

### Q.  問題49: 未回答
セキュアなコンテナイメージを作成するとき、可能であれば、どの2つの項目をビルドに組み込むべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、セキュアなコンテナイメージを作成する際のベストプラクティスを理解することが求められます。選択肢から2つを選ぶ問題なので、全ての選択肢を注意深く考慮したうえで、どれが最もセキュアなコンテナ作成に対する推奨事項であるかを判断する必要があります。これには、不必要なツールの除去や単一のアプリをパッケージ化するという一般的なセキュリティ概念が関係してきます。
基本的な概念や原則：
単一のアプリをコンテナとしてパッケージ化：コンテナの一つのロールごとに一つのコンテナを使用する原則です。これにより、セキュリティが強化され、独立性と可搬性が向上します。
不要なツールの削除：コンテナイメージから必要ないソフトウェアやツールを削除することで、アタックサーフェスを減らし、セキュリティを向上させます。
PID 1の実行：Linux内でプロセスID 1（PID 1）として実行されるプロセスは、システム内で他の全てのプロセスの親となるため、潜在的なセキュリティリスクを持つことがあります。
パブリックコンテナイメージ：一般的に公開されているコンテナイメージは、使用前にその安全性をチェックすることが重要です。不明確なソースからのイメージには潜在的なセキュリティリスクがあります。
コンテナ画像レイヤー：多くのレイヤーを使用して機密情報を隠すという行為は、セキュリティ上望ましくないとされています。適切なセキュリティ対策を通じて情報を保護するべきです。
正解についての説明：
（選択肢）
・単一のアプリをコンテナとしてパッケージ化します
・アプリに必要のない不要なツールを削除します
この選択肢が正解の理由は以下の通りです。
まず、コンテナイメージに単一のアプリをパッケージ化することは、コンテナの基本的な原則です。コンテナは軽量で独立した運用が可能なため、1つのコンテナに1つのアプリケーションを配置することで、そのアプリケーションのライフサイクルを管理しやすくなります。
また、他のアプリケーションとコンテナを独立させることで、セキュリティも向上します。
次に、アプリに必要のない不要なツールを削除することも、セキュアなコンテナイメージ作成の重要な要素です。冗長なツールやソフトウェアが存在すると、それらが予期しないセキュリティリスクとなる可能性があります。特に、不必要なネットワークサービスやデーモンは、リモートからの攻撃を可能にする潜在的な脆弱性となり得ます。これらを削除することで、攻撃面を最小限に抑え、セキュリティを高めることが可能となります。
不正解についての説明：
選択肢：アプリがPID 1として実行されていないことを確認します
この選択肢が正しくない理由は以下の通りです。
通常、コンテナ内の主要なプロセスはPID 1（プロセスID 1）として実行されます。これは、コンテナがOSを模倣し、その主要プロセスがOSの初期プロセスとして機能するためです。問題の目的と合わないため、この選択肢は不正解です。
選択肢：アプリのベースイメージとしてパブリックコンテナイメージを使用します
この選択肢が正しくない理由は以下の通りです。
パブリックコンテナイメージをベースとして使用すると、予期せぬセキュリティリスクが含まれる可能性があります。不要なツールの削除や単一のアプリのパッケージ化と比べ、セキュアなコンテナイメージ作成には適しません。
選択肢：多くのコンテナ画像レイヤーを使用して、機密情報を隠します
この選択肢が正しくない理由は以下の通りです。
多くのコンテナ画像レイヤーを使用して機密情報を隠すという考え方自体がセキュリティにおける抜本的な解決策ではありません。機密情報は元々BE含めないか、セキュアな手段（秘密情報管理ツール等）で管理すべきです。
一方、正解の選択肢は不必要な脆弱性を最小化する原則に基づいています。
参考リンク：
https://cloud.google.com/container-registry/docs/managed-base-images
https://cloud.google.com/build/docs/building/containers
https://cloud.google.com/solutions/best-practices-for-building-containers
</div></details>

### Q.  問題50: 未回答
ある顧客は、攻撃者がドメイン/IPをハイジャックし、中間者攻撃によってユーザーを悪意のあるサイトにリダイレクトするのを防ぐ必要があります。
この顧客が使用すべきソリューションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のセキュリティ脅威、具体的にはドメイン/IPのハイジャックと中間者攻撃を防ぐためのソリューションを選ぶことが求められています。そのため、選択肢の各ソリューションがどのようなセキュリティ問題に対処するもので、それぞれがどのように機能するのかを理解していることが重要です。また、問題文の状況と各選択肢が対応するセキュリティ問題を照らし合わせ、一致するものを見つけることが必要です。
基本的な概念や原則：
DNSSEC（Domain Name System Security Extensions）：DNS応答の真正性と完全性を検証するための拡張プロトコルです。ユーザーが意図したWebサイトに安全にナビゲートできるようにします。
中間者攻撃：攻撃者が通信の両端点になりすますことで、通信を盗聴したり、改ざんしたりする種類の攻撃です。DNSSECはこの種の攻撃からの保護を提供します。
VPCフローログ：ネットワークフローデータをキャプチャし、Google Cloud上のVirtual Private Cloud（VPC）ネットワークのトラフィックに関するインサイトを提供するサービスです。
Cloud Armor：Google Cloud上のアプリケーションに対する分散型サービス妨害（DDoS）攻撃やウェブ攻撃から保護するためのサービスです。
Cloud Identity-Aware Proxy：Google Cloud上のアプリケーションへのアクセスを制御するためのサービスです。使用者のアイデンティティとコンテキストを確認して、セキュアなアクセスを保証します。
正解についての説明：
（選択肢）
・DNSSEC
この選択肢が正解の理由は以下の通りです。
DNSSEC（Domain Name System Security Extensions）は、DNSレコードの改ざんを防ぎ、ユーザーが悪意のあるサイトに誘導されるのを防ぐためのプロトコルです。中間者攻撃は、攻撃者が通信を傍受し、送信者と受信者の間に入る攻撃の一つです。DNSSECがなければ、攻撃者はエンドユーザーを誤ったサイトに誘導することができます。しかし、DNSSECを適用すると、DNSレスポンスが改ざんされていないことを確認するデジタル署名が追加されます。その結果、攻撃者はドメインまたはIPをハイジャックし、ユーザーを別の目的地にリダイレクトすることができなくなります。そのため、この問題文の顧客が求めているセキュリティの要件を満たす最適な解決策はDNSSECとなります。
不正解についての説明：
選択肢：VPCフローログ
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフローのデータをキャプチャし、ネットワークのトラフィックパターンを分析する機能であり、ドメインやIPのハイジャック、中間者攻撃を防ぐ機能はありません。
一方、DNSSECはDNS応答の改ざんを防ぐもので、この問題の要件を満たします。
選択肢：Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Cloud Armorは主にDDoS攻撃などのウェブ攻撃からアプリケーションを保護するためのサービスであり、ドメイン/IPのハイジャックや中間者攻撃から保護する機能はありません。
一方、DNSSECはDNSスプーフィングや中間者攻撃を防ぐためのプロトコルで、この問題の要件を満たすソリューションです。
選択肢：Cloud Identity-Aware Proxy
この選択肢が正しくない理由は以下の通りです。
Cloud Identity-Aware Proxyは認証と承認を強化するためのサービスであり、あくまでアクセス制御を担うものです。反対にDNSSECはドメイン名の信頼性を保証するための技術であり、ドメインやIPがハイジャックされて中間者攻撃を受けることを防ぐのに対応するため、この問題の要件を満たします。
参考リンク：
https://cloud.google.com/dns/docs/dnssec
https://cloud.google.com/armor/docs/security-policy-concepts
https://cloud.google.com/iap/docs/concepts-overview
</div></details>

## 5

### Q.  問題1: 未回答
組織でBigQuery分析データウェアハウスを管理しています。すべての顧客のデータを共通のテーブルに保持する一方で、行と列の権限に基づいてクエリアクセスを制限したいと考えています。クエリ以外の操作はサポートしていません。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、BigQuery分析データウェアハウスの管理と、顧客のデータアクセス制限に関する要件が提示されています。顧客が共通のテーブル内のデータにクエリを実行しますが、それぞれのクエリアクセスは行と列の権限に基づいて制限されるべきで、クエリ以外の操作はサポートされません。この要件を満たすために選ぶべき選択肢は、行レベルと列レベルのアクセス制御の設定方法に基づいています。BigQueryのセキュリティ機能とその適切な利用に理解が必要です。
基本的な概念や原則：
BigQuery：Google Cloudのフルマネージド、サーバーレス、高度にスケーラブルなエンタープライズデータウェアハウスです。大規模な分析ワークロードに対応し、SQLクエリを使用してデータを照会することができます。
行レベルのアクセスポリシー：特定の行へのアクセスを制限するように設定したポリシーです。フィルタ式を使って、どのユーザーがどの行にアクセスできるかを制御します。
列レベルのポリシータグ：特定の列へのアクセスを制限するためのポリシーです。データカテゴリや機密度などに基づいて、どのユーザーがどの列にアクセスできるかを制御します。
Cloud Key Management Service（KMS）：Google Cloudの暗号化キー管理システムで、データの暗号化と復号を行います。ただし、列レベルのアクセス制限には適していません。
データマスキング：特定のデータを非表示にするプロセスです。しかし、BigQueryでは直接的なデータマスキング機能は提供していません。
正解についての説明：
（選択肢）
・フィルタ式をFALSEに設定してクエリを実行したときに、結果データを制限する行レベルのアクセスポリシーを作成します
・列レベルのポリシータグを作成して、クエリ実行時に列へのアクセスを制御します
この選択肢が正解の理由は以下の通りです。
まず、"フィルタ式をFALSEに設定してクエリを実行したときに、結果データを制限する行レベルのアクセスポリシーを作成します"は、BigQueryの行レベルセキュリティを活用した制御方法で、フィルタ式がFALSEと評価される行はクエリの結果から除外されます。これにより、特定のユーザーが特定の行にアクセスすることを制限することができます。
また、"列レベルのポリシータグを作成して、クエリ実行時に列へのアクセスを制御します"は、BigQueryの列レベルセキュリティを実現する手段であり、ポリシータグを用いてアクセスを制御することで、特定のユーザーが特定の列にアクセスすることを制限します。
したがって、これらのアプローチは、共通のテーブルに保持された顧客データへのクエリアクセスを制限するための適切な手段です。
不正解についての説明：
選択肢：フィルタ式をTRUEに設定してクエリを実行したときに、結果データを制限する行レベルのアクセスポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
フィルタ式をTRUEに設定すると、すべての行が条件に一致するため、特定のユーザーのアクセス制限が行われず、結果として行レベルのアクセスポリシーが効果的に作成できないからです。
一方、フィルタ式をFALSEに設定すると、クエリによってアクセスが制限されるため、特定の行へのアクセス制限が可能となります。
選択肢：Cloud Key Management Service（KMS）でAEAD（Authenticated Encryption with Associated Data）機能を使用して列レベルの暗号化を構成し、クエリ実行時に列へのアクセスを制御します
この選択肢が正しくない理由は以下の通りです。
BigQueryでは、Cloud KMSのAEAD機能を使用した列レベルの暗号化はサポートしていないため、これはアクセス制限の手段として使用できません。代わりに列レベルのアクセス制限には、列レベルのポリシータグを使用します。
選択肢：動的なデータマスキングルールを構成して、クエリ実行時に列へのアクセスを制御します
この選択肢が正しくない理由は以下の通りです。
動的なデータマスキングルールはBigQueryでは直接サポートされておらず、列アクセスを制御するのに柔軟性が欠けています。その代わりに列レベルのポリシータグが正確なアクセス制御を提供します。
参考リンク：
https://cloud.google.com/bigquery/docs/row-level-security-intro
https://cloud.google.com/bigquery/docs/column-level-security-intro
https://cloud.google.com/bigquery/docs/best-practices-access-control
</div></details>

### Q.  問題2: 未回答
あなたは、現在の保守契約が切れる前に、会社のデータセンターからGoogle Cloudにレガシーアプリケーションを移行するタスクを引き受けています。アプリケーションがどのポートを使用しているのかわからず、確認できるドキュメントもありません。この状況で、環境を危険にさらすことなく移行を完了したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ドキュメンテーションが不十分で、アプリケーションがどのポートを使用しているのか分からないレガシーアプリケーションのGoogle Cloudへの移行が課題となっています。適切な移行戦略とネットワーク管理の手法を選択する必要があります。注目すべきは"リフト＆シフト"アプローチ、カスタムネットワーク、VPCファイアウォールルールの使用、VPCフローログの使用、アプリケーションのリファクタリング、Cloud Functionsなどです。これらの要素を理解し、それぞれの選択肢が移行タスクと保全の要件をどの程度満たすかを考察することが求められています。
基本的な概念や原則：
リフト＆シフト：既存のアプリケーションをそのままクラウド環境に移行する方法です。アプリケーションの構造を変更せず、早期の実装が可能ですが、クラウド環境の特性を十分に活かすことが難しい場合もあります。
VPC（Virtual Private Cloud）：Google Cloud上で定義可能な、プライベートな仮想ネットワーク環境です。VPC内では、ユーザーが設定したネットワークのルールに基づいてリソース間の通信が管理されます。
VPCファイアウォールルール：VPC内において、特定の通信を許可したり、拒否したりするためのルールを定義します。これによりアプリケーションのセキュリティを強化することができます。
VPCフローログ：VPCネットワークの流入・流出トラフィックのログです。これにより、不正なトラフィックを検出したり、パフォーマンスの問題を診断したりすることが可能です。
適切なトラフィックの確認：アプリケーションが正しく動作するために必要なネットワーク通信を確認します。これにはVPCファイアウォールルールやVPCフローログが利用されます。
アプリケーションリファクタリング：既存のアプリケーションを改良し、新しいアーキテクチャーやプラットフォームに適応させる作業のことです。これによりクラウドの特性をより活かすことが可能になりますが、実装には時間とコストが必要です。
マイクロサービスアーキテクチャ：アプリケーションを小さな独立したサービスに分けるアーキテクチャのことです。各マイクロサービスは独自のプロセスとデータストレージを持ち、APIを介して他のサービスとやりとりします。これにより、開発と運用のフレキシビリティが向上します。
正解についての説明：
（選択肢）
・"リフト＆シフト"アプローチを採用して、アプリケーションを分離プロジェクトに移行します。VPCファイアウォールルールを使用して、すべての内部TCPトラフィックを有効にします。VPCフローログを使用して、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正解の理由は以下の通りです。
まず、リフト＆シフトとは、既存のサービスをそのままクラウドに移行する戦略です。この方法を使用すると、アプリケーションの変更が最小限になり、移行の複雑性とリスクが軽減されます。
次に、VPCファイアウォールルールを使用して、すべての内部TCPトラフィックを有効にすると、アプリケーションが必要とするすべてのポートを開放できます。これにより、アプリケーションが正常に機能することが確認できます。ただし、この方法を使用すると、アプリケーションが必要とするすべてのTCPトラフィックが許可され、セキュリティ上のリスクが発生する可能性があります。そのため、VPCフローログを使用して、アプリケーションが正常に機能するためにどのトラフィックを許可すべきかを判断することが重要です。フローログにより、リアルタイムでネットワークフローデータをキャプチャし、分析することができます。これにより、不要なポートを特定し、それらを閉じることでセキュリティを強化することが可能となります。
不正解についての説明：
選択肢："リフト＆シフト"アプローチを採用して、カスタムネットワークでアプリケーションを分離プロジェクトに移行します。VPC内のすべてのトラフィックを無効にし、ファイアウォールログを調べて、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正しくない理由は以下の通りです。
VPC内のすべてのトラフィックを無効にすると、レガシーアプリケーションの機能が全て停止してしまうためです。正解の選択肢では一時的に全てのTCPトラフィックを許可し、実際のトラフィックを見てから制限する方法を選んでいます。
選択肢：アプリケーションを、GKEクラスター内のマイクロサービスアーキテクチャにリファクタリングします。ファイアウォールルールを使用して、クラスターの外部からのすべてのトラフィックを無効にします。VPCフローログを使用して、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正しくない理由は以下の通りです。
アプリケーションをマイクロサービスアーキテクチャにリファクタリングすることは時間がかかり、アプリケーションがどのポートを使用しているかわからないという問題を解決しません。
また、保守契約が切れる前に移行を完了するという要件に対して、リファクタリングは現実的な解決策ではありません。
選択肢：アプリケーションを、分離されたプロジェクトのCloud Functionsでホストされるマイクロサービスアーキテクチャにリファクタリングします。ファイアウォールルールを使用して、プロジェクトの外部からのすべてのトラフィックを無効にします。VPCフローログを使用して、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正しくない理由は以下の通りです。
リファクタリングは、アプリケーションのコードの構造を改変するプロセスであり、時間と労力がかかるため、現在の保守契約が切れる前に移行を完了するという要件を満たすのが困難です。
また、使用するポートが不明な場合、リファクタリングはリスクが高いため、ここでの最適な解決策は"リフト＆シフト"アプローチです。
参考リンク：
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/architecture/vm-migration-validation-with-Google Cloud-migration-landing-zone
</div></details>

### Q.  問題3: 未回答
ある企業がGoogle Cloud上にアプリケーションをデプロイしています。会社のポリシーでは、少なくとも2つの地理的ロケーションにデータを自動的に複製できるソリューションを使用して長期データを保存する必要があります。
どのストレージソリューションの使用が許可されていますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、データの地理的冗長性を持つ特定のストレージソリューションについて問われています。企業のポリシーから、求められるソリューションは少なくとも2つの地理的なロケーションでデータを保存する機能が必要で、それが自動的に行われる必要があることを理解することが重要です。選択肢の中からこの要件を満たすストレージソリューションを選びましょう。
基本的な概念や原則：
Cloud BigQuery：Google Cloudの高度なデータ分析ワーケハウスサービス。複数の地域にまたがってデータを保存することが可能です。大規模なデータセットに対する分析をリアルタイムで行うことが可能で、長期データの保存にも対応しています。
Compute Engine SSDディスク：Google CloudのCompute Engineで使用するためのSSDストレージ。高性能な読み書き速度を提供しますが、単一の地域でのみ存続します。
Compute Engine Persistent Disk：Google CloudのCompute Engineで使用するための高性能ストレージ。SSDディスクとは異なり、データは耐久性がありますが、単一の地域でのみ存続します。
Cloud Bigtable：Google CloudのNoSQL Big Dataデータベースサービス。大規模な分析と操作ワークロードに対応できますが、データは指定した単一の地域に保存されます。
正解についての説明：
（選択肢）
・Cloud BigQuery
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのBigQueryは高性能のデータウェアハウスであり、その特性として自動的なデータレプリケーションと災害復旧が提供されています。BigQueryは独自のネットワークインフラストラクチャを使用してデータをGoogle内部の複数の物理的な場所に分散保存することで、データの堅牢性と耐久性を確保します。これにより、データセットの一部が何らかの理由で使用できなくなった場合でも、データの利用が可能となります。
また、BigQueryは長期データの保存に利用可能であり、大量の生データをリアルタイムに追加及び更新できます。そのため、企業の要件である複数の地理的ロケーションにデータを自動複製し、長期データを保存するというポリシーを満たすことが可能です。
したがって、BigQueryはこのシナリオにおいて適切なソリューションと考えられます。
不正解についての説明：
選択肢：Cloud Bigtable
この選択肢が正しくない理由は以下の通りです。
Cloud Bigtableは単一リージョン内での複製が可能な高性能NoSQLデータベースであり、データを少なくとも2つの地理的ロケーションに自動的に複製する要件を満たせません。
それに対して、Cloud BigQueryはデフォルトでリージョン間ののデータ複製を提供します。
選択肢：Compute Engine SSDディスク
この選択肢が正しくない理由は以下の通りです。
Compute Engine SSDディスクは単一のゾーンまたはリージョンにデータを保存し、自動的に複数の地理的ロケーションにデータを複製する機能を持たないため、適用できません。
一方、Cloud BigQueryは自動的にデータを複製し、複数地域に保存することが可能です。
選択肢：Compute Engine Persistent Disk
この選択肢が正しくない理由は以下の通りです。
Compute Engine Persistent Diskは単一の地理的ロケーションにデータを保存します。これは、少なくとも2つの地理的ロケーションにデータを複製するポリシーに反します。
一方、Cloud BigQueryはデータの自動的な地理的な冗長性を提供します。
参考リンク：
https://cloud.google.com/bigquery/docs/locations
https://cloud.google.com/bigtable/docs/replication
https://cloud.google.com/compute/docs/disks#repds
</div></details>

### Q.  問題4: 未回答
あなたの会社はGoogle Cloudを使用しており、一般に公開されているネットワーク資産があります。あなたは、最小限の時間で、ソフトウェアツールを使用して、これらの資産を発見し、これらの資産のセキュリティ監査を実行したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、公開されているネットワーク資産の発見とセキュリティ監査の実行が求められています。また、最小限の時間で、ソフトウェアツールを用いてこれを行いたいとの要件があります。したがって、選択肢を見る際には、公開されているネットワーク資産の特定とその監査が可能なツールを提供するオプションを探し、かつそれが最小限の時間で実行可能であるかどうかを評価する必要があります。
基本的な概念や原則：
Cloud Asset Inventory：Google CloudのリソースとIAMポリシーを検索、分析、監視するためのサービスです。リソース設定の変更を追跡したり、自動的に情報を取得したりすることができます。
ネットワークセキュリティスキャナー：Google Cloud上のネットワークリソースの脆弱性を定期的にスキャンし、潜在的な問題を報告するツールです。
ソフトウェアツールによるセキュリティ監査：ソフトウェアツールを使用して、脆弱性や潜在的な脅威を発見し、評価するためのプロセスです。これにはネットワークスキャン、構成管理、ログ分析などが含まれます。
プラットフォームセキュリティスキャナ：特定のプラットフォームや技術を対象としたセキュリティスキャナーです。特定の脆弱性を特定し、修正の推奨を提供します。
外部資産：企業のデジタルフットプリントの一部で、企業が所有するが直接管理していない資産のことを指します。これには、パートナーやサプライヤーが管理するウェブサイトやCloud Storage、IPアドレスなどが含まれます。
正解についての説明：
（選択肢）
・Cloud Asset Inventoryを使用してすべての外部資産を特定し、それらに対してネットワークセキュリティスキャナーを実行します
この選択肢が正解の理由は以下の通りです。
まず、要件は資産の発見とセキュリティ監査を最小限の時間で実行することを求めています。そのためには、Cloud Asset Inventoryとネットワークセキュリティスキャナーの組み合わせが最も適しています。
Cloud Asset Inventoryは、Google Cloudのすべての資産に関する情報のスナップショットや履歴を提供するサービスで、これによりあなたの会社の公開されているネットワーク資産を素早く特定できます。公開情報の範囲は広く、ストレージバケットやデータベースインスタンス、仮想マシンなど、Google Cloudのサービスに関連するあらゆる情報を含んでいます。
一方、ネットワークセキュリティスキャナーは、指定したネットワーク資産に対するセキュリティ脆弱性の検査を行うツールです。これらの資産に対してセキュリティスキャンを実施することで、可能な攻撃経路を特定し、それを是正する対策を講じることが可能となります。
したがって、この選択肢が最も効率的に要件を満たす方法と言えるでしょう。
不正解についての説明：
選択肢：組織内のすべてのインスタンスでプラットフォームセキュリティスキャナを実行します
この選択肢が正しくない理由は以下の通りです。
プラットフォームセキュリティスキャナを全インスタンスで実行する方法では、公開されているネットワーク資産を迅速に特定できず効率が悪いです。
一方、Cloud Asset Inventoryを使うと、外部資産を効率的に特定でき、その上でネットワークセキュリティスキャナを実行できます。
選択肢：Googleが承認したセキュリティベンダーに監査を依頼します
この選択肢が正しくない理由は以下の通りです。
Googleが承認したセキュリティベンダーに監査を依頼する方法は最小限の時間でセキュリティ監査を行うという要件に反します。それは、外部のベンダーと連携し、監査を実施するための時間とコーディネーションが必要になるからです。対象的に、Cloud Asset Inventoryとネットワークセキュリティスキャナーを使えば短時間で自動的に資産を発見し、セキュリティ監査を実行することが可能です。
選択肢：保留中の監査についてGoogleに通知し、スキャンを実行する前に確認を待ちます
この選択肢が正しくない理由は以下の通りです。
監査の実行についてGoogleに通知し、確認を待つという選択肢は、自社ネットワークのセキュリティ監査をGoogleが直接行うという誤解に基づいています。
逆に、Cloud Asset Inventoryとネットワークセキュリティスキャナーは、自社で迅速にネットワーク資産の検出と監査を行うツールです。
参考リンク：
https://cloud.google.com/asset-inventory/docs/overview
https://cloud.google.com/security-command-center/docs/concepts-overview
https://nmap.org/book/man.html
</div></details>

### Q.  問題5: 未回答
あなたは会社の開発チームに所属しています。あなたは、GKE上のステージングでホストされているウェブアプリケーションが、入力されたデータを最初に適切に検証することなく、ウェブページにユーザデータを動的に取り込んでいることに気づきました。このため、攻撃者は実運用環境において、被害者ユーザのブラウザで不正なコマンドを実行したり、任意のコンテンツを表示したりできる可能性があります。
この脆弱性をどのように防ぎ、修正すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ウェブアプリケーションのセキュリティ脆弱性に対処するための最適な方法を問います。具体的な脆弱性としてクロスサイトスクリプティング（XSS）が挙げられています。適切な手段を選択するためには、この脆弱性がどのような挙動をもたらすのか、どのように防ぐことができるのかを理解する必要があります。また選択肢からは、攻撃のシミュレーション、IPに基づくフィルタリング、HTTPSロードバランサーやCloud Armorの使用、古いライブラリの確認等、複数の防御手段が示されています。課題はこれらの中から、XSS攻撃に最も効果的な対策を選ぶことです。
基本的な概念や原則：
GKE（Google Kubernetes Engine）：Google CloudのマネージドKubernetesサービスです。コンテナ化されたアプリケーションをデプロイ、スケール、更新するための環境を提供します。
Web Security Scanner：Google Cloudの自動化されたスキャナーで、Webアプリケーションの脆弱性を探すツールです。クロスサイトスクリプティング（XSS）や、SQLインジェクションなどの一般的な脆弱性を検出することができます。
エスケープ処理：潜在的な攻撃コードが含まれる可能性があるデータを安全な形式に変換するプロセスです。これにより、攻撃者が意図しないコードを実行するのを防ぐことができます。
Cloud Identity-Aware Proxy（IAP）：Google Cloudのサービスで、アプリケーションへのアクセスをセキュアに管理します。しかし、ユーザーデータの検証またはエスケープ処理を自動的に提供するものではありません。
Cloud Armor：Google Cloudのサービスで、DDoS攻撃などの一般的なWeb攻撃を防ぐ機能を提供します。しかし、クライアントサイドの脆弱性（例えば、XSS）を防ぐことはできません。
HTTPSロードバランサー：HTTPSトラフィックを複数のバックエンドサービスに分散するGoogle Cloudのサービスです。セキュリティを強化するために使用することができますが、XSS攻撃を防ぐ機能は提供していません。
ライブラリの保護されたバージョン：セキュリティパッチが当てられ、脆弱性が修正されているライブラリのバージョンです。これを使用することで、一部のセキュリティリスクを軽減することができますが、ユーザーデータのエスケープ処理を自動的に提供するわけではありません。
正解についての説明：
（選択肢）
・ステージングでWeb Security Scannerを使ってXSSインジェクション攻撃をシミュレートし、コンテキストの自動エスケープをサポートするテンプレートシステムを使います
この選択肢が正解の理由は以下の通りです。
まず、Web Security ScannerはGoogle Cloudが提供するセキュリティ診断ツールで、Webアプリケーションの脆弱性を特定できる機能があります。該当のウェブアプリケーションがユーザデータを検証せずに動的に取り込んでいると問題文にあるので、このツールを使用して異常があるかどうかを確認し、特にXSS（クロスサイトスクリプティング）攻撃をシミュレートします。これにより、擬似的に攻撃を行い、その対策をあらかじめ検討することができます。
また、コンテキストの自動エスケープをサポートするテンプレートエンジンの使用は、入力値がウェブページに反映される際に、その値がコードとして実行されることを防ぎます。利用者による入力がそのままHTMLなどのコードやデータとして扱われることで生じる脆弱性、XSS攻撃の対策となります。これにより、攻撃者が不正なコマンドを実行することや、任意のコンテンツを表示する手段を取り除き、セキュリティの強化に寄与します。
不正解についての説明：
選択肢：IPアドレスまたはエンドユーザーデバイスの属性に基づくCloud Identity-Aware Proxy（IAP）を使用して、脆弱性を防止および修正します
この選択肢が正しくない理由は以下の通りです。
Cloud IAPは認証と認可を提供してアクセスを制御することに役立つサービスですが、クロスサイトスクリプティング（XSS）といったウェブページ内部での不正なコマンドの実行を防止する機能はありません。
これに対して、Web Security ScannerはXSS等の脆弱性を検出し、テンプレートシステムは不正なコードの実行を防ぐための解決策です。
選択肢：HTTPSロードバランサーをセットアップし、本番環境にCloud Armorを使用して潜在的なXSS攻撃を防ぐ
この選択肢が正しくない理由は以下の通りです。
HTTPSロードバランサーとCloud Armorを導入すると、一部のセキュリティリスクは軽減されるかもしれませんが、この設定ではXSS攻撃からの防御に特化していません。
一方、Web Security Scannerを使用すると、XSSインジェクション攻撃をシミュレートし、その脆弱性を具体的に特定することが可能となります。
選択肢：Web Security Scannerを使用して、コード内の古いライブラリの使用を検証し、含まれるライブラリの保護されたバージョンを使用します
この選択肢が正しくない理由は以下の通りです。
古いライブラリの使用を検証し、保護されたバージョンを使用することは一般的に良いセキュリティ対策ですが、これだけでは具体的な問題、つまりユーザデータの適切な検証とXSS攻撃の防止に直接対処していません。
正解の選択肢は、問題の具体的な脆弱性を対象にした手段を提供しています。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/appengine/docs/standard/python3/using-templates
https://owasp.org/www-community/attacks/xss/
</div></details>

### Q.  問題6: 未回答
あなたは、ブートディスクのソースとして使用できるイメージを制限したいと考えています。これらのイメージは専用のプロジェクトに保存されます。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のプロジェクトに保管されているイメージだけがブートディスクのソースとして利用可能にするためにどの方法が適しているかを問われています。そのため、組織ポリシーサービスやリソースマネージャーといったGoogle Cloudの管理ツールを使った対策の理解が必要です。特に、制約とその設定方法を理解することが重要です。計算機能に影響を与える制約に関連した選択肢を適切に評価する必要があります。
基本的な概念や原則：
組織ポリシーサービス：Google Cloudの組織ポリシーの管理を行うサービスです。組織のリソースに対する特定の制約を設定し、コンプライアンスを維持するのに役立ちます。
compute.trustedImageProjects制約：ブートディスクのソースとして使えるイメージを制限するための制約です。この制約を使用すると、特定のプロジェクトからのイメージのみを許可することができます。
許可操作：組織ポリシーサービスで使用できる操作の一つです。特定のリソースやアクションの実行を許可することができます。
ホワイトリスト：許可される要素のリストです。セキュリティコンテキストでは、特定のユーザー、IPアドレス、プログラムなど、特権を付与する要素のリストを作成します。
リソースマネージャー：Google Cloudのリソースを組織やプロジェクトレベルで管理するサービスです。アクセス権限やポリシーの設定などを行うことができます。
"Compute Image User"ロール：Compute Engineの特定のイメージを使用してインスタンスを作成する権限を持つロールです。
正解についての説明：
（選択肢）
・組織ポリシーサービスを使用して、組織レベルでcompute.trustedimageProjects制約を作成します。許可操作のホワイトリストとして、信頼されたプロジェクトをリストします
この選択肢が正解の理由は以下の通りです。
ブートディスクのソースとして使用できるイメージを制限するという目的に直接対応する手段として、組織ポリシーサービスが挙げられます。組織ポリシーサービスは、Google Cloudリソースの開発および運用に対する一連の典型的な制約を提供します。その中でも、compute.trustedImageProjects制約は、特定のプロジェクトからのイメージのみを信頼し、それをブートディスクのソースとして使用することを許容する制約になります。この制約により、組織全体でブートディスク作成に使用されるイメージのソースを制御することが可能になり、不適切なイメージからのブートディスク作成を抑止することができます。
したがって、この要件を満たすためには、組織ポリシーサービスを使用して、組織レベルでcompute.trustedImageProjects制約を作成し、許可操作のホワイトリストとして、信頼されたプロジェクトをリストするのが最適な解答となります。
不正解についての説明：
選択肢：組織ポリシーサービスを使用して、組織レベルでcompute.trustedimageProjects制約を作成します。拒否操作の例外として、信頼済みプロジェクトをリストします
この選択肢が正しくない理由は以下の通りです。
信頼済みのプロジェクトを拒否操作の例外としてリストするという考え方は誤っています。信頼済みのプロジェクトは許可するもので、許可操作のホワイトリストに追加すべきです。拒否操作の例外に追加すると、重要なプロジェクトが誤ってブロックされるリスクがあります。
選択肢：リソースマネージャーで、信頼できるプロジェクトのプロジェクト権限を編集します。組織をロール"Compute Image User"を持つメンバーとして追加します
この選択肢が正しくない理由は以下の通りです。
リソースマネージャーで信頼できるプロジェクトのプロジェクト権限を編集しても、特定のイメージの使用を制限することはできません。
それに対して、組織ポリシーサービスを使用すれば、compute.trustedimageProjects制約を作成し、特定のプロジェクトのイメージのみを許可操作のホワイトリストに追加できるため、要求を満たします。
選択肢：リソースマネージャーで、組織の権限を編集します。プロジェクトIDをロール"Compute Image User"を持つメンバーとして追加します
この選択肢が正しくない理由は以下の通りです。
リソースマネージャーで権限を編集し、プロジェクトIDを"Compute Image User"ロールを持つメンバーとして追加すると、そのメンバーは指定したプロジェクトのイメージにアクセスできます。しかし、これではブートディスクのソースとして使用できるイメージを制限するという要件に対応できません。
一方、組織ポリシーサービスを使って制約を作成すると、特定のプロジェクトだけがブートディスクのソースとして使用できるイメージを提供できるため、要件通りの制限が可能になります。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
https://cloud.google.com/compute/docs/access/iam
</div></details>

### Q.  問題7: 未回答
あなたはある組織のセキュリティチームのメンバーです。あなたのチームには、Webアプリケーションやデータ処理システムとともに、クレジットカード決済処理システムを含むGoogle Cloudプロジェクトが1つあります。あなたは、PCI監査基準の対象となるシステムの範囲を縮小したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、あなたが組織のセキュリティチームの一員として、PCI監査基準への対応とそれに伴うシステム範囲の縮小を考えています。公式な監査基準が関与している場合、その基準の主な目標と原則を理解しておくことが重要です。選択肢を評価する際には、特にPCI DSS（クレジットカード情報のセキュリティ基準）と関連する選択肢に対して注意深く検討するために、PCI監査の目的と要件に基づいて最適なセキュリティコントロールを選択することを心掛けてください。
基本的な概念や原則：
Google Cloudプロジェクト：Google Cloud上でリソースを管理するための主要な組織単位です。各プロジェクトは独立した設定、IAMポリシー、ネットワーキングなどを持つことができます。
PCI認証：クレジットカード情報の安全性を確保するための国際的な規格です。取引量に応じたレベルがあり、各レベルには特定の要求事項が定められています。
カード会員データ環境：クレジットカードデータを含む、あらゆる人、プロセス、技術の環境のことです。PCI監査では、これらの環境が厳しく監査されます。
多要素認証：ユーザーの身元を確認するために二つ以上の検証方法を使用するアクセス管理システムです。セキュリティレベルを向上させますが、PCI認証の範囲を縮小するわけではありません。
PA-DSS：クレジットカード業界が決定したソフトウェアのセキュリティ基準です。しかし、これが準拠しているだけではPCI監査の範囲を縮小するわけではありません。
VPN：インターネット上の公開ネットワークを利用しながら、プライベートネットワーク同様に安全に通信するための技術です。しかし、これを使用してもPCI監査の範囲を縮小するわけではありません。
正解についての説明：
（選択肢）
・カード会員データ環境を別のGoogle Cloudプロジェクトに移動します
この選択肢が正解の理由は以下の通りです。
セキュリティのベストプラクティスとして、特定の敏感情報（例えば、ここではクレジットカードデータ）を含むシステムは、他のシステムから分離・切り離すことが推奨されます。ここでは、PCI監査基準の対象となるシステムを、他のWebアプリケーションやデータ処理システムと物理的に分離することで、監査の範囲を縮小し、管理を容易にし、セキュリティリスクを最小限に抑えることができます。Google Cloudのプロジェクトは、リソースの組織化と分離を可能にする機能を提供し、このアプローチを容易にします。
したがって、カード会員データ環境を別のGoogle Cloudプロジェクトに移動することは、監査基準を満たすための適切な方法となります。
不正解についての説明：
選択肢：ウェブアプリケーションの管理者アクセスには多要素認証を使用します
この選択肢が正しくない理由は以下の通りです。
ウェブアプリケーションの管理者アクセスに多要素認証を使用することは、一般的なセキュリティ強化策ではありますが、PCI監査基準の対象範囲を縮小する目的には直接貢献しません。
一方、カード会員データを別のGoogle Cloudプロジェクトに移動することで、対象となるシステムの範囲が限定され、監査対象を縮小することが可能となります。
選択肢：PA-DSSに準拠していることが証明されたアプリケーションのみを使用します
この選択肢が正しくない理由は以下の通りです。
PA-DSSに準拠していることが証明されたアプリケーションのみを使用することは良いセキュリティプラクティスではありますが、それ自体ではPCI監査基準の対象となるシステムの範囲を縮小するものではありません。
それに対して、カード会員データ環境を別のGoogle Cloudプロジェクトに移動することで、監査範囲を限定できます。
選択肢：オフィスとクラウド環境間のすべての接続にVPNを使用します
この選択肢が正しくない理由は以下の通りです。
オフィスとクラウド環境間の接続にVPNを使用するのはセキュリティを高める手段の一つではありますが、これがPCI監査基準の対象となるシステムの範囲を縮小する直接的な効果はありません。
それに対して、カード会員データ環境を別のGoogle Cloudプロジェクトに移動することで、監査対象範囲を明確に分離、縮小できます。
参考リンク：
https://cloud.google.com/resource-manager/docs/creating-managing-projects
https://cloud.google.com/compliance/offerings#card_payment
https://cloud.google.com/solutions/pci-dss-compliance-in-Google Cloud
</div></details>

### Q.  問題8: 未回答
ある顧客が、マネージドインスタンスグループ（MIG）を使用して、センシティブなワークロードをCompute Engineベースのクラスターに移行したいと考えています。ジョブは大量に発生し、迅速に完了する必要があります。また、鍵のライフサイクルを管理できることが必要です。
この顧客の要件を満たすために、クラスター上のどのブートディスク暗号化ソリューションを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客がCompute Engineベースのクラスターにセンシティブなワークロードを移行する際、速度の速さと暗号化キーのライフサイクルの管理が必要と述べています。そのため、Compute Engineベースのクラスターに移行する際に適切な暗号化ソリューションを選ぶ必要があります。選択肢を検討する際には、それぞれが速度とキーのライフサイクル管理にどのように対応しているかを見極めることが必要となります。
基本的な概念や原則：
Cloud Key Management Service（KMS）：Google Cloudの秘密鍵管理サービスです。ユーザーは自分で暗号化キーを管理し、そのライフサイクルを制御することができます。
顧客管理の暗号化キー（CMEK）：Cloud KMSで生成と管理される暗号化キーです。ユーザーは自分で鍵のライフサイクルを管理することができ、一部またはすべてのデータを特定の鍵で暗号化して保管できます。
顧客指定の暗号化キー（CSEK）：ユーザーが明示的に提供するキーで、特定の一部のデータを保護します。Google概念内において、このキーは課質者のローカル環境に保存され、Google自体がこれらの登録キーを知らないとされています。
マネージドインスタンスグループ（MIG）：Compute Engineの一部で、指定した数の一貫性のあるVMインスタンスを作成し、管理する機能です。大量のジョブを迅速に完了させるためのスケーリングに役立ちます。
ブートディスク暗号化：センシティブなデータを保護するためのセキュリティ対策です。ブート可能なディスクドライブ上のすべてのデータを暗号化して、不正なアクセスからデータを守ります。
正解についての説明：
（選択肢）
・Cloud Key Management Service（KMS）を利用した顧客管理の暗号化キー（CMEK）を使用します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Key Management Service（KMS）を使用することで、顧客自身が鍵のライフサイクルを完全に管理することができます。これにより、鍵の生成、使用、ローテーション、そして廃棄までの各ステージを厳細にコントロールすることが可能になります。この柔軟性は、センシティブなワークロードを扱う顧客が適切なセキュリティ対策を確保する上で重要です。
そして、顧客管理の暗号化キー（CMEK）を使用することで、ブートディスクのデータを安全に暗号化可能です。これはユーザーがGoogle Cloud上で生成し、管理可能な暗号化キーであり、Compute Engineベースのクラスターのデータ保護に役立ちます。以上から、顧客が必要とするセキュリティ要件と、高速なワークロード処理の需要を両立するために、Cloud KMSとCMEKの組み合わせが最適であると言えます。
不正解についての説明：
選択肢：顧客指定の暗号化キー（CSEK）を使用します
この選択肢が正しくない理由は以下の通りです。
CSEK（顧客指定の暗号化キー）は、セキュリティが高い反面、鍵のライフサイクル管理を顧客自身が行う必要があり、これは手間がかかります。
一方、Cloud KMSを利用したCMEK（顧客管理の暗号化キー）は、Google Cloud上で鍵のライフサイクル管理が可能なため、この問題の要件をより効果的に満たします。
選択肢：デフォルトでの暗号化を使用します
この選択肢が正しくない理由は以下の通りです。
デフォルトの暗号化では、鍵のライフサイクルを自身で管理することは不可能です。要件である"鍵のライフサイクルを管理できる"という点を満たせません。
それに対して、Cloud KMSを使用したCMEKは、暗号化キーのライフサイクルを顧客が管理できるため、問題の要求を満たします。
選択肢：Google Cloudに転送する前にファイルを事前暗号化し、分析に利用します
この選択肢が正しくない理由は以下の通りです。
ファイルを事前に暗号化する方法では、クラスター上のブートディスクの暗号化に直接対応できず、また、鍵のライフサイクル管理も提供できません。
一方、Cloud KMSを利用するとCMEKを使ってディスクの暗号化が可能であり、鍵のライフサイクル管理も可能となります。
参考リンク：
https://cloud.google.com/compute/docs/instances/encrypt-disks-with-cmek
https://cloud.google.com/kms/docs
https://cloud.google.com/compute/docs/instances/create-start-instance#starting_an_instance_with_encryption_key
</div></details>

### Q.  問題9: 未回答
あなたは、2つのネットワークセグメントを設定する必要があります。1つは信頼できないサブネット、もう1つは信頼できるサブネットです。2つのネットワークセグメント間のすべてのトラフィックを検査するように、次世代ファイアウォール（NGFW）などの仮想アプライアンスを構成したいと考えています。トラフィックを検査するにはネットワークをどのように設計すればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ネットワークセキュリティと隔離を強化するためのGoogle Cloudのネットワーク設計について問われています。2つの異なる信頼レベルのネットワークセグメントの間でトラフィックを検査するための仮想アプライアンスの設置が必要なシナリオです。この要件を満たすためには、各ネットワークセグメントを正しく定義し、それぞれに対して適切なアクセスポリシーを適用するネットワーク設計を理解することが重要です。また、仮想アプライアンスの配置とその接続方法にも注意を払う必要があります。これらの要素を考慮に入れ、四つの選択肢から最も適切なネットワーク設計を選ぶことが求められています。
基本的な概念や原則：
VPCネットワーク：Google Cloudの仮想プライベートクラウド（VPC）ネットワークは、仮想ネットワークリソースであり、物理的なプロセスをシミュレートするのに役立ちます。これは各プロジェクトのプライベートIPアドレススペースとなります。
サブネット：VPCネットワーク内のIPアドレス範囲。サブネットを用いることでネットワーク空間を区切ることができます。
次世代ファイアウォール （NGFW）：トラフィックの内容に基づいてパケットを許可またはブロックするための高度なセキュリティ機能を備えたファイアウォールの一種です。
仮想アプライアンス：ソフトウェアバージョンのネットワークアプライアンス（ファイアウォール、VPNデバイスなど）のことです。
複数のネットワークインターフェイス：物理デバイスまたは仮想アプライアンスが複数のネットワークに同時に接続するための方式です。
VPCピアリング：2つのVPCネットワーク間でトラフィックをプライベートに交換するための接続です。
カスタムルート：特定のデスティネーションへのネットワークトラフィックのパスを制御するのに使用されるネットワークルートです。
正解についての説明：
（選択肢）
・1. 2つのVPCネットワークをセットアップします。1つは信頼できるネットワーク、もう1つは信頼できないネットワークです
2. 複数のネットワークインターフェイスを使用して仮想アプライアンスを構成し、各インターフェイスがVPCネットワークの1つに接続されます
この選択肢が正解の理由は以下の通りです。
VPCネットワークを2つ設定することで、信頼できるネットワークと信頼できないネットワークが物理的に分離され、それぞれが個別のネットワーク空間を占有します。これによって、2つのネットワーク間のセキュリティを大幅に向上させることが出来ます。これは、一部の組織では信頼されたネットワークのセキュリティ確保が最優先課題となり、あらゆる予防措置を導入することが求められるので重要です。
また、複数のネットワークインターフェースを使用して仮想アプライアンスを構成することで、1つの信頼されたVPCネットワークからもう1つのVPCネットワークへ向かうすべてのネットワークトラフィックを検査できます。これによって、立たされたセキュリティポリシーに従い、要求に対する回答や、その逆のトラフィックを詳細に検査することができます。これは、侵入検知・防止システム（IDS/IPS）などのセキュリティ監視機能を実装するのに適しています。特に、次世代ファイヤーウォール（NGFW）などの仮想アプライアンスは、複数のネットワークインターフェースを持つことが一般的で、この要件を満たす設定が可能です。
不正解についての説明：
選択肢：1. 2つのサブネット（1つは信頼できるサブネット、もう1つは信頼できないサブネット）を持つ1つのVPCをセットアップします
2. 仮想アプライアンスを指すすべてのトラフィック（0.0.0.0/0）のカスタムルートを構成します
この選択肢が正しくない理由は以下の通りです。
同一のVPC内のサブネット間では直接トラフィックを送受信できますが、NGFWで検査するためには別々のネットワークが必要です。
したがって、1つのVPC内に2つのサブネットを作成すると、全てのトラフィックがNGFWを経由するわけではないため、必要なセキュリティ要件が満たされません。
選択肢：1. 2つのサブネット（1つは信頼できるサブネット、もう1つは信頼できないサブネット）を持つ1つのVPCをセットアップします
2. 仮想アプライアンスを指すすべてのRFC1918サブネットのカスタムルートを構成します
この選択肢が正しくない理由は以下の通りです。
2つのサブネットを1つのVPCで設定すると、信頼できないサブネットと信頼できるサブネット間の通信が自由になってしまいます。仮想アプライアンスがネットワーク間の全てのトラフィックを検査するためには、これらのネットワークは分離されていなければならず、正解選択肢のように2つの独立したVPCを設定するべきです。
選択肢：1. 2つのVPCネットワーク（1つは信頼できるネットワーク、もう1つは信頼できないネットワーク）をセットアップし、相互にピアリングします
2. 仮想アプライアンスを指す各ネットワーク上にカスタムルートを構成します
この選択肢が正しくない理由は以下の通りです。
VPCネットワーク間のピアリングはトラフィックを中継する能力がないため、仮想アプライアンス経由のトラフィック検査を設定することはできません。正解では各ネットワークインターフェイスがアプライアンスを経由し、トラフィックを検査できるようにします。
参考リンク：
https://cloud.google.com/vpc/docs/vpc-peering
https://cloud.google.com/vpc/docs/using-vpc
https://cloud.google.com/network-connectivity/docs/vpn/concepts/topologies#multiple-vpc-networks
</div></details>

### Q.  問題10: 未回答
ある組織が、現在のオンプレミス生産性ソフトウェアシステムからG Suiteに移行しようとしています。以前のオンプレミスシステムでは、地域の規制機関によって義務付けられたネットワークセキュリティ管理が行われていました。同組織のリスクチームは、G Suiteでもネットワークセキュリティ管理が維持され、有効であることを確認したいと考えています。この移行をサポートするセキュリティアーキテクトは、組織とGoogle Cloudとの間の新しい責任共有モデルの一部として、ネットワークセキュリティ管理が確実に実施されるようにすることを求められています。
どのようなソリューションが要件を満たすのに役立ちますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、組織がオンプレミスシステムからG Suiteへの移行を検討しているケースが提示されています。セキュリティアーキテクトは、地域の規制に対応したネットワークセキュリティ管理が維持されるように要求されています。問題文の情報を解釈すると、G SuiteというSaaS製品を適用することで、それ自体がビルトインのセキュリティソリューションを持つと思われます。これは、Googleが提供するクラウドサービスの一部としての責任を理解して選択肢を見ることが重要です。その上で、各選択肢のG Suiteとの統合と規制への対応を評価し、適切な答えを選ぶべきです。
基本的な概念や原則：
G Suite：Googleが提供するクラウドベースのビジネス向けプロダクトスイートです。メール、カレンダー、ドキュメント作成、ストレージなどのサービスを提供しています。
オンプレミスシステム：企業が自社の施設内などに設置する形で情報システムを運用する方式のことです。全ての管理と保守が自分たちの責任となります。
ネットワークセキュリティ管理：ネットワーク内のユーザーやシステム、データなどを保護するための施策や戦略です。"ファイアウォールルール"などを確認して適切に設定し、不正アクセスやデータ漏洩などを防ぎます。
責任共有モデル：クラウドサービスのセキュリティ面での責任を、サービス提供者と利用者で分担する考え方です。サービス提供者と利用者がどの部分について責任を持つかはサービスによります。
ビルトインセキュリティ：ソフトウェア、ハードウェア、システムの設計段階から組み込まれるセキュリティ機能のことで、G SuiteなどのSaaS製品には基本として含まれています。
SaaS製品：サービスとして提供されるソフトウェアのことで、インフラやハードウェアについてはサービス提供者が管理し、ユーザーはアプリケーションを利用するだけです。
Cloud Armor：Google Cloudの分散型サービス拒否（DDoS）攻撃、SQLインジェクションなどのWeb攻撃からアプリケーションを保護するセキュリティサービスです。一方、G SuiteなどのSaaS製品はセキュリティが組み込まれているため、Cloud Armorをセットアップする必要はありません。
正解についての説明：
（選択肢）
・ネットワークセキュリティはビルトインソリューションであり、G SuiteのようなSaaS製品にはGoogleのクラウド責任があります
この選択肢が正解の理由は以下の通りです。
まず、Googleの責任共有モデルでは、Googleはデータセンターやネットワークといったインフラストラクチャーレベルのセキュリティを担当します。つまり、Googleはそのネットワークとデータセンターのセキュリティに対し完全な責任を負うため、組織自体がネットワークセキュリティ管理のために別途労力を割く必要はありません。
また、G SuiteはSaaS（Software as a Service）製品であり、これによりユーザーはアプリケーションレベルのセキュリティに専念できます。そのため、ネットワークセキュリティはGoogleが担当することで確保されます。
さらに、GoogleのSaaS製品は、ビルトインのセキュリティソリューションを採用しています。これにより、独自のセキュリティ対策を設定することなく、ネットワークを安全にすることが可能となります。これらの要素が組み合わさって、選択肢のソリューションは、地域の規制に対するネットワークセキュリティ管理の要件を満たす適切な選択肢となります。
不正解についての説明：
選択肢：ファイアウォールルールが必要なコントロールに適合していることを確認します
この選択肢が正しくない理由は以下の通りです。
G SuiteはSaaS製品であり、そのセキュリティ設定はGoogleが管理します。オンプレミス環境と同じように、ユーザーが制御できるなどといったファイアウォールルールを設定することは出来ないからです。そのため、この選択肢はこのシナリオには適していません。
選択肢：Cloud Armorをセットアップして、G Suiteのネットワークセキュリティコントロールが管理できるようにします
この選択肢が正しくない理由は以下の通りです。
Cloud Armorは、主にGoogle Cloudのアプリケーションに対するDDoS攻撃やWEB攻撃を防ぐためのセキュリティサービスですが、G Suiteに適用することはできません。G Suiteのネットワークセキュリティ管理はGoogleが担当し、Cloud Armorを使って追加で設定する必要はありません。
選択肢：仮想プライベートクラウド（VPC）ネットワークを構築し、関連規則に従ってネットワークセキュリティを管理します
この選択肢が正しくない理由は以下の通りです。
VPCネットワークの構築と管理は、ネットワークのインフラストラクチャレベルでのセキュリティを提供しますが、G SuiteのようなSaaS製品はそのネットワークセキュリティがGoogleによって既に管理されています。
したがって、この選択肢は冗長であり、G Suiteの利用において必要以上の作業となります。
参考リンク：
https://cloud.google.com/security
https://cloud.google.com/docs/security/best-practices
https://support.google.com/a/answer/7587183?hl=en
</div></details>

### Q.  問題11: 未回答
あるデータベース管理者が、Cloud SQLインスタンス内で悪意のあるアクティビティが行われていることに気づきました。データベース管理者は、リソースの構成またはメタデータを読み取るAPI呼び出しを監視したいと考えています。データベース管理者はどのログを確認すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud SQLインスタンスでの悪意のあるアクティビティを検出するための適切なログタイプを特定する必要があります。問題文のキーワードは"リソースの構成またはメタデータを読み取るAPI呼び出し"です。データベース管理者が監視したいのは読取り操作、つまりデータへのアクセスです。そのため、四つの選択肢の中からリソースへのアクセスに関連するログを選ぶことが重要です。
基本的な概念や原則：
データアクセスログ：Google Cloud上のリソースへの読み書きアクセスを記録するログです。このログは、消費されたリソースに基づいて課金され、リソースの内容や属性を表示します。
管理者活動ログ：Google Cloudサービスの管理操作を記録するログです。これには、リソースの作成、変更、削除など、大部分の書き込み操作が含まれます。
システムイベントログ：Google Cloudのインフラストラクチャサービスがシステムイベントを記録するログです。これには、スケジュールされたメンテナンスなど、ユーザーが直接制御できないイベントが含まれます。
アクセスの透明性ログ：Google Cloudのエンジニアやサポートスタッフが顧客データにアクセスした時のログです。これには、アクセス時間、アクセス理由、アクセスしたデータの場所や種類などの情報が含まれます。
正解についての説明：
（選択肢）
・データアクセス
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、監視やログの分析にCloud Audit Logsを使用します。Cloud Audit Logsには管理活動ログとデータアクセスログの2つの主要な種類があります。管理活動ログはAPI呼び出しや、ユーザーアクティビティなどの管理操作を記録します。一方でデータアクセスログはリソースの読み取り、書き込み、更新操作を記録します。
したがって、データベース管理者がCloud SQLインスタンス内での悪意のあるアクティビティを調査したい場合、それがリソースの構成またはメタデータの読み取りに関連していると仮定すると、データアクセスログを確認することが適切です。
不正解についての説明：
選択肢：管理者活動
この選択肢が正しくない理由は以下の通りです。
管理者活動のログは、リソースの作成、変更、削除など、Google Cloudのリソースまたはサービスを管理する操作を監視します。しかし、問題の要件はAPIの読み取り操作の監視であり、これはデータアクセスのログの範囲に含まれるため、管理者活動のログでは要件を満たせません。
選択肢：システムイベント
この選択肢が正しくない理由は以下の通りです。
システムイベントログは、リソースのライフサイクルイベントの監視に用いられますが、リソースの構成やメタデータを読み取るAPI呼び出しの監視には不適切です。反対に、データアクセスログはAPI呼び出しを監視するためのものです。
選択肢：アクセスの透明性
この選択肢が正しくない理由は以下の通りです。
アクセスの透明性はGoogleの管理者によるアクセスを追跡するためのものであり、Cloud SQLインスタンスにおけるユーザーのアクションを監視することはできません。
一方、データアクセスログはリソースの構成やメタデータの読み取りを確認できます。
参考リンク：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/auditing
https://cloud.google.com/sql/docs/mysql/admin-api/logging
</div></details>

### Q.  問題12: 未回答
コンプライアンス上の理由から、組織は範囲内のPCI Kubernetesポッドが"範囲内の"ノードのみに存在することを確認する必要があります。これらのノードには"スコープ内の"ポッドのみを含める必要があります。
組織はこの目標をどのように達成すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のノードでのみ特定のKubernetesポッドを実行する必要があるシナリオが設定されています。また、これらのノードにはこれらの特定のポッドのみが存在できると明記されています。これらの要件を満たすために、Kubernetesの仕組みや概念を理解し、適切な選択肢を選ぶことが求められます。選択肢を評価する時には、ノード制御とポッドのスケジューリングに関連する解決策を探し、組織がポッドが特定のノードに限定されていることを確実に保証できることを確認してください。
基本的な概念や原則：
Kubernetesのテイント（Taint）：ノードが特定のポッドのスケジューリングを受け付けないように設定する機能です。特定のロールや制限のあるノードへのポッドのスケジューリングを制御できます。
Kubernetesの許容範囲（Toleration）：テイントが設定されたノード上でポッドが実行できるようにする設定です。ポッドが特定のテイントを持つノードにスケジュールされるための条件を設定できます。
nodeSelector：Kubernetesの機能で、ポッドが特定のノード上で実行されるように指定できます。ノードに付けられたラベルと一致するポッドのみがそのノード上でスケジュールされます。
ノードプール：特定の設定或いは機能を持つノードの集合のことです。ノードプールを作成することで、特定のワークロードを特定のノード群にスケジュールすることが可能になります。
ポッドセキュリティポリシー：Kubernetesのセキュリティ設定の一つで、特定のポッドが実行するにあたり必要な権限や設定を管理します。
名前空間：Kubernetesクラスター内のリソースを論理的にグループ化したものです。名前空間を設定することで、リソースの管理やアクセス制御を柔軟に行うことができます。
正解についての説明：
（選択肢）
・ラベルinscope: trueを使用してノードにテイントを配置し、NoScheduleとポッド構成で一致する許容範囲を設定します
この選択肢が正解の理由は以下の通りです。
まず、Kubernetesにはノードを制御するための仕組みである"テイントとトレランス"があります。"テイント（Taint）"はノードに設定できるマーカーで、テイントが設定されたノードには指定したトレランス（tolerance）を持つポッドしかスケジュールされません。これにより、"範囲内の"ノードには"範囲内の"ポッドだけを配置するという要件を満たすことができます。
この設問の場合、"inscope: true"というラベルを使ってノードにテイントを配置し、"NoSchedule"を設定します。これにより、このラベルのテイントを許容する設定を持つポッド以外、新規のポッドがスケジュールされないように制御します。すなわち、"範囲内の"ポッドのみが"範囲内の"ノードにスケジュールされるため、コンプライアンスを満たすことが可能となります。
また、これにより予期しないポッドが"範囲内の"ノードに配置されることを防ぎ、セキュリティも確保することができます。
不正解についての説明：
選択肢：inscope: trueというラベルの付いたノードのみを使用するように、nodeSelectorフィールドをポッド構成に追加します
この選択肢が正しくない理由は以下の通りです。
nodeSelectorフィールドをポッド構成に追加すれば、"範囲内の"ノードが"範囲内の"PCI Kubernetesポッドにのみ使用されることを保証できますが、"範囲内の"ノードには"範囲内の"ポッドのみを含めるという要件を満たすことはできません。
これに対して、ノードにテイントを配置し、許容範囲を設定することで、ノードとポッドの両方で範囲制限が可能となります。
選択肢：ラベルinscope: trueを使用してノードプールを作成し、そのラベルが付いているノード上でのみポッドの実行を許可するポッドセキュリティポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
ノードプールを作成し、ポッドセキュリティポリシーを適用する方法では、特定のノードにポッドがスケジュールされることを保証することはできません。
それに対して、正解のテイントと許容範囲を使用する方法はノードの選択性を提供し、"範囲内の"ノードに対して制御を行うことができます。
選択肢：名前空間"in-scope-pci"内のスコープ内のすべてのポッドを実行します
この選択肢が正しくない理由は以下の通りです。
名前空間"in-scope-pci"内でスコープ内のすべてのポッドを実行する事は、ポッドがスコープ内のノードに限定される保証を与えません。
一方、正解ではテイントと許容範囲を使用して、スコープ内のポッドが特定のノードにしかスケジュールされない事を確認しています。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/node-taints
https://cloud.google.com/kubernetes-engine/docs/concepts/pod-security-policies
https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
</div></details>

### Q.  問題13: 未回答
Cloud External Key Managerを使用して、Google Cloudの特定のBigQueryデータを暗号化するための暗号化キーを作成する必要があります。最初にどの手順を実行する必要がありますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudのBigQueryデータの暗号化に使用するためのキーを作成するよう求められています。具体的には、Cloud External Key Managerを用いたキーの作成手順について問われています。この問題を解く際には、Google Cloudの様々なサービスとその機能、特にCloud External Key Managerの機能と使い方を理解していることが重要で、それぞれの選択肢が指示する手順が、Cloud External Key Managerを使った適切なキー作成手順と一致するかどうかを慎重に見極める必要があります。
基本的な概念や原則：
Cloud External Key Manager（Cloud EKM）：Google Cloudのサービスの一つで、顧客管理の暗号化キー（CMK）の使用を可能にします。Cloud EKMを使用すると、Google Cloudのサービスに対して外部（サードパーティ）の鍵管理システムで管理されたキーを用いた暗号化を行うことができます。
Google Cloudプロジェクト：Google Cloudのすべてのリソースを管理するための組織単位。
一意の統一リソース識別子（URI）：リソースに一意にアクセスするための識別子。暗号化キーなどのリソースを指定する際に使用します。
鍵管理パートナーシステム：Google Cloud以外の暗号化キーを管理するシステム。Cloud EKMを使用してGoogle Cloudサービスからアクセスすることができます。
Cloud Key Management Service（Cloud KMS）：Google Cloudの暗号化キー管理サービス。自身のキーリングと暗号キーを作成および管理することができますが、Cloud EKMで使用するキーはGoogle Cloudプロジェクトで作成または指定する必要があります。
正解についての説明：
（選択肢）
・1.Google Cloudプロジェクトで、一意の統一リソース識別子（URI）を持つキーを作成するか、既存のキーを使用します
2.Google Cloudプロジェクトで、サポートされている外部の鍵管理パートナーシステムへのアクセスを許可します
この選択肢が正解の理由は以下の通りです。
まず、Cloud External Key Manager（EKM）は、自身で管理する暗号化キーを使用して、Google Cloudのデータを保護するためのサービスです。このサービスを使用するためには、一意のURIを持つキーの作成が最初のステップとして必要です。このキーはGoogle Cloudプロジェクト内で管理され、BigQueryデータの暗号化に使用されます。
続いて、外部の鍵管理パートナーシステムへのアクセスを許可することで、このキーを外部の鍵管理システムで管理することができます。Google Cloudは多くの主要な鍵管理パートナーとの統合をサポートしているので、この手順によりCloud EKMを有効に活用できます。
したがって、これらの手順はBigQueryデータの暗号化キーを作成し、それをCloud External Key Managerを通じて管理するための適切な手順となります。
不正解についての説明：
選択肢：1.Cloud Key Management Service（Cloud KMS）で、一意の統一リソース識別子（URI）を持つ鍵を作成するか、既存の鍵を使用します
2.Cloud KMSで、Google Cloudプロジェクトにキーを使用するためのアクセス権を付与します
この選択肢が正しくない理由は以下の通りです。
Cloud KMSはGoogle Cloud内部のキー管理システムで、External Key Managerは外部のキーマネージメントシステムとの連携を実現します。
したがって、Cloud KMSで鍵を作成・管理するのではなく、外部のキーマネージメントシステムで行う必要があります。
選択肢：1.サポートされている外部鍵管理パートナーシステムにおいて、一意の統一リソース識別子（URI）を持つ既存の鍵を作成または使用します
2.外部鍵管理パートナーシステムで、この鍵にGoogle Cloudプロジェクトを使用するためのアクセス権を付与します
この選択肢が正しくない理由は以下の通りです。
Google Cloudにおいて必要な設定を行い、その上でキーを作成するため、最初にGoogle Cloudプロジェクトで一意のURIを持つキーを作成または使用し、次にサポートされている外部の鍵管理パートナーシステムへのアクセスを許可する必要があります。
また、不正解の選択肢は最初から外部システムでの操作を行ってしまっています。
選択肢：1.Cloud Key Management Service（Cloud KMS）で、一意の統一リソース識別子（URI）を持つ外部鍵を作成します
2.Cloud KMSで、Google Cloudプロジェクトにキーを使用するためのアクセス権を付与します
この選択肢が正しくない理由は以下の通りです。
Cloud External Key Managerは外部の鍵管理システムで暗号化キーを管理するため、Cloud Key Management Serviceでキーを作成する必要はありません。
さらに、Google Cloudプロジェクトでキーへのアクセスを許可することが必要であり、Cloud KMSで設定するのは不適切です。
参考リンク：
https://cloud.google.com/bigquery/docs/encryption-customer-managed-keys
https://cloud.google.com/ekm/docs
https://cloud.google.com/kms/docs/external-key-managers
</div></details>

### Q.  問題14: 未回答
あなたの会社は、顧客の年齢層に応じて、クレジットスコアを向上させるためにどのような商品を構築できるかを判断したいと考えています。そのためには、会社のバンキングアプリのユーザー情報と、第三者から受け取った顧客のクレジットスコアデータを結合する必要があります。この生データを使用すればこのタスクを完了できますが、機密データを暴露することになり、新たなシステムに伝播する可能性があります。
このリスクには、データベース全体の参照整合性を維持しながら、Cloud Data Loss Preventionを使用して非識別化とトークン化で対処する必要があります。
これらの要件を満たすには、どの暗号トークン形式を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題は、データの暗号化方式を選択することが求められています。必要な要素は、参照整合性を維持しつつ、データを非識別化・トークン化することです。そのため選択肢を考える際には、データ非識別化と参照整合性維持の両方を達成できる暗号化形式を選ぶべきです。また、このケースでは生データの情報を保護するために、暗号トークン形式に特定の要件が求められていることに注意深く対応する必要があります。
基本的な概念や原則：
Cloud Data Loss Prevention（DLP）：データ保護のためのGoogle Cloudのサービスです。機密データの発見、分類、保護を自動化します。
非識別化：個人を特定できる情報を削除または変換することです。プライバシーとセキュリティを向上させるために使用されます。
トークン化：機密データをデータベースやファイル内の非機密要素に置き換えるプロセスです。オリジナルデータは別の場所に保存され、元に戻すためのトークンが提供されます。
決定論的暗号化：同じ入力値に対して常に同じ暗号文を生成する暗号化手法です。文脈やパターン分析で情報を推測できるリスクがありますが、参照整合性を保つ上で有用です。
安全なキーベースのハッシュ：一方向性のあるハッシュアルゴリズムで、元のデータを特定できない形でデータを変換します。しかし、参照整合性を維持することはできません。
フォーマット保持暗号化：データを暗号化しながらも、元のデータ形式を保持する暗号化手法です。しかし、参照整合性を維持する機能はありません。
暗号ハッシュ：一方向性のあるハッシュアルゴリズムで、元のデータを特定できない形でデータを変換します。参照整合性を維持することはできません。
正解についての説明：
（選択肢）
・決定論的暗号化
この選択肢が正解の理由は以下の通りです。
まず、決定論的暗号化は一貫性を保証する暗号化方式です。同じ入力値に対しては常に同じ暗号文が生成されます。これは、参照整合性の維持に重要です。参照整合性とは、データベース内の様々な部分で、同じ値が正確かつ一貫して引用されることを保証する仕組みです。データベース全体で一貫性を保つためには、同じ値が同じ暗号文に変換される暗号方式が必要となるため、決定論的暗号化が適しています。
また、Cloud Data Loss Preventionは、データの非識別化とトークン化を行うためのサービスで、決定論的暗号化をサポートしています。これにより、個人を特定できる情報を保護しつつ、データの分析や処理を可能にします。
したがって、機密データが新たなシステムに伝播するリスクを軽減するためには、決定論的暗号化が適しています。
不正解についての説明：
選択肢：安全なキーベースのハッシュ
この選択肢が正しくない理由は以下の通りです。
安全なキー基のハッシュを使用した場合、元のデータを復元することができません。ですが、問題要件は参照整合性を維持しながら非識別化を行うことを求めています。これは、ハッシュ関数ではなく、元のデータを復元可能な決定論的暗号化の特性が必要とされているためです。
選択肢：フォーマット保持暗号化
この選択肢が正しくない理由は以下の通りです。
フォーマット保持暗号化は元のデータ型や長さを保持しますが、それ自体は参照整合性を確保できません。決定論的暗号化を用いると、同じ平文に対しては常に同じ暗号文を生成します。これがデータベース全体の参照整合性を維持できます。
選択肢：暗号ハッシュ
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュは一方向の関数であり、変換後に元のデータに戻すことができません。このため、データ全体の参照整合性を維持するという要件を満たすことができません。
それに対して、決定論的暗号化は同じ入力から同じ暗号文を生成し、暗号文から元のデータを復元できるため、参照整合性を維持することが可能です。
参考リンク：
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/dlp/docs/deidentify-sensitive-data
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題15: 未回答
組織のGoogle CloudインスタンスのPCIコンプライアンスを評価したいと考えています。Google固有のコントロールを特定する必要があります。
情報を見つけるには、どのドキュメントを確認する必要がありますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudインスタンスのPCIコンプライアンスに焦点を当てています。組織がGoogle Cloud内で適用するべき具体的なPCIコンプライアンスに関連するGoogle固有のコントロールを特定したいと考えています。ここで重要なのは、Google Cloud環境における責任の分担を理解することで、選択肢からはGoogle Cloud固有のガイダンスとセキュリティ関連の情報を提供するものを選ぶことが求められています。また、Google Cloud特有の情報提供源を探すことが重要で、一般的なPCIコンプライアンスガイドよりもGoogle Cloudに特化したリソースを重視すべきです。
基本的な概念や原則：
Google Cloud：顧客責任マトリックス：Google Cloudにおけるセキュリティコントロールと関連する責任の分配を明示したドキュメントです。事業者とGoogleがそれぞれ持つ責任を理解するために重要です。
PCIコンプライアンス：クレジットカード情報の安全性を保証するための国際基準です。PCI DSS（Payment Card Industry Data Security Standard）という規格に準拠していることが求められます。
PCI DSS：クレジットカード情報を取り扱う企業が遵守すべき国際的なセキュリティ基準です。盗難や漏洩を防ぐための技術的、運用的要件を定めています。
PCI SSCクラウドコンピューティングガイドライン：PCI SSS（Payment Card Industry Security Standards Council）が提供する、クラウド環境でのPCI DSS準拠についてのガイドラインです。
Compute Engineの製品ドキュメント：Google Compute Engineに関する公式のドキュメンテーションです。プロダクトの使用方法や仕様について詳細な情報を提供しています。
正解についての説明：
（選択肢）
・Google Cloud：顧客責任マトリックス
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの顧客責任マトリックスは、Google Cloudの製品とサービスにおけるセキュリティとコンプライアンスの責任を明確に示すための公式ドキュメントです。これには、Google Cloudのインフラストラクチャ、製品、サービスに関するコントロールと、顧客が実装すべきコントロールの詳細な情報が含まれています。
したがって、PCIコンプライアンスを評価したい場合、このマトリックスを参照すれば、Googleが担当する部分と顧客が負うべき責任を理解することができます。
さらに、Google Cloudの顧客責任マトリックスは、特定の規制基準、たとえばPCI DSSなどに対してどのようなコントロールが必要かという詳細なガイダンスも提供しています。そのため、組織がGoogle CloudインスタンスのPCIコンプライアンスを評価するためには、このマトリックスを確認することが最適と言えます。
不正解についての説明：
選択肢：PCI DSSの要件とセキュリティ評価手順
この選択肢が正しくない理由は以下の通りです。
PCI DSSの要件とセキュリティ評価手順は、基本的なPCIコンプライアンスに必要なセキュリティ要件と手順を指摘しますが、これはGoogle Cloud特有のコントロールを特定する目的には合致しません。
対照的に、Google Cloud：顧客責任マトリックスはGoogle Cloudの標準と共有責任モデルを明示的に解説します。
選択肢：PCI SSCクラウドコンピューティングガイドライン
この選択肢が正しくない理由は以下の通りです。
PCI SSCクラウドコンピューティングガイドラインは一般的なクラウドサービスのコンプライアンスガイドラインを提供しますが、Google Cloud特有のコントロールについては明確に示されていません。
これに対して、Google Cloud：顧客責任マトリックスはGoogle Cloud特有のセキュリティとコンプライアンスのロールと責任を明確に示しています。
選択肢：Compute Engineの製品ドキュメント
この選択肢が正しくない理由は以下の通りです。
Compute Engineの製品ドキュメントでは特定の製品に関する説明や設定方法が記載されていますが、Google固有のPCIコンプライアンスに関する情報は含まれていません。
それに対して、"Google Cloud：顧客責任マトリックス"では、クラウドサービスのコンプライアンスを特定できるため正解です。
参考リンク：
https://cloud.google.com/docs/security/compliance/customer-responsibility
https://cloud.google.com/security/compliance/pci-dss
https://cloud.google.com/compute/docs
</div></details>

### Q.  問題16: 未回答
あなたは、Google Cloudで一般データ保護規則（GDPR）に準拠したいと考えています。そのために、EUにおけるデータレジデンシーと運用主権を導入する必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud上で一般データ保護規則（GDPR）に準拠し、データのレジデンシーと運用主権をEU内で保持する方法を問われています。問題文からは、データの物理的な配置の制限とGoogle Cloudのサービスによるデータへのアクセス制限が必要と読み取れます。ここで注意するのは、データ保護規則への準拠には、単にデータの所在地を管理するだけでなく、データへのアクセス管理も含まれるということです。これを念頭に置きながら、各選択肢を慎重に評価する必要があります。
基本的な概念や原則：
GDPR（General Data Protection Regulation）：ヨーロッパ連合におけるデータ保護とプライバシーに関する規則です。個人データの処理と移動を厳格に制御しています。
データレジデンシー：データが物理的に保存される位置（つまり、特定の国や地域）を指します。多くの法域では、特定の種類のデータ（特に個人データ）はそのリージョン内でのみ処理または保存する必要があります。
運用主権：システムの運用に対する制御や管理権を持つことを指します。通常、システムの所有者や管理者が運用主権を持ちます。
Organization Policy Service：Google Cloudの組織全体にポリシー制限を設定するためのサービスです。
Resource Locations Constraint：Organization Policy Serviceの機能で、リソースの物理的な場所を制限できます。
Key Access Justifications：Google Cloudの機能で、Google社員のアクセスを事前に定義された属性（国籍、ロケーション等）に基づいて制限します。
Cloud IDS/IDフェデレーション/VPCフローログ：これらのサービスや機能は、ネットワークのログ、監視、またはアクセス制御などの目的で使用されますが、データレジデンシーや運用主権を保証する具体的な機能はありません。
正解についての説明：
（選択肢）
・Organization Policy Serviceの "resource locations constraint"を使用して、新しいリソースの物理的な場所を制限します
・Key Access Justificationsを使用して、国籍や地理的ロケーションなど、事前に定義された属性に基づいてGoogle Cloudのサービスのアクセスを制限します
この選択肢が正解の理由は以下の通りです。
まず、一つ目の選択肢のOrganization Policy Serviceの "resource locations constraint"を使用することは、データの物理的な場所をEU内に制限するのに適しています。これはGDPRにおけるデータレジデンシー、つまりデータが特定の地理的な領域内に保管されていることを保証するための要件を満たします。
次に、二つ目の選択肢であるKey Access Justificationsを使用することで、Google Cloudのサービスのアクセスを事前に定義された属性、例えば国籍や地理的ロケーションなどに基づいて制限することができます。これはGDPRにおける運用主権、つまり誰がデータにアクセスできるかを制御することを可能にします。
これらの選択肢は、Google CloudでGDPRに準拠するための主要な要件を満たすことができます。
したがって、正答となります。
不正解についての説明：
選択肢：Cloud IDSを使用して、EU内のサーバー間と各階層間のトラフィックを可視化し、VPC内およびVPC間の通信を監視します
この選択肢が正しくない理由は以下の通りです。
Cloud IDSはトラフィックを可視化し、監視するためのツールですが、それ自体ではGDPRの要件であるデータレジデンシーと運用主権を確保するための機能を提供していません。
したがって、この問題の要件を直接満たす選択肢ではありません。
選択肢：IDフェデレーションを使用して、EU域外からのGoogle Cloudリソースへのアクセスを制限します
この選択肢が正しくない理由は以下の通りです。
IDフェデレーションを使用すると認証と認可を管理することができますが、それ自体はデータレジデンシーや運用主権を保証するものではありません。
また、GDPRの準拠のためには、物理的なデータの場所を制限するとともに、不適切なアクセスを制限する措置が必要で、IDフェデレーションだけでは足りません。
選択肢：VPCフローログを使用して、EU内のVPC内およびVPC間のトラフィックを監視します
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークのトラフィックパターンを監視するためのツールで、データの物理的な場所を制限したり、Google Cloudのサービスのアクセスを制限したりする機能はありません。これらの要件を満たすためには、Organization Policy ServiceやKey Access Justificationsが必要です。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-resource-locations
https://cloud.google.com/kms/docs/key-access-justifications
https://cloud.google.com/compliance/gdpr
</div></details>

### Q.  問題17: 未回答
ある組織は、従業員の異常値を特定し、収入格差を是正するために、賞与報酬の経年変化を追跡したいと考えています。このタスクは、個人の重要な報酬データを公開することなく実行されなければならず、異常値を特定するために元に戻すことができなければなりません。
どのCloud Data Loss Prevention APIの機能を使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社が従業員の賞与報酬のパターンを追跡しながら、個人情報のアウトプットを避けるためにどのCloud Data Loss Prevention APIの機能を使うべきかを問います。選択肢に挙げられているAPIの各機能は異なる種類の保護を提供しますが、要求される特性である"元に戻すことができる"点に焦点を当てる必要があります。選択肢の中でどの機能がこの条件を満たすのか、それぞれの機能がどのようにデータを処理するのかを理解することが重要です。
基本的な概念や原則：
フォーマット保持暗号化：Cloud DLPの機能の一つで、データを元に戻すことが可能な形式で保護します。元のデータと同じ形式を維持するため、一部のデータ分析操作を暗号化されたデータに対して実行することが可能です。
暗号ハッシュ：データを固定長の一意な文字列に変換しますが、元に戻すことが不可能な形式で保護します。
秘匿化：一部のデータを隠し、データを元戻しできないようにします。データの一部を保持しながら、情報の機密性を保護します。
一般化：個々のデータポイントをより大きなカテゴリーに置き換えることで、データの詳細度を低下させます。これによりデータの特定性が薄れ、プライバシー保護に貢献します。
Cloud Data Loss Prevention API：機密データの検出、クラス分類、保護（非可逆的および可逆的脱識別化）を行うためのサービスです。
正解についての説明：
（選択肢）
・フォーマット保持暗号化
この選択肢が正解の理由は以下の通りです。
フォーマット保持暗号化（FPE）は、Cloud Data Loss Prevention（DLP）APIの一部です。ここでは機密データをより無害な形式に変換しながら、データの元の詳細と有用性を維持します。FPEはテキストデータを他のテキストデータに変換しますが、変換後の値は元の値と同じフォーマットを保持します。
したがって、データの構造と有用性を維持したままで、機密データを安全に保護することができます。このため、フォーマット保持暗号化は、個々の重要な報酬データを保護しつつ、賞与報酬の経年変化を追跡する組織にとって最適な方法です。
さらに、FPEの結果は逆行できるため、必要に応じて元のデータに戻すことが可能です。これは異常値を特定する際に非常に役立ちます。
不正解についての説明：
選択肢：暗号ハッシュ
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュ機能を使用した場合、元のデータへ戻すことができません。これは、組織が異常値を特定するために必要な期待の動作とは異なります。
それに対して、フォーマット保持暗号化はデータを暗号化しつつも、元の形式を保持することができ、必要に応じて復号化することが可能です。
選択肢：秘匿化
この選択肢が正しくない理由は以下の通りです。
秘匿化はデータを隠蔽する一方で、元のデータに戻す機能を持っていません。問題文では異常値を特定するために元のデータに戻すことができなければならないとあります。
それに対して、フォーマット保持暗号化は元のデータ形式を保持しつつ暗号化し、復元が可能な形式に変換します。
選択肢：一般化
この選択肢が正しくない理由は以下の通りです。
一般化によるデータ変換は一方向であり、元の情報に戻すことができないため、異常値を特定する目的には適合しません。
一方、フォーマット保持暗号化は元のデータ形式を保ったままの暗号化を提供し、必要に応じて復元することが可能なため、情報の秘匿と利用の両立を達成できます。
参考リンク：
https://cloud.google.com/dlp/docs/concepts-format-preserving-encryption
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/solutions/masking-sensitive-data-using-cloud-dlp
</div></details>

### Q.  問題18: 未回答
Compute Engineインスタンス上で実行されているアプリケーションが、Cloud Storageバケットからデータを読み取る必要があります。あなたのチームは、Cloud Storageバケットがグローバルに読み取り可能であることを許可しておらず、最小特権の原則を確保したいと考えています。
あなたのチームの要件を満たすオプションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute EngineインスタンスがCloud Storageバケットからデータを読み取る際に最小特権の原則を保つ方法が求められています。問題文から、このバケットがグローバルに読み取り可能であることは許可されていないことがわかります。そのため、データアクセスを限定し、セキュリティを確保しながらどのようにインスタンスでバケットのデータ読み取りを行うかがポイントとなります。また、最小特権の原則の規則を理解していることも非常に重要で、不要なアクセス権を減らし、制限を強化する適切なソリューションを見つけることが求められます。
基本的な概念や原則：
Compute Engine：Google Cloudの仮想マシン（VM）を提供するインフラストラクチャas aサービス（IaaS）です。仮想マシンが実行される場所（データセンター）を選択でき、OSやその他のソフトウェアをインストール、実行できます。
Cloud Storage：Google Cloudのスケーラブルで耐久性の高いオブジェクトストレージです。任意の種類の非構造化データ（写真、ビデオ、バックアップ、ログファイルなど）を保存、取得できます。
サービスアカウント：アプリケーションや仮想マシンなど、Google Cloudのリソースに対するアクセスを制御するためのアカウントです。各サービスアカウントには一意の電子メールアドレスが割り当てられています。
読み取り専用アクセス：特定のリソースへの読み取りのみ可能なアクセス権限です。データの変更、削除、追加などは不可能です。
最小特権の原則：セキュリティの基本原則で、個々のユーザーやプログラムに、そのタスクを遂行するために必要最小限の権限とアクセスのみを付与する常識です。
ACL（Access Control Lists）: リソースへのアクセスを制御するための一連の許可ルールです。特定のユーザーやサービスアカウントがデータに対して何をして良いかを定義します。ネットワークやファイルシステムなどで広く使用されています。
Cloud KMS：Googleのキーマネージメントサービスで、暗号キーを作成、管理します。このキーは、Cloud StorageやBigQueryなど他のGoogle Cloudサービスでデータを暗号化するために使用できます。
正解についての説明：
（選択肢）
・Cloud Storageバケットへの読み取り専用アクセス権を持つサービスアカウントを使用して、インスタンスメタデータから認証情報を取得します
この選択肢が正解の理由は以下の通りです。
まず、サービスアカウントはGoogle Cloud上でアプリケーションに対するセキュアな識別と認証を提供する重要な仕組みであり、特定のアクセス権を持つことができます。この場合、読み取り専用アクセス権を持つサービスアカウントを使用すれば、最小特権の原則を満たしつつ、アプリケーションがCloud Storageバケットからデータを適切に読み取ることが可能となります。
次に、インスタンスメタデータから認証情報を取得することにより、Compute Engineインスタンスがサービスアカウントに自動的に認証されるように設定することが可能です。そのため、これはセキュリティの観点からも望ましい方法であり、設定管理の複雑さも少なくなります。
さらに、Cloud Storageバケットの公開が認められていない場合でも、正認のサービスアカウントを用いることで安全にアクセスが制御できるため、要件を満たしていると言えます。
不正解についての説明：
選択肢：Compute EngineインスタンスのIPアドレスからの読み取り専用アクセスを許可し、アプリケーションが認証情報なしでバケットから読み取ることを許可するCloud Storage ACLを作成します
この選択肢が正しくない理由は以下の通りです。
最小特権の原則を確保したい場合、IPアドレスからの読み取りアクセスの許可では原則が満たされません。IPアドレスは個別のアプリケーションやユーザーにリンクされていないため、サービスアカウントを使用して特定の資格情報を持つアクセスを管理するのは効果的でありません。
選択肢：Cloud Storageバケットに読み取り専用でアクセスできるサービスアカウントを使用し、Compute Engineインスタンス上のアプリケーションのconfigにサービスアカウントの認証情報を保存します
この選択肢が正しくない理由は以下の通りです。
認証情報をアプリケーションのconfigに直接保存することは、最小特権の原則に反します。
また、この方法は認証情報が漏洩するリスクがあります。正解の選択肢と比べると、インスタンスメタデータから認証情報を取得する方がセキュリティが高いです。
選択肢：Cloud KMSを使ってCloud Storageバケット内のデータを暗号化し、アプリケーションがKMSキーでデータを復号化できるようにします
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Service（KMS）はデータの暗号化と復号化に使用されますが、アクセス制御を実装するためのものではありません。そのため、この方法ではアプリケーションがCloud Storageバケットのデータを読み取るための最小特権の原則を守ることができません。
参考リンク：
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/storage/docs/access-control/iam-permissions
https://cloud.google.com/compute/docs/storing-retrieving-metadata
</div></details>

### Q.  問題19: 未回答
セキュリティ脆弱性評価を完了した後、クラウド管理者がGoogle Cloud CLIセッションを何日も開いたままにしていることを知りました。これらのセッションを最小限の期間に設定することで、これらのオープンセッションを悪用する攻撃者のリスクを減らす必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのセキュリティ設定に関連した問題が提示されています。特に、クラウド管理者が開いたままにしているGoogle Cloud CLIセッションの厳密な制御に関する解決策について求められています。そのため、選択肢を評価する際には、Google Cloudの認証とセッションの管理に関連する各設定やポリシーを理解した上で、具体的な時間制限の設定により開かれたセッションを最小限に維持する解決策を選択することが重要です。
基本的な概念や原則：
Google Cloud Session Control：Google Cloudのユーザーおよびサービスアカウントのセッションの有効期間を制御する機能です。再認証頻度の設定により、セキュリティリスクを管理します。
再認証頻度：ユーザーが一度認証した後、引き続きセッションが有効であることを証明するために再度認証する必要がある頻度のことです。この頻度を高く設定することで、無許可のアクセスリスクを下げることができます。
組織ポリシー：Google Cloudでリソースの使用を制御するためのルールです。特定の制約を設定して、リソースの使用方法を規定します。
constraints/iam.allowServiceAccountCredentialLifetimeExtension：この組織ポリシー制約を使用して、サービスアカウントの資格情報の有効期限を超えて延長可能かどうかを制御します。
constraints/iam.serviceAccountKeyExpiryHours：この組織ポリシー制約を使用して、サービスアカウントキーの有効期限を制御します。
正解についての説明：
（選択肢）
・Google Cloud Session Controlの再認証頻度を1時間に設定します
この選択肢が正解の理由は以下の通りです。
Google Cloud Session Controlは、ユーザーセッションの再認証の頻度を設定するための機能です。これを使用して再認証頻度を1時間に設定することで、CLIセッションが何日も開いたままになることを防げます。再認証が要求されると、ユーザーは再度クレデンシャルを提供し、その認証情報が現在も有効であることを確認する必要があります。これにより、攻撃者が不適切にオープンセッションを利用するリスクを軽減できます。なぜなら、攻撃者がセッションを乗っ取りたいと思っても、1時間ごとに再認証が求められるため、そのセッションを長時間保持することは難しくなるからです。
したがって、Google Cloud Session Controlの再認証頻度を1時間に設定することは、セキュリティ上の理由からオープンセッションの期間を最小限に抑えるのに役立ちます。
不正解についての説明：
選択肢：Google Cloud Session Controlのセッション時間を1時間に設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Session Controlでは"セッション時間"を設定することはできません。正しくは"再認証頻度"を設定します。再認証頻度は、指定した時間ごとにユーザーに再ログインを求める機能で、これによって無期限に開かれたセッションを防ぎます。
選択肢：組織ポリシー制約constraints/iam.allowServiceAccountCredentialLifetimeExtensionを1時間に設定します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約constraints/iam.allowServiceAccountCredentialLifetimeExtensionは、サービスアカウントの資格情報の有効期間を制御します。しかしながら、CLIセッションの有効期間や再認証頻度の設定はGoogle Cloud Session Controlで行います。この選択肢はCLIセッションの管理とは無関係ため不正解です。
選択肢：組織ポリシー制約constraints/iam.serviceAccountKeyExpiryHoursを1時間に設定し、inheritFromParentをfalseに設定します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約constraints/iam.serviceAccountKeyExpiryHoursはサービスアカウントキーの有効期限を制御しますが、これはGoogle Cloud CLIセッションの持続時間を管理するものではありません。
正解の選択肢は、Google Cloud Session Controlの再認証頻度を1時間に設定することで、CLIセッションの持続期間を最小限に抑えることができます。
参考リンク：
https://cloud.google.com/iam/docs/configuring-reauthentication
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/sdk/gcloud/reference/auth/login
</div></details>

### Q.  問題20: 未回答
あなたの会社のメッセージングアプリは、FIPS 140-2に準拠するために、Google Cloudのコンピュートおよびネットワークサービスを使用することを決定しました。メッセージングアプリのアーキテクチャには、Compute Engineインスタンスのクラスターを制御するManaged Instance Group（MIG）が含まれています。インスタンスは、データキャッシングにローカルSSDを使用し、インスタンス間の通信にUDPを使用しています。アプリ開発チームは、標準に準拠するために必要な変更を行うことを望んでいます。
要件を満たすために、どのオプションを推奨しますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、FIPS 140-2への準拠という制約の下でGoogle Cloudのコンピュートおよびネットワークサービスを使用したメッセージングアプリケーションを設計する問題に取り組んでいます。要件には、キャッシュストレージとインスタンス間通信の暗号化も含まれています。したがって問題を解くためには、FIPS 140-2に準拠した暗号化技術やプロトコルについて理解する必要があります。また、UDPやローカルSSDの使用についても、これらの技術が準拠を満たすためにどのように利用され、あるいは変更されるべきかを評価することが求められます。このような観点から選択肢を読み解くことで、最も適切な解決策を選ぶことができます。
基本的な概念や原則：
FIPS 140-2：アメリカ国立標準技術研究所（NIST）が定めるセキュリティ要件です。暗号化モジュールがFIPS 140-2に準拠しているかを評価する基準として使用されます。
Compute Engine：Google CloudのインフラストラクチャAs-a-Service（IaaS）です。仮想マシンをデプロイと管理するためのサービスです。
Managed Instance Group（MIG）：Compute Engineインスタンスのグループを管理するための仕組みです。自動スケーリング、ローリングアップデート、自動ヒーリングなどをサポートしています。
BoringCrypto：Googleが開発したFIPS 140-2に準拠した暗号化ライブラリです。Googleのプロダクトで使用される暗号化演算の信頼性を向上するために開発されました。
ローカルSSD：Compute Engineインスタンスに直接接続された、高速で一時的なブロックストレージです。主に高いIOPS（Internet Operations Per Second）と低い遅延を必要とするアプリケーションに使用されます。
UDP通信：インターネット通信プロトコルの一つです。TCPとは異なり、通信の確認を行わないため、速度は速いものの信頼性が低いとされています。
ディスク暗号化：データを盗難や漏洩から保護するために、データを暗号化することです。顧客管理キーやGoogle-managed Keyを使用してディスク暗号化を行うことができます。
正解についての説明：
（選択肢）
・BoringCryptoモジュールを使用して、すべてのキャッシュストレージとVM間通信を暗号化します
この選択肢が正解の理由は以下の通りです。
まず、BoringCryptoモジュールはGoogleが提供するFIPS 140-2に準拠した暗号化モジュールで、必要なセキュリティ標準を満たす能力があります。すべてのキャッシュストレージとVM間通信を暗号化することは、FIPS 140-2の要求を満たす最善の手段となります。
また、BoringCryptoモジュールはCompute Engine上で動作し、ローカルSSDのデータキャッシングやUDPを使用したインスタンス間の通信など、既存のアーキテクチャの要素に影響を与えない暗号化ソリューションを提供します。これはアプリ開発者が必要としている準拠のための変更を最小限に抑えられる点で非常に重要です。
したがって、この選択肢が最適な解決策となります。
不正解についての説明：
選択肢：MIGが使用するインスタンステンプレートのディスク暗号化を顧客管理キーに設定し、インスタンス間のすべてのデータ転送にBoringSSLを使用します
この選択肢が正しくない理由は以下の通りです。
まず、ディスク暗号化を顧客管理キーに設定してもキャッシュストレージ自体の暗号化は行われないため、FIPS 140-2の要件を満たしません。
また、BoringSSLはFIPS 140-2準拠ではないため、正しくないです。正解のBoringCryptoはFIPS 140-2認定を持っています。
選択肢：アプリのインスタンス間通信をUDPからTCPに変更し、クライアントのTLS接続でBoringSSLを有効にします
この選択肢が正しくない理由は以下の通りです。
UDPからTCPへの変更とクライアントのTLS接続でのBoringSSLの有効化はデータの送受信を暗号化するために役立ちますが、これはデータのインスタンス間通信のみに影響し、データキャッシングに使用されるローカルSSDの暗号化には関わりません。
一方、BoringCryptoモジュールを使用すれば、キャッシュストレージとVM間通信の両方を暗号化するため、FIPS 140-2の要件をより全面的に満たすことができます。
選択肢：MIGが使用するインスタンステンプレートのディスク暗号化をGoogle-managed Keyに設定し、すべてのインスタンス間通信でBoringSSLライブラリを使用します
この選択肢が正しくない理由は以下の通りです。
まず、Google-managed Keyではなく、BoringCryptoがFIPS 140-2に準拠しています。
さらに、BoringSSLはFIPS 140-2に準拠していないため、これを使用することはFIPS要件を満たすことができません。この要件を満たすためには、FIPS 140-2に準拠した暗号化モジュールを使用するべきです。
参考リンク：
https://cloud.google.com/security/fips
https://cloud.google.com/compute/docs/disks#encryption
https://cloud.google.com/compute/docs/instances/encrypt-instance-communication
</div></details>

### Q.  問題21: 未回答
あなたは、規制の厳しい業界のミッションクリティカルなワークロードを管理しています。このワークロードは、エンドポイントコンピュータからCloud Storageにアップロードされた後の機密データの分析と処理にCompute Engine VMを使用しています。コンプライアンスチームは、このワークロードが機密データのデータ保護要件を満たしていないことを検出しました。データ保護要件は以下の通りです：
- データ暗号化キー（DEK）をGoogle Cloud境界外で管理します。
- サードパーティプロバイダを通じて暗号化キーを完全に管理します。
- 機密データをCloud Storageにアップロードする前に暗号化します。
- Compute Engine VMでの処理中に機密データを復号化します。
- Compute EngineVMで使用中のメモリ内の機密データを暗号化します。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudを使用して、機密データの保護を強く規制された業界で実施するための最適なソリューションを特定することが求められています。問題文から、データ暗号化キーはGoogle Cloud外部で管理する必要があり、データはCloud Storageにアップロードする前に暗号化し、Compute Engine VMで処理中はメモリ内のデータは暗号化されたままであることが要求されています。これを達成するための最適なサービスや構成を選択するためには、Google Cloudの暗号化周りの機能やサービスを理解していることが重要です。また、選択肢の中にはほぼ同じ動作をするものがありますが、細かい要件に注意してそれぞれの違いを理解することが必要です。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、大量の不構造化データを保存・取得することが可能です。データは自動的に暗号化されますが、より高いセキュリティ要件を満たすためのキー管理オプションも提供されています。
Cloud External Key Manager：Google Cloudのサービスで、Google Cloud外部のキーマネージメントシステムを使ってGoogle Cloudリソースの暗号キーを管理します。これにより、ユーザーはキーの完全なコントロールを保持しながら、Google Cloudの強力なデータ保護機能を利用できます。
Compute Engine VM：Google Cloudの仮想マシンサービスです。高度なカスタマイズが可能であり、各種ワークロードに対応します。
Confidential VM：Google Cloudのサービスで、メモリ内データの暗号化を提供します。これにより、稼働中のVMで機密データが保護されます。
Customer Managed Encryption Keys：ユーザーがGoogle Cloudで暗号化キーを生成、管理する方法です。しかし、完全なキー管理をサードパーティに委託する要件を満たすには不十分です。
VPC Service Controls：Google Cloudのサービス、データへのアクセスを制御するセキュリティ機能です。しかし、これによって暗号化キーの管理やデータの暗号化・復号化は実現できません。
正解についての説明：
（選択肢）
・機密データがCloud Storageにアップロードされる前に暗号化し、機密データがVMにダウンロードされた後に復号化するようにCloud External Key Managerを構成します
・機密データにアクセスするために、Compute EngineVMをConfidential VMに移行します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのExternal Key Managerは、Google Cloudの外部にある鍵管理システムから暗号化キーを使用することを可能にします。これにより、データ暗号化キーの管理をGoogle Cloudの外で行うという要件を満たすことができます。
さらに、クライアント側の暗号化を通じて、データがCloud Storageにアップロードされる前に暗号化され、VMでダウンロードされた後に復号化されるように設定できます。これにより、二つめの要件であるサードパーティプロバイダを通じて暗号化キーを完全に管理することも可能になります。またGoogle CloudのExternal Key Managerを使えば、クライアント側で暗号化されたデータをGoogle Cloud上で復号化して処理するという機能もあります。これにより、四つ目の要件であるCompute Engine VMでの処理中に機密データを復号化するという要件も満たすことができます。
次に、Google CloudのConfidential VMsは、メモリ暗号化技術を利用してメモリ内のデータを暗号化します。これにより、Compute EngineVMで使用中のメモリ内の機密データの暗号化という要件を満たすことができます。Confidential VMsは、データを保護しながら、パフォーマンスを犠牲にすることなくワークロードを実行することができるため、規制の厳しい業界のミッションクリティカルなワークロードに対応するには最適な選択と言えます。
不正解についての説明：
選択肢：Customer Managed Encryption Keysを設定して、機密データをCloud Storageにアップロードする前に暗号化し、機密データをVMにダウンロードした後に復号化します
この選択肢が正しくない理由は以下の通りです。
Customer Managed Encryption KeysはGoogle Cloud内で管理されるため、データ暗号化キー（DEK）をGoogle Cloud境界外で管理するというデータ保護要件を満たしません。
したがって、サードパーティプロバイダを通じて暗号化キーを完全に管理する、という要件も満たせません。
これに対し、Cloud External Key Managerを使用すれば、Google Cloud境界外で暗号化キーの管理が可能となります。
選択肢：機密データにアクセスするためのConfidential VMを作成します
この選択肢が正しくない理由は以下の通りです。
単にConfidential VMを作成するだけでは十分な保護は実現できません。Cloud External Key Managerを用いてDEKをGoogle Cloud外で管理し、それを用いてデータを暗号化、復号化する処理が必要となります。
選択肢：既存のCompute Engine VMとCloud StorageバケットにまたがるVPC Service Controlsサービス境界を作成します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsは、データの流出を防ぐためにGoogle Cloudサービスとのデータ交換を制御するのに有効ですが、その機能自体はデータ暗号化やキー管理に関連しません。
したがって、機密データの保護要件を満たすための適切な解決策とは言えません。
参考リンク：
https://cloud.google.com/security-key-management/external-key-manager
https://cloud.google.com/compute/confidential-vm/docs
https://cloud.google.com/storage/docs/encryption/customer-managed-keys
</div></details>

### Q.  問題22: 未回答
オンプレミスのデータウェアハウスをBigQuery、Cloud SQL、Cloud Storageに移行しようとしています。データウェアハウスのセキュリティサービスを構成する必要があります。会社のコンプライアンスポリシーにより、データウェアハウスは以下の要件を満たす必要があります：
- 暗号鍵の完全なライフサイクル管理により、静止状態のデータを保護します。
- データ管理とは別の鍵管理プロバイダーを導入します。
- すべての暗号化キー要求を可視化します。
データウェアハウスの実装にはどのようなサービスを含めるべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のコンプライアンスポリシーと互換性のある、適切なデータウェアハウスのセキュリティ策を選択することが求められています。具体的な要件は暗号鍵のライフサイクル管理、別の鍵管理プロバイダーの導入、そしてすべての暗号化キー要求の可視化です。これらを満たすための提供サービスの特性を理解し、選択肢から正しい組み合わせを選ぶことが必要です。
基本的な概念や原則：
Key Access Justifications：Googleが顧客のデータをアクセスした理由を説明するための機能です。すべての暗号化キー要求を可視化し、より詳細なデータアクセス制御を可能にします。
Cloud External Key Manager（EKM）：Google Cloud外部で暗号化キーを管理するサービスです。データ管理と鍵管理を分離し、静止状態のデータの保護を強化します。
顧客管理の暗号化キー（CMEK）：Google Cloud上で顧客が自身で暗号キーを作成し管理する機能です。暗号キーのライフサイクルを顧客がコントロールします。
顧客指定の暗号化キー（CSEK）：Google Cloudのリソースを暗号化する際に顧客が指定した暗号化キーを使用する機能です。暗号キーの管理を顧客が担当します。
Access Transparency and Approval：Googleのエンジニアやサポートスタッフが顧客のデータにアクセスする際の透明性を提供し、必要に応じてそのアクセスを承認または拒否することが可能にする機能です。
正解についての説明：
（選択肢）
・Key Access Justifications
・Cloud External Key Manager
この選択肢が正解の理由は以下の通りです。
まず、"Key Access Justifications"は、暗号化キーのアクセス要求の可視化に重要なロールを果たします。この機能は、Google Cloudにおけるキーの使用要求を明確に表示し、それが許可される理由や許可を求める要求元を識別することを可能にします。これにより、暗号化キー使用の監視と管理が可能となり、すべての暗号化キー要求の可視化という要件を満たします。
次に、"Cloud External Key Manager"は、Google Cloud外部で暗号化キーのライフサイクルを管理するためのサービスです。つまり、キー管理をデータ管理とは別のプロバイダーに委託しました。これにより、静止状態のデータの完全な保護と暗号鍵の完全なライフサイクル管理が可能となります。External Key Managerは、暗号鍵の全ライフサイクルを管理し、データ保護要件の満足度を高めるための最良の選択となります。
これら2つのサービスを使用することにより、静止状態のデータの保護、鍵管理の独立性、暗号化キー要求の可視化という3つの重要なコンプライアンス要件を満たすことができます。
不正解についての説明：
選択肢：顧客管理の暗号化キー
この選択肢が正しくない理由は以下の通りです。
"顧客管理の暗号化キー"ではデータ管理と鍵管理を別々のプロバイダーで行うという要件を満たしません。一方"Cloud External Key Manager"は外部の鍵管理システムを使用でき、また"Key Access Justifications"は鍵要求の可視化を可能にします。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キー（CSEK）を使用しても、暗号鍵の完全なライフサイクル管理や別の鍵管理プロバイダーの導入という要件には対応できません。反対に、Cloud External Key Managerを用いると、外部の鍵管理サービスを利用でき、Key Access Justificationsは鍵要求の可視化を提供します。
選択肢：Access Transparency and Approval
この選択肢が正しくない理由は以下の通りです。
Access Transparency and Approvalでは鍵の管理や可視化は提供されないため不適切です。
その一方で、Cloud External Key Managerは外部鍵の管理を、Key Access Justificationsは暗号化キー要求の可視化を可能にするので正解です。
参考リンク：
https://cloud.google.com/security-key-management
https://cloud.google.com/kms/docs/external-key-manager
https://cloud.google.com/bigquery/docs/encryption-key-management
</div></details>

### Q.  問題23: 未回答
あなたは、機密データの暗号化キーの管理について懸念しているクライアントと仕事をしています。このクライアントは、暗号化キーが暗号化されるデータと同じクラウドサービスプロバイダ（CSP）に暗号化キーを保存したくないと考えています。
このクライアントにどのGoogle Cloud暗号化ソリューションを勧めるべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客の特定の要望に基づいたGoogle Cloudの暗号化ソリューションを選択することが求められています。顧客は暗号化キーをデータと同じクラウドサービスプロバイダ（CSP）に保存したくないとの要望を出しています。したがって、選択肢を検討する際は、これらの要望を満足するソリューションを選ぶべきです。これは、クラウドプロバイダがキーを管理するデフォルトの暗号化ソリューションだけでなく、キーの外部管理を可能にするソリューションも考慮に入れることを意味します。
基本的な概念や原則：
顧客指定の暗号化キー（CSEK）：Google Cloudのストレージ製品で使用するエンクリプションキーを顧客が直接管理・提供する方式です。この方式では、キーはGoogle Cloud外部で管理され、データは顧客が指定したキーで暗号化されます。
Cloud External Key Manager（Cloud EKM）：Cloud EKMは、Google Cloudのリソースを、外部のキーマネージメントシステムから直接制御できるようにするサービスです。それにより、データの暗号化キーをGoogle Cloudとは別の場所で保存、管理できます。
Googleのデフォルト暗号化：Google Cloudのすべてのデータはデフォルトで暗号化されますが、この方式では、キー管理はGoogleが行い、キーはGoogle Cloud内部で管理されます。
Secret Manager：Google Cloudのセキュアで堅牢なサービスで、保護すべき秘密データのストレージと管理を提供します。しかし、暗号化キー自体の管理ではなく、APIキーやパスワードなどの秘密情報全般の管理を主に扱います。
顧客管理の暗号化キー（CMEK）：Cloud KMSを使用して作成、ローテーション、自動的に破棄するキーを指定してGoogle Cloudのデータを暗号化する方法です。この方式では、キーの管理は顧客が行いますが、キー自体はGoogle Cloud内部に保存されます。
正解についての説明：
（選択肢）
・顧客指定の暗号化キー
・Cloud External Key Manager
この選択肢が正解の理由は以下の通りです。
顧客指定の暗号化キー（CSEK）は、Google Cloud環境内のデータを保護するために顧客が提供および管理するキーで、Googleが保持しません。しかし、CSEKは暗号化されるデータと同じCSP、つまりGoogle Cloudにキーを保存する必要がありますが、キーの管理はクライアント側が行います。これはクライアントの要求に一部適合しています。
さらに、Cloud External Key Manager（EKM）は、Google Cloudの外部で暗号化キーを管理するためのサービスです。これにより、クライアントはキーを任意の第三者CSPに保存し、管理することが可能となります。この機能がクライアントの要望、つまり暗号化キーを暗号化されるデータと同じCSPに保存したくないとの要望に合致します。
したがって、顧客指定の暗号化キーとCloud External Key Managerの両方がクライアントの要望を満たす適切な選択肢となります。
不正解についての説明：
選択肢：Googleのデフォルト暗号化
この選択肢が正しくない理由は以下の通りです。
Googleのデフォルト暗号化では、キー管理はGoogleが行い、暗号化キーはGoogle Cloud上に保存されます。クライアントが暗号化キーを他のCSPに保存したいと考えているため、このオプションはクライアントの要件を満たしません。
選択肢：Secret Manager
この選択肢が正しくない理由は以下の通りです。
Secret Managerは秘密情報（パスワードやAPIキーなど）の安全な管理とアクセスを提供しますが、暗号化キーの管理機能は提供していません。
それに対して、顧客指定の暗号化キーとCloud External Key Managerは両方とも客観的な暗号化キーの管理を支援します。
選択肢：顧客管理の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客管理の暗号化キーはGoogle Cloud自体で管理されるため、暗号化データと同じプロバイダで鍵を保存することになってしまいます。
それに対し、顧客指定の暗号化キーとCloud External Key Managerは両方ともキーの管理をクライアント自身が行う設定を可能にします。
参考リンク：
https://cloud.google.com/kms/docs/external-key-manager
https://cloud.google.com/kms/docs/csek
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題24: 未回答
組織のGoogle Cloud VMは、外部ユーザー向けのウェブサービスをホストするために、パブリックIPアドレスで構成されたインスタンステンプレートを介してデプロイされます。VMは、VM用のカスタムShared VPCを1つ含むホスト（VPC）プロジェクトにアタッチされたサービスプロジェクトに常駐しています。あなたは、外部ユーザーへのサービスを継続しながら、VMのインターネットへの露出を減らすように求められました。あなたはすでに、マネージドインスタンスグループ（MIG）を起動するために、パブリックIPアドレス構成なしでインスタンステンプレートを再作成しました。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、外部ユーザー向けのウェブサービスをホストしているGoogle Cloud VMのインターネットへの露出を減らす必要があります。VMはカスタムShared VPCを1つ含むホストプロジェクトにサービスプロジェクトという形でアタッチされています。ここで注意しなければならないのは、システムがインターネットに露出することを減らすためだけでなく、同時に外部ユーザーへのサービス継続も求められているという点です。そして、パブリックIPアドレス無しでインスタンステンプレートを再作成し、マネージドインスタンスグループ（MIG）を起動するまでのタスクは完了しています。問題の鍵は、これらの情報を考慮して、MIGのインターネットへの露出の度合いを最小限に抑えつつ、外部ユーザーへのサービスは続行するための方法を選択することです。
基本的な概念や原則：
インスタンステンプレート：Compute Engineのインスタンスを作成するための設定が保存されたテンプレートです。一度作成した設定を再利用することで一貫性と作業効率を向上させます。
Shared VPC：Google Cloud上の複数のプロジェクト間で仮想ネットワークリソース（VPCネットワーク、サブネット、IPアドレス）を共有できる機能です。これにより、セキュリティとネットワーク管理が一元化され、分散リソースの対応が可能になります。
マネージドインスタンスグループ（MIG）：Compute Engineのインスタンスを自動的に管理する機能です。スケールアップやスケールダウン、負荷分散などを自動的に行うことができます。
HTTP(S)ロードバランサー：HTTP/HTTPSトラフィックを複数のインスタンスに分散する機能です。これにより、高負荷状況でも安定したサービス提供が可能になります。
Cloud NAT：Google CloudのNAT（Network Address Translation）ゲートウェイです。プライベートアドレスからパブリックアドレスへの変換機能を提供しますが、インターネットからの直接的なアクセスを可能にするものではありません。
正解についての説明：
（選択肢）
・MIGをバックエンドとするサービスプロジェクトに、外部のHTTP(S)ロードバランサーをデプロイします
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのHTTP(S)ロードバランサーは、インターネットからのトラフィックを特定のバックエンド（このケースではMIG）に分散するロールを果たします。これにより、VMのインターネットへの露出は大幅に減少し、それでも外部ユーザーからのアクセスが可能となります。ロードバランサー自体がインターネットに公開され、外部トラフィックを想定通りにルーティングします。
また、MIGをバックエンドに設定することで、MIG内のインスタンスへのトラフィックを効率的にバランスさせることができます。これにより、高い堅牢性と性能を維持しながら、外部のウェブサービスを提供することが可能となります。
さらに、改めてパブリックIPアドレスを割り当てない新しいインスタンステンプレートを作成したことで、VMのインターネットへの露出は更に軽減されます。この要件に対する最善のソリューションと評価されます。
不正解についての説明：
選択肢：MIGのサービスプロジェクトにCloud NATゲートウェイをデプロイします
この選択肢が正しくない理由は以下の通りです。
Cloud NATゲートウェイは、外部への露出を減らすのではなく、プライベートインスタンスに対してアウトバウンド通信の設定を提供します。つまり、本質的に内部から外部への接続を管理し、外部ユーザーからのアクセスを制御するものではありません。
対照的に、HTTP(S)ロードバランサーでは公開サービスへの外部ユーザーのアクセスを制御しつつ、VMの直接的なインターネット接続を防げるため、適切な選択肢となります。
選択肢：MIGのホスト（VPC）プロジェクトにCloud NATゲートウェイをデプロイします
この選択肢が正しくない理由は以下の通りです。
Cloud NATゲートウェイは、VMがインターネットと通信するためのプライベートIPアドレスを提供しますが、外部ユーザーがサービスにアクセスするためのポート付き公開IPアドレスは提供しません。上記の要件は、サービスのアクセスを維持しつつ、VMのインターネット露出を減らすことなので、Cloud NATだけでは不十分です。
選択肢：MIGをバックエンドとするホスト（VPC）プロジェクトに、外部のHTTP(S)ロードバランサーをデプロイします
この選択肢が正しくない理由は以下の通りです。
VMがサービスプロジェクトに存在するため、サービスプロジェクトにロードバランサーを配置するのが適切です。ホストプロジェクトにロードバランサーを配置した場合、外部ユーザーに対するサービスを継続できない可能性があります。
参考リンク：
https://cloud.google.com/compute/docs/instance-templates
https://cloud.google.com/load-balancing/docs/https
https://cloud.google.com/nat/docs/overview
</div></details>

### Q.  問題25: 未回答
あなたは最近、会社のGoogle Cloud導入をサポートするネットワーキングチームに加わりました。あなたには、ファイアウォールルールの構成に慣れ、ネットワーキングとGoogle Cloudの経験に基づいた推奨事項を提供することが任されています。
優先順位の高い、または等しい他のファイアウォールルールの属性と重複しているファイアウォールルールを検出するために、どの製品を推奨すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのネットワーキングとセキュリティに関する知識が求められています。具体的には、ファイアウォールルールの重複を検出するためのツールや製品を理解する必要があります。問題文中には重複するファイアウォールルールを特定する必要があると述べられており、その目的を達成するために最適な製品を選択することが求められています。したがって、各選択肢が具体的にどのような機能を提供し、それが問題の要件にどの程度適合するかを考慮する必要があります。
基本的な概念や原則：
ファイアウォールインサイト：Google Cloudの機能の一つで、ファイアウォールルールの分析と最適化を支援します。他のファイアウォールルールとの重複や未使用のルールを特定できます。
Security Command Center：Google Cloudのセキュリティ管理プラットフォームで、組織全体の脅威と脆弱性を一元的に表示・管理することができます。ただし、ファイアウォールルールの重複を特定する機能はありません。
ファイアウォールルールのログ：ファイアウォールルールがトラフィックを許可または拒否した際のログです。ルールの効果を確認するために利用しますが、ルールの重複を特定する機能はありません。
VPCフローログ：VPCネットワーク上のIPトラフィックの詳細な情報を提供するログです。ネットワーク監視やトラフィック分析、トラフィックエンジニアリングに有用ですが、ファイアウォールルールの重複を特定する機能はありません。
正解についての説明：
（選択肢）
・ファイアウォールインサイト
この選択肢が正解の理由は以下の通りです。
ファイアウォールインサイトは、Google Cloud上で構成されたファイアウォールルールやその関連情報の解析を行い、複雑なネットワーキング環境を可視化し、調整します。具体的には、ファイアウォールルール間での重複を検出したり、不要なルールや潜在的な誤設定を特定したりといった詳細な分析が可能です。これは、新しくチームに加わったあなたが、ファイアウォールルールの構成に慣れるための重要なツールとなります。
また、ファイアウォールインサイトを使用することで、ネットワーキングに関する洞察や推奨事項をチームに提供することが可能になります。そのため、このシナリオにおいては、"ファイアウォールインサイト"が最も適した製品ととなります。
不正解についての説明：
選択肢：Security Command Center
この選択肢が正しくない理由は以下の通りです。
Security Command Centerは、Google Cloudリソースの脆弱性、誤設定などを検出できますが、特に"ファイアウォールルールが重複している"ことを特定的に検出する機能はありません。
一方、ファイアウォールインサイトはGoogle Cloud内のネットワークトラフィックとファイアウォールルールを分析し、ルールの重複などを明確に識別できるので正解です。
選択肢：ファイアウォールルールのログ
この選択肢が正しくない理由は以下の通りです。
ファイアウォールルールのログはルールが適用された際のアクティビティを表しますが、ルールの重複検出機能はありません。
一方、ファイアウォールインサイトはルールの衝突分析や重複検出機能を持つため問題の要件を満たします。
選択肢：VPCフローログ
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフローの情報を収集し分析するためのサービスですが、ファイアウォールルールの属性やそれらが重複するかどうかを自動的に検出する機能は有していません。
一方、ファイアウォールインサイトはファイアウォールルールの検証と最適化を支援するサービスで、重複するルールの検出が可能です。
参考リンク：
https://cloud.google.com/network-intelligence-center/docs/firewall-insights/overview
https://cloud.google.com/network-intelligence-center/docs/firewall-insights/how-to
https://cloud.google.com/network-intelligence-center
</div></details>

### Q.  問題26: 未回答
あなたはCompute Engineのディスク上のデータを、Cloud Key Management Service（KMS）が管理するキーで静止時に暗号化したいと考えています。これらのキーに対するCloud IdentityおよびIAMのパーミッションは、すべてのキーに対して同じである必要があるため、グループ化された方法で管理する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute Engineのディスク上のデータをCloud Key Management Service（KMS）で静止時に暗号化する方法と、そのキーへのパーミッションをグループ化された方法で管理する方法が求められています。重要な要件としては、すべてのキーに対してパーミッションが同じである必要があり、これらのパーミッションを一括で管理したいという点が挙げられます。したがって、各キーを個別に管理するのではなく、キーのグループ（KeyRing）単位でパーミッションを制御する方法を選びます。その際、キー単位ではなくKeyRingレベルでIAMパーミッションを管理する点に注意しなければなりません。
基本的な概念や原則：
Compute Engine：Google Cloudのインフラストラクチャで、仮想マシンを実行する環境を提供します。高パフォーマンスネットワーキングと自動的なスケーリングが可能です。
Cloud Key Management Service（KMS）：Google Cloudの暗号キー管理サービスです。自分でキーを管理するか、Googleにキーの生成や管理を任せることができます。
KeyRing：Cloud KMSのリソースで、暗号キーの論理的なグループです。一つのKeyRingは複数の暗号キーを持ち、それらをまとめて管理することが可能です。
IAMパーミッション：Google CloudのIdentity and Access Management（IAM）における、特定のユーザーやグループに付与できるアクセス制御です。コードやデータの閲覧、編集、実行などを許可、制限することが可能です。
静止時暗号化：データが保存されている状態（つまり、データが動いていない状態）でデータを暗号化することです。ハードドライブやリムーバブルメディアなどが対象となります。
永続ディスク：Compute Engine上で使用されるブロックストレージです。インスタンスとは独立して存在し、インスタンスが削除されてもデータは保持されます。
正解についての説明：
（選択肢）
・すべての永続ディスクとこのKeyRing内のすべてのKeyについて、単一のKeyRingを作成します。KeyRingレベルでIAMパーミッションを管理します
この選択肢が正解の理由は以下の通りです。
Cloud KMSでは、複数の暗号キー（CryptoKeys）を管理するためのコンテナとしてKeyRingを提供しています。各KeyRingは、異なるCryptoKeyをグループ化して一元化し、より効率的なアクセス制御を実現します。
本問題の要件では、すべてのキーに対して同一のIAMパーミッションが求められています。
したがって、各キーに対して別々にパーミッションを付与するのではなく、それら全てを含む単一のKeyRingを作成し、このKeyRingレベルでIAMパーミッションを管理することで、一括でアクセス制御を行うことが可能になります。これは管理コストを削減し、一貫したパーミッション管理を実現します。
さらに、このアプローチはすべての永続ディスクの暗号化にも適用可能で、統一されたセキュリティポリシーを維持しながらデータを保護することができます。
不正解についての説明：
選択肢：すべての永続ディスクとこのKeyRing内のすべてのKeyについて、単一のKeyRingを作成します。KeyレベルでIAMパーミッションを管理します
この選択肢が正しくない理由は以下の通りです。
問題の要件では、すべてのキーに対して同一のIAMパーミッションを適用することが必要とされています。しかし、この選択肢ではKeyレベルでのIAMパーミッション管理を提案しており、これは個々のキーに対して異なるIAMパーミッションを設定することを意味します。これは要件と矛盾しているため、この選択肢は不正解です。
選択肢：永続ディスクごとにKeyRingを作成し、各KeyRingに1つのKeyを含めます。KeyレベルでIAMパーミッションを管理します
この選択肢が正しくない理由は以下の通りです。
要件はすべてのキーに対するIAMパーミッションが同じであることを指定しているのに対し、この選択肢は永続ディスクごとにKeyRingを作成し、各KeyRingに1つのKeyを含めることを提案しています。このアプローチは、各キーに個別の管理要件を持たせることを意味し、要件とは一致しません。
選択肢：永続ディスクごとにKeyRingを作成し、各KeyRingに1つのKeyを含めます。KeyRingレベルでIAMパーミッションを管理します
この選択肢が正しくない理由は以下の通りです。
設問の要求はすべてのキーに対してパーミッションが同じであることであり、異なるKeyRingに区分して設置すると管理が煩雑になる可能性があります。
逆に、単一のKeyRingを用いることで管理が一元化され、求められる要件に適合します。
参考リンク：
https://cloud.google.com/kms/docs/encrypting-disks
https://cloud.google.com/iam/docs/granting-roles-to-service-accounts
https://cloud.google.com/compute/docs/disks/customer-supplied-encryption
</div></details>

### Q.  問題27: 未回答
Compute Engine上でホストされているWebアプリケーションをデプロイしています。ビジネス要件として、アプリケーションのログを12年間保存し、データをヨーロッパの境界内に保存することが義務付けられています。あなたは、オーバーヘッドを最小限に抑え、費用対効果の高いストレージソリューションを実装したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute EngineでホストされるWebアプリケーションのログをヨーロッパ内に12年間保存することと、オーバーヘッドを最小限に抑え費用対効果を高めることが求められています。つまり、ログの保存場所、保存期間、費用や効率性といった要素に注目する必要があります。これらの要素に基づいて、ログの保存に最適なGoogle Cloudのストレージソリューションを選択します。アプリケーションコードの変更や、Google Cloudの異なるサービスを利用することの影響も考慮し、最適な解決策を選択することが問われています。
基本的な概念や原則：
Cloud Storage：Google Cloudのデータ保存サービスです。グローバルで、ローカルで、地域で保存できます。大量のデータを安全かつ耐久性高く保存でき、ロギングにも適しています。
リージョン：Google Cloudのデータを物理的に保管する地域のことです。リージョンの選択によりデータの住所や住所の範囲が決まります。
Google Cloudの操作組：Google Cloudの監視、トラブルシューティング、アプリケーションパフォーマンス管理を統合する一連のツールです。
Cloud Logging：Google Cloudの操作スイート内の一部で、アプリケーションとシステムからのログを収集、分析、エクスポートするサービスです。
Pub/Subトピック：Google Cloud Pub/Subにおけるエンドポイントで、パブリッシャーがメッセージを送信する場所です。
操作スイートのログバケット：ログデータを保存するためのオペレーションスイートの機能です。各バケットは特定の場所にデータを保存し、一定期間データを保存することができます。
カスタム保存ポリシー：ログバケットに格納されるログデータの保持期間を設定するためのポリシーです。これは特定のコンプライアンス要件を満たすために使われます。
正解についての説明：
（選択肢）
・europe-west1リージョンにログを保存するCloud Storageバケットを作成します。アプリケーションコードを変更して、ログをバケットに直接送信し、効率を高めます
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageは長期間のデータ保管に適したコスト効率の高いストレージオプションを提供しており、アプリケーションログの永続的な保存を行うために理想的です。12年という長期間のログ保管を求められている要件を効果的に満たします。
さらに、Google Cloud Storageはリージョナルなデータ格納に対応しています。そのため、"データをヨーロッパの境界内に保存する"という要件も満たせるわけです。この選択肢では、europe-west1リージョンにバケットを作成することでこの要件を満たすことができます。
そして、アプリケーションコードを変更してログをバケットに直接送信することで、ログの流れを最適化し、オーバーヘッドを最小限に押さえることができます。これは、パフォーマンスとコスト効率を改善するために重要なステップです。結果として、この選択肢は全ての要件を最適化した形で満たすため、正解となります。
不正解についての説明：
選択肢：Compute EngineインスタンスがGoogle CloudのオペレーションスイートCloud Loggingエージェントを使用し、アプリケーションログをeurope-west1リージョンのカスタムログバケットに送信するように設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Loggingエージェントを使用する場合、ログの送信にオーバーヘッドがかかります。そのため、オーバーヘッドを最小限に抑えるというビジネス要件を満たすことができません。
また、直接Cloud Storageにログを保存することで効率が良くなるため、コスト対効果に優れています。
選択肢：Pub/Subトピックを使用して、アプリケーションログをeurope-west1リージョンのCloud Storageバケットに転送します
この選択肢が正しくない理由は以下の通りです。
Pub/Subトピックを使用すると、ログデータの転送にオーバーヘッドが発生します。正解の選択肢と比べて、ログデータを直接Cloud Storageバケットに送信する方が効率的で、コストも少なく抑えられます。
選択肢：europe-west1リージョンのGoogle Cloudのオペレーションスイートのログバケットに、12年間のカスタム保存ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのオペレーションスイート（旧Google Cloud Operation Suite）の保存期間は最大で30日間であり、カスタム保存ポリシーを用いてそれ以上延ばすことができません。そのため、要件である12年間のログ保存を満たすことができません。
参考リンク：
https://cloud.google.com/storage/docs/creating-buckets
https://cloud.google.com/storage/docs/locations
https://cloud.google.com/compute/docs/instances/create-start-instance
</div></details>

### Q.  問題28: 未回答
多国籍企業の事業部門がGoogle Cloudにサインアップし、ワークロードをGoogle Cloudに移行し始めた。その事業部門は、何百ものプロジェクトを持つ組織リソースでCloud Identityドメインを作成します。
あなたのチームはこのことに気づき、ドメインリソースの権限管理と監査を引き継ぎたいと考えています。
この要件を満たすには、どのタイプのアクセスを付与すべきですか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のビジネスユニットがGoogle Cloudに移行を開始し、あなたのチームがドメインリソースの権限管理と監査を担当したいと考えているという状況が示されています。選択肢の中から、この要件を満たすために必要なアクセスレベルを正確に選択することが求められています。特に、ドメインリソース全体の管理と監査に必要なアクセス権とは何かを理解することが重要です。選択肢から適切なロールを洗い出すためには、Google Cloudの権限モデルと各ロールがどのようなアクセスを付与するのかを把握していることが必要です。
基本的な概念や原則：
Organization Administrator：Google Cloudの組織全体のアクセスと操作管理を提供します。組織やプロジェクトを作成し、それらに対するアクセス制限やアクセスレベルを定義できます。
Cloud Identityドメイン：Google Cloudのユーザとグループ管理を提供します。Identity and Access Management（IAM）の一部として機能し、ユーザとグループがCloud Identity Aware ProxyまたはCloud Identity Platform APIといったGoogle Cloudのリソースにアクセスするための認証を提供します。
Identity and Access Management（IAM）：ユーザとサービスアカウントへのロールベースのアクセス制御の提供し、Google Cloudリソースへのアクセスを管理します。IAMポリシーは誰が（Identity）、何を（Role）、どこで（Resource）行うことができるかを定義します。
Security Reviewer：特定のリソースに対するアクセス権限を監査するためのロールです。全組織的な権限管理には適しません。
Organization Role Administrator：組織レベルの角色を作成、変更、削除するためのロールです。全組織のリソースへのアクセス権限の設定には適しません。
Organization Policy Administrator：組織ポリシーの作成、変更、適用を行うロールです。これは組織全体のリソースに対するアクセス制御よりも、特定のリソースの使用ポリシーを定義する働きをします。
正解についての説明：
（選択肢）
・Organization Administrator
この選択肢が正解の理由は以下の通りです。
Organization Administratorのロールは、Google Cloudでの組織全体のリソース管理を効果的に制御できる最高レベルのアクセス権限を持っています。このロールが付与されると、ユーザーは組織全体のリソースに対して管理と監査の操作を実行できます。具体的には、組織のリソース階層構造のセットアップ、IAMポリシーの管理、組織設定の更新など、組織全体に関連するアクションを管理することが可能になります。これにより、その組織ダメイン内で利用されているプロジェクトやその他のリソースについて、統一した規模での管理と監視が可能となります。
したがって、Cloud Identityドメインの権限管理と監査を引き継ぎたいと考えるあなたのチームには、Organization Administratorのアクセス権限が最適となります。
不正解についての説明：
選択肢：Security Reviewer
この選択肢が正しくない理由は以下の通りです。
Security ReviewerはIAMロールの一部で、権限の監査は可能ですが、権限管理や設定の機能はありません。
一方、Organization Administratorは、ドメインリソース全体の権限管理と監査が可能で、要件を満たす全機能を提供します。
選択肢：Organization Role Administrator
この選択肢が正しくない理由は以下の通りです。
Organization Role Administratorの権限を付与されると、そのユーザーは組織全体のロールを管理できますが、それはドメインリソースの管理や監査を直接的に手助けするものではありません。Organization Administratorの権限を持つユーザーの方が、組織全体のすべてのGoogle Cloudリソースを管理できるため必要なタスクを実行することが可能です。
選択肢：Organization Policy Administrator
この選択肢が正しくない理由は以下の通りです。
Organization Policy Administratorの権限ではポリシーの設定や更新が可能ですが、ドメインリソースの全体的な権限管理や監査を行うために必要なOrganization Administratorの権限を持っているわけではありません。なので、組織全体のリソースを管理するためには、Organization Administratorの権限が必要です。
参考リンク：
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://cloud.google.com/resource-manager/docs/access-control-org
https://cloud.google.com/resource-manager/docs/creating-managing-organization
</div></details>

### Q.  問題29: 未回答
アプリケーションとリソースにアクセス制御ポリシーを適用するために、どのGoogle Cloudサービスを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、適切なアクセス制御ポリシーを適用するためのGoogle Cloudのサービス選択の課題に取り組んでいます。選択肢から判断すべき主要な観点は、それらのサービスが提供する具体的な機能と、問題文中で述べられた要件との対応関係です。課題はアクセス制御ポリシーを適用するという点であり、これに応じたサービスを選択することが求められます。この視点から選択肢を評価することで、最も適切な選択肢に辿り着きます。
基本的な概念や原則：
Identity-Aware Proxy：Google Cloudの認証と認可を行うためのサービスです。アプリケーションやリソースのアクセス制御ポリシーの適用と管理を行うことができます。
Cloud NAT：Google Cloud上での中継ネットワーキングを提供するサービスです。プライベートネットワークからインターネットへの接続を可能にします。
Google Cloud Armor：Google Cloud上のアプリケーションを保護するためのDDoS防御サービスです。
Shielded VM：Google Cloud上で実行する仮想マシンに追加のセキュリティ保護を提供するサービスです。不正なソフトウェアや不正アクセスから保護します。
正解についての説明：
（選択肢）
・Identity-Aware Proxy
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのIdentity-Aware Proxy（IAP）は、GoogleのBeyondCorpセキュリティモデルを利用して、企業のアプリケーションやリソースへのセキュアなアクセスを提供します。IAPを使用すると、公開Webアプリケーションに対するアクセスを制御し、特定のGoogle Cloudのリソースへの認証済みユーザーまたはグループのアクセスを管理することができます。
また、VPNや物理的なデバイスなどを必要とせずに、リモートワークをしているユーザーがセキュアな環境でアクセスできるようにします。これにより、安全性を維持しつつ柔軟なアクセス制御を実現することができます。
したがって、アクセス制御ポリシーを適用するためには、Identity-Aware Proxyが適したサービスとなります。
不正解についての説明：
選択肢：Cloud NAT
この選択肢が正しくない理由は以下の通りです。
Cloud NATはプライベートなGoogle Cloudリソースからインターネットにアクセスするためのサービスであり、アクセス制御ポリシーを適用する機能はありません。
一方、Identity-Aware Proxyはアプリケーションやリソースへのアクセス制御のためのサービスで、適切な認証と認可を提供します。
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは、HTTP(S) ロードバランサーのトラフィックを保護する主にDDoS攻撃防止やWAFの機能を提供していますが、アプリケーションやリソースへのアクセス制御ポリシーを適用する機能は提供していません。
一方、Identity-Aware Proxyはリソースへのアクセス制御を行うためのサービスであり、適切な選択肢となります。
選択肢：Shielded VM
この選択肢が正しくない理由は以下の通りです。
Shielded VMはVMインスタンスの信頼性とセキュリティを向上させるサービスであり、アクセス制御ポリシーをアプリケーションやリソースに適用する機能を提供していません。
逆に、Identity-Aware Proxyはアクセス制御機能を提供し、ユーザーやグループに基づいてアプリケーションやリソースへのアクセスを制御します。
参考リンク：
https://cloud.google.com/iap/docs
https://cloud.google.com/armor/docs
https://cloud.google.com/compute/docs/shielded-vm
</div></details>

# 2
## 1

### Q.  問題2: 未回答
独自の企業秘密を保管する機密性の高い Cloud Spanner データベースを管理しており、パブリック インターネットからアクセスできないようにする必要があります。不正なデータアクセスのリスクを軽減するために、すべてのデータベースクエリは、事前定義されたIPアドレスのセットによってのみ実行可能である必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud Platform リソース(特に Cloud Spanner)を不正な一般アクセスから保護することについての受験者の理解度を評価します。焦点は、データベースクエリを事前定義されたIPアドレスのセットに制限する方法です。
重要な用語:
VPC Service Controls: GCP サービスに保存されているデータの周囲にセキュリティ境界を定義して、データ流出のリスクを制限できる Google Cloud リソースのセキュリティ レイヤです。
アクセスレベル: VPC Service Controls の一部であるアクセスレベルを使用すると、IP アドレス範囲などの属性を設定して、GCP リソースへのきめ細かなアクセス制御を適用できます。
正解解説:
(オプション)
・VPC Service Controlsを使用し、承認済み送信元IPアドレスを条件とするアクセスレベルを定義します。
VPC Service Controls は、事前定義された一連の IP アドレスへのデータ アクセスを制限することで機密データのセキュリティを強化し、Cloud Spanner の周囲に安全な境界を作成するため、この選択は適切です。承認された送信元 IP アドレスの条件を含むアクセス レベルを定義することで、指定した IP のクライアントのみがデータベース クエリを実行できるようにし、パブリック インターネットからのアクセスを防止する要件に合わせます。
不正解の説明:
オプション: HTTP(S) ロードバランサ レベルで IP の承認済みリストを含めるように Google Cloud Armor セキュリティ ポリシーを構成します。
この選択が間違っている理由は、Cloud Armor が DDoS 攻撃や SQL インジェクションなどの HTTP(S) ロードバランサ レベルでの攻撃から保護するように設計されているためです。送信元 IP アドレスに基づいて Cloud Spanner データベースへのアクセスを制限する方法は提供されません。
オプション: Restrict Resource Locations 組織ポリシーの制約を Cloud Data Loss Prevention(DLP)ツールと組み合わせて実装します。
この選択が間違っている理由は、リソースの場所を制限する組織ポリシーと Cloud DLP が IP アドレスに基づいてアクセスを制御するためのツールではないためです。これらは、保存されたデータの場所を制御し、機密情報を保護することを目的としており、IPベースのアクセス管理を目的としていません。
オプション: [サービス利用の無効化] 組織ポリシーの制約を適用し、Cloud Data Loss Prevention(DLP)を利用して制御を強化します。
この選択が正しくない理由は、Disable Service Usage 組織ポリシー制約を適用すると、サービスが完全に使用されなくなり、IP アドレスに基づいてアクセスが制御されないためです。Cloud DLP はデータ保護を提供しますが、データベースクエリの実行を IP アドレスで制限することはありません。
参考：
https://cloud.google.com/vpc-service-controls/docs/create-manage-service-perimeters
https://cloud.google.com/access-context-manager/docs/overview
https://cloud.google.com/bigquery/docs/controlled-access
</div></details>

### Q.  問題8: 未回答
ある医療機関は、電子カルテシステムを Google Cloud に移行しながら、一部の重要なサービスをローカル データセンターでホストしています。シームレスなデータ転送のためには、少なくとも70Gbpsの接続を確保する必要があります。
オンプレミス インフラストラクチャとクラウド間の高速で安全な接続を維持するには、どの Google Cloud サービスを使用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、オンプレミス インフラストラクチャと Google Cloud の間で大量のデータを転送するための高速かつ安全な直接接続を確保するために、Google Cloud で利用できるサービスに対する理解度を評価します。
重要な用語:
専用相互接続: 組織のネットワークと Google のネットワークを直接物理的に接続し、可用性の高い低レイテンシの接続を提供します。
Cloud Router: VPN と連携し、Border Gateway Protocol(BGP)を使用して Google Cloud VPC とオンプレミス ネットワーク間でルートを動的に交換します。
Cloud VPN: オンプレミス ネットワークと Google Cloud VPC の間に、パブリック インターネット経由で安全で暗号化された接続を確立します。
Partner Interconnect: サポートされているサービス プロバイダを通じて Google Cloud への接続を提供し、Dedicated Interconnect よりも少ない容量しか必要としない組織に適しています。
正解解説:
(オプション)
・専用インターコネクト
Dedicated Interconnect は、組織がオンプレミス ネットワークと Google のネットワークの間に直接物理接続を確立し、リンクあたり最大 100 Gbps の転送速度を可能にするため、正しい選択です。これは、電子カルテシステム用に70Gbpsの接続を保証する必要がある医療従事者に最適です。さらに、機密性の高い健康データに不可欠な、一貫性のある低遅延で安全でプライベートな接続を提供します。
不正解の説明:
オプション:クラウドルーター
Cloud Router が正しくない理由は、Cloud Router 自体が接続ソリューションを提供していないためです。Cloud Router は VPN 接続の動的ルーティング用であり、シナリオに必要な専用帯域幅や高スループットは提供されません。
オプション:クラウドVPN
クラウドVPNが間違っている理由は、インターネット上で暗号化されたトンネルを提供し、トンネルあたりの最大スループットが3Gbpsであるため、質問に記載されている70Gbpsの要件には不十分であるためです。
オプション:パートナー相互接続
Partner Interconnect が間違っている理由は、オンプレミス ネットワークを Google Cloud に拡張するためのオプションにはなり得ますが、通常は Dedicated Interconnect の容量が大きすぎる場合に選択されるためです。必要な 70 Gbps の場合、パートナー相互接続のスループットが十分でないか、費用対効果が低くなる可能性があります。
参考：
https://cloud.google.com/interconnect/docs/how-to/dedicated
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/interconnect/docs/concepts/overview
</div></details>

### Q.  問題10: 未回答
小売企業向けに Compute Engine でホストされる在庫追跡システムを設定しています。同社のポリシーでは、システムアクセスログを15年間保持し、データレジデンシーをアジア太平洋地域内に限定することが義務付けられています。管理を簡素化し、経済的に実行可能なストレージソリューションをお探しです。
あなたは何を着手すべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、15年間の保存期間とアジア太平洋地域に限定されたデータレジデンシーという2つの特定の要件を持つシステムアクセスログのストレージソリューションを特定することを目的としています。このソリューションは、Compute Engine インスタンスと統合し、管理が容易で費用対効果が高いものでなければなりません。
重要な用語:
データ所在地: データ所在地とは、データが格納される物理的または地理的な場所を指します。特定の規制や企業ポリシーにより、コンプライアンス要件を満たすために、データが特定の地域内に保存されることが規定されている場合があります。
アイテム保持ポリシー: アイテム保持ポリシーは、データを削除する前に保持する期間を管理する一連のルールです。多くの場合、法的および規制上の要件への準拠により、これらのポリシーが決定されます。
経済的に実行可能:ソリューションが経済的に実行可能である場合、それは費用対効果が高く、初期費用と継続的な費用の両方を考慮すると、使用期間中に過度の経済的負担を課さないことを意味します。
正解解説:
(オプション)
・ASIA-EAST1リージョンにシステムアクセスログを保管するCloud Storageバケットを作成します。ログをバケットに直接プッシュするようにシステムを調整して、プロセスを最適化します。
この選択は、指定された両方の要件に直接対処するため、最適です。ASIA-EAST1 リージョンに Cloud Storage バケットを作成すると、データ レジデンシーのコンプライアンスが確保されます。Cloud Storage では、オブジェクトのライフサイクル ポリシーを設定することもできますが、15 年の固定保持期間を直接サポートしていません。代わりに、カスタム保持ポリシーを使用してオブジェクトを設定するか、ライフサイクルポリシーを実装して、必要な期間削除されないようにすることができます。また、追加のサービスを必要とせずにログの管理を簡素化し、他の複雑なソリューションと比較して費用対効果を高めることができます。
不正解の説明:
オプション: Compute Engine インスタンスで Google Cloud のオペレーション スイートの Cloud Logging エージェントを利用して、システム アクセスログを ASIA-EAST1 リージョンの専用ログバケットにエクスポートし、15 年間のカスタム保持ポリシーを設定します。
この選択が間違っている理由は、Google Cloud のオペレーション スイート内の Cloud Logging エージェントが、通常、ログの長期保存ではなく、リアルタイムのモニタリング、ログ記録、診断に使用されるためです。さらに、ログを Cloud Storage にエクスポートしてカスタム保持ポリシーを設定することは可能ですが、このアプローチはより複雑であり、長期保存の最も経済的に実行可能なソリューションではない可能性があります。
オプション: Pub/Sub トピックを使用して、ASIA-EAST1 リージョンに配置された Cloud Storage バケットにシステム アクセスログをリレーします。
この選択が間違っている理由は、Pub/Sub を使用すると、Pub/Sub なしで実行できるタスクに不必要な複雑さと追加コストが発生する可能性があるためです。Pub/Sub は、単純なログ ストレージではなく、リアルタイムのメッセージ キューイングとストリーム処理に最適です。これでは、経営の簡素化や経済性の確保という要件を満たしていません。
オプション: ASIA-EAST1 リージョンに基づく Google Cloud のオペレーション スイート ログバケットに 15 年のカスタム保持期間を設定します。
この選択が間違っている理由は、Google Cloud のオペレーション スイートのログバケットの使用を前提としているためです。カスタム保持期間を設定できますが、オペレーション スイート ログ バケットの使用は、特に単純なストレージ オプションと比較すると、ログを 15 年間保存するための最も費用対効果の高いソリューションではない可能性があります。
参考：
https://cloud.google.com/storage/docs/creating-buckets
https://cloud.google.com/storage/docs/locations
https://cloud.google.com/compute/docs/instances/create-start-instance
</div></details>

### Q.  問題11: 未回答
医療機関は、エンタープライズ レベルでの過剰な権限を懸念しており、昇格されたアクセス権を持つユーザーの数を減らしたいと考えています。
セキュリティを強化するために、組織が最小限に抑えるべき 2 つのポジションはどれですか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud のコンテキストにおけるロールベースのアクセスの理解度を評価し、特に組織のセキュリティを強化するために過剰な権限を一元的に最小限に抑えることに焦点を当てています。正解は、最小化すると、広範なアクセスが大幅に減少し、セキュリティが強化される役割を特定します。
重要な用語:
最小特権の原則: 意図した機能を実行するために不可欠な特権のみをユーザーアカウントに与えることを推奨するセキュリティ概念。
IAM ロール: ユーザー、グループ、またはサービス アカウントに割り当てることができる Google Cloud リソースに対して特定のアクションを実行するための一連の権限を定義します。
組織ポリシー: Google Cloud リソースのデプロイと使用をガイドする組織全体のガバナンス ルールの構成。
請求先アカウント: Google Cloud プロジェクトにリンクされたアカウントで、そのプロジェクトで使用されるリソースと Google Cloud サービスの料金を支払うユーザーを定義します。
正解解説:
(オプション)
・組織ポリシー管理者
・請求先アカウント管理者
"組織ポリシー管理者" ロールを持つユーザーを減らすと、組織内のすべてのリソースに影響を与えるポリシーを設定できる個人の数が制限されるため、セキュリティが強化されます。「課金アカウント管理者」を最小限に抑えることで、課金構成を管理できる個人の数が減り、リソースの可用性とセキュリティ体制に間接的に影響を与える可能性のある課金に対する不正または偶発的な変更を防ぐことができます。
不正解の説明:
オプション:ネットワーク管理者
「ネットワーク管理者」が間違った選択である理由は、この役割がネットワーク リソースを厳密に管理するため、質問の中心である組織レベルまたは請求レベルでの広範な管理者権限が与えられないためです。
オプション: Healthcare API Admin (Healthcare API 管理者)
「Healthcare API Admin」が正しくない理由は、このロールが Healthcare API の管理に固有であり、エンタープライズ レベル全体で昇格されたアクセス権を提供しないためです。
オプション: 組織ビューア
このロールは組織内のリソースへの読み取り専用アクセス権を付与するため、「組織閲覧者」の選択は正しくありません。ポリシーやアクセス許可の変更は許可されないため、この役割を減らしても、意味のある方法でセキュリティが強化されることはありません。
参考：
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/resource-manager/docs/access-control-org
https://cloud.google.com/resource-manager/docs/quickstart-organizations
</div></details>

### Q.  問題14: 未回答
組織の Cloud Bigtable インスタンスにパブリック インターネットからアクセスできないようにする必要があります。これをすべての Cloud Bigtable インスタンスに適用する場合。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud Platform(GCP)内に適切なアクセス制御と組織ポリシーを実装することで、公共のインターネットからのアクセスを防ぐために Cloud Bigtable インスタンスを保護することについて学習者が理解しているかどうかをテストします。
重要な用語:
所有者の役割: GCP リソースの所有者の役割は、リソースに対する管理制御やアクセス ポリシーを設定する機能など、さまざまな権限を付与します。
ドメイン制限付き共有: GCP の Resource Manager 内のこのポリシー設定により、信頼された組織ドメイン外の ID とリソースが共有されるのを防ぎます。
組織ポリシー: 組織ポリシーは、GCP 組織の GCP リソースを一元的に制御するための制限の構成です。
正解解説:
(オプション)
・エンドユーザーからオーナーロールを削除し、組織ポリシーでドメイン制限付き共有を強制する。
この選択により、アクセス許可を制限し、ドメイン レベルの制約を適用することが、不正アクセスを防ぐための鍵となることが正しく識別されます。所有者ロールを削除すると、ユーザーは Cloud Bigtable インスタンスを公開する可能性のあるアクセス制御を変更できなくなります。組織のポリシーを使用してドメイン制限付き共有を実装すると、組織内のユーザーによるリソースへのアクセスが制限され、Cloud Bigtable などのリソースへのパブリック インターネット アクセスが効果的にブロックされます。
不正解の説明:
オプション: エンドユーザーから所有者ロールを削除し、Bigtable の Cloud Data Loss Prevention を設定します。
この選択が間違っている理由は、所有者ロールを削除するとユーザー権限が制限されるのに対し、Bigtable に Cloud Data Loss Prevention(DLP)を設定してもパブリック インターネットからのアクセスは妨げられないためです。DLP は、主に機密データの検出とマスキングに重点を置いています。
オプション: 統一されたインスタンス レベルのアクセスを有効にし、組織のポリシーでドメイン制限付き共有を適用します。
統一されたインスタンスレベルのアクセスを有効にしても、パブリックインターネットからのアクセスが本質的に妨げられるわけではなく、権限管理が簡素化され、より安全に使用できるため、このオプションは正しくありません。ただし、これだけでは、Bigtable インスタンスが一般公開されていないことを保証するものではありません。
オプション: すべてのロールから *.setIamPolicy アクセス許可を削除し、組織のポリシーでドメイン制限付き共有を適用します。
この選択が間違っている理由は、*.setIamPolicy アクセス許可を削除するとアクセス制御の変更が妨げられますが、ドメイン制限ポリシーは適用されないためです。これにより、既存のポリシーが適切に保護されていない場合、インスタンスが引き続き公開される可能性があります。
参考：
https://cloud.google.com/storage/docs/using-bucket-policies
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題15: 未回答
顧客の機密財務データが、夜間の ETL オペレーションの一環として、地域のデータセンターから Cloud Spanner データベースに転送されていることを確認しました。顧客の詳細をマスキングするには、この情報を匿名化する必要がありますが、財務諸表のマスキングを元に戻す機能が必要です。
この要件に最も適したコンポーネントはどれですか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 環境内の機密データの保護に関する受験者の知識、特にレポート作成のための可逆性を維持しながらデータの匿名化について調べます。ETL操作中に機密情報へのアクセスを暗号化して管理するための適切なコンポーネントを選択することに重点が置かれています。
重要な用語:
確定的暗号化: 特定のデータに対して毎回同じ暗号化されたテキストを生成する暗号化の形式。暗号化されたデータを異なるシステム間で一致させる必要があるシナリオで特に役立ちます。
AES-SIV:暗号化を確定的に行うことができる認証済み暗号化モードであり、同じキーで暗号化された同じ平文は常に同じ暗号文を生成します。
データの匿名化:個人と保存されたデータをつなぐ識別子を消去または暗号化することにより、個人情報や機密情報を保護するプロセス。
正解解説:
(オプション)
・クラウドキー管理サービス
・AES-SIVによる確定的暗号化によるクラウドデータ損失防止
Cloud Key Management Service(KMS)と Cloud Data Loss Prevention(DLP)を AES-SIV を使用した確定的な暗号化と組み合わせることで、機密データの可逆的な匿名化に最適です。Cloud KMS では、データへのアクセスを制御する暗号鍵を管理し、安全な暗号化と復号のオペレーションを可能にします。AES-SIV決定論的暗号化でDLPを使用すると、データが暗号化されると、同じ一意の暗号文と一貫して照合できるため、財務報告の有用性を失うことなく、特定のデータを可逆的にマスクできます。
不正解の説明:
オプション:シークレットマネージャー
Secret Managerが正しくない理由は、ETLパイプライン内でデータの匿名化と暗号化のメカニズムを提供するのではなく、APIキーやパスワードなどのシークレットへのアクセスを保存および管理するために設計されているためです。
オプション: Cloud Data Loss Prevention と暗号化ハッシュ
暗号化ハッシュを使用した Cloud Data Loss Prevention が正しくない理由は、ハッシュが一方向の操作であり、後続の処理やレポート作成のためにデータを元に戻す必要があるシナリオには適していないためです。
オプション:自動テキスト秘匿化機能を備えたCloud Data Loss Prevention
自動テキスト墨消し機能による Cloud Data Loss Prevention が正しくない理由は、墨消しによってデータが完全に削除され、財務報告のために元のコンテンツを再構築できなくなるためです。
参考：
https://cloud.google.com/kms
https://cloud.google.com/dlp/docs/concepts-deidentification#de-identification_in_the_dlp_api
</div></details>

### Q.  問題16: 未回答
医療データのコンプライアンス チームは、機密性の高い患者の健康情報 (PHI) を削除するために、暗号シュレッダーの方法を採用しました。このプロセスを Google Cloud 内に実装しながら、ほとんどのクラウド サービスを活用し、管理の負担を最小限に抑えることが課題です。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、Google Cloud で機密データを安全に削除するための適切なアプローチ、特に健康データ規制への準拠を確保し、運用上のオーバーヘッドを最小限に抑えながら、最も効率的なデータ破壊方法に対処することに焦点を当てています。
重要な用語:
クリプトシュレッダー:暗号化キーが破棄されて関連データが読み取れないようにし、実際のデータファイルを削除せずにデータを効果的に「シュレッダー」するセキュリティプラクティス。
Cloud Key Management Service (KMS): 暗号化キーを管理するクラウドサービスで、暗号化操作の一元管理とキーの安全な削除を可能にします。
正解解説:
(オプション)
・Cloud Key Management Service(KMS)を使用して、特定の鍵バージョンを破棄します。
この選択は、Google Cloud の鍵管理サービス(KMS)を利用して暗号鍵を処理するため、最も適切です。KMS で特定のキーバージョンを破棄すると、そのキーで暗号化されたデータは復元できなくなります。このプロセスにより、KMS では削除を含むキーの集中管理が可能になり、キー管理をマネージド サービスにアウトソーシングするため、暗号化シュレッダ処理方法が役立ちます。
不正解の説明:
オプション: データを Google Cloud にアップロードする前にクライアントサイド暗号化を実装し、独自のデータセンターで鍵の削除を管理します。
この選択が間違っている理由は、暗号化と鍵の削除をオンプレミスで管理するには大量のリソースが必要であり、Google Cloud のスケーラビリティとマネージド サービスを利用していないため、質問の仕様に反して運用上の負担が増加するためです。
オプション: 顧客管理の暗号鍵(CMEK)を使用して独自の暗号鍵を作成および管理し、必要に応じて破棄します。
このアプローチに欠陥がある理由は、Google Cloud 内で顧客管理の暗号鍵(CMEK)を使用することはできますが、安全な破棄を含む鍵の管理ライフサイクル全体では、管理の負担を最小限に抑えるという望ましい目標を超えてチームのオーバーヘッドが増加するためです。
オプション: Google の自動暗号化を利用して、暗号鍵を選択的に消去します。
この選択が間違っている理由は、Googleの自動暗号化には鍵を選択的に消滅させる機能がないためです。Google は暗号化と復号化を透過的に管理し、ユーザーは暗号シュレッダーを実行するための鍵を直接制御できません。
参考：
https://cloud.google.com/kms/docs/external-key-managers
https://cloud.google.com/kms/docs/crypto-shredding
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題19: 未回答
企業は NoSQL データベースのニーズに Cloud Bigtable を活用しています。Cloud Bigtable で使用される SSD の対称暗号鍵を作成、循環、分解する方法が必要です。キーはクラウドに保存できる必要があります。
どのような対策を講じるべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Cloud Bigtable SSD を保護するための暗号鍵の管理に関する受験者の知識をテストします。クラウド環境で保存および使用される暗号化キーを作成および管理するための適切なサービスを理解することに重点を置いています。
重要な用語:
対称暗号化: データの暗号化と復号化に同じキーを使用する暗号化の一種。これは、保存データを暗号化する際のパフォーマンスに不可欠です。
データ暗号化キー (DEK): データを直接暗号化するために使用されるキーで、多くの場合、セキュリティレイヤーの追加とキー管理の利便性のために別のキー (KEK) で暗号化されます。
キー暗号化キー (KEK): キー管理プロセスのセキュリティを強化するために、他のキー (DEK など) を暗号化またはラップするために使用されるキー。
Cloud Key Management Service(KMS):クラウドサービスの暗号鍵を安全かつコンプライアンスに準拠した方法で管理できるクラウドベースのサービス。
正解解説:
(オプション)
・Cloud Key Management Serviceを使用して、データ暗号鍵(DEK)を作成および制御します。
Cloud Key Management Service(KMS)は、クラウドで暗号鍵を作成、使用、管理するための専用サービスであるため、この選択は適切です。Cloud KMS を利用すると、Cloud Bigtable 内の SSD の暗号化に使用できるデータ暗号鍵(DEK)を生成および制御し、クラウドに鍵を安全に保存するという要件を満たすことができます。
不正解の説明:
オプション: Cloud Key Management Service を使用して、鍵暗号鍵 (KEK) を作成および制御します。
これが間違っている理由は、鍵暗号鍵(KEK)を具体的に管理しても、Cloud Bigtable で使用される SSD 上のデータの暗号化をどのように処理するかという質問に直接答えられないためです。KEK は通常、データ自体ではなく、DEK を暗号化するために使用されます。
オプション: 顧客管理の暗号化キーを使用して、データ暗号化キー (DEK) を管理します。
これが正しくない理由は、顧客管理の暗号化キーは、顧客が DEK の生成と保存に責任を持つことを意味するためです。これは、鍵がクラウドに保存可能である必要があるという要件と矛盾しており、Cloud KMS などのサービスによって実現されています。
オプション: キー暗号化キー (KEK) の監視に顧客管理の暗号化キーを使用します。
これが正しくない理由は、2番目の選択肢と似ています。KEK 監視用の顧客管理の暗号化キーは、キーの生成と保存に顧客が直接関与することを意味します。これにより、Cloud KMS などのクラウドベースの鍵管理サービスが提供する効率性とセキュリティが失われます。
参考：
https://cloud.google.com/security-key-management
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/security
https://cloud.google.com/kms/docs/creating-keys
</div></details>

### Q.  問題20: 未回答
HIPAA規制に準拠するために、ある医療機関は、データ送信のすべてのインスタンスが検証されていることを確認したいと考えています。
追加の緩和措置を必要とせずにこの規定を満たしている 2 つの Google Cloud サービスはどれですか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の HIPAA 準拠サービス(特にデータ送信の検証)の理解度を評価します。学習者は、追加の保護手段なしで HIPAA に沿ったエグレス制御を本質的に提供するサービスを特定する必要があります。
重要な用語:
HIPAAコンプライアンス:機密性の高い患者の健康情報が患者の同意や知識なしに開示されないように保護するために確立された一連の基準を指します。
データ送信(外向き):通常、内部ストレージから外部宛先に転送する場合に、ネットワークから外部へのデータフロー。
エグレス制御: ネットワーク境界から出る情報の流れを監視し、場合によっては制限するために実装されたセキュリティ対策。
正解解説:
(オプション)
・コンピュートエンジン
Google Kubernetes エンジン
Compute Engine と Google Kubernetes Engine(GKE)は、追加の下り(外向き)制御を必要とせずに HIPAA 準拠のワークロードをサポートできる方法でデータ(外向き)を処理できるように設計されています。GKE は、Compute Engine 上に構築されたコンテナ オーケストレーションのマネージド サービスとして、データ送信を含む組み込みのセキュリティとコンプライアンス機能を継承しており、HIPAA 要件を満たすのに役立ちます。どちらのサービスも堅牢なネットワークセキュリティ機能を提供し、組織がファイアウォールを構成してプライベートIPを使用できるようにし、不正なデータアクセスと転送を防ぐのに役立ちます。
不正解の説明:
オプション: App Engine
App Engine が正しくない理由は、App Engine が Platform-as-a-Service サービスであり、基盤となるネットワークとセキュリティの構成がユーザーから抽象化されているため、HIPAA コンプライアンスのための追加の対策が必要になる可能性があるためです。
オプション: Cloud Functions
Cloud Functions が正しくない理由は、Cloud Functions がサーバーレス実行環境であり、ユーザーがネットワークの下り(外向き)を制御できる範囲が限られているため、HIPAA の厳格な下り(外向き)制御要件に準拠するために追加の手順が必要になる可能性があるためです。
オプション:クラウドストレージ
Cloud Storage が正しくない理由は、このサービスがデータ ストレージに重点を置いており、きめ細かなアクセス制御を提供する一方で、追加のセキュリティ層なしで HIPAA 規制に準拠する必要があるデータ送信を本質的に検証しないためです。
参考：
Hatpas://cloud.google.com/comput/DOC/vpc
https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview
https://www.pcisecuritystandards.org/documents/PCI_DSS_v3-2-1.pdf
</div></details>

### Q.  問題24: 未回答
ネットワーク エンジニアが Cloud Load Balancer で不正アクセスの試みを観察しました。エンジニアは、ネットワークリソースの構成またはメタデータにアクセスするAPI呼び出しを分析することを目的としています。
エンジニアが検査するのに最も役立つ Google Cloud ログはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud のログ機能、特に不正アクセスの試みを記録するログの種類や、ネットワーク構成の変更やメタデータへのアクセスを行う API 呼び出しに関する理解度を評価します。
重要な用語:
データアクセスログ: データの作成、変更、アクセスを記録した Google Cloud 内の詳細な監査ログ。フォレンジックやコンプライアンスの目的、特に不正アクセスの調査に役立ちます。
API 呼び出し: Google Cloud サービス内のリソースへのアクセス、変更、管理などのオペレーションを実行する API エンドポイントに対して行われたリクエスト。
正解解説:
(オプション)
・データアクセスログ
データアクセスログは、Google Cloud が提供する詳細なログで、API 呼び出しとユーザーデータへのアクセスを追跡します。不正アクセスを監視するネットワークエンジニアにとって、これらのログにはネットワーク構成とメタデータアクセスに対する読み取りおよび書き込み操作の記録が含まれているため、役立ちます。データアクセスログを分析することで、エンジニアはどのAPIコールがアクセスまたは構成を変更したかを確認できるため、不正アクセスパターンと潜在的なセキュリティ侵害に関する洞察が得られます。
不正解の説明:
オプション: 管理アクティビティ ログ
このシナリオで管理アクティビティ ログが最も役に立たない理由は、主にクラウド上のリソースの構成またはメタデータを変更する操作を追跡するためです。ただし、不正なデータアクセスの調査に必要な詳細なデータアクセス記録は提供されません。
オプション: システム・イベント・ログ
システム イベント ログが最適な選択ではない理由は、データやメタデータにアクセスまたは変更する特定の API 呼び出しではなく、リソースの状態、可用性、または構成に影響を与えるシステム生成イベントに焦点を当てているためです。
オプション: アクセスの透明性ログ
この場合、アクセスの透明性に関するログが不適切なのは、Google の担当者がユーザーのコンテンツにアクセスするたびにログが提供されるように設計されているためで、ユーザーが不正な外部アクセスを試みたり、API 呼び出しを調査したりしないようにするためです。
参考：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/auditing
https://cloud.google.com/sql/docs/mysql/admin-api/logging
</div></details>

### Q.  問題29: 未回答
あなたは、Google Cloud 内の患者データを完全に暗号化し、移動中のデータ、処理中のデータ、保存されているデータをカバーする必要がある医療機関にアドバイスしています。
これらの要件を満たすには、どのようなソリューションを実装する必要がありますか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、保存中、転送中、処理中の暗号化によって医療患者データを保護するための適切な Google Cloud ソリューションを特定するためのものです。適切なソリューションは、医療に固有の厳格なコンプライアンスおよびデータ保護基準に準拠している必要があります。
重要な用語:
コンフィデンシャル VM: メモリ暗号化を使用して使用中のデータを暗号化し、ハイパーバイザー レベルでの特権アクセスからも処理中のデータを確実に保護する仮想マシン。
Anthos Service Mesh: 移動中のデータをエンドツーエンドで暗号化し、クラウドネイティブ アプリケーション内のサービス間の通信を保護するサービス管理レイヤです。
アプリケーション層の暗号化:保存または送信する前にアプリケーション内のデータを暗号化するプロセスで、開発者はデータのセキュリティとコンプライアンスをきめ細かく制御できます。
正解解説:
(オプション)
・コンフィデンシャル VM と Anthos Service Mesh
・アプリケーション層の暗号化
コンフィデンシャル VM は、機密性の高い医療データを安全に処理するために不可欠な仮想マシンのメモリを暗号化することで、使用中のデータを暗号化します。Anthos Service Mesh は、サービス間のトラフィックを管理、監視、保護することで、移動中のデータを保護します。アプリケーション層の暗号化により、開発者は、データを保存または通信する前に、実行中のアプリケーション内で特にデータを暗号化し、保存データと転送データの両方に追加の保護レイヤーを提供できます。
不正解の説明:
オプション:クラウドキー管理サービス
Cloud Key Management Service は、クラウドでホストされる鍵管理サービスであり、サービスの暗号鍵の管理に役立ちますが、移動中または使用中のデータの暗号化は本質的に含まれていません。
オプション: 顧客管理の暗号化キー
顧客管理の暗号化キーは、保存データの暗号化キーをより詳細に制御できますが、アプリケーションのコンテキスト内で使用中のデータまたは移動中のデータの暗号化には対応していません。
オプション:Titanセキュリティキー
Titan セキュリティ キーは、2 要素認証に使用されるハードウェア セキュリティ キーであり、クラウド サービス内のストレージ、処理、または転送中のデータの暗号化は含まれません。
参考：
https://cloud.google.com/security/confidential-computing
https://cloud.google.com/istio/docs/istio-on-gke/overview
https://cloud.google.com/kms/docs/encryption-at-rest-concepts
</div></details>

### Q.  問題30: 未回答
製造会社がワークロード サーバーを Google Cloud に移行することを計画しています。これらのサーバーのマシンイメージが、すべての部門のセキュリティポリシーと一貫性を保つようにする必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ワークロードを Google Cloud に移行する際のセキュリティ コンプライアンスを維持するという課題に対処します。マシンイメージの一貫性を維持するために、組織レベルでセキュリティ ポリシーを適用するための Google Cloud のメカニズムを理解する必要があります。
重要な用語:
組織ポリシー: 組織のクラウド リソースを一元的に制御し、セキュリティ構成などの特定の要件が均一に適用されるようにする一連の制約。
マシンイメージ: 仮想マシンのディスクとメタデータ定義の完全なスナップショットで、一貫性のある状態でVMをレプリケートするために必要なすべての情報をカプセル化します。
起動ディスク: 仮想マシンのオペレーティング システムと起動スクリプトを含むプライマリ ディスク。ブート ディスクの作成を制御することで、セキュリティ コンプライアンスを強化できます。
正解解説:
(オプション)
・起動ディスクの作成を、認可されたマシンイメージプロジェクトから作成されたイメージのみに制限する組織ポリシーを実装します。
この選択は、組織全体で一貫性のあるポリシー準拠のマシンイメージを確保するという懸念に直接対処できるため、最適です。ブート ディスクの作成を指定されたプロジェクトのイメージに制限する組織のポリシーを実装することで、企業は承認された構成の使用を強制できます。これにより、すべての部門で、会社のセキュリティ ポリシーに準拠しているイメージのみを使用して新しい VM を作成できるため、標準化されたセキュリティ体制が維持されます。
不正解の説明:
オプション: 承認されたマシン イメージの使用を保証するために、すべての部門に対してシールドされた VM 機能をアクティブ化する会社全体のポリシー制約を適用します。
この選択が正しくない理由は、シールドされた VM が、ルートキットやブート レベルまたはカーネル レベルのマルウェアなど、さまざまな脅威のセットに対する保護を提供するためです。シールドされた VM 機能をアクティブ化しても、ブート ディスクに使用されるマシン イメージのソースは直接制御されません。
オプション: 承認されたマシンイメージコレクションから新しいサーバーインスタンスが開始されたときにトリガーされ、マシンイメージが最新であることを確認するように Cloud Functions の関数を設定します。
この選択が間違っている理由は、仮想マシンの起動時にトリガーするように Cloud Functions の関数を設定するのが事後対応型の手段であるためです。承認済みのマシンイメージの使用は確認されますが、未承認のイメージから仮想マシンインスタンスが起動される前に作成されるのを防ぐことはできません。
オプション: 定期的なスキャン ツールを展開して、承認されたマシン イメージ カタログ内に共通脆弱性識別子 (CVE) がないかどうかを確認します。
この選択が間違っている理由は、マシン イメージ内の CVE のスキャンは、脆弱性を特定するためのセキュリティ プラクティスであり、特定のマシン イメージの使用を強制するものではないためです。これは、ポリシー適用方法ではなく、補完的なセキュリティ対策です。
参考：
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/security-command-center/docs/concepts-security-sources-for-findings
</div></details>

### Q.  問題32: 未回答
組織での Cloud Identity-Aware Proxy(Cloud IAP)の利用が拡大するにつれて、サービスを最適化して費用を削減する必要があります。監査対象のリソースには、Cloud VPN インスタンスと Compute Engine インスタンスを介してアクセスします。リソース名には、接尾辞識別子としてゾーンとリージョンが含まれます。
コストを管理するために、どのような戦略をお勧めしますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Cloud Identity-Aware Proxy(Cloud IAP)の使用を最適化してコストを削減する方法を検討します。ここでは、Cloud VPN と Compute Engine を通じて Cloud IAP を使用する組織に焦点を当てており、リソースには場所ごとに名前が付けられています。
重要な用語:
カスタムアクセスレベル: Cloud IAP で保護されている特定のリソースにアクセスできるユーザーを制御するために管理者が設定した事前定義された条件によって決定されるアクセス制限。
要求サイズ制限: サービス拒否攻撃やリソースの過剰使用を防ぐために要求のサイズを制限し、全体的なコスト管理に貢献する構成設定。
ネットワーク タグ: Compute Engine VM インスタンスに割り当てられるラベルで、ファイアウォール ルールの適用に使用でき、セキュリティと組織のためにトラフィックをセグメント化するのに役立ちます。
正解解説:
(オプション)
・カスタムアクセスレベルとリクエストサイズ制限を採用してトラフィックをフィルタリングし、Compute Engine のネットワークタグを使用して監査範囲を制限します。
この選択は、リソースへのアクセスに特定のフィルタを適用することで、Cloud IAP の効率的な使用を強調しています。カスタムアクセスレベルを採用することで、アクセスリクエストをより正確にフィルタリングし、リソースの不必要な使用を回避できます。同時に、要求サイズの制限を設定すると、コストが増加する可能性のある過度に大きな要求の処理を防ぐことができます。さらに、Compute Engine のネットワーク タグを使用すると、広範囲のトラフィックを確認するのではなく、範囲を特定のインスタンスに制限することでターゲットを絞った監査が可能になり、オーバーヘッド コストの管理と削減がさらに促進されます。
不正解の説明:
オプション: 海外にある Compute Engine インスタンスに正確なリクエスト サイズ制限を適用し、大陸間 Cloud VPN トンネルに正確なデータ転送制限を定義します。
この選択が間違っている理由は、Compute Engine インスタンスと Cloud VPN の地理的な要因に焦点を当てているためですが、国際的な場所のみに基づいて制限しても、コスト削減に大きく貢献しない可能性があります。包括的なコスト管理戦略が欠けています。
オプション: 海外でホストされている Compute Engine インスタンスに正確なリクエスト サイズ制限を実装し、国際的な Cloud VPN 接続のトラフィック インスペクションを減らします。
この選択が間違っている理由は、国際VPN接続のトラフィックインスペクションを減らすことでコストが削減されることを前提としているためですが、これは必ずしも真実ではありません。また、海外でホストされているインスタンスにサイズ制限を設定しても、Cloud IAP のコスト最適化には直接対応できません。
オプション:AccessControlConfig と TrafficManagementConfig を活用してトラフィックをサンプリングし、インスペクション レベルを下げます。
この選択が正しくない理由は、指定された構成 AccessControlConfig と TrafficManagementConfig が Cloud IAP 内に存在しないためです。このアプローチでは、コスト削減やクラウド IAP を最適化するための具体的な戦略に直接つながらないサンプリング方法を提案しています。
参考：
https://cloud.google.com/dlp/docs/concepts-limits
https://cloud.google.com/dlp/docs/inspecting-storage
https://cloud.google.com/dlp/docs/samples/dlp-inspect-file-regexp-sample
</div></details>

### Q.  問題34: 未回答
マルチメディア会社は、業界固有の法的要件を遵守する必要があります。そのため、顧客管理の暗号鍵(CMEK)が、media-org45 というラベルの付いた組織内のすべての新しい Cloud Spanner データベースに適用されるようにする必要があります。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud で組織のポリシーを適用して、暗号化に関する法的要件に準拠していることを確認する能力をテストします。具体的には、指定された組織ラベル内の Cloud Spanner データベースの CMEK 使用の構成に関する知識を評価します。
重要な用語:
組織ポリシー: Google Cloud リソース階層でのリソースの動作に関する制限を定義するポリシー リソース。これは、クラウドのガバナンスとコンプライアンスの基本です。
顧客管理の暗号鍵(CMEK): お客様が作成、所有、管理する暗号鍵で、Google Cloud に保存されているデータの暗号化と復号を顧客が制御できるようにします。
制約: 会社のガイドラインまたはコンプライアンス要件に準拠するために、組織のポリシー内で制限または制御できるリソースの特定の側面または動作。
ポリシー・バインディング: ポリシーをプロジェクト、フォルダ、組織などの特定のリソースに関連付けて、該当する場合は定義された制限を適用します。
拒否ポリシー: ポリシーのスコープ内で許可されないサービスまたはアクションのリストを管理者が指定できる組織ポリシーの一種。
リソースラベル: Google Cloud リソースを組織構造を反映したグループに整理し、管理とフィルタリングを容易にするために使用されるキーと値のペア。
正解解説:
(オプション)
・- 組織ポリシー: constraints/GoogleCloud.restrictNonCmekServices
- バインディング: media-org45
- ポリシーの種類: 拒否
- ポリシー値: spanner.googleapis.com
この選択では、「constraints/GoogleCloud.restrictNonCmekServices」という制約を持つ組織ポリシーを正しく利用して、指定したサービスを拒否し、CMEK の使用を強制します。このポリシーを組織ラベル「media-org45」にバインドすることで、その特定の組織内のすべての新しい Cloud Spanner データベースが CMEK を使用するための業界固有の法的要件に準拠し、タスク要件を満たすようになります。
不正解の説明:
オプション: - 組織ポリシー: constraints/GoogleCloud.restrictDatabaseNonCmekServices
- バインディング: media-org45
- ポリシーの種類: 許可
- ポリシー値: サポートされているすべてのサービス
この選択が正しくない理由は、CMEK の使用を強制するタスクと一致しない「許可」ポリシータイプが指定されているためです。さらに、「サポートされているすべてのサービス」では、ポリシーが Cloud Spanner 以外のサービスも含まれるため、暗号化要件の意図した特異性は確保されません。
オプション: - 組織ポリシー: constraints/GoogleCloud.restrictDatabaseNonCmekServices
- バインディング: media-org45
- ポリシーの種類: 拒否
- ポリシー値: spanner.googleapis.com
この選択により、組織のポリシーが「constraints/GoogleCloud.restrictDatabaseNonCmekServices」と誤って指定されていますが、これは Cloud Spanner データベースに CMEK を適用するために必要な正しいポリシー制約と一致していません。「拒否」ポリシーの種類が正しく記述されているにもかかわらず、この制約はデータベース全般に不正確に調整されています。
オプション: - 組織ポリシー: constraints/GoogleCloud.restrictNonCmekServices
- バインディング: media-org45
- ポリシーの種類: 許可
- ポリシー値: spanner.googleapis.com
これが間違っている理由は、正しい制約「constraints/GoogleCloud.restrictNonCmekServices」を持つ「allow」ポリシータイプを提案しているため、CMEK 以外のサービスを拒否するのではなく許可する役割を担い、Cloud Spanner データベースに CMEK を義務付けるという目的に反しているためです。
参考：
https://cloud.google.com/storage/docs/encryption/using-customer-managed-keys
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/sdk/gcloud/reference/alpha/resource-manager/org-policies/allow-policy-constraints
</div></details>

### Q.  問題35: 未回答
あなたは医療機関のIT部門に所属しています。組織には、患者記録管理システム、社内コミュニケーション ツール、ビッグデータ分析プラットフォームを含む多目的 Google Cloud プロジェクトがあります。お客様は、HIPAAコンプライアンス監査の対象となるシステムの範囲を最小限に抑える任務を負っています。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、Google Cloud 環境内で HIPAA 準拠のデータを管理するためのベスト プラクティスを中心にしています。また、機密性の高い患者データを他のワークロードと一緒に保持している医療従事者に対して監査が必要なシステムの範囲を最小限に抑えるための戦略を探ります。
重要な用語:
HIPAA コンプライアンス: 医療保険の相互運用性と説明責任に関する法律 (HIPAA) によって課される規制基準で、機密性の高い患者データ保護の基準が定められています。
PHI データ環境: 個人健康情報 (PHI) を保存、処理、または処理する特殊なコンピューティング環境であり、厳格なセキュリティとコンプライアンス制御が必要です。
Google Cloud プロジェクトの分離: 個別の Google Cloud プロジェクトを使用してリソースを分離し、アクセスを制御する方法。これにより、コンプライアンスとセキュリティの取り組みの複雑さと範囲を軽減できます。
正解解説:
(オプション)
・患者の健康情報(PHI)データ環境を個別の Google Cloud プロジェクトに移行する。
PHI データ環境を個別の Google Cloud プロジェクトに分離することで明確な境界が作成され、必要な場合にのみ HIPAA コントロールを正確に適用できるため、この選択は適切です。これにより、コンプライアンス監査の対象となるシステムの数を最小限に抑え、PHIを直接扱う環境に重点を置きます。プロジェクトを分離することで、コンプライアンスとセキュリティ管理が簡素化され、効率的なリソース割り当てが可能になり、PHI以外のリソースに対するコンプライアンス違反のリスクが軽減されます。
不正解の説明:
オプション:医師が社内コミュニケーションツールにアクセスするための生体認証を実装します。
これが間違っている理由は、生体認証は強力なセキュリティ対策ですが、コンプライアンス監査の範囲に影響を与えないためです。コンプライアンス範囲の最小化は、単にユーザー認証方法を強化するだけでなく、アーキテクチャとデータの分離によって実現されます。
オプション: 医療 IT 標準に準拠していることが認定されたソフトウェアのみが展開されていることを確認します。
これが間違っている理由は、Health IT Standards認定ソフトウェアを使用しても、必ずしも監査範囲が最小化されるとは限らないためです。ソフトウェアは準拠している可能性がありますが、PHI以外のシステムから分離されていない場合、環境全体がコンプライアンス監査の対象となる可能性があります。
オプション: 本社から Google Cloud 環境へのすべてのトラフィックに対して、IPSec を使用して暗号化されたトンネルを確立します。
これが正しくない理由は、暗号化されたトンネルの確立がデータ転送のセキュリティに関係しているためです。これにより、転送中のデータ保護が強化されますが、クラウド環境内のHIPAAコンプライアンス監査の対象となるシステムの範囲には影響しません。
参考：
https://cloud.google.com/resource-manager/docs/creating-managing-projects
https://cloud.google.com/compliance/offerings#card_payment
https://cloud.google.com/solutions/pci-dss-compliance-in-Google クラウド
</div></details>

### Q.  問題38: 未回答
財務報告システムをクラウドに移行しています。システムでは、Google Cloud Storage バケットからレコードを取得する必要があります。財務ガバナンス標準により、暗号化キー マテリアルに対する排他的な制御を維持する必要があり、キー マテリアルへのアクセスには正当な理由が必要です。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、高度なクラウド セキュリティ プラクティス、特に Google Cloud サービスを使用して機密データを保存する際の暗号鍵の管理と厳格な財務ガバナンス基準への準拠に関する理解度を調べます。
重要な用語:
External Key Manager(EKM): Google Cloud サービスで保存されているデータに Google のインフラストラクチャの外部で管理されている暗号鍵を使用できるセキュリティ機能で、鍵管理プロセスの制御を強化します。
ハードウェア・セキュリティ・モジュール(HSM):強力な認証のためにデジタル・キーを保護・管理し、オンプレミスとクラウドの両方で動作できる暗号化処理を提供する物理コンピューティング・デバイス。
Key Access Justifications(KAJ): Google Cloud の External Key Manager の機能で、鍵を使用するすべてのアクセス リクエストに明示的な正当性を要求し、詳細なアクセス追跡と鍵の使用状況の制御を強化します。
顧客提供の暗号鍵(CSEK): Google Cloud の暗号化モデルで、お客様が独自の暗号鍵を提供し、マネージド サービス内ではなく、独自の鍵を直接管理、制御します。
正解解説:
(オプション)
・社内のセキュリティインフラ内でキーを生成し、オンプレミスのハードウェアセキュリティモジュール(HSM)内に保持する。Cloud Key Management Service(KMS)でこの鍵を外部鍵として使用し、不適切なアクセス試行を禁止するように構成された外部鍵システムで Key Access Justifications(KAJ)を有効にします。
この選択により、制御された内部環境内で暗号化キーを作成し、それをオンプレミスのハードウェア セキュリティ モジュール (HSM) で使用することで、ガバナンス標準への準拠が保証されます。Cloud KMS の外部鍵機能を活用し、鍵アクセスの正当性(KAJ)を有効にすることで、Google Cloud Storage での記録の機密性を維持しながら、暗号鍵の排他的な制御と鍵アクセスの正当な理由のニーズを満たし、詳細なアクセスの追跡と制御を保証します。
不正解の説明:
オプション: 顧客提供の暗号鍵(CSEK)を使用して Cloud Storage バケット内のレコードを暗号化し、特定のユーザー グループへのアクセスを拒否する IAM ポリシーを設定します。
この選択が間違っている理由は、顧客提供の暗号化キー(CSEK)は暗号化キーの制御を提供しますが、特定のコンプライアンスニーズであるキーアクセスに関する正当な理由に必要な外部キー管理システムの統合が不足しているためです。
オプション: Cloud Storage バケットに事前にアップロードされるレコードを暗号化するための暗号鍵を社内で作成します。鍵を Cloud Key Management Service(KMS)に転送し、鍵アクセスの理由(KAJ)をオンにして、不正なアクセス要求を禁止するように外部鍵システムを設定します。
この選択が間違っている理由は、社内で暗号鍵を作成して Cloud KMS に転送することについて言及しているため、鍵の排他制御を維持するための要件を満たしていないためです。さらに、ガバナンス基準によりオフサイトで独占的に管理する必要がある重要なマテリアルに Cloud KMS を使用することを誤って提案しています。
オプション: 指定されたクラウド ハードウェア セキュリティ モジュール(HSM)でサポートされている顧客提供の暗号鍵(CSEK)を使用して Cloud Storage バケット内のレコードを暗号化し、データ アクセスの監査ログをオンにします。
この選択が間違っている理由は、顧客提供の暗号鍵 (CSEK) とアクセスの監査を使用しているが、暗号鍵マテリアルの排他的制御を維持し、KAJ を有効にした外部鍵管理システムを使用するというガバナンス要件を満たしていないためです。
参考：
https://cloud.google.com/kms/docs/using-external-keys
https://cloud.google.com/storage/docs/encryption/using-customer-supplied-keys
https://cloud.google.com/kms/docs/key-access-justifications
</div></details>

### Q.  問題40: 未回答
あなたは会社のインフラストラクチャ チームの一員です。QA の目的で GKE にデプロイされている内部 API は、入力をサニタイズすることなく、クライアントから提供されたデータを動的に JSON レスポンスに補間することを確認しました。これにより、攻撃者は反射型 JSON インジェクション攻撃を実行し、運用環境のデプロイでコンテンツ操作につながる可能性があります。
このセキュリティの問題を軽減および修正するには、どのような対策を講じる必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Kubernetes Engine(GKE)にデプロイされた内部 API の JSON インジェクションに関連するセキュリティの脆弱性を調査します。これは、攻撃者が運用環境のデプロイでサニタイズされていないユーザー入力を通じてコンテンツを操作するリスクを軽減するための効果的なソリューションを求めています。
重要な用語:
反射型JSONインジェクション:サニタイズされていないユーザー入力をJSONレスポンスに補間し、攻撃者がAPIレスポンスを操作したり、クライアントブラウザで悪意のあるスクリプトを実行したりできる可能性のある攻撃手法。
Web Security Scanner: Google Cloud でホストされているウェブ アプリケーションのセキュリティ脆弱性を自動的にスキャンして検出するツールで、Google Cloud Security Command Center の一部です。
JSONシリアル化ライブラリ:オブジェクトをJSON形式に変換するソフトウェアコンポーネントで、一部のライブラリは、コンテンツをサニタイズしてインジェクション攻撃を防ぐためのデフォルトの出力エンコーディングを提供します。
正解解説:
(オプション)
・QA環境でWeb Security Scannerを使用してJSONインジェクション攻撃をシミュレートし、デフォルトで出力エンコードを行うJSONシリアライズライブラリを採用します。
この選択は、Web Security Scannerを使用して、QA環境に存在するJSONインジェクションの脆弱性の種類を検出してシミュレートする必要があるため、実用的です。また、既定で出力をエンコードするシリアル化ライブラリを使用することもお勧めします。この 2 つのアプローチは、シミュレートされた攻撃によって脆弱性を特定するだけでなく、データをエンコードすることで修正し、JSON 応答で悪意のあるコンテンツが操作される可能性を大幅に減らします。
不正解の説明:
オプション: 地理的な場所やユーザー グループのメンバーシップに基づくルールを使用して Cloud IAP を実装し、セキュリティ上の欠陥に対処して解決します。
この選択が間違っている理由は、Cloud IAP(Identity-Aware Proxy)が JSON インジェクションの脆弱性を解決するためではなく、ID に基づいてクラウド アプリケーションへのアクセスを制御するように設計されているためです。地域やユーザー グループに基づくルールでは、悪意のあるコードの挿入を防ぐことはできません。
オプション: SSL プロキシ ロードバランサを構成し、本番環境で Cloud Armor を有効にして、JSON インジェクションの脅威から保護します。
この選択が間違っている理由は、SSL プロキシ ロードバランサと Cloud Armor は外部からの脅威や DDoS 攻撃からの保護に役立ちますが、JSONレスポンスをサニタイズしてインジェクション攻撃を防ぐという内部的な問題(前述の主要な問題)には対処できないためです。
オプション: Web Security Scanner を使用して、アプリケーション スタック内の非推奨の依存関係を確認し、影響を受けるライブラリのパッチが適用されたバージョンにアップグレードします。
この選択が間違っている理由は、非推奨の依存関係を更新することはセキュリティ上の良い方法ですが、API がサニタイズされ、エンコードされた JSON データのみを出力するようにすることで JSON インジェクションを防ぐという差し迫った問題とは無関係であるためです。
参考：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/appengine/docs/standard/python3/using-templates
https://ovasp.org/wu-community/attacks/sss/
</div></details>

### Q.  問題42: 未回答
ビデオゲームサーバーの構成データを管理するコンテキストでは、リードDevOpsエンジニアは、ゲームサービスのライフサイクルのさまざまな段階で使用するために保存されているAPIキーやデータベースパスワードなどの機密情報とのやり取りを追跡する必要があります。
この機密情報に関連してユーザーやサービスが実行したアクションに関する分析情報を提供する 2 種類の Google Cloud ログはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、管理とデータ処理の実践に関連するGCPロギング機能、特にビデオゲームサービスの機密性の高いサーバー構成データに関する理解度を評価します。
重要な用語:
管理アクティビティ監査ログ: リソースの構成またはメタデータを変更する操作を記録するログ。管理アクションの監視とセキュリティ保護に不可欠です。
データアクセス監査ログ: ユーザー提供のデータを作成、変更、または読み取る API 呼び出しを追跡するログ。誰がどのように機密データにアクセスするかを評価するために不可欠です。
システム イベント監査ログ: Google Cloud システム イベントを記録するログで、ユーザーの直接的な操作ではなく、Google サービスによって自動的に生成されます。
Cloud Load Balancing ログ: Google Cloud Load Balancing によって生成されたログで、構成データへのアクセスではなく、アプリケーションに対して行われたリクエストに関する分析情報を提供します。
Compute Engine オペレーション ログ: Compute Engine リソースに対して実行されたオペレーションの詳細を示すログで、インフラストラクチャのアクティビティには関連しますが、機密データ アクセスには直接関連しません。
正解解説:
(オプション)
・管理者アクティビティ監査ログ
・データアクセス監査ログ
管理アクティビティの監査ログとデータアクセスの監査ログは、ユーザーによる機密情報の操作を追跡するために重要です。管理アクティビティは、リソース構成を変更する操作をログに記録し、APIキーとパスワードの変更をキャプチャします。データアクセスログは、読み取りや書き込みなどの機密データへのアクセスパターンをキャプチャし、重要なゲームサービスのライフサイクル設定データへのアクセスを監査するのに役立つ、さらなる粒度を提供します。
不正解の説明:
オプション: システム イベント監査ログ
システムイベント監査ログは、ユーザーの操作ではなくシステムによって生成されたイベントを反映するため、ユーザーによる機密データへのアクセスや変更の追跡には適していません。
オプション: Cloud Load Balancing ログ
Cloud Load Balancing ログは、サービスのバランスを取るためのリクエストベースの指標を取得することを目的としており、機密性の高い構成データの管理に関する詳細な分析情報は提供されないため、この要件には関係ありません。
オプション: Compute Engine オペレーション ログ
Compute Engine オペレーションログはインフラストラクチャの変更を対象としており、API キーやパスワードなどの機密性の高い構成データの特定のアクセスの詳細をカバーしていないため、このコンテキストには適用されません。
参考：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/audit-logging
https://cloud.google.com/security-command-center/docs/concepts-logging-and-notifications
</div></details>

### Q.  問題44: 未回答
規制を遵守するために、金融企業は、機密性の高い金融取引を処理するPodが「準拠した」ノードでのみスケジュールされることを保証する必要があります。さらに、これらのノードは「準拠した」Podを排他的にホストする必要があります。
このコンプライアンス要件を満たすために、企業はどのような方法を使用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、機密データを扱う金融企業内で、専用ノードで特定のKubernetes Podをスケジュールし、ソフトウェアコンプライアンスとハードウェア使用ポリシーの両方が遵守されていることを確認する知識を評価します。
重要な用語:
Taints and Tolerations: Kubernetesの重要なメカニズムで、Podが一致する容認を持っていない限り、ノードが一連のPodを撃退できるようにするもので、Podの配置を制御する方法を効果的に作成します。
NoSchedule: 一致する容認がない限り、ポッドがノードにスケジュールされないようにするテイントの影響。
正解解説:
(オプション)
・「compliant」ノードをfinancial-compliance: trueというラベルで汚染し、NoScheduleとエフェクトをNoScheduleで汚染し、機密性の高い金融取引に関与するPodでマッチング容認を構成する。
この選択は、目的のコンプライアンスを確保するために実用的です。ノードのテイントは、特定の容認を持つポッドを除いて、それらのノードでスケジュールできないことを保証します。「準拠」ノードでfinancial-compliance: trueとNoScheduleを設定することで、許容値が一致するPodのみがこれらのノードでスケジュールされます。このメソッドにより、両方のノードが準拠するPodに対して排他的であり、容認のないPodがこれらのノードから離れることが保証されます。
不正解の説明:
オプション: Podの仕様でnodeSelectorを使用して、financial-compliance: trueというラベルでフラグが立てられたノードをターゲットにします。
この選択が間違っている理由は、nodeSelectorは指定されたラベルを持つノードでPodがスケジュールされることを保証するだけで、他の非準拠のPodが同じノードでスケジュールされるのを防ぐものではないためです。
オプション: financial-compliance: trueというラベルでノードプールを指定し、Podセキュリティポリシーを適用して、このラベルでタグ付けされたノードでのみPodが実行されるように制限します。
この選択が間違っている理由は、適切なラベルを持つ特殊なノードプールは準拠ノードを追跡するのに役立ちますが、Podセキュリティポリシーは非推奨であり、非準拠のPodが同じノードでスケジューリングするのを防ぐことはできないためです。
オプション: 機密性の高い金融トランザクションを処理するすべてのPodを、「financial-transaction-compliant」というラベルの付いた名前空間に分離します。
この選択が間違っている理由は、Podを特定の名前空間に分離しても、Podがスケジュールされているノードが制限されないためです。名前空間は論理的なグループ化のためのものであり、スケジューリング ポリシーを強制するものではありません。
参考：
https://cloud.google.com/kubernetes-engine/docs/how-to/node-taints
https://cloud.google.com/kubernetes-engine/docs/concepts/pod-security-policies
https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
</div></details>

### Q.  問題46: 未回答
ある医療企業は、オンラインの患者ポータルを保護し、権限のないエンティティがドメインハイジャックによってサイトトラフィックを不正なWebサイトに再ルーティングするのを防ぎたいと考えています。
どの Google Cloud サービスを実装すべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Webサイトのトラフィック方向の完全性を脅かすドメインハイジャックなどの特定の攻撃ベクトルから保護するためにDNSに適用できるセキュリティ機能に関する知識を評価します。
重要な用語:
DNSセキュリティ拡張機能:DNSSECは、DNS解決プロセスに認証レイヤーを追加する高度なセキュリティ機能であり、デジタル署名を使用して、受信したDNS応答が本物であり、改ざんされていないことを確認します。
正解解説:
(オプション)
・DNSセキュリティ拡張
DNS Security Extensions(DNSSEC)は、デジタル署名ベースの認証でDNSを保護することで、ヘルスケア企業がドメインハイジャックを防ぐ方法を提供します。DNSSECを実装することで、DNSが提供するデータが転送中に変更されていないことが保証され、攻撃者がトラフィックを悪意のあるサイトに再ルーティングすることが非常に困難になります。DNSSECは、基本的なDNSプロトコルの上に信頼層を追加しますが、このプロトコルには、オンラインの患者ポータルを保護するために不可欠なDNSクエリ応答の操作から保護するためのセキュリティメカニズムが組み込まれていません。
不正解の説明:
オプション: VPC フローログ
VPC フローログが正しく選択されない理由は、VPC フローログが Google Cloud の仮想プライベートクラウド内のネットワークのモニタリング、ロギング、診断用に設計されているためです。疑わしいネットワークトラフィックを特定できる可能性はありますが、DNSハイジャックを防止したり、トラフィックが意図した宛先に誘導されたりすることはありません。
オプション:Cloud Armor
Cloud Armor が間違っている理由は、Cloud Armor が DDoS 保護やアプリケーションレベルの防御などのネットワーク セキュリティを提供するサービスであり、どちらもドメイン ハイジャックの問題に直接対処したり、DNS 解決の整合性を強化したりしないためです。
オプション:Identity-Aware Proxy
Identity-Aware Proxyが正しくない理由は、IAPがWebアプリケーションやVMへのアクセスを管理する方法であり、ID検証とコンテキストアウェアアクセスポリシーが必要であり、DNSの保護やドメインハイジャックからの保護とは関係がないためです。
参考：
https://cloud.google.com/dns/docs/dnssec
https://cloud.google.com/armor/docs/security-policy-concepts
https://cloud.google.com/iap/docs/concepts-overview
</div></details>

### Q.  問題49: 未回答
社内のデータ規制およびプライバシー部門の責任者は、コンプライアンスの目的で Google Cloud ロードバランサを通過する暗号化トラフィックの性質をよりよく理解するために、詳細な検査機能を必要としています。
このタスクには、どの Google Cloud サービスを使用しますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、規制とプライバシーのコンプライアンスのためにネットワーク内の暗号化されたトラフィックを分析するために、適切な Google Cloud サービスを選択する能力を評価します。このタスクは、ロードバランサーを通過するトラフィックの詳細な分析に必要な検査機能に焦点を当てています。
重要な用語:
Packet Mirroring:Packet Mirroringは、Virtual Private Cloud(VPC)内の指定されたインスタンスからネットワークトラフィックをコピーし、分析のために監視コレクターに転送する機能であり、ネットワークとセキュリティのフォレンジックを支援します。
暗号化トラフィック分析:暗号化トラフィック分析では、暗号化されたデータパケットのパターンとメタデータを検査して、トラフィックを復号化せずに潜在的な脅威やコンプライアンスの問題を検出します。
ロードバランサー:ロードバランサーは、ネットワークまたはアプリケーションのトラフィックを複数のサーバーに分散し、個々のサーバーの負荷を最小限に抑えることでサービスの可用性と信頼性を確保します。
コンプライアンス監視: コンプライアンス監視とは、特にデータの管理と保護において、法律、規制、およびポリシー要件へのコンプライアンスを体系的に追跡および管理するプロセスを指します。
正解解説:
(オプション)
・パケットミラーリング
この選択は、コンプライアンスとセキュリティ監視の目的で、暗号化されたパケットを含むネットワークトラフィックを可視化するのに適しています。Packet Mirroring は、トラフィックがロードバランサーに到達する前に、復号化を必要とせずに、Virtual Private Cloud (VPC) ネットワークレベルでトラフィックのコピーを作成します。これにより、トラフィックの検査、ネットワークパフォーマンスの監視、高度な分析ツールやフォレンジックツールを使用した悪意のあるアクティビティの検出が可能になり、データ規制およびプライバシー部門のニーズに応えることができます。
不正解の説明:
オプション:クラウドマーケットプレイス侵入防止システム
Cloud Marketplace Intrusion Prevention Systemsが正しくない理由は、ネットワークトラフィックを分析できますが、コンプライアンス監視のために通過するすべてのトラフィックの詳細な検査を提供するのではなく、サイバー脅威から保護するためのセキュリティサービスの提供に主眼を置いているためです。
オプション:仮想プライベートクラウドフローログ
Virtual Private Cloud フロー ログが正しくない理由は、VM インスタンスとの間で送受信されるネットワーク フローのサンプルを記録し、ネットワーク監視には役立ちますが、暗号化されたトラフィックの実際のコンテンツを検査する機能がないためです。
オプション: Virtual Private Cloud Service Controls 監査ログ
Virtual Private Cloud Service Controls 監査ログが正しくない理由は、監査ログが暗号化されたトラフィックを渡すリアルタイムの詳細な検査機能を提供するのではなく、VPC 内の管理アクティビティについて報告するためです。
オプション: Google Cloud Armor ペイロード インスペクション
Google Cloud Armor ペイロード インスペクションが正しくない理由は、ウェブベースの脅威から保護するために HTTP(S) ロード バランシング トラフィックのインスペクションを提供する一方で、暗号化されたネットワーク トラフィックの規制やコンプライアンスの詳細なインスペクションを容易にするようには設計されていないためです。
参考：
https://cloud.google.com/vpc/docs/using-packet-mirroring
https://cloud.google.com/vpc/docs/flow-logs
https://cloud.google.com/armor/docs/security-policy-overview
</div></details>

# 3
