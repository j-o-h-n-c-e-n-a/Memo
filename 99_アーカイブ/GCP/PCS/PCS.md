# 1
## 1

### Q.  問題6: 未回答
あなたのチームは、本番プロジェクトで稼働しているCompute EngineインスタンスがパブリックIPアドレスを持っていないことを確認したいと考えています。フロントエンドアプリケーションのCompute EngineインスタンスはパブリックIPを必要とします。プロダクトエンジニアは、リソースを変更するEditorロールを持っています。あなたのチームは、この要件を実施したいと考えています。
あなたのチームはどのようにこれらの要件を満たすべきですか？

1. 1つはパブリックIPを持つサブネット、もう1つはパブリックIPを持たないサブネットです
2. フロントエンドのCompute EngineインスタンスのパブリックIPのみを許可するように、組織ポリシーを設定します
3. Editorロールを削除し、エンジニアにCompute Admin IAMロールを付与します
4. 本番プロジェクトのVPCネットワークでプライベートアクセスを有効にします
<details><div>
    答え：2
この問題では、特定のCompute Engineインスタンスに対してのみパブリックIPアドレスを許可し、その他の場合では禁止する方法を考える必要があります。Compute Engineの扱いを理解して、公開しないようにするにはどうすればいいのか理解することが重要です。また、要件を達成するために組織ポリシーの設定が必要なことも理解しなければなりません。これにより、エンジニアがリソースを変更しながらも、フロントエンドのCompute Engineインスタンスが指定された要件を満たすことができるようになります。
基本的な概念や原則：
組織ポリシー：Google Cloudのリソースに対して一貫性のある管理を行えるようにするツールで、特定のリソースがどのように動作すべきかを定義します。
Compute Engineインスタンス：Google Cloudの仮想マシン（Virtual Machines）を指し、ユーザーはCompute Engineインスタンス上で自分のアプリケーションやウェブサイトを動作させることができます。
パブリックIP：インターネット上の任意の場所からアクセス可能なIPアドレス。Compute EngineのインスタンスにはパブリックIPを割り当てることができます。
VPCネットワーク：Virtual Private Cloud（VPC）ネットワークはGoogle Cloudの仮想ネットワークで、リソース（Compute Engineインスタンスなど）を論理的に分離し、ほかのネットワークから隔離します。
IAMロール：Google Cloud Identity and Access Management（IAM）のロールは特定の権限のセットで、ユーザーやサービスアカウントに割り当てることができます。ロールを使用して認可を行います。
サブネット：ネットワーク内の部分ネットワークで、ネットワークを独立したセグメントに分割する手段を提供します。一部がパブリックIPを持つ一方で、他部分はパブリックIPを持たないように設定することができます。
正解についての説明：
（選択肢）
・フロントエンドのCompute EngineインスタンスのパブリックIPのみを許可するように、組織ポリシーを設定します
この選択肢が正解の理由は以下の通りです。
組織ポリシーは、特定のリソースの使用を制限または制御するための仕組みであり、Google Cloudの特定の機能を許可または拒否することが可能です。この問題のシナリオでは、フロントエンドアプリケーションのCompute EngineインスタンスはパブリックIPを必要とする一方で、本番プロジェクトで稼働するCompute EngineインスタンスがパブリックIPを持っていないことを確認したいとの要件があります。この要件を満たすためには、パブリックIPをフロントエンドインスタンスだけに限定的に許可するように組織ポリシーを設定すれば良いのです。この方法により、プロダクトエンジニアがEditorロールを持っていても、許可されたインスタンス以外でパブリックIPを作成または使用することはできません。つまり、適切な組織ポリシーを設定することにより、要件通りの制御が可能となります。
不正解についての説明：
選択肢：本番プロジェクトのVPCネットワークでプライベートアクセスを有効にします
この選択肢が正しくない理由は以下の通りです。
本番プロジェクトのVPCネットワークでプライベートアクセスを有効化すると、パブリックIPなしでもGoogle Cloudサービスへアクセス可能になりますが、既存のCompute EngineインスタンスがパブリックIPを持っていないかの確認や、これ以上パブリックIPの追加を制限する機能はありません。一方正解の組織ポリシーを設定する方法で、特定のインスタンスのみパブリックIPの割り当てを許可するリソースを制御することが可能です。
選択肢：Editorロールを削除し、エンジニアにCompute Admin IAMロールを付与します
この選択肢が正しくない理由は以下の通りです。
Editorロールを削除し、エンジニアにCompute Admin IAMロールを付与しても、エンジニアはCompute EngineインスタンスにパブリックIPアドレスを持つ能力を引き続き持つため、問題の要件は満たせません。
逆に、組織ポリシーを設定することで、特定のCompute EngineインスタンスにパブリックIPの使用を制限することができます。
選択肢：1つはパブリックIPを持つサブネット、もう1つはパブリックIPを持たないサブネットです
この選択肢が正しくない理由は以下の通りです。
選択肢にあるサブネットを使った方法では、別々のサブネットに分けることでパブリックIPを制御しますが、それのみではEditorロールのエンジニアがリソース変更を防げません。
それに対して、組織ポリシーを使うとパブリックIPアドレスの許可制御をリソースレベルで強制し、適切なエンフォースメントが可能になります。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題7: 未回答
あなたは組織のCloud Identity管理者です。Google Cloud環境では、グループを使用してユーザー権限を管理します。各アプリケーションチームには専用のグループがあります。あなたのチームはこれらのグループを作成する責任を負い、アプリケーションチームはGoogle Cloudコンソールを使用してチームメンバーを自分で管理できます。アプリケーションチームが、組織内のユーザーのみをグループに追加できるようにする必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. Cloud IdentityログをBigQueryにエクスポートします。グループに追加された外部メンバーのアラートを設定します。アラートがCloud Functionsインスタンスをトリガーして、グループから外部メンバーを削除します
2. 組織に所属するユーザープリンシパルにグループメンバーシップを制限する条件を含むアイデンティティおよびアクセス管理（IAM）ポリシーを設定します
3. Google Workspace Adminコンソールで関連するグループの設定を変更し、外部ユーザーをグループに追加できないようにします
4. スコープ内のグループへの組織外のプリンシパルの割り当てを拒否する、アイデンティティおよびアクセス管理（IAM）拒否ポリシーを定義します
<details><div>
    答え：3
この問題では、Google Cloudの環境において、各アプリケーションチームが組織内のユーザーだけをそのグループに追加できるように制限する方法を求められています。管理者の視点から設定を考える必要があり、アプリケーションチームがGoogle Cloudコンソールを用いて自身のチームメンバーを管理できている点に注目します。不正解の選択肢には複数の方法がありますが、組織内のユーザーだけをグループに追加できるように制限する方法として最も効率的な選択肢を選びます。この問題ではGoogle Cloudの知識はもちろん、グループ管理や権限管理の基本的な理解も必要です。
基本的な概念や原則：
Google Workspace Adminコンソール：Google Workspaceの管理者がユーザーやグループの設定を管理するためのツールです。各グループのポリシーを制御し、外部ユーザーのアクセスを許可または拒否することができます。
Cloud Identity：Google CloudのIdentity and Access Management（IAM）サービスです。組織のユーザーやグループ、サービスアカウントの管理を行うことができます。
Google Cloudコンソール：Google Cloudの各サービスをグラフィカルなインターフェースから管理できるツールです。ユーザーやチームはここから資源を作成、設定、管理することができます。
アイデンティティおよびアクセス管理（IAM）ポリシー：Google Cloud内のリソースへのアクセス制御を行うことができる仕組みです。しかし、特定のプリンシパルのグループメンバーシップを直接制限することはできません。
拒否ポリシー：IAMにおいて、特定のプリンシパルに対するリソースアクセスを拒否するルールを作成するための機能です。しかし、これは個々のグループに対する機能ではなく、リソース全体に適用されます。
Cloud Functions：Google Cloudのサーバーレス実行環境です。イベント駆動のコードを実行するためのサービスで、ログの監視やアラートの設定などに利用できます。
BigQuery：Google Cloudの大規模データ分析サービスです。ログデータの長期保存やアドホックなクエリ分析に適していますが、リアルタイムのアクセス制御には向いていません。
正解についての説明：
（選択肢）
・Google Workspace Adminコンソールで関連するグループの設定を変更し、外部ユーザーをグループに追加できないようにします
この選択肢が正解の理由は以下の通りです。
まず、Google Workspace Adminコンソールは、アカウントの全体的な管理を行うためのツールであり、ここから各種設定変更を行います。身内のユーザーだけをグループに追加したい場合、グループの設定を変更して、外部のユーザーがグループに追加できないように制限することができます。これにより、アプリケーションチームが自分たちのチームを管理する際に、自社のユーザーのみを対象にすることが保証されます。それにより、不適切なアクセス許可の付与または意図しない共有を防ぐことができます。
したがって、Google Workspace Adminコンソールでグループ設定を変更することは、この要件を満たす最適な方法となります。
不正解についての説明：
選択肢：組織に所属するユーザープリンシパルにグループメンバーシップを制限する条件を含むアイデンティティおよびアクセス管理（IAM）ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
IAMポリシーはリソースアクセスの権限を制御する目的のためのもので、組織内のユーザーが特定のグループに追加されるのを制限する目的のためのものではありません。そのため、このシナリオで提案されている要件を満たすためには適切な選択肢ではありません。
選択肢：スコープ内のグループへの組織外のプリンシパルの割り当てを拒否する、アイデンティティおよびアクセス管理（IAM）拒否ポリシーを定義します
この選択肢が正しくない理由は以下の通りです。
IAM拒否ポリシーはソースから宛先へのリクエストを制御し、特定のリソースに対するアクセスを無効にします。しかし、これはグループへのメンバーの追加を制御するものではなく、このシナリオには適していません。
それに対して、Google Workspace Adminコンソールのグループ設定を変更することで、特定のグループに外部ユーザーを追加することを制限することができます。
選択肢：Cloud IdentityログをBigQueryにエクスポートします。グループに追加された外部メンバーのアラートを設定します。アラートがCloud Functionsインスタンスをトリガーして、グループから外部メンバーを削除します
この選択肢が正しくない理由は以下の通りです。
まず、この方法は対症療法であり、予防的ではありません。問題の発生を防ぐのではなく、問題が発生した後に対応します。
また、この選択肢は管理が複雑で、外部ユーザーが一時的にアクセスできる窓が開く可能性があります。正解の選択肢では、設定変更により予め不正操作を防いでいるため、より適切です。
参考リンク：
https://cloud.google.com/identity/docs/how-to/setup#creating-groups-for-your-organization
https://cloud.google.com/identity/docs/managing-groups
https://support.google.com/a/answer/167097?hl=en
</div></details>

### Q.  問題9: 未回答
Google Cloud APIにアクセスする必要があるオンプレミスのホストがあります。これらのホスト間のプライベート接続を強制し、コストを最小限に抑え、運用効率を最適化する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？

1. すべてのオンプレミスのトラフィックをIPsec VPNトンネル経由でGoogle Cloudにルーティングし、プライベートGoogleアクセスを有効にしたVPCに送信します
2. インターネットを通じて、オンプレミスとVPCのホスト間でVPCピアリングを設定します
3. ネットワーク経由でデータを送信する前に、Cloud Key Management Service（KMS）キーでデータを暗号化することをすべてのアプリケーションに義務付けるセキュリティポリシーを実施します
4. すべてのオンプレミスのトラフィックを、Cloud Interconnectまたはパートナーインターコネクトを経由して、プライベートGoogleアクセスが有効なVPCにGoogle Cloudにルーティングします
<details><div>
    答え：1
この問題では、オンプレミスのホストからGoogle Cloud APIにチャネルを通じて、プライベートにアクセスする方法が求められています。問題文から、プライバシーの強化、コスト削減、そして効率化が必須の要件となっています。そのため、適切なプライベート接続を設定し、トラフィックをルーティングするための最適なGoogle Cloudのサービスとその設定を選択することが求められます。これらの要件を考慮に入れ、実現可能な方法を選択肢から見つけることが重要です。
基本的な概念や原則：
IPsec VPNトンネル：オンプレミスのネットワークとGoogle Cloudのネットワークを安全に接続するための仮想プライベートネットワークです。
プライベートGoogleアクセス：VPCネットワークからGoogle CloudのAPIとサービスへのプライベートアクセスを提供します。パブリックインターネットを通さずにGoogleサービスに直接アクセスできます。
VPCピアリング：VPC間でネットワーク接続を直接設定し、ネットワークラウンドトリップディレイを分散させるサービスです。
Cloud Key Management Service：Google Cloudの暗号化キーの生成、使用、管理を提供するマネージドサービスです。しかし、ネットワーク層での暗号化を行いません。
Cloud Interconnect：Google Cloudとオンプレミスインフラストラクチャの間で専用のプライベート接続を提供するGoogle Cloudのサービスです。しかし、コストが発生します。
パートナーインターコネクト：サードパーティのサービスプロバイダーを経由してGoogle Cloudへの接続を提供するGoogle Cloudのサービスです。しかし、コストと運用効率に影響を与える可能性があります。
VPC：Google Cloudの仮想プライベートクラウド（VPC）は、Google Cloudリソースの論理的に隔離されたセクションを提供します。これによりユーザーは仮想ネットワークを定義できます。
正解についての説明：
（選択肢）
・すべてのオンプレミスのトラフィックをIPsec VPNトンネル経由でGoogle Cloudにルーティングし、プライベートGoogleアクセスを有効にしたVPCに送信します
この選択肢が正解の理由は以下の通りです。
まず、オンプレミスのホストからGoogle Cloud APIへのアクセスをプライベートな接続で強制するためには、VPNトンネルを利用するのが一般的です。IPsec VPNトンネルはオンプレミスとGoogle Cloud間に暗号化された通信経路を確立することが可能で、これによりデータの盗聴や改竄を防ぐことができます。
また、プライベートGoogleアクセスを有効にしたVPC（Virtual Private Cloud）にトラフィックを送信することで、Google Cloudの内部ネットワークを通じてGoogle APIに安全にアクセスすることが可能になります。これにより、パブリックインターネットを介さずにGoogle Cloudのリソースへのアクセスを保証することができ、セキュリティを強化することができます。
加えて、この方法はコストを最小限に抑える効果もあります。IPsec VPNは比較的低コストで設定・運用でき、プライベートGoogleアクセスを利用すればインターネット経由のデータ転送料を節約することができます。これらの要素が合わさり、運用効率を最適化する方法となります。
不正解についての説明：
選択肢：インターネットを通じて、オンプレミスとVPCのホスト間でVPCピアリングを設定します
この選択肢が正しくない理由は以下の通りです。
VPCピアリングはGoogle Cloud内のVPCネットワーク間での接続を可能にする機能であり、オンプレミス環境とVPC間の接続には使用できません。
それに対し、正解のIPsec VPNはオンプレミスとGoogle Cloud間の安全な接続を提供します。
選択肢：ネットワーク経由でデータを送信する前に、Cloud Key Management Service（KMS）キーでデータを暗号化することをすべてのアプリケーションに義務付けるセキュリティポリシーを実施します
この選択肢が正しくない理由は以下の通りです。
Cloud KMSを使用したデータの暗号化はセキュリティを強化する一方で、オンプレミスからGoogle Cloud APIへの接続をプライベートにすることは実現できません。
また、運用効率の最適化やコストの最小化にも寄与しないため、問題の要件を満たす解答とは言えません。
選択肢：すべてのオンプレミスのトラフィックを、Cloud Interconnectまたはパートナーインターコネクトを経由して、プライベートGoogleアクセスが有効なVPCにGoogle Cloudにルーティングします
この選択肢が正しくない理由は以下の通りです。
Cloud Interconnectやパートナーインターコネクトは、一度設定すれば堅牢な接続を提供しますが、その設定や維持にはそれなりの手間とコストがかかります。
一方、IPsec VPNトンネルは低コストで設定可能で、運用効率も高いため、このケースには最適です。
参考リンク：
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/vpn/docs/concepts/overview
https://cloud.google.com/vpc/docs/vpc-peering
</div></details>

### Q.  問題20: 未回答
あるアプリケーションをクラウドに移行しようとしています。アプリケーションはCloud Storageのバケットからデータを読み取る必要があります。現地の規制要件により、暗号化に使用するキーマテリアルを完全に管理下に置く必要があり、キーマテリアルにアクセスする正当な根拠が必要です。
この要件を満たすために、どうすればよいですか？

1. Cloud HSM（HSM）にバックアップされたカスタママネージド暗号化キーを使用して、Cloud Storageバケット内のデータを暗号化します。データアクセスログを有効にします
2. オンプレミス環境で鍵を生成し、オンプレミスで管理されているCloud HSM（HSM）に保管します。この鍵をCloud Key Management Service（KMS）の外部鍵として使用します。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムで不正アクセスを拒否するように設定します
3. Customer Managed Encryption Keysを使用してCloud Storageバケット内のデータを暗号化します。未承認グループに対してIAM拒否ポリシーを設定します
4. Cloud Storageバケットにデータをアップロードする前に、データを暗号化するキーをオンプレミス環境で生成します。鍵をCloud Key Management Service（KMS）にアップロードします。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムに不正アクセスを拒否させます

<details><div>
    答え：2
この問題では、アプリケーションがCloud Storageからデータを読取る際に、キーマテリアルを完全に管理下に置き、アクセスに正当性が必要という要件を満たす解決策を求められています。キーマテリアルの管理とアクセス正当性の確認の観点から考えると、オンプレミスで生成された鍵を使用し、Cloud HSMで保管し、アクセスが必要な場合は、Key Access Justificationsを有効にすることが考えられます。この観点を持つことにより、適切な解答を選択することが可能となります。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスです。データの永続性、可用性、耐久性を高めるために利用します。
Cloud HSM：Google Cloudの暗号化キーサービスです。Cloud HSM（HSM）を利用して暗号化キーの生成、管理を行います。
Cloud Key Management Service（KMS）：Google Cloudの暗号鍵管理サービスです。暗号鍵を作成、使用、管理、回転、破棄、復元するためのフルマネージドサービスです。
Key Access Justifications：Google Cloudの原理でアクセスの正当性を追跡し、承認するための機能です。この機能を有効にすると、キーにアクセスするたびにその合理的な理由が文書化されます。
Customer Managed Encryption Keys：顧客が自身で管理・制御するための暗号化キーのことです。これを利用することで、ユーザー自身で暗号キーのライフサイクルの管理を行うことができます。
IAM拒否ポリシー：特定のユーザーやグループが特定のリソースにアクセスすることを拒否するためのIAMの設定です。
データアクセスログ：ユーザーがデータに対して行った操作の詳細を記録したログです。データへのアクセスを監査・監視するために利用します。
正解についての説明：
（選択肢）
・オンプレミス環境で鍵を生成し、オンプレミスで管理されているCloud HSM（HSM）に保管します。この鍵をCloud Key Management Service（KMS）の外部鍵として使用します。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムで不正アクセスを拒否するように設定します
この選択肢が正解の理由は以下の通りです。
まず、要件では暗号化キーやキーマテリアルを完全に管理すること、そしてキーマテリアルにアクセスする正当な根拠が必要であると述べています。そのため、まずオンプレミスの環境で鍵を生成し、そしてCloud HSMに保管することで、鍵の生成と保管を完全に制御下に置くことができます。
更に、生成された鍵をCloud KMSの外部鍵として使用することで、クラウド環境とオンプレミス環境間で鍵の操作が可能となり、Cloud Storageからデータを読み取るというアプリケーションの要求も適切に満たすことができます。
最後に、Key Access Justifications（KAJ）を有効化することで、鍵へのアクセスに正当な根拠が必要となり、外部鍵管理システムで不正アクセスを拒否するよう設定することで、キーマテリアルへのアクセス制御もしっかりと行うことができます。
複合的に、これらの処置を講じることで、規制要件を満たすとともに、クラウド移行という動きにも適応できるため、この選択肢が最も適切です。
不正解についての説明：
選択肢：Customer Managed Encryption Keysを使用してCloud Storageバケット内のデータを暗号化します。未承認グループに対してIAM拒否ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
Customer Managed Encryption Keysを使用したとしても、完全なキーマテリアルの管理を実現することは難しいです。
また、Key Access Justifications（KAJ）は使用されておらず、これによりキーマテリアルへの正当なアクセス根拠の要件を満たすことができません。正解の選択肢では、オンプレミスで管理されたキーとKAJを使用して完全な鍵管理と正当なアクセス根拠を確保しています。
選択肢：Cloud Storageバケットにデータをアップロードする前に、データを暗号化するキーをオンプレミス環境で生成します。鍵をCloud Key Management Service（KMS）にアップロードします。Key Access Justifications（KAJ）を有効化し、外部鍵管理システムに不正アクセスを拒否させます
この選択肢が正しくない理由は以下の通りです。
現地の規制要件により、キーマテリアルを完全に管理下に置かなければならない状況で、鍵をCloud Key Management Service（KMS）にアップロードすると、鍵管理の完全なコントロールが喪失します。これに対して正解の選択肢では、鍵はオンプレミスのHSMで管理され、Cloud KMSは外部鍵としてそれを利用するだけになります。これが規制対策として相応しい選択となります。
選択肢：Cloud HSM（HSM）にバックアップされたカスタママネージド暗号化キーを使用して、Cloud Storageバケット内のデータを暗号化します。データアクセスログを有効にします
この選択肢が正しくない理由は以下の通りです。
Cloud HSMでバックアップされたカスタママネージド暗号化キーを使用すると、キーマテリアルの完全な管理が可能ですが、Key Access Justifications（KAJ）を用いたアクセス正当性の証明が利用できません。
正解の選択肢は、キーマテリアルの完全な管理とKAJを併用しているためより適しています。
参考リンク：
https://cloud.google.com/kms/docs/using-external-keys
https://cloud.google.com/storage/docs/encryption/using-customer-supplied-keys
https://cloud.google.com/kms/docs/key-access-justifications
</div></details>

### Q.  問題22: 未回答
あなたのチームは、ユーザーが組織内でプロジェクトを作成できないようにする必要があります。DevOpsチームだけが、要求者に代わってプロジェクトを作成できるようにする必要があります。
この要求を処理するために、あなたのチームはどの2つのタスクを実行する必要がありますか？（2つ選択）

1. 指定されたユーザーグループに、組織レベルでProject Editorロールを付与します
2. 組織レベルで、すべてのユーザーをProject Creatorロールから削除します
3. 指定されたDevOpsチームにBilling Account Creatorロールを付与します
4. 組織ポリシー制約を作成し、組織レベルで適用します
5. 組織レベルで、指定されたユーザーグループをProject Creatorロールに追加します
<details><div>
    答え：2,5
この問題では、プロジェクト作成の権限をDevOpsチームだけに絞り込むための適切な手段を理解しましょう。そのためには、アクセス制御とロールベースのアクセス制御（RBAC）についての理解が必要となります。組織内の全ユーザーからプロジェクト作成の権限を剥奪し、それを特定のユーザーグループ（この場合DevOpsチーム）だけに付与するという要求を満たすための適切なタスクを選択肢の中から選ぶ必要があります。
基本的な概念や原則：
Project Creatorロール：Google Cloud上で新たにプロジェクトを作成する権限を持つロールです。このロールを削除することで、特定のユーザーがプロジェクトを作成する能力を制限することができます。
組織レベルのIAMポリシー：全体の組織に対して権限を制御する仕組みです。特定のユーザーやグループに対して、Project Creatorロールなどの特定のロールを追加したり削除したりすることができます。
組織ポリシー：特定のGoogle Cloudリソースに対するアクセスや操作を管理するための仕組みです。しかし、このケースの要件（プロジェクト作成の制限）はIAMポリシーを通じて実現するほうが適切です。
Project Editorロール：既存のプロジェクトに対する全てのAPIの読み書き操作を許可するロールです。しかし、このケースでは新規プロジェクトの作成を制限するためには関連性がありません。
Billing Account Creatorロール：新たに課金アカウントを作成する権限を付与するロールですが、プロジェクト作成の制限とは直接関連がありません。
正解についての説明：
（選択肢）
・組織レベルで、すべてのユーザーをProject Creatorロールから削除します
・組織レベルで、指定されたユーザーグループをProject Creatorロールに追加します
この選択肢が正解の理由は以下の通りです。
まず、"組織レベルで、すべてのユーザーをProject Creatorロールから削除します"は適切です。これにより、基本的にはユーザーはプロジェクトの作成ができなくなります。これが問題の要求を満たしていることは明白です。
次に、"組織レベルで、指定されたユーザーグループをProject Creatorロールに追加します"も反対に、特定のユーザーグループ（この場合、DevOpsチーム）だけがプロジェクトを作成できるようにします。それは彼らがProject Creatorのロールを持つためです。これによってDevOpsチームだけが要求者に代わってプロジェクトを作成でき、問題の制約を満たしています。
よって、これら二つのタスクを組み合わせることで、問題で求められている条件を満たすことができます。これが適切な選択肢である理由です。
不正解についての説明：
選択肢：組織ポリシー制約を作成し、組織レベルで適用します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約を作成し、組織レベルで適用することはプロジェクトの作成防止に直接貢献しません。適切なアクションは、全てのユーザーをProject Creatorロールから削除し、特定のユーザーグループをProject Creatorロールに追加することで、プロジェクトの作成を制限します。
選択肢：指定されたユーザーグループに、組織レベルでProject Editorロールを付与します
この選択肢が正しくない理由は以下の通りです。
Project Editorロールはプロジェクトにリソースを追加、削除、変更する権限を持つが、新しいプロジェクトを作成する権限は含まれていません。この課題を解決するためには、Project Creatorロールを適切なユーザーグループに付与する必要があります。
選択肢：指定されたDevOpsチームにBilling Account Creatorロールを付与します
この選択肢が正しくない理由は以下の通りです。
Billing Account Creatorロールは、請求アカウントを作成する権限を与えるものであり、プロジェクトを作成する権限は含まれません。本問題の目的は、特定のユーザーグループだけがプロジェクトを作成できるように制限することであり、Billing Account Creatorロールの付与はその目的に対して効果的ではありません。
参考リンク：
https://cloud.google.com/resource-manager/docs/access-control-proj
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/resource-manager/docs/organization-policy/creating-managing-policies
</div></details>

### Q.  問題41: 未回答
個人を特定できる情報（PII）を含む機密性の高いBigQueryワークロードがあり、インターネットからアクセスできないようにしたいと考えています。データの流出を防ぐため、許可されたIPアドレスからのリクエストのみBigQueryテーブルへのクエリを許可する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. サービス境界を使用し、認可されたソースIPアドレスを条件としてアクセスレベルを作成します
2. Cloud Data Loss Prevention（DLP）とともに、リソースサービス利用制限組織ポリシー制約を使用します
3. グローバルHTTPSロードバランサーで、許可されたIPアドレスの許可リストを定義するGoogle Cloud Armorセキュリティポリシーを使用します
4. Cloud Data Loss Prevention（DLP）と共に、許可されたGoogle CloudAPIとサービスの組織ポリシー制約を使用します
<details><div>
    答え：1
この問題では、機密な情報を含むBigQueryワークロードのアクセス制御をどのように行うかということが問われています。特に、指定したIPアドレスからのリクエストのみを許可するという要件に重点を置くべきです。これにより、選択肢に含まれる各ツールやサービスがこの特定の要件に対してどのように対応できるかを理解し、最適な解決策を選択することが求められます。
基本的な概念や原則：
サービス境界：Google Cloudにおけるネットワークセキュリティ機能の一つで、特定のサービスへのアクセスを制限する機能です。境界を設定することで、特定のソースからの接続を制限したり、許可するIPアドレスを指定したりすることができます。
アクセスレベル：サービス境界の条件の一つで、指定されたIPアドレスや範囲からのリクエストを許可したり、特定のユーザーエージェントを必要としたりする状態を定義します。
Google Cloud Armor：Google Cloudのセキュリティサービスの一つで、グローバルHTTPSロードバランサーに対してセキュリティポリシーを適用する機能があります。しかし、BigQueryの制限には適していません。
Cloud Data Loss Prevention（DLP）：機密情報を特定、マスク、匿名化するためのツールです。PIIの保護には有用ですが、IPアドレスに基づいたアクセス制御には使用できません。
リソースサービス利用制限組織ポリシー制約：特定のサービスリソースの使用を制限するポリシーです。サービスの利用自体を制御しますが、IPアドレスに基づいたアクセス制御には使用できません。
正解についての説明：
（選択肢）
・サービス境界を使用し、認可されたソースIPアドレスを条件としてアクセスレベルを作成します
この選択肢が正解の理由は以下の通りです。
サービス境界は、Google Cloud上の特定のリソースへのネットワークアクセスを制御するためのポリシーベースのツールで、これにより各リソースへのアクセスを厳密に制御することが可能です。設問では、特定のIPアドレスからのアクセスのみBigQueryテーブルへのクエリを許可するような要求があったため、サービス境界を使用して、許可されたソースIPアドレスを条件としてアクセスレベルを作成することで、これを実現することができます。
また、サービス境界は、ネットワークとデータのセキュリティを強化するツールでもあります。BigQueryでは、PIIなどの機密性の高い情報を扱う場合、データの流出を防ぐための強固なセキュリティ対策が必要となります。この選択肢は、そのようなセキュリティ要件を確実に満たすための適切な解決策を示しています。
不正解についての説明：
選択肢：グローバルHTTPSロードバランサーで、許可されたIPアドレスの許可リストを定義するGoogle Cloud Armorセキュリティポリシーを使用します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは主にHTTP(S)負荷分散のトラフィックに対するセキュリティの提供に使用され、BigQueryサービス（非HTTP(S)ベース）へのアクセス制御には適していません。
一方、サービス境界は特定のサービスに対し制限を設ける能力があるため、正解となります。
選択肢：Cloud Data Loss Prevention（DLP）とともに、リソースサービス利用制限組織ポリシー制約を使用します
この選択肢が正しくない理由は以下の通りです。
Cloud Data Loss Preventionは、データを保護し情報漏洩を防止するためのサービスですが、特定のIPアドレスからのリクエストだけを許可する機能は提供していません。
一方、サービス境界を使用しアクセスレベルを作成することで、認可されたソースIPアドレスからのみのアクセスを制限することが可能です。
選択肢：Cloud Data Loss Prevention（DLP）と共に、許可されたGoogle CloudAPIとサービスの組織ポリシー制約を使用します
この選択肢が正しくない理由は以下の通りです。
Cloud DLPと組織ポリシー制約はデータの流出や不適切なパブリックアクセスを防ぐためのツールではありますが、指定したIPアドレスからのリクエストだけを許可することは出来ません。
それに対して、サービス境界とアクセスレベルを使用すれば、許可したIPアドレスからのアクセスのみを許可することができます。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/create-manage-service-perimeters
https://cloud.google.com/access-context-manager/docs/overview
https://cloud.google.com/bigquery/docs/controlled-access
</div></details>

### Q.  問題42: 未回答
オンプレミス環境からBigQueryデータセットへの日々のETLプロセスにおいて、個人を特定できる機密情報（PII）がGoogle Cloud環境にインジェストされていることが判明しました。このデータを冗長化してPIIを難読化する必要がありますが、データ分析の目的で再識別化する必要があります。
どのコンポーネントをソリューションに使用するべきですか？（2つ選択）
1. 自動テキスト再編集機能を備えたCloud Data Loss Prevention
2. Cloud Key Management Service
3. Secret Manager
4. AES-SIVを用いた決定論的暗号化によるCloud Data Loss Prevention
5. 暗号ハッシュによるCloud Data Loss Prevention
<details><div>
    答え：2,4
この問題では、PII（特定可能な個人情報）の取り扱いを問われています。PIIは一度難読化（暗号化）が必要であり、同時に再識別化（復号化）も可能でなければなりません。その上で、適切なGoogle Cloudの機能やサービスを選択することが必要です。問題は2つの答えを求めており、選択肢にはCloud Key Management Service、Cloud Data Loss Preventionなど複数のサービスが提示されています。個々の選択肢が提供するサービスや機能を理解し、問題の要求を満たすものを選ぶことが求められます。
基本的な概念や原則：
Cloud Key Management Service：暗号キーを作成、使用、管理し、アクセスを制御するGoogle Cloudのインフラストラクチャです。キーのライフサイクルを管理する機能やキーのバージョニングを提供します。
決定論的暗号化：同じ平文が常に同じ暗号文になるような暗号方式です。個人を識別できる情報などを確実に難読化し、維持することができます。
Personal Identifiable Information（PII）：個々の人物を特定できる情報のことを指します。名前やメールアドレスなどが該当します。
Cloud Data Loss Prevention：機密データの検出、分類、保護を自動化するためのサービスです。暗号化や変換などを行ってデータの保護を支援します。
AES-SIV（Authenticated Encryption with Associated Data - Synthetic Initialization Vector）：暗号化とメッセージ認証コード生成を一度に行う暗号化方式の一つです。再識別が可能な暗号化を提供します。
正解についての説明：
（選択肢）
・Cloud Key Management Service
・AES-SIVを用いた決定論的暗号化によるCloud Data Loss Prevention
この選択肢が正解の理由は以下の通りです。
まず、Cloud Key Management Service（KMS）は、Google Cloud環境での暗号鍵の管理を容易にするためのサービスです。具体的には、暗号鍵の生成、使用、ローテーション、削除などを管理できます。これにより、データの冗長化などのセキュリティ上の要求を満たすことができます。
また、Google Cloudのデータ損失防止（DLP）APIは、個人を特定できる情報（PII）を自動的に検出、分類、難読化する機能を提供します。
そして、DLP APIはAES-SIVを使用した決定論的暗号化をサポートしており、同一の入力に対して常に同じ暗号文を生成します。これにより、データ分析を行う際に同じデータを再識別化することが可能になります。つまり、DLP APIのAES-SIVを使用した決定論的暗号化は、このケースの需要に適しています。
したがって、PIIを難読化しつつ、データ分析の目的で再識別化するためには、Cloud KMSとCloud DLPのAES-SIVを使用した決定論的暗号化の組み合わせが最適です。
不正解についての説明：
選択肢：Secret Manager
この選択肢が正しくない理由は以下の通りです。
Secret Managerは秘密情報の保存・管理を行うサービスであり、データの暗号化や難読化には使えません。
それに対して、Cloud Key Management Serviceは鍵の管理を、Cloud Data Loss PreventionはPIIの保護を行うため、このケースに適しています。
選択肢：暗号ハッシュによるCloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュによるCloud Data Loss Preventionはデータを難読化しますが一度ハッシュ化された情報は元に戻すことが出来ません。そのため再識別化が必要という要件を満たすことができません。
それに対して、AES-SIVを用いた決定論的暗号化は、一貫した暗号テキストを生成しつつ元の情報に戻すことが可能なため要件を満たします。
選択肢：自動テキスト再編集機能を備えたCloud Data Loss Prevention
この選択肢が正しくない理由は以下の通りです。
自動テキスト再編集機能を備えたCloud Data Loss Preventionは、機密情報を難読化するのに有用ですが、問題の要求である"データ分析の目的で再識別化する必要がある"という条件に合致しません。再編集したデータの再識別化はできません。
一方、AES-SIVを用いた決定論的暗号化は再識別が可能なため、この要件に適しています。
参考リンク：
https://cloud.google.com/kms
https://cloud.google.com/dlp/docs/concepts-deidentification#de-identification_in_the_dlp_api
</div></details>


## 2

### Q.  問題5: 未回答
あなたは、GDPRの要件に従って、設計によるデータ保護を実装しています。設計レビューの一環として、Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Subのワークロードを含むソリューションの暗号化キーを管理する必要があると言われました。
この実装では、どのオプションを選択すべきですか？
1. Cloud External Key Manager
2. 顧客管理の暗号化キー
3. 顧客指定の暗号化キー
4. Googleのデフォルト暗号化
<details><div>
    答え：1
この問題では、データ保護を実装する場面での暗号化キーの管理について読み解く必要があります。特にEUのGDPR要件に適合させることが重要な点で、Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Subのワークロードを含むソリューションに対して、どの暗号化キー管理オプションを選ぶべきかが問われています。ここでは、各選択肢が提供する暗号化キーの管理方法と、それがGDPR要件にどのように適合するかを理解することが重要です。
基本的な概念や原則：
Cloud External Key Manager：Google Cloudリソースへのアクセスの認証に使う暗号化キーを、Google Cloud外部で管理することが可能なサービスです。GDPRの要件など、特定の規制要件に対応が必要な場合に用いられます。
GDPR（General Data Protection Regulation）：EU圏の市民のデータを保護することを目的とした法律です。設計によるデータ保護（Privacy by Design）はこの中で求められる要件の一つです。
Privacy by Design：プロダクトやサービスの設計段階からプライバシー保護を取り入れるアプローチです。つまり、事前に、そしてデフォルトでプライバシーが保護されるような設計を行います。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。データの暗号化キーについては、Cloud External Key Managerを利用して管理することが可能です。
Google Kubernetes Engine：Google Cloudでコンテナのオーケストレーションを行うためのマネージドサービスです。こちらも暗号化キーの管理には、Cloud External Key Managerを利用することが可能です。
Cloud Storage：大規模なデータをストレージとして保存、取得できるGoogle Cloudのサービスです。データの暗号化キーについては、Cloud External Key Managerを использовать для управления。
BigQuery：大規模なデータ分析を行うGoogle Cloudのフルマネージドサービスです。データの暗号化キーについては、Cloud External Key Managerを использовать для управления。
正解についての説明：
（選択肢）
・Cloud External Key Manager
この選択肢が正解の理由は以下の通りです。
Google CloudのExternal Key Managerは、Google Cloudの資源上で暗号化されたデータのキーを外部で管理することを可能にします。これは、GDPRのような特定の規制に対処するための設計によるデータ保護を実現する上で非常に重要です。各種ワークロードに適用可能であり、Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Sub等が該当します。
External Key Managerは組織がGoogle Cloudに保存されているデータの暗号化キーを自身で制御でき、自身のデータセンター、オンプレミスデバイス、またはその他のクラウドプロバイダをキーストレージとして使用することが可能です。
External Key Managerと共に適切なアクセスポリシーを組み合わせることで、組織は自身のGDPRの要件を満たすための暗号化キーの管理を実現でき、データ保護を強化することができます。このような理由から、Cloud External Key Managerは適切な選択とされます。
不正解についての説明：
選択肢：顧客管理の暗号化キー
この選択肢が正しくない理由は以下の通りです。
"顧客管理の暗号化キー"だけでは、あいまいかつ明らかなサービスや手段を指していないため不適切です。
それに対して、Cloud External Key ManagerはGoogle Cloudで提供される明確なサービスであり、これを使うことでCompute Engine、GKE、Cloud Storage、BigQuery、Pub/Subなどのワークロードの暗号化キーを一元的に管理することが可能です。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キーは特定のサービス（Cloud Storageなど）でしか利用できません。
一方、Cloud External Key ManagerはCompute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、およびPub/Subといった複数のサービスに対応しており、より広範な暗号化キー管理が可能です。
選択肢：Googleのデフォルト暗号化
この選択肢が正しくない理由は以下の通りです。
Googleのデフォルト暗号化は、Googleが全ての管理を行うため、使用者自身が暗号化キーを管理することができません。これではGDPRの要件を満たすことが難しくなります。
一方、Cloud External Key Managerは、キーの管理を使用者自身が行えるため、GDPRの要件を満たすことが可能です。
参考リンク：
https://cloud.google.com/security-key-management
https://cloud.google.com/kms/docs/ekm
https://cloud.google.com/compute/docs/disks/customer-managed-encryption
</div></details>

### Q.  問題13: 未回答
あなたはセキュリティチームの一員で、漏洩したサービスアカウントキーを調査しています。あなたは、どの新しいリソースがサービスアカウントによって作成されたかを監査する必要があります。
この要件を満たすために、どうすればよいですか？
1. 管理者のアクティビティログを照会します
2. Access Transparencyのログを照会します
3. データアクセスのログを照会します
4. Google Cloud Operation Suite監視ワークスペースに問い合わせます
<details><div>
    答え：1
この問題では、特定のセキュリティ上の課題、つまりサービスアカウントキーの漏洩を調査する方法について問われています。具体的には、漏洩したサービスアカウントキーを用いて作成された新しいリソースを特定したいという状況です。したがって、サービスアカウントによるリソースの作成というアクションをトラッキング可能なGoogle Cloudの機能を選択肢から選ぶことが必要です。選択肢を見たときには、それぞれの特性と、それが特定のアクションをトラッキングできるかどうかを考慮することが重要です。
基本的な概念や原則：
管理者のアクティビティログ：Google Cloudにおける管理者の操作を記録するログです。サービスアカウントによって新しく作成されたリソースの監査に使用します。
データアクセスログ：Google Cloudのサービスがユーザーデータにアクセスする際の情報を記録するログです。サービスアカウントがリソースにアクセスしたデータの追跡に使われますが、新しいリソースの作成には使用しません。
Access Transparencyログ：Googleのサポートやエンジニアリングチームがユーザーデータにアクセスした際の詳細情報を提供するログです。Googleの職員が行った操作の可視化に使用します。
Google Cloud Operation Suite：ログ管理、監視、トレーシングなどの機能を提供するツールセットです。しかし、特定のサービスアカウントによって新しく作成されたリソースの監査には適していません。
正解についての説明：
（選択肢）
・管理者のアクティビティログを照会します
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、管理者のアクティビティログという監査ログが提供されています。これはGoogle Cloud内のリソースに対する管理操作（作成や削除など）の詳細情報を記録します。そのため、サービスアカウントによってどのような新リソースが作成されたかを知りたい場合、管理者のアクティビティログを照会することで、それぞれの操作に対する詳細な情報を取得することが可能です。
また、活動ログはリソースを作成したユーザーやサービスアカウント、リソースの詳細、タイムスタンプなどのデータを提供します。これにより、特定のアカウントによって行われた操作の追跡や、何がいつ何によって変更されたのかを監査することが可能になります。
したがって、サービスアカウントキーの漏洩を調査し、新しいリソースの作成を監査する要件を満たすためには、管理者のアクティビティログの照会が効果的です。
不正解についての説明：
選択肢：データアクセスのログを照会します
この選択肢が正しくない理由は以下の通りです。
データアクセスのログは、Google Cloudのリソースに対する読み取りまたは書き込み操作を記録しますが、新しいリソースがサービスアカウントによって作成されたかどうかを追跡するためには不十分です。
対照的に、管理者のアクティビティログはCloudの管理活動、つまり、リソースの作成や変更などを追跡します。そのため、正確な監査には管理者のアクティビティログの照会が必要です。
選択肢：Access Transparencyのログを照会します
この選択肢が正しくない理由は以下の通りです。
Access TransparencyのログはGoogleの管理者によるアクセスを記録するためのもので、サービスアカウントによって新しく作成されたリソースの監査に用いるものではありません。この要件を満たすには、管理者のアクティビティログを照会することで、サービスアカウントによるリソースの操作をトレースできます。
選択肢：Google Cloud Operation Suite監視ワークスペースに問い合わせます
この選択肢が正しくない理由は以下の通りです。
Google Cloud Operation Suite監視ワークスペースは主にインフラストラクチャの動作状況を監視しアラートを管理するためのツールであり、特定のサービスアカウントによって作成されたリソースの監査には対応していません。ただし、管理者のアクティビティログはGoogle Cloud上のあらゆる管理活動を監視、記録するため、サービスアカウントによるリソースの作成活動を照会するのに最も適しています。
参考リンク：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/logging/docs/audit/configure-data-access
</div></details>

### Q.  問題26: 未回答
あなたの所属するDevOpsチームはPackerを使用して、次のプロセスでCompute Engineイメージを構築します。
a. 一時的なCompute Engine VMを作成します。
b. Cloud StorageバケットからVMのファイルシステムにバイナリをコピーします。
c. VMのパッケージマネージャーを更新します。
d. 外部パッケージをインターネットからVMにインストールします。
セキュリティチームは、VM上のパブリックIPアドレスの使用を制限するために、組織ポリシーのconstraints/compute.vmExternalIpAccessを有効にしました。これに応じて、DevOpsチームはスクリプトを更新して、Compute Engine VM上のパブリックIPアドレスを削除しました。ただし、接続の問題によりビルドパイプラインが失敗します。
この要件を満たすために、どうすればよいですか？（2つ選択）

1. Compute EngineVMと同じVPCおよびリージョンに、Cloud VPNトンネルをプロビジョニングします
2. インターネットからVMへのインバウンド接続を許可するために、アンマネージドインスタンスグループ内のVMでHTTPロードバランサーをプロビジョニングします
3. Compute Engine VMがデプロイされているサブネットで、プライベートGoogleアクセスを有効にします
4. Compute Engine VMと同じVPCおよびリージョンにCloud NATインスタンスをプロビジョニングします
5. VPCルートを更新して、インターネットとのトラフィックを許可します
<details><div>
    答え：3,4
この問題では、組織ポリシーで設定した外部IPアドレスへのアクセス制限により、ビルドプロセスが失敗してしまうDevOpsチームの対応策が求められています。ポイントとなるのは、パブリックIPへのアクセスを許可せずに、依然として外部からのパッケージインストールやCloud Storageバケットからのファイル転送などを維持する方法です。そのため、private IPを活用した接続手順や設定の確認、またNATやプライベートGoogleアクセスなどの機能を適切に利用することが重要となります。解答を選択する際は、これらの要素を理解し、各選択肢が提供する機能やその影響をきちんと評価することが求められます。
基本的な概念や原則：
Cloud NAT：Google CloudのマネージドNATサービスで、プライベートインターネットアクセスを提供します。特に、VPC内でのパブリックIPアドレスの使用を制限する場合に使用されます。
プライベートGoogleアクセス：Google Cloudサービスへのインターネットアクセスが制限されたインスタンスに対して、非公開IPアドレスを使用してGoogle Cloud APIとサービスにアクセスする機能です。
VPC：Google Cloudの仮想プライベートクラウド（VPC）ネットワークを構築、展開してホストするサービスで、プロジェクトのVMインスタンスに冗長性と規模の拡張性を提供します。
組織ポリシー：組織レベルで設定可能な制限や制約のことで、セキュリティ強化やコンプライアンスのために使用されます。
Packer：オープンソースのツールで、複数のプラットフォームに対するイメージを自動化的に作成します。スクリプトを用いて、一貫性のあるイメージ作成手順を定義することができます。
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、安全に大量のデータを保存し、世界中からアクセスすることができます。
正解についての説明：
（選択肢）
・Compute Engine VMと同じVPCおよびリージョンにCloud NATインスタンスをプロビジョニングします
・Compute Engine VMがデプロイされているサブネットで、プライベートGoogleアクセスを有効にします
この選択肢が正解の理由は以下の通りです。
まず、組織ポリシーでパブリックIPの使用を制限した場合、Compute Engine VMからインターネットへの直接的な接続ができなくなります。ここでCloud NATをプロビジョニングするという選択肢が有効となります。Cloud NATを使うと、Compute Engine VMがVPC内部から外部のインターネットに接続できるようになります。これにより、VMからの外部パッケージのインストールなどが可能となり、ビルドパイプラインが正常に動作するようになります。
次に、VMがデプロイされているサブネットでプライベートGoogleアクセスを有効にすることにより、VMは外部IPアドレスを持たないままでもGoogle Cloudのサービス（Cloud Storageなど）に接続できます。これにより、Cloud Storageバケットからのバイナリのコピーが失敗することなく実行できます。これら二点により、パブリックIPアドレスを使用することなく、ビルドパイプラインが問題なく実行できるようになります。
不正解についての説明：
選択肢：インターネットからVMへのインバウンド接続を許可するために、アンマネージドインスタンスグループ内のVMでHTTPロードバランサーをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
HTTPロードバランサーをプロビジョニングすることは、インターネットからのインバウンド接続を許可するものではありません。
また、この問題の要件は、VMからインターネットにアウトバウンド接続を行うことで、パブリックIPアドレスを使用せずにインターネットにパッケージをインストールすることです。これは、ロードバランサーでは解決できません。
選択肢：VPCルートを更新して、インターネットとのトラフィックを許可します
この選択肢が正しくない理由は以下の通りです。
VPCルートの更新は、パブリックIPアドレスがない場合でもインターネットと通信するための解決策ではありません。インターネットとの通信を許可するだけで、VMから外部パッケージをダウンロードできるようにはならず、要件とマッチしません。
選択肢：Compute EngineVMと同じVPCおよびリージョンに、Cloud VPNトンネルをプロビジョニングします
この選択肢が正しくない理由は以下の通りです。
Cloud VPNトンネルは、異なるネットワーク間の安全な接続を提供します。ただし、この問題はパブリックインターネットへの接続を解決する必要がありますし、Cloud VPNではその解決に不適で、Compute Engine VMが必要とするアクセスを提供しません。
それに対して、Cloud NATとプライベートGoogleアクセスはパブリックIP無しで外部パッケージをインターネットからインストールするための適切な解決策です。
参考リンク：
https://cloud.google.com/nat/docs/using-nat
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/compute/docs/ip-addresses#externaladdresses
</div></details>

### Q.  問題30: 未回答
セキュリティチームがファイアウォールルールなどのネットワークリソースを制御できるように、VPCを作成する必要があります。
ネットワークリソースの職務を分離できるようにするために、ネットワークをどのように構成すればよいですか？
1. セキュリティチームがファイアウォールルールを管理する共有VPCを設定し、サービスプロジェクトを通じて開発者とネットワークを共有します
2. 複数のVPCネットワークを設定し、ネットワークを接続するためにマルチNIC仮想アプライアンスを設定します
3. VPCネットワークピアリングを設定し、開発者が共有VPCとネットワークをピアリングできるようにします
4. プロジェクトにVPCを設定します。Compute Network Adminロールをセキュリティチームに割り当て、 Compute Adminロールを開発者に割り当てます
<details><div>
    答え：1
この問題では、ネットワークリソースに対する職務分離を達成するための最適な構成について考える必要があります。特に、セキュリティチームがネットワークリソースを制御でき、それと共に開発者もネットワークに対する作業が可能であるという要件に注目してください。選択肢を検討する際には、これらの要件を満たしつつ、適切な分離と管理が行える構成を選択することが求められます。
基本的な概念や原則：
共有VPC：Google Cloudの機能で、1つの "ホストプロジェクト" 内にVPCネットワークを作成し、同じGoogleCloudオーガニゼーション内の他の "サービスプロジェクト" とそのVPCネットワークを共有します。ファイアウォールルールやネットワークルーティングなどの中央管理を可能にします。
職務分離：セキュリティのベストプラクティスです。特定の任務や機能を複数の個々に分けることで、フラウドやエラーを防止します。
VPCネットワークピアリング：異なるVPCネットワーク間でトラフィックを私的に交換するための接続を設定する機能です。それらのネットワークは同じプロジェクト、または異なるプロジェクト内にあることができます。
マルチNIC仮想アプライアンス：複数のネットワークインターフェースカード（NIC）を備えた、特定のネットワーク機能（ファイアウォール、ロードバランサーなど）を提供するための仮想アプライアンスです。
Compute Network Adminロール：VPCリソースを含むネットワークリソースの管理を担当します。
Compute Adminロール：Compute Engineのリソース全体を管理します。
正解についての説明：
（選択肢）
・セキュリティチームがファイアウォールルールを管理する共有VPCを設定し、サービスプロジェクトを通じて開発者とネットワークを共有します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの共有VPCはネットワークリソースを複数のプロジェクト間で共有したい場合に有効な機能です。共有VPCを使用することで、一つのプロジェクト（この場合はセキュリティチームのプロジェクト）がネットワーク（例えばVPC内のサブネットやファイアウォールルール）を所有・管理し、そのネットワークの一部分を他のプロジェクト（例えば開発者のプロジェクト）に共有することが可能になります。ファイアウォールルールなどのネットワークリソースをセキュリティチームが一元的に管理できる一方で、開発者はそのネットワーク内で自身のアプリやサービスを動作させることができます。
また、職務分離も実現可能で、それぞれが必要なリソースに対する適切な権限を持つことができます。
したがって、これらの要件を見たとき、共有VPCを用いてVPCを設定し、サービスプロジェクトを通じて開発者とネットワークを共有することは最適な解決方法といえます。
不正解についての説明：
選択肢：複数のVPCネットワークを設定し、ネットワークを接続するためにマルチNIC仮想アプライアンスを設定します
この選択肢が正しくない理由は以下の通りです。
まず、複数のVPCネットワークとマルチNIC仮想アプライアンスを設定する方法は、リソースの分離と管理を行うための効果的な方法ではありません。仮想アプライアンスは通常、特定のネットワーク機能を提供するために使用されますが、ネットワークリソースの職務を分離するための効果的な手段とは言えません。
一方、共有VPCを設定することで、セキュリティチームがファイアウォールルールを一元的に管理し、開発者はそれを活用します。これにより正確な職務の分離が実現可能です。
選択肢：VPCネットワークピアリングを設定し、開発者が共有VPCとネットワークをピアリングできるようにします
この選択肢が正しくない理由は以下の通りです。
VPCネットワークピアリングを設定すると、各VPCが等しくネットワークリソースを制御でき、職務分離する目的に合致しません。
一方、共有VPCを設定すると、セキュリティチームがVPCの管理と制御を行い、開発者のプロジェクトとネットワークを明確に分けられます。
選択肢：プロジェクトにVPCを設定します。Compute Network Adminロールをセキュリティチームに割り当て、 Compute Adminロールを開発者に割り当てます
この選択肢が正しくない理由は以下の通りです。
VPCを各プロジェクトに設定し、Compute Network Adminロールをセキュリティチームに、Compute Adminロールを開発者に割り当てると、職務分離が上手く行われません。なぜなら、Compute Adminロールはファイアウォールルールを含むネットワークリソースの変更が許可されてしまうからです。
それに対して、共有VPCではネットワークリソースを制御できるのはセキュリティチームだけであり、職務分離を達成できます。
参考リンク：
https://cloud.google.com/vpc/docs/shared-vpc
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/vpc/docs/provisioning-shared-vpc
</div></details>

### Q.  問題43: 未回答
ある顧客が他社と共同でCompute Engine上にアプリケーションを構築しています。顧客は自社のGoogle Cloudの組織でアプリケーション層を構築し、他社は別のGoogle Cloudの組織でストレージ層を構築しています。これは3層のウェブアプリケーションです。アプリケーションの各部分間の通信は、どのような通信経路であっても公共のインターネットを通過してはなりません。
どの接続オプションを実装すべきですか？
1. VPCピアリング
2. Cloud VPN
3. Cloud Interconnect
4. 共有VPC
<details><div>
    答え：1
この問題は、Google Cloudの接続オプションに対する理解度を試している問題です。顧客と提携企業がそれぞれ異なるGoogle Cloudの組織でアプリケーションとストレージを構築している事実と、アプリケーション間の通信が公共インターネットを通過してはいけないという要件に注目してください。これらの要件を満たし、またGoogle Cloudの接続オプションが何を可能にするのかを理解することが求められます。
基本的な概念や原則：
VPCピアリング：異なるGoogle Cloudプロジェクト間や異なる組織間のVPCネットワークを接続するためのサービスです。公共のインターネットを経由せずに、他のネットワークへ安全に接続することが可能です。
Cloud VPN：公共インターネット上で暗号化された通信トンネルを確立するサービスです。使用すると、他のクラウドプロバイダーやオンプレミスネットワークとの間でセキュアな接続が可能となりますが、公共のインターネットを経由します。
Cloud Interconnect：Google Cloudとオンプレミスインフラや他のクラウドサービスとの間で高速な専用接続を提供するサービスです。しかし公共のインターネットを経由します。
共有VPC：複数のGoogle Cloudプロジェクト間で一つのVPCネットワークを共有するための設定です。リソースを一元管理し、ネットワーク管理を効率化することが可能です。しかし、異なる組織間の接続には使用できません。
正解についての説明：
（選択肢）
・VPCピアリング
この選択肢が正解の理由は以下の通りです。
VPCピアリングを使用すると、別々のGoogle Cloudの組織に存在するネットワーク間で通信が可能になります。この通信は完全にプライベートネットワーク内で行われ、公共のインターネットを介さずに行われます。そのため、これは問題において必要とされる条件を満たします。
また、VPCピアリングは低レイテンシでの通信を可能にし、ネットワーク間の帯域幅を最大限に活用します。これは、3層のウェブアプリケーションにおいて、アプリケーション層とストレージ層の間での高速な通信が必要となるため重要であり、VPCピアリングが最適な選択肢となります。
不正解についての説明：
選択肢：Cloud VPN
この選択肢が正しくない理由は以下の通りです。
Cloud VPNはインターネット上で暗号化されたトンネルを通じて通信が行われるため、公共のインターネットを通過してしまいます。これは問題文の要件では認められていません。
一方、VPCピアリングはネットワーク間の直接的な接続を可能にし、公共のインターネットを通過することなく通信が可能です。よって、不正解の選択肢は問題の要件に適合していません。
選択肢：Cloud Interconnect
この選択肢が正しくない理由は以下の通りです。
Cloud Interconnectは、オンプレミスとGoogle Cloud間の接続を提供し、公共のインターネットを経由せずに通信できますが、このケースは二つのGoogle Cloudの組織間の接続が求められています。
それに対し、VPCピアリングは二つのGoogle Cloudプロジェクト間のネットワーク接続を提供します。
選択肢：共有VPC
この選択肢が正しくない理由は以下の通りです。
共有VPCはFacebook社と同一のGoogle Cloudの組織内で複数のプロジェクトが同一のVPCネットワークを利用するための機能であり、別のGoogle Cloudの組織との間で利用することはできません。しかし、VPCピアリングは異なる組織間でも接続が可能で公共インターネットを回避できるため、要件を満たします。
参考リンク：
https://cloud.google.com/vpc/docs/vpc-peering
https://cloud.google.com/network-connectivity/docs/vpc-peering/how-to/setting-up-vpc-peering
https://cloud.google.com/architecture/building-internet-connectivity-for-private-vms
</div></details>

### Q.  問題47: 未回答
あなたの組織は、サードパーティ企業のCompute Engineインスタンス上で動作する金融サービスアプリケーションをホストしています。アプリケーションを使用するサードパーティ企業のサーバーも、別のGoogle Cloudの組織のCompute Engine上で実行されています。Compute Engineインスタンス間のセキュアなネットワーク接続を構成する必要があります。構成にあたっては、次の要件があります：
- ネットワーク接続が暗号化されている必要があります。
- サーバー間の通信は、プライベートIPアドレスを使用する必要があります。
この要件を満たすために、どうすればよいですか？
1. Compute EngineがホストするアプリケーションをAPIとして公開するApigeeプロキシを設定し、TLSで暗号化することで、サードパーティのみにアクセスを許可します
2. Compute Engineインスタンスの周囲にVPC Service Controlsの境界を設定し、アクセスレベルを介してサードパーティにアクセスを提供します
3. VPCファイアウォールルールによって制御される、組織のVPCネットワークとサードパーティーのVPCネットワーク間のCloud VPN接続を構成します
4. 組織のVPCネットワークとVPCファイアウォールルールで制御されるサードパーティーのVPCピアリング接続を設定します
<details><div>
    答え：3
この問題は、Google Cloud Compute Engine上で動作する異なる組織間でのセキュアなネットワーク接続の設定方法について問われています。要件として、ネットワーク接続の暗号化とプライベートIPアドレスの使用が必要であることが明示されています。以下にあげる選択肢から最適なものを選び、必要な構成を行います。VPCファイアウォールルールによって制御されるネットワーク接続、VPCピアリングの設定、VPC Service Controlsの境界設定、あるいはApigeeプロキシの設定等が考えられます。正解を選ぶためには、各選択肢がどのような機能を持ち、それが問題の要件を満たすか否かを理解することが重要です。
基本的な概念や原則：
VPC（Virtual Private Cloud）：Google Cloud上でプライベートな仮想ネットワークを作成し、そのネットワーク上でCompute Engineインスタンスなどを稼働させるためのサービスです。専用のIPアドレス範囲を持ち、自由に構成を設定できます。
Cloud VPN：Google Cloud上で仮想プライベートネットワーク（VPN）接続を作成するためのサービスです。VPN接続を使用すると、Google Cloudと他のネットワークをセキュアに接続することができます。通信は暗号化され、プライベートIPアドレスで行うことができます。
VPCファイアウォールルール：Google Cloud VPC内のリソースへのネットワークアクセスを制御するためのルールです。特定のネットワークトラフィックを許可または拒否できます。
VPCピアリング：2つのVPCネットワーク間を直接接続できるネットワークサービスです。通信はプライベートIPアドレスで行われ、ネットワーク遅延が少ないですが、通信は暗号化されません。
VPC Service Controls：Google Cloudサービスへのデータアクセスを管理および制限するツールです。しかし、Compute Engineインスタンス間のネットワーク通信の管理や暗号化には直接影響はありません。
Apigee：Google CloudのAPI管理プラットフォームです。APIに対するトラフィック管理、APIセキュリティ、APIモニタリングなどの機能を提供しますが、Compute Engineインスタンス間のセキュアなネットワーク接続の設定には直接利用できません。
正解についての説明：
（選択肢）
・VPCファイアウォールルールによって制御される、組織のVPCネットワークとサードパーティーのVPCネットワーク間のCloud VPN接続を構成します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのVPC（Virtual Private Cloud）ネットワークは、Compute Engineインスタンス間でプライベートIPアドレスを使用して通信を行うことを可能にします。これにより、サーバー間通信のプライベートIPアドレス使用の要件が満たされます。
次に、Cloud VPNはVPC間の安全な通信チャネルを提供するサービスで、IPSecプロトコルを使用してネットワークの通信を暗号化します。これにより、ネットワーク接続が暗号化される要件も満たされます。
最後に、VPCファイアウォールルールを用いて、VPCネットワーク間の通信の許可や拒否の制御が可能です。これにより、必要とされる安全なネットワーク接続を確保することができます。
したがって、正解はVPCファイアウォールルール制御の下でのCloud VPN接続の設定です。これにより、必要要件のすべてが満たされます。
不正解についての説明：
選択肢：組織のVPCネットワークとVPCファイアウォールルールで制御されるサードパーティーのVPCピアリング接続を設定します
この選択肢が正しくない理由は以下の通りです。
VPCピアリング接続は通信を暗号化しないため、要件に適合しません。
一方、Cloud VPN接続は通信を暗号化するため、こちらが適切な解決策です。VPCピアリングは、プライベートIPアドレスでの通信は可能ですが、暗号化という重要な要件を満たせないため不適切です。
選択肢：Compute Engineインスタンスの周囲にVPC Service Controlsの境界を設定し、アクセスレベルを介してサードパーティにアクセスを提供します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsはデータ漏洩を防ぐためのサービスで、特定のVPCリソースへのアクセスを管理しますが、Compute Engineインスタンス間の暗号化されたネットワーク接続の構成やプライベートIPアドレスを使用した通信の実現には向いていません。これらの要件はCloud VPN接続を通じて達成できます。
選択肢：Compute EngineがホストするアプリケーションをAPIとして公開するApigeeプロキシを設定し、TLSで暗号化することで、サードパーティのみにアクセスを許可します
この選択肢が正しくない理由は以下の通りです。
ApigeeプロキシはAPIのトラフィックを管理することが目的であり、Compute Engineインスタンス間のプライベートなネットワーク接続の設定には適していません。この要件は、VPCネットワーク間のCloud VPN接続が最適で、暗号化通信とプライベートIPアドレスの要件を満たします。
参考リンク：
https://cloud.google.com/vpn/docs/concepts/overview
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#secure_communications_between_vpcs
https://cloud.google.com/vpc/docs/vpc-peering
</div></details>

## 3

### Q.  問題6: 未回答
あなたの会社の新しいCEOは最近、会社の2つの部門を売却しました。あなたの会社の取締役は、これらの部門に関連するGoogle Cloudプロジェクトを新しい組織ノードに移行する手助けをするようあなたに依頼しました。この移行を行う前に必要な準備手順はどれですか？（2つ選択）
1. VPC Service Controlsの境界およびブリッジから特定の移行プロジェクトを削除します
2. 移行するすべてのプロジェクト用に新しいフォルダを作成します
3. 組織ポリシーの継承を禁止します
4. 移行対象プロジェクトで継承されたIDおよびIAMロールを特定します
5. プロジェクトレベルのカスタムIDおよびIAMロールをすべて削除します
<details><div>
    答え：1,4
この問題では、Google Cloudプロジェクトの組織ノードへの移行にどのような準備が必要かを理解することが求められています。既存のIDやIAMロールの移行と、VPC Service Controlsの境界からのプロジェクトの削除という明確な手順が示されています。選択肢を見る際は、既存の設定や構成を保ちつつ新しい組織ノードへの適切な移行を達成するものを選びます。さらに、互換性やセキュリティを維持し、新しい組織ノードのポリシーに準拠するものを選んでください。
基本的な概念や原則：
継承されたIDおよびIAMロール：Google Cloudのリソース階層において、特定のリソースに付与されたアクセス権限は、その下位のリソースにも継承されます。これにより、プロジェクトや組織全体での権限管理が可能になります。
VPC Service Controls：Google Cloudサービス間の通信を制御して、データ漏えいのリスクを軽減するためのサービスです。サービスパーリメーター（境界）を定義して、それを超えた通信を制限します。
移行プロジェクト：Google Cloud上での移行作業を管理するためのプロジェクトです。資源の移動や権限の付与など、移行に必要な操作がここで行われます。
組織ポリシー：Google Cloudのリソース階層全体で制御を設けるためのフレームワークです。特定の制約を定義して、それに沿ったリソース管理を強制することができます。
正解についての説明：
（選択肢）
・移行対象プロジェクトで継承されたIDおよびIAMロールを特定します
・VPC Service Controlsの境界およびブリッジから特定の移行プロジェクトを削除します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudプロジェクトを他の組織ノードに移行する際、継承されたIDおよびIdentity and Access Management（IAM）ロールを特定することは重要です。これによりアクセス管理が適切に行われ、誤ったアクセスや権限が発生する可能性を最小化します。また新しい組織に移行した後も適切な操作が実行できるようにするためには、それらのアクセス許可や権限が何であるかを明確に理解しておくことが求められます。
次に、VPC Service Controlsは、Google Cloudリソースが特定のVirtual Private Cloud（VPC）ネットワークやプロジェクトに制限されるようにするサービスです。移行対象のプロジェクトがVPC Service Controlsの境界に含まれている場合、そのプロジェクトを移行する前にこれを削除する必要があります。これにより、移行に伴うネットワークの接続問題やセキュリティの問題を防ぐことができるのです。
不正解についての説明：
選択肢：プロジェクトレベルのカスタムIDおよびIAMロールをすべて削除します
この選択肢が正しくない理由は以下の通りです。
プロジェクトレベルのカスタムIDおよびIAMロールをすべて削除する行為は、移行対象のプロジェクトの適切な運用を保証できない可能性があります。そのため、これらを特定する事が重要で、無条件に削除するのはリスクが高いです。
選択肢：組織ポリシーの継承を禁止します
この選択肢が正しくない理由は以下の通りです。
新しい組織ノードへのプロジェクト移行では、組織ポリシーの継承を禁止するのではなく、移行対象プロジェクトで継承されるIDおよびIAMロールと、VPC Service Controlsの境界およびブリッジの設定が必要です。組織ポリシーの継承を禁止することでは、これらの重要な事項が漏れてしまう可能性があります。
選択肢：移行するすべてのプロジェクト用に新しいフォルダを作成します
この選択肢が正しくない理由は以下の通りです。
新しいフォルダを作成するという手順は、移行のための直接的な準備ではなく、組織のリソース整理の一環であり、必須ではありません。
それに対して、IDやIAMロールの特定はアクセス権限を適切に移行するため、VPC Service Controlsの設定は移行によるセキュリティ影響を把握するため、といった準備が必要です。
参考リンク：
https://cloud.google.com/resource-manager/docs/project-migration
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/vpc-service-controls/docs/perimeters
</div></details>

### Q.  問題27: 未回答
ある企業が、専用サーバールームでワークロードを実行しています。これらのワークロードには、社内のプライベートネットワークからのみアクセスできる必要があります。あなたは、Google Cloudプロジェクト内のCompute Engineインスタンスからこれらのワークロードに接続する必要があります。
要件を満たすためにどの2つのアプローチを取ることができますか？（2つ選択）
1. Cloud Interconnectでプロジェクトを構成します
2. VPCピアリングでプロジェクトを構成します
3. 共有VPCでプロジェクトを構成します
4. すべてのCompute EngineインスタンスをPrivate Accessで構成します
5. Cloud VPNでプロジェクトを構成します
<details><div>
    答え：1,5
この問題では、企業のローカルネットワークとGoogle Cloudプロジェクト間の接続方法について問われています。問題文のキーポイントは、社内ネットワークからのみアクセス可能である要請、そしてGoogle CloudのCompute Engineインスタンスを用いる要件です。各選択肢を見て、これらの特性と要件を満たすものを選ぶことが求められます。ただし、Google Cloudのネットワークの仕組みや各選択肢が何を意味するのか、よく理解していないと見当違いの選択肢を選ぶ可能性がありますので注意が必要です。
基本的な概念や原則：
Cloud VPN：Google Cloudとオンプレミスネットワーク間の安全な接続を提供するフルマネージドのIPsec VPNソリューションです。プライベートネットワークの拡張やハイブリッドクラウド設定に使用します。
Cloud Interconnect：Google Cloudと自社インフラストラクチャ間の専用の物理的接続を提供します。高スループットの要求に対応し、ネットワークの信頼性とパフォーマンスを向上させます。
共有VPC：複数のGoogle Cloudプロジェクト間で単一のVPCネットワークを共有する機能です。ただし、オンプレミスのプライベートネットワークとの接続には使用しません。
VPCピアリング：Google Cloudの異なるプロジェクト間や異なるVPCネットワーク間で通信を許可する機能です。ただし、オンプレミスのプライベートネットワークとの接続には使用しません。
Private Access：Google Cloudのサービスに対してVPCネットワークからプライベートIPアドレスを使用してアクセスする機能です。ただし、オンプレミスのプライベートネットワークとの接続には使用しません。
正解についての説明：
（選択肢）
・Cloud VPNでプロジェクトを構成します
・Cloud Interconnectでプロジェクトを構成します
この選択肢が正解の理由は以下の通りです。
まず、Cloud VPNはプライベートネットワークとGoogle Cloudとの間にVPN（仮想プライベートネットワーク）接続を確立するサービスであり、Compute Engineインスタンスから企業内部のプライベートネットワークに安全に接続するのに最適です。既存のネットワークとGoogle Cloudとを安全な接続でリンクし、仮想的に同一ネットワーク上にあるかのように操作できます。
したがって、Cloud VPNは社内のプライベートネットワークからのみアクセス可能なワークロードへの接続要件を満たします。
一方、Cloud Interconnectは、Google Cloudとオンプレミスのデータセンターまたは他のネットワーク間での大量のデータ通信を高速かつ安全に行うためのサービスで、専用の接続を提供します。Compute Engineインスタンスから社内のワークロードへの高速な接続が必要な場合には、Cloud Interconnectを使用します。つまり、Cloud Interconnectも同様に社内のプライベートネットワークからのみアクセス可能なワークロードへの接続要件を満たします。
したがって、これらの2つの選択肢が正解となります。
不正解についての説明：
選択肢：共有VPCでプロジェクトを構成します
この選択肢が正しくない理由は以下の通りです。
共有VPCは、同一組織内の複数のGoogle Cloudプロジェクト間でネットワークを共有するためのものであり、社内のプライベートネットワークとGoogle Cloudプロジェクト間の接続を担保する機能はありません。
それに対して、Cloud VPNやCloud Interconnectは社内ネットワークとGoogle Cloudとの安全な接続を提供します。
選択肢：VPCピアリングでプロジェクトを構成します
この選択肢が正しくない理由は以下の通りです。
VPCピアリングは、2つのGoogle Cloudプロジェクト間または同じプロジェクト内のVPCネットワーク間でネットワーク接続を行うためのサービスで、企業内部のプライベートネットワークとの接続には用いられません。要件のように社内ネットワークとGoogle Cloudをセキュアに接続するために、Cloud VPNやCloud Interconnectの使用が適切です。
選択肢：すべてのCompute EngineインスタンスをPrivate Accessで構成します
この選択肢が正しくない理由は以下の通りです。
Compute EngineのPrivate Access設定は、インスタンスがGoogle Cloud内のサービスとプライベートに通信できるようにするものであり、社内のプライベートネットワークとは接続できません。しかし、Cloud VPNやCloud Interconnectは直接企業のネットワークとGoogle Cloudを接続し、必要な通信要件を満たすことができます。
参考リンク：
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/network-connectivity/docs/interconnect/concepts/overview
https://cloud.google.com/vpc/docs/configure-private-google-access#gcloud
</div></details>

## 4

### Q.  問題11: 未回答
サードパーティのIDプロバイダ（IdP）からCloud IdentityにIDを同期する予定です。一部の従業員が会社のメールアドレスを使用して、Googleサービスにアクセスするためのコンシューマアカウントを設定していることがわかりました。これらのコンシューマアカウントの構成、セキュリティ、およびライフサイクルを組織が確実に管理できるようにする必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 移管ツールを使用して、企業の従業員を招待し、管理されていないコンシューマーアカウントを企業ドメインに移管します
2. Google Cloud Directory Sync（GCDS）を使用して、管理されていない消費者アカウントの電子メールをユーザーエイリアスとして移行します
3. IDを同期する前に、サードパーティIdPで管理されていないコンシューマアカウントを削除します
4. 企業の従業員に、管理されていない消費者アカウントの削除を義務付けます
5. Cloud Identityには存在するがサードパーティのIdPには存在しないアカウントを照合します
<details><div>
    答え：1,5
この問題では、サードパーティのIDプロバイダからCloud IdentityにIDを同期する際に、どのようにコンシューマアカウントを管理すべきかを問いています。この問題に対しては、既存のコンシューマアカウントの管理方法と、それを組織の管理下に置く方法について理解する必要があります。キーポイントは、従業員が会社のメールアドレスを使用してGoogleサービスにアクセスするコンシューマアカウントの管理です。そのため、答えはそれらのアカウントを組織が確実に管理するための最も効果的な方法に導かれます。
基本的な概念や原則：
Cloud Identity：Google CloudのID管理システムです。ユーザー、グループ、アプリケーションの認証、承認、管理が可能です。
IDプロバイダ（IdP）：ユーザーの認証情報を管理するサービスです。SAMLやOpenID Connectといった認証プロトコルを使用して、ユーザーのIDを検証します。
コンシューマアカウント：個々のユーザーが個人用途で作成するGoogleアカウントです。これに対して、組織がユーザー用に作成するアカウントをエンタープライズアカウントと呼びます。
移管ツール：Google Workspaceの管理者が未管理のGoogleアカウントを該当する組織に移管するためのツールです。
Google Cloud Directory Sync（GCDS）：Google Workspaceと既存のLDAPディレクトリの間でユーザー、グループ、組織単位を同期するツールです。ただし管理されていない消費者アカウントの移行には適していません。
アカウントの照合：Cloud IdentityとIdP間でアカウントの存在を比較し、不一致を調整する行為です。存在するアカウントの一致を確認し、必要に応じてアカウントを移管または削除します。
正解についての説明：
（選択肢）
・Cloud Identityには存在するがサードパーティのIdPには存在しないアカウントを照合します
・移管ツールを使用して、企業の従業員を招待し、管理されていないコンシューマーアカウントを企業ドメインに移管します
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Identityは、企業がユーザーの認証とアクセス管理を行うためのサービスです。サードパーティのIdPからCloud IdentityへのID同期を行うことで、企業はIDを一元管理できるようになります。一部の従業員が自身の企業のメールアドレスでGoogleサービスにアクセスするための個人アカウントを設定している場合、それらのアカウントは企業の管理下にないため、それらのアカウントのセキュリティとライフサイクルを管理できません。そこで、Cloud Identityには存在するがサードパーティのIdPには存在しないアカウントを照合することが求められます。これにより、そのような個人アカウントを特定できます。
次に、それらの個人アカウントを企業の管理下に置くためには移管が必要です。Googleは"移管ツール"を提供しており、これを使用して管理されていないコンシューマアカウントを企業ドメインに移管します。このツールを使用することで、管理されていないコンシューマアカウントの所有者である従業員に移管を求める招待が送られ、その結果これらのアカウントを企業が管理することが可能となります。これにより、従業員が企業ドメインでGoogleのサービスに利用しているアカウントの持つ構成、セキュリティ、とライフサイクルを確実に管理することができます。
不正解についての説明：
選択肢：企業の従業員に、管理されていない消費者アカウントの削除を義務付けます
この選択肢が正しくない理由は以下の通りです。
単に従業員に消費者アカウントの削除を義務付けることでは、アカウントの構成、セキュリティ、ライフサイクルを企業が確実に管理するという要件は満たされません。
また、それは利便性や生産性の低下を引き起こす可能性があるため、企業の利益には繋がりません。
選択肢：IDを同期する前に、サードパーティIdPで管理されていないコンシューマアカウントを削除します
この選択肢が正しくない理由は以下の通りです。
コンシューマアカウントを削除すると、そのアカウントに関連付けられた全てのデータとサービスも削除されてしまうため、その後の管理が不可能となるからです。正解選択肢のように移管ツールを使ってアカウントを移管すれば、アカウントとそれに関連するデータを維持したままで組織の管理下に置くことが可能です。
選択肢：Google Cloud Directory Sync（GCDS）を使用して、管理されていない消費者アカウントの電子メールをユーザーエイリアスとして移行します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Directory Sync（GCDS）は基本的にIDの同期のみを行うツールであり、コンシューマアカウントの管理やセキュリティ、ライフサイクルを制御することはできません。そのため、GCDSを用いた方法では要件を満たすことはできません。
参考リンク：
https://cloud.google.com/identity/docs/account-transfer/intro
https://cloud.google.com/identity/docs/how-to/manage-users
https://support.google.com/a/answer/6335621
</div></details>

### Q.  問題15: 未回答
あなたの会社はSparkとHadoopのジョブにCloud Dataprocを使用しています。Cloud Dataprocで使用される永続ディスクに使用される対称暗号化キーの作成、ローテーション、破棄ができるようにしたいと考えています。暗号化キーはクラウドに保存したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 暗号化キー（KEK）の管理には、顧客が提供する暗号化キーを使用します
2. 鍵暗号化キー（KEK）を管理するために、Cloud Key Management Serviceを使用します
3. データ暗号化キー（DEK）の管理には、顧客が提供する暗号化キーを使用します
4. Cloud Key Management Serviceを使用して、データ暗号化鍵（DEK）を管理します
<details><div>
    答え：4
この問題では、Cloud Dataprocで使用される永続ディスクに使われる暗号化キーの作成、ローテーション、破棄をどのように行うべきかという課題に焦点を当てています。また、その暗号化キーはクラウドに保存したいという要件もあります。クラウドに保存し、管理する暗号化キーとして選択肢にあげられているものが正しいかどうかを注意深く考えることが求められます。
基本的な概念や原則：
Cloud Dataproc：Google CloudのマネージドSparkとHadoopサービスです。データの分析や処理、機械学習のタスク等に利用します。
Cloud Key Management Service：Google Cloudで対象鍵の管理を行うためのマネージドサービスです。暗号化キーの作成、使用、ローテーション、破棄が行えます。
データ暗号化鍵（DEK）：データそのものを暗号化するためのキーです。直接データを暗号化・復号化するために使用されます。
鍵暗号化キー（KEK）：他の暗号キー（特にDEK）を暗号化するために使用されるキーです。暗号キーの暗号化やキーのライフサイクル管理に使用します。
顧客が提供する暗号化キー：顧客が自分で制御したい場合に使う、顧客自身が生成と管理を行う暗号化キーです。しかし、すべての管理責任が顧客にあるため、専門的な知識が必要となります。
正解についての説明：
（選択肢）
・Cloud Key Management Serviceを使用して、データ暗号化鍵（DEK）を管理します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Key Management Service（KMS）は、仮想マシンや永続ディスクなどのGoogle Cloudのリソースで用いられる秘密鍵（対称暗号化キー）を生成、使用、管理、ローテーション、そして破棄することを可能にするサービスです。これはクエスチョンで述べられた暗号化キーのライフサイクルの管理が必要とされている点に直接対応しています。
また、Cloud KMSはクラウド上で鍵を保存するため、クエスチョンにおいて暗号化キーの保存場所がクラウドであるべきと要求されている要件も満たします。
したがって、Cloud KMSを使用してデータ暗号化鍵（DEK）を管理することが最適な解決策と言えます。ただし、暗号化における基本的な概念として、データ暗号化鍵（DEK）が実際にデータの暗号化と復号化に使用され、鍵暗号化鍵（KEK）がDEKを保護するために使用されることを理解することは重要です。
不正解についての説明：
選択肢：鍵暗号化キー（KEK）を管理するために、Cloud Key Management Serviceを使用します
この選択肢が正しくない理由は以下の通りです。
誤った選択肢は、永続ディスクに使用される暗号化キー自体（DEK）を管理することではなく、別の暗号化キー（KEK）を管理することを提案しています。
一方、正解の選択肢は直接的にデータ暗号化鍵（DEK）の管理を提案しているため、問題の要件を満たします。
選択肢：データ暗号化キー（DEK）の管理には、顧客が提供する暗号化キーを使用します
この選択肢が正しくない理由は以下の通りです。
顧客が提供する暗号化キーを使用する方法では、要件で明示されているように暗号化キーの作成、ローテーション、破棄をクラウドで行うことができません。
一方で、Cloud Key Management Serviceを使用すれば、これらの暗号化キーのライフサイクルの管理を効率的にクラウド上で行うことが可能です。
選択肢：暗号化キー（KEK）の管理には、顧客が提供する暗号化キーを使用します
この選択肢が正しくない理由は以下の通りです。
顧客が提供する暗号化キーを使用するという提案はクラウドに暗号化キーを保存する要件を満たしません。
一方、Cloud Key Management ServiceはDEKの作成、ローテーション、破棄を可能にし、これらのキーをGoogle Cloud内で保存できます。
参考リンク：
https://cloud.google.com/security-key-management
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/security
https://cloud.google.com/kms/docs/creating-keys
</div></details>

### Q.  問題25: 未回答
共有VPCに接続されたCompute EngineインスタンスとBigQueryデータセット間のアクセス拒否エラーのトラブルシューティングを行っています。データセットは、VPC Service Controls境界によって保護されたプロジェクトに存在します。
この要件を満たすために、どうすればよいですか？
1. Compute Engineインスタンスが存在するサービスプロジェクトをサービス境界に追加します
2. Compute Engineインスタンスが存在するサービスプロジェクトと、保護されたBigQueryデータセットを含む境界との間に境界ブリッジを作成します
3. 共有VPCを含むホストプロジェクトをサービス境界へ追加します
4. Compute Engineインスタンスが存在するサービスプロジェクトと、Shared VPCを含むホストプロジェクトの間に、サービス境界を作成します
<details><div>
    答え：3
この問題では、Google Cloudの共有VPC、Compute Engineインスタンス、BigQueryデータセットとVPC Service Controlsに関連するエラーハンドリングの知識が求められます。ここでの課題は、VPC Service Controls境界によって保護されたプロジェクト内のデータセットに共有VPCを通じてアクセスしたいというものです。選択肢を選ぶ際には、VPC Service Controlsの設定と、それがどのように共有VPCと他のGoogle Cloudサービスとの連携に影響を与えるか、を理解しておくことが重要です。
基本的な概念や原則：
共有VPC：Google Cloudのネットワークリソースを複数のプロジェクト間で共有するための機能です。ホストプロジェクトのネットワークを共有し、サービスプロジェクトのインスタンスで使用します。
VPC Service Controls：Google Cloudサービス間のデータの流れを制御するセキュリティ境界を設定する機能です。境界内のリソースへのアクセスを制限します。
ホストプロジェクト：共有VPCを持つプロジェクトです。このホストプロジェクトのネットワークをサービスプロジェクトが共有します。
サービスプロジェクト：共有VPCを使用するプロジェクトです。ホストプロジェクトからネットワークを共有します。
Compute Engine：Google Cloudの仮想マシンを提供するサービスです。柔軟な仮想マシンの設定と自動スケーリングが可能です。
BigQuery：Google Cloudの大規模データ分析サービスです。高速なSQLクエリを実行し、ビッグデータの分析を容易にします。
正解についての説明：
（選択肢）
・共有VPCを含むホストプロジェクトをサービス境界へ追加します
この選択肢が正解の理由は以下の通りです。
共有VPCを使用すると、複数のプロジェクト間でネットワークリソースを統一的に管理できます。このネットワークは一つのホストプロジェクトで定義され、他のサービスプロジェクトから利用されます。これにより、ネットワークの設定やポリシーを一元的に制御できます。
一方、VPC Service ControlsはGoogle Cloudのサービスに対するデータの流れを制御するためのセキュリティ対策の一つで、一定の範囲（サービス境界）を設定し、その範囲内からのデータアクセスのみを許可することができます。
共有VPCを含むホストプロジェクトがVPC Service Controlsのサービス境界に含まれていないと、そのネットワークからは境界によって保護されたリソースへのアクセスが拒否されます。
したがって、アクセス拒否エラーを解消するためには、共有VPCを含むホストプロジェクトをVPC Service Controlsのサービス境界に追加する必要があります。そうすることで、共有VPCからのデータアクセスが許可され、エラーは解消されます。
不正解についての説明：
選択肢：Compute Engineインスタンスが存在するサービスプロジェクトをサービス境界に追加します
この選択肢が正しくない理由は以下の通りです。
サービスプロジェクトをサービス境界に追加しても、共有VPCが保護されません。
それに対して、ホストプロジェクトを境界に追加すると、共有VPC全体が保護され、接続されたインスタンスからBigQueryデータセットにアクセスできます。
選択肢：Compute Engineインスタンスが存在するサービスプロジェクトと、Shared VPCを含むホストプロジェクトの間に、サービス境界を作成します
この選択肢が正しくない理由は以下の通りです。
サービス境界はプロジェクト間のデータ流れを制限するもので、Compute EngineインスタンスとShared VPC間に新たに境界を作ると、それらのコミュニケーションをさらに阻む可能性があります。正解は共有VPCを含むホストプロジェクトを境界に追加して、BigQueryデータセットとのアクセスを許可することです。
選択肢：Compute Engineインスタンスが存在するサービスプロジェクトと、保護されたBigQueryデータセットを含む境界との間に境界ブリッジを作成します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsは、サービスとデータ間の適切な流れを管理するために導入されたものであり、一方で存在しない概念である"境界ブリッジ"を作成することはできません。正しい対策は、共有VPCを含むホストプロジェクト全体をVPC Service Controls境界に追加することです。
参考リンク：
https://cloud.google.com/vpc-service-controls/docs/set-up-private-connectivity
https://cloud.google.com/vpc-service-controls/docs/perimeters
https://cloud.google.com/bigquery/docs/datasets-access-controls
</div></details>

### Q.  問題30: 未回答
組織のゼロトラスト戦略の一環として、Identity-Aware Proxy（IAP）を使用して複数のアプリケーションを保護しています。セキュリティ情報とイベント管理（SIEM）システムにログを取り込み、侵入の可能性を警告する必要があります。
どのログを分析すべきですか？
1. 管理者の活動監査ログ
2. データアクセス監査ログ
3. ポリシー拒否の監査ログ
4. Cloud Identityユーザーログイベント
<details><div>
    答え：1
この問題では、ゼロトラスト戦略を実行するためのIdentity-Aware Proxy（IAP）と、侵入可能性を警告するためのセキュリティ情報とイベント管理（SIEM）システムのログの統合に焦点を当てています。正しいログを選択するためには、各ログが提供する情報とその目的について理解することが重要です。選択肢を検討する際には、侵入可能性を警告するために最も適したログとして、最も関連性の高いログを選ぶことが求められます。
基本的な概念や原則：
Identity-Aware Proxy（IAP）：Google Cloud上のアプリケーションとリソースへの安全なアクセスを提供するサービスです。VPNやファイアウォールの代わりに使用できます。
ゼロトラスト戦略：信頼とアクセスを前提とせず、すべてのユーザーとデバイスを潜在的に不安全とするセキュリティ戦略です。最小限の権限を与え、継続的な認証と承認を要求します。
データアクセス監査ログ：Google Cloudサービスが提供するデータを読み取ったり、書き込んだり、修正したりしたときに記録されるログです。セキュリティ上の脅威を監視するために使用されます。
SIEMシステム：セキュリティ情報とイベント管理を行うシステムです。セキュリティ関連のログとイベントを集約し、解析して警告を出すなどの機能を持ちます。
管理者の活動監査ログ：Google Cloudプロジェクトで管理者が行った操作を記録するログです。主に管理者周りの監視やトラブルシューティングに使用されます。
ポリシー拒否の監査ログ：ポリシーが適用されてアクションが拒否された場合に記録されるログです。不正なアクセスや操作を防ぐために使用されます。
Cloud Identityユーザーログイベント：Cloud Identityでのユーザーのログイベントを記録したものです。ユーザーベースの監視や分析に使用されます。
正解についての説明：
（選択肢）
・データアクセス監査ログ
この選択肢が正解の理由は以下の通りです。
Identity-Aware Proxy（IAP）は、Google Cloudリソースへのアクセスを制御するのに使われます。ユーザーまたはサービスがリソースにアクセスを試みたときに、IAPはそのアクセス試行を記録します。データアクセス監査ログは、これらのアクセス試行を詳細に捉える一方で、リソースへの読み取り、書き込み、更新操作も記録します。監査ログはリソースの変更などの重要なイベントをトラックし、異常行動や不適切なアクセスを特定するのに役立ちます。
したがって、SIEMシステムに取り込むために分析すべきログとして、データアクセス監査ログは有効で、侵入やその他のセキュリティ脅威の早期警告となる情報を提供します。これは、ゼロトラスト戦略を実装する上で極めて重要です。
不正解についての説明：
選択肢：ポリシー拒否の監査ログ
この選択肢が正しくない理由は以下の通りです。
ポリシー拒否の監査ログは、ある操作がGoogle CloudのIAMポリシーにより拒否された場合に生成されます。しかし、Identity-Aware Proxyの使用に関しては、データアクセス監査ログがもっと詳しい情報を提供します。これには認証や認可など、IAPの保護下にあるリソースへのアクセス試行に関する情報が含まれます。
選択肢：Cloud Identityユーザーログイベント
この選択肢が正しくない理由は以下の通りです。
Cloud Identityユーザーログイベントはユーザーの身元やログイン情報を追跡しますが、アプリケーションへのアクセスや侵入の可能性に関する直接的な情報は含まれません。
それに対して、データアクセス監査ログはユーザーやサービスがGoogle Cloudのデータにどのようにアクセスしたかの詳細な記録を提供し、侵入の検知に役立ちます。
選択肢：管理者の活動監査ログ
この選択肢が正しくない理由は以下の通りです。
管理者の活動監査ログは、Google Cloud上の管理者によるリソース操作などの活動を記録しますが、IAPを通じたアクセス情報は詳細に記録されません。
それに対して、データアクセス監査ログはIAPによるデータへのアクセスを詳細に記録するため、侵入の可能性を警告するのに必要なログを提供します。
参考リンク：
https://cloud.google.com/iap/docs/audit-log-howto
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/security-command-center/docs/how-to-use-security-sources#logging
</div></details>

### Q.  問題31: 未回答
脆弱性に対するパッチがリリースされ、DevOpsチームはGoogle Kubernetes Engine（GKE）で実行中のコンテナをアップデートする必要があります。
DevOpsチームはどのようにこれを達成すべきですか？
1. アプリケーションコードを更新するかパッチを適用して、新しいイメージを構築し、再デプロイします
2. 自動アップグレードが有効になっていることを確認します。有効になっている場合、GoogleはGKEクラスター内のノードをアップグレードします
3. Container Registryでベースイメージが利用可能になったときに、自動的にアップグレードするようにコンテナを設定します
4. PuppetまたはChefを使って、実行中のコンテナにパッチをプッシュします
<details><div>
    答え：1
この問題では、パッチのリリース後にGoogle Kubernetes Engine（GKE）で実行中のコンテナをアップデートするための最適な方法を尋ねています。ここで重要なのは、コンテナテクノロジーの原則とプラクティス、特にイミュータブルなインフラストラクチャの概念への理解です。実行中のコンテナに直接パッチを適用するのではなく、新しいコンテナイメージを構築してデプロイする適切な方法を探る必要があります。
基本的な概念や原則：
コンテナイメージ：アプリケーションとその依存関係をパッケージ化し、ランタイム環境を抽象化するための可搬性のあるエンティティです。これは更新やパッチを適用するために再構築され得ます。
Google Kubernetes Engine（GKE）：Google Cloud上でコンテナ化されたアプリケーションを実行するためのマネージド、収縮可能な環境の提供サービスです。
再デプロイ：新しいバージョンのアプリケーションまたはパッチの適用後に、アプリケーションまたはサービスを実行環境に戻す手続きです。
DevOps：開発と運用部門の間で効率的に協力して作業を進めるための哲学及びプラクティスです。"Dev"はソフトウェア開発、"Ops"はIT運用を表します。
Puppet、Chef：ITインフラストラクチャの自動化と管理を補助するツールです。ハードウェア構成やアプリケーション設定などの監視及び自動化に役立ちますしかし、実行中のコンテナにパッチをプッシュするのは推奨されません。
Container Registry：Dockerイメージのプライベートストレージとデリバリーサービスです。安全にイメージを保存、管理、デプロイできます。
正解についての説明：
（選択肢）
・アプリケーションコードを更新するかパッチを適用して、新しいイメージを構築し、再デプロイします
この選択肢が正解の理由は以下の通りです。
Google Kubernetes Engine（GKE）で運用するコンテナイメージは不変であり、直接更新またはパッチ適用を行うことは原則として行われません。その代わり、アプリケーションコードを更新したりパッチを適用したりした上で新しいイメージを構築することで、その修正を反映します。新しいイメージが構築されれば、それを基にコンテナを再デプロイすることで継続的にサービスを提供しながら更新が行われます。
これは、不変のインフラストラクチャの原則に基づくもので、一旦デプロイされたインフラストラクチャは変更せず、必要な変更がある場合は新たに構築するという考え方です。これにより、システムの信頼性を保ちつつ、脆弱性への対応や改善を迅速に行うことが可能となります。
不正解についての説明：
選択肢：PuppetまたはChefを使って、実行中のコンテナにパッチをプッシュします
この選択肢が正しくない理由は以下の通りです。
PuppetやChefは主にVMなどの伝統的なサーバ管理用のツールであり、コンテナのパッチ適用には適しません。正解の選択肢はイメージを更新して再デプロイすることで、これがコンテナの最善のパッチ適用手段です。
選択肢：自動アップグレードが有効になっていることを確認します。有効になっている場合、GoogleはGKEクラスター内のノードをアップグレードします
この選択肢が正しくない理由は以下の通りです。
自動アップグレードが有効になっていると、GKEクラスターのノードはGoogleによって更新されますが、これはノードのOSやKubernetes自体のアップデートを指します。アプリケーション内のコードやパッチの適用は含まれていません。そのため、新しいイメージを作成して再デプロイする必要があります。
選択肢：Container Registryでベースイメージが利用可能になったときに、自動的にアップグレードするようにコンテナを設定します
この選択肢が正しくない理由は以下の通りです。
Container Registryでベースイメージが利用可能になったときに自動的にアップグレードする設定は存在しません。実際には、アプリケーションコードを更新するかパッチを適用して新しいイメージを構築し、再デプロイする必要があります。これにより、安全な最新版のコンテナイメージに更新することが可能です。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps
https://cloud.google.com/kubernetes-engine/docs/concepts/node-auto-upgrades
https://cloud.google.com/container-registry/docs/managing-images
</div></details>

### Q.  問題33: 未回答
あなたの組織は、CIS Google Cloud Computing Foundations Benchmark v1.3.0（CIS Google Cloud Foundation 1.3）に対して継続的に評価されることを望んでいます。コントロールの中には、組織と無関係なものもあり、評価の際に無視しなければなりません。関連するコントロールのみが評価されるように、自動化されたシステムまたはプロセスを作成する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 外部監査会社に、必要なCISベンチマークを含む独立した報告書の提出を依頼します。監査範囲において、一部の管理は不要であり、無視しなければならないことを明確にします
2. Security Command Center（SCC）Premiumをアクティベートします。SCCでセキュリティ調査結果をミュートするルールを作成し、評価されないようにします
3. Security Command Center（SCC）からすべての調査結果をCSVファイルにダウンロードします。ファイル内のCIS Google Cloud Foundation 1.3の一部である調査結果をマークします。関連性がなく、会社のスコープ外のエントリは無視します
4. 無関係なすべてのセキュリティ所見に、セキュリティ例外を示すタグと値をマークします。マークされた調査結果をすべて選択し、表示されるたびにコンソール上でミュートします。Security Command Center（SCC）Premiumをアクティブ化します
<details><div>
    答え：2
この問題では、組織がCIS Google Cloud Computing Foundations Benchmarkに対して継続的に評価されることを望んでおり、その過程で無関係な評価を無視するような自動化システムを作成する方法を探しています。重要なことは、適切なGoogle Cloudのセキュリティツールを選択すること、そしてそれをどのように設定するかです。特定のツールが提供している機能を理解し、それらが組織のセキュリティ要件にどのように適合するかを検討することが必要です。これにより、適切な自動化プロセスを確立し、規範に準拠しつつ無関係なコントロールを無視することが可能になります。
基本的な概念や原則：
CIS Google Cloud Computing Foundations Benchmark：CIS（Center for Internet Security）によって提供される、Google Cloudのセキュリティ基準のセットです。これは、Google Cloudのセキュリティ設定を評価・強化するための最善の手法を提供します。
Security Command Center（SCC）：Google Cloudの統合されたリスク報告ダッシュボードで、Google Cloudの資産とデータを保護するための洞察とデータを提供します。セキュリティ調査結果をミュート（無視）することも可能です。
セキュリティ例外：セキュリティの評価プロセスで、特定の条件下で許可されるセキュリティルールの違反を指します。セキュリティ例外を適切にマークし、管理することは、全体的なセキュリティガバナンスの一部です。
CSVファイル：データを表形式で保存するためのプレーンテキスト形式の一種です。セキュリティ調査結果をエクスポートする際に用いられます。
外部監査：独立した第三者が組織のプロセス、システム、操作を審査し、その結果を報告することです。これにより、組織は潜在的なリスクを特定し、必要な改善を行うことができます。
正解についての説明：
（選択肢）
・Security Command Center（SCC）Premiumをアクティベートします。SCCでセキュリティ調査結果をミュートするルールを作成し、評価されないようにします
この選択肢が正解の理由は以下の通りです。
まず、Security Command Center（SCC）Premiumは、Google Cloudの脆弱性と脅威を継続的に表示し、分析するためのセキュリティ管理プラットフォームです。SCC Premiumの特徴の一つは、CIS Google Cloud Foundationの基準に対する修正可能なコントロールの評価を自動化する機能です。逆に言えば、これにより継続的な評価が可能となります。
また、SCCでは"ミュートのルール"を作成することが可能で、これにより特定のセキュリティ調査結果を評価から除外することができます。つまり、組織と無関係なコントロールを評価対象から除外する要件も満たされます。
このように、SCC Premiumをアクティベートし、ミュートのルールを作ることで、自動化されたシステムが関連するコントロールだけを評価し、無関係なものは評価から除外するという要件を満たすことが可能となります。
不正解についての説明：
選択肢：無関係なすべてのセキュリティ所見に、セキュリティ例外を示すタグと値をマークします。マークされた調査結果をすべて選択し、表示されるたびにコンソール上でミュートします。Security Command Center（SCC）Premiumをアクティブ化します
この選択肢が正しくない理由は以下の通りです。
Security Command Center（SCC）を使うのは適切ですが、組織が継続的に評価されることを望むため、その都度コンソール上で手動でミュートするという方法は効率的ではありません。自動化されたプロセスを作成するためには、SCCでミュートするルールを設定することが必要です。
選択肢：Security Command Center（SCC）からすべての調査結果をCSVファイルにダウンロードします。ファイル内のCIS Google Cloud Foundation 1.3の一部である調査結果をマークします。関連性がなく、会社のスコープ外のエントリは無視します
この選択肢が正しくない理由は以下の通りです。
CSVファイルへのダウンロードを用いた方法は、適切なセキュリティ調査結果の除外が自動化されていないため不適切です。自動化されたシステムやプロセスを求められる問題文の要求に対して、この手法は手動での作業が必要となります。
一方、SCC Premiumを用いる正解の選択肢では評価結果をミュートするルールを作成することで自動化が実現でき、問題文の要求を正確に満たしています。
選択肢：外部監査会社に、必要なCISベンチマークを含む独立した報告書の提出を依頼します。監査範囲において、一部の管理は不要であり、無視しなければならないことを明確にします
この選択肢が正しくない理由は以下の通りです。
外部監査会社に依頼することは自動化されたシステムまたはプロセスの作成とは言えず、自動化要件を満たしません。
また、この方法では継続的な評価が難しく、評価が関連するコントロールのみに限定される保証もありません。
それに対して、Security Command Centerでは、必要なベンチマークを自動化して継続的に評価し、特定の調査結果をミュートすることで、関連しない管理を排除することが可能です。
参考リンク：
https://cloud.google.com/security-command-center/docs/how-to-use-mute-findings
https://cloud.google.com/security-command-center/docs/concepts-security-command-center-overview
https://www.cisecurity.org/benchmark/google_cloud_computing_platform/
</div></details>

### Q.  問題35: 未回答
ある企業がCompute Engine上でアプリケーションを実行しています。このアプリケーションにバグがあり、悪意のあるユーザーがスクリプトを繰り返し実行し、その結果、Compute Engineのインスタンスがクラッシュしてしまいました。バグは修正されましたが、このハッキングが再発した場合に備えて通知を受け取りたいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. プロセスの健全性条件を使用して、Google Cloud Operation Suiteでアラートポリシーを作成し、スクリプトの実行回数が必要な閾値未満であることを確認します。通知を有効にします
2. スクリプトの実行ごとにCloud Loggingにログを記録します。BigQueryをログシンクとして設定し、特定の時間枠内の実行回数をカウントするBigQueryスケジュールクエリを作成します
3. Cloud Loggingにスクリプトのすべての実行をログします。Cloud Loggingでログにユーザー定義のメトリックを作成し、メトリックを表示するGoogle Cloud Operation SuiteDashboardを作成します
4. Google Cloud Operation Suiteで、CPU使用率メトリクスを使用してアラートポリシーを作成します。閾値を80%に設定し、CPU使用率がこの80%を超えた場合に通知されるようにします
<details><div>
    答え：1
この問題では、悪意のあるユーザーによって引き起こされる潜在的なハッキングを監視し、それに関する通知を受け取ることに焦点を当てています。アプリケーションがCompute Engine上で実行され、過去にバグによりインスタンスがクラッシュしたという事実が重要です。また、バグ自体は修正されたが、再発に備えて通知が必要だとの要件も考慮する必要があります。Google Cloud Operation Suite、Cloud Logging、BigQueryの各機能をどのように利用すればハッキングの再発を検知できるかを理解することが重要です。さらに、シナリオは悪意のあるユーザーのスクリプトの繰り返し実行を特定するための適切な監視と通知策を見つけることに集中しています。
基本的な概念や原則：
Google Cloud Operation Suite：Google Cloudのパフォーマンスと健全性を監視、診断、アラート設定、操作の最適化、分析、表示を行うための統合管理ツールです。
アラートポリシー：異常な事態や重要な状況が発生した際に、指定した通知チャンネルから通知を受け取るための設定です。
プロセスの健全性条件：システムやアプリケーションの健全性を監視するための条件設定です。異常値や閾値を指定して、標準外の状態やクラッシュを検知します。
Cloud Logging：Google Cloudのログ管理サービスです。アプリケーションやシステムから生成されるログデータを一元的に管理し、分析と監視を行います。
メトリクス：パフォーマンスや利用状況を測定、トラッキングするための指標です。Google Cloudでは、メトリクスに基づいて監視やアラート設定を行うことが可能です。
BigQuery：Google Cloudのフルマネージド型、サーバーレス型の大規模なデータウェアハウスサービスです。大量のデータのクエリ実行を高速かつ柔軟に行うことが可能です。
ログシンク：Google CloudのLoggingで使用され、ログエントリをエクスポートするための機能です。シンクは特定の種類のログを指定したCloud Storage、BigQuery、Pub/Subへエクスポートします。
正解についての説明：
（選択肢）
・プロセスの健全性条件を使用して、Google Cloud Operation Suiteでアラートポリシーを作成し、スクリプトの実行回数が必要な閾値未満であることを確認します。通知を有効にします
この選択肢が正解の理由は以下の通りです。
Google Cloudのオペレーションスイートは、ログ監視、エラーレポート、アラートポリシーなど、一連の監視ツールを提供しています。アラートポリシーは特定の条件が満たされたときに通知を行う仕組みであり、これを使用してスクリプトの繰り返し実行や、その結果となるCompute Engineのインスタンスのクラッシュのような異常状態を検知し、事前に対策を立てることが可能になります。健全性条件を設定すれば、特定のプロセスや動作の状態を監視する事ができ、予期しない繰り返し実行が始まった際にすぐに検知し、通知を受け取ることができます。これにより、同様のハッキングが再発した場合も早期発見し迅速に対応することができます。
不正解についての説明：
選択肢：Google Cloud Operation Suiteで、CPU使用率メトリクスを使用してアラートポリシーを作成します。閾値を80%に設定し、CPU使用率がこの80%を超えた場合に通知されるようにします
この選択肢が正しくない理由は以下の通りです。
CPU使用率の高さは、アプリケーションに問題があることを必ずしも示しません。CPU使用率が80％を超えることは、アプリケーションが活発に動作しているだけかもしれません。ここでは特定のスクリプトの実行回数によるクラッシュを検知することが求められており、そのためにはプロセスの健全性条件を用いてアラートポリシーを作成する方が適しています。
選択肢：Cloud Loggingにスクリプトのすべての実行をログします。Cloud Loggingでログにユーザー定義のメトリックを作成し、メトリックを表示するGoogle Cloud Operation SuiteDashboardを作成します
この選択肢が正しくない理由は以下の通りです。
ダッシュボードはリアルタイムの監視に役立ちますが、特定の不正行為が再発した際の自動的な通知の提供はできません。通知を得るためにはCloud Operation Suiteのアラートポリシーが必要です。
選択肢：スクリプトの実行ごとにCloud Loggingにログを記録します。BigQueryをログシンクとして設定し、特定の時間枠内の実行回数をカウントするBigQueryスケジュールクエリを作成します
この選択肢が正しくない理由は以下の通りです。
BigQueryでログの解析を行うのは時間がかかり、クラッシュが起きてからの対応になってしまいます。対照的にGoogle Cloud Operation Suiteを使用すると、異常な状態が発生した瞬間に通知を受け取ることが可能なため、事前に問題を検知し対応することができます。
参考リンク：
https://cloud.google.com/monitoring/alerts/using-alerting-policies
https://cloud.google.com/logging/docs/logs-based-metrics
https://cloud.google.com/logging/docs/export/bigquery
</div></details>

## 5

### Q.  問題1: 未回答
組織でBigQuery分析データウェアハウスを管理しています。すべての顧客のデータを共通のテーブルに保持する一方で、行と列の権限に基づいてクエリアクセスを制限したいと考えています。クエリ以外の操作はサポートしていません。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、BigQuery分析データウェアハウスの管理と、顧客のデータアクセス制限に関する要件が提示されています。顧客が共通のテーブル内のデータにクエリを実行しますが、それぞれのクエリアクセスは行と列の権限に基づいて制限されるべきで、クエリ以外の操作はサポートされません。この要件を満たすために選ぶべき選択肢は、行レベルと列レベルのアクセス制御の設定方法に基づいています。BigQueryのセキュリティ機能とその適切な利用に理解が必要です。
基本的な概念や原則：
BigQuery：Google Cloudのフルマネージド、サーバーレス、高度にスケーラブルなエンタープライズデータウェアハウスです。大規模な分析ワークロードに対応し、SQLクエリを使用してデータを照会することができます。
行レベルのアクセスポリシー：特定の行へのアクセスを制限するように設定したポリシーです。フィルタ式を使って、どのユーザーがどの行にアクセスできるかを制御します。
列レベルのポリシータグ：特定の列へのアクセスを制限するためのポリシーです。データカテゴリや機密度などに基づいて、どのユーザーがどの列にアクセスできるかを制御します。
Cloud Key Management Service（KMS）：Google Cloudの暗号化キー管理システムで、データの暗号化と復号を行います。ただし、列レベルのアクセス制限には適していません。
データマスキング：特定のデータを非表示にするプロセスです。しかし、BigQueryでは直接的なデータマスキング機能は提供していません。
正解についての説明：
（選択肢）
・フィルタ式をFALSEに設定してクエリを実行したときに、結果データを制限する行レベルのアクセスポリシーを作成します
・列レベルのポリシータグを作成して、クエリ実行時に列へのアクセスを制御します
この選択肢が正解の理由は以下の通りです。
まず、"フィルタ式をFALSEに設定してクエリを実行したときに、結果データを制限する行レベルのアクセスポリシーを作成します"は、BigQueryの行レベルセキュリティを活用した制御方法で、フィルタ式がFALSEと評価される行はクエリの結果から除外されます。これにより、特定のユーザーが特定の行にアクセスすることを制限することができます。
また、"列レベルのポリシータグを作成して、クエリ実行時に列へのアクセスを制御します"は、BigQueryの列レベルセキュリティを実現する手段であり、ポリシータグを用いてアクセスを制御することで、特定のユーザーが特定の列にアクセスすることを制限します。
したがって、これらのアプローチは、共通のテーブルに保持された顧客データへのクエリアクセスを制限するための適切な手段です。
不正解についての説明：
選択肢：フィルタ式をTRUEに設定してクエリを実行したときに、結果データを制限する行レベルのアクセスポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
フィルタ式をTRUEに設定すると、すべての行が条件に一致するため、特定のユーザーのアクセス制限が行われず、結果として行レベルのアクセスポリシーが効果的に作成できないからです。
一方、フィルタ式をFALSEに設定すると、クエリによってアクセスが制限されるため、特定の行へのアクセス制限が可能となります。
選択肢：Cloud Key Management Service（KMS）でAEAD（Authenticated Encryption with Associated Data）機能を使用して列レベルの暗号化を構成し、クエリ実行時に列へのアクセスを制御します
この選択肢が正しくない理由は以下の通りです。
BigQueryでは、Cloud KMSのAEAD機能を使用した列レベルの暗号化はサポートしていないため、これはアクセス制限の手段として使用できません。代わりに列レベルのアクセス制限には、列レベルのポリシータグを使用します。
選択肢：動的なデータマスキングルールを構成して、クエリ実行時に列へのアクセスを制御します
この選択肢が正しくない理由は以下の通りです。
動的なデータマスキングルールはBigQueryでは直接サポートされておらず、列アクセスを制御するのに柔軟性が欠けています。その代わりに列レベルのポリシータグが正確なアクセス制御を提供します。
参考リンク：
https://cloud.google.com/bigquery/docs/row-level-security-intro
https://cloud.google.com/bigquery/docs/column-level-security-intro
https://cloud.google.com/bigquery/docs/best-practices-access-control
</div></details>

### Q.  問題2: 未回答
あなたは、現在の保守契約が切れる前に、会社のデータセンターからGoogle Cloudにレガシーアプリケーションを移行するタスクを引き受けています。アプリケーションがどのポートを使用しているのかわからず、確認できるドキュメントもありません。この状況で、環境を危険にさらすことなく移行を完了したいと考えています。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ドキュメンテーションが不十分で、アプリケーションがどのポートを使用しているのか分からないレガシーアプリケーションのGoogle Cloudへの移行が課題となっています。適切な移行戦略とネットワーク管理の手法を選択する必要があります。注目すべきは"リフト＆シフト"アプローチ、カスタムネットワーク、VPCファイアウォールルールの使用、VPCフローログの使用、アプリケーションのリファクタリング、Cloud Functionsなどです。これらの要素を理解し、それぞれの選択肢が移行タスクと保全の要件をどの程度満たすかを考察することが求められています。
基本的な概念や原則：
リフト＆シフト：既存のアプリケーションをそのままクラウド環境に移行する方法です。アプリケーションの構造を変更せず、早期の実装が可能ですが、クラウド環境の特性を十分に活かすことが難しい場合もあります。
VPC（Virtual Private Cloud）：Google Cloud上で定義可能な、プライベートな仮想ネットワーク環境です。VPC内では、ユーザーが設定したネットワークのルールに基づいてリソース間の通信が管理されます。
VPCファイアウォールルール：VPC内において、特定の通信を許可したり、拒否したりするためのルールを定義します。これによりアプリケーションのセキュリティを強化することができます。
VPCフローログ：VPCネットワークの流入・流出トラフィックのログです。これにより、不正なトラフィックを検出したり、パフォーマンスの問題を診断したりすることが可能です。
適切なトラフィックの確認：アプリケーションが正しく動作するために必要なネットワーク通信を確認します。これにはVPCファイアウォールルールやVPCフローログが利用されます。
アプリケーションリファクタリング：既存のアプリケーションを改良し、新しいアーキテクチャーやプラットフォームに適応させる作業のことです。これによりクラウドの特性をより活かすことが可能になりますが、実装には時間とコストが必要です。
マイクロサービスアーキテクチャ：アプリケーションを小さな独立したサービスに分けるアーキテクチャのことです。各マイクロサービスは独自のプロセスとデータストレージを持ち、APIを介して他のサービスとやりとりします。これにより、開発と運用のフレキシビリティが向上します。
正解についての説明：
（選択肢）
・"リフト＆シフト"アプローチを採用して、アプリケーションを分離プロジェクトに移行します。VPCファイアウォールルールを使用して、すべての内部TCPトラフィックを有効にします。VPCフローログを使用して、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正解の理由は以下の通りです。
まず、リフト＆シフトとは、既存のサービスをそのままクラウドに移行する戦略です。この方法を使用すると、アプリケーションの変更が最小限になり、移行の複雑性とリスクが軽減されます。
次に、VPCファイアウォールルールを使用して、すべての内部TCPトラフィックを有効にすると、アプリケーションが必要とするすべてのポートを開放できます。これにより、アプリケーションが正常に機能することが確認できます。ただし、この方法を使用すると、アプリケーションが必要とするすべてのTCPトラフィックが許可され、セキュリティ上のリスクが発生する可能性があります。そのため、VPCフローログを使用して、アプリケーションが正常に機能するためにどのトラフィックを許可すべきかを判断することが重要です。フローログにより、リアルタイムでネットワークフローデータをキャプチャし、分析することができます。これにより、不要なポートを特定し、それらを閉じることでセキュリティを強化することが可能となります。
不正解についての説明：
選択肢："リフト＆シフト"アプローチを採用して、カスタムネットワークでアプリケーションを分離プロジェクトに移行します。VPC内のすべてのトラフィックを無効にし、ファイアウォールログを調べて、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正しくない理由は以下の通りです。
VPC内のすべてのトラフィックを無効にすると、レガシーアプリケーションの機能が全て停止してしまうためです。正解の選択肢では一時的に全てのTCPトラフィックを許可し、実際のトラフィックを見てから制限する方法を選んでいます。
選択肢：アプリケーションを、GKEクラスター内のマイクロサービスアーキテクチャにリファクタリングします。ファイアウォールルールを使用して、クラスターの外部からのすべてのトラフィックを無効にします。VPCフローログを使用して、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正しくない理由は以下の通りです。
アプリケーションをマイクロサービスアーキテクチャにリファクタリングすることは時間がかかり、アプリケーションがどのポートを使用しているかわからないという問題を解決しません。
また、保守契約が切れる前に移行を完了するという要件に対して、リファクタリングは現実的な解決策ではありません。
選択肢：アプリケーションを、分離されたプロジェクトのCloud Functionsでホストされるマイクロサービスアーキテクチャにリファクタリングします。ファイアウォールルールを使用して、プロジェクトの外部からのすべてのトラフィックを無効にします。VPCフローログを使用して、アプリケーションが適切に動作するためにどのトラフィックを許可する必要があるかを判断します
この選択肢が正しくない理由は以下の通りです。
リファクタリングは、アプリケーションのコードの構造を改変するプロセスであり、時間と労力がかかるため、現在の保守契約が切れる前に移行を完了するという要件を満たすのが困難です。
また、使用するポートが不明な場合、リファクタリングはリスクが高いため、ここでの最適な解決策は"リフト＆シフト"アプローチです。
参考リンク：
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/architecture/vm-migration-validation-with-Google Cloud-migration-landing-zone
</div></details>

### Q.  問題3: 未回答
ある企業がGoogle Cloud上にアプリケーションをデプロイしています。会社のポリシーでは、少なくとも2つの地理的ロケーションにデータを自動的に複製できるソリューションを使用して長期データを保存する必要があります。
どのストレージソリューションの使用が許可されていますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、データの地理的冗長性を持つ特定のストレージソリューションについて問われています。企業のポリシーから、求められるソリューションは少なくとも2つの地理的なロケーションでデータを保存する機能が必要で、それが自動的に行われる必要があることを理解することが重要です。選択肢の中からこの要件を満たすストレージソリューションを選びましょう。
基本的な概念や原則：
Cloud BigQuery：Google Cloudの高度なデータ分析ワーケハウスサービス。複数の地域にまたがってデータを保存することが可能です。大規模なデータセットに対する分析をリアルタイムで行うことが可能で、長期データの保存にも対応しています。
Compute Engine SSDディスク：Google CloudのCompute Engineで使用するためのSSDストレージ。高性能な読み書き速度を提供しますが、単一の地域でのみ存続します。
Compute Engine Persistent Disk：Google CloudのCompute Engineで使用するための高性能ストレージ。SSDディスクとは異なり、データは耐久性がありますが、単一の地域でのみ存続します。
Cloud Bigtable：Google CloudのNoSQL Big Dataデータベースサービス。大規模な分析と操作ワークロードに対応できますが、データは指定した単一の地域に保存されます。
正解についての説明：
（選択肢）
・Cloud BigQuery
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのBigQueryは高性能のデータウェアハウスであり、その特性として自動的なデータレプリケーションと災害復旧が提供されています。BigQueryは独自のネットワークインフラストラクチャを使用してデータをGoogle内部の複数の物理的な場所に分散保存することで、データの堅牢性と耐久性を確保します。これにより、データセットの一部が何らかの理由で使用できなくなった場合でも、データの利用が可能となります。
また、BigQueryは長期データの保存に利用可能であり、大量の生データをリアルタイムに追加及び更新できます。そのため、企業の要件である複数の地理的ロケーションにデータを自動複製し、長期データを保存するというポリシーを満たすことが可能です。
したがって、BigQueryはこのシナリオにおいて適切なソリューションと考えられます。
不正解についての説明：
選択肢：Cloud Bigtable
この選択肢が正しくない理由は以下の通りです。
Cloud Bigtableは単一リージョン内での複製が可能な高性能NoSQLデータベースであり、データを少なくとも2つの地理的ロケーションに自動的に複製する要件を満たせません。
それに対して、Cloud BigQueryはデフォルトでリージョン間ののデータ複製を提供します。
選択肢：Compute Engine SSDディスク
この選択肢が正しくない理由は以下の通りです。
Compute Engine SSDディスクは単一のゾーンまたはリージョンにデータを保存し、自動的に複数の地理的ロケーションにデータを複製する機能を持たないため、適用できません。
一方、Cloud BigQueryは自動的にデータを複製し、複数地域に保存することが可能です。
選択肢：Compute Engine Persistent Disk
この選択肢が正しくない理由は以下の通りです。
Compute Engine Persistent Diskは単一の地理的ロケーションにデータを保存します。これは、少なくとも2つの地理的ロケーションにデータを複製するポリシーに反します。
一方、Cloud BigQueryはデータの自動的な地理的な冗長性を提供します。
参考リンク：
https://cloud.google.com/bigquery/docs/locations
https://cloud.google.com/bigtable/docs/replication
https://cloud.google.com/compute/docs/disks#repds
</div></details>

### Q.  問題4: 未回答
あなたの会社はGoogle Cloudを使用しており、一般に公開されているネットワーク資産があります。あなたは、最小限の時間で、ソフトウェアツールを使用して、これらの資産を発見し、これらの資産のセキュリティ監査を実行したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、公開されているネットワーク資産の発見とセキュリティ監査の実行が求められています。また、最小限の時間で、ソフトウェアツールを用いてこれを行いたいとの要件があります。したがって、選択肢を見る際には、公開されているネットワーク資産の特定とその監査が可能なツールを提供するオプションを探し、かつそれが最小限の時間で実行可能であるかどうかを評価する必要があります。
基本的な概念や原則：
Cloud Asset Inventory：Google CloudのリソースとIAMポリシーを検索、分析、監視するためのサービスです。リソース設定の変更を追跡したり、自動的に情報を取得したりすることができます。
ネットワークセキュリティスキャナー：Google Cloud上のネットワークリソースの脆弱性を定期的にスキャンし、潜在的な問題を報告するツールです。
ソフトウェアツールによるセキュリティ監査：ソフトウェアツールを使用して、脆弱性や潜在的な脅威を発見し、評価するためのプロセスです。これにはネットワークスキャン、構成管理、ログ分析などが含まれます。
プラットフォームセキュリティスキャナ：特定のプラットフォームや技術を対象としたセキュリティスキャナーです。特定の脆弱性を特定し、修正の推奨を提供します。
外部資産：企業のデジタルフットプリントの一部で、企業が所有するが直接管理していない資産のことを指します。これには、パートナーやサプライヤーが管理するウェブサイトやCloud Storage、IPアドレスなどが含まれます。
正解についての説明：
（選択肢）
・Cloud Asset Inventoryを使用してすべての外部資産を特定し、それらに対してネットワークセキュリティスキャナーを実行します
この選択肢が正解の理由は以下の通りです。
まず、要件は資産の発見とセキュリティ監査を最小限の時間で実行することを求めています。そのためには、Cloud Asset Inventoryとネットワークセキュリティスキャナーの組み合わせが最も適しています。
Cloud Asset Inventoryは、Google Cloudのすべての資産に関する情報のスナップショットや履歴を提供するサービスで、これによりあなたの会社の公開されているネットワーク資産を素早く特定できます。公開情報の範囲は広く、ストレージバケットやデータベースインスタンス、仮想マシンなど、Google Cloudのサービスに関連するあらゆる情報を含んでいます。
一方、ネットワークセキュリティスキャナーは、指定したネットワーク資産に対するセキュリティ脆弱性の検査を行うツールです。これらの資産に対してセキュリティスキャンを実施することで、可能な攻撃経路を特定し、それを是正する対策を講じることが可能となります。
したがって、この選択肢が最も効率的に要件を満たす方法と言えるでしょう。
不正解についての説明：
選択肢：組織内のすべてのインスタンスでプラットフォームセキュリティスキャナを実行します
この選択肢が正しくない理由は以下の通りです。
プラットフォームセキュリティスキャナを全インスタンスで実行する方法では、公開されているネットワーク資産を迅速に特定できず効率が悪いです。
一方、Cloud Asset Inventoryを使うと、外部資産を効率的に特定でき、その上でネットワークセキュリティスキャナを実行できます。
選択肢：Googleが承認したセキュリティベンダーに監査を依頼します
この選択肢が正しくない理由は以下の通りです。
Googleが承認したセキュリティベンダーに監査を依頼する方法は最小限の時間でセキュリティ監査を行うという要件に反します。それは、外部のベンダーと連携し、監査を実施するための時間とコーディネーションが必要になるからです。対象的に、Cloud Asset Inventoryとネットワークセキュリティスキャナーを使えば短時間で自動的に資産を発見し、セキュリティ監査を実行することが可能です。
選択肢：保留中の監査についてGoogleに通知し、スキャンを実行する前に確認を待ちます
この選択肢が正しくない理由は以下の通りです。
監査の実行についてGoogleに通知し、確認を待つという選択肢は、自社ネットワークのセキュリティ監査をGoogleが直接行うという誤解に基づいています。
逆に、Cloud Asset Inventoryとネットワークセキュリティスキャナーは、自社で迅速にネットワーク資産の検出と監査を行うツールです。
参考リンク：
https://cloud.google.com/asset-inventory/docs/overview
https://cloud.google.com/security-command-center/docs/concepts-overview
https://nmap.org/book/man.html
</div></details>

### Q.  問題5: 未回答
あなたは会社の開発チームに所属しています。あなたは、GKE上のステージングでホストされているウェブアプリケーションが、入力されたデータを最初に適切に検証することなく、ウェブページにユーザデータを動的に取り込んでいることに気づきました。このため、攻撃者は実運用環境において、被害者ユーザのブラウザで不正なコマンドを実行したり、任意のコンテンツを表示したりできる可能性があります。
この脆弱性をどのように防ぎ、修正すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ウェブアプリケーションのセキュリティ脆弱性に対処するための最適な方法を問います。具体的な脆弱性としてクロスサイトスクリプティング（XSS）が挙げられています。適切な手段を選択するためには、この脆弱性がどのような挙動をもたらすのか、どのように防ぐことができるのかを理解する必要があります。また選択肢からは、攻撃のシミュレーション、IPに基づくフィルタリング、HTTPSロードバランサーやCloud Armorの使用、古いライブラリの確認等、複数の防御手段が示されています。課題はこれらの中から、XSS攻撃に最も効果的な対策を選ぶことです。
基本的な概念や原則：
GKE（Google Kubernetes Engine）：Google CloudのマネージドKubernetesサービスです。コンテナ化されたアプリケーションをデプロイ、スケール、更新するための環境を提供します。
Web Security Scanner：Google Cloudの自動化されたスキャナーで、Webアプリケーションの脆弱性を探すツールです。クロスサイトスクリプティング（XSS）や、SQLインジェクションなどの一般的な脆弱性を検出することができます。
エスケープ処理：潜在的な攻撃コードが含まれる可能性があるデータを安全な形式に変換するプロセスです。これにより、攻撃者が意図しないコードを実行するのを防ぐことができます。
Cloud Identity-Aware Proxy（IAP）：Google Cloudのサービスで、アプリケーションへのアクセスをセキュアに管理します。しかし、ユーザーデータの検証またはエスケープ処理を自動的に提供するものではありません。
Cloud Armor：Google Cloudのサービスで、DDoS攻撃などの一般的なWeb攻撃を防ぐ機能を提供します。しかし、クライアントサイドの脆弱性（例えば、XSS）を防ぐことはできません。
HTTPSロードバランサー：HTTPSトラフィックを複数のバックエンドサービスに分散するGoogle Cloudのサービスです。セキュリティを強化するために使用することができますが、XSS攻撃を防ぐ機能は提供していません。
ライブラリの保護されたバージョン：セキュリティパッチが当てられ、脆弱性が修正されているライブラリのバージョンです。これを使用することで、一部のセキュリティリスクを軽減することができますが、ユーザーデータのエスケープ処理を自動的に提供するわけではありません。
正解についての説明：
（選択肢）
・ステージングでWeb Security Scannerを使ってXSSインジェクション攻撃をシミュレートし、コンテキストの自動エスケープをサポートするテンプレートシステムを使います
この選択肢が正解の理由は以下の通りです。
まず、Web Security ScannerはGoogle Cloudが提供するセキュリティ診断ツールで、Webアプリケーションの脆弱性を特定できる機能があります。該当のウェブアプリケーションがユーザデータを検証せずに動的に取り込んでいると問題文にあるので、このツールを使用して異常があるかどうかを確認し、特にXSS（クロスサイトスクリプティング）攻撃をシミュレートします。これにより、擬似的に攻撃を行い、その対策をあらかじめ検討することができます。
また、コンテキストの自動エスケープをサポートするテンプレートエンジンの使用は、入力値がウェブページに反映される際に、その値がコードとして実行されることを防ぎます。利用者による入力がそのままHTMLなどのコードやデータとして扱われることで生じる脆弱性、XSS攻撃の対策となります。これにより、攻撃者が不正なコマンドを実行することや、任意のコンテンツを表示する手段を取り除き、セキュリティの強化に寄与します。
不正解についての説明：
選択肢：IPアドレスまたはエンドユーザーデバイスの属性に基づくCloud Identity-Aware Proxy（IAP）を使用して、脆弱性を防止および修正します
この選択肢が正しくない理由は以下の通りです。
Cloud IAPは認証と認可を提供してアクセスを制御することに役立つサービスですが、クロスサイトスクリプティング（XSS）といったウェブページ内部での不正なコマンドの実行を防止する機能はありません。
これに対して、Web Security ScannerはXSS等の脆弱性を検出し、テンプレートシステムは不正なコードの実行を防ぐための解決策です。
選択肢：HTTPSロードバランサーをセットアップし、本番環境にCloud Armorを使用して潜在的なXSS攻撃を防ぐ
この選択肢が正しくない理由は以下の通りです。
HTTPSロードバランサーとCloud Armorを導入すると、一部のセキュリティリスクは軽減されるかもしれませんが、この設定ではXSS攻撃からの防御に特化していません。
一方、Web Security Scannerを使用すると、XSSインジェクション攻撃をシミュレートし、その脆弱性を具体的に特定することが可能となります。
選択肢：Web Security Scannerを使用して、コード内の古いライブラリの使用を検証し、含まれるライブラリの保護されたバージョンを使用します
この選択肢が正しくない理由は以下の通りです。
古いライブラリの使用を検証し、保護されたバージョンを使用することは一般的に良いセキュリティ対策ですが、これだけでは具体的な問題、つまりユーザデータの適切な検証とXSS攻撃の防止に直接対処していません。
正解の選択肢は、問題の具体的な脆弱性を対象にした手段を提供しています。
参考リンク：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/appengine/docs/standard/python3/using-templates
https://owasp.org/www-community/attacks/xss/
</div></details>

### Q.  問題6: 未回答
あなたは、ブートディスクのソースとして使用できるイメージを制限したいと考えています。これらのイメージは専用のプロジェクトに保存されます。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のプロジェクトに保管されているイメージだけがブートディスクのソースとして利用可能にするためにどの方法が適しているかを問われています。そのため、組織ポリシーサービスやリソースマネージャーといったGoogle Cloudの管理ツールを使った対策の理解が必要です。特に、制約とその設定方法を理解することが重要です。計算機能に影響を与える制約に関連した選択肢を適切に評価する必要があります。
基本的な概念や原則：
組織ポリシーサービス：Google Cloudの組織ポリシーの管理を行うサービスです。組織のリソースに対する特定の制約を設定し、コンプライアンスを維持するのに役立ちます。
compute.trustedImageProjects制約：ブートディスクのソースとして使えるイメージを制限するための制約です。この制約を使用すると、特定のプロジェクトからのイメージのみを許可することができます。
許可操作：組織ポリシーサービスで使用できる操作の一つです。特定のリソースやアクションの実行を許可することができます。
ホワイトリスト：許可される要素のリストです。セキュリティコンテキストでは、特定のユーザー、IPアドレス、プログラムなど、特権を付与する要素のリストを作成します。
リソースマネージャー：Google Cloudのリソースを組織やプロジェクトレベルで管理するサービスです。アクセス権限やポリシーの設定などを行うことができます。
"Compute Image User"ロール：Compute Engineの特定のイメージを使用してインスタンスを作成する権限を持つロールです。
正解についての説明：
（選択肢）
・組織ポリシーサービスを使用して、組織レベルでcompute.trustedimageProjects制約を作成します。許可操作のホワイトリストとして、信頼されたプロジェクトをリストします
この選択肢が正解の理由は以下の通りです。
ブートディスクのソースとして使用できるイメージを制限するという目的に直接対応する手段として、組織ポリシーサービスが挙げられます。組織ポリシーサービスは、Google Cloudリソースの開発および運用に対する一連の典型的な制約を提供します。その中でも、compute.trustedImageProjects制約は、特定のプロジェクトからのイメージのみを信頼し、それをブートディスクのソースとして使用することを許容する制約になります。この制約により、組織全体でブートディスク作成に使用されるイメージのソースを制御することが可能になり、不適切なイメージからのブートディスク作成を抑止することができます。
したがって、この要件を満たすためには、組織ポリシーサービスを使用して、組織レベルでcompute.trustedImageProjects制約を作成し、許可操作のホワイトリストとして、信頼されたプロジェクトをリストするのが最適な解答となります。
不正解についての説明：
選択肢：組織ポリシーサービスを使用して、組織レベルでcompute.trustedimageProjects制約を作成します。拒否操作の例外として、信頼済みプロジェクトをリストします
この選択肢が正しくない理由は以下の通りです。
信頼済みのプロジェクトを拒否操作の例外としてリストするという考え方は誤っています。信頼済みのプロジェクトは許可するもので、許可操作のホワイトリストに追加すべきです。拒否操作の例外に追加すると、重要なプロジェクトが誤ってブロックされるリスクがあります。
選択肢：リソースマネージャーで、信頼できるプロジェクトのプロジェクト権限を編集します。組織をロール"Compute Image User"を持つメンバーとして追加します
この選択肢が正しくない理由は以下の通りです。
リソースマネージャーで信頼できるプロジェクトのプロジェクト権限を編集しても、特定のイメージの使用を制限することはできません。
それに対して、組織ポリシーサービスを使用すれば、compute.trustedimageProjects制約を作成し、特定のプロジェクトのイメージのみを許可操作のホワイトリストに追加できるため、要求を満たします。
選択肢：リソースマネージャーで、組織の権限を編集します。プロジェクトIDをロール"Compute Image User"を持つメンバーとして追加します
この選択肢が正しくない理由は以下の通りです。
リソースマネージャーで権限を編集し、プロジェクトIDを"Compute Image User"ロールを持つメンバーとして追加すると、そのメンバーは指定したプロジェクトのイメージにアクセスできます。しかし、これではブートディスクのソースとして使用できるイメージを制限するという要件に対応できません。
一方、組織ポリシーサービスを使って制約を作成すると、特定のプロジェクトだけがブートディスクのソースとして使用できるイメージを提供できるため、要件通りの制限が可能になります。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
https://cloud.google.com/compute/docs/access/iam
</div></details>

### Q.  問題7: 未回答
あなたはある組織のセキュリティチームのメンバーです。あなたのチームには、Webアプリケーションやデータ処理システムとともに、クレジットカード決済処理システムを含むGoogle Cloudプロジェクトが1つあります。あなたは、PCI監査基準の対象となるシステムの範囲を縮小したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、あなたが組織のセキュリティチームの一員として、PCI監査基準への対応とそれに伴うシステム範囲の縮小を考えています。公式な監査基準が関与している場合、その基準の主な目標と原則を理解しておくことが重要です。選択肢を評価する際には、特にPCI DSS（クレジットカード情報のセキュリティ基準）と関連する選択肢に対して注意深く検討するために、PCI監査の目的と要件に基づいて最適なセキュリティコントロールを選択することを心掛けてください。
基本的な概念や原則：
Google Cloudプロジェクト：Google Cloud上でリソースを管理するための主要な組織単位です。各プロジェクトは独立した設定、IAMポリシー、ネットワーキングなどを持つことができます。
PCI認証：クレジットカード情報の安全性を確保するための国際的な規格です。取引量に応じたレベルがあり、各レベルには特定の要求事項が定められています。
カード会員データ環境：クレジットカードデータを含む、あらゆる人、プロセス、技術の環境のことです。PCI監査では、これらの環境が厳しく監査されます。
多要素認証：ユーザーの身元を確認するために二つ以上の検証方法を使用するアクセス管理システムです。セキュリティレベルを向上させますが、PCI認証の範囲を縮小するわけではありません。
PA-DSS：クレジットカード業界が決定したソフトウェアのセキュリティ基準です。しかし、これが準拠しているだけではPCI監査の範囲を縮小するわけではありません。
VPN：インターネット上の公開ネットワークを利用しながら、プライベートネットワーク同様に安全に通信するための技術です。しかし、これを使用してもPCI監査の範囲を縮小するわけではありません。
正解についての説明：
（選択肢）
・カード会員データ環境を別のGoogle Cloudプロジェクトに移動します
この選択肢が正解の理由は以下の通りです。
セキュリティのベストプラクティスとして、特定の敏感情報（例えば、ここではクレジットカードデータ）を含むシステムは、他のシステムから分離・切り離すことが推奨されます。ここでは、PCI監査基準の対象となるシステムを、他のWebアプリケーションやデータ処理システムと物理的に分離することで、監査の範囲を縮小し、管理を容易にし、セキュリティリスクを最小限に抑えることができます。Google Cloudのプロジェクトは、リソースの組織化と分離を可能にする機能を提供し、このアプローチを容易にします。
したがって、カード会員データ環境を別のGoogle Cloudプロジェクトに移動することは、監査基準を満たすための適切な方法となります。
不正解についての説明：
選択肢：ウェブアプリケーションの管理者アクセスには多要素認証を使用します
この選択肢が正しくない理由は以下の通りです。
ウェブアプリケーションの管理者アクセスに多要素認証を使用することは、一般的なセキュリティ強化策ではありますが、PCI監査基準の対象範囲を縮小する目的には直接貢献しません。
一方、カード会員データを別のGoogle Cloudプロジェクトに移動することで、対象となるシステムの範囲が限定され、監査対象を縮小することが可能となります。
選択肢：PA-DSSに準拠していることが証明されたアプリケーションのみを使用します
この選択肢が正しくない理由は以下の通りです。
PA-DSSに準拠していることが証明されたアプリケーションのみを使用することは良いセキュリティプラクティスではありますが、それ自体ではPCI監査基準の対象となるシステムの範囲を縮小するものではありません。
それに対して、カード会員データ環境を別のGoogle Cloudプロジェクトに移動することで、監査範囲を限定できます。
選択肢：オフィスとクラウド環境間のすべての接続にVPNを使用します
この選択肢が正しくない理由は以下の通りです。
オフィスとクラウド環境間の接続にVPNを使用するのはセキュリティを高める手段の一つではありますが、これがPCI監査基準の対象となるシステムの範囲を縮小する直接的な効果はありません。
それに対して、カード会員データ環境を別のGoogle Cloudプロジェクトに移動することで、監査対象範囲を明確に分離、縮小できます。
参考リンク：
https://cloud.google.com/resource-manager/docs/creating-managing-projects
https://cloud.google.com/compliance/offerings#card_payment
https://cloud.google.com/solutions/pci-dss-compliance-in-Google Cloud
</div></details>

### Q.  問題8: 未回答
ある顧客が、マネージドインスタンスグループ（MIG）を使用して、センシティブなワークロードをCompute Engineベースのクラスターに移行したいと考えています。ジョブは大量に発生し、迅速に完了する必要があります。また、鍵のライフサイクルを管理できることが必要です。
この顧客の要件を満たすために、クラスター上のどのブートディスク暗号化ソリューションを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客がCompute Engineベースのクラスターにセンシティブなワークロードを移行する際、速度の速さと暗号化キーのライフサイクルの管理が必要と述べています。そのため、Compute Engineベースのクラスターに移行する際に適切な暗号化ソリューションを選ぶ必要があります。選択肢を検討する際には、それぞれが速度とキーのライフサイクル管理にどのように対応しているかを見極めることが必要となります。
基本的な概念や原則：
Cloud Key Management Service（KMS）：Google Cloudの秘密鍵管理サービスです。ユーザーは自分で暗号化キーを管理し、そのライフサイクルを制御することができます。
顧客管理の暗号化キー（CMEK）：Cloud KMSで生成と管理される暗号化キーです。ユーザーは自分で鍵のライフサイクルを管理することができ、一部またはすべてのデータを特定の鍵で暗号化して保管できます。
顧客指定の暗号化キー（CSEK）：ユーザーが明示的に提供するキーで、特定の一部のデータを保護します。Google概念内において、このキーは課質者のローカル環境に保存され、Google自体がこれらの登録キーを知らないとされています。
マネージドインスタンスグループ（MIG）：Compute Engineの一部で、指定した数の一貫性のあるVMインスタンスを作成し、管理する機能です。大量のジョブを迅速に完了させるためのスケーリングに役立ちます。
ブートディスク暗号化：センシティブなデータを保護するためのセキュリティ対策です。ブート可能なディスクドライブ上のすべてのデータを暗号化して、不正なアクセスからデータを守ります。
正解についての説明：
（選択肢）
・Cloud Key Management Service（KMS）を利用した顧客管理の暗号化キー（CMEK）を使用します
この選択肢が正解の理由は以下の通りです。
まず、Cloud Key Management Service（KMS）を使用することで、顧客自身が鍵のライフサイクルを完全に管理することができます。これにより、鍵の生成、使用、ローテーション、そして廃棄までの各ステージを厳細にコントロールすることが可能になります。この柔軟性は、センシティブなワークロードを扱う顧客が適切なセキュリティ対策を確保する上で重要です。
そして、顧客管理の暗号化キー（CMEK）を使用することで、ブートディスクのデータを安全に暗号化可能です。これはユーザーがGoogle Cloud上で生成し、管理可能な暗号化キーであり、Compute Engineベースのクラスターのデータ保護に役立ちます。以上から、顧客が必要とするセキュリティ要件と、高速なワークロード処理の需要を両立するために、Cloud KMSとCMEKの組み合わせが最適であると言えます。
不正解についての説明：
選択肢：顧客指定の暗号化キー（CSEK）を使用します
この選択肢が正しくない理由は以下の通りです。
CSEK（顧客指定の暗号化キー）は、セキュリティが高い反面、鍵のライフサイクル管理を顧客自身が行う必要があり、これは手間がかかります。
一方、Cloud KMSを利用したCMEK（顧客管理の暗号化キー）は、Google Cloud上で鍵のライフサイクル管理が可能なため、この問題の要件をより効果的に満たします。
選択肢：デフォルトでの暗号化を使用します
この選択肢が正しくない理由は以下の通りです。
デフォルトの暗号化では、鍵のライフサイクルを自身で管理することは不可能です。要件である"鍵のライフサイクルを管理できる"という点を満たせません。
それに対して、Cloud KMSを使用したCMEKは、暗号化キーのライフサイクルを顧客が管理できるため、問題の要求を満たします。
選択肢：Google Cloudに転送する前にファイルを事前暗号化し、分析に利用します
この選択肢が正しくない理由は以下の通りです。
ファイルを事前に暗号化する方法では、クラスター上のブートディスクの暗号化に直接対応できず、また、鍵のライフサイクル管理も提供できません。
一方、Cloud KMSを利用するとCMEKを使ってディスクの暗号化が可能であり、鍵のライフサイクル管理も可能となります。
参考リンク：
https://cloud.google.com/compute/docs/instances/encrypt-disks-with-cmek
https://cloud.google.com/kms/docs
https://cloud.google.com/compute/docs/instances/create-start-instance#starting_an_instance_with_encryption_key
</div></details>

### Q.  問題9: 未回答
あなたは、2つのネットワークセグメントを設定する必要があります。1つは信頼できないサブネット、もう1つは信頼できるサブネットです。2つのネットワークセグメント間のすべてのトラフィックを検査するように、次世代ファイアウォール（NGFW）などの仮想アプライアンスを構成したいと考えています。トラフィックを検査するにはネットワークをどのように設計すればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、ネットワークセキュリティと隔離を強化するためのGoogle Cloudのネットワーク設計について問われています。2つの異なる信頼レベルのネットワークセグメントの間でトラフィックを検査するための仮想アプライアンスの設置が必要なシナリオです。この要件を満たすためには、各ネットワークセグメントを正しく定義し、それぞれに対して適切なアクセスポリシーを適用するネットワーク設計を理解することが重要です。また、仮想アプライアンスの配置とその接続方法にも注意を払う必要があります。これらの要素を考慮に入れ、四つの選択肢から最も適切なネットワーク設計を選ぶことが求められています。
基本的な概念や原則：
VPCネットワーク：Google Cloudの仮想プライベートクラウド（VPC）ネットワークは、仮想ネットワークリソースであり、物理的なプロセスをシミュレートするのに役立ちます。これは各プロジェクトのプライベートIPアドレススペースとなります。
サブネット：VPCネットワーク内のIPアドレス範囲。サブネットを用いることでネットワーク空間を区切ることができます。
次世代ファイアウォール （NGFW）：トラフィックの内容に基づいてパケットを許可またはブロックするための高度なセキュリティ機能を備えたファイアウォールの一種です。
仮想アプライアンス：ソフトウェアバージョンのネットワークアプライアンス（ファイアウォール、VPNデバイスなど）のことです。
複数のネットワークインターフェイス：物理デバイスまたは仮想アプライアンスが複数のネットワークに同時に接続するための方式です。
VPCピアリング：2つのVPCネットワーク間でトラフィックをプライベートに交換するための接続です。
カスタムルート：特定のデスティネーションへのネットワークトラフィックのパスを制御するのに使用されるネットワークルートです。
正解についての説明：
（選択肢）
・1. 2つのVPCネットワークをセットアップします。1つは信頼できるネットワーク、もう1つは信頼できないネットワークです
2. 複数のネットワークインターフェイスを使用して仮想アプライアンスを構成し、各インターフェイスがVPCネットワークの1つに接続されます
この選択肢が正解の理由は以下の通りです。
VPCネットワークを2つ設定することで、信頼できるネットワークと信頼できないネットワークが物理的に分離され、それぞれが個別のネットワーク空間を占有します。これによって、2つのネットワーク間のセキュリティを大幅に向上させることが出来ます。これは、一部の組織では信頼されたネットワークのセキュリティ確保が最優先課題となり、あらゆる予防措置を導入することが求められるので重要です。
また、複数のネットワークインターフェースを使用して仮想アプライアンスを構成することで、1つの信頼されたVPCネットワークからもう1つのVPCネットワークへ向かうすべてのネットワークトラフィックを検査できます。これによって、立たされたセキュリティポリシーに従い、要求に対する回答や、その逆のトラフィックを詳細に検査することができます。これは、侵入検知・防止システム（IDS/IPS）などのセキュリティ監視機能を実装するのに適しています。特に、次世代ファイヤーウォール（NGFW）などの仮想アプライアンスは、複数のネットワークインターフェースを持つことが一般的で、この要件を満たす設定が可能です。
不正解についての説明：
選択肢：1. 2つのサブネット（1つは信頼できるサブネット、もう1つは信頼できないサブネット）を持つ1つのVPCをセットアップします
2. 仮想アプライアンスを指すすべてのトラフィック（0.0.0.0/0）のカスタムルートを構成します
この選択肢が正しくない理由は以下の通りです。
同一のVPC内のサブネット間では直接トラフィックを送受信できますが、NGFWで検査するためには別々のネットワークが必要です。
したがって、1つのVPC内に2つのサブネットを作成すると、全てのトラフィックがNGFWを経由するわけではないため、必要なセキュリティ要件が満たされません。
選択肢：1. 2つのサブネット（1つは信頼できるサブネット、もう1つは信頼できないサブネット）を持つ1つのVPCをセットアップします
2. 仮想アプライアンスを指すすべてのRFC1918サブネットのカスタムルートを構成します
この選択肢が正しくない理由は以下の通りです。
2つのサブネットを1つのVPCで設定すると、信頼できないサブネットと信頼できるサブネット間の通信が自由になってしまいます。仮想アプライアンスがネットワーク間の全てのトラフィックを検査するためには、これらのネットワークは分離されていなければならず、正解選択肢のように2つの独立したVPCを設定するべきです。
選択肢：1. 2つのVPCネットワーク（1つは信頼できるネットワーク、もう1つは信頼できないネットワーク）をセットアップし、相互にピアリングします
2. 仮想アプライアンスを指す各ネットワーク上にカスタムルートを構成します
この選択肢が正しくない理由は以下の通りです。
VPCネットワーク間のピアリングはトラフィックを中継する能力がないため、仮想アプライアンス経由のトラフィック検査を設定することはできません。正解では各ネットワークインターフェイスがアプライアンスを経由し、トラフィックを検査できるようにします。
参考リンク：
https://cloud.google.com/vpc/docs/vpc-peering
https://cloud.google.com/vpc/docs/using-vpc
https://cloud.google.com/network-connectivity/docs/vpn/concepts/topologies#multiple-vpc-networks
</div></details>

### Q.  問題10: 未回答
ある組織が、現在のオンプレミス生産性ソフトウェアシステムからG Suiteに移行しようとしています。以前のオンプレミスシステムでは、地域の規制機関によって義務付けられたネットワークセキュリティ管理が行われていました。同組織のリスクチームは、G Suiteでもネットワークセキュリティ管理が維持され、有効であることを確認したいと考えています。この移行をサポートするセキュリティアーキテクトは、組織とGoogle Cloudとの間の新しい責任共有モデルの一部として、ネットワークセキュリティ管理が確実に実施されるようにすることを求められています。
どのようなソリューションが要件を満たすのに役立ちますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、組織がオンプレミスシステムからG Suiteへの移行を検討しているケースが提示されています。セキュリティアーキテクトは、地域の規制に対応したネットワークセキュリティ管理が維持されるように要求されています。問題文の情報を解釈すると、G SuiteというSaaS製品を適用することで、それ自体がビルトインのセキュリティソリューションを持つと思われます。これは、Googleが提供するクラウドサービスの一部としての責任を理解して選択肢を見ることが重要です。その上で、各選択肢のG Suiteとの統合と規制への対応を評価し、適切な答えを選ぶべきです。
基本的な概念や原則：
G Suite：Googleが提供するクラウドベースのビジネス向けプロダクトスイートです。メール、カレンダー、ドキュメント作成、ストレージなどのサービスを提供しています。
オンプレミスシステム：企業が自社の施設内などに設置する形で情報システムを運用する方式のことです。全ての管理と保守が自分たちの責任となります。
ネットワークセキュリティ管理：ネットワーク内のユーザーやシステム、データなどを保護するための施策や戦略です。"ファイアウォールルール"などを確認して適切に設定し、不正アクセスやデータ漏洩などを防ぎます。
責任共有モデル：クラウドサービスのセキュリティ面での責任を、サービス提供者と利用者で分担する考え方です。サービス提供者と利用者がどの部分について責任を持つかはサービスによります。
ビルトインセキュリティ：ソフトウェア、ハードウェア、システムの設計段階から組み込まれるセキュリティ機能のことで、G SuiteなどのSaaS製品には基本として含まれています。
SaaS製品：サービスとして提供されるソフトウェアのことで、インフラやハードウェアについてはサービス提供者が管理し、ユーザーはアプリケーションを利用するだけです。
Cloud Armor：Google Cloudの分散型サービス拒否（DDoS）攻撃、SQLインジェクションなどのWeb攻撃からアプリケーションを保護するセキュリティサービスです。一方、G SuiteなどのSaaS製品はセキュリティが組み込まれているため、Cloud Armorをセットアップする必要はありません。
正解についての説明：
（選択肢）
・ネットワークセキュリティはビルトインソリューションであり、G SuiteのようなSaaS製品にはGoogleのクラウド責任があります
この選択肢が正解の理由は以下の通りです。
まず、Googleの責任共有モデルでは、Googleはデータセンターやネットワークといったインフラストラクチャーレベルのセキュリティを担当します。つまり、Googleはそのネットワークとデータセンターのセキュリティに対し完全な責任を負うため、組織自体がネットワークセキュリティ管理のために別途労力を割く必要はありません。
また、G SuiteはSaaS（Software as a Service）製品であり、これによりユーザーはアプリケーションレベルのセキュリティに専念できます。そのため、ネットワークセキュリティはGoogleが担当することで確保されます。
さらに、GoogleのSaaS製品は、ビルトインのセキュリティソリューションを採用しています。これにより、独自のセキュリティ対策を設定することなく、ネットワークを安全にすることが可能となります。これらの要素が組み合わさって、選択肢のソリューションは、地域の規制に対するネットワークセキュリティ管理の要件を満たす適切な選択肢となります。
不正解についての説明：
選択肢：ファイアウォールルールが必要なコントロールに適合していることを確認します
この選択肢が正しくない理由は以下の通りです。
G SuiteはSaaS製品であり、そのセキュリティ設定はGoogleが管理します。オンプレミス環境と同じように、ユーザーが制御できるなどといったファイアウォールルールを設定することは出来ないからです。そのため、この選択肢はこのシナリオには適していません。
選択肢：Cloud Armorをセットアップして、G Suiteのネットワークセキュリティコントロールが管理できるようにします
この選択肢が正しくない理由は以下の通りです。
Cloud Armorは、主にGoogle Cloudのアプリケーションに対するDDoS攻撃やWEB攻撃を防ぐためのセキュリティサービスですが、G Suiteに適用することはできません。G Suiteのネットワークセキュリティ管理はGoogleが担当し、Cloud Armorを使って追加で設定する必要はありません。
選択肢：仮想プライベートクラウド（VPC）ネットワークを構築し、関連規則に従ってネットワークセキュリティを管理します
この選択肢が正しくない理由は以下の通りです。
VPCネットワークの構築と管理は、ネットワークのインフラストラクチャレベルでのセキュリティを提供しますが、G SuiteのようなSaaS製品はそのネットワークセキュリティがGoogleによって既に管理されています。
したがって、この選択肢は冗長であり、G Suiteの利用において必要以上の作業となります。
参考リンク：
https://cloud.google.com/security
https://cloud.google.com/docs/security/best-practices
https://support.google.com/a/answer/7587183?hl=en
</div></details>

### Q.  問題11: 未回答
あるデータベース管理者が、Cloud SQLインスタンス内で悪意のあるアクティビティが行われていることに気づきました。データベース管理者は、リソースの構成またはメタデータを読み取るAPI呼び出しを監視したいと考えています。データベース管理者はどのログを確認すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Cloud SQLインスタンスでの悪意のあるアクティビティを検出するための適切なログタイプを特定する必要があります。問題文のキーワードは"リソースの構成またはメタデータを読み取るAPI呼び出し"です。データベース管理者が監視したいのは読取り操作、つまりデータへのアクセスです。そのため、四つの選択肢の中からリソースへのアクセスに関連するログを選ぶことが重要です。
基本的な概念や原則：
データアクセスログ：Google Cloud上のリソースへの読み書きアクセスを記録するログです。このログは、消費されたリソースに基づいて課金され、リソースの内容や属性を表示します。
管理者活動ログ：Google Cloudサービスの管理操作を記録するログです。これには、リソースの作成、変更、削除など、大部分の書き込み操作が含まれます。
システムイベントログ：Google Cloudのインフラストラクチャサービスがシステムイベントを記録するログです。これには、スケジュールされたメンテナンスなど、ユーザーが直接制御できないイベントが含まれます。
アクセスの透明性ログ：Google Cloudのエンジニアやサポートスタッフが顧客データにアクセスした時のログです。これには、アクセス時間、アクセス理由、アクセスしたデータの場所や種類などの情報が含まれます。
正解についての説明：
（選択肢）
・データアクセス
この選択肢が正解の理由は以下の通りです。
Google Cloudでは、監視やログの分析にCloud Audit Logsを使用します。Cloud Audit Logsには管理活動ログとデータアクセスログの2つの主要な種類があります。管理活動ログはAPI呼び出しや、ユーザーアクティビティなどの管理操作を記録します。一方でデータアクセスログはリソースの読み取り、書き込み、更新操作を記録します。
したがって、データベース管理者がCloud SQLインスタンス内での悪意のあるアクティビティを調査したい場合、それがリソースの構成またはメタデータの読み取りに関連していると仮定すると、データアクセスログを確認することが適切です。
不正解についての説明：
選択肢：管理者活動
この選択肢が正しくない理由は以下の通りです。
管理者活動のログは、リソースの作成、変更、削除など、Google Cloudのリソースまたはサービスを管理する操作を監視します。しかし、問題の要件はAPIの読み取り操作の監視であり、これはデータアクセスのログの範囲に含まれるため、管理者活動のログでは要件を満たせません。
選択肢：システムイベント
この選択肢が正しくない理由は以下の通りです。
システムイベントログは、リソースのライフサイクルイベントの監視に用いられますが、リソースの構成やメタデータを読み取るAPI呼び出しの監視には不適切です。反対に、データアクセスログはAPI呼び出しを監視するためのものです。
選択肢：アクセスの透明性
この選択肢が正しくない理由は以下の通りです。
アクセスの透明性はGoogleの管理者によるアクセスを追跡するためのものであり、Cloud SQLインスタンスにおけるユーザーのアクションを監視することはできません。
一方、データアクセスログはリソースの構成やメタデータの読み取りを確認できます。
参考リンク：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/auditing
https://cloud.google.com/sql/docs/mysql/admin-api/logging
</div></details>

### Q.  問題12: 未回答
コンプライアンス上の理由から、組織は範囲内のPCI Kubernetesポッドが"範囲内の"ノードのみに存在することを確認する必要があります。これらのノードには"スコープ内の"ポッドのみを含める必要があります。
組織はこの目標をどのように達成すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、特定のノードでのみ特定のKubernetesポッドを実行する必要があるシナリオが設定されています。また、これらのノードにはこれらの特定のポッドのみが存在できると明記されています。これらの要件を満たすために、Kubernetesの仕組みや概念を理解し、適切な選択肢を選ぶことが求められます。選択肢を評価する時には、ノード制御とポッドのスケジューリングに関連する解決策を探し、組織がポッドが特定のノードに限定されていることを確実に保証できることを確認してください。
基本的な概念や原則：
Kubernetesのテイント（Taint）：ノードが特定のポッドのスケジューリングを受け付けないように設定する機能です。特定のロールや制限のあるノードへのポッドのスケジューリングを制御できます。
Kubernetesの許容範囲（Toleration）：テイントが設定されたノード上でポッドが実行できるようにする設定です。ポッドが特定のテイントを持つノードにスケジュールされるための条件を設定できます。
nodeSelector：Kubernetesの機能で、ポッドが特定のノード上で実行されるように指定できます。ノードに付けられたラベルと一致するポッドのみがそのノード上でスケジュールされます。
ノードプール：特定の設定或いは機能を持つノードの集合のことです。ノードプールを作成することで、特定のワークロードを特定のノード群にスケジュールすることが可能になります。
ポッドセキュリティポリシー：Kubernetesのセキュリティ設定の一つで、特定のポッドが実行するにあたり必要な権限や設定を管理します。
名前空間：Kubernetesクラスター内のリソースを論理的にグループ化したものです。名前空間を設定することで、リソースの管理やアクセス制御を柔軟に行うことができます。
正解についての説明：
（選択肢）
・ラベルinscope: trueを使用してノードにテイントを配置し、NoScheduleとポッド構成で一致する許容範囲を設定します
この選択肢が正解の理由は以下の通りです。
まず、Kubernetesにはノードを制御するための仕組みである"テイントとトレランス"があります。"テイント（Taint）"はノードに設定できるマーカーで、テイントが設定されたノードには指定したトレランス（tolerance）を持つポッドしかスケジュールされません。これにより、"範囲内の"ノードには"範囲内の"ポッドだけを配置するという要件を満たすことができます。
この設問の場合、"inscope: true"というラベルを使ってノードにテイントを配置し、"NoSchedule"を設定します。これにより、このラベルのテイントを許容する設定を持つポッド以外、新規のポッドがスケジュールされないように制御します。すなわち、"範囲内の"ポッドのみが"範囲内の"ノードにスケジュールされるため、コンプライアンスを満たすことが可能となります。
また、これにより予期しないポッドが"範囲内の"ノードに配置されることを防ぎ、セキュリティも確保することができます。
不正解についての説明：
選択肢：inscope: trueというラベルの付いたノードのみを使用するように、nodeSelectorフィールドをポッド構成に追加します
この選択肢が正しくない理由は以下の通りです。
nodeSelectorフィールドをポッド構成に追加すれば、"範囲内の"ノードが"範囲内の"PCI Kubernetesポッドにのみ使用されることを保証できますが、"範囲内の"ノードには"範囲内の"ポッドのみを含めるという要件を満たすことはできません。
これに対して、ノードにテイントを配置し、許容範囲を設定することで、ノードとポッドの両方で範囲制限が可能となります。
選択肢：ラベルinscope: trueを使用してノードプールを作成し、そのラベルが付いているノード上でのみポッドの実行を許可するポッドセキュリティポリシーを作成します
この選択肢が正しくない理由は以下の通りです。
ノードプールを作成し、ポッドセキュリティポリシーを適用する方法では、特定のノードにポッドがスケジュールされることを保証することはできません。
それに対して、正解のテイントと許容範囲を使用する方法はノードの選択性を提供し、"範囲内の"ノードに対して制御を行うことができます。
選択肢：名前空間"in-scope-pci"内のスコープ内のすべてのポッドを実行します
この選択肢が正しくない理由は以下の通りです。
名前空間"in-scope-pci"内でスコープ内のすべてのポッドを実行する事は、ポッドがスコープ内のノードに限定される保証を与えません。
一方、正解ではテイントと許容範囲を使用して、スコープ内のポッドが特定のノードにしかスケジュールされない事を確認しています。
参考リンク：
https://cloud.google.com/kubernetes-engine/docs/how-to/node-taints
https://cloud.google.com/kubernetes-engine/docs/concepts/pod-security-policies
https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
</div></details>

### Q.  問題13: 未回答
Cloud External Key Managerを使用して、Google Cloudの特定のBigQueryデータを暗号化するための暗号化キーを作成する必要があります。最初にどの手順を実行する必要がありますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudのBigQueryデータの暗号化に使用するためのキーを作成するよう求められています。具体的には、Cloud External Key Managerを用いたキーの作成手順について問われています。この問題を解く際には、Google Cloudの様々なサービスとその機能、特にCloud External Key Managerの機能と使い方を理解していることが重要で、それぞれの選択肢が指示する手順が、Cloud External Key Managerを使った適切なキー作成手順と一致するかどうかを慎重に見極める必要があります。
基本的な概念や原則：
Cloud External Key Manager（Cloud EKM）：Google Cloudのサービスの一つで、顧客管理の暗号化キー（CMK）の使用を可能にします。Cloud EKMを使用すると、Google Cloudのサービスに対して外部（サードパーティ）の鍵管理システムで管理されたキーを用いた暗号化を行うことができます。
Google Cloudプロジェクト：Google Cloudのすべてのリソースを管理するための組織単位。
一意の統一リソース識別子（URI）：リソースに一意にアクセスするための識別子。暗号化キーなどのリソースを指定する際に使用します。
鍵管理パートナーシステム：Google Cloud以外の暗号化キーを管理するシステム。Cloud EKMを使用してGoogle Cloudサービスからアクセスすることができます。
Cloud Key Management Service（Cloud KMS）：Google Cloudの暗号化キー管理サービス。自身のキーリングと暗号キーを作成および管理することができますが、Cloud EKMで使用するキーはGoogle Cloudプロジェクトで作成または指定する必要があります。
正解についての説明：
（選択肢）
・1.Google Cloudプロジェクトで、一意の統一リソース識別子（URI）を持つキーを作成するか、既存のキーを使用します
2.Google Cloudプロジェクトで、サポートされている外部の鍵管理パートナーシステムへのアクセスを許可します
この選択肢が正解の理由は以下の通りです。
まず、Cloud External Key Manager（EKM）は、自身で管理する暗号化キーを使用して、Google Cloudのデータを保護するためのサービスです。このサービスを使用するためには、一意のURIを持つキーの作成が最初のステップとして必要です。このキーはGoogle Cloudプロジェクト内で管理され、BigQueryデータの暗号化に使用されます。
続いて、外部の鍵管理パートナーシステムへのアクセスを許可することで、このキーを外部の鍵管理システムで管理することができます。Google Cloudは多くの主要な鍵管理パートナーとの統合をサポートしているので、この手順によりCloud EKMを有効に活用できます。
したがって、これらの手順はBigQueryデータの暗号化キーを作成し、それをCloud External Key Managerを通じて管理するための適切な手順となります。
不正解についての説明：
選択肢：1.Cloud Key Management Service（Cloud KMS）で、一意の統一リソース識別子（URI）を持つ鍵を作成するか、既存の鍵を使用します
2.Cloud KMSで、Google Cloudプロジェクトにキーを使用するためのアクセス権を付与します
この選択肢が正しくない理由は以下の通りです。
Cloud KMSはGoogle Cloud内部のキー管理システムで、External Key Managerは外部のキーマネージメントシステムとの連携を実現します。
したがって、Cloud KMSで鍵を作成・管理するのではなく、外部のキーマネージメントシステムで行う必要があります。
選択肢：1.サポートされている外部鍵管理パートナーシステムにおいて、一意の統一リソース識別子（URI）を持つ既存の鍵を作成または使用します
2.外部鍵管理パートナーシステムで、この鍵にGoogle Cloudプロジェクトを使用するためのアクセス権を付与します
この選択肢が正しくない理由は以下の通りです。
Google Cloudにおいて必要な設定を行い、その上でキーを作成するため、最初にGoogle Cloudプロジェクトで一意のURIを持つキーを作成または使用し、次にサポートされている外部の鍵管理パートナーシステムへのアクセスを許可する必要があります。
また、不正解の選択肢は最初から外部システムでの操作を行ってしまっています。
選択肢：1.Cloud Key Management Service（Cloud KMS）で、一意の統一リソース識別子（URI）を持つ外部鍵を作成します
2.Cloud KMSで、Google Cloudプロジェクトにキーを使用するためのアクセス権を付与します
この選択肢が正しくない理由は以下の通りです。
Cloud External Key Managerは外部の鍵管理システムで暗号化キーを管理するため、Cloud Key Management Serviceでキーを作成する必要はありません。
さらに、Google Cloudプロジェクトでキーへのアクセスを許可することが必要であり、Cloud KMSで設定するのは不適切です。
参考リンク：
https://cloud.google.com/bigquery/docs/encryption-customer-managed-keys
https://cloud.google.com/ekm/docs
https://cloud.google.com/kms/docs/external-key-managers
</div></details>

### Q.  問題14: 未回答
あなたの会社は、顧客の年齢層に応じて、クレジットスコアを向上させるためにどのような商品を構築できるかを判断したいと考えています。そのためには、会社のバンキングアプリのユーザー情報と、第三者から受け取った顧客のクレジットスコアデータを結合する必要があります。この生データを使用すればこのタスクを完了できますが、機密データを暴露することになり、新たなシステムに伝播する可能性があります。
このリスクには、データベース全体の参照整合性を維持しながら、Cloud Data Loss Preventionを使用して非識別化とトークン化で対処する必要があります。
これらの要件を満たすには、どの暗号トークン形式を使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題は、データの暗号化方式を選択することが求められています。必要な要素は、参照整合性を維持しつつ、データを非識別化・トークン化することです。そのため選択肢を考える際には、データ非識別化と参照整合性維持の両方を達成できる暗号化形式を選ぶべきです。また、このケースでは生データの情報を保護するために、暗号トークン形式に特定の要件が求められていることに注意深く対応する必要があります。
基本的な概念や原則：
Cloud Data Loss Prevention（DLP）：データ保護のためのGoogle Cloudのサービスです。機密データの発見、分類、保護を自動化します。
非識別化：個人を特定できる情報を削除または変換することです。プライバシーとセキュリティを向上させるために使用されます。
トークン化：機密データをデータベースやファイル内の非機密要素に置き換えるプロセスです。オリジナルデータは別の場所に保存され、元に戻すためのトークンが提供されます。
決定論的暗号化：同じ入力値に対して常に同じ暗号文を生成する暗号化手法です。文脈やパターン分析で情報を推測できるリスクがありますが、参照整合性を保つ上で有用です。
安全なキーベースのハッシュ：一方向性のあるハッシュアルゴリズムで、元のデータを特定できない形でデータを変換します。しかし、参照整合性を維持することはできません。
フォーマット保持暗号化：データを暗号化しながらも、元のデータ形式を保持する暗号化手法です。しかし、参照整合性を維持する機能はありません。
暗号ハッシュ：一方向性のあるハッシュアルゴリズムで、元のデータを特定できない形でデータを変換します。参照整合性を維持することはできません。
正解についての説明：
（選択肢）
・決定論的暗号化
この選択肢が正解の理由は以下の通りです。
まず、決定論的暗号化は一貫性を保証する暗号化方式です。同じ入力値に対しては常に同じ暗号文が生成されます。これは、参照整合性の維持に重要です。参照整合性とは、データベース内の様々な部分で、同じ値が正確かつ一貫して引用されることを保証する仕組みです。データベース全体で一貫性を保つためには、同じ値が同じ暗号文に変換される暗号方式が必要となるため、決定論的暗号化が適しています。
また、Cloud Data Loss Preventionは、データの非識別化とトークン化を行うためのサービスで、決定論的暗号化をサポートしています。これにより、個人を特定できる情報を保護しつつ、データの分析や処理を可能にします。
したがって、機密データが新たなシステムに伝播するリスクを軽減するためには、決定論的暗号化が適しています。
不正解についての説明：
選択肢：安全なキーベースのハッシュ
この選択肢が正しくない理由は以下の通りです。
安全なキー基のハッシュを使用した場合、元のデータを復元することができません。ですが、問題要件は参照整合性を維持しながら非識別化を行うことを求めています。これは、ハッシュ関数ではなく、元のデータを復元可能な決定論的暗号化の特性が必要とされているためです。
選択肢：フォーマット保持暗号化
この選択肢が正しくない理由は以下の通りです。
フォーマット保持暗号化は元のデータ型や長さを保持しますが、それ自体は参照整合性を確保できません。決定論的暗号化を用いると、同じ平文に対しては常に同じ暗号文を生成します。これがデータベース全体の参照整合性を維持できます。
選択肢：暗号ハッシュ
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュは一方向の関数であり、変換後に元のデータに戻すことができません。このため、データ全体の参照整合性を維持するという要件を満たすことができません。
それに対して、決定論的暗号化は同じ入力から同じ暗号文を生成し、暗号文から元のデータを復元できるため、参照整合性を維持することが可能です。
参考リンク：
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/dlp/docs/deidentify-sensitive-data
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題15: 未回答
組織のGoogle CloudインスタンスのPCIコンプライアンスを評価したいと考えています。Google固有のコントロールを特定する必要があります。
情報を見つけるには、どのドキュメントを確認する必要がありますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google CloudインスタンスのPCIコンプライアンスに焦点を当てています。組織がGoogle Cloud内で適用するべき具体的なPCIコンプライアンスに関連するGoogle固有のコントロールを特定したいと考えています。ここで重要なのは、Google Cloud環境における責任の分担を理解することで、選択肢からはGoogle Cloud固有のガイダンスとセキュリティ関連の情報を提供するものを選ぶことが求められています。また、Google Cloud特有の情報提供源を探すことが重要で、一般的なPCIコンプライアンスガイドよりもGoogle Cloudに特化したリソースを重視すべきです。
基本的な概念や原則：
Google Cloud：顧客責任マトリックス：Google Cloudにおけるセキュリティコントロールと関連する責任の分配を明示したドキュメントです。事業者とGoogleがそれぞれ持つ責任を理解するために重要です。
PCIコンプライアンス：クレジットカード情報の安全性を保証するための国際基準です。PCI DSS（Payment Card Industry Data Security Standard）という規格に準拠していることが求められます。
PCI DSS：クレジットカード情報を取り扱う企業が遵守すべき国際的なセキュリティ基準です。盗難や漏洩を防ぐための技術的、運用的要件を定めています。
PCI SSCクラウドコンピューティングガイドライン：PCI SSS（Payment Card Industry Security Standards Council）が提供する、クラウド環境でのPCI DSS準拠についてのガイドラインです。
Compute Engineの製品ドキュメント：Google Compute Engineに関する公式のドキュメンテーションです。プロダクトの使用方法や仕様について詳細な情報を提供しています。
正解についての説明：
（選択肢）
・Google Cloud：顧客責任マトリックス
この選択肢が正解の理由は以下の通りです。
まず、Google Cloudの顧客責任マトリックスは、Google Cloudの製品とサービスにおけるセキュリティとコンプライアンスの責任を明確に示すための公式ドキュメントです。これには、Google Cloudのインフラストラクチャ、製品、サービスに関するコントロールと、顧客が実装すべきコントロールの詳細な情報が含まれています。
したがって、PCIコンプライアンスを評価したい場合、このマトリックスを参照すれば、Googleが担当する部分と顧客が負うべき責任を理解することができます。
さらに、Google Cloudの顧客責任マトリックスは、特定の規制基準、たとえばPCI DSSなどに対してどのようなコントロールが必要かという詳細なガイダンスも提供しています。そのため、組織がGoogle CloudインスタンスのPCIコンプライアンスを評価するためには、このマトリックスを確認することが最適と言えます。
不正解についての説明：
選択肢：PCI DSSの要件とセキュリティ評価手順
この選択肢が正しくない理由は以下の通りです。
PCI DSSの要件とセキュリティ評価手順は、基本的なPCIコンプライアンスに必要なセキュリティ要件と手順を指摘しますが、これはGoogle Cloud特有のコントロールを特定する目的には合致しません。
対照的に、Google Cloud：顧客責任マトリックスはGoogle Cloudの標準と共有責任モデルを明示的に解説します。
選択肢：PCI SSCクラウドコンピューティングガイドライン
この選択肢が正しくない理由は以下の通りです。
PCI SSCクラウドコンピューティングガイドラインは一般的なクラウドサービスのコンプライアンスガイドラインを提供しますが、Google Cloud特有のコントロールについては明確に示されていません。
これに対して、Google Cloud：顧客責任マトリックスはGoogle Cloud特有のセキュリティとコンプライアンスのロールと責任を明確に示しています。
選択肢：Compute Engineの製品ドキュメント
この選択肢が正しくない理由は以下の通りです。
Compute Engineの製品ドキュメントでは特定の製品に関する説明や設定方法が記載されていますが、Google固有のPCIコンプライアンスに関する情報は含まれていません。
それに対して、"Google Cloud：顧客責任マトリックス"では、クラウドサービスのコンプライアンスを特定できるため正解です。
参考リンク：
https://cloud.google.com/docs/security/compliance/customer-responsibility
https://cloud.google.com/security/compliance/pci-dss
https://cloud.google.com/compute/docs
</div></details>

### Q.  問題16: 未回答
あなたは、Google Cloudで一般データ保護規則（GDPR）に準拠したいと考えています。そのために、EUにおけるデータレジデンシーと運用主権を導入する必要があります。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloud上で一般データ保護規則（GDPR）に準拠し、データのレジデンシーと運用主権をEU内で保持する方法を問われています。問題文からは、データの物理的な配置の制限とGoogle Cloudのサービスによるデータへのアクセス制限が必要と読み取れます。ここで注意するのは、データ保護規則への準拠には、単にデータの所在地を管理するだけでなく、データへのアクセス管理も含まれるということです。これを念頭に置きながら、各選択肢を慎重に評価する必要があります。
基本的な概念や原則：
GDPR（General Data Protection Regulation）：ヨーロッパ連合におけるデータ保護とプライバシーに関する規則です。個人データの処理と移動を厳格に制御しています。
データレジデンシー：データが物理的に保存される位置（つまり、特定の国や地域）を指します。多くの法域では、特定の種類のデータ（特に個人データ）はそのリージョン内でのみ処理または保存する必要があります。
運用主権：システムの運用に対する制御や管理権を持つことを指します。通常、システムの所有者や管理者が運用主権を持ちます。
Organization Policy Service：Google Cloudの組織全体にポリシー制限を設定するためのサービスです。
Resource Locations Constraint：Organization Policy Serviceの機能で、リソースの物理的な場所を制限できます。
Key Access Justifications：Google Cloudの機能で、Google社員のアクセスを事前に定義された属性（国籍、ロケーション等）に基づいて制限します。
Cloud IDS/IDフェデレーション/VPCフローログ：これらのサービスや機能は、ネットワークのログ、監視、またはアクセス制御などの目的で使用されますが、データレジデンシーや運用主権を保証する具体的な機能はありません。
正解についての説明：
（選択肢）
・Organization Policy Serviceの "resource locations constraint"を使用して、新しいリソースの物理的な場所を制限します
・Key Access Justificationsを使用して、国籍や地理的ロケーションなど、事前に定義された属性に基づいてGoogle Cloudのサービスのアクセスを制限します
この選択肢が正解の理由は以下の通りです。
まず、一つ目の選択肢のOrganization Policy Serviceの "resource locations constraint"を使用することは、データの物理的な場所をEU内に制限するのに適しています。これはGDPRにおけるデータレジデンシー、つまりデータが特定の地理的な領域内に保管されていることを保証するための要件を満たします。
次に、二つ目の選択肢であるKey Access Justificationsを使用することで、Google Cloudのサービスのアクセスを事前に定義された属性、例えば国籍や地理的ロケーションなどに基づいて制限することができます。これはGDPRにおける運用主権、つまり誰がデータにアクセスできるかを制御することを可能にします。
これらの選択肢は、Google CloudでGDPRに準拠するための主要な要件を満たすことができます。
したがって、正答となります。
不正解についての説明：
選択肢：Cloud IDSを使用して、EU内のサーバー間と各階層間のトラフィックを可視化し、VPC内およびVPC間の通信を監視します
この選択肢が正しくない理由は以下の通りです。
Cloud IDSはトラフィックを可視化し、監視するためのツールですが、それ自体ではGDPRの要件であるデータレジデンシーと運用主権を確保するための機能を提供していません。
したがって、この問題の要件を直接満たす選択肢ではありません。
選択肢：IDフェデレーションを使用して、EU域外からのGoogle Cloudリソースへのアクセスを制限します
この選択肢が正しくない理由は以下の通りです。
IDフェデレーションを使用すると認証と認可を管理することができますが、それ自体はデータレジデンシーや運用主権を保証するものではありません。
また、GDPRの準拠のためには、物理的なデータの場所を制限するとともに、不適切なアクセスを制限する措置が必要で、IDフェデレーションだけでは足りません。
選択肢：VPCフローログを使用して、EU内のVPC内およびVPC間のトラフィックを監視します
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークのトラフィックパターンを監視するためのツールで、データの物理的な場所を制限したり、Google Cloudのサービスのアクセスを制限したりする機能はありません。これらの要件を満たすためには、Organization Policy ServiceやKey Access Justificationsが必要です。
参考リンク：
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-resource-locations
https://cloud.google.com/kms/docs/key-access-justifications
https://cloud.google.com/compliance/gdpr
</div></details>

### Q.  問題17: 未回答
ある組織は、従業員の異常値を特定し、収入格差を是正するために、賞与報酬の経年変化を追跡したいと考えています。このタスクは、個人の重要な報酬データを公開することなく実行されなければならず、異常値を特定するために元に戻すことができなければなりません。
どのCloud Data Loss Prevention APIの機能を使うべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社が従業員の賞与報酬のパターンを追跡しながら、個人情報のアウトプットを避けるためにどのCloud Data Loss Prevention APIの機能を使うべきかを問います。選択肢に挙げられているAPIの各機能は異なる種類の保護を提供しますが、要求される特性である"元に戻すことができる"点に焦点を当てる必要があります。選択肢の中でどの機能がこの条件を満たすのか、それぞれの機能がどのようにデータを処理するのかを理解することが重要です。
基本的な概念や原則：
フォーマット保持暗号化：Cloud DLPの機能の一つで、データを元に戻すことが可能な形式で保護します。元のデータと同じ形式を維持するため、一部のデータ分析操作を暗号化されたデータに対して実行することが可能です。
暗号ハッシュ：データを固定長の一意な文字列に変換しますが、元に戻すことが不可能な形式で保護します。
秘匿化：一部のデータを隠し、データを元戻しできないようにします。データの一部を保持しながら、情報の機密性を保護します。
一般化：個々のデータポイントをより大きなカテゴリーに置き換えることで、データの詳細度を低下させます。これによりデータの特定性が薄れ、プライバシー保護に貢献します。
Cloud Data Loss Prevention API：機密データの検出、クラス分類、保護（非可逆的および可逆的脱識別化）を行うためのサービスです。
正解についての説明：
（選択肢）
・フォーマット保持暗号化
この選択肢が正解の理由は以下の通りです。
フォーマット保持暗号化（FPE）は、Cloud Data Loss Prevention（DLP）APIの一部です。ここでは機密データをより無害な形式に変換しながら、データの元の詳細と有用性を維持します。FPEはテキストデータを他のテキストデータに変換しますが、変換後の値は元の値と同じフォーマットを保持します。
したがって、データの構造と有用性を維持したままで、機密データを安全に保護することができます。このため、フォーマット保持暗号化は、個々の重要な報酬データを保護しつつ、賞与報酬の経年変化を追跡する組織にとって最適な方法です。
さらに、FPEの結果は逆行できるため、必要に応じて元のデータに戻すことが可能です。これは異常値を特定する際に非常に役立ちます。
不正解についての説明：
選択肢：暗号ハッシュ
この選択肢が正しくない理由は以下の通りです。
暗号ハッシュ機能を使用した場合、元のデータへ戻すことができません。これは、組織が異常値を特定するために必要な期待の動作とは異なります。
それに対して、フォーマット保持暗号化はデータを暗号化しつつも、元の形式を保持することができ、必要に応じて復号化することが可能です。
選択肢：秘匿化
この選択肢が正しくない理由は以下の通りです。
秘匿化はデータを隠蔽する一方で、元のデータに戻す機能を持っていません。問題文では異常値を特定するために元のデータに戻すことができなければならないとあります。
それに対して、フォーマット保持暗号化は元のデータ形式を保持しつつ暗号化し、復元が可能な形式に変換します。
選択肢：一般化
この選択肢が正しくない理由は以下の通りです。
一般化によるデータ変換は一方向であり、元の情報に戻すことができないため、異常値を特定する目的には適合しません。
一方、フォーマット保持暗号化は元のデータ形式を保ったままの暗号化を提供し、必要に応じて復元することが可能なため、情報の秘匿と利用の両立を達成できます。
参考リンク：
https://cloud.google.com/dlp/docs/concepts-format-preserving-encryption
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/solutions/masking-sensitive-data-using-cloud-dlp
</div></details>

### Q.  問題18: 未回答
Compute Engineインスタンス上で実行されているアプリケーションが、Cloud Storageバケットからデータを読み取る必要があります。あなたのチームは、Cloud Storageバケットがグローバルに読み取り可能であることを許可しておらず、最小特権の原則を確保したいと考えています。
あなたのチームの要件を満たすオプションはどれですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute EngineインスタンスがCloud Storageバケットからデータを読み取る際に最小特権の原則を保つ方法が求められています。問題文から、このバケットがグローバルに読み取り可能であることは許可されていないことがわかります。そのため、データアクセスを限定し、セキュリティを確保しながらどのようにインスタンスでバケットのデータ読み取りを行うかがポイントとなります。また、最小特権の原則の規則を理解していることも非常に重要で、不要なアクセス権を減らし、制限を強化する適切なソリューションを見つけることが求められます。
基本的な概念や原則：
Compute Engine：Google Cloudの仮想マシン（VM）を提供するインフラストラクチャas aサービス（IaaS）です。仮想マシンが実行される場所（データセンター）を選択でき、OSやその他のソフトウェアをインストール、実行できます。
Cloud Storage：Google Cloudのスケーラブルで耐久性の高いオブジェクトストレージです。任意の種類の非構造化データ（写真、ビデオ、バックアップ、ログファイルなど）を保存、取得できます。
サービスアカウント：アプリケーションや仮想マシンなど、Google Cloudのリソースに対するアクセスを制御するためのアカウントです。各サービスアカウントには一意の電子メールアドレスが割り当てられています。
読み取り専用アクセス：特定のリソースへの読み取りのみ可能なアクセス権限です。データの変更、削除、追加などは不可能です。
最小特権の原則：セキュリティの基本原則で、個々のユーザーやプログラムに、そのタスクを遂行するために必要最小限の権限とアクセスのみを付与する常識です。
ACL（Access Control Lists）: リソースへのアクセスを制御するための一連の許可ルールです。特定のユーザーやサービスアカウントがデータに対して何をして良いかを定義します。ネットワークやファイルシステムなどで広く使用されています。
Cloud KMS：Googleのキーマネージメントサービスで、暗号キーを作成、管理します。このキーは、Cloud StorageやBigQueryなど他のGoogle Cloudサービスでデータを暗号化するために使用できます。
正解についての説明：
（選択肢）
・Cloud Storageバケットへの読み取り専用アクセス権を持つサービスアカウントを使用して、インスタンスメタデータから認証情報を取得します
この選択肢が正解の理由は以下の通りです。
まず、サービスアカウントはGoogle Cloud上でアプリケーションに対するセキュアな識別と認証を提供する重要な仕組みであり、特定のアクセス権を持つことができます。この場合、読み取り専用アクセス権を持つサービスアカウントを使用すれば、最小特権の原則を満たしつつ、アプリケーションがCloud Storageバケットからデータを適切に読み取ることが可能となります。
次に、インスタンスメタデータから認証情報を取得することにより、Compute Engineインスタンスがサービスアカウントに自動的に認証されるように設定することが可能です。そのため、これはセキュリティの観点からも望ましい方法であり、設定管理の複雑さも少なくなります。
さらに、Cloud Storageバケットの公開が認められていない場合でも、正認のサービスアカウントを用いることで安全にアクセスが制御できるため、要件を満たしていると言えます。
不正解についての説明：
選択肢：Compute EngineインスタンスのIPアドレスからの読み取り専用アクセスを許可し、アプリケーションが認証情報なしでバケットから読み取ることを許可するCloud Storage ACLを作成します
この選択肢が正しくない理由は以下の通りです。
最小特権の原則を確保したい場合、IPアドレスからの読み取りアクセスの許可では原則が満たされません。IPアドレスは個別のアプリケーションやユーザーにリンクされていないため、サービスアカウントを使用して特定の資格情報を持つアクセスを管理するのは効果的でありません。
選択肢：Cloud Storageバケットに読み取り専用でアクセスできるサービスアカウントを使用し、Compute Engineインスタンス上のアプリケーションのconfigにサービスアカウントの認証情報を保存します
この選択肢が正しくない理由は以下の通りです。
認証情報をアプリケーションのconfigに直接保存することは、最小特権の原則に反します。
また、この方法は認証情報が漏洩するリスクがあります。正解の選択肢と比べると、インスタンスメタデータから認証情報を取得する方がセキュリティが高いです。
選択肢：Cloud KMSを使ってCloud Storageバケット内のデータを暗号化し、アプリケーションがKMSキーでデータを復号化できるようにします
この選択肢が正しくない理由は以下の通りです。
Cloud Key Management Service（KMS）はデータの暗号化と復号化に使用されますが、アクセス制御を実装するためのものではありません。そのため、この方法ではアプリケーションがCloud Storageバケットのデータを読み取るための最小特権の原則を守ることができません。
参考リンク：
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/storage/docs/access-control/iam-permissions
https://cloud.google.com/compute/docs/storing-retrieving-metadata
</div></details>

### Q.  問題19: 未回答
セキュリティ脆弱性評価を完了した後、クラウド管理者がGoogle Cloud CLIセッションを何日も開いたままにしていることを知りました。これらのセッションを最小限の期間に設定することで、これらのオープンセッションを悪用する攻撃者のリスクを減らす必要があります。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのセキュリティ設定に関連した問題が提示されています。特に、クラウド管理者が開いたままにしているGoogle Cloud CLIセッションの厳密な制御に関する解決策について求められています。そのため、選択肢を評価する際には、Google Cloudの認証とセッションの管理に関連する各設定やポリシーを理解した上で、具体的な時間制限の設定により開かれたセッションを最小限に維持する解決策を選択することが重要です。
基本的な概念や原則：
Google Cloud Session Control：Google Cloudのユーザーおよびサービスアカウントのセッションの有効期間を制御する機能です。再認証頻度の設定により、セキュリティリスクを管理します。
再認証頻度：ユーザーが一度認証した後、引き続きセッションが有効であることを証明するために再度認証する必要がある頻度のことです。この頻度を高く設定することで、無許可のアクセスリスクを下げることができます。
組織ポリシー：Google Cloudでリソースの使用を制御するためのルールです。特定の制約を設定して、リソースの使用方法を規定します。
constraints/iam.allowServiceAccountCredentialLifetimeExtension：この組織ポリシー制約を使用して、サービスアカウントの資格情報の有効期限を超えて延長可能かどうかを制御します。
constraints/iam.serviceAccountKeyExpiryHours：この組織ポリシー制約を使用して、サービスアカウントキーの有効期限を制御します。
正解についての説明：
（選択肢）
・Google Cloud Session Controlの再認証頻度を1時間に設定します
この選択肢が正解の理由は以下の通りです。
Google Cloud Session Controlは、ユーザーセッションの再認証の頻度を設定するための機能です。これを使用して再認証頻度を1時間に設定することで、CLIセッションが何日も開いたままになることを防げます。再認証が要求されると、ユーザーは再度クレデンシャルを提供し、その認証情報が現在も有効であることを確認する必要があります。これにより、攻撃者が不適切にオープンセッションを利用するリスクを軽減できます。なぜなら、攻撃者がセッションを乗っ取りたいと思っても、1時間ごとに再認証が求められるため、そのセッションを長時間保持することは難しくなるからです。
したがって、Google Cloud Session Controlの再認証頻度を1時間に設定することは、セキュリティ上の理由からオープンセッションの期間を最小限に抑えるのに役立ちます。
不正解についての説明：
選択肢：Google Cloud Session Controlのセッション時間を1時間に設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloud Session Controlでは"セッション時間"を設定することはできません。正しくは"再認証頻度"を設定します。再認証頻度は、指定した時間ごとにユーザーに再ログインを求める機能で、これによって無期限に開かれたセッションを防ぎます。
選択肢：組織ポリシー制約constraints/iam.allowServiceAccountCredentialLifetimeExtensionを1時間に設定します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約constraints/iam.allowServiceAccountCredentialLifetimeExtensionは、サービスアカウントの資格情報の有効期間を制御します。しかしながら、CLIセッションの有効期間や再認証頻度の設定はGoogle Cloud Session Controlで行います。この選択肢はCLIセッションの管理とは無関係ため不正解です。
選択肢：組織ポリシー制約constraints/iam.serviceAccountKeyExpiryHoursを1時間に設定し、inheritFromParentをfalseに設定します
この選択肢が正しくない理由は以下の通りです。
組織ポリシー制約constraints/iam.serviceAccountKeyExpiryHoursはサービスアカウントキーの有効期限を制御しますが、これはGoogle Cloud CLIセッションの持続時間を管理するものではありません。
正解の選択肢は、Google Cloud Session Controlの再認証頻度を1時間に設定することで、CLIセッションの持続期間を最小限に抑えることができます。
参考リンク：
https://cloud.google.com/iam/docs/configuring-reauthentication
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/sdk/gcloud/reference/auth/login
</div></details>

### Q.  問題20: 未回答
あなたの会社のメッセージングアプリは、FIPS 140-2に準拠するために、Google Cloudのコンピュートおよびネットワークサービスを使用することを決定しました。メッセージングアプリのアーキテクチャには、Compute Engineインスタンスのクラスターを制御するManaged Instance Group（MIG）が含まれています。インスタンスは、データキャッシングにローカルSSDを使用し、インスタンス間の通信にUDPを使用しています。アプリ開発チームは、標準に準拠するために必要な変更を行うことを望んでいます。
要件を満たすために、どのオプションを推奨しますか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、FIPS 140-2への準拠という制約の下でGoogle Cloudのコンピュートおよびネットワークサービスを使用したメッセージングアプリケーションを設計する問題に取り組んでいます。要件には、キャッシュストレージとインスタンス間通信の暗号化も含まれています。したがって問題を解くためには、FIPS 140-2に準拠した暗号化技術やプロトコルについて理解する必要があります。また、UDPやローカルSSDの使用についても、これらの技術が準拠を満たすためにどのように利用され、あるいは変更されるべきかを評価することが求められます。このような観点から選択肢を読み解くことで、最も適切な解決策を選ぶことができます。
基本的な概念や原則：
FIPS 140-2：アメリカ国立標準技術研究所（NIST）が定めるセキュリティ要件です。暗号化モジュールがFIPS 140-2に準拠しているかを評価する基準として使用されます。
Compute Engine：Google CloudのインフラストラクチャAs-a-Service（IaaS）です。仮想マシンをデプロイと管理するためのサービスです。
Managed Instance Group（MIG）：Compute Engineインスタンスのグループを管理するための仕組みです。自動スケーリング、ローリングアップデート、自動ヒーリングなどをサポートしています。
BoringCrypto：Googleが開発したFIPS 140-2に準拠した暗号化ライブラリです。Googleのプロダクトで使用される暗号化演算の信頼性を向上するために開発されました。
ローカルSSD：Compute Engineインスタンスに直接接続された、高速で一時的なブロックストレージです。主に高いIOPS（Internet Operations Per Second）と低い遅延を必要とするアプリケーションに使用されます。
UDP通信：インターネット通信プロトコルの一つです。TCPとは異なり、通信の確認を行わないため、速度は速いものの信頼性が低いとされています。
ディスク暗号化：データを盗難や漏洩から保護するために、データを暗号化することです。顧客管理キーやGoogle-managed Keyを使用してディスク暗号化を行うことができます。
正解についての説明：
（選択肢）
・BoringCryptoモジュールを使用して、すべてのキャッシュストレージとVM間通信を暗号化します
この選択肢が正解の理由は以下の通りです。
まず、BoringCryptoモジュールはGoogleが提供するFIPS 140-2に準拠した暗号化モジュールで、必要なセキュリティ標準を満たす能力があります。すべてのキャッシュストレージとVM間通信を暗号化することは、FIPS 140-2の要求を満たす最善の手段となります。
また、BoringCryptoモジュールはCompute Engine上で動作し、ローカルSSDのデータキャッシングやUDPを使用したインスタンス間の通信など、既存のアーキテクチャの要素に影響を与えない暗号化ソリューションを提供します。これはアプリ開発者が必要としている準拠のための変更を最小限に抑えられる点で非常に重要です。
したがって、この選択肢が最適な解決策となります。
不正解についての説明：
選択肢：MIGが使用するインスタンステンプレートのディスク暗号化を顧客管理キーに設定し、インスタンス間のすべてのデータ転送にBoringSSLを使用します
この選択肢が正しくない理由は以下の通りです。
まず、ディスク暗号化を顧客管理キーに設定してもキャッシュストレージ自体の暗号化は行われないため、FIPS 140-2の要件を満たしません。
また、BoringSSLはFIPS 140-2準拠ではないため、正しくないです。正解のBoringCryptoはFIPS 140-2認定を持っています。
選択肢：アプリのインスタンス間通信をUDPからTCPに変更し、クライアントのTLS接続でBoringSSLを有効にします
この選択肢が正しくない理由は以下の通りです。
UDPからTCPへの変更とクライアントのTLS接続でのBoringSSLの有効化はデータの送受信を暗号化するために役立ちますが、これはデータのインスタンス間通信のみに影響し、データキャッシングに使用されるローカルSSDの暗号化には関わりません。
一方、BoringCryptoモジュールを使用すれば、キャッシュストレージとVM間通信の両方を暗号化するため、FIPS 140-2の要件をより全面的に満たすことができます。
選択肢：MIGが使用するインスタンステンプレートのディスク暗号化をGoogle-managed Keyに設定し、すべてのインスタンス間通信でBoringSSLライブラリを使用します
この選択肢が正しくない理由は以下の通りです。
まず、Google-managed Keyではなく、BoringCryptoがFIPS 140-2に準拠しています。
さらに、BoringSSLはFIPS 140-2に準拠していないため、これを使用することはFIPS要件を満たすことができません。この要件を満たすためには、FIPS 140-2に準拠した暗号化モジュールを使用するべきです。
参考リンク：
https://cloud.google.com/security/fips
https://cloud.google.com/compute/docs/disks#encryption
https://cloud.google.com/compute/docs/instances/encrypt-instance-communication
</div></details>

### Q.  問題21: 未回答
あなたは、規制の厳しい業界のミッションクリティカルなワークロードを管理しています。このワークロードは、エンドポイントコンピュータからCloud Storageにアップロードされた後の機密データの分析と処理にCompute Engine VMを使用しています。コンプライアンスチームは、このワークロードが機密データのデータ保護要件を満たしていないことを検出しました。データ保護要件は以下の通りです：
- データ暗号化キー（DEK）をGoogle Cloud境界外で管理します。
- サードパーティプロバイダを通じて暗号化キーを完全に管理します。
- 機密データをCloud Storageにアップロードする前に暗号化します。
- Compute Engine VMでの処理中に機密データを復号化します。
- Compute EngineVMで使用中のメモリ内の機密データを暗号化します。
この要件を満たすために、どうすればよいですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudを使用して、機密データの保護を強く規制された業界で実施するための最適なソリューションを特定することが求められています。問題文から、データ暗号化キーはGoogle Cloud外部で管理する必要があり、データはCloud Storageにアップロードする前に暗号化し、Compute Engine VMで処理中はメモリ内のデータは暗号化されたままであることが要求されています。これを達成するための最適なサービスや構成を選択するためには、Google Cloudの暗号化周りの機能やサービスを理解していることが重要です。また、選択肢の中にはほぼ同じ動作をするものがありますが、細かい要件に注意してそれぞれの違いを理解することが必要です。
基本的な概念や原則：
Cloud Storage：Google Cloudのオブジェクトストレージサービスで、大量の不構造化データを保存・取得することが可能です。データは自動的に暗号化されますが、より高いセキュリティ要件を満たすためのキー管理オプションも提供されています。
Cloud External Key Manager：Google Cloudのサービスで、Google Cloud外部のキーマネージメントシステムを使ってGoogle Cloudリソースの暗号キーを管理します。これにより、ユーザーはキーの完全なコントロールを保持しながら、Google Cloudの強力なデータ保護機能を利用できます。
Compute Engine VM：Google Cloudの仮想マシンサービスです。高度なカスタマイズが可能であり、各種ワークロードに対応します。
Confidential VM：Google Cloudのサービスで、メモリ内データの暗号化を提供します。これにより、稼働中のVMで機密データが保護されます。
Customer Managed Encryption Keys：ユーザーがGoogle Cloudで暗号化キーを生成、管理する方法です。しかし、完全なキー管理をサードパーティに委託する要件を満たすには不十分です。
VPC Service Controls：Google Cloudのサービス、データへのアクセスを制御するセキュリティ機能です。しかし、これによって暗号化キーの管理やデータの暗号化・復号化は実現できません。
正解についての説明：
（選択肢）
・機密データがCloud Storageにアップロードされる前に暗号化し、機密データがVMにダウンロードされた後に復号化するようにCloud External Key Managerを構成します
・機密データにアクセスするために、Compute EngineVMをConfidential VMに移行します
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのExternal Key Managerは、Google Cloudの外部にある鍵管理システムから暗号化キーを使用することを可能にします。これにより、データ暗号化キーの管理をGoogle Cloudの外で行うという要件を満たすことができます。
さらに、クライアント側の暗号化を通じて、データがCloud Storageにアップロードされる前に暗号化され、VMでダウンロードされた後に復号化されるように設定できます。これにより、二つめの要件であるサードパーティプロバイダを通じて暗号化キーを完全に管理することも可能になります。またGoogle CloudのExternal Key Managerを使えば、クライアント側で暗号化されたデータをGoogle Cloud上で復号化して処理するという機能もあります。これにより、四つ目の要件であるCompute Engine VMでの処理中に機密データを復号化するという要件も満たすことができます。
次に、Google CloudのConfidential VMsは、メモリ暗号化技術を利用してメモリ内のデータを暗号化します。これにより、Compute EngineVMで使用中のメモリ内の機密データの暗号化という要件を満たすことができます。Confidential VMsは、データを保護しながら、パフォーマンスを犠牲にすることなくワークロードを実行することができるため、規制の厳しい業界のミッションクリティカルなワークロードに対応するには最適な選択と言えます。
不正解についての説明：
選択肢：Customer Managed Encryption Keysを設定して、機密データをCloud Storageにアップロードする前に暗号化し、機密データをVMにダウンロードした後に復号化します
この選択肢が正しくない理由は以下の通りです。
Customer Managed Encryption KeysはGoogle Cloud内で管理されるため、データ暗号化キー（DEK）をGoogle Cloud境界外で管理するというデータ保護要件を満たしません。
したがって、サードパーティプロバイダを通じて暗号化キーを完全に管理する、という要件も満たせません。
これに対し、Cloud External Key Managerを使用すれば、Google Cloud境界外で暗号化キーの管理が可能となります。
選択肢：機密データにアクセスするためのConfidential VMを作成します
この選択肢が正しくない理由は以下の通りです。
単にConfidential VMを作成するだけでは十分な保護は実現できません。Cloud External Key Managerを用いてDEKをGoogle Cloud外で管理し、それを用いてデータを暗号化、復号化する処理が必要となります。
選択肢：既存のCompute Engine VMとCloud StorageバケットにまたがるVPC Service Controlsサービス境界を作成します
この選択肢が正しくない理由は以下の通りです。
VPC Service Controlsは、データの流出を防ぐためにGoogle Cloudサービスとのデータ交換を制御するのに有効ですが、その機能自体はデータ暗号化やキー管理に関連しません。
したがって、機密データの保護要件を満たすための適切な解決策とは言えません。
参考リンク：
https://cloud.google.com/security-key-management/external-key-manager
https://cloud.google.com/compute/confidential-vm/docs
https://cloud.google.com/storage/docs/encryption/customer-managed-keys
</div></details>

### Q.  問題22: 未回答
オンプレミスのデータウェアハウスをBigQuery、Cloud SQL、Cloud Storageに移行しようとしています。データウェアハウスのセキュリティサービスを構成する必要があります。会社のコンプライアンスポリシーにより、データウェアハウスは以下の要件を満たす必要があります：
- 暗号鍵の完全なライフサイクル管理により、静止状態のデータを保護します。
- データ管理とは別の鍵管理プロバイダーを導入します。
- すべての暗号化キー要求を可視化します。
データウェアハウスの実装にはどのようなサービスを含めるべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のコンプライアンスポリシーと互換性のある、適切なデータウェアハウスのセキュリティ策を選択することが求められています。具体的な要件は暗号鍵のライフサイクル管理、別の鍵管理プロバイダーの導入、そしてすべての暗号化キー要求の可視化です。これらを満たすための提供サービスの特性を理解し、選択肢から正しい組み合わせを選ぶことが必要です。
基本的な概念や原則：
Key Access Justifications：Googleが顧客のデータをアクセスした理由を説明するための機能です。すべての暗号化キー要求を可視化し、より詳細なデータアクセス制御を可能にします。
Cloud External Key Manager（EKM）：Google Cloud外部で暗号化キーを管理するサービスです。データ管理と鍵管理を分離し、静止状態のデータの保護を強化します。
顧客管理の暗号化キー（CMEK）：Google Cloud上で顧客が自身で暗号キーを作成し管理する機能です。暗号キーのライフサイクルを顧客がコントロールします。
顧客指定の暗号化キー（CSEK）：Google Cloudのリソースを暗号化する際に顧客が指定した暗号化キーを使用する機能です。暗号キーの管理を顧客が担当します。
Access Transparency and Approval：Googleのエンジニアやサポートスタッフが顧客のデータにアクセスする際の透明性を提供し、必要に応じてそのアクセスを承認または拒否することが可能にする機能です。
正解についての説明：
（選択肢）
・Key Access Justifications
・Cloud External Key Manager
この選択肢が正解の理由は以下の通りです。
まず、"Key Access Justifications"は、暗号化キーのアクセス要求の可視化に重要なロールを果たします。この機能は、Google Cloudにおけるキーの使用要求を明確に表示し、それが許可される理由や許可を求める要求元を識別することを可能にします。これにより、暗号化キー使用の監視と管理が可能となり、すべての暗号化キー要求の可視化という要件を満たします。
次に、"Cloud External Key Manager"は、Google Cloud外部で暗号化キーのライフサイクルを管理するためのサービスです。つまり、キー管理をデータ管理とは別のプロバイダーに委託しました。これにより、静止状態のデータの完全な保護と暗号鍵の完全なライフサイクル管理が可能となります。External Key Managerは、暗号鍵の全ライフサイクルを管理し、データ保護要件の満足度を高めるための最良の選択となります。
これら2つのサービスを使用することにより、静止状態のデータの保護、鍵管理の独立性、暗号化キー要求の可視化という3つの重要なコンプライアンス要件を満たすことができます。
不正解についての説明：
選択肢：顧客管理の暗号化キー
この選択肢が正しくない理由は以下の通りです。
"顧客管理の暗号化キー"ではデータ管理と鍵管理を別々のプロバイダーで行うという要件を満たしません。一方"Cloud External Key Manager"は外部の鍵管理システムを使用でき、また"Key Access Justifications"は鍵要求の可視化を可能にします。
選択肢：顧客指定の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客指定の暗号化キー（CSEK）を使用しても、暗号鍵の完全なライフサイクル管理や別の鍵管理プロバイダーの導入という要件には対応できません。反対に、Cloud External Key Managerを用いると、外部の鍵管理サービスを利用でき、Key Access Justificationsは鍵要求の可視化を提供します。
選択肢：Access Transparency and Approval
この選択肢が正しくない理由は以下の通りです。
Access Transparency and Approvalでは鍵の管理や可視化は提供されないため不適切です。
その一方で、Cloud External Key Managerは外部鍵の管理を、Key Access Justificationsは暗号化キー要求の可視化を可能にするので正解です。
参考リンク：
https://cloud.google.com/security-key-management
https://cloud.google.com/kms/docs/external-key-manager
https://cloud.google.com/bigquery/docs/encryption-key-management
</div></details>

### Q.  問題23: 未回答
あなたは、機密データの暗号化キーの管理について懸念しているクライアントと仕事をしています。このクライアントは、暗号化キーが暗号化されるデータと同じクラウドサービスプロバイダ（CSP）に暗号化キーを保存したくないと考えています。
このクライアントにどのGoogle Cloud暗号化ソリューションを勧めるべきですか？（2つ選択）
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、顧客の特定の要望に基づいたGoogle Cloudの暗号化ソリューションを選択することが求められています。顧客は暗号化キーをデータと同じクラウドサービスプロバイダ（CSP）に保存したくないとの要望を出しています。したがって、選択肢を検討する際は、これらの要望を満足するソリューションを選ぶべきです。これは、クラウドプロバイダがキーを管理するデフォルトの暗号化ソリューションだけでなく、キーの外部管理を可能にするソリューションも考慮に入れることを意味します。
基本的な概念や原則：
顧客指定の暗号化キー（CSEK）：Google Cloudのストレージ製品で使用するエンクリプションキーを顧客が直接管理・提供する方式です。この方式では、キーはGoogle Cloud外部で管理され、データは顧客が指定したキーで暗号化されます。
Cloud External Key Manager（Cloud EKM）：Cloud EKMは、Google Cloudのリソースを、外部のキーマネージメントシステムから直接制御できるようにするサービスです。それにより、データの暗号化キーをGoogle Cloudとは別の場所で保存、管理できます。
Googleのデフォルト暗号化：Google Cloudのすべてのデータはデフォルトで暗号化されますが、この方式では、キー管理はGoogleが行い、キーはGoogle Cloud内部で管理されます。
Secret Manager：Google Cloudのセキュアで堅牢なサービスで、保護すべき秘密データのストレージと管理を提供します。しかし、暗号化キー自体の管理ではなく、APIキーやパスワードなどの秘密情報全般の管理を主に扱います。
顧客管理の暗号化キー（CMEK）：Cloud KMSを使用して作成、ローテーション、自動的に破棄するキーを指定してGoogle Cloudのデータを暗号化する方法です。この方式では、キーの管理は顧客が行いますが、キー自体はGoogle Cloud内部に保存されます。
正解についての説明：
（選択肢）
・顧客指定の暗号化キー
・Cloud External Key Manager
この選択肢が正解の理由は以下の通りです。
顧客指定の暗号化キー（CSEK）は、Google Cloud環境内のデータを保護するために顧客が提供および管理するキーで、Googleが保持しません。しかし、CSEKは暗号化されるデータと同じCSP、つまりGoogle Cloudにキーを保存する必要がありますが、キーの管理はクライアント側が行います。これはクライアントの要求に一部適合しています。
さらに、Cloud External Key Manager（EKM）は、Google Cloudの外部で暗号化キーを管理するためのサービスです。これにより、クライアントはキーを任意の第三者CSPに保存し、管理することが可能となります。この機能がクライアントの要望、つまり暗号化キーを暗号化されるデータと同じCSPに保存したくないとの要望に合致します。
したがって、顧客指定の暗号化キーとCloud External Key Managerの両方がクライアントの要望を満たす適切な選択肢となります。
不正解についての説明：
選択肢：Googleのデフォルト暗号化
この選択肢が正しくない理由は以下の通りです。
Googleのデフォルト暗号化では、キー管理はGoogleが行い、暗号化キーはGoogle Cloud上に保存されます。クライアントが暗号化キーを他のCSPに保存したいと考えているため、このオプションはクライアントの要件を満たしません。
選択肢：Secret Manager
この選択肢が正しくない理由は以下の通りです。
Secret Managerは秘密情報（パスワードやAPIキーなど）の安全な管理とアクセスを提供しますが、暗号化キーの管理機能は提供していません。
それに対して、顧客指定の暗号化キーとCloud External Key Managerは両方とも客観的な暗号化キーの管理を支援します。
選択肢：顧客管理の暗号化キー
この選択肢が正しくない理由は以下の通りです。
顧客管理の暗号化キーはGoogle Cloud自体で管理されるため、暗号化データと同じプロバイダで鍵を保存することになってしまいます。
それに対し、顧客指定の暗号化キーとCloud External Key Managerは両方ともキーの管理をクライアント自身が行う設定を可能にします。
参考リンク：
https://cloud.google.com/kms/docs/external-key-manager
https://cloud.google.com/kms/docs/csek
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題24: 未回答
組織のGoogle Cloud VMは、外部ユーザー向けのウェブサービスをホストするために、パブリックIPアドレスで構成されたインスタンステンプレートを介してデプロイされます。VMは、VM用のカスタムShared VPCを1つ含むホスト（VPC）プロジェクトにアタッチされたサービスプロジェクトに常駐しています。あなたは、外部ユーザーへのサービスを継続しながら、VMのインターネットへの露出を減らすように求められました。あなたはすでに、マネージドインスタンスグループ（MIG）を起動するために、パブリックIPアドレス構成なしでインスタンステンプレートを再作成しました。
この要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、外部ユーザー向けのウェブサービスをホストしているGoogle Cloud VMのインターネットへの露出を減らす必要があります。VMはカスタムShared VPCを1つ含むホストプロジェクトにサービスプロジェクトという形でアタッチされています。ここで注意しなければならないのは、システムがインターネットに露出することを減らすためだけでなく、同時に外部ユーザーへのサービス継続も求められているという点です。そして、パブリックIPアドレス無しでインスタンステンプレートを再作成し、マネージドインスタンスグループ（MIG）を起動するまでのタスクは完了しています。問題の鍵は、これらの情報を考慮して、MIGのインターネットへの露出の度合いを最小限に抑えつつ、外部ユーザーへのサービスは続行するための方法を選択することです。
基本的な概念や原則：
インスタンステンプレート：Compute Engineのインスタンスを作成するための設定が保存されたテンプレートです。一度作成した設定を再利用することで一貫性と作業効率を向上させます。
Shared VPC：Google Cloud上の複数のプロジェクト間で仮想ネットワークリソース（VPCネットワーク、サブネット、IPアドレス）を共有できる機能です。これにより、セキュリティとネットワーク管理が一元化され、分散リソースの対応が可能になります。
マネージドインスタンスグループ（MIG）：Compute Engineのインスタンスを自動的に管理する機能です。スケールアップやスケールダウン、負荷分散などを自動的に行うことができます。
HTTP(S)ロードバランサー：HTTP/HTTPSトラフィックを複数のインスタンスに分散する機能です。これにより、高負荷状況でも安定したサービス提供が可能になります。
Cloud NAT：Google CloudのNAT（Network Address Translation）ゲートウェイです。プライベートアドレスからパブリックアドレスへの変換機能を提供しますが、インターネットからの直接的なアクセスを可能にするものではありません。
正解についての説明：
（選択肢）
・MIGをバックエンドとするサービスプロジェクトに、外部のHTTP(S)ロードバランサーをデプロイします
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのHTTP(S)ロードバランサーは、インターネットからのトラフィックを特定のバックエンド（このケースではMIG）に分散するロールを果たします。これにより、VMのインターネットへの露出は大幅に減少し、それでも外部ユーザーからのアクセスが可能となります。ロードバランサー自体がインターネットに公開され、外部トラフィックを想定通りにルーティングします。
また、MIGをバックエンドに設定することで、MIG内のインスタンスへのトラフィックを効率的にバランスさせることができます。これにより、高い堅牢性と性能を維持しながら、外部のウェブサービスを提供することが可能となります。
さらに、改めてパブリックIPアドレスを割り当てない新しいインスタンステンプレートを作成したことで、VMのインターネットへの露出は更に軽減されます。この要件に対する最善のソリューションと評価されます。
不正解についての説明：
選択肢：MIGのサービスプロジェクトにCloud NATゲートウェイをデプロイします
この選択肢が正しくない理由は以下の通りです。
Cloud NATゲートウェイは、外部への露出を減らすのではなく、プライベートインスタンスに対してアウトバウンド通信の設定を提供します。つまり、本質的に内部から外部への接続を管理し、外部ユーザーからのアクセスを制御するものではありません。
対照的に、HTTP(S)ロードバランサーでは公開サービスへの外部ユーザーのアクセスを制御しつつ、VMの直接的なインターネット接続を防げるため、適切な選択肢となります。
選択肢：MIGのホスト（VPC）プロジェクトにCloud NATゲートウェイをデプロイします
この選択肢が正しくない理由は以下の通りです。
Cloud NATゲートウェイは、VMがインターネットと通信するためのプライベートIPアドレスを提供しますが、外部ユーザーがサービスにアクセスするためのポート付き公開IPアドレスは提供しません。上記の要件は、サービスのアクセスを維持しつつ、VMのインターネット露出を減らすことなので、Cloud NATだけでは不十分です。
選択肢：MIGをバックエンドとするホスト（VPC）プロジェクトに、外部のHTTP(S)ロードバランサーをデプロイします
この選択肢が正しくない理由は以下の通りです。
VMがサービスプロジェクトに存在するため、サービスプロジェクトにロードバランサーを配置するのが適切です。ホストプロジェクトにロードバランサーを配置した場合、外部ユーザーに対するサービスを継続できない可能性があります。
参考リンク：
https://cloud.google.com/compute/docs/instance-templates
https://cloud.google.com/load-balancing/docs/https
https://cloud.google.com/nat/docs/overview
</div></details>

### Q.  問題25: 未回答
あなたは最近、会社のGoogle Cloud導入をサポートするネットワーキングチームに加わりました。あなたには、ファイアウォールルールの構成に慣れ、ネットワーキングとGoogle Cloudの経験に基づいた推奨事項を提供することが任されています。
優先順位の高い、または等しい他のファイアウォールルールの属性と重複しているファイアウォールルールを検出するために、どの製品を推奨すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Google Cloudのネットワーキングとセキュリティに関する知識が求められています。具体的には、ファイアウォールルールの重複を検出するためのツールや製品を理解する必要があります。問題文中には重複するファイアウォールルールを特定する必要があると述べられており、その目的を達成するために最適な製品を選択することが求められています。したがって、各選択肢が具体的にどのような機能を提供し、それが問題の要件にどの程度適合するかを考慮する必要があります。
基本的な概念や原則：
ファイアウォールインサイト：Google Cloudの機能の一つで、ファイアウォールルールの分析と最適化を支援します。他のファイアウォールルールとの重複や未使用のルールを特定できます。
Security Command Center：Google Cloudのセキュリティ管理プラットフォームで、組織全体の脅威と脆弱性を一元的に表示・管理することができます。ただし、ファイアウォールルールの重複を特定する機能はありません。
ファイアウォールルールのログ：ファイアウォールルールがトラフィックを許可または拒否した際のログです。ルールの効果を確認するために利用しますが、ルールの重複を特定する機能はありません。
VPCフローログ：VPCネットワーク上のIPトラフィックの詳細な情報を提供するログです。ネットワーク監視やトラフィック分析、トラフィックエンジニアリングに有用ですが、ファイアウォールルールの重複を特定する機能はありません。
正解についての説明：
（選択肢）
・ファイアウォールインサイト
この選択肢が正解の理由は以下の通りです。
ファイアウォールインサイトは、Google Cloud上で構成されたファイアウォールルールやその関連情報の解析を行い、複雑なネットワーキング環境を可視化し、調整します。具体的には、ファイアウォールルール間での重複を検出したり、不要なルールや潜在的な誤設定を特定したりといった詳細な分析が可能です。これは、新しくチームに加わったあなたが、ファイアウォールルールの構成に慣れるための重要なツールとなります。
また、ファイアウォールインサイトを使用することで、ネットワーキングに関する洞察や推奨事項をチームに提供することが可能になります。そのため、このシナリオにおいては、"ファイアウォールインサイト"が最も適した製品ととなります。
不正解についての説明：
選択肢：Security Command Center
この選択肢が正しくない理由は以下の通りです。
Security Command Centerは、Google Cloudリソースの脆弱性、誤設定などを検出できますが、特に"ファイアウォールルールが重複している"ことを特定的に検出する機能はありません。
一方、ファイアウォールインサイトはGoogle Cloud内のネットワークトラフィックとファイアウォールルールを分析し、ルールの重複などを明確に識別できるので正解です。
選択肢：ファイアウォールルールのログ
この選択肢が正しくない理由は以下の通りです。
ファイアウォールルールのログはルールが適用された際のアクティビティを表しますが、ルールの重複検出機能はありません。
一方、ファイアウォールインサイトはルールの衝突分析や重複検出機能を持つため問題の要件を満たします。
選択肢：VPCフローログ
この選択肢が正しくない理由は以下の通りです。
VPCフローログはネットワークフローの情報を収集し分析するためのサービスですが、ファイアウォールルールの属性やそれらが重複するかどうかを自動的に検出する機能は有していません。
一方、ファイアウォールインサイトはファイアウォールルールの検証と最適化を支援するサービスで、重複するルールの検出が可能です。
参考リンク：
https://cloud.google.com/network-intelligence-center/docs/firewall-insights/overview
https://cloud.google.com/network-intelligence-center/docs/firewall-insights/how-to
https://cloud.google.com/network-intelligence-center
</div></details>

### Q.  問題26: 未回答
あなたはCompute Engineのディスク上のデータを、Cloud Key Management Service（KMS）が管理するキーで静止時に暗号化したいと考えています。これらのキーに対するCloud IdentityおよびIAMのパーミッションは、すべてのキーに対して同じである必要があるため、グループ化された方法で管理する必要があります。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute Engineのディスク上のデータをCloud Key Management Service（KMS）で静止時に暗号化する方法と、そのキーへのパーミッションをグループ化された方法で管理する方法が求められています。重要な要件としては、すべてのキーに対してパーミッションが同じである必要があり、これらのパーミッションを一括で管理したいという点が挙げられます。したがって、各キーを個別に管理するのではなく、キーのグループ（KeyRing）単位でパーミッションを制御する方法を選びます。その際、キー単位ではなくKeyRingレベルでIAMパーミッションを管理する点に注意しなければなりません。
基本的な概念や原則：
Compute Engine：Google Cloudのインフラストラクチャで、仮想マシンを実行する環境を提供します。高パフォーマンスネットワーキングと自動的なスケーリングが可能です。
Cloud Key Management Service（KMS）：Google Cloudの暗号キー管理サービスです。自分でキーを管理するか、Googleにキーの生成や管理を任せることができます。
KeyRing：Cloud KMSのリソースで、暗号キーの論理的なグループです。一つのKeyRingは複数の暗号キーを持ち、それらをまとめて管理することが可能です。
IAMパーミッション：Google CloudのIdentity and Access Management（IAM）における、特定のユーザーやグループに付与できるアクセス制御です。コードやデータの閲覧、編集、実行などを許可、制限することが可能です。
静止時暗号化：データが保存されている状態（つまり、データが動いていない状態）でデータを暗号化することです。ハードドライブやリムーバブルメディアなどが対象となります。
永続ディスク：Compute Engine上で使用されるブロックストレージです。インスタンスとは独立して存在し、インスタンスが削除されてもデータは保持されます。
正解についての説明：
（選択肢）
・すべての永続ディスクとこのKeyRing内のすべてのKeyについて、単一のKeyRingを作成します。KeyRingレベルでIAMパーミッションを管理します
この選択肢が正解の理由は以下の通りです。
Cloud KMSでは、複数の暗号キー（CryptoKeys）を管理するためのコンテナとしてKeyRingを提供しています。各KeyRingは、異なるCryptoKeyをグループ化して一元化し、より効率的なアクセス制御を実現します。
本問題の要件では、すべてのキーに対して同一のIAMパーミッションが求められています。
したがって、各キーに対して別々にパーミッションを付与するのではなく、それら全てを含む単一のKeyRingを作成し、このKeyRingレベルでIAMパーミッションを管理することで、一括でアクセス制御を行うことが可能になります。これは管理コストを削減し、一貫したパーミッション管理を実現します。
さらに、このアプローチはすべての永続ディスクの暗号化にも適用可能で、統一されたセキュリティポリシーを維持しながらデータを保護することができます。
不正解についての説明：
選択肢：すべての永続ディスクとこのKeyRing内のすべてのKeyについて、単一のKeyRingを作成します。KeyレベルでIAMパーミッションを管理します
この選択肢が正しくない理由は以下の通りです。
問題の要件では、すべてのキーに対して同一のIAMパーミッションを適用することが必要とされています。しかし、この選択肢ではKeyレベルでのIAMパーミッション管理を提案しており、これは個々のキーに対して異なるIAMパーミッションを設定することを意味します。これは要件と矛盾しているため、この選択肢は不正解です。
選択肢：永続ディスクごとにKeyRingを作成し、各KeyRingに1つのKeyを含めます。KeyレベルでIAMパーミッションを管理します
この選択肢が正しくない理由は以下の通りです。
要件はすべてのキーに対するIAMパーミッションが同じであることを指定しているのに対し、この選択肢は永続ディスクごとにKeyRingを作成し、各KeyRingに1つのKeyを含めることを提案しています。このアプローチは、各キーに個別の管理要件を持たせることを意味し、要件とは一致しません。
選択肢：永続ディスクごとにKeyRingを作成し、各KeyRingに1つのKeyを含めます。KeyRingレベルでIAMパーミッションを管理します
この選択肢が正しくない理由は以下の通りです。
設問の要求はすべてのキーに対してパーミッションが同じであることであり、異なるKeyRingに区分して設置すると管理が煩雑になる可能性があります。
逆に、単一のKeyRingを用いることで管理が一元化され、求められる要件に適合します。
参考リンク：
https://cloud.google.com/kms/docs/encrypting-disks
https://cloud.google.com/iam/docs/granting-roles-to-service-accounts
https://cloud.google.com/compute/docs/disks/customer-supplied-encryption
</div></details>

### Q.  問題27: 未回答
Compute Engine上でホストされているWebアプリケーションをデプロイしています。ビジネス要件として、アプリケーションのログを12年間保存し、データをヨーロッパの境界内に保存することが義務付けられています。あなたは、オーバーヘッドを最小限に抑え、費用対効果の高いストレージソリューションを実装したいと考えています。
あなたはこの要件を満たすために、どうすればよいですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、Compute EngineでホストされるWebアプリケーションのログをヨーロッパ内に12年間保存することと、オーバーヘッドを最小限に抑え費用対効果を高めることが求められています。つまり、ログの保存場所、保存期間、費用や効率性といった要素に注目する必要があります。これらの要素に基づいて、ログの保存に最適なGoogle Cloudのストレージソリューションを選択します。アプリケーションコードの変更や、Google Cloudの異なるサービスを利用することの影響も考慮し、最適な解決策を選択することが問われています。
基本的な概念や原則：
Cloud Storage：Google Cloudのデータ保存サービスです。グローバルで、ローカルで、地域で保存できます。大量のデータを安全かつ耐久性高く保存でき、ロギングにも適しています。
リージョン：Google Cloudのデータを物理的に保管する地域のことです。リージョンの選択によりデータの住所や住所の範囲が決まります。
Google Cloudの操作組：Google Cloudの監視、トラブルシューティング、アプリケーションパフォーマンス管理を統合する一連のツールです。
Cloud Logging：Google Cloudの操作スイート内の一部で、アプリケーションとシステムからのログを収集、分析、エクスポートするサービスです。
Pub/Subトピック：Google Cloud Pub/Subにおけるエンドポイントで、パブリッシャーがメッセージを送信する場所です。
操作スイートのログバケット：ログデータを保存するためのオペレーションスイートの機能です。各バケットは特定の場所にデータを保存し、一定期間データを保存することができます。
カスタム保存ポリシー：ログバケットに格納されるログデータの保持期間を設定するためのポリシーです。これは特定のコンプライアンス要件を満たすために使われます。
正解についての説明：
（選択肢）
・europe-west1リージョンにログを保存するCloud Storageバケットを作成します。アプリケーションコードを変更して、ログをバケットに直接送信し、効率を高めます
この選択肢が正解の理由は以下の通りです。
まず、Google Cloud Storageは長期間のデータ保管に適したコスト効率の高いストレージオプションを提供しており、アプリケーションログの永続的な保存を行うために理想的です。12年という長期間のログ保管を求められている要件を効果的に満たします。
さらに、Google Cloud Storageはリージョナルなデータ格納に対応しています。そのため、"データをヨーロッパの境界内に保存する"という要件も満たせるわけです。この選択肢では、europe-west1リージョンにバケットを作成することでこの要件を満たすことができます。
そして、アプリケーションコードを変更してログをバケットに直接送信することで、ログの流れを最適化し、オーバーヘッドを最小限に押さえることができます。これは、パフォーマンスとコスト効率を改善するために重要なステップです。結果として、この選択肢は全ての要件を最適化した形で満たすため、正解となります。
不正解についての説明：
選択肢：Compute EngineインスタンスがGoogle CloudのオペレーションスイートCloud Loggingエージェントを使用し、アプリケーションログをeurope-west1リージョンのカスタムログバケットに送信するように設定します
この選択肢が正しくない理由は以下の通りです。
Cloud Loggingエージェントを使用する場合、ログの送信にオーバーヘッドがかかります。そのため、オーバーヘッドを最小限に抑えるというビジネス要件を満たすことができません。
また、直接Cloud Storageにログを保存することで効率が良くなるため、コスト対効果に優れています。
選択肢：Pub/Subトピックを使用して、アプリケーションログをeurope-west1リージョンのCloud Storageバケットに転送します
この選択肢が正しくない理由は以下の通りです。
Pub/Subトピックを使用すると、ログデータの転送にオーバーヘッドが発生します。正解の選択肢と比べて、ログデータを直接Cloud Storageバケットに送信する方が効率的で、コストも少なく抑えられます。
選択肢：europe-west1リージョンのGoogle Cloudのオペレーションスイートのログバケットに、12年間のカスタム保存ポリシーを設定します
この選択肢が正しくない理由は以下の通りです。
Google Cloudのオペレーションスイート（旧Google Cloud Operation Suite）の保存期間は最大で30日間であり、カスタム保存ポリシーを用いてそれ以上延ばすことができません。そのため、要件である12年間のログ保存を満たすことができません。
参考リンク：
https://cloud.google.com/storage/docs/creating-buckets
https://cloud.google.com/storage/docs/locations
https://cloud.google.com/compute/docs/instances/create-start-instance
</div></details>

### Q.  問題28: 未回答
多国籍企業の事業部門がGoogle Cloudにサインアップし、ワークロードをGoogle Cloudに移行し始めた。その事業部門は、何百ものプロジェクトを持つ組織リソースでCloud Identityドメインを作成します。
あなたのチームはこのことに気づき、ドメインリソースの権限管理と監査を引き継ぎたいと考えています。
この要件を満たすには、どのタイプのアクセスを付与すべきですか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、会社のビジネスユニットがGoogle Cloudに移行を開始し、あなたのチームがドメインリソースの権限管理と監査を担当したいと考えているという状況が示されています。選択肢の中から、この要件を満たすために必要なアクセスレベルを正確に選択することが求められています。特に、ドメインリソース全体の管理と監査に必要なアクセス権とは何かを理解することが重要です。選択肢から適切なロールを洗い出すためには、Google Cloudの権限モデルと各ロールがどのようなアクセスを付与するのかを把握していることが必要です。
基本的な概念や原則：
Organization Administrator：Google Cloudの組織全体のアクセスと操作管理を提供します。組織やプロジェクトを作成し、それらに対するアクセス制限やアクセスレベルを定義できます。
Cloud Identityドメイン：Google Cloudのユーザとグループ管理を提供します。Identity and Access Management（IAM）の一部として機能し、ユーザとグループがCloud Identity Aware ProxyまたはCloud Identity Platform APIといったGoogle Cloudのリソースにアクセスするための認証を提供します。
Identity and Access Management（IAM）：ユーザとサービスアカウントへのロールベースのアクセス制御の提供し、Google Cloudリソースへのアクセスを管理します。IAMポリシーは誰が（Identity）、何を（Role）、どこで（Resource）行うことができるかを定義します。
Security Reviewer：特定のリソースに対するアクセス権限を監査するためのロールです。全組織的な権限管理には適しません。
Organization Role Administrator：組織レベルの角色を作成、変更、削除するためのロールです。全組織のリソースへのアクセス権限の設定には適しません。
Organization Policy Administrator：組織ポリシーの作成、変更、適用を行うロールです。これは組織全体のリソースに対するアクセス制御よりも、特定のリソースの使用ポリシーを定義する働きをします。
正解についての説明：
（選択肢）
・Organization Administrator
この選択肢が正解の理由は以下の通りです。
Organization Administratorのロールは、Google Cloudでの組織全体のリソース管理を効果的に制御できる最高レベルのアクセス権限を持っています。このロールが付与されると、ユーザーは組織全体のリソースに対して管理と監査の操作を実行できます。具体的には、組織のリソース階層構造のセットアップ、IAMポリシーの管理、組織設定の更新など、組織全体に関連するアクションを管理することが可能になります。これにより、その組織ダメイン内で利用されているプロジェクトやその他のリソースについて、統一した規模での管理と監視が可能となります。
したがって、Cloud Identityドメインの権限管理と監査を引き継ぎたいと考えるあなたのチームには、Organization Administratorのアクセス権限が最適となります。
不正解についての説明：
選択肢：Security Reviewer
この選択肢が正しくない理由は以下の通りです。
Security ReviewerはIAMロールの一部で、権限の監査は可能ですが、権限管理や設定の機能はありません。
一方、Organization Administratorは、ドメインリソース全体の権限管理と監査が可能で、要件を満たす全機能を提供します。
選択肢：Organization Role Administrator
この選択肢が正しくない理由は以下の通りです。
Organization Role Administratorの権限を付与されると、そのユーザーは組織全体のロールを管理できますが、それはドメインリソースの管理や監査を直接的に手助けするものではありません。Organization Administratorの権限を持つユーザーの方が、組織全体のすべてのGoogle Cloudリソースを管理できるため必要なタスクを実行することが可能です。
選択肢：Organization Policy Administrator
この選択肢が正しくない理由は以下の通りです。
Organization Policy Administratorの権限ではポリシーの設定や更新が可能ですが、ドメインリソースの全体的な権限管理や監査を行うために必要なOrganization Administratorの権限を持っているわけではありません。なので、組織全体のリソースを管理するためには、Organization Administratorの権限が必要です。
参考リンク：
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://cloud.google.com/resource-manager/docs/access-control-org
https://cloud.google.com/resource-manager/docs/creating-managing-organization
</div></details>

### Q.  問題29: 未回答
アプリケーションとリソースにアクセス制御ポリシーを適用するために、どのGoogle Cloudサービスを使用すべきですか？
1. 
2. 
3. 
4. 
<details><div>
    答え：
この問題では、適切なアクセス制御ポリシーを適用するためのGoogle Cloudのサービス選択の課題に取り組んでいます。選択肢から判断すべき主要な観点は、それらのサービスが提供する具体的な機能と、問題文中で述べられた要件との対応関係です。課題はアクセス制御ポリシーを適用するという点であり、これに応じたサービスを選択することが求められます。この視点から選択肢を評価することで、最も適切な選択肢に辿り着きます。
基本的な概念や原則：
Identity-Aware Proxy：Google Cloudの認証と認可を行うためのサービスです。アプリケーションやリソースのアクセス制御ポリシーの適用と管理を行うことができます。
Cloud NAT：Google Cloud上での中継ネットワーキングを提供するサービスです。プライベートネットワークからインターネットへの接続を可能にします。
Google Cloud Armor：Google Cloud上のアプリケーションを保護するためのDDoS防御サービスです。
Shielded VM：Google Cloud上で実行する仮想マシンに追加のセキュリティ保護を提供するサービスです。不正なソフトウェアや不正アクセスから保護します。
正解についての説明：
（選択肢）
・Identity-Aware Proxy
この選択肢が正解の理由は以下の通りです。
まず、Google CloudのIdentity-Aware Proxy（IAP）は、GoogleのBeyondCorpセキュリティモデルを利用して、企業のアプリケーションやリソースへのセキュアなアクセスを提供します。IAPを使用すると、公開Webアプリケーションに対するアクセスを制御し、特定のGoogle Cloudのリソースへの認証済みユーザーまたはグループのアクセスを管理することができます。
また、VPNや物理的なデバイスなどを必要とせずに、リモートワークをしているユーザーがセキュアな環境でアクセスできるようにします。これにより、安全性を維持しつつ柔軟なアクセス制御を実現することができます。
したがって、アクセス制御ポリシーを適用するためには、Identity-Aware Proxyが適したサービスとなります。
不正解についての説明：
選択肢：Cloud NAT
この選択肢が正しくない理由は以下の通りです。
Cloud NATはプライベートなGoogle Cloudリソースからインターネットにアクセスするためのサービスであり、アクセス制御ポリシーを適用する機能はありません。
一方、Identity-Aware Proxyはアプリケーションやリソースへのアクセス制御のためのサービスで、適切な認証と認可を提供します。
選択肢：Google Cloud Armor
この選択肢が正しくない理由は以下の通りです。
Google Cloud Armorは、HTTP(S) ロードバランサーのトラフィックを保護する主にDDoS攻撃防止やWAFの機能を提供していますが、アプリケーションやリソースへのアクセス制御ポリシーを適用する機能は提供していません。
一方、Identity-Aware Proxyはリソースへのアクセス制御を行うためのサービスであり、適切な選択肢となります。
選択肢：Shielded VM
この選択肢が正しくない理由は以下の通りです。
Shielded VMはVMインスタンスの信頼性とセキュリティを向上させるサービスであり、アクセス制御ポリシーをアプリケーションやリソースに適用する機能を提供していません。
逆に、Identity-Aware Proxyはアクセス制御機能を提供し、ユーザーやグループに基づいてアプリケーションやリソースへのアクセスを制御します。
参考リンク：
https://cloud.google.com/iap/docs
https://cloud.google.com/armor/docs
https://cloud.google.com/compute/docs/shielded-vm
</div></details>

# 2
## 1

### Q.  問題2: 未回答
独自の企業秘密を保管する機密性の高い Cloud Spanner データベースを管理しており、パブリック インターネットからアクセスできないようにする必要があります。不正なデータアクセスのリスクを軽減するために、すべてのデータベースクエリは、事前定義されたIPアドレスのセットによってのみ実行可能である必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud Platform リソース(特に Cloud Spanner)を不正な一般アクセスから保護することについての受験者の理解度を評価します。焦点は、データベースクエリを事前定義されたIPアドレスのセットに制限する方法です。
重要な用語:
VPC Service Controls: GCP サービスに保存されているデータの周囲にセキュリティ境界を定義して、データ流出のリスクを制限できる Google Cloud リソースのセキュリティ レイヤです。
アクセスレベル: VPC Service Controls の一部であるアクセスレベルを使用すると、IP アドレス範囲などの属性を設定して、GCP リソースへのきめ細かなアクセス制御を適用できます。
正解解説:
(オプション)
・VPC Service Controlsを使用し、承認済み送信元IPアドレスを条件とするアクセスレベルを定義します。
VPC Service Controls は、事前定義された一連の IP アドレスへのデータ アクセスを制限することで機密データのセキュリティを強化し、Cloud Spanner の周囲に安全な境界を作成するため、この選択は適切です。承認された送信元 IP アドレスの条件を含むアクセス レベルを定義することで、指定した IP のクライアントのみがデータベース クエリを実行できるようにし、パブリック インターネットからのアクセスを防止する要件に合わせます。
不正解の説明:
オプション: HTTP(S) ロードバランサ レベルで IP の承認済みリストを含めるように Google Cloud Armor セキュリティ ポリシーを構成します。
この選択が間違っている理由は、Cloud Armor が DDoS 攻撃や SQL インジェクションなどの HTTP(S) ロードバランサ レベルでの攻撃から保護するように設計されているためです。送信元 IP アドレスに基づいて Cloud Spanner データベースへのアクセスを制限する方法は提供されません。
オプション: Restrict Resource Locations 組織ポリシーの制約を Cloud Data Loss Prevention(DLP)ツールと組み合わせて実装します。
この選択が間違っている理由は、リソースの場所を制限する組織ポリシーと Cloud DLP が IP アドレスに基づいてアクセスを制御するためのツールではないためです。これらは、保存されたデータの場所を制御し、機密情報を保護することを目的としており、IPベースのアクセス管理を目的としていません。
オプション: [サービス利用の無効化] 組織ポリシーの制約を適用し、Cloud Data Loss Prevention(DLP)を利用して制御を強化します。
この選択が正しくない理由は、Disable Service Usage 組織ポリシー制約を適用すると、サービスが完全に使用されなくなり、IP アドレスに基づいてアクセスが制御されないためです。Cloud DLP はデータ保護を提供しますが、データベースクエリの実行を IP アドレスで制限することはありません。
参考：
https://cloud.google.com/vpc-service-controls/docs/create-manage-service-perimeters
https://cloud.google.com/access-context-manager/docs/overview
https://cloud.google.com/bigquery/docs/controlled-access
</div></details>

### Q.  問題8: 未回答
ある医療機関は、電子カルテシステムを Google Cloud に移行しながら、一部の重要なサービスをローカル データセンターでホストしています。シームレスなデータ転送のためには、少なくとも70Gbpsの接続を確保する必要があります。
オンプレミス インフラストラクチャとクラウド間の高速で安全な接続を維持するには、どの Google Cloud サービスを使用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、オンプレミス インフラストラクチャと Google Cloud の間で大量のデータを転送するための高速かつ安全な直接接続を確保するために、Google Cloud で利用できるサービスに対する理解度を評価します。
重要な用語:
専用相互接続: 組織のネットワークと Google のネットワークを直接物理的に接続し、可用性の高い低レイテンシの接続を提供します。
Cloud Router: VPN と連携し、Border Gateway Protocol(BGP)を使用して Google Cloud VPC とオンプレミス ネットワーク間でルートを動的に交換します。
Cloud VPN: オンプレミス ネットワークと Google Cloud VPC の間に、パブリック インターネット経由で安全で暗号化された接続を確立します。
Partner Interconnect: サポートされているサービス プロバイダを通じて Google Cloud への接続を提供し、Dedicated Interconnect よりも少ない容量しか必要としない組織に適しています。
正解解説:
(オプション)
・専用インターコネクト
Dedicated Interconnect は、組織がオンプレミス ネットワークと Google のネットワークの間に直接物理接続を確立し、リンクあたり最大 100 Gbps の転送速度を可能にするため、正しい選択です。これは、電子カルテシステム用に70Gbpsの接続を保証する必要がある医療従事者に最適です。さらに、機密性の高い健康データに不可欠な、一貫性のある低遅延で安全でプライベートな接続を提供します。
不正解の説明:
オプション:クラウドルーター
Cloud Router が正しくない理由は、Cloud Router 自体が接続ソリューションを提供していないためです。Cloud Router は VPN 接続の動的ルーティング用であり、シナリオに必要な専用帯域幅や高スループットは提供されません。
オプション:クラウドVPN
クラウドVPNが間違っている理由は、インターネット上で暗号化されたトンネルを提供し、トンネルあたりの最大スループットが3Gbpsであるため、質問に記載されている70Gbpsの要件には不十分であるためです。
オプション:パートナー相互接続
Partner Interconnect が間違っている理由は、オンプレミス ネットワークを Google Cloud に拡張するためのオプションにはなり得ますが、通常は Dedicated Interconnect の容量が大きすぎる場合に選択されるためです。必要な 70 Gbps の場合、パートナー相互接続のスループットが十分でないか、費用対効果が低くなる可能性があります。
参考：
https://cloud.google.com/interconnect/docs/how-to/dedicated
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/interconnect/docs/concepts/overview
</div></details>

### Q.  問題10: 未回答
小売企業向けに Compute Engine でホストされる在庫追跡システムを設定しています。同社のポリシーでは、システムアクセスログを15年間保持し、データレジデンシーをアジア太平洋地域内に限定することが義務付けられています。管理を簡素化し、経済的に実行可能なストレージソリューションをお探しです。
あなたは何を着手すべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、15年間の保存期間とアジア太平洋地域に限定されたデータレジデンシーという2つの特定の要件を持つシステムアクセスログのストレージソリューションを特定することを目的としています。このソリューションは、Compute Engine インスタンスと統合し、管理が容易で費用対効果が高いものでなければなりません。
重要な用語:
データ所在地: データ所在地とは、データが格納される物理的または地理的な場所を指します。特定の規制や企業ポリシーにより、コンプライアンス要件を満たすために、データが特定の地域内に保存されることが規定されている場合があります。
アイテム保持ポリシー: アイテム保持ポリシーは、データを削除する前に保持する期間を管理する一連のルールです。多くの場合、法的および規制上の要件への準拠により、これらのポリシーが決定されます。
経済的に実行可能:ソリューションが経済的に実行可能である場合、それは費用対効果が高く、初期費用と継続的な費用の両方を考慮すると、使用期間中に過度の経済的負担を課さないことを意味します。
正解解説:
(オプション)
・ASIA-EAST1リージョンにシステムアクセスログを保管するCloud Storageバケットを作成します。ログをバケットに直接プッシュするようにシステムを調整して、プロセスを最適化します。
この選択は、指定された両方の要件に直接対処するため、最適です。ASIA-EAST1 リージョンに Cloud Storage バケットを作成すると、データ レジデンシーのコンプライアンスが確保されます。Cloud Storage では、オブジェクトのライフサイクル ポリシーを設定することもできますが、15 年の固定保持期間を直接サポートしていません。代わりに、カスタム保持ポリシーを使用してオブジェクトを設定するか、ライフサイクルポリシーを実装して、必要な期間削除されないようにすることができます。また、追加のサービスを必要とせずにログの管理を簡素化し、他の複雑なソリューションと比較して費用対効果を高めることができます。
不正解の説明:
オプション: Compute Engine インスタンスで Google Cloud のオペレーション スイートの Cloud Logging エージェントを利用して、システム アクセスログを ASIA-EAST1 リージョンの専用ログバケットにエクスポートし、15 年間のカスタム保持ポリシーを設定します。
この選択が間違っている理由は、Google Cloud のオペレーション スイート内の Cloud Logging エージェントが、通常、ログの長期保存ではなく、リアルタイムのモニタリング、ログ記録、診断に使用されるためです。さらに、ログを Cloud Storage にエクスポートしてカスタム保持ポリシーを設定することは可能ですが、このアプローチはより複雑であり、長期保存の最も経済的に実行可能なソリューションではない可能性があります。
オプション: Pub/Sub トピックを使用して、ASIA-EAST1 リージョンに配置された Cloud Storage バケットにシステム アクセスログをリレーします。
この選択が間違っている理由は、Pub/Sub を使用すると、Pub/Sub なしで実行できるタスクに不必要な複雑さと追加コストが発生する可能性があるためです。Pub/Sub は、単純なログ ストレージではなく、リアルタイムのメッセージ キューイングとストリーム処理に最適です。これでは、経営の簡素化や経済性の確保という要件を満たしていません。
オプション: ASIA-EAST1 リージョンに基づく Google Cloud のオペレーション スイート ログバケットに 15 年のカスタム保持期間を設定します。
この選択が間違っている理由は、Google Cloud のオペレーション スイートのログバケットの使用を前提としているためです。カスタム保持期間を設定できますが、オペレーション スイート ログ バケットの使用は、特に単純なストレージ オプションと比較すると、ログを 15 年間保存するための最も費用対効果の高いソリューションではない可能性があります。
参考：
https://cloud.google.com/storage/docs/creating-buckets
https://cloud.google.com/storage/docs/locations
https://cloud.google.com/compute/docs/instances/create-start-instance
</div></details>

### Q.  問題11: 未回答
医療機関は、エンタープライズ レベルでの過剰な権限を懸念しており、昇格されたアクセス権を持つユーザーの数を減らしたいと考えています。
セキュリティを強化するために、組織が最小限に抑えるべき 2 つのポジションはどれですか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud のコンテキストにおけるロールベースのアクセスの理解度を評価し、特に組織のセキュリティを強化するために過剰な権限を一元的に最小限に抑えることに焦点を当てています。正解は、最小化すると、広範なアクセスが大幅に減少し、セキュリティが強化される役割を特定します。
重要な用語:
最小特権の原則: 意図した機能を実行するために不可欠な特権のみをユーザーアカウントに与えることを推奨するセキュリティ概念。
IAM ロール: ユーザー、グループ、またはサービス アカウントに割り当てることができる Google Cloud リソースに対して特定のアクションを実行するための一連の権限を定義します。
組織ポリシー: Google Cloud リソースのデプロイと使用をガイドする組織全体のガバナンス ルールの構成。
請求先アカウント: Google Cloud プロジェクトにリンクされたアカウントで、そのプロジェクトで使用されるリソースと Google Cloud サービスの料金を支払うユーザーを定義します。
正解解説:
(オプション)
・組織ポリシー管理者
・請求先アカウント管理者
"組織ポリシー管理者" ロールを持つユーザーを減らすと、組織内のすべてのリソースに影響を与えるポリシーを設定できる個人の数が制限されるため、セキュリティが強化されます。「課金アカウント管理者」を最小限に抑えることで、課金構成を管理できる個人の数が減り、リソースの可用性とセキュリティ体制に間接的に影響を与える可能性のある課金に対する不正または偶発的な変更を防ぐことができます。
不正解の説明:
オプション:ネットワーク管理者
「ネットワーク管理者」が間違った選択である理由は、この役割がネットワーク リソースを厳密に管理するため、質問の中心である組織レベルまたは請求レベルでの広範な管理者権限が与えられないためです。
オプション: Healthcare API Admin (Healthcare API 管理者)
「Healthcare API Admin」が正しくない理由は、このロールが Healthcare API の管理に固有であり、エンタープライズ レベル全体で昇格されたアクセス権を提供しないためです。
オプション: 組織ビューア
このロールは組織内のリソースへの読み取り専用アクセス権を付与するため、「組織閲覧者」の選択は正しくありません。ポリシーやアクセス許可の変更は許可されないため、この役割を減らしても、意味のある方法でセキュリティが強化されることはありません。
参考：
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/resource-manager/docs/access-control-org
https://cloud.google.com/resource-manager/docs/quickstart-organizations
</div></details>

### Q.  問題14: 未回答
組織の Cloud Bigtable インスタンスにパブリック インターネットからアクセスできないようにする必要があります。これをすべての Cloud Bigtable インスタンスに適用する場合。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud Platform(GCP)内に適切なアクセス制御と組織ポリシーを実装することで、公共のインターネットからのアクセスを防ぐために Cloud Bigtable インスタンスを保護することについて学習者が理解しているかどうかをテストします。
重要な用語:
所有者の役割: GCP リソースの所有者の役割は、リソースに対する管理制御やアクセス ポリシーを設定する機能など、さまざまな権限を付与します。
ドメイン制限付き共有: GCP の Resource Manager 内のこのポリシー設定により、信頼された組織ドメイン外の ID とリソースが共有されるのを防ぎます。
組織ポリシー: 組織ポリシーは、GCP 組織の GCP リソースを一元的に制御するための制限の構成です。
正解解説:
(オプション)
・エンドユーザーからオーナーロールを削除し、組織ポリシーでドメイン制限付き共有を強制する。
この選択により、アクセス許可を制限し、ドメイン レベルの制約を適用することが、不正アクセスを防ぐための鍵となることが正しく識別されます。所有者ロールを削除すると、ユーザーは Cloud Bigtable インスタンスを公開する可能性のあるアクセス制御を変更できなくなります。組織のポリシーを使用してドメイン制限付き共有を実装すると、組織内のユーザーによるリソースへのアクセスが制限され、Cloud Bigtable などのリソースへのパブリック インターネット アクセスが効果的にブロックされます。
不正解の説明:
オプション: エンドユーザーから所有者ロールを削除し、Bigtable の Cloud Data Loss Prevention を設定します。
この選択が間違っている理由は、所有者ロールを削除するとユーザー権限が制限されるのに対し、Bigtable に Cloud Data Loss Prevention(DLP)を設定してもパブリック インターネットからのアクセスは妨げられないためです。DLP は、主に機密データの検出とマスキングに重点を置いています。
オプション: 統一されたインスタンス レベルのアクセスを有効にし、組織のポリシーでドメイン制限付き共有を適用します。
統一されたインスタンスレベルのアクセスを有効にしても、パブリックインターネットからのアクセスが本質的に妨げられるわけではなく、権限管理が簡素化され、より安全に使用できるため、このオプションは正しくありません。ただし、これだけでは、Bigtable インスタンスが一般公開されていないことを保証するものではありません。
オプション: すべてのロールから *.setIamPolicy アクセス許可を削除し、組織のポリシーでドメイン制限付き共有を適用します。
この選択が間違っている理由は、*.setIamPolicy アクセス許可を削除するとアクセス制御の変更が妨げられますが、ドメイン制限ポリシーは適用されないためです。これにより、既存のポリシーが適切に保護されていない場合、インスタンスが引き続き公開される可能性があります。
参考：
https://cloud.google.com/storage/docs/using-bucket-policies
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題15: 未回答
顧客の機密財務データが、夜間の ETL オペレーションの一環として、地域のデータセンターから Cloud Spanner データベースに転送されていることを確認しました。顧客の詳細をマスキングするには、この情報を匿名化する必要がありますが、財務諸表のマスキングを元に戻す機能が必要です。
この要件に最も適したコンポーネントはどれですか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 環境内の機密データの保護に関する受験者の知識、特にレポート作成のための可逆性を維持しながらデータの匿名化について調べます。ETL操作中に機密情報へのアクセスを暗号化して管理するための適切なコンポーネントを選択することに重点が置かれています。
重要な用語:
確定的暗号化: 特定のデータに対して毎回同じ暗号化されたテキストを生成する暗号化の形式。暗号化されたデータを異なるシステム間で一致させる必要があるシナリオで特に役立ちます。
AES-SIV:暗号化を確定的に行うことができる認証済み暗号化モードであり、同じキーで暗号化された同じ平文は常に同じ暗号文を生成します。
データの匿名化:個人と保存されたデータをつなぐ識別子を消去または暗号化することにより、個人情報や機密情報を保護するプロセス。
正解解説:
(オプション)
・クラウドキー管理サービス
・AES-SIVによる確定的暗号化によるクラウドデータ損失防止
Cloud Key Management Service(KMS)と Cloud Data Loss Prevention(DLP)を AES-SIV を使用した確定的な暗号化と組み合わせることで、機密データの可逆的な匿名化に最適です。Cloud KMS では、データへのアクセスを制御する暗号鍵を管理し、安全な暗号化と復号のオペレーションを可能にします。AES-SIV決定論的暗号化でDLPを使用すると、データが暗号化されると、同じ一意の暗号文と一貫して照合できるため、財務報告の有用性を失うことなく、特定のデータを可逆的にマスクできます。
不正解の説明:
オプション:シークレットマネージャー
Secret Managerが正しくない理由は、ETLパイプライン内でデータの匿名化と暗号化のメカニズムを提供するのではなく、APIキーやパスワードなどのシークレットへのアクセスを保存および管理するために設計されているためです。
オプション: Cloud Data Loss Prevention と暗号化ハッシュ
暗号化ハッシュを使用した Cloud Data Loss Prevention が正しくない理由は、ハッシュが一方向の操作であり、後続の処理やレポート作成のためにデータを元に戻す必要があるシナリオには適していないためです。
オプション:自動テキスト秘匿化機能を備えたCloud Data Loss Prevention
自動テキスト墨消し機能による Cloud Data Loss Prevention が正しくない理由は、墨消しによってデータが完全に削除され、財務報告のために元のコンテンツを再構築できなくなるためです。
参考：
https://cloud.google.com/kms
https://cloud.google.com/dlp/docs/concepts-deidentification#de-identification_in_the_dlp_api
</div></details>

### Q.  問題16: 未回答
医療データのコンプライアンス チームは、機密性の高い患者の健康情報 (PHI) を削除するために、暗号シュレッダーの方法を採用しました。このプロセスを Google Cloud 内に実装しながら、ほとんどのクラウド サービスを活用し、管理の負担を最小限に抑えることが課題です。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、Google Cloud で機密データを安全に削除するための適切なアプローチ、特に健康データ規制への準拠を確保し、運用上のオーバーヘッドを最小限に抑えながら、最も効率的なデータ破壊方法に対処することに焦点を当てています。
重要な用語:
クリプトシュレッダー:暗号化キーが破棄されて関連データが読み取れないようにし、実際のデータファイルを削除せずにデータを効果的に「シュレッダー」するセキュリティプラクティス。
Cloud Key Management Service (KMS): 暗号化キーを管理するクラウドサービスで、暗号化操作の一元管理とキーの安全な削除を可能にします。
正解解説:
(オプション)
・Cloud Key Management Service(KMS)を使用して、特定の鍵バージョンを破棄します。
この選択は、Google Cloud の鍵管理サービス(KMS)を利用して暗号鍵を処理するため、最も適切です。KMS で特定のキーバージョンを破棄すると、そのキーで暗号化されたデータは復元できなくなります。このプロセスにより、KMS では削除を含むキーの集中管理が可能になり、キー管理をマネージド サービスにアウトソーシングするため、暗号化シュレッダ処理方法が役立ちます。
不正解の説明:
オプション: データを Google Cloud にアップロードする前にクライアントサイド暗号化を実装し、独自のデータセンターで鍵の削除を管理します。
この選択が間違っている理由は、暗号化と鍵の削除をオンプレミスで管理するには大量のリソースが必要であり、Google Cloud のスケーラビリティとマネージド サービスを利用していないため、質問の仕様に反して運用上の負担が増加するためです。
オプション: 顧客管理の暗号鍵(CMEK)を使用して独自の暗号鍵を作成および管理し、必要に応じて破棄します。
このアプローチに欠陥がある理由は、Google Cloud 内で顧客管理の暗号鍵(CMEK)を使用することはできますが、安全な破棄を含む鍵の管理ライフサイクル全体では、管理の負担を最小限に抑えるという望ましい目標を超えてチームのオーバーヘッドが増加するためです。
オプション: Google の自動暗号化を利用して、暗号鍵を選択的に消去します。
この選択が間違っている理由は、Googleの自動暗号化には鍵を選択的に消滅させる機能がないためです。Google は暗号化と復号化を透過的に管理し、ユーザーは暗号シュレッダーを実行するための鍵を直接制御できません。
参考：
https://cloud.google.com/kms/docs/external-key-managers
https://cloud.google.com/kms/docs/crypto-shredding
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題19: 未回答
企業は NoSQL データベースのニーズに Cloud Bigtable を活用しています。Cloud Bigtable で使用される SSD の対称暗号鍵を作成、循環、分解する方法が必要です。キーはクラウドに保存できる必要があります。
どのような対策を講じるべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Cloud Bigtable SSD を保護するための暗号鍵の管理に関する受験者の知識をテストします。クラウド環境で保存および使用される暗号化キーを作成および管理するための適切なサービスを理解することに重点を置いています。
重要な用語:
対称暗号化: データの暗号化と復号化に同じキーを使用する暗号化の一種。これは、保存データを暗号化する際のパフォーマンスに不可欠です。
データ暗号化キー (DEK): データを直接暗号化するために使用されるキーで、多くの場合、セキュリティレイヤーの追加とキー管理の利便性のために別のキー (KEK) で暗号化されます。
キー暗号化キー (KEK): キー管理プロセスのセキュリティを強化するために、他のキー (DEK など) を暗号化またはラップするために使用されるキー。
Cloud Key Management Service(KMS):クラウドサービスの暗号鍵を安全かつコンプライアンスに準拠した方法で管理できるクラウドベースのサービス。
正解解説:
(オプション)
・Cloud Key Management Serviceを使用して、データ暗号鍵(DEK)を作成および制御します。
Cloud Key Management Service(KMS)は、クラウドで暗号鍵を作成、使用、管理するための専用サービスであるため、この選択は適切です。Cloud KMS を利用すると、Cloud Bigtable 内の SSD の暗号化に使用できるデータ暗号鍵(DEK)を生成および制御し、クラウドに鍵を安全に保存するという要件を満たすことができます。
不正解の説明:
オプション: Cloud Key Management Service を使用して、鍵暗号鍵 (KEK) を作成および制御します。
これが間違っている理由は、鍵暗号鍵(KEK)を具体的に管理しても、Cloud Bigtable で使用される SSD 上のデータの暗号化をどのように処理するかという質問に直接答えられないためです。KEK は通常、データ自体ではなく、DEK を暗号化するために使用されます。
オプション: 顧客管理の暗号化キーを使用して、データ暗号化キー (DEK) を管理します。
これが正しくない理由は、顧客管理の暗号化キーは、顧客が DEK の生成と保存に責任を持つことを意味するためです。これは、鍵がクラウドに保存可能である必要があるという要件と矛盾しており、Cloud KMS などのサービスによって実現されています。
オプション: キー暗号化キー (KEK) の監視に顧客管理の暗号化キーを使用します。
これが正しくない理由は、2番目の選択肢と似ています。KEK 監視用の顧客管理の暗号化キーは、キーの生成と保存に顧客が直接関与することを意味します。これにより、Cloud KMS などのクラウドベースの鍵管理サービスが提供する効率性とセキュリティが失われます。
参考：
https://cloud.google.com/security-key-management
https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/security
https://cloud.google.com/kms/docs/creating-keys
</div></details>

### Q.  問題20: 未回答
HIPAA規制に準拠するために、ある医療機関は、データ送信のすべてのインスタンスが検証されていることを確認したいと考えています。
追加の緩和措置を必要とせずにこの規定を満たしている 2 つの Google Cloud サービスはどれですか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の HIPAA 準拠サービス(特にデータ送信の検証)の理解度を評価します。学習者は、追加の保護手段なしで HIPAA に沿ったエグレス制御を本質的に提供するサービスを特定する必要があります。
重要な用語:
HIPAAコンプライアンス:機密性の高い患者の健康情報が患者の同意や知識なしに開示されないように保護するために確立された一連の基準を指します。
データ送信(外向き):通常、内部ストレージから外部宛先に転送する場合に、ネットワークから外部へのデータフロー。
エグレス制御: ネットワーク境界から出る情報の流れを監視し、場合によっては制限するために実装されたセキュリティ対策。
正解解説:
(オプション)
・コンピュートエンジン
Google Kubernetes エンジン
Compute Engine と Google Kubernetes Engine(GKE)は、追加の下り(外向き)制御を必要とせずに HIPAA 準拠のワークロードをサポートできる方法でデータ(外向き)を処理できるように設計されています。GKE は、Compute Engine 上に構築されたコンテナ オーケストレーションのマネージド サービスとして、データ送信を含む組み込みのセキュリティとコンプライアンス機能を継承しており、HIPAA 要件を満たすのに役立ちます。どちらのサービスも堅牢なネットワークセキュリティ機能を提供し、組織がファイアウォールを構成してプライベートIPを使用できるようにし、不正なデータアクセスと転送を防ぐのに役立ちます。
不正解の説明:
オプション: App Engine
App Engine が正しくない理由は、App Engine が Platform-as-a-Service サービスであり、基盤となるネットワークとセキュリティの構成がユーザーから抽象化されているため、HIPAA コンプライアンスのための追加の対策が必要になる可能性があるためです。
オプション: Cloud Functions
Cloud Functions が正しくない理由は、Cloud Functions がサーバーレス実行環境であり、ユーザーがネットワークの下り(外向き)を制御できる範囲が限られているため、HIPAA の厳格な下り(外向き)制御要件に準拠するために追加の手順が必要になる可能性があるためです。
オプション:クラウドストレージ
Cloud Storage が正しくない理由は、このサービスがデータ ストレージに重点を置いており、きめ細かなアクセス制御を提供する一方で、追加のセキュリティ層なしで HIPAA 規制に準拠する必要があるデータ送信を本質的に検証しないためです。
参考：
Hatpas://cloud.google.com/comput/DOC/vpc
https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview
https://www.pcisecuritystandards.org/documents/PCI_DSS_v3-2-1.pdf
</div></details>

### Q.  問題24: 未回答
ネットワーク エンジニアが Cloud Load Balancer で不正アクセスの試みを観察しました。エンジニアは、ネットワークリソースの構成またはメタデータにアクセスするAPI呼び出しを分析することを目的としています。
エンジニアが検査するのに最も役立つ Google Cloud ログはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud のログ機能、特に不正アクセスの試みを記録するログの種類や、ネットワーク構成の変更やメタデータへのアクセスを行う API 呼び出しに関する理解度を評価します。
重要な用語:
データアクセスログ: データの作成、変更、アクセスを記録した Google Cloud 内の詳細な監査ログ。フォレンジックやコンプライアンスの目的、特に不正アクセスの調査に役立ちます。
API 呼び出し: Google Cloud サービス内のリソースへのアクセス、変更、管理などのオペレーションを実行する API エンドポイントに対して行われたリクエスト。
正解解説:
(オプション)
・データアクセスログ
データアクセスログは、Google Cloud が提供する詳細なログで、API 呼び出しとユーザーデータへのアクセスを追跡します。不正アクセスを監視するネットワークエンジニアにとって、これらのログにはネットワーク構成とメタデータアクセスに対する読み取りおよび書き込み操作の記録が含まれているため、役立ちます。データアクセスログを分析することで、エンジニアはどのAPIコールがアクセスまたは構成を変更したかを確認できるため、不正アクセスパターンと潜在的なセキュリティ侵害に関する洞察が得られます。
不正解の説明:
オプション: 管理アクティビティ ログ
このシナリオで管理アクティビティ ログが最も役に立たない理由は、主にクラウド上のリソースの構成またはメタデータを変更する操作を追跡するためです。ただし、不正なデータアクセスの調査に必要な詳細なデータアクセス記録は提供されません。
オプション: システム・イベント・ログ
システム イベント ログが最適な選択ではない理由は、データやメタデータにアクセスまたは変更する特定の API 呼び出しではなく、リソースの状態、可用性、または構成に影響を与えるシステム生成イベントに焦点を当てているためです。
オプション: アクセスの透明性ログ
この場合、アクセスの透明性に関するログが不適切なのは、Google の担当者がユーザーのコンテンツにアクセスするたびにログが提供されるように設計されているためで、ユーザーが不正な外部アクセスを試みたり、API 呼び出しを調査したりしないようにするためです。
参考：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/auditing
https://cloud.google.com/sql/docs/mysql/admin-api/logging
</div></details>

### Q.  問題29: 未回答
あなたは、Google Cloud 内の患者データを完全に暗号化し、移動中のデータ、処理中のデータ、保存されているデータをカバーする必要がある医療機関にアドバイスしています。
これらの要件を満たすには、どのようなソリューションを実装する必要がありますか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、保存中、転送中、処理中の暗号化によって医療患者データを保護するための適切な Google Cloud ソリューションを特定するためのものです。適切なソリューションは、医療に固有の厳格なコンプライアンスおよびデータ保護基準に準拠している必要があります。
重要な用語:
コンフィデンシャル VM: メモリ暗号化を使用して使用中のデータを暗号化し、ハイパーバイザー レベルでの特権アクセスからも処理中のデータを確実に保護する仮想マシン。
Anthos Service Mesh: 移動中のデータをエンドツーエンドで暗号化し、クラウドネイティブ アプリケーション内のサービス間の通信を保護するサービス管理レイヤです。
アプリケーション層の暗号化:保存または送信する前にアプリケーション内のデータを暗号化するプロセスで、開発者はデータのセキュリティとコンプライアンスをきめ細かく制御できます。
正解解説:
(オプション)
・コンフィデンシャル VM と Anthos Service Mesh
・アプリケーション層の暗号化
コンフィデンシャル VM は、機密性の高い医療データを安全に処理するために不可欠な仮想マシンのメモリを暗号化することで、使用中のデータを暗号化します。Anthos Service Mesh は、サービス間のトラフィックを管理、監視、保護することで、移動中のデータを保護します。アプリケーション層の暗号化により、開発者は、データを保存または通信する前に、実行中のアプリケーション内で特にデータを暗号化し、保存データと転送データの両方に追加の保護レイヤーを提供できます。
不正解の説明:
オプション:クラウドキー管理サービス
Cloud Key Management Service は、クラウドでホストされる鍵管理サービスであり、サービスの暗号鍵の管理に役立ちますが、移動中または使用中のデータの暗号化は本質的に含まれていません。
オプション: 顧客管理の暗号化キー
顧客管理の暗号化キーは、保存データの暗号化キーをより詳細に制御できますが、アプリケーションのコンテキスト内で使用中のデータまたは移動中のデータの暗号化には対応していません。
オプション:Titanセキュリティキー
Titan セキュリティ キーは、2 要素認証に使用されるハードウェア セキュリティ キーであり、クラウド サービス内のストレージ、処理、または転送中のデータの暗号化は含まれません。
参考：
https://cloud.google.com/security/confidential-computing
https://cloud.google.com/istio/docs/istio-on-gke/overview
https://cloud.google.com/kms/docs/encryption-at-rest-concepts
</div></details>

### Q.  問題30: 未回答
製造会社がワークロード サーバーを Google Cloud に移行することを計画しています。これらのサーバーのマシンイメージが、すべての部門のセキュリティポリシーと一貫性を保つようにする必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ワークロードを Google Cloud に移行する際のセキュリティ コンプライアンスを維持するという課題に対処します。マシンイメージの一貫性を維持するために、組織レベルでセキュリティ ポリシーを適用するための Google Cloud のメカニズムを理解する必要があります。
重要な用語:
組織ポリシー: 組織のクラウド リソースを一元的に制御し、セキュリティ構成などの特定の要件が均一に適用されるようにする一連の制約。
マシンイメージ: 仮想マシンのディスクとメタデータ定義の完全なスナップショットで、一貫性のある状態でVMをレプリケートするために必要なすべての情報をカプセル化します。
起動ディスク: 仮想マシンのオペレーティング システムと起動スクリプトを含むプライマリ ディスク。ブート ディスクの作成を制御することで、セキュリティ コンプライアンスを強化できます。
正解解説:
(オプション)
・起動ディスクの作成を、認可されたマシンイメージプロジェクトから作成されたイメージのみに制限する組織ポリシーを実装します。
この選択は、組織全体で一貫性のあるポリシー準拠のマシンイメージを確保するという懸念に直接対処できるため、最適です。ブート ディスクの作成を指定されたプロジェクトのイメージに制限する組織のポリシーを実装することで、企業は承認された構成の使用を強制できます。これにより、すべての部門で、会社のセキュリティ ポリシーに準拠しているイメージのみを使用して新しい VM を作成できるため、標準化されたセキュリティ体制が維持されます。
不正解の説明:
オプション: 承認されたマシン イメージの使用を保証するために、すべての部門に対してシールドされた VM 機能をアクティブ化する会社全体のポリシー制約を適用します。
この選択が正しくない理由は、シールドされた VM が、ルートキットやブート レベルまたはカーネル レベルのマルウェアなど、さまざまな脅威のセットに対する保護を提供するためです。シールドされた VM 機能をアクティブ化しても、ブート ディスクに使用されるマシン イメージのソースは直接制御されません。
オプション: 承認されたマシンイメージコレクションから新しいサーバーインスタンスが開始されたときにトリガーされ、マシンイメージが最新であることを確認するように Cloud Functions の関数を設定します。
この選択が間違っている理由は、仮想マシンの起動時にトリガーするように Cloud Functions の関数を設定するのが事後対応型の手段であるためです。承認済みのマシンイメージの使用は確認されますが、未承認のイメージから仮想マシンインスタンスが起動される前に作成されるのを防ぐことはできません。
オプション: 定期的なスキャン ツールを展開して、承認されたマシン イメージ カタログ内に共通脆弱性識別子 (CVE) がないかどうかを確認します。
この選択が間違っている理由は、マシン イメージ内の CVE のスキャンは、脆弱性を特定するためのセキュリティ プラクティスであり、特定のマシン イメージの使用を強制するものではないためです。これは、ポリシー適用方法ではなく、補完的なセキュリティ対策です。
参考：
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/security-command-center/docs/concepts-security-sources-for-findings
</div></details>

### Q.  問題32: 未回答
組織での Cloud Identity-Aware Proxy(Cloud IAP)の利用が拡大するにつれて、サービスを最適化して費用を削減する必要があります。監査対象のリソースには、Cloud VPN インスタンスと Compute Engine インスタンスを介してアクセスします。リソース名には、接尾辞識別子としてゾーンとリージョンが含まれます。
コストを管理するために、どのような戦略をお勧めしますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Cloud Identity-Aware Proxy(Cloud IAP)の使用を最適化してコストを削減する方法を検討します。ここでは、Cloud VPN と Compute Engine を通じて Cloud IAP を使用する組織に焦点を当てており、リソースには場所ごとに名前が付けられています。
重要な用語:
カスタムアクセスレベル: Cloud IAP で保護されている特定のリソースにアクセスできるユーザーを制御するために管理者が設定した事前定義された条件によって決定されるアクセス制限。
要求サイズ制限: サービス拒否攻撃やリソースの過剰使用を防ぐために要求のサイズを制限し、全体的なコスト管理に貢献する構成設定。
ネットワーク タグ: Compute Engine VM インスタンスに割り当てられるラベルで、ファイアウォール ルールの適用に使用でき、セキュリティと組織のためにトラフィックをセグメント化するのに役立ちます。
正解解説:
(オプション)
・カスタムアクセスレベルとリクエストサイズ制限を採用してトラフィックをフィルタリングし、Compute Engine のネットワークタグを使用して監査範囲を制限します。
この選択は、リソースへのアクセスに特定のフィルタを適用することで、Cloud IAP の効率的な使用を強調しています。カスタムアクセスレベルを採用することで、アクセスリクエストをより正確にフィルタリングし、リソースの不必要な使用を回避できます。同時に、要求サイズの制限を設定すると、コストが増加する可能性のある過度に大きな要求の処理を防ぐことができます。さらに、Compute Engine のネットワーク タグを使用すると、広範囲のトラフィックを確認するのではなく、範囲を特定のインスタンスに制限することでターゲットを絞った監査が可能になり、オーバーヘッド コストの管理と削減がさらに促進されます。
不正解の説明:
オプション: 海外にある Compute Engine インスタンスに正確なリクエスト サイズ制限を適用し、大陸間 Cloud VPN トンネルに正確なデータ転送制限を定義します。
この選択が間違っている理由は、Compute Engine インスタンスと Cloud VPN の地理的な要因に焦点を当てているためですが、国際的な場所のみに基づいて制限しても、コスト削減に大きく貢献しない可能性があります。包括的なコスト管理戦略が欠けています。
オプション: 海外でホストされている Compute Engine インスタンスに正確なリクエスト サイズ制限を実装し、国際的な Cloud VPN 接続のトラフィック インスペクションを減らします。
この選択が間違っている理由は、国際VPN接続のトラフィックインスペクションを減らすことでコストが削減されることを前提としているためですが、これは必ずしも真実ではありません。また、海外でホストされているインスタンスにサイズ制限を設定しても、Cloud IAP のコスト最適化には直接対応できません。
オプション:AccessControlConfig と TrafficManagementConfig を活用してトラフィックをサンプリングし、インスペクション レベルを下げます。
この選択が正しくない理由は、指定された構成 AccessControlConfig と TrafficManagementConfig が Cloud IAP 内に存在しないためです。このアプローチでは、コスト削減やクラウド IAP を最適化するための具体的な戦略に直接つながらないサンプリング方法を提案しています。
参考：
https://cloud.google.com/dlp/docs/concepts-limits
https://cloud.google.com/dlp/docs/inspecting-storage
https://cloud.google.com/dlp/docs/samples/dlp-inspect-file-regexp-sample
</div></details>

### Q.  問題34: 未回答
マルチメディア会社は、業界固有の法的要件を遵守する必要があります。そのため、顧客管理の暗号鍵(CMEK)が、media-org45 というラベルの付いた組織内のすべての新しい Cloud Spanner データベースに適用されるようにする必要があります。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud で組織のポリシーを適用して、暗号化に関する法的要件に準拠していることを確認する能力をテストします。具体的には、指定された組織ラベル内の Cloud Spanner データベースの CMEK 使用の構成に関する知識を評価します。
重要な用語:
組織ポリシー: Google Cloud リソース階層でのリソースの動作に関する制限を定義するポリシー リソース。これは、クラウドのガバナンスとコンプライアンスの基本です。
顧客管理の暗号鍵(CMEK): お客様が作成、所有、管理する暗号鍵で、Google Cloud に保存されているデータの暗号化と復号を顧客が制御できるようにします。
制約: 会社のガイドラインまたはコンプライアンス要件に準拠するために、組織のポリシー内で制限または制御できるリソースの特定の側面または動作。
ポリシー・バインディング: ポリシーをプロジェクト、フォルダ、組織などの特定のリソースに関連付けて、該当する場合は定義された制限を適用します。
拒否ポリシー: ポリシーのスコープ内で許可されないサービスまたはアクションのリストを管理者が指定できる組織ポリシーの一種。
リソースラベル: Google Cloud リソースを組織構造を反映したグループに整理し、管理とフィルタリングを容易にするために使用されるキーと値のペア。
正解解説:
(オプション)
・- 組織ポリシー: constraints/GoogleCloud.restrictNonCmekServices
- バインディング: media-org45
- ポリシーの種類: 拒否
- ポリシー値: spanner.googleapis.com
この選択では、「constraints/GoogleCloud.restrictNonCmekServices」という制約を持つ組織ポリシーを正しく利用して、指定したサービスを拒否し、CMEK の使用を強制します。このポリシーを組織ラベル「media-org45」にバインドすることで、その特定の組織内のすべての新しい Cloud Spanner データベースが CMEK を使用するための業界固有の法的要件に準拠し、タスク要件を満たすようになります。
不正解の説明:
オプション: - 組織ポリシー: constraints/GoogleCloud.restrictDatabaseNonCmekServices
- バインディング: media-org45
- ポリシーの種類: 許可
- ポリシー値: サポートされているすべてのサービス
この選択が正しくない理由は、CMEK の使用を強制するタスクと一致しない「許可」ポリシータイプが指定されているためです。さらに、「サポートされているすべてのサービス」では、ポリシーが Cloud Spanner 以外のサービスも含まれるため、暗号化要件の意図した特異性は確保されません。
オプション: - 組織ポリシー: constraints/GoogleCloud.restrictDatabaseNonCmekServices
- バインディング: media-org45
- ポリシーの種類: 拒否
- ポリシー値: spanner.googleapis.com
この選択により、組織のポリシーが「constraints/GoogleCloud.restrictDatabaseNonCmekServices」と誤って指定されていますが、これは Cloud Spanner データベースに CMEK を適用するために必要な正しいポリシー制約と一致していません。「拒否」ポリシーの種類が正しく記述されているにもかかわらず、この制約はデータベース全般に不正確に調整されています。
オプション: - 組織ポリシー: constraints/GoogleCloud.restrictNonCmekServices
- バインディング: media-org45
- ポリシーの種類: 許可
- ポリシー値: spanner.googleapis.com
これが間違っている理由は、正しい制約「constraints/GoogleCloud.restrictNonCmekServices」を持つ「allow」ポリシータイプを提案しているため、CMEK 以外のサービスを拒否するのではなく許可する役割を担い、Cloud Spanner データベースに CMEK を義務付けるという目的に反しているためです。
参考：
https://cloud.google.com/storage/docs/encryption/using-customer-managed-keys
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/sdk/gcloud/reference/alpha/resource-manager/org-policies/allow-policy-constraints
</div></details>

### Q.  問題35: 未回答
あなたは医療機関のIT部門に所属しています。組織には、患者記録管理システム、社内コミュニケーション ツール、ビッグデータ分析プラットフォームを含む多目的 Google Cloud プロジェクトがあります。お客様は、HIPAAコンプライアンス監査の対象となるシステムの範囲を最小限に抑える任務を負っています。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、Google Cloud 環境内で HIPAA 準拠のデータを管理するためのベスト プラクティスを中心にしています。また、機密性の高い患者データを他のワークロードと一緒に保持している医療従事者に対して監査が必要なシステムの範囲を最小限に抑えるための戦略を探ります。
重要な用語:
HIPAA コンプライアンス: 医療保険の相互運用性と説明責任に関する法律 (HIPAA) によって課される規制基準で、機密性の高い患者データ保護の基準が定められています。
PHI データ環境: 個人健康情報 (PHI) を保存、処理、または処理する特殊なコンピューティング環境であり、厳格なセキュリティとコンプライアンス制御が必要です。
Google Cloud プロジェクトの分離: 個別の Google Cloud プロジェクトを使用してリソースを分離し、アクセスを制御する方法。これにより、コンプライアンスとセキュリティの取り組みの複雑さと範囲を軽減できます。
正解解説:
(オプション)
・患者の健康情報(PHI)データ環境を個別の Google Cloud プロジェクトに移行する。
PHI データ環境を個別の Google Cloud プロジェクトに分離することで明確な境界が作成され、必要な場合にのみ HIPAA コントロールを正確に適用できるため、この選択は適切です。これにより、コンプライアンス監査の対象となるシステムの数を最小限に抑え、PHIを直接扱う環境に重点を置きます。プロジェクトを分離することで、コンプライアンスとセキュリティ管理が簡素化され、効率的なリソース割り当てが可能になり、PHI以外のリソースに対するコンプライアンス違反のリスクが軽減されます。
不正解の説明:
オプション:医師が社内コミュニケーションツールにアクセスするための生体認証を実装します。
これが間違っている理由は、生体認証は強力なセキュリティ対策ですが、コンプライアンス監査の範囲に影響を与えないためです。コンプライアンス範囲の最小化は、単にユーザー認証方法を強化するだけでなく、アーキテクチャとデータの分離によって実現されます。
オプション: 医療 IT 標準に準拠していることが認定されたソフトウェアのみが展開されていることを確認します。
これが間違っている理由は、Health IT Standards認定ソフトウェアを使用しても、必ずしも監査範囲が最小化されるとは限らないためです。ソフトウェアは準拠している可能性がありますが、PHI以外のシステムから分離されていない場合、環境全体がコンプライアンス監査の対象となる可能性があります。
オプション: 本社から Google Cloud 環境へのすべてのトラフィックに対して、IPSec を使用して暗号化されたトンネルを確立します。
これが正しくない理由は、暗号化されたトンネルの確立がデータ転送のセキュリティに関係しているためです。これにより、転送中のデータ保護が強化されますが、クラウド環境内のHIPAAコンプライアンス監査の対象となるシステムの範囲には影響しません。
参考：
https://cloud.google.com/resource-manager/docs/creating-managing-projects
https://cloud.google.com/compliance/offerings#card_payment
https://cloud.google.com/solutions/pci-dss-compliance-in-Google クラウド
</div></details>

### Q.  問題38: 未回答
財務報告システムをクラウドに移行しています。システムでは、Google Cloud Storage バケットからレコードを取得する必要があります。財務ガバナンス標準により、暗号化キー マテリアルに対する排他的な制御を維持する必要があり、キー マテリアルへのアクセスには正当な理由が必要です。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、高度なクラウド セキュリティ プラクティス、特に Google Cloud サービスを使用して機密データを保存する際の暗号鍵の管理と厳格な財務ガバナンス基準への準拠に関する理解度を調べます。
重要な用語:
External Key Manager(EKM): Google Cloud サービスで保存されているデータに Google のインフラストラクチャの外部で管理されている暗号鍵を使用できるセキュリティ機能で、鍵管理プロセスの制御を強化します。
ハードウェア・セキュリティ・モジュール(HSM):強力な認証のためにデジタル・キーを保護・管理し、オンプレミスとクラウドの両方で動作できる暗号化処理を提供する物理コンピューティング・デバイス。
Key Access Justifications(KAJ): Google Cloud の External Key Manager の機能で、鍵を使用するすべてのアクセス リクエストに明示的な正当性を要求し、詳細なアクセス追跡と鍵の使用状況の制御を強化します。
顧客提供の暗号鍵(CSEK): Google Cloud の暗号化モデルで、お客様が独自の暗号鍵を提供し、マネージド サービス内ではなく、独自の鍵を直接管理、制御します。
正解解説:
(オプション)
・社内のセキュリティインフラ内でキーを生成し、オンプレミスのハードウェアセキュリティモジュール(HSM)内に保持する。Cloud Key Management Service(KMS)でこの鍵を外部鍵として使用し、不適切なアクセス試行を禁止するように構成された外部鍵システムで Key Access Justifications(KAJ)を有効にします。
この選択により、制御された内部環境内で暗号化キーを作成し、それをオンプレミスのハードウェア セキュリティ モジュール (HSM) で使用することで、ガバナンス標準への準拠が保証されます。Cloud KMS の外部鍵機能を活用し、鍵アクセスの正当性(KAJ)を有効にすることで、Google Cloud Storage での記録の機密性を維持しながら、暗号鍵の排他的な制御と鍵アクセスの正当な理由のニーズを満たし、詳細なアクセスの追跡と制御を保証します。
不正解の説明:
オプション: 顧客提供の暗号鍵(CSEK)を使用して Cloud Storage バケット内のレコードを暗号化し、特定のユーザー グループへのアクセスを拒否する IAM ポリシーを設定します。
この選択が間違っている理由は、顧客提供の暗号化キー(CSEK)は暗号化キーの制御を提供しますが、特定のコンプライアンスニーズであるキーアクセスに関する正当な理由に必要な外部キー管理システムの統合が不足しているためです。
オプション: Cloud Storage バケットに事前にアップロードされるレコードを暗号化するための暗号鍵を社内で作成します。鍵を Cloud Key Management Service(KMS)に転送し、鍵アクセスの理由(KAJ)をオンにして、不正なアクセス要求を禁止するように外部鍵システムを設定します。
この選択が間違っている理由は、社内で暗号鍵を作成して Cloud KMS に転送することについて言及しているため、鍵の排他制御を維持するための要件を満たしていないためです。さらに、ガバナンス基準によりオフサイトで独占的に管理する必要がある重要なマテリアルに Cloud KMS を使用することを誤って提案しています。
オプション: 指定されたクラウド ハードウェア セキュリティ モジュール(HSM)でサポートされている顧客提供の暗号鍵(CSEK)を使用して Cloud Storage バケット内のレコードを暗号化し、データ アクセスの監査ログをオンにします。
この選択が間違っている理由は、顧客提供の暗号鍵 (CSEK) とアクセスの監査を使用しているが、暗号鍵マテリアルの排他的制御を維持し、KAJ を有効にした外部鍵管理システムを使用するというガバナンス要件を満たしていないためです。
参考：
https://cloud.google.com/kms/docs/using-external-keys
https://cloud.google.com/storage/docs/encryption/using-customer-supplied-keys
https://cloud.google.com/kms/docs/key-access-justifications
</div></details>

### Q.  問題40: 未回答
あなたは会社のインフラストラクチャ チームの一員です。QA の目的で GKE にデプロイされている内部 API は、入力をサニタイズすることなく、クライアントから提供されたデータを動的に JSON レスポンスに補間することを確認しました。これにより、攻撃者は反射型 JSON インジェクション攻撃を実行し、運用環境のデプロイでコンテンツ操作につながる可能性があります。
このセキュリティの問題を軽減および修正するには、どのような対策を講じる必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Kubernetes Engine(GKE)にデプロイされた内部 API の JSON インジェクションに関連するセキュリティの脆弱性を調査します。これは、攻撃者が運用環境のデプロイでサニタイズされていないユーザー入力を通じてコンテンツを操作するリスクを軽減するための効果的なソリューションを求めています。
重要な用語:
反射型JSONインジェクション:サニタイズされていないユーザー入力をJSONレスポンスに補間し、攻撃者がAPIレスポンスを操作したり、クライアントブラウザで悪意のあるスクリプトを実行したりできる可能性のある攻撃手法。
Web Security Scanner: Google Cloud でホストされているウェブ アプリケーションのセキュリティ脆弱性を自動的にスキャンして検出するツールで、Google Cloud Security Command Center の一部です。
JSONシリアル化ライブラリ:オブジェクトをJSON形式に変換するソフトウェアコンポーネントで、一部のライブラリは、コンテンツをサニタイズしてインジェクション攻撃を防ぐためのデフォルトの出力エンコーディングを提供します。
正解解説:
(オプション)
・QA環境でWeb Security Scannerを使用してJSONインジェクション攻撃をシミュレートし、デフォルトで出力エンコードを行うJSONシリアライズライブラリを採用します。
この選択は、Web Security Scannerを使用して、QA環境に存在するJSONインジェクションの脆弱性の種類を検出してシミュレートする必要があるため、実用的です。また、既定で出力をエンコードするシリアル化ライブラリを使用することもお勧めします。この 2 つのアプローチは、シミュレートされた攻撃によって脆弱性を特定するだけでなく、データをエンコードすることで修正し、JSON 応答で悪意のあるコンテンツが操作される可能性を大幅に減らします。
不正解の説明:
オプション: 地理的な場所やユーザー グループのメンバーシップに基づくルールを使用して Cloud IAP を実装し、セキュリティ上の欠陥に対処して解決します。
この選択が間違っている理由は、Cloud IAP(Identity-Aware Proxy)が JSON インジェクションの脆弱性を解決するためではなく、ID に基づいてクラウド アプリケーションへのアクセスを制御するように設計されているためです。地域やユーザー グループに基づくルールでは、悪意のあるコードの挿入を防ぐことはできません。
オプション: SSL プロキシ ロードバランサを構成し、本番環境で Cloud Armor を有効にして、JSON インジェクションの脅威から保護します。
この選択が間違っている理由は、SSL プロキシ ロードバランサと Cloud Armor は外部からの脅威や DDoS 攻撃からの保護に役立ちますが、JSONレスポンスをサニタイズしてインジェクション攻撃を防ぐという内部的な問題(前述の主要な問題)には対処できないためです。
オプション: Web Security Scanner を使用して、アプリケーション スタック内の非推奨の依存関係を確認し、影響を受けるライブラリのパッチが適用されたバージョンにアップグレードします。
この選択が間違っている理由は、非推奨の依存関係を更新することはセキュリティ上の良い方法ですが、API がサニタイズされ、エンコードされた JSON データのみを出力するようにすることで JSON インジェクションを防ぐという差し迫った問題とは無関係であるためです。
参考：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/appengine/docs/standard/python3/using-templates
https://ovasp.org/wu-community/attacks/sss/
</div></details>

### Q.  問題42: 未回答
ビデオゲームサーバーの構成データを管理するコンテキストでは、リードDevOpsエンジニアは、ゲームサービスのライフサイクルのさまざまな段階で使用するために保存されているAPIキーやデータベースパスワードなどの機密情報とのやり取りを追跡する必要があります。
この機密情報に関連してユーザーやサービスが実行したアクションに関する分析情報を提供する 2 種類の Google Cloud ログはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、管理とデータ処理の実践に関連するGCPロギング機能、特にビデオゲームサービスの機密性の高いサーバー構成データに関する理解度を評価します。
重要な用語:
管理アクティビティ監査ログ: リソースの構成またはメタデータを変更する操作を記録するログ。管理アクションの監視とセキュリティ保護に不可欠です。
データアクセス監査ログ: ユーザー提供のデータを作成、変更、または読み取る API 呼び出しを追跡するログ。誰がどのように機密データにアクセスするかを評価するために不可欠です。
システム イベント監査ログ: Google Cloud システム イベントを記録するログで、ユーザーの直接的な操作ではなく、Google サービスによって自動的に生成されます。
Cloud Load Balancing ログ: Google Cloud Load Balancing によって生成されたログで、構成データへのアクセスではなく、アプリケーションに対して行われたリクエストに関する分析情報を提供します。
Compute Engine オペレーション ログ: Compute Engine リソースに対して実行されたオペレーションの詳細を示すログで、インフラストラクチャのアクティビティには関連しますが、機密データ アクセスには直接関連しません。
正解解説:
(オプション)
・管理者アクティビティ監査ログ
・データアクセス監査ログ
管理アクティビティの監査ログとデータアクセスの監査ログは、ユーザーによる機密情報の操作を追跡するために重要です。管理アクティビティは、リソース構成を変更する操作をログに記録し、APIキーとパスワードの変更をキャプチャします。データアクセスログは、読み取りや書き込みなどの機密データへのアクセスパターンをキャプチャし、重要なゲームサービスのライフサイクル設定データへのアクセスを監査するのに役立つ、さらなる粒度を提供します。
不正解の説明:
オプション: システム イベント監査ログ
システムイベント監査ログは、ユーザーの操作ではなくシステムによって生成されたイベントを反映するため、ユーザーによる機密データへのアクセスや変更の追跡には適していません。
オプション: Cloud Load Balancing ログ
Cloud Load Balancing ログは、サービスのバランスを取るためのリクエストベースの指標を取得することを目的としており、機密性の高い構成データの管理に関する詳細な分析情報は提供されないため、この要件には関係ありません。
オプション: Compute Engine オペレーション ログ
Compute Engine オペレーションログはインフラストラクチャの変更を対象としており、API キーやパスワードなどの機密性の高い構成データの特定のアクセスの詳細をカバーしていないため、このコンテキストには適用されません。
参考：
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/iam/docs/audit-logging
https://cloud.google.com/security-command-center/docs/concepts-logging-and-notifications
</div></details>

### Q.  問題44: 未回答
規制を遵守するために、金融企業は、機密性の高い金融取引を処理するPodが「準拠した」ノードでのみスケジュールされることを保証する必要があります。さらに、これらのノードは「準拠した」Podを排他的にホストする必要があります。
このコンプライアンス要件を満たすために、企業はどのような方法を使用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、機密データを扱う金融企業内で、専用ノードで特定のKubernetes Podをスケジュールし、ソフトウェアコンプライアンスとハードウェア使用ポリシーの両方が遵守されていることを確認する知識を評価します。
重要な用語:
Taints and Tolerations: Kubernetesの重要なメカニズムで、Podが一致する容認を持っていない限り、ノードが一連のPodを撃退できるようにするもので、Podの配置を制御する方法を効果的に作成します。
NoSchedule: 一致する容認がない限り、ポッドがノードにスケジュールされないようにするテイントの影響。
正解解説:
(オプション)
・「compliant」ノードをfinancial-compliance: trueというラベルで汚染し、NoScheduleとエフェクトをNoScheduleで汚染し、機密性の高い金融取引に関与するPodでマッチング容認を構成する。
この選択は、目的のコンプライアンスを確保するために実用的です。ノードのテイントは、特定の容認を持つポッドを除いて、それらのノードでスケジュールできないことを保証します。「準拠」ノードでfinancial-compliance: trueとNoScheduleを設定することで、許容値が一致するPodのみがこれらのノードでスケジュールされます。このメソッドにより、両方のノードが準拠するPodに対して排他的であり、容認のないPodがこれらのノードから離れることが保証されます。
不正解の説明:
オプション: Podの仕様でnodeSelectorを使用して、financial-compliance: trueというラベルでフラグが立てられたノードをターゲットにします。
この選択が間違っている理由は、nodeSelectorは指定されたラベルを持つノードでPodがスケジュールされることを保証するだけで、他の非準拠のPodが同じノードでスケジュールされるのを防ぐものではないためです。
オプション: financial-compliance: trueというラベルでノードプールを指定し、Podセキュリティポリシーを適用して、このラベルでタグ付けされたノードでのみPodが実行されるように制限します。
この選択が間違っている理由は、適切なラベルを持つ特殊なノードプールは準拠ノードを追跡するのに役立ちますが、Podセキュリティポリシーは非推奨であり、非準拠のPodが同じノードでスケジューリングするのを防ぐことはできないためです。
オプション: 機密性の高い金融トランザクションを処理するすべてのPodを、「financial-transaction-compliant」というラベルの付いた名前空間に分離します。
この選択が間違っている理由は、Podを特定の名前空間に分離しても、Podがスケジュールされているノードが制限されないためです。名前空間は論理的なグループ化のためのものであり、スケジューリング ポリシーを強制するものではありません。
参考：
https://cloud.google.com/kubernetes-engine/docs/how-to/node-taints
https://cloud.google.com/kubernetes-engine/docs/concepts/pod-security-policies
https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/
</div></details>

### Q.  問題46: 未回答
ある医療企業は、オンラインの患者ポータルを保護し、権限のないエンティティがドメインハイジャックによってサイトトラフィックを不正なWebサイトに再ルーティングするのを防ぎたいと考えています。
どの Google Cloud サービスを実装すべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Webサイトのトラフィック方向の完全性を脅かすドメインハイジャックなどの特定の攻撃ベクトルから保護するためにDNSに適用できるセキュリティ機能に関する知識を評価します。
重要な用語:
DNSセキュリティ拡張機能:DNSSECは、DNS解決プロセスに認証レイヤーを追加する高度なセキュリティ機能であり、デジタル署名を使用して、受信したDNS応答が本物であり、改ざんされていないことを確認します。
正解解説:
(オプション)
・DNSセキュリティ拡張
DNS Security Extensions(DNSSEC)は、デジタル署名ベースの認証でDNSを保護することで、ヘルスケア企業がドメインハイジャックを防ぐ方法を提供します。DNSSECを実装することで、DNSが提供するデータが転送中に変更されていないことが保証され、攻撃者がトラフィックを悪意のあるサイトに再ルーティングすることが非常に困難になります。DNSSECは、基本的なDNSプロトコルの上に信頼層を追加しますが、このプロトコルには、オンラインの患者ポータルを保護するために不可欠なDNSクエリ応答の操作から保護するためのセキュリティメカニズムが組み込まれていません。
不正解の説明:
オプション: VPC フローログ
VPC フローログが正しく選択されない理由は、VPC フローログが Google Cloud の仮想プライベートクラウド内のネットワークのモニタリング、ロギング、診断用に設計されているためです。疑わしいネットワークトラフィックを特定できる可能性はありますが、DNSハイジャックを防止したり、トラフィックが意図した宛先に誘導されたりすることはありません。
オプション:Cloud Armor
Cloud Armor が間違っている理由は、Cloud Armor が DDoS 保護やアプリケーションレベルの防御などのネットワーク セキュリティを提供するサービスであり、どちらもドメイン ハイジャックの問題に直接対処したり、DNS 解決の整合性を強化したりしないためです。
オプション:Identity-Aware Proxy
Identity-Aware Proxyが正しくない理由は、IAPがWebアプリケーションやVMへのアクセスを管理する方法であり、ID検証とコンテキストアウェアアクセスポリシーが必要であり、DNSの保護やドメインハイジャックからの保護とは関係がないためです。
参考：
https://cloud.google.com/dns/docs/dnssec
https://cloud.google.com/armor/docs/security-policy-concepts
https://cloud.google.com/iap/docs/concepts-overview
</div></details>

### Q.  問題49: 未回答
社内のデータ規制およびプライバシー部門の責任者は、コンプライアンスの目的で Google Cloud ロードバランサを通過する暗号化トラフィックの性質をよりよく理解するために、詳細な検査機能を必要としています。
このタスクには、どの Google Cloud サービスを使用しますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、規制とプライバシーのコンプライアンスのためにネットワーク内の暗号化されたトラフィックを分析するために、適切な Google Cloud サービスを選択する能力を評価します。このタスクは、ロードバランサーを通過するトラフィックの詳細な分析に必要な検査機能に焦点を当てています。
重要な用語:
Packet Mirroring:Packet Mirroringは、Virtual Private Cloud(VPC)内の指定されたインスタンスからネットワークトラフィックをコピーし、分析のために監視コレクターに転送する機能であり、ネットワークとセキュリティのフォレンジックを支援します。
暗号化トラフィック分析:暗号化トラフィック分析では、暗号化されたデータパケットのパターンとメタデータを検査して、トラフィックを復号化せずに潜在的な脅威やコンプライアンスの問題を検出します。
ロードバランサー:ロードバランサーは、ネットワークまたはアプリケーションのトラフィックを複数のサーバーに分散し、個々のサーバーの負荷を最小限に抑えることでサービスの可用性と信頼性を確保します。
コンプライアンス監視: コンプライアンス監視とは、特にデータの管理と保護において、法律、規制、およびポリシー要件へのコンプライアンスを体系的に追跡および管理するプロセスを指します。
正解解説:
(オプション)
・パケットミラーリング
この選択は、コンプライアンスとセキュリティ監視の目的で、暗号化されたパケットを含むネットワークトラフィックを可視化するのに適しています。Packet Mirroring は、トラフィックがロードバランサーに到達する前に、復号化を必要とせずに、Virtual Private Cloud (VPC) ネットワークレベルでトラフィックのコピーを作成します。これにより、トラフィックの検査、ネットワークパフォーマンスの監視、高度な分析ツールやフォレンジックツールを使用した悪意のあるアクティビティの検出が可能になり、データ規制およびプライバシー部門のニーズに応えることができます。
不正解の説明:
オプション:クラウドマーケットプレイス侵入防止システム
Cloud Marketplace Intrusion Prevention Systemsが正しくない理由は、ネットワークトラフィックを分析できますが、コンプライアンス監視のために通過するすべてのトラフィックの詳細な検査を提供するのではなく、サイバー脅威から保護するためのセキュリティサービスの提供に主眼を置いているためです。
オプション:仮想プライベートクラウドフローログ
Virtual Private Cloud フロー ログが正しくない理由は、VM インスタンスとの間で送受信されるネットワーク フローのサンプルを記録し、ネットワーク監視には役立ちますが、暗号化されたトラフィックの実際のコンテンツを検査する機能がないためです。
オプション: Virtual Private Cloud Service Controls 監査ログ
Virtual Private Cloud Service Controls 監査ログが正しくない理由は、監査ログが暗号化されたトラフィックを渡すリアルタイムの詳細な検査機能を提供するのではなく、VPC 内の管理アクティビティについて報告するためです。
オプション: Google Cloud Armor ペイロード インスペクション
Google Cloud Armor ペイロード インスペクションが正しくない理由は、ウェブベースの脅威から保護するために HTTP(S) ロード バランシング トラフィックのインスペクションを提供する一方で、暗号化されたネットワーク トラフィックの規制やコンプライアンスの詳細なインスペクションを容易にするようには設計されていないためです。
参考：
https://cloud.google.com/vpc/docs/using-packet-mirroring
https://cloud.google.com/vpc/docs/flow-logs
https://cloud.google.com/armor/docs/security-policy-overview
</div></details>

# 3


# Ohter
## 2

### Q.  問題6: 未回答
あなたは、プロジェクト X の BigQuery データセットにプロジェクト Y からのみアクセスできるようにする必要があるデータ ガバナンス チームの一員であり、適切な権限があっても、指定された環境外の他の BigQuery データセットから BigQuery データセットの情報を取得したり、転送したりできないようにする必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、さまざまなプロジェクト環境にわたって Google Cloud の BigQuery 内のデータを保護するための知識を評価し、データセットが定義された境界に限定され、適切な権限があってもその境界外にアクセスまたは転送されないようにします。
重要な用語:
VPC Service Controls: サービス間の通信を制御し、データ流出を防止するセキュリティ境界を作成することで、GCP サービスの機密データのセキュリティを強化します。
セキュリティ境界: GCP サービスのリソースの周囲に境界を定義し、この境界内でデータが保護される VPC Service Controls の機能。
ドメイン制限付き共有: 特定のドメイン内のリソース共有を制限し、指定されたドメイン外のエンティティとデータが共有されないようにする組織ポリシー。
Uniform Bucket-level Access: Cloud Storage バケット内のすべてのオブジェクトに一貫したアクセス制御リスト(ACL)を適用し、権限管理を簡素化する機能。
限定公開の Google アクセス: 外部 IP アドレスを持たない VM インスタンスが、パブリック IP を使用せずに、Google のプライベート ネットワーク経由でのみ BigQuery などの Google サービスにアクセスできるようにします。
VPC ネットワーク ピアリング: Google Cloud のネットワーク機能で、異なる VPC ネットワークを相互に接続し、外部 IP を使用せずにルートを共有し、ネットワークの分離を維持できます。
正解解説:
(オプション)
・VPC Service Controls を有効にし、プロジェクト X と Y を含むセキュリティ境界を作成し、そこに BigQuery サービスを追加します。
VPC Service Controls は、定義された境界外でのデータ流出を防ぐのに役立つ強化されたセキュリティ境界を提供するため、この選択は最適なソリューションです。プロジェクト X と Y を含むセキュリティ境界を作成し、そこに BigQuery サービスを追加することで、プロジェクト X の BigQuery データセットにプロジェクト Y からのみアクセスできるようにします。このセットアップは、構成されたアクセス許可に関係なく、外部プロジェクトへのデータ転送から保護され、制御されたデータガバナンスの要件を満たします。
不正解の説明:
オプション: ドメイン制限付き共有組織ポリシーを設定し、BigQuery データセットに均一バケットレベルのアクセスを適用します。
このオプションが正しくない理由は、ドメイン制限付き共有と均一バケットレベルのアクセスを組み合わせると、ドメインまたは組織外での意図しない共有を防ぐことができますが、シナリオで必要なプロジェクト間のネットワーク/境界ベースのアクセス制限は適用されないためです。
オプション: プロジェクト X とプロジェクト Y の両方のネットワークで限定公開の Google アクセスを設定し、2 つのプロジェクト間のネットワーク トラフィックに厳格なファイアウォール ルールを適用します。
このオプションが間違っている理由は、限定公開の Google アクセスを設定すると、外部 IP のない VM で GCP サービスを使用できるようになり、厳格なファイアウォール ルールを適用してもネットワーク トラフィックは制御されますが、BigQuery データセットへのアクセスが特に制限されたり、データ転送が効果的に妨げられたりすることはないためです。
オプション: プロジェクト X と Y のネットワーク間に VPC ネットワーク ピアリングを確立し、厳格なファイアウォール ルールを適用してネットワーク間のデータ フローを管理します。
このオプションが正しくない理由は、VPC ネットワーク ピアリングでは 2 つのネットワークを接続してルートを共有できますが、追加の VPC Service Controls を使用しないと、シナリオに従ってピアリングされたネットワーク外の BigQuery データセットにデータにアクセスしたり転送したりするのを防ぐことができないためです。
参考：
https://cloud.google.com/storage/docs/vpc-service-controls
https://cloud.google.com/vpc-service-controls/docs/overview
https://cloud.google.com/storage/docs/access-control/
</div></details>

### Q.  問題9: 未回答
あるメディア企業は、Google Cloud の柔軟なスケーリング機能を活用する Compute Engine インスタンスを使用して、オンライン ストリーミング サービスを立ち上げました。
Linux Compute Engine インスタンスが必要なすべてのソフトウェア パッチで最新の状態に保たれるようにするために、DevOps チームにどのようなアドバイスをしますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、Linux Compute Engine インスタンスを最新のソフトウェア パッチで更新するためのベスト プラクティスを対象としており、特にメディア企業がストリーミング サービス インフラストラクチャに柔軟なスケーラビリティを必要とするシナリオを対象としています。
重要な用語:
CI/CD: 継続的インテグレーションと継続的デプロイは、ソフトウェア配信のプロセスを自動化するために設計された DevOps 手法です。これにより、頻繁で信頼性の高いコード変更を行い、本番環境にデプロイできます。
カスタム イメージ: カスタム イメージは、ファイルまたは設定を追加または変更することによってカスタマイズされた起動可能なディスク イメージであり、新しい VM の作成に使用したり、クラウド内の VM のグループの基盤として使用したりできます。
段階的アプローチ: 更新プログラムまたは変更を段階的に展開する方法。すべてのシステムが同時に更新されないようにすることでリスクを軽減し、問題が発生した場合のロールバックポイントを提供します。
正解解説:
(オプション)
・更新プログラムが利用可能になったときに新しいカスタム イメージを作成し、継続的インテグレーション/継続的デプロイ (CI/CD) ワークフローを使用して、段階的なアプローチで VM を再作成してデプロイします。
この選択は、VM インスタンスを維持するためのベスト プラクティスを推奨しています。必要な更新を含むカスタムイメージを作成し、自動化されたCI/CDパイプラインを介してこれらのイメージをデプロイすることで、メディア会社は更新されたインスタンスにスムーズに移行できます。このプロセスにより、変更の継続的な統合と自動デプロイが可能になり、ダウンタイムと中断が最小限に抑えられます。段階的なアプローチにより、更新プログラムが徐々にプッシュされ、広範な問題のリスクが軽減されます。
不正解の説明:
オプション: Compute Engine に中央管理サーバーを統合し、構成管理ツールを使用して毎週更新を伝達します。
この選択が間違っている理由は、中央管理サーバーでは手動更新が必要であり、GCP の柔軟なスケーリングと管理機能をフルに活用できないためです。構成管理ツールは便利ですが、VM の再作成を自動化および合理化するための完全な CI/CD ソリューションは提供されません。
オプション: Google Cloud Deployment Manager を活用して、最新のイメージ バージョンの VM を新しいマネージド インスタンス グループ (MIG) にロールアウトします。
この選択が間違っている理由は、Google Cloud Deployment Manager はリソースの作成を自動化できますが、継続的な更新の必要性には対応できないためです。Deployment Manager は CI/CD ツールではないため、デプロイ構成を定義および維持するには手動による介入が必要です。
オプション: 事前定義されたサービス期間中にすべてのインスタンスのシステム再起動をスケジュールし、起動スクリプトを使用してオンラインリポジトリから最新の更新をフェッチして適用します。
この選択が正しくない理由は、VM の起動時に再起動をスケジュールして更新をフェッチすると、更新が失敗したり、追加の介入が必要になったりした場合に、予期しない状態になる可能性があるためです。スタートアップ スクリプトは、CI/CD パイプラインと同じレベルの制御と自動化を提供しません。
参考：
https://cloud.google.com/compute/docs/instances/windows/creating-managing-windows-instances
https://cloud.google.com/compute/docs/instances/windows#install-windows-updates
https://cloud.google.com/solutions/cicd-pipeline-for-compute-engine-deployments
</div></details>

### Q.  問題12: 未回答
Secret Manager に保存されている会社の API トークンに対して新しいセキュリティポリシーを設定しています。現在、高トラフィック サービスと低トラフィック サービスのトークンは分離され、個別のサービス アカウントを介してアクセスされます。デザインは以下を満たす必要があります。
- トークンの詳細なアクセス許可を許可する
- トークンを保護する暗号化キーのローテーション期間を指定できます
- サービスレベル間の分離を維持
- 管理タスクの簡素化
どの戦略を導入すべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の Secret Manager サービス内の API トークンに関するセキュリティ ポリシーを管理するためのベスト プラクティスに焦点を当てています。これは、詳細な権限の割り当て、暗号化キーのローテーション制御、サービスレベルの分離、および管理の簡素化の要件に対処することを目的としています。
重要な用語:
Secret Manager:APIトークン、パスワード、証明書、その他の機密データ用の安全で便利なストレージシステム。これにより、シークレットの集中管理とプログラム管理が可能になります。
Identity and Access Management(IAM): 誰がどのリソースに対してどのアクセス権(役割)を持つかを定義することで、アクセス制御を管理するための Google Cloud のスイートです。
顧客管理の暗号鍵(CMEK): ユーザーが暗号鍵を作成、使用、管理できるようにする機能で、Google Cloud でのデータ暗号化を制御できます。
トークンのローテーション:トークンの侵害や誤用のリスクを軽減するために、APIトークンを定期的に新しいトークンに置き換えるセキュリティ手順。
正解解説:
(オプション)
・高トラフィックおよび低トラフィックのサービス トークン用に個別の Google Cloud プロジェクトを作成します。プロジェクト固有の Identity and Access Management (IAM) ポリシーを使用して、トークンのアクセス管理を実装します。顧客管理の暗号鍵(CMEK)を利用してトークンを暗号化します。
この選択は、個別の Google Cloud プロジェクトを利用することで、高トラフィックと低トラフィックのサービスレベルを分離するため、最適です。プロジェクト固有のIAMポリシーは、各プロジェクトのニーズに合わせてきめ細かなアクセス制御を提供します。顧客管理の暗号鍵 (CMEK) を使用すると、暗号鍵のユーザー定義のローテーション期間が可能になり、鍵のローテーション制御の設計要件を満たし、ユーザー ガバナンス下にある鍵でトークンを暗号化することでセキュリティを補完できます。
不正解の説明:
オプション: 高トラフィックと低トラフィックのサービス トークンを、統合された Google Cloud プロジェクト内に統合します。トークンレベルのIdentity and Access Management(IAM)ポリシーを適用して、アクセスを制御します。Google が管理する暗号鍵を使用してトークンを暗号化します。
このオプションが正しくない理由は、サービス トークンが 1 つのプロジェクトに統合され、必要に応じて高トラフィック サービスと低トラフィック サービスの分離が維持されないためです。トークンレベルの IAM は詳細な権限を提供しますが、Google が管理する暗号化鍵を使用すると、カスタムローテーション期間は許可されません。
オプション: 高トラフィックと低トラフィックのサービス トークン用に個別の Google Cloud プロジェクトを確立します。トークンレベルのIdentity and Access Management(IAM)ポリシーを適用して、トークンアクセスを管理します。Google が管理する暗号鍵を使用してトークンを暗号化します。
このオプションが正しくない理由は、Google が管理する暗号鍵を使用しているため、ユーザーがローテーション期間を定義できないためです。分離は個別のプロジェクトを使用して維持されますが、顧客管理の暗号鍵 (CMEK) がないため、鍵のローテーション制御の要件を満たしません。
オプション: 高トラフィックと低トラフィックのサービス トークンを 1 つの Google Cloud プロジェクトに組み合わせます。プロジェクト全体の広範な Identity and Access Management (IAM) ポリシーを使用してアクセスを規制します。顧客管理の暗号鍵(CMEK)を使用してトークンを保護します。
このオプションが正しくない理由は、トークンを 1 つのプロジェクトに結合し、サービス レベル間の分離を維持するという要件と矛盾するためです。さらに、プロジェクト全体の広範な IAM ポリシーでは、CMEK が正しく使用されているにもかかわらず、設計基準で義務付けられている詳細な権限レベルは付与されません。
参考：
https://cloud.google.com/secret-manager/docs
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://cloud.google.com/kms/docs/secret-management
</div></details>

### Q.  問題13: 未回答
臨床医に代わってカレンダー イベントをスケジュールする必要がある医療プラットフォームのバックエンド サービスを開発しています。組織は、臨床医の個人的な資格情報に依存しないことを好みます。また、Google Cloud が推奨するベスト プラクティスを遵守することも目的としています。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、臨床医の個人資格情報を使用せずにカレンダー イベントをスケジュールするバックエンド サービスのベスト プラクティスを評価します。セキュリティと機能を維持するために、Google Cloud のサービス アカウントとロールを適切に使用する方法について説明します。
重要な用語:
サービス アカウント: サーバー間のやり取りに使用される Google Cloud エンティティで、個々のユーザー アカウントから離れた抽象化レベルを提供し、認証と承認のための安全なモデルを提供します。
ドメイン全体の委任: 個々の認証情報を必要とせずに、サービス アカウントが Google Workspace ドメイン内のユーザーに代わって動作できるようにする高度な機能で、ユーザーデータにアクセスするアプリケーションで一般的に使用されます。
サービスアカウントユーザーロール:サービスアカウントが自分自身として操作を実行したり、同じプロジェクト内で他のサービスアカウントになりすますことができ、責任を委任する機能を提供するロール。
偽装: サービスアカウントがリソースにアクセスするために別のアカウント(通常はユーザー)のIDを仮定し、サービスアカウントが他のアカウントであるかのようにアクションを実行できるようにするプロセス。
正解解説:
(オプション)
・新しいサービス アカウントを作成し、Google Workspace のドメイン全体の委任を付与します。サービスでこのアカウントを使用して臨床医を偽装します。
この選択は、ユーザーに代わって実行されるアクションを管理するときに、セキュリティと管理制御を維持するための推奨されるベスト プラクティスです。Google Workspace のドメイン全体の委任でサービス アカウントを作成すると、カレンダーの予定をスケジュールする際に、サービスで臨床医になりすますことができます。これにより、個々の資格情報への依存を回避し、資格情報が侵害されるリスクが軽減され、個々のユーザーアクセス許可を処理するのではなく、ドメイン レベルでのアクセス許可管理が簡素化されます。
不正解の説明:
オプション:新しいサービスアカウントを作成し、すべてのプラットフォームユーザにサービスアカウントユーザロールを割り当てます。
この選択が間違っている理由は、サービスアカウントユーザーロールをすべてのプラットフォームユーザーに割り当てるだけでは、サービスアカウントの管理や権限の委任のベストプラクティスと一致しないためです。さらに、権限を過剰にプロビジョニングすることでセキュリティリスクが生じる可能性があります。
オプション: 新しいサービス アカウントを作成し、すべてのプラットフォーム ユーザーを Google グループに含めます。このグループにサービスアカウントユーザーロールを割り当てます。
この選択が正しくない理由は、グループを作成してサービス アカウント ユーザーロールを割り当てることが、Google Cloud が推奨するセキュリティ プラクティスに準拠していないためです。管理は簡素化されますが、すべてのグループメンバーに過剰な権限が誤って付与される可能性があります。
オプション: 別の Google Workspace 管理者アカウントを使用して、これらの Workspace 認証情報を使用してバックエンド サービスのアクションを認証します。
この選択が正しくない理由は、サービス操作に高い特権を持つ管理者アカウントを利用することで最小特権の原則に違反し、管理者の資格情報が公開される可能性があるため、重大なセキュリティ上の懸念が生じるためです。
参考：
https://cloud.google.com/iam/docs/understanding-service-accounts
https://cloud.google.com/iam/docs/impersonating-service-accounts
https://developers.google.com/identity/protocols/oauth2/service-account#delegatingauthority
</div></details>

### Q.  問題14: 未回答
あるメディア会社は、コンピューティング インスタンスのフリートを使用して大きな動画ファイルを処理し、レンダリングされた動画を Cloud Storage バケットに保存したいと考えています。ネットワーク・セキュリティ・ポリシーでは、コンピュート・インスタンスがパブリック・インターネットにアクセスできないことが義務付けられています。
この要件を満たすための最も適切な方法は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、インターネット アクセスを許可せずに、Google Cloud コンピューティング インスタンスと Cloud Storage バケット間の安全でプライベートな接続の設定に関する受験者の知識を評価します。クラウド環境におけるネットワークセキュリティポリシーの理解度をテストします。
重要な用語:
限定公開の Google アクセス: サブネット上の VM インスタンスがパブリック IP アドレスなしで Google サービスにアクセスできるようにする機能。GCP内の内部ルーティングを利用して、GCPサービスにアクセスします。
正解解説:
(オプション)
・コンピューティング インスタンスの限定公開 Google アクセスを有効にすると、パブリック インターネット アクセスを必要とせずに Cloud Storage バケットとやり取りできます。
コンピューティング インスタンスで限定公開の Google アクセスを有効にすると、内部 GCP ルーティングを使用して Cloud Storage などの Google サービスに接続できるため、この選択は正確です。これにより、パブリック インターネットへのアクセスを制限するネットワーク セキュリティ ポリシーを遵守しながら、動画ファイルを処理して Cloud Storage に保存するという同社の要件を満たします。
不正解の説明:
オプション: コンピュート・インスタンスからインターネットへのアウトバウンド・トラフィックを防止するファイアウォール・ルールを設定します。
この選択が間違っている理由は、ファイアウォール ルールによって送信インターネット トラフィックは防止されますが、Cloud Storage への必要な接続が容易になるわけではないためです。インスタンスは、追加の設定なしでは、レンダリングされたビデオをバケットに保存できません。
オプション: コンピューティング インスタンスが Cloud Storage バケットにアクセスできるように NAT Gateway を構成します。
この選択が正しくない理由は、NATゲートウェイがパブリックIPアドレスのないインスタンスにインターネットアクセスを提供し、ネットワークセキュリティポリシーに違反するためです。目標は、インターネットアクセスを完全に回避することであり、NATを介してインターネットアクセスを隠すことではありません。
オプション: Cloud Storage バケットを各コンピューティング インスタンスのファイルシステムに直接統合します。
この選択が間違っている理由は、ネットワークセキュリティ要件を見落としているためです。Cloud Storage バケットをファイルシステムに直接統合すると、アクセシビリティの問題は解決する可能性がありますが、セキュリティ ポリシーで義務付けられているインターネット アクセスは制限されません。
参考：
https://cloud.google.com/storage/docs/accessing-private-access
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/storage/docs/gcs-fuse
</div></details>

### Q.  問題15: 未回答
ある医療機関は、Google Kubernetes Engine を使用して患者データを処理しており、BigQuery を使用して治療効果を評価しようとしています。機密性の高い個人健康情報(PHI)が BigQuery に保存されないようにする必要があります。
どのような行動を取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、GKE と BigQuery を利用する医療機関のコンテキストで個人健康情報(PHI)を処理するシナリオを取り上げます。焦点は、PHI が BigQuery に保存されないようにすることで、プライバシー規範を順守することです。
重要な用語:
Cloud Data Loss Prevention API: 機密データの管理を支援するサービスです。分類、匿名化、再識別機能を提供し、データのプライバシーと規制コンプライアンスを確保します。
正解解説:
(オプション)
・Cloud Data Loss Prevention APIを活用して、BigQueryにデータを取り込む前に機密情報タイプをサニタイズします。
Cloud Data Loss Prevention(DLP)API は、Google Cloud サービス全体の機密データの検出、分類、保護を支援するために特別に設計されているため、この選択は適切です。PHI を含むさまざまな infoType をサポートし、BigQuery などの他のサービスで使用される前に機密情報を匿名化できます。取り込み前にデータをサニタイズするように DLP API を設定することで、教育機関はコンプライアンスを確保し、患者データのプライバシーを維持します。
不正解の説明:
オプション: PHI パターンに一致するように設計された正規表現を使用して BigQuery 仮想ビューを構成し、関連するレコードを識別して切り取ります。
この選択が間違っている理由は、BigQuery の仮想ビューが基になるデータを変更しないためです。これらは、クエリ時に動的な変換レイヤーを提供するだけです。PHIは保存されたデータにまだ存在し、機密情報を保護するためのコンプライアンス要件を満たしていません。
オプション: Security Command Center を使用して、BigQuery データセットで個人の健康情報として分類されたアセットを特定します。
この選択が間違っている理由は、Security Command Center が Google Cloud リソース内の脆弱性と脅威のモニタリングと特定に重点を置いているためです。不適切に保存された PHI を事後的に特定することはできますが、BigQuery データセットへの PHI の保存を予防的にサニタイズしたり防止したりすることはありません。
オプション: Cloud Identity-Aware Proxy を有効にして、情報が BigQuery にアーカイブされる前に PHI データを妨害します。
この選択が間違っている理由は、Cloud Identity Aware Proxy(IAP)は Google Cloud で実行されているウェブ アプリケーションや VM へのアクセスを制御しますが、BigQuery などのデータベースに保存される前に、PHI などの機密データのコンテンツを調べたりフィルタリングしたりしないためです。
参考：
https://cloud.google.com/dlp/docs/transformations/redact-sensitive-data
https://cloud.google.com/bigquery/docs
https://cloud.google.com/bigquery/docs/best-practices-security
</div></details>

### Q.  問題16: 未回答
Google Cloud Healthcare API データセット内の非常に機密性の高い情報の管理を監督している。臨床アナリストはこのデータにアクセスする必要がありますが、HIPAA規制により、患者の社会保障番号や医療記録番号などの機密情報を表示できないことが重要です。これらの特定の機密要素は、コンプライアンスおよび監査部門の権限のある担当者のみが利用できるようにする必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、GCP 環境における機密性の高い健康情報の保護対策の実装を取り上げ、HIPAA 規制への準拠を確保します。課題は、許可された役割の機能を損なうことなくアクセスを制限することで、患者の詳細を保護することです。
重要な用語:
匿名化:個人を特定する情報を削除または変更し、データを個人と関連付けることを不可能または非現実的に困難にするプロセス。
トークン化: このコンテキストでは、トークン化とは、機密性の高いデータ要素を、悪用可能な意味や価値を持たないトークンと呼ばれる機密性の低い同等のものに置き換えることを指します。
HIPAA:Health Insurance Portability and Accountability Actの略で、米国における機密性の高い患者データを保護するための基準を定めています。
正解解説:
(オプション)
・Cloud Data Loss Prevention API を使用して匿名化を適用し、機密性の高い要素をトークン化し、その情報を Healthcare API データセットに保持してアクセスを制限します。
トークン化による匿名化により、機密性の高い患者情報を効果的に保護できるため、この選択は正しいです。Data Loss Prevention API は、このようなデータをトークン化するメカニズムを提供し、臨床アナリストが機密性の低い要素のみにアクセスできるようにする一方で、元のデータは Healthcare API データセット内に安全に保存され、コンプライアンスおよび監査部門の権限のある担当者がアクセスできるようにします。
不正解の説明:
オプション: Cloud Data Loss Prevention API を使用してデータの難読化を行い、必要なアクセスのためにその情報を Healthcare API データセットに保存します。
この選択が間違っている理由は、「データの難読化」という用語が広すぎて、保護方法が指定されていないため、社会保障番号などの機密情報の処理方法があいまいなままになっているためです。
オプション: Cloud Data Loss Prevention API を活用してパターンを隠蔽し、その情報を Healthcare API データセット内で保護して使用を制限します。
この選択が間違っている理由は、「パターン隠蔽」がデータセット内の特定の機密情報へのアクセスを制限する方法を適切に記述していないためです。これは、データ保護に関するHIPAA要件に完全に準拠していない可能性のあるデータパターンを変更することを示唆しています。
オプション: Cloud Data Loss Prevention API を使用してデータ分析を実装し、そのデータを Healthcare API データセットに保存して、条件付きアクセシビリティを実現します。
この選択が間違っている理由は、機密情報の保護に直接関係しない「データ分析」に焦点を当てているからです。「条件付きアクセシビリティ」のために Healthcare API にデータを保存するのは曖昧すぎるため、HIPAA 規制で要求されるセキュリティのレベルは保証されません。
参考：
https://cloud.google.com/dlp/docs/tokenization
https://cloud.google.com/bigquery/docs/column-level-security-intro
https://cloud.google.com/bigquery/docs/best-practices-security-controls
</div></details>

### Q.  問題17: 未回答
あなたの会社はビデオストリーミング技術の開発を専門としており、知的財産の保護とコードの整合性の確保に関心を持っています。ビルド パイプラインが侵害されておらず、ソフトウェアがセキュリティで保護されていることを示す必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、ソフトウェアサプライチェーンの整合性を確保し、ビルドパイプラインが安全であることを示すことに関連しています。焦点は、独自のビデオストリーミング技術を開発している企業のコードの整合性を検証し、知的財産を保護できるアクションです。
重要な用語:
SLSA: Supply Chain Levels for Software Artifacts (SLSA) は、ソフトウェア サプライ チェーン全体でソフトウェア アーティファクトの整合性を確保することを目的としたセキュリティ フレームワークです。これは、段階的に導入可能な一連のセキュリティ ガイドラインです。
Cloud Build: Cloud Build は、Google Cloud のインフラストラクチャ上でビルドを実行するサービスです。ソースコードをインポートし、仕様に合わせてビルドを実行し、コンテナや非コンテナ成果物などの成果物を生成できます。
ビルドの来歴: ビルドの出所は、ソフトウェア成果物のビルド プロセスの検証可能な記録を提供するメタデータです。これには、どのビルダーがいつ、どこでアーティファクトを作成したかなどの詳細が含まれます。
Security Command Center: Security Command Center は、クラウド資産の可視化、脆弱性のスキャン、コンプライアンスの維持を支援する Google Cloud のセキュリティおよびリスク管理ツールです。
正解解説:
(オプション)
・Cloud Buildを使用して、Supply Chain Levels for Software Artifacts(SLSA)レベル3の保証を生成します。ビルドの来歴は、Google Cloud コンソールの Security Command Center で確認できます。
SLSA レベル 3 の保証を取得すると、ビルド プロセスが定義されたセキュリティ基準を満たし、改ざんや侵害を防ぐのに役立つため、この選択が推奨されます。Google の Cloud Build を使用して SLSA レベル 3 準拠のビルドを生成し、Google Cloud のセキュリティ コマンド センターでビルドの出所を確認することで、ビルド パイプラインの整合性が維持され、ソフトウェアの変更や更新が追跡可能で安全であることを示す検証可能な証拠が得られます。
不正解の説明:
オプション: ビルド パイプラインのセキュリティを評価および認定するサードパーティのサイバーセキュリティ会社を任命します。調査結果を文書化し、公式ウェブサイトに認定を表示します。
この選択が間違っている理由は、サードパーティのサイバーセキュリティ企業を持つことで信頼性が高まる可能性はあるものの、構築パイプラインが損なわれないことを本質的に保証するものではないからです。また、質問は、1 回限りの認定ではなく、継続的な保証を実証することに重点を置いています。
オプション:ビデオストリーミングソフトウェアの構築プロセスを徹底的に調べます。RSAキーペアを生成し、コード署名証明書を使用してソフトウェアディストリビューションを認証し、署名されたダイジェストを企業ポータルに公開します。
この選択が正しくない理由は、コード署名証明書はソフトウェア配布を認証する一方で、ビルドパイプライン自体の潜在的な侵害に対処しないためです。RSA キー ペアと署名付きダイジェストは、ビルド後の整合性に役立ちますが、SLSA によって提供される継続的な検証が欠けています。
オプション:ビデオストリーミングソフトウェアのソースコードをオープンソースリポジトリで公開します。脆弱性の発見に対するインセンティブ プログラムを開始し、潜在的なセキュリティの問題を分析、開示、解決するようコミュニティに呼びかけます。
この選択が間違っている理由は、コードをオープンソース化し、脆弱性報奨金プログラムに参加しても、ビルド パイプラインの整合性が直接保証されないためです。これは、開発パイプラインのセキュリティを検証するというよりも、コードの公開後に脆弱性を見つけるためのコミュニティ主導のアプローチです。
参考：
https://cloud.google.com/build/docs/building/build-containers
https://cloud.google.com/binary-authorization/docs/getting-started-cli
https://slsa.dev/levels
</div></details>

### Q.  問題18: 未回答
貴社は CIS Google Cloud Computing Foundations Benchmark v1.3.0 (CIS Google Cloud Foundation 1.3) への準拠を維持する予定ですが、一部のベンチマークは適用されないため、評価から除外する必要があります。あなたは、関連するベンチマークのみを評価するプロセスを自動化する方法またはシステムを設計する任務を負っています。
どのような手順を実行しますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、CIS Google Cloud Foundations Benchmark に準拠するために Google Cloud セキュリティ ツールを効率的に活用する能力を評価し、適用できないベンチマークを除外して評価プロセスを自動化することに重点を置きます。
重要な用語:
CIS ベンチマーク: 安全なベースライン構成を確立するための規範的なガイダンスを提供するように設計された、一連のベスト プラクティス セキュリティ構成ガイド。
Security Command Center: Google Cloud の包括的なセキュリティおよびリスク管理プラットフォームであり、統一された可視性、継続的なモニタリング、実用的なセキュリティ分析情報を提供します。
検出結果のミュート: Security Command Center の機能で、ユーザーはビューとレポートから特定の検出結果を省略し、セキュリティ評価で効果的に無視できます。
カスタムルール: Security Command Center 内のユーザー定義の基準で、特定の検出結果に対して実行される解釈やアクションに自動的に影響を与えることができます。
正解解説:
(オプション)
・Security Command Center (SCC) Premiumを有効にする。SCC 内でカスタム ルールを確立して、無関係なセキュリティ検出結果をミュートし、評価に含まれないようにします。
この選択は、Security Command Center (SCC) Premium の高度な機能を活用してコンプライアンス評価を自動化するため、最適です。SCC 内でカスタム ルールを確立することで、無関係なセキュリティ検出結果を体系的にミュートできます。この機能により、継続的な評価は、手動による介入なしに関連するベンチマークに焦点を当てることができ、組織の評価が該当するCISベンチマークと一貫して整合していることが保証されます。
不正解の説明:
オプション: 適用されない各セキュリティ検出結果に、セキュリティ免除として示す特定のタグと関連する値のラベルを付けます。タグ付けされたすべての検出結果が報告されるたびに、Security Command Center (SCC) インターフェイス内で手動でミュートします。Security Command Center (SCC) Premium がアクティブであることを確認します。
この選択が間違っている理由は、かなりの手作業が必要であり、継続的な運用には効率的ではないためです。セキュリティ検出結果を手動でミュートしてもコンプライアンスプロセスは自動化されず、報告された検出結果ごとに継続的な手動介入を行うことは非常に非現実的です。
オプション: Security Command Center (SCC) からすべてのセキュリティ検出結果のリストをスプレッドシート形式にエクスポートします。スプレッドシート内で CIS Google Cloud Foundation 1.3 に関連する検出結果に注釈を付けます。組織のスコープに関連しない項目は無視してください。
この選択が間違っている理由は、自動化用に設計された SCC の機能を完全に回避し、手動プロセスに依存しているためです。調査結果をスプレッドシートにエクスポートしても、リアルタイムの更新はサポートされず、クラウド環境内での継続的なコンプライアンス監視に必要な洗練度に欠けます。
オプション:サードパーティの監査会社と契約して、必要なCISベンチマークを含む定期的なレポートを作成します。組織のコンプライアンス評価に不可欠ではないと見なされた特定のコントロールを省略するように監査人に指示します。
この選択が間違っている理由は、不必要な費用がかかり、報告の遅れにつながる可能性があるためです。コンプライアンスに関する手作業の報告を第三者に頼ることは、評価プロセスを自動化するという要件と矛盾し、監査人の時間枠に依存する可能性があります。
参考：
https://cloud.google.com/security-command-center/docs/how-to-use-mute-findings
https://cloud.google.com/security-command-center/docs/concepts-security-command-center-overview
https://www.cisecurity.org/benchmark/google_cloud_computing_platform/
</div></details>

### Q.  問題19: 未回答
医療機関で、外部企業の SAML ID プロバイダでシングル サインオン(SSO)プロセスを使用するように gcloud コマンドライン ツールを設定しています。
外部 SAML ID プロバイダーと互換性のある認証を有効にするために不可欠な構成はどれですか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、外部企業の SAML ID プロバイダを使用して SSO 用に gcloud CLI を構成するために必要な知識とスキルを調べます。高度なアクセス管理のためにSAML認証をGCP環境に統合することの理解度を評価します。
重要な用語:
SAML: Security Assertion Markup Language (SAML) は、当事者間、特に ID プロバイダーとサービス プロバイダーの間で認証および承認データを交換するための XML ベースの標準です。
SSO:シングルサインオン(SSO)は、ユーザーが1セットのログイン資格情報で複数のアプリケーションにアクセスできるようにする認証プロセスであり、セキュリティとユーザーエクスペリエンスを向上させます。
gcloud CLI: Google Cloud コマンドライン インターフェース(gcloud CLI)は、ターミナル コマンドを使用して Google Cloud のリソースとサービスを管理する機能を提供するツールです。
正解解説:
(オプション)
・外部SAMLベースのシングルサインオン(SSO)用にgcloudを構成する
・外部IDプロバイダー連携のためのSAMLとの互換性検証
適切な選択には、SAML ベースの外部 SSO 用に gcloud を構成し、外部 SAML ID プロバイダとの互換性を確保することが含まれます。SSO を使用するように gcloud を設定する場合は、認証を外部 ID プロバイダに委任するように SAML ベースの方法を設定することが重要です。その後、認証リクエストは SAML プロバイダにリダイレクトされ、認証が成功すると、プロバイダは SAML トークンを発行し、Google 固有の認証情報を入力することなく Google Cloud サービスにアクセスするために使用されます。
不正解の説明:
オプション: Google Cloud Identity Platform を設定する
この選択が間違っている理由は、Google Cloud Identity Platform の設定は、Google Cloud サービス全体でユーザーとグループの管理を一元化することに重点を置いており、gcloud CLI での SAML ベースの外部 SSO の設定とは直接関係がないためです。
オプション: Google Cloud Identity-Aware Proxy を実装する
この選択が間違っている理由は、Google Cloud Identity-Aware Proxy(IAP)は、gcloud CLI に SAML ベースの SSO 認証を統合しないで、ID とコンテキストに基づいて Google Cloud で実行されているアプリケーションへのアクセスを制御することで機能するためです。
オプション: Google Cloud Identity サービスに移行する
この選択が間違っている理由は、Google Cloud Identity サービスに移行すると、Google をプライマリ ID プロバイダとして使用するように変更されるのに対し、この質問では外部の SAML ID プロバイダを gcloud CLI と統合する必要があるためです。
参考：
https://cloud.google.com/sdk/gcloud/reference/auth/login
https://cloud.google.com/identity/saml
Hatps://openid.net/connect/
</div></details>

### Q.  問題20: 未回答
ある金融会社は、Docker イメージに格納された Google Kubernetes Engine(GKE)に、重要度の高いトランザクション処理ソフトウェアをデプロイしています。同社は、既知の脆弱性について画像を評価し、データを Google Cloud の内部に保持しながら、レポートをコンプライアンス チームに安全に割り当てることを義務付けています。
取るべき適切な行動方針は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud ネイティブ サービスを使用して GKE 内の脆弱性がないか Docker イメージをスキャンするためのベスト プラクティスに関する受験者の理解度を評価し、レポートの安全性と Google Cloud インフラストラクチャの内部でのレポートを確保します。
重要な用語:
アーティファクト・レジストリ: Dockerコンテナ・イメージやその他のタイプの言語パッケージを保存、管理、保護するためのサービス。GKE と統合されており、脆弱性の自動スキャン機能を提供します。
Cloud Build: ソースコードをインポートし、ビルド手順を実行し、Docker イメージやその他のアーティファクトを生成するサービス。多くの場合、継続的インテグレーションと継続的デプロイのワークフロー用に構成されます。
脆弱性スキャン: ソフトウェアコンポーネント内のセキュリティ問題を特定して報告するプロセス。クラウドサービスのコンテキストでは、コンテナイメージをスキャンして既知の脆弱性を検出するための自動化ツールが組み込まれています。
正解解説:
(オプション)
・アーティファクトレジストリのパラメータ内で脆弱性スキャンを有効にする。次に、イメージ作成プロセスに Cloud Build を活用します。これに続いて、イメージをアーティファクトレジストリにアップロードすると、自動スキャンがトリガーされます。続いて、アーティファクト・レジストリのスキャン・レポートにアクセスします。
この選択は、Google Cloud のネイティブ サービスを利用してセキュリティ基準を維持し、運用を合理化するため、正しい行動です。アーティファクト・レジストリで脆弱性スキャンを有効にすると、既知の脆弱性についてDockerイメージを自動的にスキャンできます。イメージ作成プロセスに Cloud Build を活用すると、イメージがアーティファクト レジストリにアップロードされ、自動スキャンがトリガーされます。生成された脆弱性レポートは、アーティファクト・レジストリ内でアクセスでき、機密性の高いコンプライアンス・データの整合性とプライバシーが維持されます。
不正解の説明:
オプション: Security Command Center の Premium レベルで Container Threat Detection をオンにします。次に、既存のクラスタが古いバージョンで動作している場合は、サポートされている最新バージョンの GKE に昇格します。最後に、Security Command Center から調査結果を検査して配布します。
この選択が間違っている理由は、Container Threat Detection がランタイム セキュリティに使用される Security Command Center の一部であり、デプロイ前に既知の脆弱性がないか Docker イメージをスキャンするためではないためです。クラスタのアップグレードは、Dockerイメージのスキャンとは直接関係ありません。
オプション: Cloud Build 内のサードパーティのオープンソース スキャン ユーティリティを使用して、画像をスキャンします。次に、gsutil ツールを使用して、一般公開されている Cloud Storage バケットにスキャン レポートを転送します。最後に、スキャン レポートへのリンクをコンプライアンス チームに配布します。
この選択が間違っている理由は、サードパーティのオープンソース スキャン ユーティリティを使用しても、重要度の高いトランザクション処理ソフトウェアに必要な包括的な脆弱性評価が保証されないためです。さらに、一般公開されている Cloud Storage バケットにレポートを転送すると、データのセキュリティが損なわれる可能性があります。
オプション: GitHub などのソース コード ホスティング プラットフォームのサブスクリプションを調達します。Cloud Build を使用して Docker イメージをビルドし、プラットフォーム上に保持して、その本来のスキャン機能を実現します。プラットフォームからスキャンレポートをダウンロードし、コンプライアンス部門に引き渡します。
この選択が間違っている理由は、GitHub がサードパーティのサービスであり、脆弱性スキャンのために Docker イメージをそこに保持すると、Google Cloud の外部でデータが漏洩する可能性があるためです。また、この方法では複雑さが増し、Google Cloud の組み込みのセキュリティ機能が利用されません。
参考：
https://cloud.google.com/artifact-registry/docs/container-analysis
https://cloud.google.com/container-analysis/docs/vulnerability-scanning
https://cloud.google.com/build/docs/building/build-containers
</div></details>

### Q.  問題21: 未回答
Google Cloud リソースを利用する必要があるワークロードをオンプレミスのデータセンターで処理している。ワークロード ID フェデレーションを利用して、外部 ID に Identity and Access Management (IAM) 特権を付与し、サービス アカウント キーの管理に関連する運用上のオーバーヘッドとセキュリティ リスクを回避します。悪意のあるエンティティが別のユーザーの ID を模倣して Google Cloud リソースに不正にアクセスするのを防ぐには、どのような対策を講じる必要がありますか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ワークロード ID フェデレーションを使用してオンプレミスのワークロードを統合する際の Google Cloud リソースのセキュリティ保護について説明します。外部エンティティによる不正アクセスを防ぐためのベスト プラクティスの理解をテストします。
重要な用語:
Workload Identity フェデレーション: Google Cloud の外部で実行されているアプリケーションがサービス アカウント キーを使用せずに IAM ロールを引き受けられるようにする認証方法であり、より安全で保守しやすいクロス環境アクセスを促進します。
属性マッピング: 外部 ID プロバイダーからのクレームを IAM ロールに関連付けるプロセス。定数属性または式属性を使用して、一貫したアクセス管理を確保します。
ID プール: Google Cloud 内に個々の IAM ユーザーを作成することなく、外部 ID のプールを作成し、それらを IAM 権限に関連付ける方法を提供するフェデレーション メカニズム。
正解解説:
(オプション)
・ワークロード ID プールとコネクタの管理専用のプロジェクトを別途割り当てる。
・設定時の属性割り当てに定数属性を活用する。
これらの選択肢は、リソースの構築と一貫性のあるセキュリティ アサーションを利用して、ID が Google Cloud の権限に正確かつ安全に関連付けられるようにすることに重点を置いています。ID プールを管理するための専用プロジェクトを作成すると、ID 管理をアプリケーションリソースから分離することで、設定ミスが発生した場合の影響範囲が制限されます。属性マッピング中に定数属性を利用することで、IAMロールの決定論的で検証可能な割り当てが保証され、予期しないアクセス権につながる可能性のある動的評価を回避できます。
不正解の説明:
オプション: IAMサービス内でのデータ取得の監査ログをオンにします。
この選択が間違っている理由は、監査ログを有効にするとイベントの記録が提供されますが、それ自体は不正アクセスを防ぐものではなく、アクセス後の調査と説明責任のツールとして機能するためです。
オプション: サービス アカウントの ID を引き受ける機能を持つ外部 ID の数を制限します。
この選択が正しくない理由は、外部 ID の数を制限することに重点を置いているため、セキュリティが直接向上しないためです。重要なのは、IDの数だけでなく、IDをIAMロールにマッピングする方法を制御することです。
オプション: サービス アカウントが要求できるリソースの範囲を制限します。
この選択が正しくない理由は、サービス アカウント リクエストの範囲が Google Cloud 内のリソース アクセスの制限に関係しており、フェデレーションを介した外部エンティティによるなりすましや不正アクセスを防止していないためです。
参考：
httpps://cloud.google.com/iam/docs/workload-identity-federation
https://cloud.google.com/iam/docs/configuring-workload-identity-federation
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題22: 未回答
Google Cloud データ ウェアハウスのセキュリティ構成を監督する必要があります。分析ワークロードと開発ワークロード用に別々の環境を維持します。各 Compute Engine インスタンスは、デフォルトのサービス アカウントで設定されます。ネットワーク トラフィック フローを確認したところ、タグを使用して適切なセグメンテーションを適用するために優先度 1,000 の VPC ファイアウォール ルールが設定されているにもかかわらず、Compute Engine インスタンスは制限なく相互に通信できることがわかりました。
この問題の最も可能性の高い原因は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Compute Engine サービス アカウントの動作、VPC ファイアウォール ルール、ネットワーク タグ、およびインスタンスに適用した場合の優先順位についての理解度を評価します。インスタンス間通信が不適切な環境で診断スキルをテストします。
重要な用語:
term: ネットワークタグ
説明: VPC ファイアウォール ルールと連携してインスタンス間のトラフィック フローを制御する VM インスタンスに割り当てられるラベル。
用語: VPC ファイアウォールルール
description: Google Cloud VPC 内のインスタンスとの間のトラフィックを制御します。これらはステートフルであり、優先度タグとターゲットタグによって評価されます。
term: ファイアウォールの優先度
description: 評価順序を決定する各 VPC ファイアウォールルールに関連付けられた数値で、数値が小さいほど優先度が高いことを示します。
正解解説:
(オプション)
・Compute Engine インスタンスに適切なネットワーク タグがない。
・同一のサービスアカウントを使用するインスタンスのトラフィックを許可するVPCファイアウォールルールがあり、優先度999が設定されている。
インスタンスに適切なネットワークタグがないと、これらのルールはタグに依存してアクセス許可を適用するため、設定されたファイアウォールルールが無効になります。さらに、優先度が 999 のファイアウォール ルールは、優先度が 1000 のファイアウォール ルールよりも優先されます。特定のサービスアカウントを持つインスタンスのトラフィックを許可すると、制限の厳しいタグベースのルールが上書きされ、不要な通信が許可される可能性があります。
不正解の説明:
オプション: Compute Engine インスタンスはすべて 1 つの共有サブネット内にあります。
その理由は、1 つの共有サブネット内にあるため、適切に構成された VPC ファイアウォール ルールが適用されていれば、インスタンス間の無制限のトラフィックを本質的に許可しません。
オプション: Compute Engine インスタンスは、同一のネットワーク ルーティングで設定されています。
同一のネットワークルーティングで設定されたインスタンスは、それ自体は問題ではありません。制約は、通常、ルーティング構成ではなく、ファイアウォール規則によって使用されます。
オプション: VPC ファイアウォールルールは、優先度 1001 で設定された同じサービスアカウントを使用するインスタンスのトラフィックを許可するように設定されています。
優先度が 1001 の VPC ファイアウォールルールは、優先度が 1000 の VPC ファイアウォールルールの後に評価されるため、セグメンテーションを適用するために設定されたファイアウォールルールは上書きされません。
参考：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/vpc/docs/using-firewalls
https://cloud.google.com/vpc/docs/vpc-networks-and-firewalls#priority
</div></details>

### Q.  問題23: 未回答
コンプライアンス チームは、Google Cloud Storage バケットでホストされている独自の知的財産を保護するための多層的なセキュリティ戦略を打ち出しています。チームの具体的な条件は次のとおりです。
- 企業プロジェクト A 内の Cloud Storage バケットは、製造プロジェクト B からの読み取りオペレーションを排他的に許可する必要があります。
- 企業プロジェクト A 内の Cloud Storage バケットには、外部からアクセスできません。
- Cloud Storage バケット内の知的財産は、許可されていない外部の Cloud Storage バケットに譲渡してはなりません。
コンプライアンスチームはどのような行動を取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、外部アクセスを許可することなく、さまざまなプロジェクト間で Cloud Storage バケット内の専有データを保護するための厳格なセキュリティ要件に準拠するために、Google Cloud 内に正確なアクセス管理スキームを実装する能力を評価します。
重要な用語:
VPC Service Controls: ユーザーが Google Cloud リソースの周囲にセキュリティ境界を定義してデータ流出のリスクを軽減できる高度なセキュリティ機能。これにより、他の Google Cloud サービスや外部ネットワークへのリソースへのアクセスが制限されます。
セキュリティ境界: Google Cloud リソースを包含し、境界に含まれるリソースとの間のデータフローを制御する VPC Service Controls 内の仮想境界。
正解解説:
(オプション)
・VPC Service Controls を実装し、企業プロジェクト A と製造プロジェクト B を網羅するセキュリティ境界を確立し、境界設定内の保護対象サービスのリストに Cloud Storage サービスを追加します。
この選択では、VPC Service Controls を活用して、定義されたセキュリティ境界内で機密データを分離して保護する堅牢な境界を作成します。企業プロジェクト A と製造プロジェクト B の両方を含むセキュリティ境界を設定し、この境界内でのみ Cloud Storage サービスを許可することで、Cloud Storage に保存されているデータにコンプライアンス要件に従ってのみアクセスできるようにし、外部からの不正アクセスや他の外部 Cloud Storage バケットへのデータ転送を防止します。
不正解の説明:
オプション: 組織のポリシーを適用して特定のドメインへの共有を制限し、均一なバケットレベルのアクセスを使用するように Cloud Storage バケットを設定します。
この選択が間違っている理由は、共有を特定のドメインに制限する組織のポリシーでは、問題のプロジェクト外への不正なデータ転送に対する保護が不十分であるためです。Cloud Storage サービスに必要な分離は作成されません。
オプション: 企業プロジェクト A と製造プロジェクト B の両方に限定公開の Google アクセスを設定し、厳格なファイアウォール構成で補完して、これらのプロジェクト間でのみネットワークのやり取りを可能にします。
この選択が間違っている理由は、限定公開の Google アクセスを設定しても、外部 IP なしで Google サービスへのアクセスを許可するだけで、外部 Cloud Storage バケットへのデータ流出を防ぐことも、2 つのプロジェクト専用のアクセスを制限することもできないためです。
オプション: 企業プロジェクト A と製造プロジェクト B の VPC 間に VPC ネットワーク ピアリングを設定し、これら 2 つのプロジェクト ネットワーク間のトラフィックのみを厳密に許可するファイアウォール ルールを適用します。
この選択が間違っている理由は、VPC ネットワーク ピアリングはプライベート ネットワーク接続を容易にし、ファイアウォール境界はネットワーク トラフィックを制御しますが、承認されていない外部 Cloud Storage バケットへのデータ転送の可能性を防ぐことはできないためです。
参考：
https://cloud.google.com/vpc-service-controls/docs
https://cloud.google.com/storage/docs/uniform-bucket-level-access
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-domains
</div></details>

### Q.  問題24: 未回答
医療データ処理アプリケーション用の安全なコンテナを構築するプロセスにおいて、構築フェーズに含めることが推奨される 2 つのプラクティスはどれですか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、医療アプリケーションのコンテナを構築する際、特にビルドフェーズで、セキュリティのベストプラクティスに関する知識を評価します。セキュリティを強化するために、コンテナの分離とミニマリズムの原則に焦点を当てています。
重要な用語:
コンテナの分離: 各コンテナが 1 つのアプリケーションまたはプロセスを実行し、1 つのコンテナの問題が他のコンテナに影響を与えるのを防ぎ、攻撃対象領域を制限するセキュリティ原則。
ミニマリスト・コンテナ・イメージ:特定のアプリケーションを実行するために必要なコンポーネントのみをコンテナ内に含めることで、脆弱性や潜在的なエクスプロイトのリスクを軽減します。
正解解説:
(オプション)
・単一の医療データ処理アプリケーションをコンテナ内にカプセル化する。
・アプリケーションが必要としない余計なユーティリティを排除します。
単一の医療データ処理アプリケーションを独自のコンテナ内にカプセル化することは、分離を確実にし、セキュリティ侵害の潜在的な影響を制限するため、ベストプラクティスです。さらに、アプリケーションで必要のない無関係なユーティリティをコンテナから排除することで、攻撃対象領域が縮小され、安全性が高まります。これらのプラクティスは、コンテナセキュリティに対する最小限のアプローチの一部であり、脆弱性と潜在的な攻撃ポイントを最小限に抑えることを目的としています。
不正解の説明:
オプション: アプリケーションが PID 1 で動作するように構成されていないことを確認します。
PID 1 を使用してコンテナー化されたアプリケーションを実行することは、アプリケーションがシグナルを適切に処理できるようにするための一般的な方法です。この選択は、ビルド フェーズ中のコンテナーのセキュリティや効率とは直接関係ありません。
オプション: 医療アプリケーション用に、パブリックにアクセス可能なコンテナー ベース イメージに依存します。
パブリックにアクセス可能なコンテナーの基本イメージには脆弱性が含まれている可能性があり、医療アプリケーションに必要な厳格なセキュリティ規制に準拠していない可能性があるため、この方法は安全なコンテナーを構築するにはお勧めできません。
オプション: コンテナー イメージ内に複数のレイヤーを使用して、機密データを隠蔽します。
コンテナー イメージ内で複数のレイヤーを使用しても、機密データは適切に隠されません。隠蔽によるセキュリティは推奨される方法ではなく、適切なデータ処理と暗号化の基本的なニーズには対応していません。
参考：
https://cloud.google.com/container-registry/docs/managed-base-images
https://cloud.google.com/build/docs/building/containers
https://cloud.google.com/solutions/best-practices-for-building-containers
</div></details>

### Q.  問題25: 未回答
あなたは、Google Cloud でホストされている医療アプリケーションのうち、厳しいセキュリティ規制に該当するアプリケーションのコンプライアンス責任者です。役割には、ドメイン内のアクセス管理の監視が含まれます。コンプライアンスチェックが近づくと、権限割り当ての文書化された証明をまとめる作業が課せられます。
このタスクに最も適した Google Cloud ユーティリティはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
このシナリオでは、厳格なセキュリティ規制に準拠する必要がある医療アプリケーションの権限割り当てを文書化して証明するための最適な Google Cloud ユーティリティを見つけることに重点を置いています。このツールは、コンプライアンス担当者の監査および報告要件を容易にする必要があります。
重要な用語:
Policy Analyzer: Google の Cloud IAM スイートの一部である Policy Analyzer は、クラウド リソース全体のアクセス ポリシーのレポート作成と分析を可能にし、コンプライアンスと監査対応の維持に不可欠です。
監査ログ: クラウド環境内の管理アクティビティとアクセスを記録するログ。これらは、セキュリティ調査やコンプライアンス監査での分析に使用されます。
正解解説:
(オプション)
・ポリシーアナライザー
Policy Analyzer は、ユーザーが Google Cloud のリソース全体で誰がどのアクセス権を持っているかをクエリして表示できるため、この仕事に適したツールです。これは、監査可能な形式で文書化されたアクセス許可の割り当ての証明を取得できるため、コンプライアンス チェックに役立ちます。これは、アクセス許可が最小特権の原則に準拠し、アクセス ポリシーがコンプライアンス要件に準拠していることを確認するのに役立つため、厳しいセキュリティ規制下にあるアプリケーションに特に役立ちます。
不正解の説明:
オプション: ポリシーのトラブルシューティング ツール
Policy Troubleshooter が正しくない理由は、ユーザーがリソースにアクセスできる理由を理解したり、アクセスできない理由をトラブルシューティングしたりするために使用されるためです。コンプライアンスの目的でアクセス許可の割り当てを文書化するためのレポートは作成されません。
オプション: IAM レコメンダー
IAM Recommender が正しくない理由は、監査のために既存のアクセス許可を文書化するのではなく、アクセスパターンを分析し、必要に応じてより制限の厳しいロールを提案することで、主にアクセス許可の最適化を支援するためです。
オプション: Policy Simulator
Policy Simulator が間違っている理由は、その主な目的が、既存の権限割り当てを文書化して証明することではなく、仮想的な IAM ポリシーの変更がリソースへのアクセスに及ぼす潜在的な影響をテストすることであるためです。
参考：
https://cloud.google.com/iam/docs/policy-analyzer
https://cloud.google.com/iam/docs/managing-policies#analyzing_permissions
https://support.google.com/cloud/answer/10324190
</div></details>

### Q.  問題26: 未回答
ある医療機関は、機密性の高い患者情報をバージョン管理システム内にプレーンテキストで保存しないようにしたいと考えています。
Google Cloud でこの機密データを保護するための推奨される方法は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 環境内で機密データを管理するためのベスト プラクティス、特にデータのセキュリティとコンプライアンスを確保しながら、バージョン管理システム内のプレーンテキスト ストレージを回避する方法について、受験者が理解するかどうかが問われます。
重要な用語:
顧客管理の暗号鍵(CMEK): CMEK を使用すると、ユーザーは暗号鍵を作成、制御、使用して Google Cloud サービスに保存されているデータを保護できるため、機密情報のセキュリティを強化できます。
正解解説:
(オプション)
・CMEK(Customer-Managed Encryption Key)でデータを暗号化し、Cloud Storageに保存
CMEK は保存データのセキュリティを大幅に向上させる方法を提供するため、この選択は適切です。医療機関は、機密データを Google Cloud Storage に保存する前に、顧客が管理する鍵で暗号化することで、バージョン管理システムへの不正アクセスがあった場合でも、機密データのプレーンテキスト表現が公開されないようにします。
不正解の説明:
オプション: Cloud Source Repositories を利用してコードのバージョンを管理しながら、機密情報を Cloud Spanner に保持します。
この選択が間違っている理由は、Cloud Source Repositories はコードのバージョンを管理するための GCP 上のプライベート Git リポジトリですが、機密情報を Cloud Spanner に保存しても、プレーンテキストであることが妨げられず、バージョン管理戦略と統合されないためです。
オプション: Cloud Data Loss Prevention API を実装して機密情報を評価し、Cloud Firestore に保持します。
この選択が間違っている理由は、Cloud Data Loss Prevention API はデータセット内の機密情報を識別して難読化できますが、保存中またはバージョン管理中のデータを暗号化するためのソリューションではないため、機密データがプレーンテキストで公開される可能性があるためです。
オプション: 永続ディスクを使用してバージョン管理システムを Compute Engine インスタンスに移行し、プリエンプティブル インスタンスを選択します。
この選択が間違っている理由は、バージョン管理システムを Compute Engine に移行するだけでは、機密データの暗号化という中核的な問題に対処できないためです。プリエンプティブルインスタンスを使用すると、コンピューティングリソースのコストが削減されますが、目前のセキュリティ上の懸念とは無関係です。
参考：
https://cloud.google.com/kms/docs/encrypt-decrypt
https://cloud.google.com/storage/docs/encryption/customer-managed-keys
https://cloud.google.com/solutions/secrets-management
</div></details>

### Q.  問題27: 未回答
ある医療機関は、ラボ サービス プロバイダと統合して、Compute Engine で患者データ分析プラットフォームを開発しています。医療機関は Google Cloud 組織で処理レイヤを設計し、ラボ サービス プロバイダは別の Google Cloud 組織内のデータレイヤに注力しています。これは健康データ関連のプラットフォームであるため、これらのレイヤー間のデータ転送はセキュリティで保護され、パブリックインターネットを経由してはなりません。
どの接続オプションを適用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、転送中の機密性の高い患者データのプライバシーを確保しながら、コンプライアンスに準拠した医療データ処理プラットフォームを設計する目的で、Google Cloud 組織間の安全なネットワーク接続オプションに関する理解度を評価します。
重要な用語:
VPC ピアリング: Google の内部ネットワークを使用して、パブリック インターネットを経由することなく、異なるプロジェクトや組織の仮想プライベート クラウド(VPC)間でプライベート ネットワーク トラフィックを流すことができます。
データ層:通常、データが格納および管理される多層アーキテクチャ内のデータベースまたはストレージ層を指します。
処理レイヤー: データが分析、処理、または変換されるデータ処理アーキテクチャの論理パーティション。
健康データのコンプライアンス: 医療関連データの保存、処理、送信を管理する HIPAA などの法律や規制の遵守を指します。
正解解説:
(オプション)
・VPCピアリング
VPC ピアリングは、トラフィックのプライバシーと Google のネットワーク内を維持しながら、2 つの Google Cloud 組織を安全に接続するための適切な選択肢です。パブリック インターネットを利用するオプションや 1 つの組織に限定されるオプションとは異なり、VPC ピアリングを使用すると、医療機関とラボ サービス プロバイダーが VPC を直接相互接続できるため、インターネットに公開されることなく VPC 間でデータを移動できます。これにより、安全なデータ転送方法を必要とする医療データ規制への準拠が保証され、提示されたシナリオに最適です。
不正解の説明:
オプション:クラウドVPN
転送中のデータを暗号化しているにもかかわらず、このシナリオでクラウド VPN が最適な選択ではない理由は、健康データをパブリック ネットワークから遠ざけるという厳格な要件に準拠していない接続を確立するためにパブリック インターネットを利用するためです。
オプション:クラウドインターコネクト
Cloud Interconnect は、インフラストラクチャを Google Cloud に接続する方法を提供しますが、大量のデータ転送を目的としており、異なる Google Cloud 組織間にプライベート ネットワーク リンクを作成することを目的としていないため、要件を満たしていません。
オプション:共有VPC
共有 VPC は、同じ組織内の複数のプロジェクトがネットワーク リソースを共有できるように設計されており、異なる組織間で VPC を接続するのには適していません。
参考：
https://cloud.google.com/vpc/docs/vpc-peering
https://cloud.google.com/network-connectivity/docs/vpc-peering/how-to/setting-up-vpc-peering
https://cloud.google.com/architecture/building-internet-connectivity-for-private-vms
</div></details>

### Q.  問題28: 未回答
モニタリング指標を Google Cloud から社内の分析プラットフォームに効率的に送信するには、どうすればよいでしょうか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、Google Cloud の指標をモニタリングするための効率的なデータ転送方法を外部分析プラットフォームに深く理解しているかどうかを評価することを目的としています。既存の Google Cloud サービスを活用してプロセスを合理化すると同時に、スケーラビリティとリアルタイム分析機能を実現することに重点を置いています。
重要な用語:
Monitoring Sinks: Google Cloud Monitoring 内の機能で、特定のログを他の宛先(Cloud Pub/Sub、BigQuery、Cloud Storage など)にエクスポートする方法を指定するシンクを作成できます。
Cloud Pub/Sub: スケーラブルで耐久性のあるイベント取り込みおよび配信システムであり、イベントベースのシステムとストリーミング分析パイプラインを構築するための基盤として機能します。
データフロー: ストリームとバッチのデータ計算に使用される、フルマネージドのサーバーレスでワークロードに最適化されたデータ処理サービス。これは通常、データストリームをリアルタイムで収集および分析するために使用されます。
SNMP:簡易ネットワーク管理プロトコルは、IPネットワーク上のサーバー、ワークステーション、ルーター、スイッチなどのノードを管理するように設計されたネットワーク管理用のプロトコルです。
正解解説:
(オプション)
・プロジェクト間のモニタリング シンクを構成して、指標を Cloud Pub/Sub トピックにエクスポートし、Dataflow を使用して分析プラットフォームに処理します。
この選択は、Google Cloud 内でモニタリング データのエクスポートを処理するための効率的でスケーラブルな方法を示しています。プロジェクト間でモニタリング シンクを構成することで、指標を 1 つの Cloud Pub/Sub トピックに統合できます。Cloud Pub/Sub は、可用性と拡張性に優れたイベント取り込みサービスを提供します。Dataflow は、トピックのデータをシームレスに利用して処理し、社内の分析プラットフォームに整理的かつタイムリーに配信することで、リアルタイムのストリーミング分析を可能にします。
不正解の説明:
オプション: SNMP などの標準プロトコルを使用して、すべてのメトリックを分析プラットフォームに直接ストリーミングします。
この選択が間違っている理由は、SNMPなどのプロトコルを使用してすべてのメトリックを直接ストリーミングすると、大規模に非効率的になる可能性があるためです。Google Cloud のモニタリング データのエクスポート方法と互換性がない可能性があり、パフォーマンスのボトルネックや、データ変換とストリーミングの処理の複雑さの増大につながる可能性があります。
オプション: 個々のプロジェクトの指標記述子を設定して、すべての指標を共有 BigQuery データセットにエクスポートし、分析プラットフォームで取得できるようにします。
この選択が間違っている理由は、指標を BigQuery にエクスポートするように個々の指標記述子を設定することは、リアルタイム分析にとって最も効率的ではなく、すべての指標を BigQuery に保存することで不要なコストが発生する可能性があるためです。
オプション: 分析プラットフォームが Google Cloud Monitoring API からすべての指標をオンデマンドで取得できるようにするカスタム アダプタを開発します。
この選択が間違っている理由は、カスタム アダプターの開発に関連する潜在的なスケーラビリティとパフォーマンスの問題によるものです。このアプローチでは、かなりのレイテンシが発生する可能性が高く、Google Cloud Monitoring API からのオンデマンド フェッチはリアルタイム分析に適していません。
参考：
https://cloud.google.com/pubsub/docs
https://cloud.google.com/logging/docs/export
https://cloud.google.com/dataflow/docs/guides/templates/provided-streaming#cloudpubsubsubscriptiontobigquery
</div></details>

### Q.  問題29: 未回答
Basic ネットワーク サービス階層を利用しながら、デフォルトで元のクライアント IP アドレスを保持するには、どの Google Cloud ロードバランサを構成する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、発信元クライアントの IP アドレスを本質的に保持する適切な Google Cloud ロードバランサの選択に関する知識を評価します。ロード バランサーの機能とサービス レベルを理解することに重点が置かれています。
重要な用語:
ネットワーク サービス階層: Google Cloud のネットワーク サービス階層は、パフォーマンスとコストの観点からネットワークの品質を定義します。Basic レベルは費用対効果が高く、Premium レベルはより高いパフォーマンスを提供します。
発信元クライアント IP の保持: 負荷分散のコンテキストでは、発信元クライアント IP アドレスを保持することで、宛先サーバーは要求が開始された実際の IP アドレスを確認でき、セキュリティと分析にメリットがあります。
正解解説:
(オプション)
・TCP/UDPネットワークロードバランサ
TCP/UDP Network Load Balancer は、OSI モデルのレイヤー 4 で動作し、クライアント IP を変更せずに負荷分散を実行するため、発信元のクライアント IP アドレスを保持する必要がある場合に適しています。また、Google Cloud の基本的なネットワーク サービス階層と互換性があるため、ターゲットの仮想マシン インスタンスへの直接アクセス機能を確保しながら、費用対効果の高いソリューションになります。
不正解の説明:
オプション: SSL プロキシー・ロード・バランサー
SSL Proxy Load Balancer が不適切な選択である理由は、プレゼンテーション層で動作し、SSL オフロード用に設計されているためです。SSL接続を終了するため、デフォルトではクライアントIPは保持されず、バックエンドサービスを公開することなくHTTPSトラフィックの負荷分散が可能になります。
オプション: TCP プロキシ ロード バランサー
TCP Proxy Load Balancer が誤った選択である理由は、OSI モデルのレイヤー 7 での動作にあります。これは、TCPトラフィックのグローバルロードバランシングのニーズに対応し、デフォルトではクライアントIPを保持しないロードバランシングレイヤーでクライアント接続を終了します。
オプション:内部TCP/UDPロードバランサー
内部 TCP / UDP ロードバランサは、その名前が示すように、同じ VPC ネットワーク内の内部負荷分散を目的としており、外部トラフィックに対して発信元のクライアント IP アドレスを保持する必要があるユースケースを伴わないため、正しい選択ではありません。
参考：
https://cloud.google.com/load-balancing/docs/network
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
</div></details>

### Q.  問題30: 未回答
機密性の高い金融プロジェクトのサービス アカウント キーが、いくつかのオープンソース ドキュメント サイトで誤って開示されています。アクティビティレコードを調べたところ、キーが一時的なアクセストークンの取得に使用されていることがわかりました。サービス アカウントのアクセス許可を遅滞なく無効にすることが重要です。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、リスクの高いプロジェクトの Google Cloud サービス アカウント キーが侵害された場合の適切な対応を評価します。機密性の高い資格情報の漏洩後の不正アクセスを防ぐために必要な即時修復アクションの知識をテストします。
重要な用語:
サービス アカウント キー: プログラムで Google Cloud サービスにアクセスするために使用される認証情報。これはサービス アカウントに関連付けられており、コード自体を認証および承認する必要があるシナリオで使用されます。
アクセス トークン: Google の OAuth 2.0 サーバーによって生成され、認証プロセスで使用され、アプリケーションがユーザーまたはサービス アカウントに代わって一定期間動作できるようにします。
キーの無効化: これには、サービス アカウントに関連付けられた資格情報を無効化または取り消して、それ以上使用できないようにすることが含まれ、侵害されたキーを使用して新しいアクセス トークンを取得できないようにします。
正解解説:
(オプション)
・対象となるサービスアカウントを削除します。
この選択は、影響を受けるサービス アカウントの悪用を防ぐための最も迅速で効果的な方法です。サービスアカウントを削除すると、漏洩したキーを含むすべての関連キーが無効になり、サービスアカウントはリクエストの認証や新しいアクセストークンの生成に使用できなくなります。このアクションにより、攻撃者は侵害された認証情報を使用して Google Cloud リソースにアクセスできなくなります。
不正解の説明:
オプション: 公開されているサービス アカウント キーを非アクティブ化します。
この選択が正しくない理由は、キーを非アクティブ化しても、サービス アカウントの継続的な悪用の可能性を防げないためです。攻撃者は、キーが非アクティブ化された後でもアクティブなままのアクセス トークンを生成した可能性があります。
オプション: サービス アカウントの資格情報が自動的に期限切れになるのを待ちます。
この選択が間違っている理由は、状況の緊急性を無視しているからです。待機すると、資格情報が自然に期限切れになるまで継続的な不正アクセスが許可され、データ侵害やリソースの悪用につながる可能性があります。
オプション: 影響を受けるサービス アカウント キーの新しい資格情報を作成します。
この選択が間違っている理由は、新しい資格情報を作成しても差し迫ったリスクが解決されないためです。公開された鍵は引き続き有効であるため、攻撃者はその鍵を使用して認証を行い、Google Cloud サービスにアクセスする可能性があります。
参考：
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/iam/docs/granting-changing-revoking-access
</div></details>

### Q.  問題31: 未回答
ある医療機関は、既存のオンサイト データ管理アプリケーションから Google Workspace に移行しています。以前は、医療規制で義務付けられている特定のネットワークセキュリティプロトコルがありました。同社のコンプライアンスチームは、クラウドへの移行もこれらの厳格なネットワークセキュリティ基準に準拠していることを確認することに重点を置いています。セキュリティ コンサルタントは、Google Cloud の移行に、Google との分散責任の一部として同じレベルのネットワーク セキュリティが含まれるようにする任務を負っています。
ネットワークセキュリティガイドラインへの準拠を確実にするのに役立つ対策はどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、医療機関が Google Workspace に移行する際にネットワーク セキュリティ コンプライアンスを維持するために必要な手順について説明します。これは、Google が提供する SaaS ソリューションへの移行において、既存のネットワーク セキュリティ プロトコルを確実に遵守するコンサルタントの責任に焦点を当てています。
重要な用語:
SaaS (Software as a Service):アプリケーションをベンダーまたはサービスプロバイダーがホストし、ネットワーク(通常はインターネット)を介して顧客が利用できるようにするソフトウェア配布モデル。
分散責任モデル: クラウド コンピューティングでは、これは、クラウド サービス内のセキュリティ制御の実装と管理について、クラウド サービス プロバイダーと顧客の間で共有される責任です。
法規制の遵守:組織のビジネスプロセスに関連する法律、規制、ガイドライン、および仕様を順守します。医療の場合、これには多くの場合、厳格なデータ保護とネットワークセキュリティ対策が含まれます。
正解解説:
(オプション)
・ネットワーク セキュリティは本質的にソリューションの一部であり、Google Workspace などのサービスとしてのソフトウェア(SaaS)サービスに対する Google Cloud の責任にあります。
Google Workspace のような SaaS モデルでは、クラウド プロバイダーである Google がネットワーク セキュリティを含むセキュリティとインフラストラクチャに責任を持つため、この選択は正確です。Google Workspace をご利用のお客様は、医療に特有の規制を含む、グローバルおよび業界固有の規制に準拠して構築された Google の堅牢なセキュリティ モデルを継承しています。セキュリティ コンサルタントの役割には、Google 固有のセキュリティ対策が会社の既存のプロトコルを満たしているか、上回っているかを確認することが含まれます。
不正解の説明:
オプション: 現在のセキュリティ基準に合わせて、組織内にファイアウォール規則を実装します。
これが間違っている理由は、ファイアウォールはネットワーク セキュリティの重要な部分ですが、SaaS サービスである Google Workspace のコンテキストでは、基盤となるネットワーク セキュリティの管理は、個々のクライアント側のファイアウォール ルールではなく Google によって処理されるためです。
オプション: Google Cloud Armor を導入して、Google Workspace に合わせたネットワーク セキュリティ制御を管理します。
これが間違っている理由は、Google Cloud Armor は、Google Workspace などの SaaS アプリケーションではなく、Google Cloud で実行されているアプリケーションを保護するように設計されているためです。DDoS 防御とウェブ アプリケーション ファイアウォール機能は、Google Workspace サービスではなく、Google Cloud 上のアプリケーションに提供します。
オプション:仮想プライベートクラウド(VPC)ネットワークのネットワークを確立して、医療規制で規定されているネットワークセキュリティを強化します。
これが間違っている理由は、仮想プライベートクラウド(VPC)ネットワークの確立は、Compute Engine や Kubernetes Engine などの Google Cloud サービスのインフラストラクチャ管理に関連しており、Google Workspace には適用されないためです。VPC は、Google が提供する SaaS アプリケーションにネットワーク セキュリティを適用することはできません。
参考：
https://cloud.google.com/security
https://cloud.google.com/docs/security/best-practices
Hatps://support.google.com/a/answer/7587183?hl=n
</div></details>

### Q.  問題32: 未回答
あるマーケティング代理店は、分散したチームが Google Cloud にデプロイされたカスタム広告ダッシュボードに安全にアクセスできるようにしたいと考えています。現在、ダッシュボードは、機関の内部ネットワーク内でのみアクセスするように制限されています。この機関は、多要素認証もサポートする追加の認証レイヤーを使用して、インターネットに公開するソリューションを求めています。
これらの要件を満たすには、マーケティング エージェンシーはどの Google Cloud プロダクトを使用すべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、多要素認証のサポートに重点を置き、内部ダッシュボードへの安全で認証されたインターネット公開アクセスを提供するために、最も適切な Google Cloud プロダクトを選択する上級学習者の能力を調べます。
重要な用語:
Cloud Identity-Aware Proxy: Google Cloud で実行されているアプリケーションへのアクセスを制御するための Google Cloud サービスで、VPN なしでアクセス ポリシーの適用と多要素認証の使用を可能にします。
正解解説:
(オプション)
・クラウドID対応プロキシ
Cloud Identity-Aware Proxy(IAP)を使用すると、Google Cloud でホストされているアプリケーションにアクセスできるユーザーを制御できるため、この選択は要件に適しています。IAPを採用することで、マーケティングエージェンシーはアクセス制御ポリシーを簡単に適用し、ダッシュボードに追加の認証レイヤーを実装できます。多要素認証をサポートしているため、従来のVPNソリューションを必要とせずに、アクセスを安全かつ認証済みにすることができます。IAPはアプリのゲートキーパーとして機能し、ユーザーのIDを検証し、ユーザーが代理店によって設定されたアクセスポリシーを満たしていることを確認します。
不正解の説明:
オプション:Cloud Armor
Cloud Armor が間違っている理由は、主に Google Cloud で実行されているアプリケーションに対して DDoS 保護とウェブ アプリケーション ファイアウォール(WAF)機能を提供しているためです。アプリケーションを攻撃から保護するために使用されますが、アクセス制御や認証機能は提供しません。
オプション:クラウドエンドポイント
Cloud Endpoints が正しくない理由は、Cloud Endpoints が Google Cloud での API の開発、デプロイ、管理に役立つサービスであるためです。API をセキュリティで保護する手段を提供しますが、すぐに使用できる多要素認証はサポートしておらず、ユーザー インターフェイスやダッシュボードへの直接アクセスを提供することには重点が置かれていません。
オプション:クラウドインターコネクト
Cloud Interconnect が正しくない理由は、企業のオンプレミス ネットワークから Google のネットワークへの高性能なエンタープライズ グレードの接続を提供することを目的としているためです。アプリケーションレベルのアクセス制御やユーザー認証機能は提供されません。
参考：
https://cloud.google.com/iap/docs
https://cloud.google.com/identity-platform/docs/web/mfa
Hatps://support.google.com/a/answer/6197438?hl=n
</div></details>

### Q.  問題33: 未回答
Cloud Storage バケット上のデータは、Cloud Key Management Service(KMS)によって制御される鍵を使用して保管時に暗号化する必要があります。これらの鍵に適用される Cloud Identity and Access Management(IAM)の権限は、すべての鍵で統一されている必要があるため、まとめて管理する必要があります。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Cloud KMS を使用して Cloud Storage に保存されているデータの暗号鍵を管理することについて、複数の暗号鍵間で統一されたポリシーを適用するための IAM 権限の一元管理に焦点を当てて、理解度を評価します。
重要な用語:
KeyRing: Google Cloud KMS の暗号鍵を論理的にグループ化したもので、鍵管理を簡素化できます。IAM アクセス許可は、KeyRing レベルで設定して、含まれているすべてのキーに影響を与えることができます。
IAM 権限: Identity and Access Management 権限は、ユーザー、グループ、またはサービス アカウントが Google Cloud リソースに対して実行できるアクションを決定します。これは、KMS キーへのアクセスを制御する上で中心的な役割を果たします。
正解解説:
(オプション)
・すべてのCloud Storageバケットに対して1つのKeyRingを作成し、このKeyRing内にすべてのKeyを含めます。IAM アクセス許可を KeyRing レベルで管理します。
この選択は、IAMの一元管理を可能にするため、複数の暗号化キー間で一貫した権限モデルを維持するための最適なソリューションです。Cloud Storage バケットに必要なすべての鍵を保持する 1 つの鍵リングを作成し、KeyRing レベルで権限を管理することで、すべてのアクセス ポリシーが KeyRing に含まれるすべての鍵に均一に適用されるようになり、一括管理の要件を満たすことができます。
不正解の説明:
オプション: すべての Cloud Storage バケットに対して 1 つのキーリングを作成し、このキーリング内にすべてのキーを含めます。IAM アクセス許可を個々のキーレベルで管理します。
この選択が正しくない理由は、アクセス許可をまとめて管理するのではなく、個々のキー レベルで管理するためです。これは、すべてのキーで統一されたアクセス許可の要件に準拠しておらず、一貫したポリシーの適用を複雑にします。
オプション: Cloud Storage バケットごとに個別の KeyRing を生成し、各 KeyRing に 1 つの Key を保持させます。IAM アクセス許可を個々のキーレベルで管理します。
この選択が間違っている理由は、Cloud Storage バケットごとに個別のキーリングが作成され、権限管理が断片化されているためです。各KeyRingの個別のキーレベルで権限を管理する必要があるため、一括管理の要件を満たしていません。
オプション: Cloud Storage バケットごとに個別の KeyRing を生成し、各 KeyRing に 1 つの Key を保持させます。IAM アクセス許可を KeyRing レベルで管理します。
この選択が間違っている理由は、IAM 権限を KeyRing レベルで管理することを提案しており、これは通常、一括管理に有利ですが、Cloud Storage バケットごとに個別の KeyRing を作成することを提案しているため、失敗します。この不要なセグメンテーションにより、すべてのキーで統一されたアクセス許可管理ができなくなります。
参考：
https://cloud.google.com/kms/docs/encrypting-disks
https://cloud.google.com/iam/docs/granting-roles-to-service-accounts
https://cloud.google.com/compute/docs/disks/customer-supplied-encryption
</div></details>

### Q.  問題34: 未回答
多国籍銀行のコンプライアンス責任者は、Google Cloud のデータガバナンスのセキュリティ プロトコルを監督しています。
認証と承認のメカニズムを設定する際に採用すべきベストプラクティスは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 環境内のデータ ガバナンスのための安全な認証と承認の実践に関する知識を評価します。学習者は、多国籍銀行業務を監督するコンプライアンス担当者に適したベストプラクティスを適用することに挑戦します。
重要な用語:
Cloud Identity: ID とアクセスの管理を提供する Google Cloud サービスで、適切なユーザーがリソースに適切にアクセスできるようにします。
SSO/SAML:Security Assertion Markup Language(SAML)を使用したシングルサインオン(SSO)により、複数のWebアプリケーション間で認証プロセスを一元化できるため、ユーザーは一度ログインするだけで、関連するすべてのサービスに安全にアクセスできます。
事前定義されたロール: 特定のサービスやリソースに合わせてきめ細かな権限を提供するように設計された Google Cloud 内のロールで、最小権限の原則を推進します。
正解解説:
(オプション)
・Cloud IdentityとSSO/SAMLを連携し、セキュアなユーザー認証と効率的なユーザーアカウント管理を実現します。
・あらかじめ定義されたロールできめ細かな権限を付与し、厳重なアクセス制御を維持
Cloud Identity と SSO / SAML の統合は、ユーザー認証を簡素化し、多国籍銀行システム全体のセキュリティを強化し、安全で効率的なユーザー アカウント管理を促進する堅牢な戦略です。事前定義されたロールを使用して微調整された権限を割り当てることは、データガバナンスのベストプラクティスに沿った厳格なアクセス制御を維持するために重要であり、過剰な権限や潜在的なセキュリティ侵害のリスクを最小限に抑えます。
不正解の説明:
オプション: Google Cloud のデフォルトのデータ暗号化方式を使用します。
この選択が間違っている理由は、Google Cloud では保存中および転送中のデータを保護するためにデフォルトのデータ暗号化を提供していますが、コンプライアンスには通常、デフォルトの暗号化方法を超える追加の認証および承認手段が必要であるためです。
オプション: Google Cloud にユーザーを個別に直接追加します。
この選択が間違っている理由は、ユーザーを個別に Google Cloud に直接追加することはスケーラブルではなく、管理が複雑になり、特に大規模な組織では、安全で効率的なユーザー アカウント管理に悪影響を及ぼす可能性があるためです。
オプション: 一般的な方法として、Google の Identity and Access Management(IAM)を使用してユーザーに一般的な役割を割り当てます。
この選択が正しくない理由は、ユーザーに一般的なロールを割り当てることは、最小特権のベスト プラクティスに従っておらず、不要なアクセス許可を付与し、データ ガバナンス フレームワーク内の潜在的なセキュリティの脆弱性につながる可能性があるためです。
参考：
https://cloud.google.com/identity/saml
https://cloud.google.com/iam/docs/using-predefined-roles
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題35: 未回答
あなたの会社は Google Cloud を導入しており、財務部門のセキュリティを重視しています。セキュリティを強化するには、特定のプロジェクト内の財務分析 Google Kubernetes Engine(GKE)クラスタで認証されたコンテナ イメージのみが使用されるようにすることを目指しています。これらのコンテナーは、信頼できる機関によって検証された規制対象のコンテナー レジストリから作成する必要があります。
どの手順を踏む必要がありますか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、認証されたコンテナ イメージのみが使用されるようにすることで、GKE 環境内のコンテナ セキュリティを強化することについての受験者の知識を評価します。これは、組織のポリシーレベルでのセキュリティの実装と、イメージの有効性の適用を中心に展開します。
重要な用語:
組織ポリシーの制約: 組織ポリシーの制約を使用すると、企業は GCP 環境内のリソース全体に適用されるポリシーを構成し、コンプライアンスとセキュリティの設定を管理するためのガバナンスのレイヤーを追加できます。
Binary Authorization: Binary Authorization は、イメージが特定の基準を満たし、使用前に当局によって承認されることを要求することで、信頼できるコンテナ イメージのみが GKE にデプロイされるようにするセキュリティ制御です。
構成証明: 構成証明は、イメージの特定のプロパティまたは承認をアサートするために使用されるコンテナー イメージに関連付けられたメタデータであり、バイナリ承認では、イメージをデプロイできるかどうかを判断するのに役立ちます。
正解解説:
(オプション)
・プロジェクトに適切な組織ポリシーの制約を設定することで、信頼できるイメージの要件を実装します。
・プロジェクトに必要な認証を含むBinary Authorizationポリシーを設定します。
最初のステップでは、コンテナーが信頼できると見なされる条件を指定する組織のポリシーを設定し、信頼できるイメージ要件を効果的に作成します。2 番目の正しい手順であるバイナリ承認ポリシーの確立では、構成証明者が特定の条件が満たされていることを確認し、この検証 (構成証明と呼ばれる) の後にのみ、コンテナー イメージをプロジェクトの Kubernetes クラスターにデプロイできるシステムを設計することで、セキュリティをさらに強化します。これらの対策を組み合わせると、安全で認証されていることがわかっているイメージのみを実行できます。
不正解の説明:
オプション: プロジェクトの Security Command Center (SCC) 内で Container Threat Detection をアクティブ化します。
この選択が間違っている理由は、コンテナ脅威検出がランタイムの脅威を検出するためのツールであり、デプロイ前のイメージ認証用ではないためです。デプロイ後のセキュリティには影響しますが、コンテナー イメージのデプロイ前の承認には影響しません。
オプション: すべての Google Kubernetes Engine(GKE)デプロイでバイナリ認証を義務付けるカスタム組織ポリシーの制約を設定します。
このオプションが正しくない理由は、意図が目標と一致している一方で、バイナリ承認のカスタム組織ポリシー制約を作成することは正しいアプローチではないためです。それよりも、既存のバイナリ承認ポリシーを構成して、適切なコンテナー イメージの検証を確実に行うことが目的です。
オプション: クラスタの「PodSecurityポリシー」を「制限付き」レベルにオンにします。
この選択が間違っている理由は、PodSecurityポリシーが、ポッドをクラスタ内で実行するために準拠する必要があるセキュリティ標準を定義するためのものです。これらは、認証されたコンテナー イメージのみがデプロイされるようにするのではなく、ポッドのランタイム環境に重点を置いています。
参考：
https://cloud.google.com/binary-authorization/docs
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/kubernetes-engine/docs/how-to/binary-authorization
</div></details>

### Q.  問題36: 未回答
現在のホスティング契約の終了が間近に迫っているため、次の会計四半期中に、期限切れの課金システムを組織のオンプレミス サーバーから Google Cloud に移行する必要があります。アプリケーションのネットワークポートの使用状況は不明であり、これを明確にするドキュメントは存在しません。移行が安全であり、運用の安定性を損なわないようにする任務があります。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud への移行戦略の理解度を評価するもので、移行プロセス中にセキュリティと運用の安定性を維持しながら、既存のドキュメントなしでネットワークの使用状況を特定する必要があります。
重要な用語:
リフト&シフト: アプリケーションを再設計することなく、アプリケーションをある環境から別の環境に移動する移行戦略。レガシーシステムをクラウドに移行するためによく使用されます。
VPCファイアウォール:仮想プライベートクラウド用の分散型ステートフルファイアウォールサービスで、ネットワーク境界に出入りするトラフィックの種類をネットワークセキュリティで制御します。
VPC フローログ: VM インスタンスとの間で送受信されるネットワークフローのサンプルを記録し、ネットワークの監視、フォレンジック、セキュリティに役立てます。
専用プロジェクト: セキュリティ、請求、管理の目的でリソースとサービスを異なるプロジェクトに分離する Google Cloud の組織構造。
正解解説:
(オプション)
・「リフト&シフト」戦略による専用プロジェクトへの課金システムの移行VPC ファイアウォール設定内のすべての内部 TCP トラフィックを許可します。VPC フローログをモニタリングして、システムの機能に必要なトラフィック権限を特定します。
この選択はプロアクティブでセキュリティを重視したもので、「リフト&シフト」アプローチを使用して、最小限の変更で請求システムを専用の Google Cloud プロジェクトに移行します。最初にすべての内部 TCP トラフィックを許可すると、サービスの中断を回避できます。VPCフローログの監視は、使用されているネットワークポートを識別し、必要なトラフィック権限を正確にファイアウォール設定に微調整できるため、セキュリティと機能のバランスをとることができるため、非常に重要です。
不正解の説明:
オプション:カスタムネットワークで「リフト&シフト」戦略を使用して、請求システムを専用プロジェクトに移行します。すべての VPC 内部トラフィックをブロックし、ファイアウォールログを参照して、システムの操作に必要なトラフィック権限を特定します。
この選択が正しくない理由は、すべての VPC 内部トラフィックを最初にブロックすると、サービスまたはコンポーネント間の必要な通信が中断され、運用上の問題が発生する可能性があるためです。権限が調整されるまで課金システムが動作しない可能性が高く、運用の安定性が損なわれます。
オプション: Google Kubernetes Engine(GKE)を使用して、課金システムをコンテナ化された設計に再設計します。ファイアウォールルールを使用して、クラスタへのすべての外部通信を禁止します。VPC フローログを分析して、システム全体の運用に必要なトラフィック権限を特定します。
この選択が間違っている理由は、従来の請求システムの再設計とコンテナ化に必要な複雑さと時間によるもので、次の会計四半期の制約内では実現不可能です。また、アプリケーションのニーズを知らずにすべての外部通信をブロックすると、その機能が中断される可能性があります。
オプション: 別のプロジェクト内で Cloud Functions を使用して、課金システムをサーバーレス モデルに変換します。ファイアウォールルールを使用して、プロジェクトへのすべての受信トラフィックを制限します。VPC フローログを検査して、システムを正しく実行するために不可欠なトラフィック権限を解読します。
この選択が間違っている理由は、ネットワークの依存関係を完全に理解していない複雑な課金システムに Cloud Functions を使用するのが不適切であることにあります。さらに、最初にすべての受信トラフィックを制限すると、システムが必要な操作を実行できなくなる可能性があります。
参考：
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/architecture/vm-migration-validation-with-Google Cloud-migration-landing-zone (クラウド移行ランディングゾーン)
</div></details>

### Q.  問題37: 未回答
あなたの会社は、継続的インテグレーションとデプロイ(CI/CD)プロセスのオーケストレーションにGitLab Runnersを利用しています。これらの CI / CD ワークフローから Google Cloud サービスへの安全な接続を確保する必要があります。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、GitLab Runners を使用して CI / CD ワークフローから Google Cloud サービスへの接続を保護するための知識を評価します。セキュリティ対策を損なうことなく、Google の ID およびアクセス管理と統合する安全な認証方法を確立することに重点を置いています。
重要な用語:
Workload Identity フェデレーション: サービス アカウント キーを使用するのではなく、外部の ID プロバイダに依存して、ネイティブの認証情報を使用して Google Cloud サービスでアプリケーションを認証できるようにする機能。
外部 ID プロバイダー: ユーザー認証を提供するサードパーティ サービス。Workload Identity フェデレーションは、Google Cloud リソースへのアクセスを許可する前に、GitLab などのプロバイダを使用してユーザーまたはサービスを認証します。
サービス アカウント キー: Google Cloud リソースにアクセスするときにアプリケーションやサービスの認証に使用できる、サービス アカウント用に Google Cloud が提供する暗号化キー。
環境変数: 実行中のプロセスがコンピューター上でどのように動作するかに影響を与える可能性のある動的な名前付き値。CI/CD の場合、構成設定と資格情報を格納するために使用されます。
GitLab CI/CD:継続的インテグレーション(CI)、継続的デプロイ、継続的デリバリー(CD)という継続的な方法論によるソフトウェア開発のためにGitLabに組み込まれているツール。
正解解説:
(オプション)
・GitLabを外部IDプロバイダーとして使用するためのワークロードIDフェデレーションの設定
ワークロード ID フェデレーションは、GitLab Runners などの Google Cloud の外部で実行されているアプリケーションが Google Cloud サービスで認証できるようにする安全な方法であるため、この選択は賢明です。GitLab Runners が Google Cloud リソースにアクセスするための一時的な ID を引き受けられるようにすることで、サービス アカウント キーの処理と保存に関連するリスクを回避します。この方法は、セキュリティのベストプラクティスに準拠しており、有効期間の長い資格情報を管理する必要がなくなります。
不正解の説明:
オプション: サービス アカウント キーを生成し、GitLab CI/CD パイプラインの環境変数内に格納します。
これが正しくない理由は、サービス アカウント キーを環境変数として格納すると、キーが公開される可能性があるため、安全性が低くなるためです。CI / CD パイプラインの環境が侵害されると、攻撃者はサービス アカウント キーに簡単にアクセスでき、Google Cloud リソースへの不正アクセスにつながる可能性があります。
オプション: サービス アカウント キーを生成し、GitLab リポジトリに直接コミットします。
これが間違っている理由は、サービス アカウント キーをリポジトリに直接コミットすると、重大なセキュリティ リスクが生じるためです。リポジトリが公開されていたり、侵害されたりすると、権限のないユーザーがサービス アカウント キーを取得し、データ侵害や不正アクセスにつながる可能性があります。
オプション: Workload Identity を有効にして Google Kubernetes Engine クラスタを確立し、GitLab Runner の認証を提供します。
これが間違っている理由は、Workload Identity を有効にして GKE クラスタを確立しても、GitLab Runners が Google Cloud サービスに接続するための認証が直接提供されないためです。Workload Identity は、Kubernetes ポッドが Google Cloud に対して認証するためのものであり、GitLab などの外部 CI / CD システム用ではありません。
参考：
httpps://cloud.google.com/iam/docs/workload-identity-federation
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://docs.github.com/en/actions/security-guides/automatic-token-authentication
</div></details>

### Q.  問題38: 未回答
医療機関は、各スタッフに Google Cloud サービスの利用を許可しています。すべてのユニットには Google グループがあり、ユニットのメンバー全員が参加します。ユニットメンバーが新しいプロジェクトを開始する場合、そのユニットのすべてのメンバーが、その新しいプロジェクト内のリソースへの読み取り専用アクセスを自動的に取得する必要があります。異なるユニットの担当者は、このプロジェクトにアクセスできません。
このアクセスモデルを設定するには、どのような手順が必要ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、組織単位に基づくアクセス制限を実装するための Google Cloud のリソース階層とアクセス制御管理の理解度を調べます。これには、フォルダーとロールを効率的に活用して、新しいプロジェクトのアクセス許可を自動化するための知識が必要です。
重要な用語:
フォルダ: Google Cloud では、フォルダは組織の下にプロジェクトをグループ化する組織エンティティです。フォルダーを使用して階層構造を作成し、よりきめ細かなアクセス制御とリソース編成を行うことができます。
Google グループ: 共通の権限を持つユーザーの集まりです。Google グループでは、グループのすべてのメンバーに同時に役割を割り当てることができるため、権限管理が簡素化されます。
プロジェクト閲覧者ロール: プロジェクト閲覧者は、Google Cloud の事前定義された IAM ロールで、プロジェクト内のリソースを表示するための読み取り専用アクセス権を付与しますが、ユーザーはリソースやデータを変更することはできません。
リソース階層: Google Cloud のリソースの構造化された組織で、組織、フォルダ、プロジェクト、リソースで構成され、アクセス制御とプロジェクト設定を大規模に管理するために使用されます。
正解解説:
(オプション)
・組織内のユニットごとにフォルダを作成します。各ユニットに対応するフォルダについて、そのユニットに関連付けられている Google グループにプロジェクト閲覧者の役割を割り当てます。
この選択は、Google Cloud のリソース管理の階層構造に合致するため、正しいソリューションです。各ユニットのフォルダを作成し、そのユニットの Google グループにプロジェクト閲覧者の役割を割り当てることで、フォルダ内でプロジェクトが作成されると、メンバーに自動的に読み取り専用アクセス権が与えられます。この戦略により、組織は個々のプロジェクトではなくフォルダレベルでアクセスを管理できるため、権限管理が合理化され、すべてのユニットメンバーが新しいプロジェクトごとに手動の介入なしでアクセスできるという要件に合わせることができます。
不正解の説明:
オプション: 組織内の各ユニットのフォルダを作成します。各ユニットに対応するフォルダについて、そのユニットに関連付けられている Google グループにプロジェクト ブラウザの役割を付与します。
この選択が間違っている理由は、プロジェクト ブラウザ ロールでは、フォルダの下にプロジェクトを一覧表示できますが、プロジェクト内のリソースへの読み取り専用アクセスは提供されず、プロジェクト名とメタデータの表示のみが許可されているためです。
オプション: 組織のユニットごとに個別のプロジェクトを設定します。各単元に関連するプロジェクトについて、その単元の Google グループにプロジェクト閲覧者の役割を割り当てます。
この選択が間違っている理由は、個々のプロジェクトごとに手動でアクセス権を設定する必要があるため、非効率的であり、ユニットメンバーがユニット内の将来のプロジェクトに自動的にアクセスすることが保証されないためです。
オプション: 組織内のユニットごとに個別のプロジェクトを確立します。各ユニットに属するプロジェクトについて、各ユニットの Google グループにプロジェクト ブラウザの役割を付与します。
この選択が間違っている理由は、最初の間違ったオプションと似ています。プロジェクト ブラウザの役割は、プロジェクト リソースへの必要な読み取り専用アクセス権を提供せず、プロジェクト リストの表示のみを許可します。
参考：
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://cloud.google.com/iam/docs/understanding-roles#basic-definitions
https://cloud.google.com/resource-manager/docs/access-control-proj
</div></details>

### Q.  問題39: 未回答
金融アナリストは、費用対効果の高い方法で取引取引ログを5年間保存する必要があります。関連するログエントリをふるいにかけるフィルターを作成しました。ログをどのサービスにエクスポートする必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、費用対効果の高い方法で財務ログを長期保存するのに適した Google Cloud サービスの理解度を評価します。これには、ログ管理、データ分析、メッセージング、特にアーカイブ用に最適化されたストレージ サービスに関する Google Cloud のオプションに関する知識が必要です。
重要な用語:
データライフサイクル管理:より安価なストレージクラスへのデータの移行や、不要になったデータの削除を自動化するポリシー。
オブジェクト・ライフサイクル・ポリシー: オブジェクトを別のストレージ・クラスに自動的に移行したり、一定期間後に期限切れにしたりすることで、ストレージ・コストを管理するための特定のルール。
ニアライン / コールドライン ストレージ クラス: アクセス頻度の低いデータ向けの Google Cloud Storage オプションで、アクセス時に取得コストが発生する長期ストレージの低コストの代替手段を提供します。
正解解説:
(オプション)
・クラウドストレージバケット
Cloud Storage バケットは、大量のデータを保存するためのフルマネージドで拡張性の高いサービスを提供し、ログの長期保存に理想的なため、この選択は適切です。さらに、Cloud Storage には Nearline や Coldline などのさまざまなストレージ クラスが用意されており、アクセス頻度の低いデータに対して費用対効果の高いデータを提供します。これをオブジェクト・ライフサイクル・ポリシーと組み合わせることで、財務アナリストは5年間にわたってログを経済的に管理し、データが古くなるにつれて、よりコスト・パフォーマンスの高いストレージに自動的に移行できます。
不正解の説明:
オプション: BigQuery データセット
BigQuery データセットが最適な選択肢ではない理由は、BigQuery は分析には優れていますが、長期的でアクセス頻度の低いストレージ シナリオではなく、アクティブに使用されるデータを対象としており、長期間にわたってストレージとデータ取得のコストが大幅に増加する可能性があるためです。
オプション: Cloud Logging
Cloud Logging が正しくない理由は、主にリアルタイムのログ管理と分析に使用されるためです。Cloud Logging は、長年にわたるログの低コストのアーカイブ ストレージ サービスとしてではなく、アプリケーションと仮想マシンのモニタリングに重点を置いています。
オプション: Cloud Pub/Sub トピック
Cloud Pub/Sub トピックが間違っている理由は、Pub/Sub がサービスの長期保存ではなく、サービス間の非同期通信を可能にするために設計されたリアルタイム メッセージング サービスであるためです。Pub/Sub のデータは一時的なものであり、配信後はすぐにまたは短期間で消費されることを意図しています。
参考：
https://cloud.google.com/logging/docs/storage
https://cloud.google.com/storage/docs
https://cloud.google.com/logging/docs/export/aggregated_exports
</div></details>

### Q.  問題40: 未回答
医療機関では、患者は Google Cloud Storage に保存されているデジタル プラットフォームを通じて医療記録と ID カードを送信します。18か月以上経過した記録から個人を特定できる情報(PII)を匿名化し、コンプライアンス上の理由から編集されたドキュメントを保持する必要があります。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、データ保持要件に準拠しながら、Google Cloud Storage 内に保存されている機密性の高い患者データを適切に処理し、匿名化する能力を評価します。目標は、特定の年齢しきい値を超えるレコードから PII を確実に削除することです。
重要な用語:
Cloud Data Loss Prevention(DLP): Google Cloud サービス全体でデータの検査、分類、秘匿化機能を提供することで、機密データの管理と保護を支援するサービスです。
墨消し: ドキュメントから機密情報を削除するプロセス。データセキュリティの文脈では、秘匿化は、開示すべきではない個人情報や機密情報を不明瞭にしたり、削除したりします。
保存:コンプライアンスの文脈では、保存とは、多くの場合、法的に義務付けられている期間、変更や損失なしにデータの整合性とアクセス性を維持することを指します。
正解解説:
(オプション)
・Cloud Data Loss Prevention(DLP)検査ジョブを作成して、18 か月以上経過したレコードから PII を編集し、別の Google Cloud Storage バケットに転送します。元のファイルを削除します。
この選択は、コンプライアンスのためのデータ保存を維持しながら、PIIを匿名化するという重要な要件に対処するため、正しいです。これには、18 か月以上経過したドキュメントの PII を自動的に検査して編集する Cloud Data Loss Prevention ジョブの設定が含まれます。その後、編集されたドキュメントは別の Google Cloud Storage バケットに転送して保管し、機密情報を含む元のファイルはデータ侵害のリスクを軽減するために削除する必要があります。
不正解の説明:
オプション: Google Cloud Storage バケットに 18 か月の TTL ポリシーを実装して PII を匿名化し、ファイルをよりコールドなストレージクラスに移行します。
この選択が正しくない理由は、TTL(Time-to-Live)ポリシーを実装しても、実際にはレコードからPIIが匿名化または編集されないためです。TTLは、設定された期間が経過するとデータを削除するだけであり、保存要件に準拠しなくなる可能性があります。
オプション: Google Cloud Storage バケットの自動分類機能を設定して、PII を自動的に削除し、18 か月以上経過したレコードをアーカイブ状態にします。次に、元のレコードを消去します。
この選択が正しくない理由は、Autoclass 機能にはレコードからの PII の削除が含まれていないためです。自動クラスは、格納されたデータのライフサイクルの管理を支援しますが、コンテンツは変更しません。さらに、アーカイブ状態はストレージクラスを指し、PIIの編集や削除は伴いません。
オプション: 機密情報を削除するために、PII を使用して Google Cloud Storage ファイルに適用される暗号鍵について、18 か月の Cloud Key Management Service(KMS)鍵ローテーション スケジュールを確立します。古い暗号化キーの削除に進みます。
この選択が間違っている理由は、Cloud KMS の鍵ローテーションは、保存データを保護する暗号鍵の管理に関するものであり、保存されたファイルから機密情報を編集または削除するためのメカニズムが提供されていないためです。
参考：
https://cloud.google.com/dlp/docs/creating-job-triggers
https://cloud.google.com/dlp/docs/deidentify-sensitive-data
https://cloud.google.com/storage/docs/bucket-archiving-classes
</div></details>

### Q.  問題41: 未回答
ある多国籍製薬会社は、独自の研究データ システムを Google Cloud に移行しています。組織は、機密性の高い実験結果をアップロードする際に、科学者のワークステーションと Google Cloud 間の通信が保護されていることを確認する必要があります。
彼らは何をすべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、製薬会社のワークステーションと Google Cloud 間の通信を保護するための適切な方法の選択に関するものです。機密データをインターネット経由で送信し、送信中にデータが暗号化されるようにすることに重点を置いています。
重要な用語:
SSL証明書:SSL証明書は、Webサイトの認証を提供し、暗号化された接続を可能にするために使用されるデジタル証明書です。これは、転送中のデータを保護するために重要です。
HTTP(S) ロードバランサ: HTTP(S) ロードバランサは、受信 HTTP または HTTPS トラフィックを仮想インスタンスなどの複数のターゲットに分散します。SSLターミネーションを提供し、データ転送の保護と管理を支援します。
暗号化: 暗号化は、不正アクセスを防ぐためにデータをエンコードするプロセスです。これは、送信中の機密情報を保護するために不可欠です。
正解解説:
(オプション)
・HTTP(S)ロードバランサーにSSL証明書を設定し、暗号化を要求します。
HTTP(S) ロードバランサーで SSL 証明書を構成すると、転送中のデータが暗号化を使用して保護されるため、この選択が最も適切です。HTTP(S) ロードバランサは SSL ターミネーションを処理するため、データはクライアントのブラウザからロードバランサまで暗号化され、Google Cloud にアップロードされる機密性の高い実験結果のエンドツーエンドのセキュリティが確保されるため、これは機密データにとって特に重要です。
不正解の説明:
オプション: ネットワーク TCP/UDP ロードバランサーで SSL 証明書を構成し、暗号化を要求します。
この選択が正しくない理由は、ネットワーク TCP/UDP ロードバランサーが SSL ターミネーションを提供しないためです。これらのロードバランサーは、主にHTTP/Sベースではないトラフィック用に設計されているため、HTTP/Sプロトコルを使用して転送される機密データに必要なレベルのセキュリティは提供されません。
オプション: ポート 8443 で受信トラフィックを許可し、他のすべての受信トラフィックを拒否するようにファイアウォールを構成します。
この選択が間違っている理由は、ファイアウォールのポートを開くだけでは通信が保護されないためです。SSL証明書などの暗号化メカニズムがないと、トラフィックがファイアウォールを通過できていても、データが安全に送信されない可能性があります。
オプション: ポート 8443 で送信トラフィックを許可し、他のすべての送信トラフィックを拒否するようにファイアウォールを構成します。
この選択が間違っている理由は、2番目の選択と似ています。特定のポートで送信トラフィックを許可しても、本質的にはデータが暗号化されません。機密データは、ファイアウォールの構成に関係なく、適切に暗号化されていない場合、傍受や不正アクセスのリスクにさらされる可能性があります。
参考：
https://cloud.google.com/load-balancing/docs/ssl-certificates
https://cloud.google.com/load-balancing/docs/https
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題42: 未回答
急成長中のeコマース企業の財務アナリストは、発注書とトランザクションの照合と支出通知の設定を担当しています。規制基準により、財務アナリストには、これらの責任を果たすために必要な Identity and Access Management (IAM) アクセス許可のみが許可されています。
金融アナリストに付与すべきIAMの役割は2つですか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、金融取引の調整と支出通知の規制基準に準拠した請求権限の管理に関連する、Google Cloud IAM のロールベースのアクセス制御に関する受験者の理解度を評価します。
重要な用語:
最小特権の原則: リスクを最小限に抑えて、職務の遂行に不可欠なアクセス許可のみをユーザーに付与することを推奨するセキュリティの概念。
ロールベースのアクセス制御 (RBAC): 組織内で定義されたロールに基づいて、権限をロールに結合して、許可されたユーザーにシステムアクセスを制限する方法。
請求先アカウント閲覧者: 請求先アカウントのコスト情報とトランザクション履歴を、請求先の設定を管理せずに表示できる IAM ロール。
請求先アカウントコストマネージャー: より広範なアカウント管理権限なしで、予算、アラートの管理、請求データのエクスポートを行う権限を付与する IAM ロール。
正解解説:
(オプション)
・請求先アカウントビューア
・請求先アカウントコストマネージャー
請求先アカウント閲覧者と請求先アカウント コスト マネージャーの役割を組み合わせることで、財務アナリストは最小特権の原則を遵守しながら、必要な職務を実行できます。請求先アカウント閲覧者ロールを使用すると、アナリストはトランザクションとコスト情報を表示でき、請求先アカウント コスト マネージャー ロールでは、アクセス許可を過度に拡張せずに発注書を調整するための重要なタスクである支出通知と予算管理を構成できます。
不正解の説明:
オプション: 組織管理者
この選択が間違っている理由は、組織管理者ロールが GCP 組織全体に幅広い権限を提供し、トランザクションの調整や支出通知の設定に必要な権限をはるかに超えているため、最小権限の原則に違反しているためです。
オプション: プロジェクトオーナー
この選択が間違っている理由は、プロジェクト所有者ロールには、請求に重点を置いた財務アナリストにとって不要で潜在的にリスクの高い非財務操作を含む、プロジェクト内のリソースを管理するための幅広い権限が含まれているためです。
オプション: 請求先アカウント管理者
この選択が間違っている理由は、請求先アカウント管理者ロールが請求先アカウントの作成や管理の権限など、請求先アカウントに対するフルコントロールを付与しているためで、これは注文の調整や支出通知の設定に最低限必要な権限を超えているためです。
参考：
https://cloud.google.com/billing/docs/how-to/billing-access
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://cloud.google.com/billing/docs/how-to/budgets
</div></details>

### Q.  問題43: 未回答
あるヘルステック企業では、患者データシステムへの悪意のあるアクセス試行が増加しています。
患者データアクセスシステムのセキュリティを強化するために、企業はどのようなアクションを実装すべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
このシナリオでは、不正アクセスの試みが増加しているため、患者データアクセスシステムのセキュリティを強化する必要があるヘルステック企業に焦点を当て、機密情報を保護するための最適なソリューションを模索しています。
重要な用語:
多要素認証: リソースにアクセスするために 2 つ以上の検証要素を必要とする認証方法であり、パスワードだけでなく防御層を追加することで、アカウントのセキュリティを劇的に向上させます。
正解解説:
(オプション)
・多要素認証
多要素認証の実装は、効率的で強く推奨されるセキュリティプラクティスです。これにより、ユーザーは機密データにアクセスする前に、ID を確認するために 2 つ以上の異なる種類の証拠を提供する必要があります。パスワードが盗まれた場合でも、攻撃者がアクセスするために追加の要素が必要になるため、パスワードの漏洩によってもたらされるリスクが軽減され、患者データアクセスシステムのセキュリティが大幅に強化されます。
不正解の説明:
オプション: 堅牢なパスワードの複雑さの要件を実装する
この選択が間違っている理由は、堅牢なパスワードポリシーはセキュリティを強化しますが、フィッシングやその他の攻撃ベクトルによってバイパスされる可能性があるためです。追加の認証形式を要求するのと同じレベルのセキュリティは提供されません。
オプション: 患者データポータルのサインインページでの Captcha チャレンジの追加
この選択が間違っている理由は、キャプチャチャレンジは主に自動化された攻撃から保護しますが、患者データへの不正アクセスを試みようとする決意した人間の攻撃者を阻止するにはほとんど役に立たないためです。
オプション:患者データへのアクセスに暗号化されたメッセージングシステムを利用する
この選択が間違っている理由は、暗号化されたメッセージングは転送中のデータの機密性と整合性を保護できますが、患者データが存在するシステムのアクセス制御手段には対応していないためです。
参考：
https://cloud.google.com/iam/docs/multifactor-authentication
https://cloud.google.com/identity-platform/docs/web/mfa
Hatps://support.google.com/a/answer/9213912?hl=n
</div></details>

### Q.  問題44: 未回答
エンベロープ暗号化を実装し、医療データ分析プラットフォームのアプリケーション層でデータを保護するには、Google の推奨プラクティスに従う必要があります。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、クラウド環境における機密性の高い医療データのセキュリティを強化するためのエンベロープ暗号化の実装について説明します。これは、暗号鍵管理のベストプラクティスとアプリケーション層でのデータの安全な暗号化に関する受験者の理解に疑問を投げかけます。
重要な用語:
エンベロープ暗号化:データ暗号化キー(DEK)を使用してデータを暗号化し、別のキー暗号化キー(KEK)を使用してDEKを暗号化するセキュリティメカニズムで、機密データの全体的なセキュリティを強化します。
DEK: データ暗号化キーは、データの暗号化と復号化に使用される対称キーで、セキュリティを強化するために頻繁にローテーションまたは変更されるように設計されています。
KEK: Key Encryption Key は、DEK の暗号化と保護に使用される非対称キーまたは対称キーです。通常、キー管理システムなどの安全なサービスで保存および管理されます。
CLOUD KMS: クラウド リソースの暗号鍵を管理、作成、ローテーションできるクラウドベースの鍵管理サービスです。
正解解説:
(オプション)
・アプリケーション内でデータ暗号鍵(DEK)を作成して患者記録を暗号化し、Cloud Key Management Serviceで新しい鍵暗号鍵(KEK)をプロビジョニングしてDEKを暗号化します。暗号化された患者記録と暗号化されたDEKの両方を保護します。
この選択は、Google の推奨プラクティスに従ってエンベロープ暗号化を実装するための正しい手順です。まず、アプリケーション内に DEK を作成し、特定のデータ暗号化操作がアプリケーション環境に対してローカルに保持されるようにすることを規定しています。その後、暗号鍵の安全な管理を提供する Cloud Key Management Service 内で KEK をプロビジョニングするように指示します。その後、DEK は KEK で暗号化され、暗号化された DEK と暗号化された患者記録の両方が、エンベロープ暗号化の原則に従って安全に保存されます。
不正解の説明:
オプション: アプリケーション内で患者記録を暗号化するためのデータ暗号鍵(DEK)を作成し、Cloud Key Management Service で新しい鍵暗号鍵(KEK)を作成して DEK を暗号化します。暗号化された患者記録と KEK の両方を保持します。
この選択が間違っている理由は、暗号化された患者記録と共に KEK を保存することを示唆しているからです。このアプローチでは、KEK は Cloud KMS などの安全な環境で管理し、オープンに保存しないため、セキュリティ リスクにつながる可能性があります。
オプション: Cloud Key Management Service で新しいデータ暗号鍵(DEK)を直接プロビジョニングして患者記録を暗号化し、アプリケーション環境内に鍵暗号鍵(KEK)を作成して DEK を暗号化します。暗号化された患者記録と暗号化された DEK の両方を保存します。
この選択が正しくない理由は、DEK を Cloud KMS 内で直接プロビジョニングする必要があることを意味し、データ暗号化オペレーションの制御を維持するためにアプリケーション環境内で DEK を生成するというベスト プラクティスに反するためです。
オプション: Cloud Key Management Service を使用して新しいデータ暗号鍵(DEK)をインスタンス化し、患者記録を保護し、アプリケーション内で鍵暗号鍵(KEK)を生成して DEK を暗号化します。暗号化された患者記録と KEK の両方を手元に置いてください。
この選択が間違っている理由は、アプリケーション内で Cloud KMS と KEK を使用して DEK を生成することが提案されているためです。これにより、推奨される方法に反して DEK と KEK の役割が逆転し、キーの管理と保存にリスク要因が生じる可能性があります。
参考：
https://cloud.google.com/kms/docs/envelope-encryption
https://cloud.google.com/kms/docs/encrypt-decrypt
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題45: 未回答
あるヘルステック企業は、パーソナライズされたケアプランを改善するために、患者の人口統計の詳細と複数の診療所から取得した健康記録を照合する新しい方法を模索しています。
しかし、この機密性の高い生データを処理に利用すると、個人の健康情報が漏洩するリスクがあり、新しい規制環境に違反する可能性があります。解決策として、組織は Cloud Data Loss Prevention を使用してこのデータを匿名化し、異なる医療システム間でデータの一貫性が保たれるようにする必要があります。これらの条件を満たすには、どの暗号化トークン形式が最も適していますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、複数の医療システム間で一貫性を維持しながら侵害を防ぐために機密データを匿名化する必要性に対処します。Google Cloud のデータ損失防止機能内で、このような目的に適した暗号化技術を理解する必要があります。
重要な用語:
確定的暗号化: 特定の入力が常に同じ暗号化された出力になる暗号化の方法。このプロパティを使用すると、元のデータを公開することなく、異なるデータセット間で暗号化されたデータを照合できます。
匿名化: データセットから個人を特定できる情報を削除または暗号化して、データセット内の個人のプライバシーを保護するプロセス。
Cloud Data Loss Prevention(DLP): 機密情報の保護とコンプライアンスの維持に役立つデータ検査、分類、匿名化機能を提供する Google Cloud サービス。
正解解説:
(オプション)
・確定的暗号化
決定論的暗号化では、データセット間で同じ入力結果が同じ暗号化された出力になるように、組織が患者の人口統計の詳細を暗号化できるため、この選択は適切です。この方法により、複数の診療所の暗号化されたレコードを照合するときに、暗号化された形式のデータの一貫性が保たれ、機密情報を公開することなくデータセットの比較と組み合わせが可能になります。プライバシー規制に準拠しながら、分析やパーソナライズされたケアプランにデータを活用したいという組織のニーズを満たします。
不正解の説明:
オプション: 安全なキーベースのハッシュ
この選択が間違っている理由は、安全なキーベースのハッシュは可逆的に設計されており、元の情報をハッシュから導き出すことができないためです。これにより、データは安全になりますが、組織は異なるシステム間でレコードを照合できなくなります。
オプション:フォーマット保持暗号化
この選択が間違っている理由は、暗号化後もクレジット カード番号の形式を保持するなど、元のデータ形式を保持する必要がある場合に、形式保持暗号化が主に使用されるためです。ただし、これは、決定論的暗号化のように、データ照合の目的での一貫性を必ずしも保証するものではありません。
オプション: 暗号化ハッシュ
この選択が間違っている理由は、暗号化ハッシュの不可逆的な性質にあります。ハッシュ化されたデータは復号化して元の形式に戻すことができないため、医療システム全体で匿名化されたレコードを一貫して照合する必要があるアプリケーションには適していません。
参考：
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/dlp/docs/deidentify-sensitive-data
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題46: 未回答
重要でないシステム用のセクションとミッションクリティカルなシステム用のセクションを含む監視システムを構成する必要があります。これら 2 つのゾーン間のすべてのトラフィックを分析するには、次世代侵入防御システム(IPS)などのネットワーク検査ソリューションを実装する必要があります。
トラフィックのインスペクションを可能にするためにネットワークを構築するための最良のアプローチは何ですか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、システムの重要度の異なるレベルでのトラフィック検査のための Google Cloud ネットワーク アーキテクチャに関する知識を評価します。仮想プライベートクラウド(VPC)ネットワークの構築に重点を置き、高度な侵入防止システムを使用してトラフィックの監視を容易にします
重要な用語:
VPC ネットワーク: VPC ネットワークは、Google Cloud のリソース内に存在し、相互接続する従来の物理ネットワークの仮想バージョンであり、リソースの分離と論理的なパーティション分割を提供します。
ネットワーク インターフェース: ネットワーク インターフェースを使用すると、ネットワーク デバイスは VPC ネットワークと対話できます。Google Cloud では、VM インスタンスは複数のネットワーク インターフェースを持ち、異なる VPC ネットワークに接続できます。
侵入防止システム(IPS):IPSは、ネットワークトラフィックフローを調べて脆弱性の悪用を検出して防止するネットワークセキュリティ/脅威防止テクノロジーです。
ネットワーク トラフィックの検査: このプロセスでは、ネットワーク内のさまざまなサービスやエンティティ間の通信を分析して、悪意のあるアクティビティやパフォーマンスの問題を検出します。
正解解説:
(オプション)
・1.2 つの Google Cloud VPC ネットワーク(1 つはミッションクリティカルなシステム用、もう 1 つは重要でないシステム用)を確立します。
2. 複数のネットワーク インターフェイスを持つネットワーク検査ソリューションを導入し、各インターフェイスを VPC ネットワークの 1 つに関連付けます。
この選択では、二股アプローチを提唱し、異なるシステム重要度レベル(ミッションクリティカル用と重要でないシステム用)に個別の VPC ネットワークを設定します。これは、複数のネットワークインターフェイスを備えたマルチホームネットワークデバイスを持つ機能を活用します。ネットワーク検査ソリューションは、各インターフェイスを個別の VPC に接続することで、2 つの間を流れるトラフィックを精査し、構造的な分離を維持しながらセキュリティ プロトコルが満たされていることを確認できます。
不正解の説明:
オプション: 1. 2 つのサブネット (1 つはミッションクリティカルなシステム用、もう 1 つは重要でないシステム用) を持つ 1 つの VPC を作成します。
2. すべてのトラフィック(0.0.0.0/0)がネットワーク検査デバイスを通過するカスタムルートを設定します。
この選択が間違っている理由は、すべてのリソースが 1 つの VPC 内にあり、セキュリティ境界の適用がより複雑になるためです。トラフィックは検査デバイスを通過しますが、ミッションクリティカルなシステムと重要でないシステムの分離は、個別の VPC の場合ほど厳密ではありません。
オプション: 1. 2 つのサブネット (1 つはミッションクリティカルなシステム用、もう 1 つは重要でないシステム用) を持つ 1 つの VPC を作成します。
2. すべてのプライベート アドレス空間 (RFC1918 アドレス) がネットワーク検査デバイスを通過するカスタム ルートを設定します。
このオプションが正しくない理由は、最初の制限と同じ制限、つまり両方のシステム階層で 1 つの VPC を単独で使用することに起因します。ネットワーク検査デバイスを介してRFC1918アドレスをルーティングしても、重要度レベル間のトラフィックが効果的に検査または分離されるとは限りません。
オプション: 1. ミッションクリティカルなシステム用と重要でないシステム用の 2 つの Google Cloud VPC ネットワークを確立し、VPC ピアリングを使用して接続します。
2. 各 VPC ネットワークにカスタムルートを作成し、トラフィックをネットワーク検査ソリューションに転送します。
2 つの Google Cloud VPC ネットワークを確立することはベスト プラクティスに沿っていますが、VPC ピアリングを使用すると、トラフィックの検査が本質的に容易ではないため、複雑さが生じます。カスタムルートだけでは、ネットワーク検査ソリューションによるトラフィックの徹底的な検査を保証するのに十分ではありません。
参考：
https://cloud.google.com/vpc/docs/vpc-peering
https://cloud.google.com/vpc/docs/using-vpc
https://cloud.google.com/network-connectivity/docs/vpn/concepts/topologies#multiple-vpc-networks
</div></details>

### Q.  問題47: 未回答
組織は、Google Cloud リソースへのアクセス権を付与するために、Cloud Identity にアカウントを手動で追加しています。運用の拡大に伴い、数千のアカウントのオンボーディングを簡素化することを目指しています。Google Cloud Directory Sync(GCDS)を使用して内部 Active Directory サービスに接続する予定である。タスクには次のものが含まれます。
- アカウントとグループのライフサイクルの更新を社内の Active Directory から Cloud Identity にミラーリングする。
- 以前に同期なしで設定した Cloud Identity で手動アカウントを無効にする。
LDAP 検索パラメータは、Google Cloud の使用用に指定されたアカウントとセキュリティ グループを見つけるためにすでに調整されています。
この統合を完了するための次のステップは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud Directory Sync(GCDS)を使用して Cloud Identity を既存の Active Directory(AD)に統合するプロセスについて説明します。Google Cloud 上のリソース アクセスのアカウントとグループのライフサイクルを効果的に同期して管理するために、LDAP 検索パラメータを設定した後に必要な手順を検討します。
重要な用語:
GCDS: Google Cloud Directory Sync は、管理者が Microsoft Active Directory または LDAP ディレクトリからユーザーやグループの詳細を Cloud Identity や Google Workspace と同期できるツールです。
LDAP: ライトウェイト ディレクトリ アクセス プロトコルは、Active Directory が使用するユーザー アカウントやグループなどのディレクトリ情報にネットワーク経由でアクセスして管理するために使用される業界標準のプロトコルです。
Cloud Identity: ID 管理機能とデバイス管理機能を提供する Google のサービスで、ユーザーは 1 組の認証情報でアプリケーションやサービスに簡単にアクセスできます。
正解解説:
(オプション)
・同期中にActive DirectoryにないCloud Identityアカウントを停止する設定を行います。次に、GCDS との定期的な同期スケジュールを設定します。
この選択は、ディレクトリ同期によってユーザー アカウントを管理するためのベスト プラクティスと一致しています。この設定により、Active Directory で見つからない場合、Cloud Identity アカウントは停止され、アクティブな関連ユーザーのみがアクセスできるようになります。定期的な GCDS スケジュールを設定することで、ディレクトリの正確性が維持され、冗長な手動による介入やメンテナンスを行うことなく、最新の情報が Google Cloud に反映されます。
不正解の説明:
オプション: Active Directory で追跡できない Cloud Identity アカウントを消去するように設定を調整します。GCDS の同期は、アカウントとグループのライフサイクルの変更後に実装します。
この選択が間違っている理由は、貴重なデータや設定が意図せずに失われる可能性があるため、Cloud Identity アカウントの消去が理想的ではない可能性があるためです。データの損失を避けるために、最初にアカウントを削除するよりも一時停止する方が安全です。
オプション: LDAP 検索構成を調整して、手動で作成され、Active Directory に存在しない Cloud Identity アカウントを却下します。定期的な同期を実行するように GCDS を設定します。
この選択が間違っている理由は、アカウントを無視するように LDAP 検索構成を適応させることを提案しているためであり、これは一般的な同期操作やベスト プラクティスと一致しません。GCDS の目的はデータの同期であり、LDAP 設定内で手動で作成したアカウントに例外を設けるものではありません。
オプション: LDAP 検索パラメータを変更して、手動で追加した Active Directory に存在しない Cloud Identity アカウントを除外します。GCDS のアカウントとグループのライフサイクル変更後にトリガーします。
この選択が正しくない理由は、LDAP検索パラメータを変更することを意味するため、適切なアカウントとグループを見つけるためにパラメータが設定されると不要になります。また、ライフサイクルの変更後にのみ GCDS をトリガーすると、自動化された定期的な同期のメリットが失われます。
参考：
https://cloud.google.com/identity/docs/gcds
https://cloud.google.com/identity/docs/how-to/gcds-configure
Hatps://support.google.com/a/answer/106368?hl=n
</div></details>

### Q.  問題48: 未回答
Compute Engine のコンピューティング クラスタを使用して、アプリケーションの継続的デリバリー システムを設定しています。承認されていないエンティティへの資格情報の公開を減らすことを目指しています。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、認証情報の漏洩リスクを最小限に抑えて、Compute Engine で継続的デリバリーを安全に設定するために必要な知識を評価します。焦点は、サービス アカウントの使用に関するベスト プラクティスを採用し、組織のポリシー レベルでセキュリティ制約を適用することです。
重要な用語:
カスタムサービスアカウント:カスタムサービスアカウントは、アプリケーションに特定の権限を付与するユーザー定義のアカウントであり、サービスがアクセスできるアクションとリソースをより詳細に制御できます。
constraints/iam.disableServiceAccountKeyCreation: この組織ポリシーは、サービスアカウントキーを作成できないようにし、有効期間の長い認証情報の悪用の可能性を防ぐことでセキュリティレイヤーを追加します。
正解解説:
(オプション)
・コンピュートクラスタのカスタムサービスアカウントを作成します。プロジェクトレベルで constraints/iam.disableServiceAccountKeyCreation 組織ポリシーを有効にします
この選択は、Google Cloud のセキュリティのベスト プラクティスを理解していることを示しています。カスタム サービス アカウントを作成することで、最小特権の原則に従って、継続的デリバリー システムに必要な特権のみを提供します。「constraints/iam.disableServiceAccountKeyCreation」ポリシーを有効にすると、ユーザーがプロジェクトの有効期間の長いサービスアカウントキーを作成できないようにすることでセキュリティがさらに強化され、資格情報の盗難のリスクが軽減されます。
不正解の説明:
オプション: コンピューティング クラスタの個別の Cloud Identity ユーザー アカウントを作成します。ユーザーの一時的な資格情報を管理するための堅牢な独自のコンテナー ソリューションを採用します。
この選択が間違っている理由は、コンピューティング クラスタに個別の Cloud Identity ユーザー アカウントを使用することは、サービス インスタンスのベスト プラクティスではなく、代わりにサービス アカウントを使用する必要があるためです。さらに、独自のボールトを使用すると複雑さが増し、Google Cloud の組み込みのセキュリティ機能とシームレスに統合されません。
オプション: コンピューティング クラスタの個別の Cloud Identity ユーザー アカウントを作成します。プロジェクトレベルで constraints/iam.disableServiceAccountCreation 組織ポリシーを有効にします。
この選択が間違っている理由は 2 つあります: まず、Cloud Identity ユーザー アカウントは、コンピューティング クラスタなどのサービス インスタンスではなく、個々のユーザー向けに設計されています。第 2 に、「constraints/iam.disableServiceAccountCreation」ポリシーでサービスアカウントの作成を無効にすると、リソースへのアクセスを管理および保護するためのサービスアカウントの適切な構成が妨げられます。
オプション: コンピューティング クラスターのカスタム サービス アカウントを作成します。プロジェクトレベルで constraints/iam.allowServiceAccountCredentialLifetimeExtension 組織ポリシーを有効にします。
この選択が正しくない理由は、組織のポリシーが有効になっているためです。「constraints/iam.allowServiceAccountCredentialLifetimeExtension」を使用すると、サービスアカウントの認証情報の有効期間を延長できますが、認証情報が適切に管理およびローテーションされていない場合、セキュリティリスクが高まる可能性があります。
参考：
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/access/service-accounts
</div></details>

### Q.  問題49: 未回答
ある金融会社は、既存のインフラストラクチャを Google Cloud に拡張することを検討しています。実装する予定の最初のステップは、将来のデータ処理のニーズに備えて、既存のアーカイブ サービスとビジネス継続性サービスを Google Cloud に移行することです。中核となる財務業務は、当面の間、現地で運営され続けます。同社は、拡張性と経済的に実行可能なソリューションを必要としています。
どの Google Cloud サービスを利用すべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、コア業務をオンプレミスで維持しながら、アーカイブとビジネス継続性に適した Google Cloud サービスを選択するために必要な知識を評価します。これは、費用対効果が高く、スケーラブルなソリューションをビジネス戦略に合わせることを目的としています。
重要な用語:
cronジョブ:cronジョブは、Unixライクなオペレーティングシステムの時間ベースのスケジューラです。Google Cloud では、指定した時間や間隔でスクリプトやコマンドなどのタスクの実行を自動化するためによく使用されます。
Gsutil: Gsutil は、ユーザーが Google Cloud Storage 内のリソースを管理できるようにする Python アプリケーションです。これは、Cloud Storage との間でのデータ転送など、さまざまなバケットおよびオブジェクトの管理タスクに使用されます。
データアーカイブ:データアーカイブとは、アクティブに使用されなくなったデータを、長期保存のために専用のストレージサービスに移動するプロセスを指します。アーカイブ・ソリューションは、即時アクセスや高スループットよりも、コスト効率とデータの耐久性を優先します。
ビジネス継続性:ビジネス継続性には、重要な業務の維持や迅速な再開など、重大なインシデントや災害の発生中および災害後に重要なビジネス機能を継続できるようにする戦略とソリューションが含まれます。
経済的に実行可能: この用語は、必要な機能やスケーラビリティを損なうことなく、企業の財務目標とリソースの制約に合わせて費用対効果を提供するソリューションを指します。
正解解説:
(オプション)
・cronジョブとgsutilを活用したクラウドストレージ
この選択肢は、高い耐久性と可用性のために設計されたサービスである Cloud Storage を活用しており、特に「コールド」データやアクセス頻度の低いデータに対して低コストであるため、アーカイブやビジネス継続性のニーズに適しているため、理想的です。gsutil と cron ジョブを併用することで、定期的なデータ転送や操作のスケジュール設定が可能になり、バックアップを管理するための体系的で自動化された方法が提供され、不必要な複雑さやコストをかけずに、拡張可能で経済的に実行可能なアーカイブ戦略という会社の要件を満たすことができます。
不正解の説明:
オプション: BigQuery で継続的な同期を伴うストリーミング データ転送プロセスを実装する
BigQuery が最適なソリューションではない理由は、BigQuery が主に分析プラットフォームであり、アーカイブ用に設計されていないためです。アーカイブのニーズに合わせてストリーミングデータ転送プロセスを実装すると、手元のユースケースに必要なコストと複雑さが増します。
オプション: SSD 永続ディスクが接続された Compute Engine インスタンス
SSD 永続ディスクを使用した Compute Engine が正しくない理由は、このセットアップが、費用対効果の高い長期的なアーカイブ ストレージではなく、コンピューティングと処理のワークロード向けに設計されているためです。永続SSDは高速ですが、アーカイブ専用の他のストレージソリューションと比較してコストがかかります。
オプション: 定期的なデータ インポート タスクを使用する Firestore
Firestore が同社の要件に適していない理由は、専用の費用対効果の高いアーカイブ ストレージ ソリューションではなく、リアルタイム同期機能を備えたアプリ開発用に設計された NoSQL データベース サービスであるためです。定期的なデータインポートタスクは、経済的実行可能性の目標と一致しません。
参考：
https://cloud.google.com/storage/docs/uploading-objects
https://cloud.google.com/storage/docs/creating-buckets
https://cloud.google.com/storage/docs/lifecycle#gsutil
</div></details>

### Q.  問題50: 未回答
ある医療従事者は、ローカルのデータセンターサーバー上で重要なアプリケーションを運用しています。これらのアプリケーションは、医療提供者独自のネットワークを介してのみ利用できる必要があります。Google Cloud プロジェクト内の Compute Engine インスタンスがこれらのアプリケーションに接続できることを確認する必要があります。
これらの基準を満たすために、どのような2つの方法を採用できますか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、医療機関がローカル データセンターのネットワークを Google Cloud に安全に拡張し、重要なアプリケーションのプライベート接続を確保するために利用できる方法を検討します。これは、この特定のユースケースに対するさまざまなネットワーキングサービスの適切性を区別します。
重要な用語:
Cloud VPN: Cloud VPN を使用すると、Google Cloud ネットワークとオンプレミス ネットワークの間にインターネット経由で安全で暗号化された接続を作成できます。
Cloud Interconnect: Cloud Interconnect は、インターネットベースの接続よりも高速で信頼性が高く、低レイテンシの Google Cloud への接続を提供します。
正解解説:
(オプション)
・プロジェクトとローカルサーバー間のネットワークリンクをCloud VPNで構築します。
・プロジェクトとローカルサーバ間の直接接続をCloud Interconnectで設定します。
正しい方法では、プライバシーとデータの整合性を維持しながら、ローカル ネットワークを Google Cloud に拡張します。クラウド VPN を確立すると、インターネット上で安全で暗号化された IPsec 接続が可能になります。一方、Cloud Interconnect は、よりパフォーマンスと信頼性の高い Google Cloud への直接プライベート接続を容易にし、重要なワークロードに適した高速接続を提供します。機密データを扱う医療機関にとって、これら 2 つのソリューションは、ローカルのデータセンター サーバーで実行されている HIPAA 準拠のアプリケーションが Google Cloud リソースとプライベートにやり取りするために必要なセキュリティを提供します。
不正解の説明:
オプション: プロジェクト内に共有 VPC を実装して、必要な接続を実現します。
この選択が間違っている理由は、共有 VPC は、複数の Google Cloud プロジェクトを共通の仮想プライベートクラウドに接続することで、リソースを安全に共有できるように設計されているためです。オンプレミス環境への接続は有効になりません。
オプション: VPC ピアリングを利用して、プロジェクトのネットワークをローカル サーバーのネットワークにリンクします。
この選択が正しくない理由は、VPC ピアリングが Google Cloud 内の 2 つの VPC ネットワークの接続に使用され、Google Cloud ネットワークのオンプレミス ネットワークへの接続をサポートしていないためです。
オプション: プロジェクト内のすべての Compute Engine インスタンスを限定公開の Google アクセスを使用するように割り当てます。
この選択が間違っている理由は、限定公開の Google アクセスでは、プライベート IP アドレスのみを持つ Compute Engine インスタンスが、外部 IP なしで Cloud Storage や BigQuery などの Google サービスに到達できるためです。オンプレミス サーバーへの直接ネットワーク リンクは容易ではありません。
参考：
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/network-connectivity/docs/interconnect/concepts/overview
https://cloud.google.com/vpc/docs/configure-private-google-access#gcloud
</div></details>


## 3

### Q.  問題1: 未回答
Google Cloud インフラストラクチャへの直接アクセスを必要とする分析チームとサポート担当者ごとに、Google Cloud で個別のクラウド サービス ユーザー アカウントを構成する必要があります。会社のポリシーでは、シングル サインオン機能を備えた外部 ID 管理ソリューションを使用してユーザー ID を管理することが義務付けられています。このプロセスでは、スタッフのかなりの部分がプライベートな Google アカウントに仕事用ドメインのメールを使用していることがわかったため、Google が推奨する方法に従って、これらの管理対象外のアカウントを企業管理対象アカウントに移行したいと考えています。
どのような手順を実装する必要がありますか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、外部の ID 管理システムを Google Cloud と統合して、特に仕事用のメール ドメインを使用する既存の限定 Google アカウントを持つユーザーのユーザー認証と ID 管理を処理するシナリオを取り上げます。
重要な用語:
Cloud Identity: アクセス制御と ID サービスを提供する Google Cloud の ID 管理サービスで、多くの場合、シングル サインオン(SSO)のためにサードパーティの ID プロバイダと組み合わせて使用されます。
Google Cloud Directory Sync: 既存の LDAP ベースの ID 管理システムと Google の Cloud Identity サービス間の同期サービスを提供するツール。
管理対象外のユーザー向け転送ツール(TTUU): 管理者が管理対象外の(個人の)Google アカウントからドメイン内の管理対象の Google アカウントにユーザーデータを移行できるようにする、Google が提供する機能。
正解解説:
(オプション)
・Google Cloud Directory Sync を使用して、外部 ID 管理システムを Cloud Identity に連携させます。
・Transfer Tool for Unmanaged Users(TTUU)を利用して、競合するアカウントを持つ個人を特定し、非公開のGoogleアカウントを移行するように促します。
Google Cloud Directory Sync を使用すると、外部 ID 管理ソリューションと Cloud Identity 間の同期が可能になり、Google Cloud のユーザー アカウントに会社のディレクトリ構造とユーザー属性が反映されます。管理対象外のユーザー向け移行ツール(TTUU)の使用は、個人向けサービスで会社のドメインを使用して作成されたアカウントを特定して移行する際にユーザーを支援し、競合するアカウントを管理し、アカウント管理に関する Google のベスト プラクティスを遵守する場合に推奨される方法です。
不正解の説明:
オプション: Google 管理コンソールを操作して、再設定用のメールアドレスに非公開のアカウントを設定している企業管理対象ユーザーを確認します。
この選択が間違っている理由は、管理コンソールで再設定用のメールアドレスを確認しても、非公開アカウントと仕事用ドメインのメールアドレスの競合に直接対処できず、それらのアカウントを企業管理対象アカウントに移行するメカニズムも提供されないためです。
オプション: 管理対象の Google ドメインにユーザーを追加し、非公開アカウントにリンクされているメールアドレスの切り替えをユーザーに義務付けます。
この選択が間違っている理由は、ユーザーを強制的に含めたり、非公開アカウントに関連付けられたメールアドレスの変更を義務付けたりすると、混乱が生じる可能性があり、競合するアカウントを管理するために Google が推奨するプロセスに従っていないためです。
オプション: プライベートな Google アカウントに関連付けられた仕事用メールアドレスを持つスタッフに、その個人アカウントを遅滞なく終了するよう依頼するメール ディレクティブをすべてのスタッフに送信します。
この選択が間違っている理由は、従業員に指示を電子メールで送信することは、非公開アカウントと企業管理アカウント間の競合を解決するための信頼できる方法ではなく、個人アカウントが時期尚早かつ不適切に終了された場合にデータ損失が発生する可能性があるためです。
参考：
https://cloud.google.com/identity/docs/how-to/setup#connecting_to_your_ldap_directory
https://cloud.google.com/identity/docs/troubleshooting-common-sso
Hatps://support.google.com/a/answer/106368?hl=n
</div></details>

### Q.  問題2: 未回答
あなたは、会社のセキュリティ チームのメンバーで、Windows ジャンプ サーバーを担当しています。すべてのパブリック IP アドレスを削除することで、外部からの攻撃対象領域を最小限に抑えることが求められています。開発者は、オフィスの外にいるときに仮想プライベートクラウド(VPC)の内部サービスに到達するために、さまざまな場所からジャンプサーバーにリモートでアクセスできる必要があります。
この要件を容易にするために、どのようなアプローチを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、パブリック IP の脆弱性にさらさずに Windows ジャンプ サーバーへのリモート アクセスをセキュリティで保護する方法を評価します。分散したチームが VPC リソースへの安全でプライベートな接続を可能にする GCP ネットワークとセキュリティ サービスを理解する必要があります。
重要な用語:
Identity-Aware Proxy(IAP): IAP は Google Cloud 上で動作するクラウド アプリケーションや VM へのアクセスを制御し、VPN を使用せずに ID とグループ メンバーシップに基づいてアクセスできるようにします。
TCP転送: IAPを介したTCP転送は、TCPセッションを介した安全なデータ送信を可能にし、安全な接続を介してさまざまなタイプのトラフィックをトンネリングする方法を提供します。
正解解説:
(オプション)
・ジャンプサーバにIdentity-Aware Proxy TCP転送を実装します。
Identity-Aware Proxy(IAP)TCP転送により、開発者はパブリックIPなしでジャンプサーバーにリモートアクセスできるため、この選択が最も適切です。IAPは、ユーザーのIDとリクエストのコンテキストを検証して、アクセスを許可するかどうかを判断します。その後、IAPはユーザーのデバイスからアプリにTCPトラフィックを転送し、最小権限の原則に従って、認証されたユーザーのみがジャンプサーバーにアクセスできるようにします。
不正解の説明:
オプション: ジャンプ サーバーがホストされているゾーン専用のインターコネクトを展開します。
専用インターコネクトのデプロイが適していない理由は、オンプレミスのインフラストラクチャとGCPの間にプライベート接続を確立するためのものだからです。これはコストがかかり、個々のリモートアクセスのニーズに対するソリューションではありません。
オプション:ジャンプサーバーにセキュリティキーを使用したOSログインを利用します。
ジャンプサーバにセキュリティキーでOSログインを利用するのは、GoogleのIAM機能を使ってSSHログインのセキュリティを強化する一方で、リモートアクセスのためのパブリックIPが不要になるわけではないからです。
オプション: ジャンプ サーバーを保護するように Cloud Armor を設定します。
Cloud Armor の設定が正しくないのは、Cloud Armor が主に HTTP(S) ロードバランサに対する DDoS 攻撃やウェブ攻撃に対する防御として使用されるためです。安全なリモートアクセスを容易にしたり、パブリックIPの必要性を排除したりすることはありません。
参考：
https://cloud.google.com/iap/docs/using-tcp-forwarding
https://cloud.google.com/compute/docs/instances/connecting-advanced#identity_aware_proxy
https://cloud.google.com/architecture/identity/identify-access#identity-aware-proxy
</div></details>

### Q.  問題3: 未回答
Cloud External Key Manager を使用して、Google Cloud の特定の Pub/Sub メッセージを保護するための暗号鍵を生成する場合。
最初に取るべき行動はどれか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Cloud External Key Manager と Google Cloud サービスを統合して Pub/Sub メッセージの暗号化を管理する方法に関する知識を評価します。セキュリティ上の目的で外部キーを使用するために必要な初期アクションに重点が置かれています。
重要な用語:
Cloud External Key Manager: Google Cloud サービス内で暗号鍵を使用しながら、Google のインフラストラクチャの外部で暗号鍵を管理できるセキュリティ機能。
Uniform Resource Identifier (URI): 特定のリソースを一意に識別する文字列。キーのコンテキストでは、Google サービス内で外部キーを参照するために使用されます。
鍵管理サービス(KMS): 暗号鍵を作成、管理し、さまざまな Google Cloud サービスやアプリケーションで暗号鍵の使用を制御するために使用されるサービスです。
正解解説:
(オプション)
・1.Google Cloud プロジェクトで、個別の Uniform Resource Identifier(URI)を持つ既存のキーを生成または選択します。
2. 準拠している外部鍵管理サービスにアクセスするための権限を Google Cloud プロジェクトに付与します。
この選択は、Google Cloud 内で外部キー マネージャーを使用するために必要な手順に従うため、正確です。最初に、Google Cloud プロジェクトで一意の URI を持つキーを作成または識別する必要があります。その後、Google Cloud プロジェクトには、Google の仕様に準拠するサードパーティの外部鍵管理サービスを使用してこの鍵にアクセスするための権限を付与する必要があります。
不正解の説明:
オプション: 1. Cloud Key Management Service(Cloud KMS)内で、固有の Uniform Resource Identifier(URI)を持つ確立された鍵を生成または利用します。
2. Cloud KMS 内で、Google Cloud プロジェクトが鍵を使用することを承認します。
この選択が間違っている理由は、Cloud Key Management Service(Cloud KMS)を使用してGoogle Cloud内に鍵を内部的に保存することを提案しており、外部鍵管理サービスを必要とする「Cloud External Key Manager」を採用する前提と矛盾しているためです。
オプション: 1. 適切な外部キー管理パートナー ソリューションで、一意の Uniform Resource Identifier (URI) を使用して以前に作成したキーを作成または選択します。
2. 外部鍵管理パートナー ソリューション内で、Google Cloud プロジェクトに鍵へのアクセスと管理を許可します。
この選択が間違っている理由は、外部の鍵管理パートナー ソリューションの使用を適切に推奨しているにもかかわらず、そのソリューションを Google Cloud と統合するために必要なプロセスを説明していないため、外部マネージャー内ではなく Google Cloud プロジェクト自体内で権限を設定する必要があるためです。
オプション: 1. Cloud Key Management Service(Cloud KMS)を介して、排他的な URI (Uniform Resource Identifier) を特徴とする外部鍵を開始します。
2. Cloud KMS 内で、Google Cloud プロジェクトに鍵を使用する権限を許可します。
この選択が正しくない理由は、Google Cloud サービスである Cloud KMS を介して外部鍵を開始することを誤って提案しているためです。この質問では、「Cloud External Key Manager」の必要性が明記されており、鍵を Google Cloud のインフラストラクチャの外部で管理する必要があります。
参考：
https://cloud.google.com/bigquery/docs/encryption-customer-managed-keys
https://cloud.google.com/ekm/docs
https://cloud.google.com/kms/docs/external-key-managers
</div></details>

### Q.  問題4: 未回答
ある多国籍小売企業は、e コマース分析を Google Cloud に移行しています。Cloud Spanner 内に保存されているデータの暗号化メカニズムをきめ細かく制御したいと考えています。
企業はどの方法を活用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Cloud Spanner に保存されているデータの暗号化を構成するための知識を評価します。保存データの暗号化オプションと、カスタマイズ可能なレベルの制御を提供する方法を理解することに重点を置いています。
重要な用語:
カスタマー管理の暗号鍵(CMEK): お客様が Google Cloud KMS で独自の暗号鍵を管理し、クラウド リソース内の保存データを暗号化するために使用される機能。
保存データ: デバイスからデバイスへ、またはネットワークからネットワークへアクティブに移動していないデータを指します。これには、ハードドライブ、ラップトップ、フラッシュドライブに保存されているデータ、またはその他の方法でアーカイブ/保存されているデータが含まれます。
Cloud Spanner: グローバル規模でのトランザクションの一貫性、自動マルチリージョン レプリケーション、高可用性を備えた、フルマネージドでスケーラブルなリレーショナル データベース サービスです。
正解解説:
(オプション)
・顧客管理の暗号鍵(CMEK)
顧客管理の暗号鍵(CMEK)を使用すると、組織は Google Cloud Key Management Service(KMS)内で制御、管理する暗号鍵を使用できるため、この選択は適切です。CMEK を使用することで、小売企業は Cloud Spanner で保存されているデータの暗号化をきめ細かく制御でき、カスタマイズ可能なセキュリティ対策の要件を満たしながら、潜在的な規制要件へのコンプライアンスを維持できます。
不正解の説明:
オプション: Cloud Spanner を BigQuery の外部データソースとして活用する
この選択が間違っている理由は、Cloud Spanner を BigQuery の外部データソースとして使用することは、Cloud Spanner 自体の保存データの暗号化ではなく、データ分析に関係しているためです。暗号化メカニズムの制御は提供されません。
オプション: クラウド ハードウェア セキュリティ モジュール(Cloud HSM)を実装する
この選択が間違っている理由は、Cloud Hardware Security Module(Cloud HSM)は鍵管理用のハードウェア環境を提供することで暗号鍵の使用を補完しますが、Cloud Spanner の保存データの暗号化方式は決定しないからです。
オプション: 独自の暗号化キー (CSEK) を指定します。
この選択が間違っている理由は、独自の暗号鍵(CSEK)の提供が Cloud Spanner でサポートされている機能ではないためです。CSEK は通常、各操作にキーを提供することを指し、ストレージ レベルでの暗号化の管理とは異なります。
参考：
https://cloud.google.com/bigquery/docs/encryption-cmek
https://cloud.google.com/kms/docs
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題5: 未回答
ある医療研究会社は、研究者とセキュリティ担当者の両方がアクセスできる Google Cloud Storage バケットに患者のケース スタディ ドキュメントをアーカイブしています。研究者は、患者の健康情報(PHI)を含まないケーススタディの閲覧のみを許可されるべきです。PHIを含むドキュメントは、セキュリティ担当者のみがアクセスできる別のバケットに保管する必要があります。
これを実現するための最良のアプローチは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud のデータ ストレージとプライバシー対策に関する知識を調べます。コンテンツの機密性に基づいて機密データを分離する安全な環境を作成し、自動化されたデータ処理とプライバシーコンプライアンスの理解を示す必要があります。
重要な用語:
Cloud Pub/Sub: アプリケーションやサービス間でイベントデータを交換するためのメッセージングサービス。イベント インジェストおよび配信システムとして機能し、イベント駆動型アーキテクチャを促進します。
Cloud Functions: クラウド サービスを構築および接続するためのサーバーレス実行環境。これは、Cloud Storage、Pub/Sub、または直接呼び出しからのイベントによってトリガーされます。
データ損失防止 (DLP) API: データ検査、分類、および秘匿化機能を提供するサービス。これは、データストリームまたは保存されたデータ内の機密情報を見つけて匿名化するのに役立ちます。
正解解説:
(オプション)
・Cloud Pub/Sub と Cloud Functions を使用して、ドキュメントが共通バケットにアップロードされるたびに情報漏えい対策スキャンをトリガーします。PHI が見つかった場合、関数はそれをセキュリティ担当者専用の Cloud Storage バケットに転送する必要があります。
この選択は、PHIを含むドキュメントをスキャンして分離するプロセスを自動化するため、効果的です。Cloud Pub/Sub と Cloud Functions が連携して、ドキュメントのアップロード時にスキャンを開始します。PHI がデータ損失防止 (DLP) API によって検出されると、システムはドキュメントを保護されたバケットに自動的に再配置します。これにより、手作業によるエラーが最小限に抑えられ、許可された担当者のアクセスを妨げることなく、データプライバシー規制への準拠が保証されます。
不正解の説明:
オプション: ケーススタディ・ドキュメントを共通バケットとセキュリティ担当者の専用バケットの両方に同期します。Cloud Data Loss Prevention API を使用してジョブトリガーを設定し、PHI を含むドキュメントを共通バケットから消去します。
この選択が正しくない理由は、DLP スキャンが実行される前に同期が行われるため、機密性の高い PHI が最初に公開される潜在的なリスクに起因します。アップロード後の自動消去では、一時的なリスクは軽減されません。
オプション: 研究者とセキュリティ担当者の両方が使用できるバケットにオブジェクトライフサイクル管理を設定して、PHIを含むドキュメントを自動的に消去します。
この選択が適切でない理由は、オブジェクト・ライフサイクル管理が、コンテンツの機密性ではなく、経過時間やその他の基準に基づいてオブジェクトの削除またはアーカイブを管理するように設計されているためです。抹消する前にPHIを検出するメカニズムがありません。
オプション: 研究者とセキュリティ担当者の両方がアクセスするバケットに、アップロードされたドキュメントで PHI が検出された場合にのみアクティブ化される Cloud Storage トリガーを構成します。Cloud Functions を利用してトリガーを処理し、そのようなドキュメントを消去します。
このオプションが失敗する理由は、ネイティブ機能ではない Cloud Storage イベントをトリガーする PHI の検出に依存しているためです。Cloud Storage トリガーと Cloud Functions を併用して消去しても、リアルタイムの PHI 検出は提供されないため、機密データが公開されます。
参考：
https://cloud.google.com/storage/docs/using-pubsub
https://cloud.google.com/dlp/docs/quickstarts
https://cloud.google.com/functions/docs/calling/storage
</div></details>

### Q.  問題6: 未回答
組織のセキュリティ チームとインフラストラクチャ チームは、クラウド仮想プライベート ネットワーク内およびクラウド仮想プライベート ネットワーク間の異常なネットワーク アクティビティを追跡し、ある Compute Engine インスタンスから別のインスタンスへの内部トラフィックを監視し、国際的なエンドポイントからインスタンスへの交換を監視し、インスタンスから本番環境のさまざまな Google Cloud サービスへのトラフィックを精査する必要があります。
これを実現するには、どの方法が最も適切ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud Virtual Private Network 内のネットワーク トラフィックのモニタリングと保護に関する知識を評価します。具体的には、セキュリティと監査の目的で、ネットワーク内および外部のパケット交換を監視および分析するための最も効果的な方法を特定することを目的としています。
重要な用語:
Packet Mirroring: 指定されたイングレス/エグレストラフィックのコピーをインスタンスに複製し、分析のために指定されたパケットコレクタに配信するネットワークサービス。
VPC フローログ: 同じ VPC 内、VPC 間、Google サービスと VM 間のトラフィックなど、VM インスタンスとの間で送受信されるネットワーク フローのログ記録を有効にする機能。
組織のポリシーの制約: ガバナンスとコンプライアンスの要件に準拠するために、GCP 組織全体に特定のリソース構成を適用するのに役立つポリシー。
Cloud 監査ログ: Google Cloud 内のユーザー、管理者、その他の関係者が実行したアクションを記録し、誰が、どこで、いつ、何をしたかを追跡するログ。
正解解説:
(オプション)
・Packet Mirroringの設定
パケット ミラーリングでは、Compute Engine VM または特定の Google Kubernetes Engine ノードからのネットワーク トラフィックを複製して詳細な分析を行うことができるため、この選択が最も適しています。トラフィックのミラーコピーを持つことで、サードパーティまたは独自のネットワーク監視アプライアンスを使用してトラフィックを検査し、VPC内通信と外部エンドポイント通信の両方で、異常なアクティビティや悪意のあるアクティビティの検出を含む高度なセキュリティとトラフィック分析を行うことができます。
不正解の説明:
オプション: 組織のポリシー制約を実装します。
組織のポリシー制約の実装が正しくない理由は、これらの制約が、ネットワーク アクティビティを積極的に追跡するのではなく、組織全体のリソース構成とコンプライアンスを管理することを目的としているためです。
オプション: サブネットレベルの VPC フローログをアクティブ化します。
サブネットレベルの VPC フローログのアクティブ化が正しくない理由は、ネットワークフローを可視化する一方で、高度な分析に必要なネットワークトラフィックのリアルタイム検査や複製を許可しないためです。
オプション: Cloud Audit Logs を調べて解釈します。
Cloud Audit Logs の調査と解釈が正しくない理由は、これらのログは、セキュリティ監視に必要な詳細なネットワーク トラフィック分析ではなく、管理アクションとサービスへのアクセスに関する情報を提供するためです。
参考：
https://cloud.google.com/vpc/docs/packet-mirroring
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/logging/docs/audit
</div></details>

### Q.  問題7: 未回答
あなたのチームは、機密性の高い顧客情報に対する暗号化キーガバナンスの管理について懸念を表明している国際金融機関と協力しています。この機関は、この情報を保護するために使用される暗号化キーを、データが保存されているのと同じクラウドサービスプロバイダー内に保持しないことを主張しています。
どの Google Cloud オプションを提案しますか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud のデータ保護機能、特にセキュリティ コンプライアンスを強化するためにデータ ストレージと暗号鍵管理を分離する暗号鍵管理ソリューションに関する受験者の知識を評価します。
重要な用語:
顧客提供の暗号化キー: 顧客が独自の暗号化キーを生成して管理し、保存データを暗号化するためにクラウドプロバイダーに提供できるようにすることで、クラウド環境の外部で独立したキー制御が可能になります。
Cloud External Key Manager: 暗号鍵を外部で管理するサービスで、ユーザーは Google のインフラストラクチャの外部に保存されている暗号鍵を使用しながら、データの処理と保存に Google Cloud サービスを利用することができます。
正解解説:
(オプション)
・お客様提供の暗号鍵
・Cloud External Key Manager(クラウド外部キーマネージャー)
[顧客提供の暗号鍵] を選択すると、教育機関は独自の暗号鍵を Google Cloud サービスに提供することで、暗号鍵のガバナンスを管理できます。Cloud External Key Manager はさらに一歩進んで、教育機関が選択した外部鍵管理サービスで暗号鍵を使用、管理できるようにすることで、鍵が Google Cloud のインフラストラクチャの外部に完全に残るようにし、鍵の個別の保管と管理に関するクライアントの要件を満たします。
不正解の説明:
オプション: Google が管理する暗号鍵
Google が管理する暗号鍵が適切でない理由は、これらの鍵が Google Cloud によって完全に管理されているためです。つまり、キー管理はサービス内に統合されており、金融機関が必要とする分離は提供されません。
オプション:シークレットマネージャー
Secret Manager が正しくない理由は、保存データの暗号化キーを管理するためではなく、API キーや資格情報などのシークレットを保存および管理するために設計されているためです。
オプション: 顧客管理の暗号鍵(CMEK)
カスタマー管理の暗号鍵(CMEK)は、Google Cloud 環境内である程度の鍵管理制御を提供しますが、クライアントの要求に応じて Google Cloud サービスの外部で鍵を完全に管理することはできません。
参考：
https://cloud.google.com/kms/docs/external-key-manager
https://cloud.google.com/kms/docs/csek
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題8: 未回答
特殊なデータ・ストレージ・プロジェクトでデータ・ストレージに使用できるデータベースを制限したい。
どうすればこれを実現できますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の組織ポリシー サービスを使用してデータ ストレージ制限を実装するための知識を調べます。これは、制約を操作することで、特定のデータベースの使用を組織内の 1 つの専用プロジェクトに制限することです。
重要な用語:
組織ポリシー サービス: 組織の要件を反映したポリシーを一貫して適用するために、Google Cloud リソース階層全体に制約を構成するのに役立つサービスです。
compute.trustedImageProjects 制約: 指定されたプロジェクトから承認されたイメージのみを使用できるようにする制約で、承認されていないイメージや安全でない可能性のあるイメージの使用を防止します。
許可リスト操作: リストに含まれるもののみを明示的に許可し、それ以外はすべて拒否するポリシー操作。リソースの使用状況を制御するために、組織ポリシー サービスを通じて適用されます。
拒否リスト操作: 許可リストとは対照的に、このポリシー操作では、具体的にリストされているエンティティを禁止し、リストされていない他のすべてのエンティティを許可します。
正解解説:
(オプション)
・Organization Policy Service を使用して、組織レベルで compute.trustedImageProjects 制約を作成します。専用プロジェクトを、許可リスト操作で唯一の許可プロジェクトとして指定します。
組織ポリシー サービスを使用して compute.trustedImageProjects 制約を適用すると、組織内で使用できるコンピューティング リソースが効果的に制限されるため、この選択は適切です。許可された唯一のプロジェクトとして専用プロジェクトを指定することで、ポリシーは許可リストとして機能し、そのプロジェクトのデータベースのみにデータ保存の目的でアクセスできるようにします。これは、データストレージを単一の専用プロジェクトに制限するという質問の目標と一致しています。
不正解の説明:
オプション: 組織ポリシーサービスを使用して、組織レベルで compute.trustedImageProjects 制約を作成します。承認済みプロジェクトを拒否リスト操作の例外として指定します。
これが正しくない理由は、組織ポリシー サービスを使用する一方で、このアプローチでは、承認済みプロジェクト リストを拒否リスト操作の例外として定義することについて説明しているためです。これは、拒否リストで例外を定義するのではなく、特定のリソースの使用を明示的に許可する必要があるため、許可リストがどのように機能するかではありません。
オプション: リソース マネージャで、専用プロジェクトのプロジェクト設定を変更します。コンピュート・イメージ・ユーザー・ロールを持つメンバーとして組織を含めます。
これが間違っている理由は、リソース マネージャーでプロジェクト設定を変更しても、組織全体のデータ ストレージの使用に制限が適用されないためです。組織をコンピュート・イメージ・ユーザーとして含めても、データベースの使用が1つのプロジェクトに制限されるわけではありません。
オプション: リソース・マネージャで、組織の権限を調整します。専用プロジェクト ID を Compute Image User ロールを持つメンバーとして追加します。
これが間違っている理由は、プロジェクトIDをコンピュートイメージユーザーとして追加するように組織の権限を調整しても、データベースの使用が制限されないためです。イメージ レベルでアクセス許可を付与するだけで、データ ストレージに必要な制約は適用されません。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
https://cloud.google.com/compute/docs/access/iam
</div></details>

### Q.  問題9: 未回答
CI / CD ワークフローをオーケストレーションして、Google Kubernetes Engine(GKE)上の医療機関の本番環境にマイクロサービスを一貫して配信しています。特定された脆弱性を持つマイクロサービスのリリースがブロックされていることを確認する必要があります。システムの要件は次のとおりです。
- Google Cloud のネイティブ機能を活用する必要がある
- 費用対効果が高いこと
- 手作業による管理の必要性を減らすことを目指す
これらの基準を満たすために、どのような手順を実行しますか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、セキュリティとコンプライアンスを CI / CD パイプラインに統合して、マイクロサービスを GKE に安全にデプロイする方法の理解度を評価します。脆弱性の検出を自動化して手作業の手間を省き、Google Cloud のネイティブ ツールを活用してセキュリティを強化することに重点を置いています。
重要な用語:
Cloud Build:ソースコードをインポートし、ビルドを実行してソフトウェアを構築し、ビルドしたアーティファクトをGoogle Cloud Storageに出力するサービス。
Container Analysis:コンテナの脆弱性のメタデータを継続的に分析・保存するサービス。これは、Google Cloud のアーティファクト レジストリ サービスに統合されています。
Binary Authorization: イメージの出所と整合性を確認するポリシーを適用することで、信頼できるコンテナ イメージのみが GKE にデプロイされるようにするセキュリティ制御。
構成証明: コンテナ イメージが定義された一連の基準を満たしていることを確認するセキュリティ アサーションで、イメージの信頼性を確保するために GKE のバイナリ認証と併用されることがよくあります。
正解解説:
(オプション)
・Cloud Source Repositories に保存されているマイクロサービス コードの変更を評価する Cloud Build ワークフローを統合します。ビルドが進行する前に、Container Analysis の結果を検査する検証手順を導入します。
・脆弱性のない検証後にマイクロサービスイメージの認証を組み込みます。Binary Authorization ポリシーを実装して、構成証明のないマイクロサービスが GKE 環境でロールアウトされるのを拒否します。
最初の選択肢は、Cloud Build と Cloud Source Repositories を統合してビルドを自動的にトリガーし、Container Analysis を使用してデプロイ前に脆弱性を特定する方法です。2 番目の選択肢では、脆弱性チェックに合格したイメージの構成証明を設定し、準拠しているイメージのみがバイナリ承認によってデプロイされるようにする必要があります。これらの戦略を組み合わせることで、コンテナのセキュリティとコンプライアンスに関する Google Cloud のベスト プラクティスに準拠した、自動化された安全なデプロイ プロセスが実現します。
不正解の説明:
オプション: Google Cloud のオペレーション スイートのログ アクティビティを通じて呼び出される Cloud Functions の関数を使用して、Container Registry 内のマイクロサービス イメージに対して自動スキャンを実行します。
この選択が間違っている理由は、Cloud Functions を使用してスキャンを実行すると、スキャンをトリガーして結果を処理するための手作業が増加し、手動管理を減らし、ネイティブ機能を活用するための基準と一致しないためです。
オプション: Compute Engine 仮想マシンで、既知の脆弱性についてソースコード リポジトリ全体で定期的なスキャンを実行し、検出された非準拠のマイクロサービス イメージに対してアラートを通知するスケジュールされたタスクを設定します。
この選択が間違っている理由は、定期的なスキャンのためにスタンドアロンの仮想マシンを運用することは費用対効果が高くなく、Google Cloud のネイティブ機能を活用できないため、指定された要件を満たしていないためです。
オプション: GKE で Jenkins インストールを構成して、マイクロサービスを Container Registry にプッシュする CI / CD ワークフローを作成します。マイクロサービス イメージを運用環境にデプロイする前に、その検証プロセスを確立します。
この選択が間違っている理由は、イメージを Container Registry にプッシュするように GKE で Jenkins を構成するには、複雑なスクリプトと手動による監視が必要であり、人為的エラーの可能性が高くなり、手動管理が最小限に抑えられないためです。
参考：
https://cloud.google.com/build/docs/automating-builds/build-repos-from-source
https://cloud.google.com/binary-authorization/docs
https://cloud.google.com/container-analysis/docs/getting-started
</div></details>

### Q.  問題10: 未回答
お客様は、Google Cloud での会社の医療データ管理を監査し、HIPAA コンプライアンスを確保する任務を負っています。このコンプライアンスに関連する Google の組み込みコントロールを特定する必要があります。
この情報を明らかにするために、どのリソースを調べる必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 内の HIPAA コンプライアンスを監査するための適切なリソースを特定するためのクラウド プロフェッショナルの知識を評価します。ここでは、Google とユーザー間のセキュリティ責任の分担を理解することに重点を置いています。
重要な用語:
責任共有モデル:クラウドサービスプロバイダーが使用するセキュリティフレームワークで、プロバイダーとユーザーの役割と責任を明確にします。これは、クラウドのコンプライアンスとデータセキュリティ戦略において極めて重要です。
HIPAAコンプライアンス:HIPAAによって組織された保護された医療情報の使用と共有に関する基準と保護を満たすことを指し、医療提供者は遵守する必要があります。
Google Cloud コンプライアンス リソース: Google が提供するドキュメントとリソースで、クラウド サービス内の HIPAA を含むさまざまな標準への準拠に関するガイダンスと詳細を提供します。
正解解説:
(オプション)
・Google Cloud: 責任共有マトリックス
Google Cloud: 責任共有マトリックスでは、Google Cloud とその顧客間のセキュリティとプライバシーの責任の分担が説明されているため、この選択は正確です。これは、Google が医療データを管理するための組み込みコントロールをどのように実装しているかについての具体的な情報を提供するため、クラウドでの HIPAA コンプライアンスにとって非常に重要です。企業はこのリソースを使用して、Google Cloud サービスを使用する際に HIPAA コンプライアンスを維持するために何をする必要があるかを理解できます。
不正解の説明:
オプション: HIPAA セキュリティ規則とプライバシー規則
この選択が間違っている理由は、HIPAA セキュリティ ルールとプライバシー ルールを理解することはコンプライアンスに不可欠ですが、これらのルールでは、クラウド環境での運用上の責任に関する具体的なガイダンスや、Google の組み込みコントロールの詳細が提供されていないためです。
オプション:HIPAAとクラウドコンピューティングに関するHHSガイドライン
この選択が間違っている理由は、HHS ガイドラインが HIPAA に基づくクラウド サービスの使用に関する公式情報を提供している一方で、Google がクラウド環境内で引き受けている特定の責任分担に焦点を当てていないためです。
オプション: Healthcare API の製品ドキュメント
この選択が間違っている理由は、Healthcare API のプロダクト ドキュメントには、そのサービスの機能とユースケースに関する具体的な情報が記載されていますが、Google のすべてのコンプライアンス対策や共同責任の概要が示されていないためです。
参考：
https://cloud.google.com/docs/security/compliance/customer-responsibility
https://cloud.google.com/security/compliance/pci-dss
https://cloud.google.com/compute/docs
</div></details>

### Q.  問題11: 未回答
あなたの会社は農業研究に従事しており、BigQuery で実施されている最近の実験のデータを処理する必要があります。施肥期間には、開始日と終了日が組み込まれています。この期間データは解析に不可欠ですが、正確な日付によって特定の作物サイクルが特定され、結果が歪む可能性があります。各エントリの開始日と終了日は、期間情報を保持したまま不明瞭にする必要があります。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、分析のための相対的な期間の詳細を維持しながら、プライバシーのためにデータセット内の機密性の高い日付情報を不明瞭にするという課題に対処します。その目的は、処理されたデータが、農業サイクルに関連する元のタイミングシーケンスを損なうことなく、分析のための価値を確実に保持することです。
重要な用語:
日付シフト: 日付を一定の量だけシフトすることで匿名化し、シフトされた日付間の間隔を元の日付間の間隔と同じに保ち、期間情報を保持する手法。
コンテキスト属性: 日付シフトなどの匿名化手法を使用するときに、異なるレコード間で同じ入力値が反復可能な方法で一貫して難読化されるようにするために使用される一意の識別子。
正解解説:
(オプション)
・作物サンプルの一意のIDに設定されたコンテキストで日付シフトを使用します。
日付シフトでは、開始日と終了日の間の間隔期間を維持しながら、一貫した方法で日付を変更できるため、この選択が最も適しています。コンテキストを作物サンプルの一意のIDに設定することで、個々のエントリが一貫した方法で難読化され、相対的な期間が保持され(分析にとって重要)、逆算によって特定の作物サイクルが損なわれるリスクが軽減されます。
不正解の説明:
オプション: 各日付フィールドから TimePartConfig を使用してコンポーネントを抽出し、ランダムな月と年と組み合わせることで、新しい日付を生成します。
この選択が正しくない理由は、コンポーネントを抽出してランダムな月と年と組み合わせると、日付間の元の間隔の長さが乱れるためです。この恣意的な変更により、期間データの重要性が低下し、分析が歪められる可能性があります。
オプション: 値バケットを使用して、元の値に従って日付を標準日付に再割り当てします。
この選択が正しくない理由は、バケット値によって日付が一般化される可能性がある一方で、値が標準日付に再割り当てされ、開始日と終了日の間の期間情報が失われる可能性があるためです。分析に不可欠な相対的な間隔を維持できません。
オプション: 暗号化されたデータの一貫性を確保しながら、形式保持暗号化 (FPE) の FFX モードを採用します。
この選択が間違っている理由は、形式を保持する暗号化では、データ形式は維持されますが、本質的に日付間の間隔は保持されないためです。時間的制約のある農業データの分析にとって重要な開始日と終了日の関係が損なわれていないことを保証することはできません。
参考：
https://cloud.google.com/bigquery/docs/tokenizing-data
https://cloud.google.com/bigquery/docs/reference/standard-sql/date_functions
https://cloud.google.com/blog/products/data-analytics/tips-for-using-the-bigquery-data-transfer-service
</div></details>

### Q.  問題12: 未回答
会社では、Google Managed Encryption Keys(GMEK)を使用して Cloud Storage に動画をアーカイブしていましたが、カスタマー管理の暗号鍵(CMEK)の使用を義務付ける新しいポリシーに準拠する必要があります。あなたは、ビデオを迅速かつ費用対効果の高い方法で再暗号化する任務を負っています。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、アーカイブされたコンテンツを Google が管理する暗号鍵から Cloud Storage のカスタマー管理の暗号鍵に移行して、強化されたセキュリティ コンプライアンス要件を満たすプロセスについて、迅速で費用対効果の高い戦略に焦点を当てています。
重要な用語:
Google Managed Encryption Keys(GMEK): GMEK は Google Cloud によって管理される暗号鍵を指し、ユーザーは鍵の作成、ローテーション、破棄などの鍵管理プロセスを制御できません。
カスタマー マネージド暗号化キー(CMEK): CMEK を使用すると、お客様は Google Cloud 内で独自の暗号化キーを管理できるため、暗号化キーの作成、ローテーション、セキュリティなど、キー管理をより詳細に制御できます。
書き換え操作: Google Cloud Storage のコンテキストでは、書き換え操作を使用して、オブジェクトをある場所から別の場所に移動またはコピーし、プロセス中にメタデータを変更したり、ストレージクラスを変更したりする可能性があります。
正解解説:
(オプション)
・バケットの暗号化設定をCMEKに変更し、動画の書き換え操作を開始する
この選択は、CMEK でデータを再暗号化するための最も効率的な方法です。CMEK を使用するように Cloud Storage バケットの暗号化設定を変更し、書き換えオペレーションを開始すると、動画は新しい鍵で再暗号化されます。このプロセスは Google Cloud によってサーバー側で処理されるため、時間とコストがかかる暗号化のために手動で再アップロードしたり、追加のローカル リソースやクラウド リソースを使用したりする必要がなくなります。
不正解の説明:
オプション: gsutil コマンドラインで CMEK を指定しながら、現在の Cloud Storage バケットに動画を手動で再度アップロードします。
この選択が間違っている理由は、ビデオを手動で再度アップロードすると時間がかかり、不要であるためです。gsutil コマンドの書き換え機能を使用すると、手動で再アップロードすることなく、CMEK を使用して再暗号化プロセスを自動化できます。
オプション: ローカル サーバーで動画を暗号化し、gsutil コマンドライン ツールを使用して、新しく作成したバケットに転送します。
この選択が間違っている理由は、動画をローカルで暗号化することの非効率さと、ネットワークが過度に使用され、Cloud Storage に転送するのに時間がかかる可能性があるためです。再暗号化に Cloud Storage の組み込み機能を使用する方が、はるかに実用的です。
オプション: CMEK が適用された別のバケットに動画を複製し、そのバケットが別の地域にあることを確認します。
この選択が間違っている理由は 2 つあります。データを別のバケットに複製すると、ストレージコストが増加する可能性があり、データを別の地理的リージョンに移動すると、レイテンシーの問題や追加の転送コストが発生し、再暗号化プロセスに関するメリットが得られない可能性があります。
参考：
https://cloud.google.com/storage/docs/encryption/using-customer-managed-keys
https://cloud.google.com/storage/docs/encrypting-objects
https://cloud.google.com/storage/docs/gsutil/commands/rewrite
</div></details>

### Q.  問題13: 未回答
組織はマルチテナントストリーミングサービスを運用しており、アプリケーションサーバー間のネットワーク相互作用に不規則なアクティビティがないか検査する必要があります。
Google Cloud 内のネットワーク トラフィックを精査するための推奨されるアプローチは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 内のマルチテナント環境でのネットワークの相互作用のモニタリングに関する受験者の知識を評価します。具体的には、異常なアクティビティを検出するためのリアルタイムのネットワーク精査に推奨される Google Cloud 機能を特定することに重点を置いています。
重要な用語:
Packet Mirroring:仮想マシン(VM)インスタンスなどのネットワークエンティティからのトラフィックのキャプチャとミラーリングを可能にする高度なネットワーク機能。これは主に、ネットワークパフォーマンスの監視、診断、およびセキュリティ分析の目的で使用されます。
正解解説:
(オプション)
・パケットミラーリングを設定して、検査用のトラフィックを複製します。
Packet Mirroring では、選択した Google Cloud VM インスタンスからトラフィックのコピーを作成することで、ネットワーク トラフィックを検査できるため、この選択は適切です。ミラーリングされたトラフィックは、マルチテナント環境内の不規則なアクティビティを検出するのに役立つ詳細な分析に使用できます。Packet Mirroring は、トラフィックの実際のフローに影響を与えることなく、ネットワーク パケットのコピーをセキュリティ アプライアンスに送信して検査します。
不正解の説明:
オプション: 許可されたネットワーク構成を管理する組織ポリシーを実装します。
この選択が間違っている理由は、組織のポリシーが主に Google Cloud リソースの管理方法に関する制約を定義することに重点を置いており、ネットワーク トラフィックの検査や不規則なアクティビティの検出のために特別に設計された機能が含まれていないためです。
オプション: 関連するネットワークサブネットの VPC フローログをアクティブ化します。
この選択が正しくない理由は、VPC フローログが、送信元、宛先、トラフィック量などのネットワークトラフィックに関するメタデータをキャプチャするために使用されるためです。ただし、異常や潜在的なセキュリティ脅威の詳細な検査やリアルタイム分析に必要な完全なペイロードデータは提供されません。
オプション: Cloud Audit Logs を利用して、ネットワーク イベントを監視、評価します。
この選択が間違っている理由は、Cloud Audit Logs が Google Cloud サービス内の管理操作とアクセスを記録するためです。ガバナンスと監査には重要ですが、リアルタイムのパケットレベルのネットワーク検査や、異常なネットワーク相互作用の即時検出には適していません。
参考：
https://cloud.google.com/vpc/docs/packet-mirroring
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/logging/docs/audit
</div></details>

### Q.  問題14: 未回答
Google Cloud Bigtable インスタンスを監督し、小売業の顧客とのやり取りをすべて行うデータ リポジトリとして機能します。顧客とのやり取りをすべて 1 つのテーブル内に維持すると同時に、クエリ アクセスが最小特権の原則に従って規制され、行ベースのアクセス許可と列ベースのアクセス許可のみに重点が置かれるようにすることを目的としています。クエリ以外の操作を禁止するつもりです。
どのようなアクションを取る必要がありますか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この Google Cloud 認定試験の問題では、最小権限の原則を守るために、特定の行レベルと列レベルのセキュリティ対策を使用して、クエリ以外のすべての操作をブロックしながら、Bigtable のデータへのアクセスを規制する方法に関する受験者の知識を評価します。
重要な用語:
行レベルのアクセス制御: 行に基づいて権限が設定されるデータベーステーブルのデータ可視性を管理し、クエリ実行中に行フィルタリングを有効にする方法。
列レベルのセキュリティラベル:列に添付されたラベルを使用してアクセス権を制御し、列ごとにきめ細かな権限管理を可能にするセキュリティ機能。
最小特権の原則: タスクの実行に必要なアクセス許可のみをユーザーに付与し、機密データやシステムへのアクセスを最小限に抑えることを含む重要なセキュリティ概念。
正解解説:
(オプション)
・フィルタ条件がFALSEと評価された場合にクエリ実行時に表示されるデータを制限する行レベルのアクセス制御を設計する。
・クエリ実行時のカラムの権限管理にカラムレベルのセキュリティラベルを実装
クエリのフィルター条件が FALSE と評価されたときにデータの可視性を制限する行レベルのアクセス制御を設計し、クエリの実行中にアクセス許可を管理するために列レベルのセキュリティ ラベルを実装することは、効果的な戦略です。これらの方法では、権限を行レベルまたは列レベルに微調整できるようにすることで、データアクセスをきめ細かく制御し、最小権限の原則に沿って、適切な権限を持つユーザーのみがデータにアクセスできるようにします。
不正解の説明:
オプション: 行レベルのアクセス制御を実装して、フィルター条件が TRUE と評価された場合のクエリの出力を制限します。
この選択が正しくない理由は、行レベルのアクセス制御の実装が、フィルター条件の TRUE 評価に基づいてはならないためです。これは、条件が満たされるたびに行へのアクセス権を付与することを意味し、最小特権の原則に違反する可能性があります。
オプション: クエリ中の列アクセスを管理するために、Google Cloud Key Management Service(KMS)に関連付けられた Authenticated Encryption with Associated Data(AEAD)コンストラクトをデプロイすることで、列レベルの暗号化を利用します。
この選択が間違っている理由は、KMS にリンクされた AEAD を使用した列レベルの暗号化は、アクセス制御メカニズムではなく、データ暗号化戦略であるためです。保存データのセキュリティに重点が置かれており、クエリ実行中の列アクセス許可は管理されません。
オプション: 動的データ難読化ポリシーを設定して、クエリ実行中の列アクセス パラメーターを管理します。
この選択が間違っている理由は、動的データの難読化がデータを匿名化するための手法であるためです。これは通常、クエリの実行中にデータへのアクセスやアクセス許可を規制するのではなく、機密情報を保護するために使用されます。
参考：
https://cloud.google.com/bigquery/docs/row-level-security-intro
https://cloud.google.com/bigquery/docs/column-level-security-intro
https://cloud.google.com/bigquery/docs/best-practices-access-control
</div></details>

### Q.  問題15: 未回答
あなたの会社は、医療分野の機密データを処理するウェブサービスを Cloud Run でホストしています。セキュリティを強化するために、同社はセキュリティの脆弱性のスキャンを実行します。コンプライアンスを厳格に守り、承認されたコンテナ イメージのみが Cloud Run のデプロイで使用されていることを確認する必要があります。
どの2つのステップを踏むべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、バイナリ認証を適用して Cloud Run サービスを保護するための受験者の専門知識を調べます。これは、機密性の高い医療データを処理するデプロイに承認されたコンテナイメージの使用を義務付けることで、セキュリティポリシーへの準拠を確保する方法の理解に疑問を投げかけます。
重要な用語:
Binary Authorization: 組織が設定したポリシーを適用することで、信頼できるコンテナ イメージのみがクラウド サービスにデプロイされるようにする方法を提供する Google Cloud 上のサービス。
組織ポリシーの制約: 組織内の Google Cloud リソースのリソース構成を定義する一連のルールで、コンプライアンスとガバナンスのルールを適用するのに役立ちます。
正解解説:
(オプション)
・デプロイした Cloud Run サービスのバイナリ認証を有効にして、セキュリティレイヤーを強化します。
・組織ポリシーの制約制約/compute.trustedBinaryAuthorizationPoliciesに、セキュアで承認されたコンテナイメージを保持するプロジェクトの識別子を設定します。
Cloud Run サービスのバイナリ認証を有効にすることは、承認および検証済みのコンテナ イメージのみがデプロイされていることを確認するために不可欠であり、これは医療分野の機密データにとって特に重要です。組織のポリシー制約 'constraints/compute.trustedBinaryAuthorizationPolicies' を構成すると、指定された信頼できるプロジェクトに格納されているコンテナー イメージのみにデプロイを制限することで、これらの厳しいセキュリティ標準が覆されます。
不正解の説明:
オプション: 組織ポリシー制約制約/run.permittedBinaryAuthorizationPolicies を適用して、受け入れ可能なバイナリ承認ポリシー識別子を指定します。
組織ポリシーの制約「constraints/run.permittedBinaryAuthorizationPolicies」が Google Cloud のポリシー管理内に存在しません。これは、組織のリソース管理に使用できるポリシーの制約を正しく理解していないことを意味します。
オプション: 構成済みの Google Kubernetes Engine クラスタでバイナリ認証をオンにして、コンテナ イメージを検証します。
Google Kubernetes Engine(GKE)クラスタでのバイナリ認証の有効化は、Cloud Run サービスのセキュリティとは無関係です。どちらのサービスもバイナリ認証を使用できますが、問題は特に Cloud Run デプロイに関連するソリューションを求めています。
オプション: Cloud Run の breakglass オプションを活用して、デフォルトで準拠するコンテナ イメージをデプロイする際にバイナリ承認ポリシーを適用します。
Cloud Run の「breakglass」オプションを使用すると、デバッグ目的でバイナリ承認ポリシーを一時的にバイパスすることになり、厳格なコンプライアンスと本番環境で承認されたイメージのみを許可するという目的に沿うものではありません。
参考：
https://cloud.google.com/binary-authorization/docs/using-binary-authorization
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/run/docs/configuring/container-images
</div></details>

### Q.  問題16: 未回答
大規模なeコマースプラットフォームのトランザクションレコードにデータセキュリティアーキテクチャを設定し、データの機密性に基づいて暗号化管理を最適化する必要があります。アーキテクチャは、次の基準を満たす必要があります。
- 価値の高いトランザクションデータの暗号化キーのローテーションを自動化します。
- 価値の高い取引記録を暗号化する鍵が、指定された地理的な場所に保存されていることを確認します。
- 価値の高いトランザクションレコードとバルクトランザクションレコードの両方で使用される暗号化キーの取得時間を短縮します。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、暗号化キーのローテーションを自動化し、キーの地理的なストレージを確保し、キーの取得時間を最適化できるデータセキュリティアーキテクチャを設計する能力を評価します。ここでは、Google が管理する鍵サービスと顧客管理の鍵サービスの使用の適切なバランスを判断することに重点を置いています。
重要な用語:
Cloud Key Management Service(Cloud KMS): データを保護するための暗号鍵を管理できるクラウドサービス。自動キーローテーションをサポートし、キーの地理的な場所を定義できます。
Google が管理する暗号鍵: ユーザー管理のオーバーヘッドなしに Google が完全に処理する暗号鍵。使いやすさは優れていますが、キー管理プロセスの制御は困難です。
データの機密性: 保護するデータの重要度を示す尺度で、多くの場合、データに適用される暗号化やキー管理などのセキュリティ対策の厳格さを決定します。
正解解説:
(オプション)
・Googleが管理する暗号鍵で一括取引記録を暗号化し、Cloud Key Management Serviceで高額な取引データを暗号化します。
この選択は、Cloud KMS を使用すると、鍵のローテーションと地理的な場所の制御が自動化され、価値の高いトランザクション データに関する懸念に対処できるため、すべての基準を満たすため、最適です。一括レコードの場合、Google が管理するキーは、より厳密な制御手段を必要とするため、オーバーヘッドが少なく、取得時間が短縮される可能性があります。
不正解の説明:
オプション:外部の鍵管理システムを使用して、一括取引記録と価値の高い取引データを暗号化します。
これが間違っている理由は、外部の鍵管理システムでは、Cloud KMS と同じレベルの鍵ローテーションの統合と自動化が提供されず、特定の場所での鍵の保管が保証されない可能性があるためです。
オプション: 一括取引記録と高額取引データの暗号化の両方に Cloud Key Management Service を利用します。
これが正しくない理由は、一括データに Cloud KMS を過度に使用しているため、不要なオーバーヘッドとコストが発生し、取得時間の最適化という点で比例したメリットが得られない可能性があるためです。
オプション: Google が管理する暗号鍵を使用して一括取引記録を暗号化し、外部の鍵管理システムを使用して価値の高い取引データを保護します。
これが正しくない理由は、基準を部分的に満たしているものの、価値の高いデータに外部システムを使用しても、場所の制御が低下するため、地理的なストレージ要件への準拠が保証されないためです。
参考：
https://cloud.google.com/kms/docs/encrypting-data
https://cloud.google.com/security/encryption-at-rest/default-encryption
https://cloud.google.com/kms/docs/rotating-keys
</div></details>

### Q.  問題17: 未回答
ある医療機関は、IT インフラストラクチャをレガシー データセンターから Google Cloud に移行しています。最初の動きは、アクティブな電子カルテのバックアップと緊急復旧システムを Google Cloud に移転することです。また、この医療機関は、次のフェーズでデータセンターの運用を Google Cloud に移行することを計画しています。レガシー データセンターと Google Cloud の間に一貫性のある信頼性の高いネットワーク接続を確立することが優先事項です。
医療機関はどの Google Cloud プロダクトを実装する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、特にバックアップやディザスタ リカバリの目的で、機密データをレガシー システムからクラウドに転送するために一貫性のある信頼性の高いネットワーク接続を必要とする医療機関にとって、適切な Google Cloud プロダクトの理解度を評価します。
重要な用語:
Cloud Interconnect: オンプレミス ネットワークと Google のネットワークの間に安全で高帯域幅の接続を提供し、パブリック インターネット接続と比較してレイテンシを低減し、信頼性を高めます。
gsutil: Google Cloud Storage 内のファイルを管理する Python ベースのコマンドライン ツール。これにより、同期タスクを作成してデータ転送を自動化できます。
電子カルテ(EHR):患者の紙のカルテのデジタル版。EHRには、病歴、診断、投薬、治療計画、予防接種日、アレルギー、および検査結果が含まれています。
正解解説:
(オプション)
・Cloud Interconnectによるgsutil同期タスクのスケジュール設定によるCloud Storage
Cloud Storage は、電子カルテのバックアップに適した、耐久性と可用性に優れたオブジェクト ストレージを提供するため、この選択は適切です。Cloud Interconnect を活用することで、機密性の高い医療データの大規模な転送に最適な、安全で高スループットな接続が保証されます。gsutil 同期タスクのスケジュールを設定することで、災害復旧や医療システム運用の冗長性に不可欠な、バックアップを同期するための自動化された一貫性のある方法が提供されます。
不正解の説明:
オプション: BigQuery で Cloud VPN 経由の連続ストリーミング データ転送ジョブを使用
これが間違っている理由は、BigQuery が分析データ ウェアハウスであり、EHR のバックアップとディザスタ リカバリを目的として設計されていないためです。さらに、Cloud VPN 経由のストリーミング転送は暗号化されていますが、Cloud Interconnect と同じレベルの帯域幅と信頼性は提供されません。
オプション: 永続ディスクと Cloud Interconnect を介したデータ レプリケーションを備えた Compute Engine インスタンス
これが間違っている理由は、Compute Engine インスタンスはさまざまな目的に使用できますが、Interconnect 経由のバックアップに永続ディスクを使用すると、Cloud Storage などのストレージのニーズに合わせて調整されたソリューションが考慮されないためです。通常、Compute Engine はバックアップよりもアクティブなワークロードに適しています。
オプション: Cloud VPN 経由の定期的なバッチ データ インポート プロセスを備えた Firestore
これが間違っている理由は、Firestore がアプリのデータの保存、同期、クエリ用に設計された NoSQL ドキュメント データベースであるためです。Cloud VPN は安全な接続を提供しますが、Firestore は健康記録のバックアップや緊急復旧システムに最適なソリューションではありません。
参考：
https://cloud.google.com/storage/docs/uploading-objects
https://cloud.google.com/interconnect/docs
https://cloud.google.com/storage/docs/using-object-versioning
</div></details>

### Q.  問題18: 未回答
Google Cloud からのすべての外部ウェブ トラフィックを、企業のデータセンターのインターネット接続経由で転送しています。あなたは、これが安全に、そして利用可能な最大限の帯域幅で実行されるようにする任務を負っています。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud から企業のデータセンターへの安全で効率的なトラフィック ルーティングに関する知識を評価します。これには、外部システムへの安全で高帯域幅の接続を可能にする基盤となるネットワークサービスと構成を理解することが含まれます。
重要な用語:
Cloud Interconnect: Google のネットワークと企業の内部ネットワークをエンタープライズ レベルの直接接続で接続します。低遅延、帯域幅の増加、およびプライベート接続を提供します。
データセンターベースのファイアウォール:企業のデータセンター内に配置された物理的または仮想的なファイアウォールで、事前に定義されたセキュリティルールに基づいて送受信ネットワークトラフィックを監視および制御します。
ルートトラフィック:セキュリティポリシーやネットワーク効率などの特定の基準に基づいて、ネットワークトラフィックを送信するネットワーク内のパスを選択するネットワークプロセスを指します。
正解解説:
(オプション)
・Cloud Interconnectを設定し、データセンターベースのファイアウォール経由でトラフィックをルーティングします。
Cloud Interconnect では、Google Cloud とオンプレミス ネットワーク間の高帯域幅、低レイテンシのプライベート接続が可能になるため、この選択が最適です。トラフィックがインターネットに到達する前にデータセンターベースのファイアウォールを介してルーティングすることで、セキュリティと企業ポリシーの遵守の両方を確保しながら、帯域幅の使用率を最大化できます。Cloud Interconnect は、このようなユースケース向けに明示的に設計されており、パブリック インターネット ベースのソリューションと比較して信頼性とパフォーマンスが向上しています。
不正解の説明:
オプション: Google Cloud への HA VPN 接続を確立し、この接続を利用するようにデフォルトのインターネット ルートを更新します。
この選択が間違っている理由は、HA VPN は Google Cloud と企業ネットワーク間の安全な接続を提供しますが、通常、Cloud Interconnect に比べて帯域幅の機能が低く、最適な帯域幅使用率ではなく冗長性を考慮して設計されているためです。
オプション: Compute Engine で専用ルーティング インスタンスを設定し、このインスタンスをネクストホップとして使用するようにデフォルトのインターネット ルートを調整します。
この選択が間違っている理由は、Compute Engine で専用ルーティング インスタンスを設定しても、Cloud Interconnect と同じレベルの帯域幅と低レイテンシが提供されず、物理的なデータセンター ベースのファイアウォールと同じレベルのセキュリティとコンプライアンスも提供されないためです。
オプション: Cloud Interconnect を HA VPN と一緒に設定し、デフォルトのインターネット ルートを社内のデータセンターを指すように変更します。
この選択が間違っている理由は、Cloud Interconnect を HA VPN と併用すると冗長になり、帯域幅やセキュリティを改善せずに不必要な複雑さが加わるためです。推奨されるアプローチは、セキュリティと帯域幅の最適化の両方のために、データセンターベースのファイアウォールを介した適切なルーティングで Cloud Interconnect を利用することです。
参考：
https://cloud.google.com/interconnect/docs
https://cloud.google.com/network-connectivity/docs/vpn/concepts/overview
https://cloud.google.com/network-connectivity/docs/interconnect/concepts/throughput
</div></details>

### Q.  問題19: 未回答
あなたは、医療業界の Google Cloud プロジェクト(プロジェクト X)を監督しており、API アクセスを阻止する VPC Service Control(SC)境界で保護されており、Cloud Storage に影響を与えています。VPC SC 境界で保護されていない別のプロジェクト(プロジェクト Y)のサービス アカウントを使用するコンピューティング インスタンスには、プロジェクト内の Cloud Storage バケットからデータを読み取る機能が必要です。最小権限の原則に従いながら、プロジェクト Y からプロジェクト X の Cloud Storage バケットへの読み取りアクセスを容易にする必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問には、VPC Service Control で保護されたプロジェクト内の Cloud Storage バケットを読み取るためのコンピュート インスタンスのプロジェクト間のアクセスの構成が含まれます。これは、安全なクラウド環境でプロジェクト間のアクセスを可能にしながら、最小特権の原則を遵守することに重点を置いています。
重要な用語:
VPC Service Controls: VPC Service Controls は、リソースの周囲に境界ベースの保護を提供し、データ流出を防ぐことで、GCP サービスに保存されている機密データのセキュリティを強化します。
最小特権の原則: 職務を遂行するために必要な最低限のアクセスレベル (またはアクセス許可) をユーザーに付与するセキュリティ概念。
イングレスポリシー: VPC Service Controls のコンテキストでは、イングレスポリシーによってサービス境界内のリソースへの受信リクエストが制御され、保護された境界に入ることができるものを指定できます。
正解解説:
(オプション)
・プロジェクトXのSC境界のイングレスポリシーを設定し、プロジェクトYのサービスアカウントにバケットからデータを読み取る権限を付与します。
この選択は、シナリオに最も安全で適切です。プロジェクト Y のサービス アカウント専用のイングレス ポリシーを設定することで、アクセスを絞り込み、必要以上にアクセスを広げることなく、そのアカウントがプロジェクト X の指定された Cloud Storage バケットから読み取れるようにします。このアプローチは、最小権限の原則に厳密に準拠し、サービス アカウントが機能するために不可欠な権限のみを付与し、VPC Service Controls 境界の整合性を維持します。
不正解の説明:
オプション: プロジェクト Y のアナリストがプロジェクト X の Cloud Storage バケットからデータを読み取ることを許可するアクセスレベルを設定します。
この選択が間違っている理由は、プロジェクト Y のすべてのアナリストにデータへのアクセスを許可することで特権を過剰に拡張し、最小特権の原則に違反し、機密性の高い医療データを権限のないユーザーに公開する可能性があるためです。
オプション: 境界ブリッジを構成して、プロジェクト X とプロジェクト Y 間の無制限のデータ転送を許可します。
この選択が正しくない理由は、2 つのプロジェクト間で無制限のデータ転送を許可することで境界セキュリティが損なわれ、最小特権の原則が無視され、機密データが公開される可能性があるためです。
オプション: プロジェクト X の VPC SC 境界設定の制限付きサービスリストから Cloud Storage API を除外します。
この選択が間違っている理由は、Cloud Storage API を VPC SC の制限から広く除外することで、全体的なセキュリティが弱まるためです。このアクションは最小特権の原則に準拠しておらず、データ流出のリスクにつながる可能性があります。
参考：
https://cloud.google.com/vpc-service-controls/docs/ingress-policy
https://cloud.google.com/vpc-service-controls/docs/perimeter-bridges
https://cloud.google.com/pubsub/docs/access-control
</div></details>

### Q.  問題20: 未回答
Google Cloud の鍵管理サービスの鍵に関する特定の地理的データ ストレージ規制を満たすには、鍵マテリアルが asia-southeast1 と asia-northeast1 にのみ存在することを確認する必要があります。また、キーは両方の場所で高可用性を維持する必要があります。
これを実現するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の鍵管理サービス(KMS)の鍵の地理的データ所在地と高可用性の構成に関する受験者の知識をテストします。正しいセットアップは、データの保存場所を規定する特定の規制に準拠している必要があります。
重要な用語:
ユーザー管理レプリケーション ポリシー: これは KMS 内の特定の構成オプションであり、ユーザーは暗号化キー マテリアルを格納およびレプリケートするリージョンを選択でき、データ所在地を正確に制御できます。
データ所在地: データ所在地とは、データが保存される物理的な場所を規定する法律や規制を指します。データ所在地要件への準拠は、一部の組織にとって重要です。
高可用性: 高度なアップタイムで運用を継続するシステムの能力を指し、リソースが地理的な場所にレプリケートおよび分散される方法によって影響を受ける可能性があります。
正解解説:
(オプション)
・ユーザー管理のレプリケーションポリシーでキーリングを設定し、適切なリージョンを選択します。
この選択は、キーが格納される領域を制御できるため、適切なソリューションです。KMS 内のユーザー管理レプリケーション ポリシーでは、キーを格納するためのカスタムの場所を指定できるため、地理的なデータ ストレージ規制に確実に準拠できます。asia-southeast1 と asia-northeast1 の両方を選択すると、キーが両方の場所にレプリケートされ、要件に沿った高可用性が維持されます。
不正解の説明:
オプション: 自動レプリケーションポリシーを使用してキーリングを設定し、必要なリージョンを選択します。
この選択が正しくない理由は、自動レプリケーション ポリシーで特定のリージョンの選択が許可されていないためです。自動レプリケーションは、指定された地理的要件以外のリージョンを含む可能性のある、使用可能なすべてのクラウドリージョンにキーマテリアルを配布します。
オプション: Cloud Deployment Manager を使用して、asia-southeast1 と asia-northeast1 の 2 つの個別のキーリングを作成します。
この選択が正しくない理由は、異なるリージョンに個別のキーリングを作成しても高可用性が保証されないためです。レプリケーション ポリシーを使用しない場合、キーは各リージョンに独立して存在するため、単一障害点が発生する可能性があり、フォールト トレランスや高可用性はサポートされません。
オプション: キー リングに自動レプリケーション ポリシーを使用し、組織のポリシーを適用して、データ所在地のニーズ以外のリージョンでのキーの作成を制限します。
この選択が正しくない理由は、組織のポリシー ガバナンス アプローチで自動レプリケーション ポリシーを使用すると、許可されたリージョンの外部にキーが作成されないことが厳密に保証されないためです。これは、明示的な構成ではなくポリシーの適用に大きく依存しており、常に効果的であるとは限りません。
参考：
https://cloud.google.com/secret-manager/docs/configuring-replication
https://cloud.google.com/secret-manager/docs/locations
https://www.terraform.io/docs/providers/google/r/secret_manager_secret.html
</div></details>

### Q.  問題21: 未回答
組織のデータ アナリストは、分析のためにデータセットを自宅のコンピューターに頻繁にダウンロードします。データセットは、安全なデータ処理が認定された会社が発行したコンピューターにのみダウンロードできるようにする必要があります。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、許可されていないデバイスへのデータのダウンロードを防ぐためにセキュリティポリシーを適用する機能を評価します。これは、企業のデータセットが、安全なデータ処理プラクティスに準拠している認定された会社のデバイスにのみダウンロードされるようにすることに重点を置いています。
重要な用語:
BeyondCorp Enterprise: Google Cloud が提供するセキュリティ モデルとプロダクトで、多くの場合、ユーザーとデバイスのコンテキストの検証に基づいて、企業のデータやリソースへのゼロトラスト アクセスを可能にします。
デバイス証明書: ID をアサートするためにデバイスにインストールされるデジタル証明書。これは、リソースへのアクセスを許可する前にデバイスを認証するために、安全な環境内で使用されます。
アクセス ポリシー: ユーザー ID、デバイスのセキュリティ ステータス、その他の属性に基づいてリソースへのアクセスを許可または拒否するための基準を定義する、BeyondCorp などのセキュリティ サービスの構成。
正解解説:
(オプション)
・BeyondCorp Enterprise にアクセスポリシーを実装し、デバイス証明書を検証します。作成したばかりのアクセス・ポリシーでアクセス・バインディングを作成します。
この選択は、アクセスを許可する前にユーザーとデバイスのコンテキストを検証することでゼロトラスト セキュリティの原則をサポートする BeyondCorp Enterprise を活用するため、効果的です。デバイス認定に合わせたアクセス ポリシーを実装すると、適切なデバイス証明書を持つデバイスのみがデータセットをダウンロードでき、認定された会社発行のコンピューターのみがアクセスを許可するという要件と完全に一致します。
不正解の説明:
オプション: VPC Service Controls 境界を実装します。データセットをダウンロードする前に、プライベート接続を構成し、デバイス証明書を認証するポリシーを設定します。
この選択が間違っている理由は、VPC Service Controls が Google Cloud サービスに保存されているデータの周囲に安全な境界を作成し、流出リスクを防ぐように設計されているためです。データ アクセスに制約を課すことはできますが、ダウンロード機能をデバイスの認定状態に結び付けるという要件には特に対応していません。
オプション: エンタープライズ デバイス証明書の検証に基づいてダウンロード機能を制限する組織のポリシーを設定します。
この選択が間違っている理由は、組織のポリシーによって、Google Cloud 組織全体でのリソースの使用方法が管理されるためです。広範な制約を設定できますが、リアルタイムでのデバイス認証などの動的な条件に基づいてアクセスを強制するようには設計されていません。
オプション: データセットのダウンロードを許可する前に、有効なデバイス証明書をチェックする条件を含む Identity and Access Management (IAM) ポリシーを作成します。
この選択が正しくない理由は、IAMポリシーは、誰が(どのユーザー)どのリソースにアクセスできるかを制御する一方で、通常、ダウンロードデータセットへのアクセスを許可する前に、ユーザーのデバイスの状態や認証を検証するために使用されないためです。
参考：
https://cloud.google.com/beyondcorp-enterprise/docs/access-policies-introduction
https://cloud.google.com/identity-aware-proxy/docs/device-policy
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations
</div></details>

### Q.  問題22: 未回答
大手小売企業のセキュリティ マネージャーは、「retail-operations」フォルダにグループ化された一連の Google Cloud プロジェクトを監督し、オンライン、アウトレット、ポップアップ ストアなど、さまざまな小売チャネルに対応しています。不正な要素や脆弱なスクリプトによる潜在的なデータ流出を阻止するためのセキュリティ対策を確立しながら、プロジェクト間の円滑なコミュニケーションを維持することを目指しています。
どのようなアプローチを採用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、受験者は、フォルダ構造内の Google Cloud プロジェクトを保護するための適切なセキュリティ対策を選択するよう求められます。これは、複雑な小売業環境で必要なプロジェクト間通信を維持しながら、データ流出の防止を目的としています。
重要な用語:
Infrastructure-as-Code (IaC): 物理的なハードウェア構成や対話型構成ツールではなく、機械で読み取り可能な定義ファイルを使用してコンピューティング インフラストラクチャを管理およびプロビジョニングする方法。
サービス ペリメーター: Google Cloud の VPC Service Controls のコンテキストでは、サービス境界は、その境界内に存在するリソースとサービスを、その境界外のサービスによるアクセスから保護するセキュリティ境界です。
Cloud Pub/Sub: システムやアプリケーションをスケーラブルで信頼性の高いイベントの取り込みと配信と統合することで、非同期のサービス間通信を可能にするフルマネージドのリアルタイム メッセージング サービスです。
Cloud Function: クラウドサービスを構築および接続するためのサーバーレス実行環境。イベントドリブンであり、さまざまなクラウドサービスや外部ソースからのイベントに応答できます。
Terraform: HashiCorp Configuration Language (HCL) と呼ばれる宣言型構成言語、またはオプションで JSON を使用して、ユーザーがデータセンター インフラストラクチャを定義および提供できるようにする、オープンソースのコードとしてのインフラストラクチャ ソフトウェア ツール。
正解解説:
(オプション)
・Infrastructure-as-Codeソリューションをデプロイして統合サービス境界を作成し、Monitoring と Cloud Pub/Sub を通じて「retail-operations」フォルダを監視する Cloud Functions の関数を設定します。フォルダ内で新しいプロジェクトの追加が検出されると、Terraformがトリガーされ、確立されたサービス境界内に新しいプロジェクトが含まれます。
この選択は、コードとしてのインフラストラクチャ ソリューションのデプロイを推奨し、'retail-operations' フォルダーの下にあるすべてのプロジェクトに対して統合サービス境界を作成することです。これには、フォルダのアクティビティをモニタリングし、新しいプロジェクトが追加されたときに Terraform を使用してサービス境界を自動的に更新するように Cloud Functions の関数を設定することが含まれます。これにより、一元化されたセキュリティアプローチが可能になり、プロジェクトメンバーシップの変更は、手動の介入なしに保護境界に自動的に反映されるため、プロジェクトが誤って保護されないままになる可能性を防ぐことができます。
不正解の説明:
オプション: すべてのプロジェクトに共有 VPC を実装して相互接続を可能にし、特定のファイアウォール ルールで補完して、潜在的なデータ流出チャネルをブロックします。
この選択が間違っている理由は、共有 VPC を実装するだけではデータ流出から保護されないためです。プロジェクト間の接続性は実現しますが、新しいプロジェクトが統一されたセキュリティ境界に自動的に含まれることはなく、インフラストラクチャ保護の動的な側面には対応していません。
オプション: さまざまな Access Context Manager アクセス レベルを設定して、データ流出を防ぎ、共有 VPC を確立してプロジェクト間のやり取りを容易にします。
この選択が間違っている理由は、さまざまな Access Context Manager アクセス レベルを使用することの複雑な性質にあり、完全に管理しないとセキュリティにギャップが生じる可能性があります。さらに、共有 VPC はプロジェクト間の接続を提供しますが、インフラストラクチャ内の変更に自動的に対応する動的でスケーラブルなソリューションを提供しません。
オプション: Infrastructure-as-Code ソリューションを使用して、オンライン、アウトレット、ポップアップ ストアなどのチャネルごとに個別のサービス境界を構築し、Monitoring と Cloud Pub/Sub を使用して「retail-operations」フォルダを監視する Cloud Functions の関数を設定します。 新しいプロジェクトが特定された場合、関数は Terraform を使用して対応する境界に追加します。
この選択が間違っている理由は、小売チャネルごとに個別のサービス境界を作成すると複雑さが増し、チャネルの分類が変更されるたびに手動管理が必要になるためです。これにより、セキュリティの脅威への対応が遅くなり、人為的ミスのリスクが高まる可能性があり、特に大規模な小売企業にとって、効率の悪いアプローチになる可能性があります。
参考：
https://cloud.google.com/vpc-service-controls/docs/create-service-perimeters
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://www.terraform.io/docs/providers/google/r/google_folder.html
</div></details>

### Q.  問題23: 未回答
グローバルに分散した複数のゲームサービスについて、チームのアプリケーションクラッシュレポートを統合する必要があります。チームがログエクスプローラーを使用してクラッシュレポートを検索および分析できるようにする必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、グローバルに分散されたサービスからのログを一元化して分析するための Google Cloud の機能を活用する方法について、受験者の理解度を評価します。焦点は、チームがログエクスプローラーを使用してアプリケーションクラッシュレポートにアクセスして調査するための最も効率的な方法を決定することです。
重要な用語:
Logs Explorer: Google Cloud のオペレーション スイート内のツールで、ユーザーは Google Cloud のリソースやアプリケーションによって生成されたログを表示、検索、分析できます。
組織レベルのフィルタリング: 組織レベルで Google Cloud リソースにフィルタを設定することを指し、基盤となるすべてのフォルダとプロジェクトを網羅し、包括的なビューを提供します。
集約エクスポート: このプロセスでは、フォルダや組織など、指定した範囲内の複数のソースからログをコンパイルし、BigQuery や Pub/Sub などの指定された宛先にエクスポートします。
正解解説:
(オプション)
・ログエクスプローラーを組織レベルで使用し、ゲームサービスのログをフィルタリングします。
この選択により、ログエクスプローラーの機能を活用して組織レベルでログをフィルタリングおよび分析し、グローバルに分散されたゲームサービス全体のアプリケーションクラッシュレポートを含む、すべてのログデータの広範で一元的な視点を容易にします。組織レベルのフィルタリングを使用することで、チームはログを効果的に統合し、さまざまなフィルタリング基準を適用してゲームサービスのログに焦点を当て、ログエクスプローラーインターフェイス内で関連データを検索および分析する能力を強化できます。
不正解の説明:
オプション: Cloud Monitoring ワークスペースを有効にし、ゲームサービスをモニタリング構成に含めます。
選択肢 1 が間違っている理由は、Cloud Monitoring workspace はリアルタイムのパフォーマンス モニタリングやダッシュボードやアラートの作成には役立ちますが、質問に記載されている主な要件であるログの検索と分析用に設計されたツールではないためです。
オプション: ゲームサービスを含むフォルダレベルで集計エクスポートを作成し、コピー先を BigQuery データセットに設定します。
選択肢 2 が間違っているのは、BigQuery データセットへの集計エクスポートを作成するとログの分析が容易になるが、ログ エクスプローラと統合されていないためです。さらに、このシナリオでは、データセット分析ではなく、ログ エクスプローラー内の検索可能なログ データに重点が置かれています。
オプション: ゲームサービスを含むフォルダレベルで集計エクスポートを作成し、宛先を Pub/Sub トピックに設定します。
選択肢 3 が間違っている理由は、Pub/Sub トピックにエクスポートすると、さらにデータ処理や他のサービスとの統合が可能になりますが、質問で概説されているログ エクスプローラーによる直接検索と分析はサポートされていないためです。
参考：
https://cloud.google.com/logging/docs/explorer
https://cloud.google.com/logging/docs/aggregated-sinks
https://cloud.google.com/logging/docs/storage#log-entries-in-cloud-storage
</div></details>

### Q.  問題24: 未回答
あなたは医療会社のITコンサルタントです。同社は患者データを Google Cloud に移行することを検討していますが、執行役員会は極めて機密性の高いデータの保護に懸念を抱いています。特に、Google Cloud の担当者が Google Cloud に保存されている医療会社の患者情報にアクセスする可能性が懸念されています。
これらの懸念に対処するには、どのソリューションをお勧めしますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud への移行時に、医療機関の機密性の高い患者データへの不正アクセス(特に Google Cloud 担当者による不正アクセス)を防止する Google Cloud のコンプライアンスとセキュリティ機能に関する受験者の知識を評価します。
重要な用語:
アクセスの透明性: データや構成を操作する際に Google のスタッフが実行した Google Cloud Platform のアクションのログを提供し、プロバイダーによる運用アクセスを可視化します。
アクセス承認: Google がサポート目的でデータや設定を操作する必要がある場合に、Google のサポートやエンジニアリングによるデータへのアクセスを承認または拒否できる機能です。
正解解説:
(オプション)
・Google社員のアクセス承認リクエストでアクセスの透明性ログを有効にする。
この選択をお勧めするのは、アクセスの透明性ログとアクセス承認リクエストを組み合わせることで、医療機関が Google Cloud 担当者のデータへのアクセスを管理できるためです。アクセスの透明性を有効にすると、ユーザー コンテンツに対する Google スタッフの操作のログが生成され、可視性と監査証跡が提供されます。アクセス承認では、Google の従業員によるデータへのアクセスは、データ所有者からの明示的な承認を条件としているため、機密保持に関する取締役会の懸念に対処できます。
不正解の説明:
オプション: 顧客提供の暗号化キー (CSEK) を実装して、データの暗号化を管理します。
この選択が間違っている理由は、お客様指定の暗号鍵(CSEK)を使用すると、お客様は暗号鍵を制御し、保存データを暗号化できますが、Google の従業員によるデータへの直接アクセスを特に制御したり、ログに記録したりすることはないためです。
オプション: Google の Identity and Access Management(IAM)機能を利用して、Google Cloud 内にアクセス境界を設定します。
この選択が間違っている理由は、Google の IAM 機能は Google Cloud 環境内のアクセスを制御しますが、運用目的で顧客データにアクセスする際に Google のサポートとエンジニアリングが実行するアクションを管理または記録しないためです。
オプション: 「データアクセスログ」を有効にして、データへのアクセス要求を追跡します。
この選択が間違っている理由は、データアクセスログは、Google Cloud 担当者によるアクションではなく、ユーザーがデータにアクセスするリクエストを追跡するためです。これらのログは、アクセスを承認または拒否するための制御メカニズムを提供しません。
参考：
https://cloud.google.com/access-transparency
https://cloud.google.com/access-approval/docs
https://cloud.google.com/security/encryption-at-rest/default-encryption
</div></details>

### Q.  問題25: 未回答
企業は、地域のデータ処理センターと企業の仮想プライベートクラウド(VPC)ネットワークの間にクラウドインターコネクトリンクを確立する必要があります。目的は、地域のデータ処理アプリケーションが、公共のインターネット チャネルではなく、Cloud Interconnect を介してのみ Google サービスと通信できるようにすることです。サポートされていない API エンドポイントに関連する流出リスクを最小限に抑えるために、すべての API インタラクションは VPC Service Controls に準拠する必要があります。
これらの基準を満たすネットワーク構成はどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、企業の地域データ処理センターと Google Cloud VPC 間の安全な接続を構成し、Google サービスへの通信が Cloud Interconnect を介して行われ、VPC Service Controls に準拠していることを確認する能力を評価します。
重要な用語:
Cloud Interconnect: オンプレミス ネットワークと Google のネットワーク間の直接のプライベート接続を提供するサービス。
VPC Service Controls: VPC 内の Google Cloud サービスからのデータ流出を防ぐための境界を提供する一連のセキュリティ機能。
制限付き googleapis.com: Google Cloud 内からのみルーティング可能な一連の IP アドレスを使用して Google API へのアクセスを許可するエンドポイントで、パブリック インターネットにデータを公開しないことでセキュリティを強化します。
VPC: Google Cloud 内の仮想ネットワークで、リソースを起動できる Google Cloud のプライベートで分離されたセクションを提供します。
正解解説:
(オプション)
・制限付き googleapis.com を使用して、Google Cloud 内からのみルーティング可能な一連の IP アドレスを使用して Google API にアクセスし、Cloud Interconnect 接続を介したルートとしてアドバタイズします。
この選択は、「制限付き googleapis.com」アクセス方法を利用するため、Google API へのアクセスに使用される IP アドレスは非公開で、Google Cloud 内でのみルーティング可能であるため、最適です。これらの IP アドレスは Cloud Interconnect リンクを介してアドバタイズできるため、すべてのデータが Google のネットワーク内にとどまり、パブリック インターネットを通過しないため、データ流出のリスクを最小限に抑え、VPC Service Controls を順守するための基準を満たすことができます。
不正解の説明:
オプション: データ処理リージョン内のサブネットワークに対して限定公開の Google アクセスを有効にし、グローバル動的ルーティングを使用するようにネットワークを設定します。
このオプションが正しくない理由は、限定公開の Google アクセスでは、外部 IP アドレスを持たないリソースが Google API に到達できますが、Cloud Interconnect リンクへの API アクセスは制限されないため、データが指定された基準を満たさないパブリック インターネット ルートを通過する可能性があるためです。
オプション: 「all-apis」というラベルの付いた統合 API グループを使用して Private Service Connect エンドポイントの IP アドレスを設定し、Cloud Interconnect リンクを介してルートとしてブロードキャストします。
このオプションが正しくない理由は、Private Service Connect エンドポイントは Google サービスへのプライベート アクセスを提供しますが、「all-apis」というラベルの付いた統合 API グループを使用しても、トラフィックが Google のネットワーク内にとどまることや、サポートされていない API エンドポイントに対して特別に調整された VPC Service Controls に準拠していることが保証されないためです。
オプション: Google API のアクセシビリティに private.googleapis.com を採用し、Google Cloud 内でのみルーティング可能で、Cloud Interconnect を介してブロードキャストされる IP アドレスのグループを活用します。
このオプションが正しくない理由は、private.googleapis.com は Google API への内部アクセスを提供しますが、トラフィックが Cloud Interconnect パスのみを使用することや、要件に記載されている API エンドポイント サポートの VPC Service Controls に準拠することを明示的に示していないためです。
参考：
https://cloud.google.com/interconnect/docs/how-to/restricting-api-access
https://cloud.google.com/vpc-service-controls/docs/set-up-private-connectivity
https://cloud.google.com/vpc/docs/configure-private-google-access#restricted-google-access
</div></details>

### Q.  問題26: 未回答
あなたは、各部門に数千人の従業員がいる多国籍企業の IT 管理者です。アクセス制御権限の管理作業を各部門に分散させる必要があります。要件には次のものが含まれます。 - 個々の部門は、Google Cloud で独自のリソースを処理する自律性を持っている必要があります。- アクセス制御権限は、各部門内で大規模に効果的に管理する必要があります。- 部門は互いのリソースにアクセスできてはなりません。- 従業員が別の部門に異動したり、企業を退職したりした場合は、従業員のアクセス権限を取り消す必要があります。- ユーザー アカウントとアクセスは、既存のオンプレミスの Active Directory によって制御される必要があります。
これらの要件を満たすには、どの 2 つのステップを実行する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、スケーラブルな Google Cloud IAM 構造と、部門が分かれている大企業全体のアクセスを管理するためのオンプレミス ID システムとの統合に関する受験者の理解度を評価します。これには、Google Cloud のリソース編成機能と外部ディレクトリとの同期機能を適用する必要があります。
重要な用語:
フォルダ: Google Cloud では、フォルダは、プロジェクトやその他のフォルダなどの関連リソースをグループ化し、階層的なポリシーの継承と管理を可能にする組織構造です。
CLOUD IDENTITY: ID およびアクセス管理(IAM)機能を提供する Google Cloud サービスで、Google Cloud サービスと Active Directory などの外部システム全体で認証情報を統一できます。
GOOGLE CLOUD DIRECTORY SYNC: Active Directory などのオンプレミスのディレクトリ サービスからユーザー、グループ、その他のデータを Google の Cloud Identity サービスと同期するツール。
ロールの割り当て: 事前定義された IAM ロールをユーザーまたはグループに割り当て、Google Cloud リソースにアクセスして管理するための特定の権限を付与するプロセス。
正解解説:
(オプション)
・各部門ごとにリソースをフォルダに構造化し、フォルダスコープでGoogleグループに役割を割り振る。
・Google Cloud Directory Syncを実装して、Active DirectoryユーザーとそのグループメンバーシップをCloud Identityに複製します。
部門ごとにリソースをフォルダに構造化すると、各部門のリソースを分離して格納して管理し、フォルダ スコープで Google グループに役割を割り当てることができます。この設計により、アクセス許可をスケーラブルに管理できます。Google Cloud Directory Sync を実装することで、ユーザー アカウントとグループ メンバーシップが企業の既存のオンプレミス Active Directory と一貫性を保ち、ユーザーが退職したり部署が変わったりしたときに、一元管理とアクセスの自動取り消しが可能になります。
不正解の説明:
オプション: Virtual Private Cloud (VPC) Service Controls を使用して、各部門のリソースを安全な境界に分離します。
この選択が間違っている理由は、VPC Service Controls がネットワーク セキュリティ、特にデータを流出から保護する境界を作成するために設計されているためです。この機能は、フォルダーのように、個々の部門のリソース アクセスに対する階層的なアクセス管理や Active Directory 統合には対応していません。
オプション: ディレクトリ サービスで組織単位 (OU) を使用して部門をグループ化し、これらの OU に従ってアクセス ロールを管理します。
この選択が間違っている理由は、組織部門はユーザーを整理できますが、Google Cloud IAM ロールを OU に直接リンクできないためです。Google Cloud の階層は、特にフォルダ構造がタスクに適しているオンプレミスのディレクトリから同期する場合に、OU 構造に基づくアクセス管理を直接サポートしていません。
オプション: リソースの命名パターンを考案し、IAM条件を利用して、プロジェクト名の接頭辞に基づくアクセス制御を管理します。
この選択が間違っている理由は、命名パターンで IAM 条件を使用しても、部門リソースの堅牢な分離や合理化された管理が保証されないためです。条件が複雑になり、Active Directory と統合されないため、大規模なエンタープライズ管理には適していません。
参考：
https://cloud.google.com/iam/docs/overview
https://cloud.google.com/identity/docs/cloud-directory-sync
https://cloud.google.com/resource-manager/docs/creating-managing-folders
</div></details>

### Q.  問題27: 未回答
医療機関の最高コンプライアンス責任者 (CCO) は、多国籍事業に影響を与える医療データ コンプライアンス法を遵守するために、患者記録を特定の地域に保存することを義務付けています。この要件を満たすための戦略を分析した後、次の点を確認します。 - 関連するサービスは、Google Cloud データ レジデンシー規約の対象となります。- 患者レコードは、同じ組織内の定義された地域内に保存されます。- 組織フォルダーは、さまざまなデータ所在地リージョンを管理できます。リソースの場所の制限組織ポリシー制約を適用することにします。
この制約を設定するのに適したリソース階層のレベルはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 内のリソースの場所制限組織ポリシーの理解度を評価します。データ所在地に関する法律に準拠して、機密性の高い医療データの地理的なストレージ制限を適用するために、適切なレベルの識別が必要です。
重要な用語:
組織ポリシー: 組織ポリシーは、組織のリソース全体に一元化されたガバナンスを提供します。データを保存できる場所を制限するなど、リソースに制約を適用できます。
データ所在地: データ所在地とは、データが格納される物理的または地理的な場所を指します。さまざまな法的要件や規制要件の対象となり、データの維持方法と場所が決まります。
リソース階層: 組織、フォルダ、プロジェクト、リソースレベルを含むGCPリソースを整理する構造。階層は、ガバナンス、アクセス許可、ポリシーを適用するときに重要です。
正解解説:
(オプション)
・組織体制
リソースの場所の制限組織ポリシーは、組織全体にデータ所在地の規制を適用することを目的としているため、この選択は適切です。この制約を組織レベルで適用することは、基になるすべてのフォルダー、プロジェクト、およびリソースにわたって標準ポリシーを保証するため、戦略的です。これは、患者記録の保管に関する最高コンプライアンス責任者の義務を満たすために必須であり、同じ組織内の複数の地域のすべての業務でポリシーの一貫性を維持します。
不正解の説明:
オプション:フォルダ
フォルダー レベルでポリシーを適用するのが正しくない理由は、特に多国籍企業の場合、ポリシーが細かすぎるため、組織全体をカバーしていない可能性があるためです。フォルダーはサブユニットであるため、組織のさまざまな部分でポリシーに一貫性がなくなる可能性があります。
オプション: リソース
リソースレベルでのポリシーの適用が正しくない理由は、リソースレベルが Google Cloud のリソース階層内で最も詳細なレベルであるためです。ここでポリシーを適用するには、すべてのリソースに対して個別に制約を設定する必要がありますが、これは非効率的であり、監視によるコンプライアンス違反につながる可能性があります。
オプション: プロジェクト
プロジェクト レベルでポリシーを適用するのが正しくない理由は、プロジェクトがリソースを保持するコンテナーであり、ポリシーが組織全体に適用されることを保証しないためです。これにより、一部のプロジェクトが準拠している場合でも、他のプロジェクトが準拠していない可能性があり、全体的な義務を果たせなくなる可能性があります。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/resource-manager/docs/creating-managing-policy
https://cloud.google.com/resource-manager/docs/creating-managing-organization
</div></details>

### Q.  問題28: 未回答
Google Cloud 組織は、Google Cloud プロジェクトに所有者ロール(roles/owner)を割り当てることで、各ビジネスユニットに管理者権限を付与します。この組織は、さまざまなリージョンで多数の Google Cloud プロジェクトを管理しています。Security Command Center Premium では、いくつかのOPEN_REDIS_PORT脆弱性を特定しています。このような広範な構成エラーを回避するためのセキュリティ対策の強化に取り組んでいます。
どのようなアクションを実装する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、正当な内部トラフィックを中断することなく、マルチプロジェクトの Google Cloud 組織で Security Command Center Premium によって特定されたOPEN_REDIS_PORT脆弱性のリスクを軽減するセキュリティ対策を実装する受験者の能力を評価します。
重要な用語:
階層型ファイアウォール ポリシー: この機能を使用すると、管理者はすべての Google Cloud リソースのファイアウォール ルールを一元的に管理できます。ルールはリソース階層の下位レベルに継承され、広範なポリシーの適用が可能になります。
Security Command Center: Google Cloud が提供する統合リスク管理ソリューションで、クラウド資産全体のセキュリティとデータ リスクを特定、レビュー、修正します。
OPEN_REDIS_PORT脆弱性: ポートが公開されているため、インターネット経由で Redis インスタンスにアクセスでき、データへの不正アクセスを可能にする可能性があるセキュリティ上のリスク。
組織レベルのポリシー: 個々のプロジェクトやアセットではなく、Google Cloud 組織全体に適用される一連の制御と構成で、統一されたセキュリティ体制を確保します。
正解解説:
(オプション)
・組織レベルで階層的なファイアウォールポリシーを作成し、指定された内部IP範囲からの接続のみを許可します。
この選択は、内部接続の機能を維持しながら、脅威から環境を保護することのバランスをとるため、戦略的です。組織レベルで階層的なファイアウォール ポリシーを作成することで、管理者はすべてのプロジェクトとリソースにファイアウォール ルールを適用できます。このポリシーでは、指定された内部 IP 範囲からの接続のみが許可され、正当な内部ビジネス操作を許可しながら、一貫性のある包括的なファイアウォールの動作を保証することで、リスクから環境を保護します。
不正解の説明:
オプション: 組織レベルで階層的なファイアウォール ポリシーを確立して、0.0.0.0/0 からのすべての着信接続をブロックします。
この選択が正しくない理由は、制限が厳しすぎて、正当なトラフィックがブロックされる可能性があるためです。すべての着信接続をブロックすると、外部アクセスを必要とする可能性のあるサービスの運用が妨げられ、ビジネスの中断につながります。
オプション: 0.0.0.0/0 から発信されるすべてのトラフィックをブロックするように Google Cloud Armor セキュリティ ポリシーを設定します。
この選択が間違っている理由は、Google Cloud Armor は主にロードバランサなどのネットワークのエッジにあるサービスを保護し、Google Cloud の内部リソースや個々のプロジェクト内のアクセスを管理するようには設計されていないためです。さらに、すべてのトラフィックをブロックすることは、組織の運用にとって制限が厳しすぎます。
オプション: 各 Virtual Private Cloud (VPC) にファイアウォールルールをデプロイして、優先度が最も高い (0) 0.0.0.0/0 からのイングレストラフィックをブロックします。
この選択が間違っている理由は、各 VPC に個別のファイアウォールルールをデプロイすることのスケーラビリティの低さと非効率性によるものです。不要なアクセスをブロックすることはできますが、大規模な組織に必要な統合的で管理しやすいアプローチは提供されません。さらに、最高の優先度を設定すると、他の必要なルールと競合する可能性があります。
参考：
https://cloud.google.com/network-connectivity/docs/hierarchical-firewall/overview
https://cloud.google.com/security-command-center/docs/concepts-security-command-center-overview
https://cloud.google.com/vpc/docs/firewalls
</div></details>

### Q.  問題29: 未回答
ある多国籍小売企業の監査チームは、企業内のすべての部門の監査ログにアクセスする必要があります。彼らのニーズには以下が含まれます。
- アクセスをログの閲覧のみに制限することにより、最小特権の原則を順守します。
- 管理アクションのログを表示する機能。
- データの相互作用に関連するログを表示する機能。
- アクセスの透明性機能によって提供されるログを表示する機能。
これらの要件を満たすために、監査チームに割り当てる必要がある Identity and Access Management (IAM) ロールはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、特定の種類のログへの読み取り専用アクセスを必要とするサイバー防御チームに適切なIAMロールを割り当てることに関する候補者の知識を評価します。セキュリティとアクセシビリティの両方を確保するために、さまざまな役割とその権限を理解することが重要です。
重要な用語:
最小特権の原則: 職務を遂行するために必要な最低限のアクセスレベル(または権限)をユーザーに付与するセキュリティの概念。
システムイベントログ:管理者アクティビティや構成の変更など、システム内で発生するイベントを記録するログ。
ネットワークトラフィックログ:ネットワーク内の送受信トラフィックの記録で、ネットワークアクティビティ、パフォーマンス、およびセキュリティインシデントの分析に使用されます。
コンプライアンス監査ログ: 規制コンプライアンスに影響を与える個人およびシステムによるアクションの証跡を文書化するログ。
正解解説:
(オプション)
・roles/logging.privateLogViewer
「roles/logging.privateLogViewer」ロールは、すべてのログエントリへの読み取り専用アクセスを提供し、チームが変更を加えずにログを表示するように制限することで最小特権の原則をサポートするため、適切な選択です。この役割には、システムイベント、ネットワークトラフィック、コンプライアンス監査ログへのアクセスが含まれ、これは、サイバー防御チームが会社のすべての部門を監視するために要求する特定の必要性と一致します。
不正解の説明:
オプション: roles/logging.admin
「roles/logging.admin」が正しく選択されない理由は、ログの作成、ログの削除、ログ設定の変更などの管理アクションのアクセス許可を付与するためです。この役割は、読み取り専用アクセスを超えており、サイバー防御チームが要求する最小特権の原則に違反しています。
オプション: roles/viewer
「roles/viewer」が正しくない理由は、Google Cloud リソースへの読み取り専用アクセスを提供する一方で、プライベートログへのアクセスは許可されないためです。サイバー防御チームは、システムイベント、ネットワークトラフィック、コンプライアンス監査ログなどのプライベートログの監視機能を特に必要としています。
オプション: roles/logging.viewer
「roles/logging.viewer」が正しくない理由は、このロールがログへの読み取り専用アクセスを提供しますが、プライベートログは含まれないためです。プライベートログへのアクセスは、サイバー防御チームがシステムイベント、ネットワークトラフィック、コンプライアンス監査ログへのアクセスの要件を満たすために必要です。
参考：
https://cloud.google.com/iam/docs/understanding-roles#logging-roles
https://cloud.google.com/logging/docs/access-control
https://cloud.google.com/logging/docs/audit#admin-activity
</div></details>

### Q.  問題30: 未回答
規制遵守の追跡のために、財務コンプライアンス チームは、まだ適用されていないミッション クリティカルなデータベース パッチを保留しているデータベース サーバーのカタログを提供する必要があります。このカタログは半年ごとにコンパイルし、そのための最も効率的な方法を模索する必要があります。
どのようなアプローチを取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 内でコンプライアンスを目的としたデータベース パッチの効率的な追跡とレポートに関する受験者の知識を評価し、手動による介入なしに定期的かつ自動化されたコンプライアンス チェックを容易にする機能に焦点を当てます。
重要な用語:
OS 構成エージェント: 構成管理、パッチ管理、コンプライアンス管理機能を提供し、VM のフリート全体で OS パッチを自動的に追跡して適用する管理サービス。
パッチ管理: マネージド インスタンスのパッチ適用プロセスを自動化し、VM インベントリ全体のパッチ コンプライアンスをレポートできる OS 構成エージェント内の機能。
正解解説:
(オプション)
・OS Configエージェントがすべてのデータベースサーバにインストールされていることを確認し、パッチ管理機能を使用して必要なレポートを6か月ごとに生成します。
この選択が最も効果的であるのは、OS Configエージェントがデータベース・サーバーにインストールされると、オペレーティング・システムのパッチが管理されるためです。パッチ管理機能を使用すると、パッチステータスに関するレポートを自動生成できます。これにより、手動のオーバーヘッドなしで保留中のパッチの効率的な半年ごとのカタログ作成が容易になり、最小限の手作業でコンプライアンスデータが最新かつ正確になります。
不正解の説明:
オプション:すべてのデータベース サーバで Web セキュリティ スキャナのクロールを開始し、重要なデータベース パッチ要件が未処理のサーバを半年ごとに特定します。
この選択が間違っている理由は、Web セキュリティ スキャナが主に Web アプリケーションのセキュリティ脆弱性を検出し、データベース サーバを検出しないためです。保留中のデータベース・パッチを識別するようには設計されていないため、データベース・パッチ・ステータスを監視するための特定のコンプライアンス要件には対応していません。
オプション: gcloud compute instances list コマンドを実行して、データベース サーバーのパッチレベルを半年ごとに取得します。
この選択が間違っている理由は、gcloud compute instances list コマンドでは、実行中の VM インスタンスに関する情報は提供されますが、実行している可能性のあるデータベースの詳細なパッチレベルは提供されないためです。コンプライアンスに必要な保留中のミッションクリティカルなデータベースパッチに関するターゲットを絞ったレポートは提供されません。
オプション: すべてのデータベース サーバーに Cloud Monitoring エージェントをインストールし、データベース パッチが期限切れになったタイミングを 6 か月ごとに追跡するアラートを設定します。
この選択が間違っている理由は、Cloud Monitoring がパフォーマンス指標とヘルスチェックに重点を置き、特定のソフトウェアパッチを追跡しないためです。アラートはさまざまな条件に対して設定できますが、コンプライアンスの追跡に必要なデータベースパッチのステータスを詳細に監視およびレポートすることはできません。
参考：
https://cloud.google.com/compute/docs/osconfig/rest
https://cloud.google.com/security-command-center/docs
https://cloud.google.com/logging/docs/agent/logging/
</div></details>

### Q.  問題31: 未回答
社内で、社内のコンプライアンス ガイドラインに従ったカスタム データベース イメージを開発し、規制の厳しい財務チームのプロジェクト内に保存するように設定しました。会社の Google Cloud インフラストラクチャの管理者としてのタスクは、管理の負担を可能な限り軽減することを目指しながら、すべてのデータベース VM インスタンスがこの特定のデータベース イメージを排他的に利用するように強制することです。
どのような手順を踏む必要がありますか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、管理オーバーヘッドを最小限に抑えながら、組織の GCP インフラストラクチャ全体で特定の準拠データベース イメージを効果的に使用することに重点を置いています。リソース共有に関連するIAMロールと組織ポリシーの制約に関する知識を評価します。
重要な用語:
compute.imageUser: ユーザーが Cloud Storage のイメージを使用して Compute Engine VM インスタンスのブートディスクを作成できるようにする Google Cloud IAM のロール。
組織ポリシーの制約: 管理者が組織、フォルダー、プロジェクト、またはリソース レベルで構成して、スコープ内のすべてのリソースに特定の動作を適用できる一連の制限。
正解解説:
(オプション)
・財務チームが管理するデータベースイメージプロジェクト内のメンバーにcompute.imageUserロールを割り当てます。
・イメージアクセス組織ポリシーの制約を実装し、プロジェクトの許可リストに財務チームのプロジェクトを指定します。
データベースイメージプロジェクト内のメンバーに compute.imageUser ロールを割り当てると、これらのユーザーは、他の領域でのアクセス許可を付与せずに、プロジェクト内に格納されたカスタムデータベースイメージを使用できます。イメージ アクセス組織ポリシーの制約を実装すると、データベース イメージの使用が、特定の財務チームのプロジェクトを含む許可リスト内のものに制限され、最小限の管理作業で全社的なコンプライアンス ガイドラインが維持されます。
不正解の説明:
オプション: compute.imageUser ロールを個々のプロジェクト内のメンバーに提供します。
この選択が正しくない理由は、各プロジェクト内で個別のロールの割り当てが必要になるため、管理オーバーヘッドが増加し、準拠するデータベース イメージの使用が強制されないためです。
オプション: 会社の Google Cloud 内に作成された新しいプロジェクトごとにデータベース イメージを複製します。
この選択が正しくない理由は、イメージ管理に追加のオーバーヘッドが発生し、すべてのレプリカで最新のコンプライアンスが保証されず、不整合のリスクが高まるためです。
オプション: プロジェクト・メンバーからデータベースVMインスタンスを作成する権限を取り消し、この権限を自分および指定された担当者のみに制限します。
この選択が間違っている理由は、制御が過度に集中化され、ボトルネックが発生し、プロジェクトチームの自律性が低下し、ワークフローと効率が妨げられる可能性があるためです。
参考：
https://cloud.google.com/compute/docs/access/iam
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題32: 未回答
ある医療機関は先月、データを処理して Cloud Storage に送信するための新しい Compute Engine サービスを実装しました。プロジェクトには他にアクティブなサービスがありません。Cloud Storage へのすべてのアップロードが Compute Engine のデフォルト サービス アカウントのみを使用して行われたことを確認する必要があります。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Compute Engine と Cloud Storage 間のやり取りで特定のサービス アカウントの使用状況を検証し、確認のためにログを調べることで、正しい認証情報を使用してデータのアップロードが実行されたことを確認する機能を評価します。
重要な用語:
Cloud Logging: GCP リソースからのログを保存し、フィルタリングと分析を可能にするサービス。このシナリオでは、Cloud Storage への書き込みアクションの履歴を確認するために利用されます。
サービス アカウント: GCP サービスとやり取りするために、人ではなくアプリケーションによって使用される特別なタイプのアカウント。Compute Engine インスタンスは、認証やオペレーションの実行に使用できます。
認証フィールド: リクエストの認証に使用された資格情報を示すログエントリのコンポーネント。このフィールドを確認すると、要求者の ID を確認できます。
正解解説:
(オプション)
・Cloud Loggingを使用し、Cloud Storageの書き込みアクションをフィルタリングします。認証欄で、Compute Engine のデフォルト サービス アカウントに属するリクエスタのメールを確認します。類似のエントリを非表示にすることを選択します。残りの項目がリストされていないことを確認します。
この選択では、Cloud Logging を効果的に使用して、Cloud Storage への書き込みアクションのレコードを調べ、Compute Engine のデフォルト サービス アカウントに対応するリクエスタのメールの認証フィールドを検査します。類似のエントリを非表示にすることで、ユーザーは異なるアカウントからのアクションがないことを効率的に確認し、すべての操作がデフォルトのサービスアカウントを使用して行われたことを確認できます。
不正解の説明:
オプション: Cloud Logging を使用して、Cloud Storage の書き込みアクションをフィルタリングします。認証欄で、Compute Engine のデフォルト サービス アカウントに属するリクエスタのメールを確認します。類似のエントリを表示するように選択します。残りの項目がリストされていないことを確認します。
この選択が間違っている理由は、同様のエントリを表示するように選択しても、Compute Engine のデフォルト サービス アカウントのアクティビティを分離するのに役立たないためです。これにより、書き込み操作でそのアカウントの排他的使用を確認することがより困難になるだけです。
オプション: Cloud Storage で、関連するバケットの権限を開きます。Compute Engine のデフォルトのサービス アカウントが、バケットへの書き込み権限を付与された排他的エンティティであることを確認します。
この選択が間違っている理由は、Cloud Storage のバケット権限を確認するだけでは、過去のアップロードが Compute Engine サービス アカウントによって排他的に実行されたかどうかは確認できないためです。アクセス許可だけでは、資格情報の実際の使用履歴を検証できません。
オプション: プロジェクトの Identity and Access Management (IAM) ページにアクセスします。Compute Engine のデフォルトのサービス アカウントが、Cloud Storage への書き込みオペレーションを許可するロールを持つ唯一の ID であることを確認します。
この選択が間違っている理由は、IAMロールを確認するだけでは、過去のアクションの証拠が得られないためです。IAMは、操作の実行を許可されているユーザーを示しますが、実際のサービスインタラクションを追跡または記録したり、承認されたアカウントが使用されたかどうかを確認したりすることはありません。
参考：
https://cloud.google.com/logging/docs/view/overview
https://cloud.google.com/bigquery/docs/reference/auditlogs
https://cloud.google.com/iam/docs/granting-changing-revoking-access
</div></details>

### Q.  問題33: 未回答
Google Cloud サービスに関するインタラクティブなトレーニングをクライアントに提供するために不可欠な、Google Cloud 組織内の多数の一時的な環境のプロビジョニング プロセスを自動化する任務を負っています。Google Cloud の推奨プラクティスへの準拠を強化するために、デフォルト ネットワークを回避する必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、クラウド リソースの保護と管理に関する Google Cloud のベスト プラクティスに関する受験者の理解度を評価します。クラウド環境を自動化および制御するための組織のポリシー、特にデフォルトのネットワーク構成を扱う場合の知識が必要です。
重要な用語:
組織ポリシー: 組織内のすべての Google Cloud リソースにガバナンスを適用し、クラウド リソースの運用方法に制限を設定する管理ポリシー。
constraints/compute.skipDefaultNetworkCreation: Google Cloud で新しいプロジェクトを作成する際にデフォルト ネットワークの自動作成を防ぐための組織のポリシー制約。
正解解説:
(オプション)
・constraints/compute.skipDefaultNetworkCreation 組織ポリシー制約を組織レベルで適用します。
この選択は、リソース階層の最上位でポリシーを適用して組織内のすべてのプロジェクトの動作を制御することにより、最小特権と組織ガバナンスの原則を順守しています。constraints/compute.skipDefaultNetworkCreation 制約を設定すると、新しいプロジェクトで既定のネットワークが作成されなくなるため、エンタープライズ グレードの実装のネットワーク設計とセキュリティのベスト プラクティスに合わせることができます。
不正解の説明:
オプション: Cloud Scheduler ジョブをスケジュールして、すべてのプロジェクトからデフォルトのネットワークを定期的に削除する Cloud Functions の関数を呼び出します。
この選択が間違っている理由は、リソースを大量に消費し、反応性があり、フェイルセーフではないためです。Cloud Scheduler ジョブと Cloud Functions の関数を使用してデフォルト ネットワークを手動で削除すると、デフォルト ネットワークが存在するタイミングウィンドウが発生し、削除される前にコンプライアンス違反になる可能性があります。
オプション: 組織レベルで IAM 所有者ロールをクライアントに割り当て、compute.googleapis.com API を制限する VPC Service Controls 境界でプロジェクトをラップします。
この選択が正しくない理由は、IAM 所有者ロールで過度に広範なアクセス許可を付与するためであり、重大なセキュリティリスクをもたらします。VPC Service Controls を使用すると、境界セキュリティが提供されますが、主要なコンプライアンス要件であるデフォルト ネットワークの作成が本質的に妨げられることはありません。
オプション: 既定のネットワークの生成を回避する標準化されたインフラストラクチャ ブループリントのカタログを含む CI/CD パイプラインのみをクライアントが利用できるようにします。
この選択が間違っている理由は、クライアントが CI/CD パイプライン プロセスに準拠していることに依存しているためです。これは良い方法ですが、ネットワーク構成ポリシーを適用しないため、バイパスしてもデフォルトネットワークの作成を妨げない可能性があります。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/vpc/docs/using-vpc-service-controls
https://cloud.google.com/kubernetes-engine/docs/concepts/network-overview
</div></details>

### Q.  問題34: 未回答
新たに開発した製品設計システムで営業秘密に関するデータを管理しています。チーフ・コンプライアンス・オフィサーは、機密設計が調査分析プラットフォーム内で公開されることに懸念を表明しています。あなたは、この機密情報を元に戻すことができない方法で匿名化するタスクを担当しています。また、匿名化されたデータでは、元の文字パターンと長さのメトリックを保持してはなりません。
この要件に最も適した Google Cloud ソリューションはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、分析中に企業秘密の機密性を維持するための Google Cloud のデータ匿名化技術の理解度を評価します。匿名化されたデータによって元のデータパターンや指標が明らかにされないようにすることに重点を置いています。
重要な用語:
暗号化ハッシュ: データを元に戻せない固定サイズのハッシュに変換する方法。元の情報をハッシュから導き出すことができないため、データの機密性を確保するのに最適です。
確定的暗号化: 特定のデータに対して毎回同じ暗号化出力を生成する暗号化アルゴリズム。一貫性は必要だが、機密データ パターンの安全性が低いシナリオに役立ちます。
形式保持暗号化: 英数字の構造や長さなど、データの元の形式を維持する暗号化の一種で、元のデータパターンを保持する際に問題になる可能性があります。
Cloud Key Management Service (KMS): 暗号化キーを管理するためのクラウドサービス。DLP と併用すると、追加のセキュリティ層が提供されますが、匿名化技術の遵守には影響しません。
正解解説:
(オプション)
・暗号ハッシュによるクラウドデータ損失防止
この選択は、暗号化ハッシュによってデータが不可逆的に変換され、元のデータのパターンや長さの情報が保持または再構築されないようにするため、シナリオに最も適したソリューションです。Cloud Data Loss Prevention(DLP)は、機密情報の検出、分類、保護を支援するために特別に設計されており、暗号化ハッシュと組み合わせることで、企業秘密データを匿名化するための厳しい要件を満たします。
不正解の説明:
オプション:AES-SIVを使用した確定的暗号化によるCloud Data Loss Prevention
この選択が間違っている理由は、決定論的な暗号化では、機密性がある程度保たれる一方で、特に脆弱性につながる可能性のある一貫したパターンを通じて、元のデータに関する情報を推測する可能性が残されているためです。
オプション:Cloud Data Loss Prevention(フォーマット保持暗号化)
この選択が間違っている理由は、フォーマット保持暗号化ではデータの元の構造が維持されるため、機密性の高い企業秘密の場合、基礎となる機密情報を示すパターンや長さが明らかになる可能性があるためです。
オプション: Cloud Data Loss Prevention と Cloud Key Management Service でラップされた暗号鍵
このオプションが間違っている理由は、Cloud KMS を使用すると安全な鍵管理が提供されますが、暗号化されるデータのパターンや構造は本質的に変更されないため、元の文字パターンや指標が識別されるのを防ぐために必要になるためです。
参考：
https://cloud.google.com/dlp/docs/concepts-hashing
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/dlp/docs/encrypting-cloud-kms
</div></details>

### Q.  問題35: 未回答
医学研究会社は、オンサイトのデータセンターと、「ClinicalData」と「ResearchData」という名前の個別のサブネットを持つ共有 VPC を含む Google Cloud プラットフォーム間の接続を確立する必要があります。要件は次のとおりです。
- 安全でプライベートな接続を採用します。
- オンサイト ネットワークからプライベート サービス エンドポイント経由で Google Cloud サービスへのアクセスを設定します。
- Google Cloud サービスへのすべてのアクセスが VPC Service Controls によって仲介されるようにします。
どのような行動を取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、共有 VPC を使用して、オンサイトのデータセンターから Google Cloud 環境への安全なプライベート接続を確立することに焦点を当てています。また、このソリューションでは、プライベート エンドポイント経由で Google サービスにアクセスできるようにし、セキュリティを強化するために VPC Service Controls と互換性がある必要があります。
重要な用語:
専用インターコネクト: このサービスは、オンプレミス ネットワークと Google Cloud 間の直接物理接続を提供し、低レイテンシで高帯域幅のデータ転送を実現します。
VPC Service Controls: 管理者が Google Cloud リソースの周囲にセキュリティ境界を定義してデータの流出を防止できる高度なセキュリティ メカニズムです。
共有 VPC: 組織が複数のプロジェクトのリソースを共通の仮想プライベートクラウドに接続し、プロジェクト間での効率的な管理とリソース共有を可能にする Google Cloud の機能。
プライベートサービスエンドポイント: 内部 IP アドレスを使用してサービスを VPC に直接接続し、セキュリティを強化し、パブリックインターネットへの露出を減らすネットワーク機能。
正解解説:
(オプション)
・専用インターコネクトを構成して、オンサイトのデータセンターと Google Cloud の間にプライベート リンクを提供します。さらに、VPC Service Controls によって制御される境界を使用して、Google Cloud サービスへのアクセスを制限します。
Dedicated Interconnect は、オンサイト ネットワークと Google Cloud ネットワーク間の直接かつプライベートな高速接続を提供するため、この選択は最適です。これを VPC Service Controls のアプリケーションと組み合わせることで、定義されたサービス境界内からのみ Google Cloud サービスへのアクセスが可能になり、機密性の高い医療データの取り扱いに指定されたセキュリティとプライバシーの要件を満たすことができます。
不正解の説明:
オプション: Cloud VPN を実装してオンサイトのデータセンターと Google Cloud をブリッジし、オンサイト環境内の DNS 解決に restricted.googleapis.com ドメインを利用します。
この選択が不適切な理由は、Cloud VPN はインターネット上で安全な接続を確立しますが、医学研究で一般的な大量の機密データの転送に適していることが多い Dedicated Interconnect と同じレベルの帯域幅と潜在的な低レイテンシを提供しないためです。
オプション: オンサイト ネットワークから Google Cloud との Partner Interconnect 接続を確立し、Google サービスにアクセスするための private.googleapis.com ドメインに対して解決する DNS 構成を設定します。
この選択が間違っている理由は、Partner Interconnect はオンサイト ネットワークと Google Cloud 間の接続を提供しますが、サードパーティのサービス プロバイダに依存しており、Google サービスへの安全でプライベートなアクセスに必要なレベルの制御と VPC Service Controls へのコンプライアンスを提供しない可能性があるためです。
オプション: ダイレクト ピアリングの取り決めを作成して、オンサイトのデータセンターを Google Cloud に接続し、「ClinicalData」と「ResearchData」の両方のサブネットに対してのみプライベート サービス アクセスを有効にします。
このオプションが適切でない理由は、ダイレクト ピアリングがプライベート回線や専用回線ではなく、インターネット ベースの接続を提供するためです。パブリック インターネットをバイパスする接続を介して Google サービスにアクセスできますが、サービス境界内でデータ セキュリティ ポリシーを適用するための VPC Service Controls との統合がありません。
参考：
https://cloud.google.com/network-connectivity/docs/interconnect/concepts/dedicated-overview
https://cloud.google.com/vpc/docs/configure-private-google-access-hybrid
https://cloud.google.com/vpc-service-controls/docs/private-connectivity
</div></details>

### Q.  問題36: 未回答
承認された機械学習モデルのアーティファクトを、アーティファクト リポジトリとして機能する専用の Google Cloud プロジェクトに保存しました。このプロジェクトは VPC Service Controls で保護されており、企業内の他のプロジェクトと同じ境界の一部です。組織内の他のプロジェクトは、この設定を使用して、成果物リポジトリ プロジェクトから成果物をデプロイします。チームは、別の Google Cloud 組織でホストされているサードパーティのモデル アーティファクトを利用する必要があります。このモデル・アーティファクトへの読取りアクセス権を提供して、制御された境界内にデプロイできるようにする必要があります。
どのようなアクションを実行する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、VPC Service Controls を尊重しながら、さまざまな Google Cloud 組織に保存されている機械学習モデルのアーティファクトへの安全なアクセスを実装するための理解度を評価します。焦点は、組織間の展開を可能にしながら、制御された境界セキュリティを維持することです。
重要な用語:
VPC Service Controls: Google Cloud リソースの仮想境界内のデータを制限し、信頼できないソースへのデータ流出を防ぎ、アクセス ポリシーを適用します。
egressTo: VPC Service Controls 境界から外部サービスまたはプロジェクトへのアウトバウンドアクセスを設定し、許可するサービスまたはエンティティを指定します。
egressFrom: VPC Service Controls 境界からエグレスポリシーで定義されたサービスにリクエストを送信できる ID を決定します。
serviceName: アクセスを制御するために VPC Service Controls で指定されている特定の Google Cloud サービス(AI Platform の場合は ml.googleapis.com など)を指します。
identityType: VPC Service Controls ポリシーの ID のタイプ(ソースに関係なく、認証されたユーザーまたはサービスのANY_IDENTITYなど)を指定します。
正解解説:
(オプション)
・1.既存の周長を修正します。
2. egressTo パラメータを調整して、サードパーティの個別の Google Cloud プロジェクト番号を承認済みエンティティとして含め、serviceName を ml.googleapis.com に設定します。
3. egressFrom パラメーターを修正して、identityType を ANY_IDENTITY に設定します。
この選択により、VPC Service Controls の調整が正しく実装され、制御された境界を損なうことなく、サードパーティのアクセスが提供されます。サード パーティのプロジェクト番号を含め、serviceName を ml.googleapis.com に設定して既存の境界の egressTo を変更すると、外部モデル アーティファクトにアクセスできるようになります。egressFrom から ANY_IDENTITY への変更により、認証されたユーザーまたはサービスが境界内にアーティファクトをデプロイできるようになり、サード・パーティー・モデル・アーティファクトのデプロイが容易になります。
不正解の説明:
オプション: 組織のポリシー制約 constraints/ml.trustedArtifactProjects を適用して、サードパーティ プロジェクトを統合します。
この選択が間違っている理由は、組織のポリシーを適用しても、VPC Service Controls の境界を越えてアクセスを提供するという問題に適切に対処できないためです。このソリューションでは、信頼できる成果物ソースを定義する方法が提案される場合がありますが、必要な境界を越えたアクセスは許可されません。
オプション: 1. 外周構成を修正します。
2. ingressFrom パラメーターの identityType を ANY_IDENTITY に設定します。
3. ingressTo パラメータを更新して、承認済みエンティティとしてのサードパーティの個別の Google Cloud プロジェクト番号と serviceName を ml.googleapis.com に含めます。
この選択が正しくない理由は、イングレス権限(ingressFromとingressTo)の変更を伴うのに対し、問題はエグレス(つまり、サードパーティプロジェクトへのアウトバウンドアクセス)の許可に関係しているためです。この誤った設定により、境界の整合性が損なわれる可能性があります。
オプション: 1. 既存の境界設定を更新します。
2. egressTo パラメーターの identityType を ANY_IDENTITY に設定します。
3. egressFrom パラメータを変更して、承認されたエンティティとしてのサードパーティの個別の Google Cloud プロジェクト番号と ml.googleapis.com の serviceName を含めます。
この選択が正しくない理由は、egressTo パラメーターの identityType を ANY_IDENTITY に構成して境界設定を変更する必要はなく、指定された外部サービスまたはプロジェクトではなく、送信エグレスの ID タイプを調整することが誤って意味されるためです。
参考：
https://cloud.google.com/vpc-service-controls/docs
https://cloud.google.com/vpc-service-controls/docs/perimeter-configuration
https://cloud.google.com/compute/docs/images/sharing-images-across-projects
</div></details>

### Q.  問題37: 未回答
組織は、機密性の高い健康情報を管理する医療記録システムを Google Cloud で運用しています。医療データ保護法に従い、情報は指定された期間のみ保存することが許可されており、この期間が経過すると不可逆的に削除する必要があります。所定の保存期間にまだ達していないレコードは、そのままにしておく必要があります。これらの法的要件を遵守するために、自動化されたソリューションを採用する必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud でのデータ ライフサイクル管理、特に機密性の高い健康情報の一定期間後の削除を義務付ける医療データ保護法の遵守に関する受験者の知識を評価します。
重要な用語:
オブジェクトのライフサイクル管理: Google Cloud Storage の機能で、経過時間、メタデータの変更、ストレージ クラスなど、指定した条件に基づいてオブジェクトの削除や移行を自動化できます。
正解解説:
(オプション)
・Google Cloud Storageバケットにデータを保存し、定義した経過時間に達した時点で自動的に削除されるようにObject Lifecycle Managementを設定します。
Google Cloud Storage のオブジェクト ライフサイクル管理機能は、データ保持の実践を自動化するだけでなく、医療規制へのコンプライアンスも保証するため、この選択は正確です。これにより、オブジェクトの経過時間のしきい値を正確に設定でき、しきい値に達すると、オブジェクトは完全に削除されます。この自動化により、人為的ミスのリスクが排除され、オブジェクトが指定された年齢に達すると、新しいデータに影響を与えることなく不可逆的に消去されます。
不正解の説明:
オプション: Compute Engine 永続ディスクにデータをデプロイし、保持期間の終了時にディスクを消去するルーチンをスクリプト化します。
この選択が間違っている理由は、完全に自動化されたソリューションではなく、人為的エラーやスクリプトの失敗の潜在的なリスクを伴うためです。Compute Engine 永続ディスクでルーチンを手動でスクリプト化すると、ライフサイクル管理用に設計された Google Cloud のネイティブ機能が活用されないため、法定期間を超えてデータが保持される可能性があります。
オプション: BigQuery データセットにデータを挿入し、特定の期間が経過するとレコードを消去するテーブルの有効期限ポリシーを定義します。
この選択が間違っている理由は、BigQuery のテーブル有効期限ポリシーがデータセット内の個々のレコードではなく、データセット用に設計されているためです。さらに、法律に準拠したフレームワーク内で、経過時間やコンテンツの機密性に基づいてレコードをきめ細かく削除するためのすぐに使用できるソリューションは提供されません。
オプション: Cloud Bigtable インスタンス内のデータを統合し、列ファミリにガベージ コレクション ルールを構成して、特定の経過時間を過ぎた行を削除します。
この選択が間違っている理由は、Cloud Bigtable のガベージ コレクション ルールが、事前定義された間隔に基づいて古いバージョンのデータの削除に適用されるためです。ただし、これは主にストレージを最適化するために使用され、指定されたストレージ期間に達したときに機密性の高い健康情報を削除するための法令遵守を保証するものではありません。
参考：
https://cloud.google.com/storage/docs/managing-lifecycles
https://cloud.google.com/bigquery/docs/table-expiration
https://cloud.google.com/bigtable/docs/creating-managing-column-families#setting-gc-policy
</div></details>

### Q.  問題38: 未回答
Security Command Center(SCC)を利用してメディアストリーミングインフラストラクチャを保護しており、不正なビデオコンテンツのスクレイピングアクティビティを検出する必要があります。
どの SCC 機能を実装する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、特定の種類のセキュリティ脅威(この場合は、メディアストリーミングインフラストラクチャ内の不正なビデオコンテンツスクレイピングアクティビティ)を検出するための適切なセキュリティコマンドセンター(SCC)機能の理解度を評価します。
重要な用語:
仮想マシンの脅威検出: 仮想マシン (VM) ワークロードを標的とする脅威 (マルウェア、リモート コード実行、その他の形式の不正な VM アクティビティなど) を特定して対応するために設計された SCC の機能。
正解解説:
(オプション)
・仮想マシンの脅威検知
仮想マシンの脅威検出は、仮想マシン環境内で発生する脅威を特定するために特別に調整されているため、適切な選択です。メディア ストリーミング サービスのシナリオでは、コンテンツ スクレイピング、流出、または不正なスクレイピングを示す可能性のある異常なアクセス パターンの兆候がないか VM を監視することが重要です。VM Threat Detection を採用することで、Security Command Center はこのようなインシデントについてセキュリティ チームに警告を発し、これらのリスクを軽減するための迅速な対応を取ることができます。
不正解の説明:
オプション:コンテナ脅威の検出
Container Threat Detectionが正しくない理由は、Kubernetesクラスタなどのコンテナ化された環境内の脅威の特定に特化しており、仮想マシン環境やコンテンツスクレイピングアクティビティの検出という特定のユースケースに直接焦点を当てていないためです。
オプション:イベント脅威の検出
イベント脅威検出が正しくない理由は、疑わしいクラウドイベントの特定には長けていますが、ビデオコンテンツのスクレイピングなどの特定の望ましくないアクティビティを検出するための仮想マシンレベルの操作の詳細な分析を提供していないためです。
オプション:Web セキュリティ スキャナー
Web Security Scannerが正しくない理由は、Webアプリケーション内の脆弱性を特定できる一方で、仮想マシンレベルでのメディアストリーミングインフラストラクチャ内のビデオコンテンツスクレイピングなどの脅威の監視と検出には適していないためです。
参考：
https://cloud.google.com/security-command-center/docs/concepts-threat-detection-overview
https://cloud.google.com/security-command-center/docs/how-to-use-threat-detection
https://cloud.google.com/security-command-center/docs/how-to-use-virtual-machine-threat-detection
</div></details>

### Q.  問題39: 未回答
DevOpsチームは、Terraformを使用して、次の手順でKubernetes Engineクラスタを作成します。
1. 一時的な Kubernetes Engine クラスタを設定します。
2. 構成ファイルを Cloud Storage バケットからクラスタのノードに転送します。
3. ノードのソフトウェアリポジトリにパッチを適用します。
4. 外部データソースから追加の設定を取得します。
セキュリティ部門は最近、組織のポリシー制約 'constraints/compute.vmExternalIpAccess' を適用して、クラスタ ノードへのパブリック IP アドレスの割り当てを制限しました。その後、DevOpsチームはスクリプトでKubernetes Engineノードから外部IPアドレスを削除しましたが、クラスタの作成中に接続の問題に直面しています。
これを解決するために、どのようなアクションを取る必要がありますか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、VMインスタンスでのパブリックIPアドレスの使用を制限するポリシーの適用に続いて、Kubernetes Engineクラスタにネットワーク接続を実装するという課題を中心に展開されます。Google Cloud 内のネットワーク構成の理解度をテストし、パブリック IP なしでサービスのアクセシビリティを維持します。
重要な用語:
Cloud NAT: パブリック IP アドレスを持たないインスタンスが、着信接続に公開されることなくインターネットに接続できるようにする Google Cloud サービス。
限定公開の Google アクセス: 内部 IP アドレスのみを持つ VM インスタンスが Google API とサービスの外部 IP アドレスに到達する方法を提供します。
正解解説:
(オプション)
・対応するVPCネットワークとゾーンにCloud NATアプライアンスをKubernetes Engineクラスタとして設定します。
・Kubernetes Engine クラスタ ノードが存在するサブネットの限定公開 Google アクセスを ON にします。
パブリック IP アドレスのない Kubernetes Engine クラスタの接続の問題を解決するために、Cloud NAT を設定することで、プライベート サブネット内のノードが安全なインフラストラクチャを維持しながら、インターネットへの送信接続を開始できるようになります。さらに、限定公開の Google アクセスを有効にすると、プライベートサブネット内のノードは、パブリック IP アドレスを必要とせずに、クラスタ構成の転送および取得操作中に重要な Google API とサービスにアクセスできるため、組織のポリシーに準拠し、機能を維持できます。
不正解の説明:
オプション: クラスタ・ノードを含む管理対象外インスタンス・グループを指すネットワーク・ロード・バランサを作成して、受信インターネット接続を有効にします。
この選択が正しくない理由は、ネットワーク・ロード・バランサーを作成すると、ノードが誤ってインターネットに公開され、パブリックIPの割り当てを制限する組織のポリシーと競合し、セキュリティ・リスクが高まるためです。
オプション: VPC のネットワークルートを変更して、インターネットからのイングレストラフィックとエグレストラフィックを許可します。
この選択が正しくない理由は、直接インターネット トラフィックを許可するように VPC ネットワーク ルートを変更すると、パブリック IP アドレスの割り当てを制限するという組織のポリシーの意図に反し、クラスタが不要なセキュリティ リスクにさらされる可能性があるためです。
オプション: Kubernetes Engine クラスタと同じ VPC ネットワークおよびゾーン内に Cloud VPN ゲートウェイを確立します。
この選択が間違っている理由は、クラウド VPN を確立すると、ネットワーク間の安全な通信が可能になりますが、外部 IP アドレスのないクラスタ ノードからの送信インターネット アクセスの必要性に対応できないためです。
参考：
https://cloud.google.com/nat/docs/using-nat
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/compute/docs/ip-addresses#externaladdresses
</div></details>

### Q.  問題40: 未回答
医療分析チームには、特定の Compute Engine インスタンスがインターネットから分離され、Google が管理するデータ分析サービスや API とやり取りできない安全な環境が必要です。
これらの制約を満たすために非アクティブのままにしておく必要がある 2 つの構成はどれですか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、厳格なネットワーク分離ポリシーを適用するための Google Compute Engine インスタンスの構成に関する理解度を評価します。具体的には、インスタンスがインターネットベースのサービスや Google が管理する API にアクセスできないようにする設定を対象としています。
重要な用語:
パブリックIP: パブリックIPアドレスは、コンピュート・インスタンスに割り当てられた外部アドレスであり、インターネットやその他の外部サービスとの通信を可能にします。
プライベート Google アクセス: プライベート IP アドレスのみを持つインスタンスが、パブリック IP アドレスを使用せずに Google Cloud API やサービスなどの Google サービスにアクセスできるようにします。
正解解説:
(オプション)
・グローバルIP
・プライベートGoogleアクセス
「パブリックIP」を無効にすると、インスタンスに外部IPアドレスがないため、インターネットとの直接アクセスが防止されます。「プライベートGoogleアクセス」を無効にすると、プライベートIPのみであっても、インスタンスはGoogleのデータ分析サービスとAPIにアクセスできなくなります。これらの構成により、インスタンスはインターネットから分離され、Google が管理するサービスとやり取りすることなく、必要な厳格なネットワーク分離に準拠します。
不正解の説明:
オプション:IP フォワーディング
「IP 転送」が正しくない理由は、仮想マシン インスタンスが自身の IP アドレスと一致しないネットワーク トラフィックを送受信できるようにするためです。特定の構成では重要ですが、本質的にインターネット アクセスや Google サービスとのやり取りは許可されません。
オプション: カスタム ルート
「カスタムルート」が正しくない理由は、ネットワーク内のトラフィックの流れを誘導するために使用されるためです。データのルーティング方法を指定することはできますが、インターネットや Google が管理するサービスへの直接アクセスを有効または無効にすることはできません。
オプション: IAM ネットワーク閲覧者ロール
「IAM Network Viewer Role」が正しくない理由は、ネットワークリソースを表示するためのアクセス許可が付与されるためです。Compute Engine インスタンスのネットワーク接続や、外部サービスやインターネットとのやり取りには影響しません。
参考：
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/vpc/docs/using-firewalls
Hattops://cloud.google.com/comput/DOC/IP-addresses#ReservedAres
</div></details>

### Q.  問題41: 未回答
会社のデータ分析業務を Google Cloud に移行しています。認証情報の盗難とセッション乗っ取りの両方のインシデントが、同社の既存のオンプレミス データベースと開発チームのマシン上の Google Cloud コマンドライン インターフェースで発生しています。これらの脆弱性を軽減するには、セキュリティを強化する必要があります。
どの2つのステップを踏むべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 環境内での認証情報の盗難やセッションの乗っ取りを防ぐためのセキュリティ強化に関する知識を評価します。このような脆弱性を軽減するための最善の対策、特にセッション管理とユーザーの再認証戦略の効果的な使用を理解することに焦点を当てています。
重要な用語:
セッションタイムアウト設定:これは、非アクティブな状態が一定時間続いた後にユーザーをログアウトするセキュリティ対策を指します。これらの設定を調整すると、ユーザーがエンドポイントを無人で離れた場合の不正アクセスを防ぐのに役立ちます。
ユーザー再認証間隔: これは、ユーザーが ID を確認するために資格情報を再入力する必要がある頻度であり、セッションが長期間にわたってハイジャックされないようにすることでセキュリティを強化します。
正解解説:
(オプション)
・Google Cloud Consoleのセッションタイムアウト設定を調整し、より早く期限切れにしました。
・Google Cloudリソースへのアクセスにおけるユーザー再認証間隔の頻度を高くする。
2 つの正しい選択は、Google Cloud 内にセッション管理セキュリティ プロトコルを実装することです。セッションのタイムアウト設定を調整して、より早く期限切れにすると、権限のないユーザーが無人セッションを悪用する期間が短縮されます。Google Cloud リソースにアクセスするためのユーザー再認証間隔をより頻繁に実装すると、ユーザーはより頻繁に ID を証明する必要があり、認証情報が定期的に検証されるようにすることでセッション ハイジャックのリスクが軽減されます。
不正解の説明:
オプション: OAuth 2.0 更新トークンの有効期間を短縮する企業ポリシーを制定します。
OAuth 2.0 更新トークンの有効期間の調整はトークン管理に関するものであり、アクティブなセッション管理や、アクティブな Google Cloud Console 環境や CLI 内でのセッション ハイジャックへの対処とは直接関係がないためです。
オプション: サードパーティの ID ソリューションを統合して、セッションの長さを管理します。
この質問は、Google Cloud 環境自体のセキュリティ対策の改善に重点を置いているため、この選択は正しくありません。サードパーティの ID ソリューションを統合すると、全体的なセキュリティに貢献できますが、Google Cloud 内のセッション管理とユーザーの再認証間隔に関する特定の問題には対処できません。
オプション: すべての従業員に 2 段階認証 (2SV) の物理セキュリティ キーの使用を義務付けます。
2 段階認証プロセスに物理的なセキュリティ キーの使用を義務付けると、特にユーザーのログイン時のセキュリティは強化されますが、アクティブな Google Cloud セッションのセッション タイムアウト設定やユーザーの再認証間隔に関する特定の問題には対処できません。
参考：
https://cloud.google.com/identity-platform/docs/session-management
https://cloud.google.com/docs/authentication
https://support.google.com/a/answer/9368756
</div></details>

### Q.  問題42: 未回答
あなたは、医療データ処理会社の VPC Service Controls を有効にして、データセットへのアクセスを中断することなく境界設定をテストする任務を負っています。
どの VPC Service Controls モードを有効にする必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、特にデータの機密性が高い医療分野で、企業のデータアクセスプロセスの通常の運用に影響を与えることなくセキュリティ境界を検証する必要があるシナリオでの VPC Service Controls のデプロイに焦点を当てています。
重要な用語:
ドライラン モード: ドライ ラン モードでは、管理者は、VPC Service Controls に違反するリクエストを実際に適用せずにログに記録することで、VPC Service Controls の影響を評価できます。
VPC Service Controls: VPC Service Controls は、データ リソースの周囲に安全な境界を作成することで、Google Cloud サービス内の機密データのセキュリティを強化します。
正解解説:
(オプション)
・予行演習
この選択は、ドライランモードは、VPC Service Controls を適用せずにその影響をテストするために特別に設計されているとして説明されているシナリオに最も適しています。これにより、管理者は、特定の制限を実装することで影響を受けるサービスやデータ転送を実際に実施する前に把握できるため、組織のVPC内の現在のアクティビティやデータアクセスを中断することなく、検証と調整を行うことができます。
不正解の説明:
オプション:ペリメーターガード
境界ガードが適切な選択ではない理由は、実際には VPC Service Controls のモードではないためです。この選択は邪魔なようで、VPC Service Controls の設定オプションとしては存在しません。
オプション:標準
Standard が正しくない理由は、標準が VPC Service Controls のデフォルトの操作モードを表している可能性が高く、構成された境界を適用するため、適切に構成されていないとデータへのアクセスが中断される可能性があるためです。
オプション: 適用
適用が正しくない理由は、このモードではすべての VPC Service Controls が適用されるため、データ アクセスが中断される可能性があり、アクセスを中断せずに設定をテストするという特定のシナリオの要件と矛盾するためです。
参考：
https://cloud.google.com/vpc-service-controls/docs/set-up-vpc-sc
https://cloud.google.com/vpc-service-controls/docs/dry-run
https://cloud.google.com/vpc-service-controls/docs/overview
</div></details>

### Q.  問題43: 未回答
組織の医療データ分析プロジェクトですべての Google Cloud サービスのインベントリを作成しています。データベース インスタンスを変更するアクセス許可を持つすべての ID を決定することを目的としています。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、特にデータのセキュリティとコンプライアンスが重要な医療データ分析環境に焦点を当てて、Google Cloud 内のデータベース インスタンスを変更する機能を備えた ID の監査に必要な適切なツールと権限を特定する能力を評価します。
重要な用語:
Policy Analyzer: Google Cloud の IAM のツールで、組織全体のリソースに誰がどのアクセス権を持っているかを把握し、ユーザーの権限に関連するセキュリティとコンプライアンスのチェックを可能にします。
権限 sql.instances.update または sql.instances.patch または sql.instances.delete: Cloud SQL の特定の IAM 権限で、ユーザーはそれぞれデータベース インスタンスの更新、パッチの適用、削除を行うことができ、これらは綿密なモニタリングが必要な重要なアクションです。
正解解説:
(オプション)
・Policy Analyzerを使用して、sql.instances.update、sql.instances.patch、sql.instances.deleteの権限を照会します。
この選択は、アクセス ポリシーを検査し、Google Cloud リソース全体のユーザー権限を特定し、ID がデータベース インスタンスに変更を加えることを許可する権限に焦点を当てるように設計された機能である Policy Analyzer を使用しているため、正確です。記載されている権限は Cloud SQL インスタンスの変更に固有のもので、医療におけるセキュリティ ガバナンスを目的としたインベントリに関連する更新、パッチ適用、削除オペレーションが含まれます。
不正解の説明:
オプション: Policy Analyzer を使用して、アクセス許可 sql.instances.get または sql.instances.list を照会します。
この選択が正しくない理由は、Policy Analyzer を介してアクセス許可 sql.instances.get または sql.instances.list を照会すると、データベース インスタンスを変更する機能を含まない読み取りレベルのアクセス権を持つ ID に関する情報のみが提供されるためです。
オプション: Database Insightsを使用して、データベース・インスタンスの使用率の傾向を確認します。
この選択が正しくない理由は、Database Insights がデータベースのパフォーマンスと使用率の分析を目的としており、データベース インスタンスを変更するアクセス許可を持つ ID の監査や検出は含まれていないためです。
オプション: Security Command Center の「Security Health Analytics – SQL Vulnerability Assessment」を参照してください。
この選択が正しくない理由は、Security Command Center のセキュリティ正常性分析 – SQL 脆弱性評価では、SQL データベースの潜在的なセキュリティ上の弱点を浮き彫りにすることはできますが、データベース インスタンスを変更するアクセス許可を持つ特定の ID を識別するための適切なツールではないためです。
参考：
https://cloud.google.com/iam/docs/policy-analyzer-overview
https://cloud.google.com/security-command-center/docs/how-to-security-health-analytics
https://cloud.google.com/network-intelligence-center/docs/firewall-insights/using-firewall-insights
</div></details>

### Q.  問題44: 未回答
ある医療機関が Google Cloud にシステムを実装しています。規制コンプライアンスでは、アーカイブデータをサービスに保存し、少なくとも2つの地理的リージョン間で自動的に複製する必要があります。
どのGoogle Cloudストレージオプションを利用するべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud ストレージ サービスに関する知識と、地理的に異なるリージョン間でのデータ重複に関する規制要件への準拠に関する機能を評価します。
重要な用語:
マルチリージョン ストレージ: Cloud Storage マルチリージョンは、地理的に離れた複数のリージョンにデータを保存することで高可用性と冗長性を提供する Google Cloud 内のストレージ クラスです。
地理的冗長性:地理的冗長性とは、地理的に離れたデータセンター間でデータをレプリケートし、高可用性とディザスターリカバリーを確保するストレージシステムの機能を指します。
正解解説:
(オプション)
・クラウドストレージマルチリージョナル
Cloud Storage Multi-Regional は、地理的に離れた少なくとも 2 つのリージョンにデータを自動的に保存するため、この選択は適切です。データアーカイブに関する規制遵守を必要とする医療機関は、高可用性とリージョンの障害に対する保護を確保します。マルチリージョンストレージに保存されたデータは、サービスの中断から保護され、サービスにアクセスする場所に近いため、エンドユーザーに低遅延でサービスを提供できます。
不正解の説明:
オプション:クラウドデータストア
この選択が間違っている理由は、Cloud Datastore は、拡張性が高く、フルマネージドの NoSQL データベースであるにもかかわらず、医療機関のコンプライアンス ニーズの要件である、複数の地理的リージョン間でのデータの自動複製をデフォルトで提供しないためです。
オプション: Cloud SQL SSD ストレージ
この選択が間違っている理由は、Cloud SQL SSD Storage が Google Cloud のフルマネージド データベース サービスである Cloud SQL 上のリレーショナル データベース用のストレージの一種であるためです。ただし、医療規制のコンプライアンスが重視する複数の地理的地域間でデータが自動的に複製されることは本質的に保証されません。
オプション: Compute Engine のローカル SSD
この選択が間違っている理由は、Compute Engine のローカル SSD は高性能な一時ストレージを提供しますが、複数の地理的リージョン間での自動データ複製を一切サポートしていないためです。これらは一時的なものであり、インスタンスが停止または終了するとデータが失われます。
参考：
https://cloud.google.com/bigquery/docs/locations
Hotpas://cloud.google.com/bigtable/doc/replication
Hutpas://cloud.google.com/comput/DOC/dis#rapds
</div></details>

### Q.  問題45: 未回答
会社の Google Cloud Compute Engine インスタンスは、外部クライアントがアクセスできる金融アプリケーションを実行するためのパブリック IP アドレスで設定するインスタンス テンプレートを使用してプロビジョニングされます。これらのインスタンスは、これらのインスタンス用に設計されたカスタム共有 VPC を含むホスト プロジェクトに接続されたマネージド サービス プロジェクトの一部です。これらのインスタンスのインターネットへの露出を最小限に抑えながら、外部クライアントのアクセシビリティを維持する必要があります。新しいマネージド・インスタンス・グループ(MIG)のパブリックIPアドレス構成を削除して、インスタンス・テンプレートをすでに更新しています。
次のステップは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、インターネットへの露出を減らしながら、Compute Engine インスタンス上の金融アプリケーションへの外部クライアントのアクセシビリティを維持する方法を中心にしています。このシナリオには、マネージド インスタンス グループ、パブリック IP 割り当ての取り消し、カスタム共有 VPC、および後続の手順の必要性が含まれます。
重要な用語:
外部HTTPSロードバランサー:HTTPSプロトコルを使用してネットワークまたはアプリケーションのトラフィックを複数のサーバーに分散し、安全な通信を確保するフロントエンドとして機能します。
マネージド インスタンス グループ(MIG): デプロイと管理を容易にするために Compute Engine によって 1 つのエンティティとして管理される VM インスタンスの集合。
共有VPC:組織は複数のプロジェクトのリソースを共通の仮想プライベートクラウドネットワークに接続し、ネットワークリソースを一元的に管理できます。
Cloud NAT Gateway: パブリック IP アドレスを持たない VM インスタンスがインターネットに接続できるようにし、部外者がインスタンスとの接続を開始できないようにします。
正解解説:
(オプション)
・バックエンド サービスとして MIG を指定したサービス プロジェクトに外部 HTTPS ロード バランサを設定します。
サービス プロジェクトで外部 HTTPS ロード バランサを設定し、MIG をバックエンド サービスとして指定すると、インスタンスにパブリック IP アドレスを割り当てることなく、インターネット経由で安全なトラフィックを提供できるため、この選択は最適です。このアプローチでは、ロードバランサーのIPを前面インターフェイスとして利用するため、各インスタンスのインターネットへの直接的な露出が最小限に抑えられ、外部クライアントが金融アプリケーションにアクセスできるようになります。
不正解の説明:
オプション: MIG をダイレクトで使用するために、サービス プロジェクト内に Cloud NAT Gateway を実装します。
この選択が間違っている理由は、Cloud NAT Gateway が外部クライアントのアクセシビリティを維持するという要件を満たしていないためです。Cloud NAT では、パブリック IP アドレスを持たないインスタンスは送信インターネット トラフィックを送信できますが、外部クライアントからの受信通信は有効になりません。
オプション: 管理対象インスタンス グループの管理ホスト プロジェクト内に Cloud NAT Gateway をインストールします。
この選択が間違っている理由は、最初の間違った選択と同じ理由です。Cloud NAT Gateway は、外部クライアントからの受信通信を容易にしません。また、ホスト プロジェクト内にインストールしても、この操作の動作は変更されません。
オプション: ホスト プロジェクト内に外部 HTTPS ロード バランサーを設定し、MIG をバックエンド サービスとして指定します。
ホスト プロジェクト内に存在するマネージド インスタンス グループへのトラフィックを管理するロード バランサーはホスト プロジェクトではなくサービス プロジェクトに含まれる必要があるため、ホスト プロジェクト内に外部 HTTPS ロード バランサーを確立することは正しくありません。
参考：
https://cloud.google.com/compute/docs/instance-templates
https://cloud.google.com/load-balancing/docs/https
https://cloud.google.com/nat/docs/overview
</div></details>

### Q.  問題46: 未回答
企業は Google Cloud で運営されており、一般ユーザーがアクセスできる複数のネットワーク リソースがあります。これらのリソースをカタログ化し、ソフトウェアソリューションを使用してセキュリティレビューをできるだけ早く実行する必要があります。
どのように進めればよいですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud で一般公開されているネットワーク リソースをカタログ化し、不必要な遅延や依存関係なしにセキュリティ評価を実施するための最も効果的かつ効率的な方法を決定することが受験者に求められます。
重要な用語:
Cloud Asset Inventory: ユーザーがクラウド リソースの可視性を維持し、プロジェクトやサービス全体でクラウド アセットの検出、モニタリング、分析をサポートする Google Cloud サービス。
ネットワーク・セキュリティ・スキャナー:ネットワーク・サービスの自動セキュリティ・スキャンを実行し、クラウド環境内の公開リソースの脆弱性とリスクを検出するために使用されるツールまたはサービス。
正解解説:
(オプション)
・Cloud Asset Inventoryを使用して、公開されているすべてのリソースを列挙し、ネットワークセキュリティスキャナーを展開して分析します。
Cloud Asset Inventory では、Google Cloud 環境内のすべての公開リソースを包括的かつ迅速に列挙できるため、この選択は顕著です。その後、ネットワーク・セキュリティ・スキャナーを導入することで、これらのリソースの脆弱性とセキュリティ体制を自動的かつ詳細に分析し、迅速なセキュリティ・レビューの必要性に応えます。
不正解の説明:
オプション: 企業全体のすべての仮想マシンで、プラットフォームに合わせたセキュリティ スキャンを開始します。
このオプションが正しくない理由は、すべての仮想マシンを個別にスキャンするには時間がかかり、VM に関連付けられていないリソースなど、公開されているすべてのリソースをカバーできない可能性があるためです。また、事前にリソースインベントリを使用することを意味するものでもありません。
オプション: Google の承認を得ているセキュリティ会社にセキュリティ評価を依頼します。
このオプションが間違っている理由は、たとえGoogleが承認したとしても、セキュリティ会社と契約することは、セキュリティレビュープロセスに追加の調整と遅延をもたらす可能性があるため、最も迅速なアプローチではないためです。
オプション: 今後のセキュリティ レビューについて Google に通知し、承認が得られるまでスキャンの実施を保留します。
このオプションが正しくない理由は、Googleが独自のリソースでセキュリティスキャンを実行する前に通知を必要としないためです。承認を待つ間、セキュリティレビューを遅らせると、不必要な遅延が発生し、スピードの要件に逆効果になります。
参考：
https://cloud.google.com/asset-inventory/docs/overview
https://cloud.google.com/security-command-center/docs/concepts-overview
Hatps://nmap.org/book/value.html
</div></details>

### Q.  問題47: 未回答
ある企業は、Google Cloud で認証されたパートナー専用のマルチレベル マーケティング プラットフォームを展開することを計画しています。企業のセキュリティ・ポリシーでは、検証済みで安全なCIDR範囲のコレクションからのシステム・アクセスのみを許可することが義務付けられています。企業は、プラットフォームがネイティブの Google Cloud 保護を使用して HTTP フラッド攻撃のみから保護されることを喜んで受け入れます。
これらのセキュリティポリシーを遵守するために、企業はどのソリューションを実装する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud のネットワーキング サービスと機能、特にセキュリティ ポリシーの調整と特定の種類のネットワーク攻撃に対する保護に関する知識を評価します。ソース IP 範囲とネイティブ攻撃の軽減に基づいてセキュリティ制約を実装するための適切なサービスの選択に重点を置いています。
重要な用語:
Cloud Armor: セキュリティと DDoS 保護を強化する Google Cloud サービス。IP 許可リスト/拒否リスト、および地理ベースのアクセス制御をサポートし、グローバル HTTP(S) 負荷分散と統合します。
HTTPフラッド攻撃:DDoS攻撃の一種で、攻撃者は一見正当なHTTP GETまたはPOSTリクエストを悪用して、標的のサーバーまたはネットワークを圧倒します。
正解解説:
(オプション)
・クラウドアーマー
Cloud Armor は、企業の要件に沿って必要な防御メカニズムを提供します。特定のCIDR範囲からのトラフィックを許可するセキュリティ・ルールを作成することで、認証されたパートナにのみアクセスを許可するように構成できます。さらに、Cloud Armor は、Google のグローバル インフラストラクチャとセキュリティ システムを使用して、HTTP フラッド攻撃などの DDoS 攻撃からアプリケーションを保護することを専門としています。これは、このような攻撃からネイティブの Google Cloud 保護でプラットフォームを防御するという同社の意欲と一致しています。
不正解の説明:
オプション: VPC ファイアウォール ルール
VPCファイアウォールルールが正しくない理由は、IP範囲に基づいてアクセスを制限できる一方で、企業がセキュリティ戦略の一環として求めているHTTPフラッドDDoS攻撃に対する特別な保護を提供していないためです。
オプション: Cloud Identity and Access Management(IAM)
Cloud Identity and Access Management(IAM)が正しくない理由は、IAM が IP 範囲ではなく ID とロールに基づいて Google Cloud リソースへのアクセスを制御し、特定の DDoS 攻撃保護メカニズムを提供していないためです。
オプション:クラウド負荷分散
Cloud Load Balancing が正しくない理由は、受信トラフィックをリソース間で分散することはできますが、それ自体では、定義された CIDR 範囲からのトラフィックを許可またはブロックする機能や、HTTP フラッド攻撃に特化した DDoS 保護を提供していないためです。
参考：
https://cloud.google.com/armor/docs/security-policy-concepts
https://cloud.google.com/armor/docs/ddos-defender-overview
https://cloud.google.com/vpc/docs/firewalls
</div></details>

### Q.  問題48: 未回答
組織は、サービス アカウント キーの使用を制限するためのセキュリティ指令を制定しています。企業ネットワーク内の従来の Linux ベースのシステムは、Google Cloud API と連携する必要があります。Workload Identity フェデレーションは、社内の ID プロバイダとの間で確立する必要があります。
どのような対策を講じるべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、サービス アカウント キーを使用せずにオンプレミス システムと Google Cloud サービスを統合する方法の理解度を評価し、ID フェデレーションのセキュリティ プラクティスとプロトコルに焦点を当てます。
重要な用語:
Workload Identity フェデレーション: Google Cloud の外部で実行されているアプリケーションが、サービス アカウント キーを必要とせずに Google Cloud リソースに安全にアクセスできるようにするセキュリティ機能。
ライトウェイト ディレクトリ アクセス プロトコル (LDAP): インターネット プロトコル (IP) ネットワークを介して分散ディレクトリ情報サービスにアクセスして維持するための、ベンダーに依存しないオープンなアプリケーション プロトコル。
ID プール: Google Cloud サービス アカウントの権限にマッピングできる外部 ID プロバイダーからの ID のコレクション。
OpenID Connect (OIDC): OAuth 2.0 プロトコルの上にあるシンプルな ID レイヤーで、コンピューティング クライアントは、承認サーバーによって実行される認証に基づいてエンドユーザーの ID を検証できます。
正解解説:
(オプション)
・社内の Lightweight Directory Access Protocol (LDAP) を使用してワークロード ID プールを確立します。プール内の ID が Google Cloud サービス アカウントの ID を引き継ぐことを許可するポリシーを構成します。
この選択は、レガシー システムがサービス アカウント キーを使用せずに Google Cloud API とやり取りする必要があるシナリオに合わせているため、正しいです。認証に組織の LDAP を使用してワークロード ID プールを確立し、プールに関連付けられた ID が Google Cloud サービス アカウントの役割を引き受けるように制限するポリシーを慎重に作成することで、アクセス制御が保証され、セキュリティ指令に準拠します。この方法では、社内 ID を Google Cloud サービスとシームレスかつ安全に連携させることができます。
不正解の説明:
オプション: オンプレミスのライトウェイト ディレクトリ アクセス プロトコル (LDAP) を使用してワークロード ID プールを作成します。プール内のすべての ID が Google Cloud サービス アカウントの ID を引き受けることを許可します。
この選択が間違っている理由は、LDAP ベースの ID プール内のすべての ID に Google Cloud サービス アカウントの引き受けを許可するだけでは、最小権限の原則に違反し、過剰な権限が付与され、セキュリティが損なわれる可能性があるためです。
オプション: 同じサーバー上で OpenID Connect (OIDC) エンドポイントを使用してワークロード ID プールをインスタンス化します。プール内の ID が Google Cloud サービス アカウントの ID を引き受けられるようにするポリシーを構成します。
この選択が正しくない理由は、レガシ システムではサポートされていない可能性のある OpenID Connect (OIDC) エンドポイントの存在を前提としており、組織のセキュリティ ポリシーに従ってアクセス許可を制限することについて言及していないためです。
オプション: 同じサーバー上に OpenID Connect (OIDC) エンドポイントを持つワークロード ID プールをセットアップします。プール内のすべての ID が Google Cloud サービス アカウントの ID を引き継ぐことを許可します。
この選択が間違っている理由は、前の選択と同じですが、プール内のすべての ID が Google Cloud サービス アカウントの ID を引き受けることを許可するという追加のエラーがあるため、アクセス権が過度に寛容になる可能性があります。
参考：
httpps://cloud.google.com/iam/docs/workload-identity-federation
https://cloud.google.com/iam/docs/impersonating-service-accounts
https://cloud.google.com/docs/authentication/production#auth-cloud-implicit-python
</div></details>

### Q.  問題49: 未回答
国際的な小売企業の財務部門が Google Cloud を活用した戦略を開始し、金融システムを Google Cloud に移行するプロセスを開始しました。財務部門は、多数のプロジェクトを含む組織リソースのコレクションを含む Cloud Identity ドメインを設定します。あなたのチームは、この開発を知り、ドメイン リソースに対する権限の管理と監査の実施の制御を引き受けるつもりです。
この目標を達成するには、チームがどのような種類のアクセスレベルを取得する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、チームが財務部門の Google Cloud の組織リソース内で権限を効果的に管理し、監査を実施するために必要なアクセス レベルに関するものです。このシナリオは、Cloud Identity ドメインのマルチプロジェクト環境を示しています。
重要な用語:
組織管理者: 組織内のすべてのリソースを完全に制御できる Google Cloud 内の IAM ロール。これには、ポリシーの設定、コンプライアンス設定の管理、すべてのプロジェクトにわたる IAM ロールの監視が含まれます。
Cloud Identity: 組織が Google Cloud リソース全体のユーザー、デバイス、アプリ、サービスへのアクセスを一元的に管理するのに役立つ Google Cloud の機能。
Rights Management: クラウド環境内のリソースに対するユーザーまたはグループのアクセス許可とアクセス レベルを定義および制御するプロセス。
監査: リソースの使用状況、構成、およびセキュリティ ポリシーを体系的に調査して、企業または規制の基準に準拠していることを確認します。
正解解説:
(オプション)
・組織管理者
組織管理者ロールは Google Cloud の階層内で最高レベルのアクセス権を付与するため、すべてのリソースを完全に制御し、組織全体で IAM ポリシーを設定および変更できるため、この選択は適切です。この役割には組織全体の権限と監査管理機能が含まれるため、チームは、監査の実施、コンプライアンスの管理、必要に応じてユーザー権限の制御の引き受けなど、すべての組織リソースを効果的に監視できます。
不正解の説明:
オプション: セキュリティ監査人
この選択が間違っている理由は、セキュリティ監査人のロールが、セキュリティコンプライアンスを確保するためのログとポリシーの表示に主眼を置いているためです。監査の実施には便利ですが、アクセス権の管理や、組織のリソース設定内で変更を行う機能は許可されません。
オプション: ロール管理者
この選択が間違っている理由は、ロール管理者ロールがカスタム IAM ロールの作成と管理に特化しているためです。これには、きめ細かなアクセス許可の定義と割り当てが含まれますが、ポリシーを調整したり、すべての組織リソースに対してエンドツーエンドの監査を実施したりするための包括的な権限は付与されません。
オプション: ポリシー管理者
この選択が間違っている理由は、ポリシー管理者ロールがプロジェクトレベルまたは組織レベルでリソースポリシーの設定と管理を担当しているためです。この役割にはリソースレベルのポリシーの管理が含まれますが、組織内のすべてのプロジェクトとリソースにわたる包括的な権限管理または監査機能を網羅しているわけではありません。
参考：
https://cloud.google.com/iam/docs/granting-changing-revoking-access
https://cloud.google.com/resource-manager/docs/access-control-org
https://cloud.google.com/resource-manager/docs/creating-managing-organization
</div></details>

### Q.  問題50: 未回答
Google Cloud の医療機関内で、ユーザーが Cloud Storage バケットに保存されている診断データを一般公開することを制限するポリシーを確立する必要があります。医療機関は、Cloud Storage バケットをまだ作成していません。
管理作業を最小限に抑えながら、このセキュリティ対策が確実に実施されるようにするにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、データへの一般公開を防止するための Google Cloud のプロアクティブなセキュリティ対策に関する知識を評価します(Cloud Storage の使用を計画しているが、現在バケットが作成されていない医療機関向けに特別に調整されています)。
重要な用語:
PublicAccessPrevention: 有効にすると、Cloud Storage バケット内のデータへのパブリック アクセスの作成を防止し、より高いレベルのセキュリティを確保する機能。
OrganizationPolicy: Google Cloud の一元化されたリソースで、管理者はコンプライアンスとガバナンスのニーズを反映した制約を設定できます。
UniformBucketLevelAccess: IAM のみを使用して Cloud Storage バケットのアクセス制御管理を統合および簡素化する機能。
VPIServiceControls: データ流出リスクの制御に役立つ追加のセキュリティ層を提供する一連のセキュリティ機能。
正解解説:
(オプション)
・constraints/storage.publicAccessPrevention制約を組織レベルで適用する。
この選択は、先制的なセキュリティ ガバナンス手段を確立するため、最も効率的です。組織レベルで constraints/storage.publicAccessPrevention を適用すると、組織全体のすべての Cloud Storage バケットにポリシーが適用され、デフォルトで一般公開されるバケットがなくなります。これはスケーラブルであり、作成時に各バケットを監視して手動で保護する必要がなくなるため、管理作業が最小限に抑えられます。
不正解の説明:
オプション: スケジュール設定された Cloud Scheduler ジョブを設定して、一般公開されている Cloud Storage バケットを 1 時間ごとにスキャンして保護する Cloud Functions の関数をトリガーします。
この選択が間違っている理由は、予防的ではなく事後対応的なアプローチを表しているためです。継続的な監視が必要であり、関数がバケットを保護する前にデータがパブリックにアクセス可能になる期間が短くなる可能性があり、機密データの処理には理想的ではありません。
オプション: constraints/storage.uniformBucketLevelAccess 制約を組織レベルで適用します。
この選択が正しくない理由は、バケットレベルのアクセス許可ポリシーが適用されますが、バケットへのパブリックアクセスは特に制限されないためです。権限管理は簡素化されますが、それ自体ではデータがパブリックに共有される可能性を防ぐことはできません。
オプション: Cloud Storage バケットを使用して既存の医療プロジェクト用に storage.googleapis.com サービスの周囲に VPC Service Controls 境界を構築し、Cloud Storage バケットを使用する将来のプロジェクトをこの境界に含めます。
この選択が間違っている理由は、VPC Service Controls 境界はネットワーク全体のデータ移動を制御するように設計されているが、パブリックにアクセス可能なストレージリソースの作成を妨げないためです。この制御メカニズムは、バケット内のパブリックデータアクセスを制御するよりも、流出を防ぐのに適しています。
参考：
https://cloud.google.com/storage/docs/public-access-prevention
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-public-access
https://cloud.google.com/storage/docs/uniform-bucket-level-access
</div></details>

## 4

### Q.  問題1: 未回答
あるクライアントは、Compute Engine で多層 SaaS アプリケーションの広範なセットをスケールアウトしようとしています。
クライアントは、各アプリケーションのさまざまなレイヤー間で認証されたネットワークの分離をどのように保証できますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud Compute Engine の多層 SaaS(Software-as-a-Service)アーキテクチャ内でネットワーク分離を実装するための戦略を評価します。これは、認証されたネットワーク通信が異なるアプリケーション層間で制限されるようにすることに重点を置いています。
重要な用語:
サービス アカウント: サービス アカウントは、個人ではなく、アプリケーションまたは仮想マシン (VM) インスタンスによって使用される特別な種類のアカウントです。これは、サーバーまたはコードが個別に認証する必要があるシナリオを対象としています。
ファイアウォール ルール: Google Cloud のネットワーク ファイアウォール内で構成されたルールで、IP アドレス、プロトコル、ポートに従って仮想マシン インスタンスとの間の送受信ネットワーク トラフィックを制御します。
正解解説:
(オプション)
・各アプリケーション層に個別のサービスアカウント(SA)を割り当て、SAベースのファイアウォールルールでアクセスを管理します。
この選択が効果的なのは、個別のサービス アカウントを使用して、アプリケーション層レベルで ID およびアクセス管理を実行できるためです。各階層に一意のサービス アカウントを割り当て、サービス アカウントを認識するファイアウォール ルールを作成することで、サービス アカウントを ID として扱う Google Cloud の機能を巧みに活用しています。このアプローチにより、きめ細かなアクセス制御と最小特権の原則の遵守が保証され、ファイアウォール ルールは認識された認証に基づいてトラフィックを明示的に許可または拒否できます。
不正解の説明:
オプション: 各アプリケーション層を個別のプロジェクト内に分離し、プロジェクト ラベルを使用して分離を管理します。
この選択が間違っている理由は、各アプリケーション層を個別のプロジェクトに分離してネットワーク分離を管理するのは粗すぎて、プロジェクト内のマイクロセグメンテーション用に設計されていないためです。また、管理のオーバーヘッドと複雑さが増し、必要なきめ細かなネットワーク分離が提供されます。
オプション: 各アプリケーション層を専用のサブネットに配置し、サブネット固有のファイアウォール規則を使用して分離を実装します。
この選択が間違っている理由は、各アプリケーション層を専用のサブネットに配置するとネットワーク セグメンテーションを提供できますが、これは主にネットワーク インフラストラクチャ レベルであり、アクセス制御に認証された ID を使用しないため、サービス アカウント ベースのルールほど安全ではないためです。
オプション: 各アプリケーション層に一意の VM タグを割り当て、タグに依存するファイアウォール規則を使用して分離を定義します。
この選択が間違っている理由は、一意の VM タグを割り当てると識別メカニズムが提供されますが、タグは静的な識別子であり、サービス アカウントが提供できる認証の側面が欠けているためです。セグメンテーションをシンプルにするには実用的ですが、それ自体ではネットワーク トラフィックを認証しません。
参考：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/iam/docs/understanding-service-accounts
https://cloud.google.com/compute/docs/instances/service-accounts
</div></details>

### Q.  問題2: 未回答
ここで行うタスクは、App Engine にデプロイされたアプリケーションの機密構成パラメータを管理し、アクセスするための適切な方法を特定することです。
どのようなサービスをお勧めしますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、App Engine 上のアプリケーションの機密性の高い構成データを、偶発的な漏洩や不正アクセスのリスクにさらされることなく安全に管理し、アクセスするための適切な Google Cloud サービスを特定することに重点を置いています。
重要な用語:
シークレットマネージャー:APIキー、パスワード、証明書、その他のシークレットなどの機密情報を保存および管理できる安全で便利なストレージシステム。Google の Cloud Identity and Access Management と統合されており、きめ細かなアクセス制御が可能です。
環境変数: 実行中のプロセスがコンピューター上でどのように動作するかに影響を与える可能性のある、アプリケーションのランタイム内の変数。機密データを安全に保持するようには設計されていません。
インスタンスメタデータ: 実行中のインスタンスを構成または管理するためにアプリケーションで使用できるインスタンスに関するデータ。インスタンスメタデータはインスタンス内からアクセスでき、シークレットを格納するようには設計されていません。
Cloud KMS: クラウド サービスの暗号鍵を一元的に管理できる、クラウドでホストされる鍵管理サービスで、機密データの暗号化に役立ちますが、秘密の管理用に特別に設計されたものではありません。
正解解説:
(オプション)
・シークレットマネージャー
Secret Manager は機密性の高い構成データを処理するように特別に設計されているため、この選択は適切です。バージョニングにより、シークレットのさまざまなバージョンを維持でき、堅牢なアクセス制御も提供されます。Cloud IAMとの統合により、誰がどのシークレットにアクセスできるかを決定でき、シークレットごとに監査ログが保持されるため、誰がどのシークレットにいつアクセスしたかを監視できるため、機密情報を安全かつ管理しやすい方法で処理できます。
不正解の説明:
オプション:クラウドキー管理サービス
この選択が間違っている理由は、Cloud KMS がアプリケーション シークレットの管理ではなく、主に暗号鍵の作成、インポート、管理に使用されるためです。シークレットを暗号化することはできますが、シークレットマネージャーのようにシークレットに固有の管理機能は提供されません。
オプション: App Engine インスタンスのメタデータ
この選択が間違っている理由は、App Engine インスタンスのメタデータが機密性の低い構成データを保存するように設計されているためです。このようなメタデータは、リスクの高いデータを対象としておらず、Secret Manager と同じレベルのセキュリティを提供しないため、機密パラメーターに対しては安全ではありません。
オプション: App Engine の app.yaml 環境変数
この選択が間違っている理由は、App Engine の app.yaml 環境変数を使用して構成パラメータを設定できますが、プレーンテキストで保存されるためです。これにより、シークレット以外のアプリケーション構成には適していますが、Secret Manager などのサービスを必要とする機密情報の保護には適していません。
参考：
https://cloud.google.com/secret-manager/docs
https://cloud.google.com/kms/docs
https://cloud.google.com/compute/docs/storing-retrieving-metadata
</div></details>

### Q.  問題3: 未回答
チームは、ネットワーク内の他の仮想マシンから接続することなく、分析ソフトウェアからログ データベースに排他的にアクセスできるように環境を構成する必要があります。
チームはどのようなネットワーク構成を実装する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、クラウド環境内のネットワークアクセス制御とセキュリティメカニズムに関する知識を評価します。これは、特定のアプリケーションのみがログデータベースと通信できるように、ログデータベースへのアクセスを制限する方法の理解を確立することを目的としています。
重要な用語:
イングレス・ファイアウォール・ルール: 定義されたセキュリティ・ポリシーに基づいて、サービス・インスタンスへの受信ネットワーク・トラフィックのフローを制御するネットワーク・セキュリティ機能。
ファイアウォール タグ: Google Cloud の仮想マシン インスタンスに適用できる属性で、ファイアウォール ルールと照合して適切なネットワーク アクセス制御を適用するために使用されます。
正解解説:
(オプション)
・ファイアウォールタグを使用して、分析ソフトウェアからロギングデータベースへのアクセスのみを許可するイングレスファイアウォールルールを作成します。
適切なタグを使用してイングレス ファイアウォール ルールを設定すると、ネットワーク トラフィックを正確に制御できるため、この選択は正確です。分析ソフトウェアにタグを付け、そのソフトウェアからログデータベースへのアクセスのみを許可するルールを作成することで、指定されたタグを持つ仮想マシン以外の仮想マシンがデータベースと対話できないようにすることができます。これにより、同じ仮想プライベートクラウド(VPC)内で安全なネットワークソリューションが提供され、アーキテクチャが簡素化され、オーバーヘッドが削減されます。
不正解の説明:
オプション:分析ソフトウェアとロギングデータベース専用のサブネットを確立して、ネットワークセグメンテーションをアサートします。
この選択が正しくない理由は、サブネットの作成によるネットワーク セグメンテーションで十分であることを前提としているためです。ただし、適切なファイアウォール ルールがないと、同じサブネット内の仮想マシンがログ データベースにアクセスする可能性があり、排他アクセスの要件を満たしません。
オプション: 2 つの個別の Virtual Private Cloud(VPC)をプロビジョニングし、それらを Cloud VPN ゲートウェイでリンクしてネットワーク セグメンテーションを強化します。
この選択が間違っている理由は、個別の VPC を作成して Cloud VPN とリンクすると、ネットワーク セグメンテーションが強化される可能性がある一方で、要件に対して過度に複雑であり、他の仮想マシンがログ データベースにアクセスするのを本質的に妨げるものではないためです。
オプション: 2 つの異なる VPC ネットワークを設定し、VPC ピアリングを介して相互接続を容易にし、ネットワークのコンパートメント化を保証します。
この選択が正しくない理由は、個別の VPC ネットワークを設定し、VPC ピアリングを介して接続することは、より広範なネットワークのコンパートメント化のための方法ですが、他の VM が同じ VPC 内のログデータベースにアクセスすることを本質的に制限するものではないためです。
参考：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/vpc/docs/using-firewalls
https://cloud.google.com/compute/docs/networking
</div></details>

### Q.  問題4: 未回答
金融サービス会社の最高コンプライアンス責任者は、取引プラットフォームのインフラストラクチャ内でサービスアカウントを生成する機能を制限することで、セキュリティプロトコルを強化する必要があります。
これを会社全体で一律に実現するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、金融取引プラットフォームのインフラストラクチャ内での新しいサービス アカウントの作成を制限する全社的なセキュリティ対策の実装を扱い、特に適切な Google Cloud Platform メカニズムの利用に焦点を当てています。
重要な用語:
組織ポリシーの制約: 組織ポリシーは、リソース階層全体の GCP リソースの構成を一元的に管理します。これにより、特定のサービス動作を強制できます。
iam.disableServiceAccountCreation: GCP の組織ポリシー内のブール型の制約で、有効にすると、組織内のユーザーやサービス アカウントが新しいサービス アカウントを作成できなくなります。
正解解説:
(オプション)
・Organization policy constraints/iam.disableServiceAccountCreation ブール値を使用して、新しいサービスアカウントの作成を無効にします。
この選択は、全社的にセキュリティ強化を一律に実施することを目指すチーフ・コンプライアンス・オフィサーにとって正しい行動です。組織ポリシーで「iam.disableServiceAccountCreation」ブール制約を有効にすると、新しいサービスアカウントの作成が禁止されます。この方法により、組織内のすべてのプロジェクトとフォルダーで新しいサービス アカウントを作成できなくなり、会社の強化されたセキュリティ プロトコルに準拠できます。
不正解の説明:
オプション: Identity and Access Management (IAM) ポリシーを適用して、取引プラットフォームにリンクされているすべてのユーザーとサービス アカウントのアクセス許可を取り消します。
この選択が間違っている理由は、取引プラットフォームにリンクされているユーザーの権限を取り消すだけでは、他のプロジェクトまたはフォルダーでサービスアカウント管理権限を持つユーザーが作成できる新しいサービスアカウントの作成が妨げられないためです。
オプション: 組織ポリシーの制約/iam.disableServiceAccountKeyCreation ブール値を有効にして、新しいサービスアカウントが確立されないようにします。
この選択が間違っている理由は、新しいサービス キーの確立を禁止することは、新しいサービス アカウントの作成を禁止することと同じではないためです。サービス アカウントは引き続き作成できますが、関連付けられたキーを作成することはできません。
オプション: 組織ポリシーの制約/iam.disableServiceAccountKeyUploadブール値をアクティブにして、新しいサービスアカウントの作成をブロックします。
この選択が正しくない理由は、新しいサービス アカウント キーのアップロードを禁止しても、新しいサービス アカウントの作成が妨げられないためです。上記のポリシーは、アカウントの作成ではなく、特にキーのアップロードに関するものです。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-service-accounts
</div></details>

### Q.  問題5: 未回答
医療従事者には450人の医療スタッフがいます。組織は、さまざまなアクセスレベルを効果的に委任し、テストおよびライブサービスプラットフォームプロジェクトにおけるチームメンバー間のIAM権限の管理を簡素化したいと考えています。
これらのニーズを満たすために、組織はどのような手順を実装する必要がありますか?アクションを 2 つ選択します。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、さまざまなアクセスレベルを必要とする多数のユーザーを抱える組織で、Google Cloud でリソースを構造化し、ID およびアクセス管理(IAM)を効率的に管理する方法について、受験者の理解度を評価します。
重要な用語:
フォルダ階層: Google Cloud リソースの論理的なグループ化により、権限の効果的な整理と管理が可能になり、フォルダ レベルからプロジェクトまでのアクセス制御の継承とカスケードをサポートします。
Google グループ: Google が提供するコラボレーション機能で、グループを作成して効率的に管理し、複数のユーザー間で権限を分散できます。
正解解説:
(オプション)
・テスト・ライブサービスプラットフォームごとにフォルダを設置
・医療従事者向けのGoogleグループを編成し、フォルダ階層でアクセス制御を割り当てます。
フォルダを確立することで、リソースを明確に分離し、IAMポリシーを合理化できます。各環境 (テスト環境とライブ環境) にフォルダーを割り当てることで、組織はアクセス許可の継承を活用してアクセスを効果的に管理できます。医療スタッフ用の Google グループを作成し、フォルダ レベルでアクセス制御をリンクすると、個々の IAM ポリシーを変更することなくグループ メンバーシップを簡単に調整できるため、権限の管理と変更が簡素化されます。
不正解の説明:
オプション: 各プラットフォーム専用の個別の VPC ネットワークを含むプロジェクトを開始します。
この選択が間違っている理由は、プラットフォームごとに個別の VPC ネットワークを作成しても、IAM や権限管理の簡素化には関係がないためです。ネットワークの分離に重点が置かれており、ユーザーのアクセス レベルの制御には直接影響しません。
オプション: プラットフォームの各フォルダーに合わせて調整された組織ポリシー制約を適用します。
この選択が正しくない理由は、フォルダー レベルで組織のポリシーを適用すると、リソースの使用方法が制限されますが、さまざまなアクセス レベルをさまざまなユーザーまたはグループに直接付与または委任するわけではないためです。
オプション: 各プラットフォームに固有のプロジェクトを設定し、各医療スタッフメンバーに直接 IAM 権限を付与します。
この選択が間違っている理由は、各スタッフメンバーに対してIAM権限を直接設定することは、管理を簡素化することとは逆であるためです。医療スタッフの変更や規模に合わせて維持するには時間がかかり、エラーが発生しやすくなります。
参考：
https://cloud.google.com/resource-manager/docs/creating-managing-folders
https://cloud.google.com/iam/docs/groups-best-practices
https://cloud.google.com/resource-manager/docs/access-control-proj
</div></details>

### Q.  問題6: 未回答
ある教育機関の IT 部門は、Google App Engine など、Google Cloud の PaaS ソリューションを使用してデプロイされたさまざまな教育アプリケーションに対するセキュリティ責任を評価しています。彼らは、これらの教育ワークロードに関する Google Cloud との責任分担を理解することを目的としています。教育機関の IT 部門は、App Engine にアプリケーションをデプロイする際に、技術スタックのどの部分にセキュリティの取り組みを集中させる必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、サービスとしてのプラットフォーム(PaaS)サービス、特に Google App Engine を使用する際のセキュリティ責任に関する IT 部門の理解度を評価します。これは、クラウドプロバイダーとクライアント機関の間のセキュリティタスクの分割を強調しています。
重要な用語:
クロスサイトスクリプティング(XSS):多くの場合、ユーザー入力フィールドを介して、他の方法では信頼できるWebサイトのコンテンツに悪意のあるスクリプトを挿入する攻撃。
SQLインジェクション(SQLi):データベースを破壊する可能性のあるコードインジェクション手法。これは、最も一般的なWebハッキング手法の1つです。これは、Webページの入力を介して、SQLステートメントに悪意のあるコードを配置することです。
サービスとしてのプラットフォーム (PaaS): インフラストラクチャの構築と保守の複雑さを伴わずに、顧客がアプリケーションを開発、実行、管理できるプラットフォームを提供するクラウド コンピューティング モデル。
正解解説:
(オプション)
・クロスサイトスクリプティング(XSS)およびSQLインジェクション(SQLi)の脅威の軽減
Google App Engine などの PaaS ソリューションでは、ネットワーク制御、物理的なセキュリティ、サーバーへのパッチ適用、オペレーティング システム(OS)のメンテナンスなど、インフラストラクチャのセキュリティをクラウド プロバイダーが担当するため、この選択は正しいです。ただし、クライアントは、クロスサイトスクリプティング(XSS)やSQLインジェクション(SQLi)などの脅威への対処を含む、アプリケーションレベルのセキュリティを担当します。これらは、アプリケーションのコードと設計を通じて導入される可能性のある脆弱性であり、その軽減策は、特に展開機関のIT部門の範囲内にあります。
不正解の説明:
オプション: Identity and Access Management (IAM) ポリシーの設定と管理
この選択が間違っている理由は、Google Cloud の IAM ポリシーはクラウド プロバイダ レベルで管理されますが、クライアントはきめ細かなアクセス制御を構成して適用することもできます。ただし、PaaS では、一部の IAM の責任が共有されるため、機関の IT 部門に限定されるわけではありません。
オプション: 基盤となるオペレーティング システムの定期的な更新とセキュリティ パッチ
この選択が間違っている理由は、基盤となるオペレーティング システムの定期的なアップデートとセキュリティ パッチが PaaS サービス(App Engine)の一部として Google Cloud によって管理されているためです。クライアントは、システム管理のこの側面について責任を負いません。
オプション: 教育コンテンツとデータベースの保存中および転送中の暗号化を実装する
この選択が間違っている理由は、保存中および転送中のデータの暗号化が Google Cloud のインフラストラクチャによって処理され、厳格なセキュリティ基準に準拠しているためです。クライアントは追加の暗号化手段を採用できますが、基本的な暗号化はクラウドプロバイダーとの共同責任の一部です。
参考：
https://cloud.google.com/appengine/docs/standard/security-roles
https://cloud.google.com/security/shared-responsibility
https://ovasp.org/wu-community/attacks/sss/
</div></details>

### Q.  問題7: 未回答
ある多国籍企業が Google Cloud を導入してデータ分析プラットフォームを管理しており、Cloud Identity アカウントのパスワード ポリシーの設定に関するアドバイスを求めています。企業では、データアナリストの役割のパスワードは最小長でなければならないことを義務付けています。
この特定のパスワード ポリシー要件を確立するために、Cloud Identity にはどのようなオプションが用意されていますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、データ アナリスト アカウントの Google Cloud Identity 内で使用できるパスワード ポリシー設定オプションに関する知識を評価します。このサービスを使用して設定できるパスワードの最小長要件を理解することに重点が置かれています。
重要な用語:
Cloud Identity: さまざまな Google Cloud サービスでユーザー ID 管理のための一元化された標準化されたシステムを提供し、管理者がパスワードの最小文字数などのセキュリティ ポリシーを実装できるようにするサービスです。
正解解説:
(オプション)
・パスワードの文字数は8文字以上とします。
Cloud Identity では、管理者がユーザー アカウントのセキュリティ ポリシーの一部としてパスワードの最小文字数を適用できるため、この選択は有効です。最小長を 8 文字に設定することは、Cloud Identity が提供するポリシー構成オプション内にあります。これは、基本的なレベルのパスワードの複雑さを確保するのに役立ち、パスワードの最小長として一般的に使用される標準です。
不正解の説明:
オプション: パスワードの最小長を 14 文字に設定します。
この選択が間違っている理由は、Cloud Identity では管理者がパスワードの最小文字数を設定できますが、サービスでは 14 文字の最小パスワード長がサポートされていないためです。Google Cloud では、パスワード ポリシー パラメータで許容される最大文字数と最小文字数を指定していますが、14 文字はこの範囲に含まれません。
オプション: パスワードの最小長を 16 文字に設定します。
この選択が間違っている理由も、Cloud Identity のパスワード設定の制約に基づいています。パスワードの最小文字数を 16 文字に設定すると、Google Cloud Identity がサポートするパスワードの最小文字数の標準制限を超えます。
オプション: パスワードの最小長を 7 文字に設定します。
この選択が正しくない理由は、Cloud Identity のパスワードの複雑さに関するデフォルトの最小要件を下回っているためです。最小長 7 文字は、Google Cloud Identity で適用される最小文字数 8 文字よりも短く、目的のパスワード ポリシーを確立するには不十分です。
参考：
https://cloud.google.com/identity/docs/how-to/setup-password-policies
https://cloud.google.com/identity/docs/concepts/identity-fundamentals
Hatps://support.google.com/a/answer/91555?hl=n
</div></details>

### Q.  問題8: 未回答
医療機関のアプリケーションは、機密性の高い患者データを処理するために、ユーザー管理のサービス アカウント キーを使用してデプロイされます。Google が推奨するサービス アカウントのキーのローテーションに関するベスト プラクティスに従うことに関心があります。
どのような手順を踏む必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud のコンテキストにおけるサービス アカウント キーのローテーションのベスト プラクティス、特に機密データを処理するアプリケーションに関する質問について検討します。キー管理のライフサイクルとセキュリティコンプライアンスの理解をテストします。
重要な用語:
サービス アカウント キーのローテーション: 新しいキーを作成し、古いキーを安全に置き換えます。この方法では、1 つのキーの使用時間を制限することでセキュリティが確保されます。
ユーザー管理サービス アカウント: キーがアカウント ユーザーによって管理されるサービス アカウントの種類で、キーの安全な生成、保存、ローテーションの責任が追加されます。
キーの失効: キーを無効にして、認証でそれ以上使用されないようにするプロセス。失効は、セキュリティを継続するために、新しいキーにローテーションした後に重要です。
正解解説:
(オプション)
・新しいキーを作成し、新しいキーを使用するようにアプリケーションを更新します。次に、サービス アカウントから古いキーを取り消します。
この選択は、新しいキーが安全に作成され、アプリケーション内の古いキーを置き換えて認証されたアクセスを維持し、その後、古いキーを取り消して誤用を防ぐことで、ベスト プラクティスに対処しています。キーの失効により、古いキーは使用できなくなりますが、これはローテーション プロセスにおける重要なセキュリティ手順です。このアプローチにより、古い鍵を使用した不正アクセスのリスクが最小限に抑えられ、アプリケーションが必要な Google Cloud リソースへの継続的なアクセスが維持されます。
不正解の説明:
オプション: Cloud Shell を使用して gcloud iam service-accounts keys enable-rotation --account=SERVICE_ACCOUNT を実行し、鍵のローテーションを有効にします。
この選択が間違っている理由は、「gcloud iam service-accounts keys enable-rotation」が有効な gcloud CLI コマンドではないためです。Google Cloud IAM には、1 つの CLI コマンドで自動キーローテーションを有効にする直接的な方法は用意されていません。
オプション: Cloud Shell で gcloud iam service-accounts keys rotate --account=SERVICE_ACCOUNT --new-key=KEY_NAME コマンドを実行して、鍵をローテーションします。
この選択が間違っている理由は、「gcloud iam service-accounts keys rotate」が gcloud CLI で有効なコマンドではないためです。キーのローテーションは手動で管理する必要があります。これには、必要に応じてキーを作成、実装、および取り消すことが含まれます。
オプション: 新しいキーを生成し、それをアプリケーションと統合し、緊急復旧のために以前のキーをローカル サーバーに格納しておきます。
この選択が間違っている理由は、たとえ緊急の目的であっても、古いキーを保存すると、キーが侵害された場合にセキュリティ上のリスクが生じる可能性があるためです。Google Cloud のベスト プラクティスでは、不正使用を防ぐために古い鍵を取り消すことをおすすめしています。
参考：
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/service-accounts
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題9: 未回答
教育機関向けに新しい Google Cloud 組織を設定するのは、お客様の責任です。
特権管理者アカウントを設定する際に実行する必要がある 2 つの手順はどれですか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、新しい Google Cloud 組織で特権管理者アカウントを保護する方法と、ベスト プラクティスに関する理解度を評価します。焦点は、高度なセキュリティ対策の利用と、管理操作に対する最小特権の原則です。
重要な用語:
多要素認証(MFA):MFAは、単なるパスワードだけでなく、セキュリティのレイヤーを追加します。ユーザーは、リソースにアクセスするために 2 つ以上の検証要素を提供する必要があります。
ハードウェアセキュリティキー: サービスまたはデバイスへのアクセスを許可する前にユーザーのIDを確認することで、安全な2要素認証を提供する物理デバイス。
最小特権の原則:公務の遂行に必要なアクセス権または許可のみがユーザーに付与されるセキュリティの概念。
正解解説:
(オプション)
・スーパー管理者の認証情報を、ハードウェアセキュリティキーを使用した多要素認証(MFA)で保護します。
・特権の少ないユーザーアカウントをスーパー管理者の個人に割り当てて、日常業務を任せる。
ハードウェアセキュリティキーを使用して多要素認証(MFA)で特権管理者の認証情報を保護すると、不正アクセスの試みに対する堅牢な保護が提供されます。ハードウェア セキュリティ キーは、フィッシング攻撃に対する回復力のあるセキュリティの物理レイヤーを提供します。さらに、日常的な操作に権限の少ないユーザーアカウントを割り当てることで、特権管理者は必要な場合にのみ、責任を持って強力なアカウントを使用できます。このように最小特権の原則に従うことで、システム構成や機密データに対する偶発的または意図的な損傷のリスクが最小限に抑えられます。
不正解の説明:
オプション: Google 管理コンソールでアクセス境界を実装して、特権管理者による Google Cloud サービスへのアクセスを制限します。
Google 管理コンソールでのアクセス境界の実装が正しくないのは、アクセス境界は、サービス自体へのアクセスを制限するためではなく、管理者が Google Cloud サービス内で実行できる操作を制限するために使用されるためです。
オプション: Google Cloud Platform Console で、組織レベルで特権管理者に割り当てられている Identity and Access Management(IAM)ロールをすべて削除します。
通常、スーパー管理者は責任を果たすために幅広いアクセスを必要とするため、組織レベルでスーパー管理者からIAMロールを削除することは逆効果です。代わりに、役割は正確に、実行する必要のあるジョブに従って管理する必要があります。
オプション: セキュリティで保護されたネットワーク上でスーパー管理者アカウントを確立し、パブリック インターネット経由での資格情報の送信を回避します。
セキュリティで保護されたネットワーク上で特権管理者アカウントを確立することは、良い習慣のように思えるかもしれませんが、フィッシングやその他のエクスプロイトから認証情報を保護する必要性に取って代わるものではありません。ハードウェア セキュリティ キーを使用した MFA は、特権管理者の認証情報を保護するためのより直接的かつ効果的な方法です。
参考：
https://cloud.google.com/iam/docs/using-mfa
https://cloud.google.com/resource-manager/docs/creating-managing-organization
https://cloud.google.com/iam/docs/creating-managing-service-accounts
</div></details>

### Q.  問題10: 未回答
医療分野では、時間的制約のあるサービスを運用しており、さまざまな診療所から Cloud Storage に転送された機密の患者記録の処理と評価を Compute Engine VM で行っています。
ただし、セキュリティ チームは、現在の設定が保護医療情報 (PHI) に義務付けられている厳格なプライバシー基準に準拠していないというフラグを立てました。コンプライアンスを確保するには、次のことを行う必要があります。
- データ暗号化鍵(DEK)を Google Cloud 境界の外部で管理します。
- 独立したベンダーによる暗号化キーの完全なガバナンスを実施します。
- 機密の患者記録を暗号化してから Cloud Storage に送信する。
- Compute Engine VM での処理中に PHI を復号します。
- PHI をランダム アクセス メモリ(RAM)で暗号化し、Compute Engine VM で処理する。
これらのセキュリティ要件を遵守するには、どのようなアクションを実行する必要がありますか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、医療分野の組織が厳格なプライバシー基準に準拠してPHIのデータセキュリティ対策を強化する必要があるシナリオを示しています。暗号化キーを外部で管理し、処理中にPHIを暗号化しておくことに重点が置かれています。
重要な用語:
External Key Manager: Google Cloud の境界外で暗号鍵を管理できる機能で、サードパーティの鍵管理サービスによって管理される鍵をデータ暗号化に容易に使用できます。
コンフィデンシャル VM: 使用中のデータを暗号化する高度な Compute Engine サービスであるため、機密情報はメモリ内で処理されている間も暗号化されたままです。
正解解説:
(オプション)
・Cloud External Key Managerを実装して、患者記録をCloud Storageに転送する前に暗号化して保護し、VMに取得した後に復号できるようにします。
・患者記録の安全な処理のためのコンフィデンシャルVMへの移行。
Cloud External Key Manager を使用すると、サードパーティ サービスを使用して DEK を制御でき、外部でキーを管理する要件と、独立したベンダーによるガバナンスの保持の両方が義務付けられます。このサービスは、送信前に PHI を暗号化するメカニズムを提供し、VM での暗号化解除を可能にします。コンフィデンシャル VM の実装により、処理中に PHI が RAM 内で暗号化されたままになり、機密データのセキュリティレベルが向上します。
不正解の説明:
オプション: 顧客管理の暗号鍵(CMEK)を設定して、患者記録を Cloud Storage に送信する前に暗号化し、VM にインポートされたら復号します。
この選択が間違っている理由は、顧客管理の暗号鍵(CMEK)が引き続き Google Cloud の境界内で動作するためです。これにより、顧客はキーを管理できますが、独立したベンダーによる外部ガバナンスの要件を完全には満たしていません。
オプション: PHI データを操作するために新しいコンフィデンシャル VM をプロビジョニングします。
この選択が正しくない理由は、コンフィデンシャル VM の使用は正しいアプローチですが、この選択だけでは DEK を外部で管理する要件に対応できないためです。独立系ベンダーによる暗号化キーのガバナンスは、セキュリティ対策に欠けている部分です。
オプション: 現在デプロイされている Compute Engine VM と関連する Cloud Storage バケットの周囲に VPC Service Controls の境界を確立します。
この選択が間違っている理由は、VPC Service Controls 境界の確立は、質問で述べたように PHI に義務付けられている特定の暗号化とキー ガバナンスの要件を満たすのではなく、リソースの分離とデータ流出の制御に重点を置いているためです。
参考：
https://cloud.google.com/security-key-management/external-key-manager
https://cloud.google.com/compute/confidential-vm/docs
https://cloud.google.com/storage/docs/encryption/customer-managed-keys
</div></details>

### Q.  問題11: 未回答
あなたは、外部 ID プロバイダ(IdP)のユーザーデータを金融サービス会社の Google Cloud Identity に統合する役割を担っています。一部のスタッフは、仕事用のメールアドレスを使用して、さまざまな Google サービスにアクセスするための個人用の Google アカウントを作成していることに気付きました。組織にとって、構成、セキュリティ、および管理の観点から、これらの個人アカウントの監視を維持することは非常に重要です。
どのような行動を取るべきですか?(2つ選択)
1. 
2. 
3. 
4. 
<details><div>
    答え：
Google Cloud Identity の管理も行いながら外部 IdP を使用している組織の場合、この質問は、仕事用メールで作成された個人アカウントを処理するという課題に対処します。これらのアカウントを企業の監督下に確実かつ効果的に組み込むための手順に関する知識を評価します。
重要な用語:
Identity Reconciliation: 組織のIDプロバイダー(IdP)のユーザー・レコードが、別のサービスまたはデータベースのレコードと一致することを確認するプロセス。不整合は、正確で最新のユーザーデータを維持するために解決されます。
アカウント移行ツール: 管理者がユーザーの個人アカウントを管理対象の Google Workspace ドメインに移動し、これらのアカウントを組織が管理できるようにするために Google が提供する機能です。
正解解説:
(オプション)
・外部 IdP に対応するレコードがない Cloud Identity の ID を照合します。
・口座振替ツールを活用し、社員の個人口座を自社ドメイン管理下に移動するよう促す。
ID の調整には、Cloud Identity と外部 IdP 間のユーザー レコードの照合と検証、不一致の解決、正確で安全なユーザー管理が含まれます。アカウント転送ツールを利用することで、組織は従業員に個人アカウントを会社のドメイン管理に移行するように促すことができ、セキュリティとポリシーの構成を一元的に監視し、それらのアカウントに適用することができます。
不正解の説明:
オプション: 個人のコンシューマー アカウントを持つ従業員に、それらのアカウントを終了するように指示します。
従業員に個人アカウントの解約を指示することは、現実的でも強制力もありません。これは、管理およびセキュリティ上の目的でこれらのアカウントを企業の監視下に置くことの問題を解決するものではありません。
オプション:ID 同期を開始する前に、外部 IdP システムからコンシューマ アカウントを削除します。
外部 IdP からコンシューマ アカウントを削除するだけでは、Google Cloud Identity 内で管理する必要性に対処できず、個人向けサービスで企業ドメインが不正に使用され続ける可能性を認識できません。
オプション: Google Cloud Directory Sync(GCDS)を適用して、個人の消費者アカウントのメールアドレスを企業構造内のエイリアス アカウントに変換します。
Google Cloud Directory Sync(GCDS)を適用して一般ユーザー向けアカウントのメールアドレスをエイリアス アカウントに変換しても、個々のアカウントが会社のドメイン管理下に置かれることはなく、アカウントの設定やセキュリティ設定に必要な制御も行えません。
参考：
https://cloud.google.com/identity/docs/account-transfer/intro
https://cloud.google.com/identity/docs/how-to/manage-users
https://support.google.com/a/answer/6335621
</div></details>

### Q.  問題12: 未回答
ある医療機関は、さまざまな Google Cloud リージョンに複数の冗長な医療データ処理サーバーを設定しており、ユーザーの地理的な場所に基づいて最も近い処理サーバーにユーザーを誘導する必要があります。
医療従事者はどのようにしてこれを達成できるのでしょうか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の負荷分散サービスに関する理解と、データセンターへのユーザーの地理的な距離に基づいてトラフィック分散を最適化するための構成方法を評価します。
重要な用語:
TCP Proxy Load Balancing: OSI モデルのトランスポート層で動作するロードバランサーの一種。これにより、着信 TCP 接続プロパティに基づいて非 HTTP トラフィックをルーティングできます。
グローバル負荷分散:世界中の複数のデータセンターにユーザーリクエストを分散する方法。これにより、ユーザーを最も近いデータセンターまたは最もパフォーマンスの高いデータセンターにルーティングすることで、低遅延と高可用性が確保されます。
ポート995:通常、安全なPost Office Protocol 3(POP3S)で使用されるこのTCPポートは、SSL/TLS接続を介してリモートサーバーから電子メールを取得するための暗号化通信に利用されます。
地理的位置ルーティング: 受信ネットワーク要求を最も近い地理的サーバーエンドポイントに転送し、待機時間を短縮し、ユーザーエクスペリエンスを向上させる負荷分散の機能。
正解解説:
(オプション)
・TCPプロキシ負荷分散を、ポート995でリッスンするグローバル負荷分散サービスとして構成します。
TCP プロキシ負荷分散は、トランスポート層で動作するグローバルな負荷分散ソリューションを提供するため、この選択は適切です。ポート 995 でリッスンするように構成することで、医療提供者は、暗号化されたトラフィックがユーザーの場所に基づいて最も近いサーバーにインテリジェントに分散されるようにすることができます。これにより、データ処理のレイテンシーが短縮され、医療情報の安全な転送が保証され、医療におけるデータ保護に関する規制要件に適合します。
不正解の説明:
オプション: 地理的な場所に基づいてトラフィックを迂回させるように設計された一連の転送ルールを使用して、TCPポート995でリッスンするネットワークロードバランサを確立します。
この選択が正しくない理由は、標準の Network Load Balancer がグローバルレベルではなくリージョナルレベルで動作するためです。受信 TCP/UDP トラフィックはリージョンのバックエンド サービス間でルーティングされますが、クライアントの地理的な場所に基づいてグローバルなトラフィックを分散する機能はありません。
オプション: HTTP(S) ロードバランサーで構成されたマルチリージョン負荷分散を利用して、トラフィックを最も近いリージョンに転送します。
この選択が正しくない理由は、HTTP(S) ロード バランシングが一般的な TCP トラフィックではなく、HTTP および HTTPS トラフィック用に設計されているためです。マルチリージョンの負荷分散は提供されますが、ポート 995 でルーティングされる非 HTTP トラフィックを適切に処理することはできません。
オプション: Cloud CDN を実装して、クライアントの IP アドレスに従って、医療データ処理トラフィックを最も近い発信元サーバーに分散します。
この選択が間違っている理由は、Cloud CDN(コンテンツ配信ネットワーク)が主にエッジ ロケーションでの HTTP コンテンツと HTTPS コンテンツのキャッシュを目的としているためです。コンテンツの配信速度は向上しますが、地理的な場所に基づいてトラフィックを処理サーバーに転送するようには設計されていません。
参考：
https://cloud.google.com/load-balancing/docs/tcp
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
</div></details>

### Q.  問題13: 未回答
従業員を Google Cloud Identity に統合しているときに、会社のメール サフィックスを使用して個人の Google アカウントを作成している人がいることに気付きました。
これらの個人の Google アカウントを Cloud Identity 内でどのように処理しますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、従業員が仕事用のメールアドレスで個人の Google アカウントを持っている場合のシナリオと、ユーザーのデータやアクセスを中断することなく、これらのアカウントを Cloud Identity に効果的に統合する方法を探ります。
重要な用語:
管理対象外のアカウント: 組織の管理外のユーザーによって作成され、多くの場合、会社のメールアドレスを使用して作成され、Google サービス内で独立して存在するアカウント。
データ移行ツール: 管理対象外の Google アカウントまたは「一般ユーザー向け」の Google アカウントから管理対象の Google Workspace アカウントにユーザーデータを移行できる Google サービスの機能です。
正解解説:
(オプション)
・管理対象外アカウント用のデータ移行ツールを活用する。
この選択は、データ移行ツールを使用して、従業員が会社の電子メールで個人アカウントを作成したアカウントの競合の問題に対処するため、正しいです。このツールは、これらの「管理されていないアカウント」を組織のドメインの下にある「管理対象アカウント」に移行するのに役立ち、企業がアカウントとそのデータを管理制御できるようにし、会社のドメインに関連付けられているデジタル資産を統合します。
不正解の説明:
オプション: Google Cloud Directory Sync を使用して、管理対象外のアカウントを管理対象アカウントに移行します。
この選択が間違っている理由は、管理対象外のアカウントの移行を処理するのではなく、Google Cloud Directory Sync(GCDS)を使用してユーザーデータを LDAP ディレクトリまたは Microsoft Active Directory から Cloud Identity に同期するためです。
オプション: 各個人コンシューマー アカウントと並行して、個別の企業アカウントを生成します。
この選択が間違っている理由は、個人のコンシューマー アカウントごとに個別の企業アカウントを作成しても、アカウントの競合の問題が解決されず、アカウント管理とユーザー エクスペリエンスがさらに複雑になるためです。
オプション: 顧客が使用するサード パーティの ID プロバイダーを使用したシングル サインオンを実装します。
この選択が間違っている理由は、サードパーティの ID プロバイダーでシングル サインオン (SSO) を実装しても、会社の電子メールを使用する既存の個人コンシューマー アカウントの問題に対処できないためです。SSO統合は、アカウント管理やデータ移行ではなく、認証プロセスを合理化するためのものです。
参考：
https://cloud.google.com/identity/docs/manage-unmanaged-users
https://cloud.google.com/identity/docs/how-to/setup#migrate-unmanaged
Hatps://support.google.com/a/answer/10026322?hl=n
</div></details>

### Q.  問題14: 未回答
Compute Engine、Google Kubernetes Engine、Cloud Storage、BigQuery、Pub/Sub などのサービスにまたがる重要な患者データを含む、医療データ処理システムの HIPAA 要件に沿ってセキュリティ対策を強化しています。セキュリティ アーキテクチャのブレーンストーミング セッション中に、作業中のシステムの暗号化キーを制御する必要性を認識します。
このシナリオに最も適したアプローチはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、医療保険の相互運用性と説明責任に関する法律(HIPAA)標準に準拠した Google Cloud 内の暗号鍵管理オプションに関する知識を評価します。焦点は、機密性の高い医療データに対して最高レベルのユーザー制御とセキュリティを提供する暗号化キー管理サービスを選択することです。
重要な用語:
HIPAA: 医療保険の相互運用性と説明責任に関する法律は、機密性の高い患者データを保護するための基準を定めています。PHIを扱う企業は、必要なすべての物理的、ネットワーク、およびプロセスセキュリティ対策が実施され、遵守されていることを確認する必要があります。
Cloud External Key Manager: 外部のサードパーティの鍵管理システムを使用して、外部鍵を使用して Google Cloud サービス内のデータを保護できる Google Cloud サービス。
顧客管理の暗号鍵: Google の Cloud Key Management Service 内でお客様が作成、管理する暗号鍵で、制御と利便性のバランスが取れています。
お客様提供の暗号鍵: お客様が Google Cloud サービスの外部で暗号鍵を生成して管理し、Google Cloud で使用するために提供する鍵管理オプションです。
Google が管理する暗号鍵: Google Cloud Platform によって自動的に生成、管理される暗号鍵で、鍵管理に必要なお客様の労力は最小限です。
正解解説:
(オプション)
・Cloud External Key Manager(クラウド外部キーマネージャー)
この選択は、サードパーティの鍵管理サービスを使用して Google Cloud の外部で暗号鍵を維持できるため、HIPAA などの厳格な規制コンプライアンスを必要とするシナリオに最適です。Cloud External Key Manager(EKM)を使用すると、保存データと暗号鍵を分離できるため、Google Cloud のネイティブ サービスを使用しながら、追加のセキュリティ レイヤと鍵の制御が可能になります。医療システムは、高度なセキュリティを活用し、独自のセキュリティ境界または信頼できる外部キー管理システム内に暗号化キーを保持することで、コンプライアンスを満たすことができます。
不正解の説明:
オプション: 顧客管理の暗号化キー
この選択が間違っている理由は、顧客管理の暗号鍵が引き続き Google Cloud Platform のインフラストラクチャ内に保存されているためです。これらのキーはお客様が管理しますが、HIPAA の厳しい規制や外部監査に準拠するために必要なキー管理環境を完全に制御することはできません。
オプション:お客様提供の暗号化キー
この選択が正しくない理由は、お客様が指定した暗号化キーは、お客様から提供されたものですが、クラウド環境内で引き続き使用および管理されるためです。これでは、鍵管理プロセスがクラウドプロバイダーから完全に分離されるわけではなく、規制コンプライアンスが要求される環境には適さなくなる可能性があります。
オプション: Google が管理する暗号化
この選択が間違っている理由は、Google が管理する暗号鍵は Google によって完全に作成、管理、ローテーションされるため、お客様に提供される制御が最も少ないためです。このアプローチは、通常、顧客が暗号化キーを厳密に制御する必要があるHIPAAなどの規制要件が厳しいアプリケーションには適していません。
参考：
https://cloud.google.com/security-key-management
https://cloud.google.com/kms/docs/ekm
https://cloud.google.com/compute/docs/disks/customer-managed-encryption
</div></details>

### Q.  問題15: 未回答
あなたの会社は、医療保険の相互運用性と説明責任に関する法律 (HIPAA) への準拠を確実にすることに熱心です。SRE が米国リージョン内でのみ Google Cloud リソースを作成できるポリシーを適用する場合。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 内でのリソースの場所に関するポリシーの適用、特に HIPAA などの地域規制への準拠に関する理解度を評価します。SREがリソースを作成できる場所を管理および制限するための組織的制約の適用に焦点を当てています。
重要な用語:
constraints/gcp.resourceLocations: GCP リソース階層(組織、フォルダ、プロジェクト)のどこにリソースを作成できるかを定義できる階層的なリソースの場所の制約で、地域法に準拠するために重要です。
組織ポリシー: Google Cloud 内のポリシー フレームワークで、組織のリソース階層全体で制限を構成し、全社的な規制とコンプライアンス基準を適用するのに役立ちます。
正解解説:
(オプション)
・Google Cloud 組織ノードで組織ポリシー制約「constraints/gcp.resourceLocations」を使用します。
「constraints/gcp.resourceLocations」制約は、Google Cloud でリソースをデプロイできる地理的な場所を制御することを特に目的としているため、この選択は適切です。組織ノード レベルで適用すると、許可されたリージョンにのみリソースが作成されるようにするポリシーを作成できるため、データの保存場所と処理場所に関する厳格な要件を持つ HIPAA コンプライアンスを維持できます。
不正解の説明:
オプション: Access Context Manager で Identity-Aware Proxy(IAP)を構成して、Google Cloud リソースの作成を米国リージョンに制限します。
このオプションが正しくない理由は、Access Context Manager を使用した Identity-Aware Proxy(IAP)は、Google Cloud リソースを作成できる場所を制限するためではなく、アプリケーションや VM へのアクセスを管理するために使用されるためです。IAPは、ユーザーとグループのアクセス制御に重点を置いています。
オプション: 組織ポリシーの制約「constraints/compute.restrictXpnProjectLienRemoval」を Google Cloud 組織ノードに適用します。
このオプションが正しくない理由は、「constraints/compute.restrictXpnProjectLienRemoval」が、リソースの場所を制限するためではなく、プロジェクトの削除を妨げる先取特権の削除を制御するための組織ポリシーであるためです。これは、地理的な展開の制約とは無関係です。
オプション: Identity and Access Management (IAM) の条件付きロールを実装して、SRE チームが米国リージョン内でのみリソースをプロビジョニングできるようにします。
このオプションが正しくない理由は、IAM 条件付きロールは、条件に基づいてアクセス許可を定義および適用するために使用されますが、リソースをプロビジョニングできる場所に関する地理的な制限を直接適用しないためです。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/resource-manager/docs/creating-managing-policy
https://cloud.google.com/compliance/geographic-specificities
</div></details>

### Q.  問題16: 未回答
プロジェクト内の Bigtable インスタンスを参照する機能を必要とする新しいサービス アカウントを作成する必要があります。
このシナリオで Google Cloud が推奨するベスト プラクティスは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、最小権限とロールのカスタマイズの原則に関して、Google Cloud リソースへのアクセス管理に関する理解度を評価します。Bigtable インスタンスを一覧表示できるサービス アカウントを作成する必要があるため、IAM のロールと権限に関する知識が必要です。
重要な用語:
カスタムロール: Google の事前定義されたロールでは完全には満たせないロールの特定のニーズに合わせて調整されたユーザー定義の権限セット。これにより、最小特権の原則に従うことができます。
サービス アカウント: アプリケーション、仮想マシン、その他のサービスがプログラムで GCP サービスとやり取りするために使用する特殊なタイプのアカウントで、IAM ロールを使用して特定の権限を付与できます。
bigtable.instances.list: プロジェクト内の Bigtable インスタンスのリストを表示する機能を付与する特定の IAM 権限。これにより、インスタンスの詳細を表示したり、管理タスクを実行したりするためのアクセス許可は付与されません。
正解解説:
(オプション)
・bigtable.instances.list権限でカスタムロールを作成し、サービスアカウントに割り当てます。
この選択は、ジョブの実行に必要なアクセス許可のみを付与することを提案する最小特権の原則に最も合致しています。「bigtable.instances.list」権限を持つカスタムロールを作成することで、サービス アカウントは、不要なアクセス権なしで Bigtable インスタンスの参照に正確に制限されます。また、この選択により、事前定義されたロールに付随するより広範なアクセス許可の付与が回避されるため、不正アクセスの潜在的なベクトルが制限され、セキュリティが強化されます。
不正解の説明:
オプション: 通常ディスクのスナップショットを生成し、サービス アカウントに Bigtable アクセス スコープの読み取り専用アクセス権を付与します。
この選択が間違っている理由は、永続ディスクのスナップショットが IAM 権限の付与とは無関係であり、サービス アカウントの Bigtable へのアクセスに影響を与えないためです。Bigtable アクセス スコープの読み取り専用アクセスでは、インスタンスを一覧表示するために必要な権限は提供されません。
オプション: サービス アカウントに Bigtable Viewer のロールを割り当て、すべてのインスタンスで使用します。
この選択が間違っている理由は、Bigtable Viewer のロールを割り当てると、インスタンスを一覧表示するだけのために必要な以上のアクセスが可能になるためです。すべてのインスタンスでデータを表示するアクセス許可が付与され、最小特権の原則に違反します。
オプション: サービスアカウントにプロジェクトブラウザの役割を割り当て、すべてのインスタンスに適用します。
この選択が間違っている理由は、プロジェクトブラウザの役割が広すぎるため、サービスアカウントがすべてのプロジェクトリソースを参照できるためです。アカウントを Bigtable インスタンスの一覧表示のみに制限することはできず、最小権限の原則に違反します。
参考：
https://cloud.google.com/iam/docs/creating-custom-roles
https://cloud.google.com/compute/docs/instances/managing-instance-access#configure_service_accounts
https://cloud.google.com/iam/docs/understanding-roles#compute-engine-roles
</div></details>

### Q.  問題17: 未回答
会社では、Compute Engine インスタンスで e コマース プラットフォームを運用しており、このプラットフォームをロジスティクス パートナーのシステムと統合し、別の Google Cloud 組織の Compute Engine でホストしています。Compute Engine 環境間の安全な通信チャネルを設定する必要があります。要件は次のとおりです。 - トラフィックは暗号化する必要があります。- 接続では、通信にプライベート IP 空間を使用する必要があります。
どうすればこれを実現できますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、異なる Google Cloud 組織間で Compute Engine インスタンス間に安全でプライベートな通信チャネルを確立する能力をテストします。焦点は、トラフィックを暗号化し、組織間の接続にプライベートIP空間を利用するために利用できるメカニズムを理解することです。
重要な用語:
Cloud VPN: 安全なトンネルを使用して転送中のデータを保護し、プライベート IP を使用した通信を可能にすることで、異なる Google Cloud プロジェクト間または外部ネットワークとのネットワークの接続を容易にします。
VPC: グローバルにスケーラブルで柔軟性の高い仮想ネットワークで、お客様は Google Cloud インフラストラクチャ内に分離された環境を確立できます。
VPC ファイアウォールルール: VPC 内のインスタンスとの間で許可または拒否されるトラフィックを定義し、IP アドレス、プロトコル、ポートに従ってインバウンドとアウトバウンドのデータフローを制御します。
正解解説:
(オプション)
・自社のVPCネットワークと物流パートナーのVPCの間にCloud VPN接続を確立し、VPCファイアウォールルールで管理されるようにします。
Cloud VPN は 2 つの VPC ネットワーク間に暗号化されたトンネルを構築し、プライベート IP アドレスを使用してデータを安全に交換できるため、この選択は適切であり、両方の要件を満たします。また、各組織の VPC 内にカスタムルートとファイアウォール ルールを作成して、Compute Engine インスタンス間のデータ トラフィックを管理および保護することもできます。
不正解の説明:
オプション: 会社の VPC ネットワークとロジスティクス パートナーの VPC の間に VPC ピアリング接続を設定し、データフローは VPC ファイアウォール ルールによって規制されます。
この選択が間違っている理由は、VPC ピアリングでは 2 つの VPC ネットワーク間の直接ネットワーク接続が可能ですが、本質的にトラフィックの暗号化は提供されないためです。VPC ピアリングの対象となるリージョン内でのトラフィック交換のみが許可されます。
オプション: Compute Engine インフラストラクチャの周囲に VPC Service Controls を導入し、ロジスティクス パートナーが定義されたアクセスレベルで接続できるようにします。
この選択が間違っている理由は、VPC Service Controls が、データ流出を防ぐためにサービスに境界セキュリティを提供するように設計されているためです。組織間のプライベートトラフィックのための安全な通信チャネルの確立は容易ではありません。
オプション: Apigee プロキシをデプロイして、Compute Engine でホストされる e コマース アプリケーションを API として利用できるようにすることで、TLS 暗号化を利用し、アクセスをロジスティクス パートナーのみに制限します。
この選択が間違っている理由は、Apigee が API 管理プラットフォームであり、Compute Engine インスタンス間の安全な通信チャネルを作成することを目的としていないためです。APIアクセスにTLSを利用すると、暗号化は保証されますが、マシン間通信にプライベートIP空間を利用するユースケースには適合しません。
参考：
https://cloud.google.com/vpn/docs/concepts/overview
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#secure_communications_between_vpcs
https://cloud.google.com/vpc/docs/vpc-peering
</div></details>

### Q.  問題18: 未回答
App Engine アプリケーションにアクセスするために、Identity and Access Management(IAM)ユーザーに付与する必要がある Identity-Aware Proxy ロールはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ユーザーが App Engine アプリケーションにアクセスするために必要な Identity-Aware Proxy(IAP)の正しいロールの理解度を評価します。ここでは、適切な IAP ロールと、IAP を介した App Engine へのアクセスに関連しない他のロールを区別することに重点が置かれています。
重要な用語:
Identity-Aware Proxy: IAP は、GCP で実行されているアプリケーションへのアクセスを制御し、ID 検証とコンテキスト(ユーザーの役割など)に基づいて安全な境界を確立する Google Cloud サービスです。
IAP で保護されたウェブアプリ ユーザー: この IAM ロールは、IAP で保護されているウェブ アプリケーション(App Engine アプリケーションを含む)にアクセスする権限をユーザーに付与します。
IAM ユーザー: Google の Identity and Access Management システムにアカウントを持ち、GCP エコシステム内でさまざまな権限とロールを付与できるユーザー。
正解解説:
(オプション)
・IAPで保護されたWebアプリユーザー
「IAP で保護されたウェブアプリ ユーザー」ロールは、Google Cloud の Identity-Aware Proxy で保護されているウェブベースのアプリケーションにアクセスする必要があるユーザーを特に対象としているため、この選択は適切です。このロールを IAM ユーザーに付与すると、IAP を経由して App Engine アプリケーションにアクセスできるようになり、認証および許可されたユーザーのみがアプリケーションにアクセスできるようになります。
不正解の説明:
オプション: ソースリポジトリレビューア
この選択が間違っている理由は、「ソース リポジトリ レビュアー」が Google Cloud のソースコード リポジトリに関連する役割であり、App Engine でホストされているような IAP で保護されたアプリケーションへのアクセスには関係がないためです。
オプション: IAPで保護されたSSHトンネルユーザー
この選択が間違っている理由は、「IAP で保護された SSH トンネル ユーザー」ロールは、IAP を介して仮想マシン インスタンスへの安全な SSH アクセスを必要とするユーザー専用であり、App Engine アプリケーションにアクセスする権限を付与しないためです。
オプション:API Gateway エディタ
この選択が間違っている理由は、「API Gateway エディタ」が Google Cloud での API Gateway の管理に関連付けられたロールであり、ユーザーはゲートウェイと関連リソースを作成、更新、削除できますが、IAP で保護されているアプリケーションへのアクセスは許可されないためです。
参考：
https://cloud.google.com/iap/docs/managing-access#member
https://cloud.google.com/iap/docs/using-tcp-forwarding
Hatps://vv.youtube.com/watch?v=7d81sfat04
</div></details>

### Q.  問題19: 未回答
ある顧客のマーケティング分析部門は、広告パフォーマンス分析タスクに Google Cloud を活用することを検討しています。同社のガイドラインでは、すべてのデータセットを自社の管理下に置き、すべての認証プロセスを独自のSecurity Assertion Markup Language(SAML)2.0 IDプロバイダー(IdP)と整合させる必要があると述べています。IT セキュリティ アーキテクトは、お客様の Cloud Identity を設定しているときに、お客様の優先ドメインがすでに Google Workspace アカウントに関連付けられていることに気付きました。
中断を最小限に抑えるために、ITセキュリティアーキテクトが取るべき最も適切な行動方針は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、会社の優先ドメインが別の Google Workspace アカウントですでに使用されている場合の手順を調べます。企業の既存のセキュリティ プロトコルを Cloud Identity と統合することで、Google Cloud サービス内のドメインの競合を解決するための知識をテストします。
重要な用語:
特権管理者: Google Workspace アカウント内で最も強力な役割で、すべての設定と機能に完全にアクセスでき、他のユーザーに役割を割り当てることができます。
SAML 2.0 ID プロバイダー (IdP): 企業がユーザー認証に、サードパーティによって管理される資格情報ではなく、独自の資格情報を使用してシングルサインオンを可能にするシステム。
Cloud Identity: ID およびアクセス管理(IAM)を提供する Google Cloud サービスで、組織がユーザーを管理し、多要素認証とセキュリティ ポリシーを適用できるようにします。
ドメインチャレンジ プロセス: 別の Google サービスに登録されているドメインの所有権を証明するために Google Cloud サポートで開始される手順。
正解解説:
(オプション)
・会社の経営陣と連携して、Google のマネージド サービスに関するその他のエンゲージメントを明らかにし、そのドメインの現在の特権管理者とコラボレーションする。
この選択は、対立よりもコミュニケーションとコラボレーションを重視するため、最も適切なアクションです。ドメインが既存の Google Workspace アカウントにすでに関連付けられている場合は、会社の経営陣と協力して、すでに Google サービスを使用している組織部門があるかどうかを確認することが不可欠です。また、ITセキュリティアーキテクトは、既存のスーパー管理者と協力して、データの中断や競合を引き起こすことなく、データ管理とSAMLベースの認証に関する会社のポリシーとの整合性を維持しながら、ドメインを今後どのように管理できるかについて話し合う必要があります。
不正解の説明:
オプション: Google Cloud サポートに連絡してドメイン チャレンジ プロセスを開始し、新しい Cloud Identity アカウントのドメイン名を申請します。
この選択が間違っている理由は、ドメイン異議申し立てプロセスを開始すると、時間がかかり、対立的な行動になる可能性があり、混乱を引き起こす可能性があり、組織内での Google サービスの既存の使用が考慮されていないためです。
オプション: 新しい Cloud Identity アカウントの確立に使用するセカンダリ ドメイン名を取得します。
この選択が間違っている理由は、セカンダリドメインを調達すると、データを管理下に置くという会社のガイドラインに違反する可能性があり、認証用に確立されたSAML 2.0 IdPと一致しない可能性があり、混乱やユーザーエクスペリエンスのばらつきにつながる可能性があるためです。
オプション: マーケティング分析リードを、すでに使用されているドメインの特権管理者として設定するよう Google にリクエストします。
この選択が間違っている理由は、正当な手続きなしにユーザーを特権管理者として設定するよう Google にリクエストすると、セキュリティ上の問題が発生する可能性があるためです。さらに、管理者の役割は、社内の決定を反映し、会社のガバナンス構造内の適切な承認プロトコルに従う必要があります。
参考：
https://cloud.google.com/iam/docs/using-saml-to-enable-federated-sso
https://cloud.google.com/identity/docs/how-to/setup#authenticating_users_with_federated_sso
https://cloud.google.com/docs/enterprise/best-practices-for-enterprise-organizations#identity
</div></details>

### Q.  問題20: 未回答
貴社は、Google Cloud における医療保険の相互運用性と説明責任に関する法律(HIPAA)の遵守に全力で取り組んでいます。HIPAA要件に沿ったデータガバナンスを実施し、米国リージョン内の運用管理を確保する必要があります。
どうすればこれを実現できますか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の米国リージョンにおけるデータ ガバナンスと運用管理による HIPAA コンプライアンスの適用に関する理解度を評価します。そのためには、業務を規制上の制約に合わせ、データアクセスを制御する方法を選択する必要があります。
重要な用語:
組織ポリシー・サービス: 組織のクラウド・リソースにリソース・ポリシーを定義して適用し、規制基準への準拠を維持するのに役立つサービス。
主なアクセスの正当性: Google の担当者によるデータアクセスの詳細な理由を提供する機能で、お客様がそのようなアクセスを許可または拒否できるようにすることで、データの透明性と管理を強化します。
リソースの場所の制約: リソースを作成できる場所を制限し、組織が規制およびコンプライアンスの要件を満たすのに役立つ組織ポリシー サービス内のポリシー設定。
正解解説:
(オプション)
・組織ポリシーサービスの「リソースの場所の制約」を活用して、新しい資産の地理的境界を確立します。
・Key Access Justificationsを活用して、国籍や所在地などの特定の基準に基づいてGoogleスタッフのアクセスを制限します。
"リソースの場所の制約" を定義して組織ポリシー サービスで地理的制限を実装すると、HIPAA コンプライアンスに不可欠な、指定された範囲内ですべての新しい資産が確立されます。同様に、Key Access Justifications を利用すると、HIPAA の「必要最低限のルール」に合わせて、Google のスタッフに基準に基づく制限を適用することで、機密データにアクセスできるユーザーをきめ細かく制御できます。
不正解の説明:
オプション: Cloud IDS を導入して、米国内の横方向および縦方向のトラフィックを監視し、仮想プライベート クラウド間の内部通信を監視します。
この選択が間違っている理由は、Cloud IDS がネットワーク トラフィック内の侵入検知に重点を置き、HIPAA コンプライアンスに必要なデータ ガバナンスや運用管理に重点を置いていないためです。
オプション: ID フェデレーション手法を適用して、米国外に拠点を置くユーザー アカウントの Google Cloud アセットへのアクセスを制限します。
IDフェデレーションはアクセスを制御するための方法ですが、この質問では特に、HIPAAに沿ったデータガバナンスを実施するメカニズムを求めています。場所別のフェデレーション手法では、Google Cloud 内で HIPAA に準拠したガバナンスや制御は提供されません。
オプション: VPC フローログを利用して、仮想プライベートクラウド内および米国領土内の仮想プライベートクラウド間のトラフィックを追跡します。
VPC フローログは、ネットワークフローのモニタリングとデバッグに役立ちますが、HIPAA で要求されるデータガバナンスや運用管理の確立に直接貢献したり、データアクセス制限を適用したりすることはありません。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-resource-locations
https://cloud.google.com/kms/docs/key-access-justifications
https://cloud.google.com/compliance/gdpr
</div></details>

### Q.  問題21: 未回答
あるデジタル マーケティング会社は、すべてのクライアント キャンペーンを Google Cloud の App Engine に移行しました。一部のキャンペーンは開発中であり、さまざまな場所からクライアントと会社のスタッフにのみ表示される必要があります。
これらの開発段階のキャンペーンへのアクセスを制限するには、どのような方法を採用できますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、開発フェーズで Google Cloud の App Engine でホストされているウェブ アプリケーションのアクセス制限を構成する機能について検討します。焦点は、アプリケーションを一般に公開することなく、クライアントとスタッフに選択的に可視性を与えることです。
重要な用語:
Cloud Identity-Aware Proxy(IAP): ユーザーの ID を検証し、事前定義されたポリシーに基づいてアクセスを許可するかどうかを決定することで、Google Cloud 上で動作するウェブ アプリケーションへのアクセスを制御する統合サービスです。
Google グループ: 1 つのエンティティとして管理できるユーザー アカウントの集合体で、Cloud IAP などの共有リソースの管理を簡素化するために使用できるため、ユーザーグループに対する権限の管理が個別ではなく容易になります。
正解解説:
(オプション)
・Cloud Identity-Aware Proxy(IAP)を有効にし、クライアントとスタッフのユーザーアカウントを含むGoogleグループへのアクセスを許可します。
この選択肢は、App Engine でホストされているアプリケーションへのアクセスを制限するための最も安全で管理しやすいソリューションです。Cloud Identity-Aware Proxy(IAP)を有効にすることで、組織は定義された認証情報セットに対してユーザーを認証し、権限によってアクセスを制御できます。ユーザーを Google グループに関連付けると、権限の管理が容易になり、グループのメンバーは安全な方法でアプリケーションにアクセスでき、グループ外からのアクセスは制限されます。
不正解の説明:
オプション: クライアントとスタッフのユーザー アカウントを使用して .htaccess ファイルを構成し、App Engine にデプロイします。
この選択が間違っている理由は、App Engine が Apache ウェブサーバーで使用される設定メカニズムである .htaccess ファイルをネイティブにサポートしていないためです。ただし、App Engine は、アクセス制御のためにこれらのファイルを組み込まない別の環境を使用します。
オプション: クライアントとスタッフの IP 範囲からのアクセスのみを許可し、他のすべてのアクセスをブロックする App Engine ファイアウォール ルールを設定します。
この選択が間違っている理由は、App Engine のファイアウォール ルールはネットワークレベルのアクセス制御を提供しますが、特に異なる場所と異なる IP アドレスを使用している場合、クライアントとスタッフの動的なアクセスに対して制限が厳しすぎるためです。
オプション: クライアントとスタッフのオンプレミス ネットワークと、デジタル マーケティング会社の Google Cloud Virtual Private Cloud(VPC)ネットワークの間に Cloud VPN 接続を確立します。
この選択が間違っている理由は、Cloud VPN 接続を確立する方が、オンプレミス ネットワークと Google Cloud リソースの安全な統合に適しており、会社のネットワーク外の多数の個人ユーザーのアプリケーション アクセスを制御するための実用的なソリューションを提供していないためです。
参考：
https://cloud.google.com/iap/docs/app-engine-quickstart
https://cloud.google.com/appengine/docs/standard/python/config/appref
https://cloud.google.com/appengine/docs/standard/python/security-controls
</div></details>

### Q.  問題22: 未回答
会社でオンプレミスの LDAP ディレクトリ サービスを採用しており、Security Assertion Markup Language (SAML) ベースの認証を展開したいと考えています。従業員にシングルサインオン(SSO)を実装して適用する必要があります。
これを達成するために必要な手順は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、クラウド環境でのシングルサインオン(SSO)用のSAMLベースの認証システムとオンプレミスのLDAPディレクトリサービスの統合に関する候補者の知識を評価します。
重要な用語:
SAML統合:SAML準拠のIDプロバイダーからの認証を受け入れるようにサービスプロバイダーを構成し、SSOの信頼を確立するプロセス。
コールバックURL: 認証後にブラウザがリダイレクトされる場所であり、ユーザー資格情報を検証するためのSAMLフローで重要です。
X.509セキュリティ証明書:公開鍵証明書の形式を定義する標準で、署名と暗号化のためにSAMLセットアップで使用され、安全な資格情報交換を保証します。
アイデンティティ・プロバイダ・エンティティID: SAMLトランザクションにおけるアイデンティティ・プロバイダの一意の識別子で、サービス・プロバイダとの信頼関係を構成するために使用されます。
アサーション コンシューマ サービス (ACS) URL: サービス プロバイダーが ID プロバイダーから SAML アサーション (認証応答) を受信するエンドポイント。
正解解説:
(オプション)
・1.新しいSAML統合を作成します。
2. サインインとサインアウトのコールバック URL を入力します。
3. X.509 セキュリティ証明書をアップロードします。
4. ID プロバイダーで ID プロバイダー エンティティ ID とアサーション コンシューマ サービス (ACS) URL を構成します。
この選択は、ID プロバイダーとしてのオンプレミス LDAP ディレクトリと、SAML 統合によるサービス プロバイダー間の信頼関係の確立をカバーします。まず、新しいSAML統合を作成してプロセスを開始します。サインインとサインアウトのコールバック URL は、アクション後にユーザーが送信される場所を指示するために指定する必要があります。X.509 セキュリティ証明書のアップロードは、アサーションに安全に署名、要求、および検証するために必要です。ID プロバイダーは、エンティティ ID とサービス プロバイダーの ACS URL を使用して構成され、SAML 応答が正しく処理されるようにします。
不正解の説明:
オプション: 1. LDAP ディレクトリ サービス内で OpenID Connect (OIDC) の要件を確立します。
2. LDAPドメインを確認します。
3. SAML 認証を必要とする従業員を決定します。
4. 事前に確立された統合を、選択した組織単位 (OU) と関連チームに適用します。
この選択が間違っている理由は、SAML と OpenID Connect (OIDC) という 2 つの異なるシングル サインオン プロトコルを混同しているためです。指示は SAML ではなく OIDC のセットアップに傾いており、これは SAML ベースの認証の初期要件と一致しません。
オプション: 1. 新しいSAML統合を確立します。
2. X.509 セキュリティ証明書をアップロードします。
3. パスワードリセットURLを有効化します。
4. ID プロバイダーで ID プロバイダー エンティティ ID とアサーション コンシューマ サービス (ACS) URL を設定します。
この選択には、SSOのSAMLベースの認証の設定に本質的に関連付けられていないステップである「パスワードリセットURLをアクティブ化する」が誤って含まれています。SAML統合を確立し、エンティティIDとACS URLを構成することを正しく提案していますが、パスワードリセットプロセスに関する言及は、統合自体に関連しないため、誤解を招く可能性があります。
オプション: 1. SAML統合の割り当てを監督します。
2. LDAP ディレクトリサービス内で OpenID Connect (OIDC) をアクティブ化します。
3. ドメインの所有権を検証します。
1 番目と 3 番目のステップは SAML 統合に関連していますが、このオプションでは、SAML ベースの要件とは関係のない OpenID Connect (OIDC) のアクティブ化が導入され、認証プロトコルとその個別の実装が誤解されていることを示しています。
参考：
https://cloud.google.com/identity/saml
https://cloud.google.com/identity/docs/how-to/setup-sso
Hatps://support.google.com/a/answer/60224?hl=n
</div></details>

### Q.  問題23: 未回答
分析チームは、組織内のさまざまなマーケティング関連のクラウド プロジェクトに対して、一元化されたログ記録メカニズムを組み込む必要があります。これらのプロジェクトは、ブランディングやキャンペーンプロジェクトを含むPROMO部門に属します。すべてのマーケティング プロジェクトは、XYZ-MARKETING 請求先アカウントに関連付けられ、大規模なエンタープライズ契約の一部です。
この統合ロギングレイヤーを実現するための最も効果的なロギングエクスポートアプローチは何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、マルチプロジェクトのGCP環境における集中ロギングメカニズムの理解度を評価します。これは、部門内の複数のプロジェクトに対して統合ログレイヤーを作成し、特定の請求先アカウントに関連付け、構造と管理性を最適化することに重点を置いています。
重要な用語:
Cloud Pub/Sub: イベント駆動型システムの構築とストリーミング分析のためのメッセージング サービス。アプリケーション間でリアルタイムで信頼性の高いメッセージングを提供します。
includeChildren: GCP のリソース階層のプロパティで、true に設定すると、すべての子リソースからのログエントリがシンクのエクスポートに含まれるようになります。
ログのエクスポート: ログが Stackdriver Logging から GCP 内の別のサービスに転送され、処理、分析、または長期保存が行われる GCP のオペレーションを指します。
請求先アカウント: GCP 内のアカウントで、特定の GCP リソース セットに対して誰が支払うかを定義するために使用されます。プロジェクトは請求先アカウントにリンクされます。
フォルダ: GCP 内の組織構造で、共通の機能を共有するプロジェクトや、単一のエンティティとして扱う必要があるプロジェクトをグループ化して階層的に整理できます。
正解解説:
(オプション)
・別のアナリティクス プロジェクトで folders/PROMO を親とし、includeChildren プロパティを True に設定した Cloud Pub/Sub トピックにログをエクスポートし、アナリティクス システムを Pub/Sub トピックにサブスクライブします。
この選択は、Cloud Pub/Sub をログ メッセージの一元化されたハブとして活用し、スケーラブルでリアルタイムのメッセージ キューイングを提供するため、最適です。Folders/PROMO を親として Pub/Sub トピックにログをエクスポートし、「includeChildren」を有効にすると、指定したフォルダの下にあるすべてのプロジェクトのログが集計され、統一されたビューが提供されます。この構造化されたアプローチにより、個別の分析プロジェクトは、さまざまなマーケティングプロジェクトからのデータを簡単にサブスクライブして吸収できます。
不正解の説明:
オプション: billingAccounts/XYZ-MARKETING の Cloud Storage シンクを設定し、別の分析プロジェクトで includeChildren プロパティを False に設定すると、分析システムが Cloud Storage オブジェクトを処理します。
この選択が不十分である理由は、'includeChildren' を False に設定しても、指定された請求先アカウントの子プロジェクトからのログが集計されないためです。これにより、集中ロギングメカニズムの要件に反して、ロギングシステムが断片化されます。
オプション: 各マーケティング プロジェクト内の共通の Cloud Pub/Sub トピックへの個々のログのエクスポートを構成し、次にこの Pub/Sub トピックをサブスクライブするように分析システムを構成します。
この選択が実用的でない理由は、各マーケティングプロジェクトで個々のログエクスポートを構成するオーバーヘッドです。共通の Cloud Pub/Sub トピックを使用しますが、フォルダレベルのエクスポートで実現できる、よりシンプルで一元化された構造は利用されません。
オプション: 各マーケティング プロジェクトの共有 Cloud Storage バケットにログを送信する Cloud Storage シンクをデプロイし、その後、分析システムによって処理されます。
この選択が非効率的である理由は、各マーケティング プロジェクトに 1 つずつ、複数の Cloud Storage シンクをデプロイする必要があるためです。これにより、ログ記録データの構造が分散し、さまざまなプロジェクト間でログを管理および処理する際の複雑さが増す可能性があります。
参考：
https://cloud.google.com/logging/docs/export/aggregated-exports
https://cloud.google.com/logging/docs/export/configure_export_v2
https://cloud.google.com/pubsub/docs/overview
</div></details>

### Q.  問題24: 未回答
Google Cloud Storage バケットのファイル アクセス イベントのモニタリングと監査、および Google Cloud Storage バケットの構成を変更する API アクションを設定するのは、お客様の責任です。セットアップは、次の基準を満たす必要があります。 - Google Cloud 組織内のすべての Google Cloud Storage バケットから関連するログをキャプチャします。- ほぼリアルタイムでログをオフサイト分析ツールにストリーミングします。
どのような手順を踏む必要がありますか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Cloud Audit Logs と Pub/Sub を使用して Google Cloud Storage の堅牢なモニタリングおよび監査システムを確立し、ほぼリアルタイムで外部分析ツールにデータをストリーミングし、Google Cloud 組織内のすべてのストレージ バケットを包括的に可視化する候補者の能力を評価します。
重要な用語:
Logging Sink: Logging モジュールからサポートされている宛先(Pub/Sub、BigQuery、Cloud Storage など)にログをエクスポートするための Google Cloud のメカニズム。
includeChildren: ログ シンクを作成するときに使用されるパラメーターで、すべての子プロジェクトのログをログ エクスポートに含める必要があることを示します。
Cloud Audit Logs: リソースに影響を与えるアクションのログ レコードを提供し、コンプライアンス、運用、リスクの監査ニーズに関する分析情報を提供する Google Cloud サービス。
httpRequest フィールド: Google Cloud の API 呼び出しまたはサービス イベントに関連付けられた HTTP リクエストに関する情報を含む Cloud 監査ログの一部。
正解解説:
(オプション)
・includeChildren パラメータを使用して組織レベルでログシンクを確立し、出力を Google Cloud Pub/Sub トピックに転送します。
・外部分析ツールがCloud Audit LogsのhttpRequestフィールドを処理し、必要なアクセス情報を抽出できることを確認します。
組織レベルで includeChildren パラメータを使用してログシンクを確立する場合は、組織内のすべてのバケットが監視され、ログの一元化されたエクスポートポイントが作成されます。これらのログを Pub/Sub トピックに送信すると、外部ツールへのリアルタイム ストリーミングがサポートされます。外部分析ツールが httpRequest フィールドを処理する能力を確認することで、ファイル アクセス イベントと API アクションの詳細を分析に利用できるようになり、包括的な監査に必要なアクセス情報が提供されます。
不正解の説明:
オプション: 組織レベルでログ記録シンクを設定し、追加のパラメータを指定せずに Google Cloud Pub/Sub トピックに直接出力します。
この選択が正しくない理由は、すべての子プロジェクトとバケットのログが含まれることを保証する includeChildren などの追加パラメーターの指定がないため、すべてのバケットから関連するログをキャプチャする基準を満たさないためです。
オプション: 組織全体でアクセスの透明性ログを有効にすると、すべての Google Cloud Storage バケットが自動的にカバーされます。
この選択が間違っている理由は、アクセスの透明性ログは、ユーザーが実行した通常のファイル アクセスやバケット設定イベントではなく、Google のスタッフが実行した操作を記録するために使用され、規定のモニタリングと監査の要件には不十分であるためです。
オプション: Google Workspace 管理コンソールで、Google Workspace 監査ログと Google Cloud の同期を有効にします。
この選択が間違っている理由は、Cloud Storage のログとは別の Google Workspace 監査ログの統合について説明しているため、Google Cloud Storage でのファイル アクセスとバケット設定の変更のモニタリングや監査には役立たないためです。
参考：
https://cloud.google.com/logging/docs/export/configure_export_v2
https://cloud.google.com/logging/docs/audit
https://cloud.google.com/pubsub/docs
</div></details>

### Q.  問題25: 未回答
チームでは、サービス アカウントを使用して、App Engine アプリケーションと専用の Bigtable インスタンス間のネットワーク リクエストを処理します。悲しいことに、クリーニング操作中の設定ミスにより、サービスアカウントが削除され、アプリケーションが動作しなくなりました。システムの通常の運用をできるだけ早く復元すると同時に、セキュリティ基準が損なわれないようにする必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、セキュリティの整合性を維持しながら Google Cloud でのサービス アカウントの削除に対処する候補者の能力を評価します。App Engine と Bigtable の通信に不可欠なサービス アカウントが誤って削除された後、セキュリティ プロトコルを損なうことなく通常のオペレーションを回復することに重点を置いています。
重要な用語:
Undelete コマンド: Google Cloud IAM では、undelete コマンドを使用して、削除されたサービス アカウントを復旧期間内に復元できます。このコマンドは、権限を再設定することなく、誤って削除した元に戻すために重要です。
正解解説:
(オプション)
・undeleteコマンドで、削除したサービスアカウントを復元してください。
Google Cloud には、最近削除されたサービス アカウントを復元するための undelete コマンドが IAM 内に用意されているため、この選択が最も適切です。これにより、以前のすべての権限と役割がそのままの状態でアカウントがすぐに復元され、システムが大幅な中断やセキュリティ侵害なしに通常の動作状態に戻ることが保証されます。
不正解の説明:
オプション: Bigtable インスタンスのすべてのセキュリティ チェックを一時的に停止します。
この選択が間違っている理由は、Bigtable インスタンスのセキュリティチェックを無効にすると、システムのセキュリティが損なわれるためです。これは一時的な回避策であり、削除されたサービスアカウントの根本的な問題は解決しません。
オプション: 削除されたアカウントと同じ名前を使用して、サービス アカウントを再作成します。
この選択が正しくない理由は、同じ名前でサービス アカウントを再作成しただけでは、以前のロールとアクセス許可が自動的に復元されないためです。手動での再構成はリスクが高く、時間がかかります。
オプション: 別のサービス アカウントのロールとアクセス許可を再割り当てし、それらの資格情報を使用してアプリケーションを再デプロイします。
この選択が正しくない理由は、ロールとアクセス許可を別のサービス アカウントに再割り当てし、アプリケーションを再デプロイすると、時間のかかるプロセスになる可能性があるためです。また、細心の注意を払わないと、潜在的なエラーやセキュリティリスクが発生します。
参考：
https://cloud.google.com/iam/docs/creating-managing-service-accounts
https://cloud.google.com/iam/docs/creating-managing-service-account-keys
https://cloud.google.com/iam/docs/service-accounts#undeleting
</div></details>

### Q.  問題26: 未回答
会社では、Google Cloud Virtual Private Cloud(VPC)内で内部 IP アドレスのみを使用するように構成された一連の Compute Engine インスタンスを運用しています。これらのインスタンスでは、ソフトウェアパッケージの毎日のセキュリティアップデートを取得すると同時に、アップデートアクティビティの概要レポートを生成するためにインターネット接続が必要です。
これらの要件を満たすには、どのようなアプローチを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、外部 IP アドレスを使用せずに Compute Engine インスタンスでソフトウェア アップデートを安全に管理する方法の理解度を評価します。これには、内部のみのインスタンスがセキュリティのベストプラクティスに準拠しながら更新を取得し、アクティビティを報告できるようにする方法を選択することが含まれます。
重要な用語:
OS Config API: パッチ管理タスクの実行機能など、仮想マシン (VM) インスタンス全体のオペレーティング システム構成の管理を可能にするサービス。
パッチ管理: セキュリティと機能を向上させるために、システムパッチを定期的に実行してコンピュータのネットワークを管理するプロセス。
アクセス許可: クラウド環境内のリソースまたはサービスに対する特別に定義されたアクセス権。適切な権限設定により、他のサービスと対話するVMインスタンスのセキュリティとアクセス制御が確保されます。
定期的なパッチ ジョブ: 定期的に実行されるようにスケジュールされた自動操作により、手動による介入なしで VM が最新のセキュリティ パッチを維持できます。
エグレスファイアウォールルール: VPC からインターネットへのトラフィックなど、ネットワーク境界を離れるネットワークトラフィックを制御するアウトバウンドセキュリティルール。
正解解説:
(オプション)
・OS Config APIが有効になっていて、VMインスタンスに適切な権限が設定されていることを確認します。OS パッチ管理サービスで定期的なパッチ ジョブを設定して、重要なセキュリティ更新プログラムを毎日自動的に適用し、必要なレポートを生成します。
この選択は、OS Config API を利用して、外部 IP を持たない Google Cloud VPC 内の VM インスタンスの一元的かつ自動化されたパッチ管理を可能にするため、適切です。適切な権限で定期的なパッチ ジョブを設定することで、重要な更新が毎日適用され、セキュリティ要件を満たします。さらに、これらのアクティビティのレポートを生成して管理する機能はサービスに固有のものであるため、外部 IP アドレスを必要とせずに必要な監視とコンプライアンスの証拠を提供します。
不正解の説明:
オプション: VPC のエグレス ファイアウォール ルールですべてのアウトバウンド接続が許可されていることを確認します。各 Compute Engine インスタンスに手動で接続し、オペレーティング システム固有のコマンドを実行してアップデートをインストールします。更新コマンドを毎日実行するように Cloud Scheduler ジョブをスケジュールします。
この選択が正しくない理由は、エグレス トラフィックを開くだけでは、VM が更新プログラムのダウンロードを開始するための外部 IP アドレスの不足に対処できないためです。さらに、Cloud Scheduler による手動更新プロセスと更新コマンドの作成は非効率的であり、人為的エラーが発生しやすくなります。
オプション: 必要なセキュリティ アップデートを Cloud Storage バケットに手動でアップロードします。各 Compute Engine インスタンスにアクセスし、バケットから更新を取得して、各インスタンスに個別に更新を適用します。
この選択が間違っている理由は、労働集約的でエラーが発生しやすく、スケーラブルではないためです。アップデートを Cloud Storage に手動でアップロードし、取得して各インスタンスに適用すると、かなりのオーバーヘッドが必要になり、セキュリティ アップデート ポリシーへの準拠が保証されるわけではありません。
オプション: 外部 IP アドレスを Compute Engine インスタンスにアタッチして、インターネットに直接アクセスできるようにします。エグレス ファイアウォール規則が、すべての送信トラフィックを許可するように構成されていることを確認します。各インスタンスで、最小限のアクティビティの時間帯に更新スクリプトを実行する毎日の cron ジョブを手動で設定します。
この選択が正しくない理由は、外部 IP アドレスのアタッチが提案されており、内部のみの接続というシナリオの要件と矛盾するためです。さらに、すべてのアウトバウンド・トラフィックを許可するようにエグレス・ルールを構成すると、不要なセキュリティ・リスクが課せられる可能性があり、手動のcronジョブ・セットアップは、パッチ管理のための効率的または信頼できるアプローチではありません。
参考：
https://cloud.google.com/compute/docs/os-patch-management
https://cloud.google.com/nat/docs/overview
https://cloud.google.com/blog/products/identity-security/simplifying-cloud-operations-with-os-patch-management
</div></details>

### Q.  問題27: 未回答
チームは、医療プロジェクトでデータ分析に使用される Kubernetes Engine クラスタが、患者インターフェースとして機能するクラスタを除き、外部 IP アドレスなしでデプロイされるようにしたいと考えています。データアナリストには編集者の役割があり、クラスター設定を変更する権限があります。チームは、この構成を一貫して適用する必要があります。
チームはどのようなアプローチを取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Kubernetes Engine クラスタの外部 IP アドレスへのアクセスを制限し、医療プロジェクトのセキュリティおよびコンプライアンス基準に沿った選択的な接続を確保することで、ガバナンス制御を実装する能力を評価します。
重要な用語:
組織ポリシー: Google Cloud 組織全体に制約を適用することでガバナンスを有効にし、管理者がリソースと運用に制限を設定できるようにします。
パブリック IP 制限: コンピューティング リソースへのインターネットへの直接アクセスを防止し、外部の脅威にさらされる可能性を制限し、攻撃対象領域を減らすためのセキュリティ対策。
編集者ロール: ロールとアクセス許可の管理を除くすべてのリソースを変更するアクセス許可を付与する事前定義された IAM ロール。
正解解説:
(オプション)
・パブリックIPを患者インターフェースのKubernetes Engineクラスタのみに制限する組織ポリシーを確立する。
この選択は、組織内のすべての Kubernetes Engine クラスタに制限を適用するための一元的でスケーラブルな方法である組織ポリシーの作成を伴うため、最も適切です。ポリシーによってパブリック IP の割り当てを選択的に制限することで、患者インターフェイスとして指定されたクラスターのみが外部インターネットにアクセスできるようにし、他のクラスターはデフォルトのプライベート IP でデプロイされ、編集者ロールによって付与されたアクセス許可に関係なく、コンプライアンスを維持し、クラスター設定を制御します。
不正解の説明:
オプション: ヘルスケア プロジェクトで Kubernetes Engine のプライベート クラスター機能をアクティブ化します。
この選択が正しくない理由は、プライベート クラスター機能をアクティブ化すると、外部 IP をノードに割り当てないという必要な機能が提供されますが、プロジェクト内のすべてのクラスターに対して割り当てが行われ、パブリック アクセスを必要とする特定のクラスターの例外を許可するためのきめ細かな制御が提供されないためです。
オプション: 編集者ロールを再割り当てし、Kubernetes Engine 管理者 IAM ロールをデータ アナリストに割り当てます。
この選択が間違っている理由は、IAMロールをエディタからKubernetes Engine Adminに変更するだけでは、外部IPアドレスの割り当ては本質的に制限されず、権限のレベルが変更されるだけで、特定のクラスタ構成の制約は適用されないためです。
オプション: VPC ネットワークに 2 つのサブネットワーク セット(1 つは外部 IP を持つクラスタ用、もう 1 つは外部 IP を持たないクラスタ用)を設定します。
この選択が間違っている理由は、外部 IP の有無にかかわらず、クラスタ用に別々のサブネットワークを使用して VPC ネットワークを構成すると、複雑さが増し、エラーが発生しやすく、必要な一貫した組織全体のポリシー適用が提供されないため、手動による適用に依存するためです。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題28: 未回答
あなたは、ある医療機関が患者記録を Google Cloud に移行するのを支援する任務を負っています。次の条件を満たすキー管理ソリューションを提案する必要があります。
- ルートキーは、少なくとも 60 日ごとに循環させる必要があります。
- ルートキーを格納するキー管理サービスは、FIPS 140-2 レベル 3 セキュリティ標準に準拠している必要があります。
- 高可用性を実現するには、ルートキーを米国内の複数の地理的ゾーンにレプリケートする必要があります。
これらの要件に合致するサービスはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、少なくとも 60 日ごとに自動ローテーションでき、厳格なセキュリティ基準(FIPS 140-2 レベル 3)に準拠し、複数の地域ゾーンに複製される暗号鍵を管理するための Google Cloud サービスを特定するよう学習者に求めます。Google Cloud の鍵管理オプションとそのセキュリティ レベルを理解する必要があります。
重要な用語:
顧客管理の暗号鍵(CMEK): 顧客によって作成、制御、管理される暗号鍵。これらは、キー管理ポリシーの柔軟性を高め、保存データの保護に使用できます。
Cloud HSM: ユーザーが FIPS 140-2 レベル 3 認定環境で暗号化キーをホストし、暗号化操作を実行できるようにするクラウドベースのハードウェア セキュリティ モジュール サービス。
FIPS 140-2 レベル 3: 機密情報の不正アクセス、変更、または抽出を防止するための暗号化モジュールを認定する米国政府のセキュリティ標準。
キーローテーション: 暗号化キーを廃止し、新しいキーに置き換えるプロセス。頻繁な自動ローテーションにより、キーが侵害される可能性が減り、セキュリティが強化されます。
正解解説:
(オプション)
・Cloud HSMによる顧客管理の暗号鍵
Cloud HSM は、FIPS 140-2 レベル 3 のセキュリティ基準を満たすフルマネージド サービスでハードウェア セキュリティ モジュールを提供するため、この選択肢は医療機関の要件に最も適しています。これにより、カスタマーマネージド鍵を Google Cloud 内で使用しながら、複数のリージョン間で鍵を複製することで高可用性要件を満たすことができます。さらに、Cloud HSM は、指定された 60 日間の期間内のカスタマー マネージド キーの自動ローテーションをサポートしています。
不正解の説明:
オプション:Cloud Key Management Serviceによる顧客管理の暗号鍵
この選択が間違っている理由は、Cloud KMS では顧客管理の暗号鍵と鍵のローテーションが可能ですが、ソフトウェアベースの鍵管理サービスであるため、FIPS 140-2 レベル 3 のセキュリティ基準を満たしていないためです。
オプション:お客様提供の暗号化キー
この選択が間違っている理由は、お客様提供の暗号鍵(CPEK)はお客様が Google Cloud の外部で生成して管理する鍵であり、複数のゾーン間での自動鍵ローテーションやレプリケーションが規定されていないためです。
オプション: Google が管理する暗号鍵
この選択が間違っている理由は、Google が管理する暗号鍵は Google によって完全に管理されており、鍵のローテーション ポリシーや FIPS 140-2 レベル 3 への準拠など、医療機関が必要とする同程度の顧客管理を提供していないためです。
参考：
https://cloud.google.com/kms/docs
Hatpas://cloud.google.com/hsam/doc
https://cloud.google.com/security-key-management
</div></details>

### Q.  問題29: 未回答
組織の新しいクラウドベースのデータ分析プラットフォームのセキュリティプロトコルを構成しています。Google Cloud データ パイプラインの処理のボトルネックを分析して対処する際に、データ エンジニアリング チームが実装するアクセス制御戦略を定義する必要があります。この戦略は、次の 2 つの重要な原則に従う必要があります。
- 最小特権の原則を実装します。
- データエンジニアリングチームが、データパイプライン処理の問題の調査中に必要なリソースにアクセスできるようにします。
Google の推奨プラクティスに沿ってアクセスをプロビジョニングする最適な方法は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、最小特権と状況に応じたアクセス権の原則に基づいて、クラウド環境におけるアクセス管理の理解度を調べます。具体的には、Google Cloud の IAM ポリシーを調整して、最小限の権限昇格で運用上のニーズに対応する能力を評価します。
重要な用語:
カスタムIAMロール:カスタムIAMロールを使用すると、管理者は、事前定義されたロールを超えて、チームまたはプロセスの特定の要件に合わせて調整された正確な権限セットを持つ一意のロールを作成できます。
最小特権の原則: ユーザーに職務を遂行するために必要なアクセス許可のみを付与し、セキュリティ侵害の潜在的な経路を最小限に抑えるセキュリティの概念。
正解解説:
(オプション)
・データパイプラインの表示と調査に必要な権限を持つカスタムIAMロールを作成し、このロールをデータエンジニアリングチームに割り当てます。
この選択は、Google Cloud IAM の機能を活用して適切なアクセス制御ポリシーを確立するため、最適です。データエンジニアリングチームがデータパイプラインの問題を診断するために必要なアクセス許可のみを含むカスタム IAM ロールを作成することは、最小特権の原則に従います。これにより、チームメンバーに調査タスクの範囲を超える過剰な権限が付与されないため、クラウド環境内のセキュリティとコンプライアンスが強化されます。
不正解の説明:
オプション: データフロービューアの IAM ロールをデータエンジニアリングチームに付与して、プロジェクト内の全体像を把握します。
この選択が間違っている理由は、Dataflow Viewer IAM ロールを付与すると、調査中に必要なデータパイプラインだけでなく、プロジェクト内のすべてのデータパイプラインにアクセスできるようになるためです。これは、特定の処理のボトルネックに対処するために必要な範囲よりも広い可視性を与えることで、最小特権の原則に違反します。
オプション: サービスアカウントを設定し、プロジェクトオーナーのIAMロールを適用し、このアカウントのサービスアカウントユーザーロールをデータエンジニアリングチームに付与します。
この選択が間違っている理由は、プロジェクト所有者にアクセス権を付与すると、たとえサービスアカウントであっても、タスクに必要な権限を大幅に超えるためです。これは、セキュリティリスクをもたらす可能性のあるプロジェクト全体に対する広範な権限を提供することにより、最小特権の原則に反対します。
オプション: サービスアカウントを作成し、データパイプラインを一覧表示および表示するために必要な権限を割り当て、データエンジニアリングチームにこのアカウントのサービスアカウントユーザーロールを付与します。
この選択が間違っている理由は、サービス アカウントを使用すると、より詳細なアクセスが構成されるのに対し、サービス アカウント ユーザー ロールを使用すると、データ エンジニアリング チームは特定のタスクに必要な権限よりも広範なアクセス許可を間接的に取得でき、最小特権の原則に違反する可能性があるためです。
参考：
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/iam/docs/creating-custom-roles
https://cloud.google.com/iam/docs/granting-changing-revoking-access
</div></details>

### Q.  問題30: 未回答
組織は、europe-west-3 の Google Cloud ロードバランサの背後にあるインスタンスグループで現在サポートされている動画処理サービスを管理しており、スタンダード階層ネットワークを使用しています。エンジニアリング部門は、別の Google Cloud リージョンである asia-southeast-1 にプレゼンスを確立する予定です。受信メディア処理リクエストを両方のリージョンのインスタンスグループにルーティングするには、統合された外部 IP アドレスが必要です。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の負荷分散サービスを使用して、単一のフロントエンド IP でグローバル負荷分散を構成する能力を評価します。主な課題は、ビデオ処理ワークロードを処理するさまざまなリージョンにルーティングできる要求の単一のエントリ ポイントを維持することです。
重要な用語:
スタンダード階層ネットワーク: ユーザーのトラフィックをパブリック インターネット経由で最も近い Google ネットワーク エッジ ロケーションにルーティングする Google Cloud ネットワーク サービス階層。
プレミアム ティア ネットワーク: Google のプライベートな高速ネットワークを活用して、低レイテンシと高い信頼性を提供する Google Cloud ネットワーク サービス階層です。
ネットワーク エンドポイント グループ: IP アドレスとポートでエンドポイントを指定できる Google Cloud の機能で、Google Cloud の外部または内部でホストされているサービスを表すことができます。
Global Load Balancer: リージョン間の負荷分散を提供する Google Cloud サービスで、レイテンシと可用性に基づいてユーザー トラフィックを最も近いインスタンス グループに転送します。
正解解説:
(オプション)
・Premium Tierネットワークを使用するようにロードバランサーのフロントエンド構成を変更し、新しいインスタンスグループを追加します。
Premium レベルのネットワークを利用すると、単一の外部 IP を提供し、異なるリージョン間でトラフィックをインテリジェントにルーティングできるグローバル ロード バランサーを設定できるため、この選択は適切です。Premium Tier を使用するようにロードバランサーの設定を変更し、asia-southeast-1 インスタンスグループを追加することで、指定されたユニファイド IP への受信リクエストを、最も短いレイテンシーで使用可能な最も近いインスタンスグループに分散できます。
不正解の説明:
オプション: インスタンス・グループのかわりにネットワーク・エンドポイント・グループを利用するようにロード・バランサ・バックエンドを構成します。
この選択が正しくない理由は、ネットワーク エンドポイント グループへの切り替えでは、リージョン間で要求をルーティングするための統合外部 IP の要件に対応できないためです。ネットワーク エンドポイント グループは、Google Cloud の内部または外部でホストされているサービスのエンドポイントを指定するなど、さまざまな目的で使用されます。
オプション: Standard レベルのネットワークを使用して asia-southeast-1 に別のロード バランサーを設定し、静的外部 IP アドレスを構成します。
この選択が正しくない理由は、静的 IP を使用して別のリージョンに別のロード バランサーを設定すると、統合された外部 IP アドレスを持つという要件が満たされないためです。この設定により、リージョンごとに異なるエントリ ポイントが作成されます。
オプション: 2 つのリージョン間に Cloud VPN リンクを確立し、Google プライベート アクセスを有効にします。
この選択が間違っている理由は、クラウド VPN を確立しても、メディア処理リクエストをルーティングするための統一された外部 IP が提供されないためです。Cloud VPN は、インターネット経由で 2 つのネットワークを安全にリンクしますが、グローバル ロードバランサの目的には適していません。
参考：
https://cloud.google.com/network-tiers/docs/using-network-service-tiers
https://cloud.google.com/load-balancing/docs/load-balancing-overview
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address
</div></details>

### Q.  問題31: 未回答
ある国際的な小売企業は、サプライ チェーン管理システム全体を Google Cloud に移行しました。このシステムは、さまざまなチームによって監督されている多数のプロジェクトにわたって、膨大な数のインスタンスを運用しています。お客様は、特定の履歴時点における Google Cloud のインスタンス構成とステータスの履歴ビューを維持する任務を負っています。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、さまざまなチームが管理するさまざまなプロジェクトにわたる Google Cloud の多数のインスタンスの構成とステータスの履歴ビューを維持する能力を評価します。これには、在庫データを自動化および管理するための適切なツールとサービスを理解することが含まれます。
重要な用語:
Forseti Security: Google Cloud 環境の保護に役立つオープンソース ツール。これにより、GCPリソースを継続的に監視して、組織のセキュリティポリシーを確実に満たすことができます。
インベントリ スナップショット: 特定の時点でのリソース メタデータのキャプチャされた状態。スナップショットを使用すると、組織はリソースの構成と変更を経時的に追跡でき、監査とレビューに役立ちます。
正解解説:
(オプション)
・Forseti Securityを使用して、インベントリのスナップショットを自動化します。
Forseti Security は Google Cloud 環境でのセキュリティとポリシーの適用に特化して設計されたツールであるため、この選択は適切です。これには、リソースの状態をキャプチャする定期的な在庫スナップショットを取得する機能が含まれており、会社のサプライチェーン管理システムに必要な履歴データを提供します。Forseti を使用すると、任意の時点でインベントリをキャプチャするプロセスを自動化できるため、インスタンスの構成とステータスの履歴ビューを維持するという要件を満たすことができます。
不正解の説明:
オプション: 組織レベルでCloud Resource Managerを利用します。
この選択が間違っている理由は、Cloud Resource Manager が主に組織のリソースに対する階層的な可視性と制御を管理するためです。組織レベルでリソースを表示および管理するために使用できますが、インスタンスの設定とステータスの履歴を追跡するための自動インベントリスナップショットは提供されません。
オプション: Cloud Monitoring を使用して、すべてのプロジェクトを統合するダッシュボードを構成します。
この選択が間違っている理由は、Cloud Monitoring がクラウド リソースのパフォーマンスに基づくリアルタイムのデータ収集とアラートに重点を置いているためです。プロジェクト間のビューを統合することはできますが、リソース構成の履歴スナップショットはキャプチャされず、Forseti のような長期的なインベントリ追跡用には設計されていません。
オプション: Security Command Center を展開して、組織内のすべてのリソースを調べます。
この選択が間違っている理由は、Security Command CenterがGCPリソースのリアルタイムのセキュリティ監視とリスク評価を目的としているためです。これは、組織全体を可視化する高度なセキュリティツールですが、履歴設定とステータス追跡のための自動インベントリスナップショット機能は提供していません。
参考：
https://cloud.google.com/forseti/docs
https://cloud.google.com/security-command-center/docs
https://cloud.google.com/logging/docs/view/overview
</div></details>

### Q.  問題32: 未回答
内部ウェブアプリと関連アセットの認証ポリシーを管理するには、どの Google Cloud サービスを使用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ウェブ アプリケーションの認証とアクセス制御を容易にする Google Cloud サービスに関する知識を評価します。これは、Webアプリケーションの保護と組織のクラウドインフラストラクチャ内の内部アクセスの管理に関する専門知識を持つ個人向けに作成されています。
重要な用語:
Identity-Aware Proxy: ユーザー ID とアクセス試行のコンテキストを検証して、ユーザーがアプリケーション リソースにアクセスできるかどうかを判断することで、アプリケーションへのアクセスを管理するのに役立つサービス。
Access Context Manager: 管理者は、Google Cloud のプロジェクトやリソースに対して属性ベースのきめ細かなアクセス制御を定義でき、Identity-Aware Proxy などのサービスでアクセス ポリシーを適用するために利用されます。
正解解説:
(オプション)
・Identity-Aware Proxy(アイデンティティ認識型プロキシ)
Identity-Aware Proxy(IAP)は、従来のVPNを必要とせずに、リクエストのIDとコンテキストに基づいてWebアプリケーションやクラウドリソースへのアクセスを管理できるため、正しい選択です。Google の Access Context Manager と統合して、安全できめ細かなアクセス制御を提供し、ユーザー ID、場所、デバイスのセキュリティ ステータスなどの側面を考慮したポリシーを適用できます。IAPは、アプリへのアクセスリクエストをインターセプトし、認証および承認されたユーザートラフィックのみを許可することで機能します。
不正解の説明:
オプション:クラウドルーター
Cloud Router が適切な選択肢ではない理由は、Cloud Router が BGP を使用したハイブリッド環境での動的ルーティングに重点を置いたネットワーキング サービスであるためです。Cloud Router の主な機能は、オンプレミス ネットワークと Google Cloud 間のトラフィックとルートを管理することであり、ウェブ アプリケーションの認証ポリシーを管理することではありません。
オプション: Google Cloud Load Balancing
Google Cloud Load Balancingが正しくない理由は、受信ネットワークトラフィックを複数のサーバーに分散して、単一のサーバーが過度の需要に耐えないようにするように設計されたネットワーキングサービスであるためです。大量のWebトラフィックを処理し、高可用性を提供する上で重要な役割を果たしますが、認証ポリシーを直接処理することはありません。
オプション: コンフィデンシャル VM
コンフィデンシャル VM が適切な選択ではない理由は、コンフィデンシャル VM が VM インスタンスのメモリ暗号化を提供してデータをセキュリティで保護するコンピューティング サービスであるためです。これにより、使用中にデータが暗号化される環境でワークロードを実行できます。ただし、このテクノロジは、Web アプリの認証ポリシーの管理とは無関係です。
参考：
https://cloud.google.com/iap/docs
https://cloud.google.com/armor/docs
https://cloud.google.com/compute/docs/shielded-vm
</div></details>

### Q.  問題33: 未回答
ある医療企業は、インターネット経由でアクセスできる患者管理システムを導入しています。このアプリケーションは、さまざまな Google Cloud リージョンでホストされており、URI クエリに基づいてユーザーを適切なバックエンドにルーティングするように設計されています。同社は、アプリケーションがインターネットに直接公開されないようにし、既知の悪意のあるIPアドレスの所定のセットからの接続をブロックする必要があります。
これらの目標を達成するには、どの Google Cloud サービスを使用すべきでしょうか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、特定のルーティングとセキュリティ要件を持つパブリックにアクセス可能なアプリケーションを保護するために、適切な Google Cloud サービスを選択する能力を評価します。焦点は、悪意のあるトラフィックに対する保護を提供しながら、URI クエリを処理できるサービスです。
重要な用語:
ジオベースのルーティング: ジオベースのルーティングでは、ローカライズされたコンテンツを提供し、レイテンシーを短縮するために不可欠な、クライアントの地理的な場所に基づくトラフィック分散が可能になります。
IPブラックリスト:IPブラックリストは、有害または望ましくないことがわかっている特定のIPアドレスからのトラフィックをブロックし、潜在的な攻撃を防ぐセキュリティメカニズムです。
WAF(Web Application Firewall):WAFは、Webアプリとインターネット間のHTTPトラフィックをフィルタリングおよび監視することにより、一般的なWebエクスプロイトや脆弱性からWebアプリケーションを保護します。
正解解説:
(オプション)
・クラウドアーマー
Cloud Armor は Web アプリケーション ファイアウォール(WAF)を含むセキュリティ サービスであり、さまざまなオンラインの脅威からアプリケーションを保護するように設計されているため、この選択は医療機関のニーズに適しています。Cloud Armor は、既知の悪意のある IP アドレスをブロックするための IP ブラックリストを含むカスタム セキュリティ ポリシーを定義できるという点で、Google Cloud サービスの中で際立っています。HTTP(S)負荷分散と統合することで、URIクエリに基づいてユーザーリクエストのルーティングを管理し、アプリケーションがインターネットに直接露出しないようにしながら、ユーザーが適切なバックエンドに誘導されるようにすることもできます。
不正解の説明:
オプション: HTTP(S) 負荷分散
HTTP(S) 負荷分散が適切な選択ではない理由は、URI クエリに基づいてユーザーを適切なバックエンドにルーティングできる一方で、Cloud Armor との統合なしには、既知の悪意のある IP アドレスのセットに対する保護が組み込まれていないためです。
オプション:TCP プロキシ ロード バランシング
TCPプロキシロードバランシングが正しくない理由は、通常、下位レベル(TCP層)で動作し、URIベースのルーティングまたはIPブラックリスト機能を提供しないためです。これは主に HTTP(S) 以外のトラフィックに使用されます。
オプション:クラウドNAT
Cloud NAT が正しくない理由は、外部 IP アドレスを持たない仮想マシン インスタンスがインターネットやその他の Google サービスに接続できるが、悪意のあるインターネット トラフィックに対する直接的な保護や URI ベースのルーティングのサポートが提供されないためです。
参考：
https://cloud.google.com/armor
https://cloud.google.com/load-balancing/docs/ssl
https://cloud.google.com/load-balancing/docs/network
</div></details>

### Q.  問題34: 未回答
会社のオンプレミス データセンターから Google Cloud Storage に動画アーカイブを移動すると、ストレージ バケットがバケット ロック機能に適用されたバケット ポリシーと互換性がないことを示すエラーが表示されます。
この問題に対処するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、バケットロック機能のバケットポリシーに準拠していないためにエラーが発生したときに、ビデオアーカイブをGoogle Cloud Storageに転送するシナリオに対処します。焦点は、この安全なデータ転送の互換性の問題を解決するための正しいアプローチです。
重要な用語:
バケットロック: Google Cloud Storage の機能で、バケット内のオブジェクトのデータ保持ポリシーを設定し、一定期間削除されないようにすることができます。
アクセス制御設定: ユーザーやサービスに権限を付与する方法を指定する Cloud Storage バケット内の構成で、バケットロックなどの特定の機能との互換性に影響を与える可能性があります。
正解解説:
(オプション)
・バケットのアクセス制御設定を修正し、バケットロック機能に対応させる
この選択では、バケットポリシーがバケットロック機能の要件に沿っていることを確認するために、バケットのアクセスコントロール設定を変更することをお勧めします。このエラーはポリシーレベルの非互換性を意味するため、バケットロックの制約を可能にするようにバケットの設定を直接調整することが適切な手段です。このプロセスには、統一されたバケットレベルのアクセスを有効にしたり、保持ポリシーの適用を容易にするために他の関連するポリシー設定を調整したりすることが含まれる場合があります。
不正解の説明:
オプション: ストレージ転送ジョブを修正して、別のストレージバケットをターゲットにします。
別のバケットをターゲットにするように転送ジョブを変更するのが正しくない理由は、ポリシーの非互換性という根本的な問題に対処していないためです。また、別のバケットがバケットロック用に設定されていない可能性があり、ターゲットバケットを変更するだけでは、特定のエラーは解決されません。
オプション: roles/storage.objectCreator IAM ロールをストレージ転送サービス アカウントの Cloud Storage バケットに割り当てます。
roles/storage.objectCreator IAM ロールをストレージ転送サービスアカウントに割り当てても効果がないのは、このロールがオブジェクト作成権限に関係しているためです。現在の問題は、転送サービスアカウントの権限ではなく、バケットロックに関連するバケットのポリシー設定に起因しています。
オプション: roles/storage.admin IAM ロールをストレージ転送サービス アカウントの Cloud Storage バケットに付与します。
roles/storage.admin IAM ロールをストレージ転送サービスアカウントに付与するのが正しくない理由は、このロールがバケットのオブジェクトに対する広範な管理アクセス許可を付与するためです。バケットロック機能ポリシーに関する特定のコンプライアンスの問題には対処しません。
参考：
https://cloud.google.com/storage/docs/uniform-bucket-level-access
https://cloud.google.com/logging/docs/export/configure_export_v2
https://cloud.google.com/storage/docs/access-control/using-iam-permissions
</div></details>

### Q.  問題35: 未回答
組織の財務部門にプライベートクラウドネットワークを確立し、IT監査チームがアクセス制御リスト(ACL)などのネットワークコンポーネントを管理できるようにする必要があります。
これらのネットワーク コンポーネントの管理責任を分割できるようにするには、ネットワークをどのように設定する必要がありますか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud のネットワーク アーキテクチャと管理、特に財務部門と IT 監査チームの両方に役立つプライベート クラウド ネットワーク設定における責任の委任に関する理解度を評価します。
重要な用語:
共有 VPC: 複数の Google Cloud プロジェクト(サービス プロジェクト)を共通のホスト プロジェクト VPC に接続できるようにするネットワーク リソース。このセットアップにより、ネットワーク管理が簡素化され、セキュリティを損なうことなくリソースの共有が保証されます。
アクセス制御リスト(ACL): Google Cloud のコンテキストでの ACL は、ネットワーク サブネットとの間のトラフィックのフローを制御するために使用されます。これらは、ネットワークセキュリティ管理の不可欠な部分です。
サービス プロジェクト: Google Cloud では、サービス プロジェクトはホスト プロジェクトの共有 VPC に接続されたプロジェクトです。これにより、サービス プロジェクトはホスト プロジェクトのネットワーク リソースを利用できます。
正解解説:
(オプション)
・IT監査チームがACLを担当する共有VPCを作成し、サービスプロジェクトとして財務部門のプロジェクトとネットワークを連携させる。
この選択により、共有 VPC を使用して責任が効率的に割り当てられます。共有 VPC では、ネットワーク リソースはホスト プロジェクトに一元化され、この場合は IT 監査チームによって管理されます。その後、ACL管理は共同責任となり、財務部門のプロジェクトはサービスプロジェクトとして接続され、一元管理された一貫したネットワークポリシーの恩恵を受けます。このセットアップにより、ネットワーク コンポーネントに対する共同管理制御と分離管理制御の両方が容易になります。
不正解の説明:
オプション: 部門ごとに個別の VPC ネットワークを実装し、マルチインターフェイス ネットワーク アプライアンスを使用してこれらのネットワークを相互接続します。
これが最適でない理由は、部門ごとに個々の VPC を管理すると、複雑さとオーバーヘッドが増すためです。相互接続用のマルチインターフェイスネットワークアプライアンスは、コストがかかり、追加の構成が必要になる場合があり、管理責任の分割が合理化されません。
オプション: VPC ネットワーク ピアリングを構成し、財務部門のプロジェクトが IT 監査チームによって制御される共有 VPC とのピアリングを確立できるようにします。
これが間違っている理由は、VPC ネットワーク ピアリングが本質的にネットワーク管理の責任を分割していないためです。これにより、VPC ネットワークは通信できますが、質問で求められている特定のチームによる集中型 ACL 管理は提供されません。
オプション: 単一のプロジェクト内で VPC を構成します。IT 監査チームに roles/compute.networkAdmin ロールを付与し、財務部門の開発者に roles/compute.admin ロールを付与します。
このオプションが推奨されない理由は、1 つのプロジェクト内で IT 監査チームと財務部門の開発者の両方に広範なネットワーク管理ロールを付与するためです。このアプローチでは、管理責任が効果的に分離されず、セキュリティ上の懸念につながる可能性があります。
参考：
https://cloud.google.com/vpc/docs/shared-vpc
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/vpc/docs/provisioning-shared-vpc
</div></details>

### Q.  問題36: 未回答
現在、会社のポリシーでは、農業セクターのデータベース管理を一元化する必要があります。データベース運用チームのみが、必要なユーザーに代わって BigQuery データセットをインスタンス化できるようにする必要があります。
このポリシーを遵守するために、あなたの会社が実施すべき2つのアクションはどれですか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 環境における BigQuery のアクセス管理とポリシー制御の理解度を探ります。また、指定された運用チームの下で BigQuery データセットの作成を一元化するポリシーを確立し、適用する方法についても説明します。
重要な用語:
BigQuery データ編集者: ユーザーがデータセットとテーブルを作成、変更できる BigQuery の役割。テーブル内のデータを管理したり、クエリを実行したりする権限は提供されません。
組織レベルのポリシー: Google Cloud 組織全体に適用される階層管理ポリシー。これらのポリシーは、アクセス許可と制約を一様に管理するのに役立ちます。
正解解説:
(オプション)
・BigQuery データ編集者のロールを組織レベルのすべての個人から取り消します。
・データベース運用チームのメンバーを含む特定のグループを、組織レベルで BigQuery データ編集者のロールに割り当てます。
すべての個人から BigQuery データ編集者のロールを取り消すと、権限のあるグループ以外はデータセットを作成または変更できなくなります。データベース運用チームを含むグループを組織レベルでこのロールに割り当てることで、データベース運用チームのみが BigQuery データセットをインスタンス化できるようにするというポリシー要件を遵守しながら、この機能を特定の制御されたユーザー セットに一元化できます。
不正解の説明:
オプション: BigQuery データセットに組織ポリシー サービスの制約を実装し、組織全体に適用します。
この選択が間違っている理由は、組織ポリシー サービスは広範なガバナンス機能を提供しますが、BigQuery データセットのインスタンス化を直接制限しないためです。これは通常、特定のIAMロールではなく、制約を設定するために使用されます。
オプション: 組織レベルで特定のグループに BigQuery ユーザーの役割を付与します。
この選択が間違っている理由は、BigQuery ユーザーロールでは、プロジェクト内のクエリ ジョブを含むジョブの実行を個人が許可しているためです。ただし、データセットを作成または変更する機能は制限されないため、ポリシー要件に反します。
オプション: データベース運用チームに BigQuery リソース管理者のロールを付与します。
この選択が間違っている理由は、BigQuery Resource Admin ロールでは、データセットやテーブルの削除など、データセットやテーブルの削除など、データセットのインスタンス化のタスクには不要であり、ポリシーで要求される管理を特に一元化していないためです。
参考：
https://cloud.google.com/resource-manager/docs/access-control-proj
https://cloud.google.com/iam/docs/understanding-roles
https://cloud.google.com/resource-manager/docs/organization-policy/creating-managing-policies
</div></details>

### Q.  問題37: 未回答
会社には、Google Cloud サービスとの安全な通信を必要とするローカル サーバーがあります。これらのサーバーが Google Cloud にプライベートに接続できるようにしながら、費用を抑え、合理化された運用を維持する必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、オンプレミス サーバーと Google Cloud サービスの間にプライベートで費用対効果の高い接続を作成する能力を評価します。候補者は、安全で効率的なコミュニケーションを確立するために、利用可能なオプションを区別する必要があります。
重要な用語:
IPsec VPNトンネル:ネットワーク経由で送信されるデータのパケットを認証および暗号化して、2つのサイト間に安全なトンネルを確立する安全なネットワークプロトコルスイート。
VPC with Private Google Access: Google Cloud Virtual Private Cloud 内のプライベート IP アドレスのみを持つインスタンスが、パブリック IP アドレスを使用せずに Google API とサービスにアクセスできるようにします。
暗号化されたデータ転送: 暗号化方式を使用して、送信中の不正な傍受やアクセスからデータを確実に保護します。
正解解説:
(オプション)
・すべてのローカルサーバーデータをIPsec VPNトンネル経由でGoogle Cloudにルーティングし、プライベートGoogleアクセスを有効にしたVPCにルーティングします。
この選択は、セキュリティとコスト効率のバランスが取れた最も実用的です。IPsec VPN トンネルを使用すると、オンプレミス サーバーと Google Cloud サービス間の接続が保護されます。これをVPCのプライベートGoogleアクセス機能と組み合わせることで、パブリックIPアドレスやInterconnectなどのより高価な専用接続に関連するコストを発生させることなくGoogleサービスにアクセスできるため、インターネットを介した安全なデータ転送に適しています。
不正解の説明:
オプション: パブリックインターネット経由でローカルインフラストラクチャから VPC への VPC ピアリングを実装します。
この回答が間違っている理由は、パブリックインターネット経由の VPC ピアリングがプライベート接続の要件を満たしていないためです。このアプローチでは、トラフィックが暗号化されていても、オンプレミス サーバーと Google Cloud 間のプライベート パスを確保するのではなく、トラフィックがインターネットに公開される可能性があります。
オプション: ネットワーク経由でデータを送信する前に、すべてのサービスが Cloud Key Management Service(KMS)キーを使用してデータを暗号化することを要求するセキュリティ プロトコルを実装します。
この回答が間違っている理由は、すべてのサービスに個別に暗号化要件を実装することが現実的ではないためです。サービスレベルの暗号化はセキュリティを強化しますが、Google Cloud サービスとの安全な通信を実現するための複雑でコストのかかる、一元化されていないアプローチです。
オプション: すべてのローカル サーバー データを、専用またはパートナー インターコネクトを介して、限定公開の Google アクセスが設定された VPC に転送します。
この答えが間違っている理由は、専用相互接続とパートナー相互接続のオプションは、プライベート接続を提供する一方で、特に帯域幅の要件がそのような高コストの投資を正当化しない場合、通常、IPsec VPNソリューションと比較して高価で合理化されていないためです。
参考：
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/vpn/docs/concepts/overview
https://cloud.google.com/vpc/docs/vpc-peering
</div></details>

### Q.  問題38: 未回答
あるメディア企業は、マネージド インスタンス グループ(MIG)を使用して、独自の動画処理タスクを Compute Engine ベースのセットアップに移行しようとしています。タスクは断続的に発生し、迅速な実行が必要です。また、キーのライフサイクルを自分で管理する機能も必要です。
会社のニーズを満たすために、セットアップで利用されるブートディスクの暗号化方法は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Compute Engine のブート ディスクの暗号化方法に関する知識を評価し、マネージド インスタンス グループを使用してタスクを迅速に実行しながら、鍵のライフサイクルを管理するお客様の要件に焦点を当てます。
重要な用語:
カスタマー管理の暗号鍵(CMEK): CMEK を使用すると、ユーザーは Cloud KMS を使用して暗号鍵を作成、制御、ローテーションできます。これにより、クラウドサービスの暗号化プロセスをより詳細に制御できます。
クラウドキー管理サービス(KMS):クラウドサービスの暗号化キーを一元化されたクラウドサービスで管理できるクラウドサービス。
マネージド インスタンス グループ (MIG): MIG を使用すると、ユーザーは複数のインスタンスを 1 つのエンティティとして操作できるため、高可用性、自動スケーリング、負荷分散が促進されます。
保存時の暗号化:永続ストレージに保存されている(保存されている)データを暗号化し、使用していないときに不正アクセスから保護することを指します。
正解解説:
(オプション)
・Cloud Key Management Service(KMS)を利用した顧客管理暗号鍵(CMEK)
顧客管理の暗号鍵(CMEK)は、マネージド インスタンス グループ内の Compute Engine インスタンスのブートディスクを暗号化するための鍵を適用し、鍵管理に必要な自律性をメディア企業に提供するため、この選択は適切です。Cloud Key Management Service(KMS)を活用することで、同社は暗号鍵とそのローテーション ポリシーを制御し、自己管理型の鍵ライフサイクルのニーズを満たしながら、断続的なタスク実行中に暗号化されたディスクを迅速に起動することができます。
不正解の説明:
オプション:お客様提供の暗号化キー(CSEK)
顧客提供の暗号鍵(CSEK)が最適な選択肢ではない理由は、ユーザーが Google Cloud サービスとは無関係に鍵の保存と保護を管理する必要があるため、管理が複雑になり、インスタンスの起動時間に遅延が生じる可能性があるためです。
オプション: Google が管理する暗号鍵(GMEK)
Googleが管理する暗号鍵(GMEK)は、Googleによって管理されており、問題のメディア会社が述べている要件である暗号鍵のライフサイクルを自分で管理する機能を顧客に提供しないため、適切ではありません。
オプション: 動画ファイルを Google Cloud にアップロードして処理する前に、動画ファイルをローカルで暗号化します。
Google Cloud にアップロードする前に動画ファイルをローカルで暗号化しても、アップロード前のデータは保護されますが、Compute Engine インスタンスのブート ディスクで顧客管理の暗号鍵が必要になるため、このコンテキストでは効果がありません。
参考：
https://cloud.google.com/compute/docs/instances/encrypt-disks-with-cmek
https://cloud.google.com/kms/docs
https://cloud.google.com/compute/docs/instances/create-start-instance#starting_an_instance_with_encryption_key
</div></details>

### Q.  問題39: 未回答
医療業界における PaaS のセキュリティ責任共有モデルでは、組織が管理する必要がある 2 つのコンポーネントはどれですか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、特に厳しいデータ保護規制の対象となる医療業界のコンテキスト内で、サービスとしてのプラットフォーム (PaaS) オファリングにおける共有セキュリティ責任の理解を評価します。
重要な用語:
共有セキュリティモデル:クラウドサービスプロバイダーとクライアントの両方がクラウドリソースのセキュリティを確保する責任を持つことを規定するクラウドコンピューティングフレームワーク。
PaaS: インフラストラクチャの構築と保守の複雑さを伴わずに、顧客がアプリケーションを開発、実行、管理できるプラットフォームを提供するクラウド コンピューティング サービス モデル。
HIPAA: 医療保険の相互運用性と説明責任に関する法律は、医療における患者のデータ保護の基準を定めています。保護対象の医療情報を扱う事業体は、データの機密性、可用性、完全性を確保する必要があります。
正解解説:
(オプション)
・患者データアクセス制御
・アプリケーションセキュリティ
PaaSモデルでは、患者データアクセスとアプリケーションセキュリティの制御が組織の責任であり、HIPAAなどの規制があるため、医療では特に重要です。前者には、機密性の高い医療データへのアクセスを制限するための適切な認証および承認システムの設計と実装が含まれます。後者には、アプリケーション自体にセキュリティパッチを適用することで潜在的な脅威からアプリケーションを保護し、データ侵害や不正なデータ漏洩などの問題から保護するために安全なコーディングプラクティスが守られるようにすることが含まれます。
不正解の説明:
オプション: コンピュート・リソース
"コンピューティング リソース" が正しくない理由は、PaaS 環境では、クラウド プロバイダーが基になるコンピューティング リソースを管理するためです。これには、サーバー ハードウェア、ネットワーク、ストレージ、および仮想化レイヤーが含まれます。
オプション: データベース・パッチ適用
「データベースへのパッチ適用」が正しくない理由は、PaaS オファリングでは、通常、クラウド プロバイダーがデータベースへのパッチ適用を担当するためです。このサービスには、基盤となるデータベース・インフラストラクチャを保護するために必要な更新、バグ修正、およびセキュリティ・パッチが含まれます。
オプション:オペレーティングシステム
「オペレーティング システム」が正しくない理由は、パッチ適用を含むオペレーティング システムのメンテナンスがクラウド プロバイダーによって管理されているためです。OS のセキュリティと更新プログラムは PaaS の配置で抽象化されるため、お客様は処理する必要はありません。
参考：
https://cloud.google.com/security/foundation
https://cloud.google.com/iam/docs
https://docs.aws.amazon.com/IAM/latest/UserGuide/introduction.html
</div></details>

### Q.  問題40: 未回答
会社では最近、Security Command Center (SCC) の標準レベルを実装しました。複数の BigQuery データセットが誤って公開されていたことが判明しました。この見落としが引き起こした可能性のある影響を評価し、それに対処するための措置を講じる必要があります。
どのような行動を取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、BigQuery データセットが一般公開されたセキュリティ インシデントへの対応における Security Command Center ユーザーの知識を評価します。学習者は、問題を修復し、将来の露出を防ぐために必要な手順を理解する必要があります。
重要な用語:
Security Command Center: Google Cloud のセキュリティとリスク管理の統合プラットフォームで、組織のクラウド資産全体のセキュリティを可視化し、コンプライアンスを実現します。
bigquery.publicDataAccessPrevention: BigQuery リソースへの一般公開を禁止し、データセットが誤って公開されるのを防ぐ組織のポリシー。
クエリ使用状況ログ: これらのログは、BigQuery で実行されたクエリに関する詳細情報を提供し、アクセス パターンの監査と不正なデータ アクセスの特定を可能にします。
正解解説:
(オプション)
・1.データセットのアクセス許可を変更して、アクセスを制限します。
2. クエリ使用状況ログを調べて、未承認のデータクエリを分析します。
3. 今後のインシデントを防ぐために、組織ポリシー bigquery.publicDataAccessPrevention を実装します。
この選択には、データセットの権限を速やかに更新して不正アクセスを防止すること、クエリ使用ログを慎重に監査してデータが公開された期間中に不正なクエリが発生していないかどうかを確認すること、BigQuery データセットが今後不注意で公開されることを予防的に防止することでセキュリティ体制を強化するための「bigquery.publicDataAccessPrevention」組織ポリシーのデプロイが含まれます。このアクションの組み合わせにより、同様のリスクの即時軽減、徹底的な調査、および戦略的防止が保証されます。
不正解の説明:
オプション: 1. すべてのユーザーにデータセットへのアクセスを許可する Identity and Access Management (IAM) アクセス許可を削除します。
2. 組織ポリシー bigquery.uniformAccess をすべての BigQuery データセットに実装して、今後の問題を回避します。
3. BigQuery のデータ アクセス ログを調査して、不正なデータクエリを探します。
この選択が正しくない理由は、すべてのユーザーの IAM 権限の削除を示唆しており、これが漏洩の具体的な原因ではない可能性があり、「bigquery.uniformAccess」を実装するというアサーションは公開データの漏洩を直接防ぐものではないためです。データセットに対して一貫したアクセス制御を適用するだけです。
オプション: 1. アクセス許可を調整して、データセットへのアクセスを承認されたユーザーのみに制限します。
2. すべての運用プロジェクトの周囲に VPC Service Controls の境界を配置し、承認されていないデータ アクセスを停止します。
3. BigQuery 管理アクティビティの監査ログで、不正アクセスの可能性がないか調べます。
この選択が間違っている理由は、即時のステップとして VPC Service Controls の使用を提案していることにありますが、これは BigQuery データセットに合わせて特別に調整されていない広範な手段です。さらに、管理アクティビティ監査ログを分析しても、監査のさまざまな側面をカバーするため、承認されていないデータ クエリに関する分析情報が得られない可能性があります。
オプション: 1. データセットのアクセス許可を更新して、パブリック アクセスを取り消します。
2. BigQuery のデータ アクセス監査ログを分析して、データセットに対する不正なクエリがないか確認します。
3. 設定エラーが修正されたら、Security Command Center で検出結果を抑制します。
この選択が正しくない理由は、アクセス許可の更新とデータ アクセス監査ログの確認は適切なアクションですが、SCC で検出結果を抑制するように指示しても、露出の影響の評価には役立たず、ダッシュボードからアラートがクリアされるだけだからです。
参考：
https://cloud.google.com/security-command-center/docs
https://cloud.google.com/storage/docs/access-logs
https://cloud.google.com/storage/docs/using-public-access-prevention
</div></details>

### Q.  問題41: 未回答
貴社の動画ストリーミング サービスを FIPS 140-2 に準拠させる取り組みとして、Google Cloud のコンピューティング リソースとネットワーク リソースを採用することが決議されました。サービス インフラストラクチャは、Managed Instance Group(MIG)を使用して Compute Engine インスタンスのプールを管理します。高速なコンテンツ配信のために、これらのインスタンスはローカルSSDを活用し、サーバー間メッセージング用のUDPを実装します。サービス開発チームは、標準に準拠するために必要な変更を行う準備ができています。
基準に準拠するために、どのような推奨事項を提案しますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、FIPS 140-2 標準に準拠したビデオ ストリーミング サービスのインフラストラクチャのセキュリティ保護について説明します。Managed Instance Group(MIG)の構成と、Google Cloud リソースを使用した保存中および転送中のデータに対する暗号化技術の正しい適用に焦点を当てています。
重要な用語:
FIPS 140-2: 暗号化モジュールを認定し、安全なデータ管理のためのコンプライアンスを確保するために使用される米国政府のコンピューターセキュリティ標準。
BoringCrypto: BoringSSL ライブラリの一部である FIPS 140-2 検証済みの暗号化モジュールで、暗号化操作に承認されたセキュリティ機能を提供します。
ローカル SSD: 仮想マシン インスタンスをホストしているサーバーに物理的に接続され、I/O 集中型のアプリケーションに低レイテンシーを提供する、高パフォーマンスのローカル ブロック ストレージ。
UDP:ユーザー・データグラム・プロトコルは、コネクションレス型ネットワーク・プロトコルで、配信や順序を保証することなく、低遅延で高速なデータ伝送を実現します。
正解解説:
(オプション)
・キャッシュデータやサーバ間通信をBoringCryptoモジュールで暗号化
この選択は、キャッシュされたコンテンツとサーバー間通信の暗号化を実装するために、BoringSSL の FIPS 140-2 検証済みサブセットである BoringCrypto モジュールの使用を推奨しています。BoringCryptoを利用することで、同社は認証に必要な厳しい暗号化要件への準拠を保証し、ローカルSSDに保存されているデータとサーバー間で転送中のデータの両方をカバーしています。
不正解の説明:
オプション: ディスクの暗号化にユーザー指定の暗号化キーを使用し、サーバー間の安全なデータ転送に BoringSSL を使用するように MIG のインスタンス テンプレートを設定します。
この選択が間違っている理由は、BoringCryptoの代わりにBoringSSLの使用を示唆しているためです。BoringSSL には BoringCrypto モジュールが含まれていますが、FIPS 140-2 に準拠するには BoringSSL を使用するだけでは不十分です。ディスク暗号化用のお客様提供の暗号化キーは、FIPS 140-2 標準に特に関連していません。
オプション:サーバー間通信プロトコルをUDPからTCPに切り替え、ストリーミングクライアントの安全なTLS接続にBoringSSLを適用します。
この選択が正しくない理由は、FIPS 140-2 準拠がトランスポート プロトコルではなく暗号化モジュールに重点を置いているためです。UDP から TCP への切り替えは、FIPS 140-2 に必要な暗号化標準には影響しません。TLSにBoringSSLを使用することはセキュリティに貢献する可能性がありますが、問題のFIPSコンプライアンスとは特に関係ありません。
オプション: MIG のインスタンス テンプレートで Google が管理する暗号化キーを使用してディスク暗号化を適用し、サーバー間メッセージングに BoringSSL ライブラリの使用を統合します。
この選択が間違っている理由は、Google が管理する暗号鍵の使用と、BoringCrypto などの特定の暗号化モジュールを必要とする FIPS 140-2 準拠を混同するためです。BoringCrypto の使用を指定せずに BoringSSL ライブラリーだけでは、サーバー間メッセージングの標準への準拠は保証されません。
参考：
https://cloud.google.com/security/fips
https://cloud.google.com/compute/docs/disks#encryption
https://cloud.google.com/compute/docs/instances/encrypt-instance-communication
</div></details>

### Q.  問題42: 未回答
クライアントは、Cloud Storage に保存されているファイルに対してオペレーションを実行する Compute Engine インスタンスを使用して、動画処理ワークロードを管理しています。これらのインスタンスが分離され、外部インターネットトラフィックと通信したり、外部インターネットトラフィックからアクセスされたりしないようにする必要があります。
この孤立を実現するために、どのような2つの戦術を実装すべきでしょうか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud Compute Engine 内のネットワーク セキュリティと分離に関する学習者の理解度を評価します。機密性の高い操作を処理するインスタンスをプライベートに保ち、外部のインターネットソースからアクセスできないようにするためのベストプラクティスに焦点を当てています。
重要な用語:
限定公開の Google アクセス: サブネット上のリソースが、外部 IP アドレスを使用せずに Google API やサービスにアクセスできるようにします。
外部 IP アドレス: Compute Engine インスタンスに関連付けられた一般公開されている IP アドレスで、インターネットから直接トラフィックを送受信できます。
正解解説:
(オプション)
・Compute Engine サブネットの限定公開 Google アクセスを有効にする
・外部 IP アドレスによる Compute Engine インスタンスのプロビジョニングを控える
限定公開の Google アクセスを有効にすると、外部 IP アドレスを持たないインスタンスは、Cloud Storage などの Google サービスをインターネットに公開することなく使用できるようになります。外部 IP アドレスをプロビジョニングしない場合、インスタンスがインターネットからアドレス指定できなくなり、外部トラフィックからの分離が維持されます。両方の方法を同時に使用すると、必要な Google サービスの接続を維持しながら、インスタンスを効果的に分離できます。
不正解の説明:
オプション: Compute Engine インスタンスが分離されたサブネット内に配置されていることを確認します
この選択が間違っている理由は、外部 IP アドレスが割り当てられている場合や、外部接続を許可する特定のネットワーク設定が有効になっている場合、Compute Engine インスタンスを分離されたサブネット内に配置するだけでは、インターネット経由でのアクセスやアクセスを本質的に防ぐことはできないためです。
オプション: グループ内の Compute Engine インスタンスの IP 転送を無効にする
IP 転送を無効にすると、インスタンスは自身の送信元 IP アドレス以外のパケットを送信できなくなります。ただし、インスタンスに外部 IP アドレスがある場合、外部インターネットトラフィックがインスタンスに到達することは制限されません。
オプション: 送信インターネット アクセス用に Cloud NAT を設定する
Cloud NAT を設定すると、外部 IP アドレスを持たないインスタンスがインターネットへの接続を開始できますが、受信接続は妨げられません。これは、インスタンスが外部インターネットと通信したり、外部インターネットからアクセスできないようにするという目的と矛盾します。
参考：
- https://cloud.google.com/vpc/docs/configure-private-google-access
- https://cloud.google.com/vpc/docs/using-private-google-access
- https://cloud.google.com/compute/docs/ip-addresses#reserved
</div></details>


### Q.  問題44: 未回答
DevOps チームは、オンラインの顧客がアクセスできる e コマース プラットフォーム向けに、Google Kubernetes Engine に新しいマイクロサービスベースのアーキテクチャをデプロイする準備をしています。マイクロサービスのセキュリティを強化するために、チームはサービスコンテナの潜在的な脆弱性を減らすことを目指しています。
どのような行動を取るべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Kubernetes Engine を使用してマイクロサービスベースの e コマース プラットフォームを保護するための DevOps チームの知識を調べます。コンテナの潜在的な脆弱性を軽減するための最も効果的な方法を特定することに重点が置かれています。
重要な用語:
コンテナセキュリティ:ビルド、出荷、実行など、DevOpsパイプラインのさまざまなフェーズでコンテナ化されたアプリケーションのセキュリティを確保する方法論、ツール、プラクティスを指します。
基本イメージ: コンテナーの構築に使用される基になるレイヤー。基本イメージが小さいほど、含まれるコンポーネントが少なくなり、潜在的な脆弱性の攻撃対象領域が小さくなるため、一般的に安全性が高くなります。
正解解説:
(オプション)
・コンテナは、ベースイメージを小さくして構築し、全体のサイズを小さくする。
コンテナーの構築に小さな基本イメージを採用することで、不要なパッケージや潜在的な脆弱性の数を減らすことで、潜在的な攻撃対象領域を大幅に最小限に抑えることができるため、この選択は適切です。イメージが小さいほど、悪用される可能性のあるコンポーネントが少なくなるだけでなく、更新やパッチの管理の複雑さも軽減されます。攻撃対象領域を制限することは、コンテナセキュリティのベストプラクティスであり、コンテナをよりスリムで効率的なものにすると同時に、セキュリティを強化します。
不正解の説明:
オプション: コンテナ イメージの構築に Google Cloud Build を採用します。
この選択が間違っている理由は、Google Cloud Build はコンテナ イメージのビルド プロセスを自動化する一方で、コンテナ内の脆弱性を本質的に軽減するものではないためです。ビルド プロセス自体では、構築中のイメージ内の攻撃対象領域が最小限に抑えられるわけではありません。
オプション: Google Container Registry から未使用のイメージタグを削除します。
この選択が間違っている理由は、Google Container Registry から未使用のイメージタグを削除することはイメージ管理に関連し、コンテナ自体の脆弱性の低減には貢献しないためです。これは、セキュリティ強化手法というよりは、ハウスキーピングのプラクティスです。
オプション: アプリケーションのデプロイ プロセスに継続的デリバリー ツールを利用します。
この選択が間違っている理由は、継続的デリバリーツールの利用がデプロイプロセスの自動化に重点が置かれているためです。アップデートや新機能を迅速に提供するためには不可欠ですが、サービスコンテナ内の脆弱性の直接的な削減には対応していません。
参考：
https://cloud.google.com/kubernetes-engine/docs/concepts/container-images
https://cloud.google.com/solutions/best-practices-for-building-containers
https://cloud.google.com/architecture/best-practices-for-operating-containers
</div></details>

### Q.  問題45: 未回答
小売会社の共有 VPC に指定された中央ネットワーク プロジェクトが、チームが意図せずに削除しないようにする必要があります。
どの組織レベルのポリシー制約をアクティブ化する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、小売企業のネットワークの安定性とセキュリティにとって重要な、共有 VPC 環境で中央ネットワーク プロジェクトが誤って削除されるのを防ぐための組織ポリシーの適用に焦点を当てています。
重要な用語:
共有 VPC: 組織が複数のプロジェクトのリソースを共通の VPC ネットワークに接続し、そのネットワークの内部 IP を使用して安全かつ効率的に相互に通信できるようにします。
組織ポリシー: 組織全体に特定の動作を適用するためにCloud Resource Manager階層リソースに適用できる一連の制約。
プロジェクト先取特権:GCPプロジェクトの偶発的な削除を防ぐためのメカニズム。一度設定すると、最初に先取特権を削除しないと、プロジェクトを削除することはできません。
正解解説:
(オプション)
・compute.restrictXpnProjectLienRemoval(コンピュート・リstrict・エクスプン・プロジェクト・リムーバル)
正しいポリシー制約「compute.restrictXpnProjectLienRemoval」は、共有 VPC セントラルプロジェクトを保護するように設計されています。これを有効にすると、ポリシーによってプロジェクトの削除を防ぐ先取特権が追加され、チーム メンバーがプロジェクトを削除しようとしても、先取特権のためにそのまま残ります。先取特権は、削除を行う前に明示的に削除して、共有 VPC を偶発的な損失から保護する必要があります。
不正解の説明:
オプション: compute.restrictSharedVpcHostDeletion
この選択が間違っている理由は、共有 VPC ホスト プロジェクトの削除の防止に言及しており、特に主要なプロジェクトの削除を妨げる先取特権の削除に対するセーフガード メカニズムに言及していないためです。
オプション: Comput.Limitshared Expansion
この選択が正しくない理由は、共有 VPC セットアップ内のサブネットの拡張に制約があることを示唆しているためです。これは、セントラルネットワークプロジェクトの削除に対する保護とは関係ありません。
オプション: compute.designateSharedVpcOwnerProjects
この選択が正しくない理由は、共有 VPC プロジェクトの意図しない削除に対する制限を課すのではなく、共有 VPC 構造内のプロジェクトに所有者ロールを割り当てることを意味するためです。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/vpc/docs/shared-vpc
https://cloud.google.com/resource-manager/docs/creating-managing-liens
</div></details>

### Q.  問題46: 未回答
Google Cloud 環境内で一元化されたセキュリティ プロトコルを確立しました。組織内の特定のディレクトリに対して、仮想マシン (VM) に外部 IP アドレスが割り当てられないようにする組織のポリシーを実装しました。
ただし、数日後、そのディレクトリ内で外部 IP アドレスを持つ新しい VM が検出されたことが通知されます。
このアラートの理由は何である可能性がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の階層型リソース管理とポリシー適用メカニズムの理解を深めます。これは、外部 IP を防止するように設計された組織のポリシーにもかかわらず、VM が外部 IP を持つ可能性がある理由を診断する個人の能力をテストします。
重要な用語:
組織ポリシー: 特定のサービス構成と制限を大規模に適用するために、Google Cloud リソース階層全体に適用される一連の制約。
リソース階層: 組織が組織、フォルダ、プロジェクト、リソースなどのリソースを階層的に配置、管理できるようにする Google Cloud の構造化メカニズム。
ポリシーの継承: 明示的にオーバーライドされない限り、下位レベルが上位レベルからポリシーを継承して、リソース階層全体にポリシーが適用されるメカニズム。
ポリシーのオーバーライド: リソース階層の下位レベルにポリシーを設定するアクションで、上位レベルから継承されたポリシーと矛盾し、優先されます。
正解解説:
(オプション)
・プロジェクトレベルでは、外部IPアドレスを許可するように組織のポリシー制御がオーバーライドされています。
この選択は、VM が外部 IP アドレスを持つのを防ぐことを目的とした組織のポリシーがプロジェクト レベルでオーバーライドされたシナリオを正しく説明しています。Google Cloud のポリシーは、リソース階層のさまざまなレベルで調整でき、ディレクトリまたはフォルダに適用されたポリシーは、プロジェクトまたはリソース レベルでのより具体的な設定に置き換えることができます。この場合、適切なアクセス許可を持つユーザーが特定のプロジェクトのポリシーを変更して外部 IP の割り当てを許可し、より広範な組織ポリシーを無効にしました。
不正解の説明:
オプション: VM には、組織のポリシーの実装前にプロジェクトに割り当てられていた静的外部 IP アドレスが割り当てられました。
この選択が間違っている理由は、Google Cloud の組織ポリシーによって外部 IP の新規割り当ては禁止されますが、以前に割り当てられた IP にさかのぼって影響することはないためです。既存の静的外部 IP は、ポリシーの実装後も、オーバーライドを必要とせずに VM に割り当てることができます。
オプション: 組織ポリシーの適用は完全には有効ではなく、現在 "ドライ ラン" モードで実行されています。
この選択が間違っている理由は、Google Cloud の組織ポリシーが保存後すぐに適用されるという事実にあります。Google Cloud にポリシーを適用するための「リハーサル」モードはありません。アクティブになると、有効になります。
オプション: ディレクトリ レベルでのポリシー制限は、上位の組織レベルでの同じポリシーの "許可" 値により無効になります。
この選択が間違っている理由は、Google Cloud のリソース管理とポリシー アプリケーションの階層的な性質に基づいています。ポリシーは下位に継承されるため、ディレクトリ レベルまたはプロジェクト レベルでオーバーライドが指定されていない限り、ディレクトリ レベルで設定されたポリシーを上位の組織レベルのポリシーによって無効にすることはできません。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/understanding-hierarchy
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address#reserve_new_static
</div></details>

### Q.  問題47: 未回答
ヘルスケア業界では、仮想相談プラットフォームを介して患者と対話するときに、機密情報を含む健康記録の画像をアップロードすることがあります。コンプライアンス部門は、サービス品質分析のために内部スタッフとサードパーティの監査人の両方がアクセスする定期的なプラットフォーム監査ログに含まれる可能性のある、この機密性の高い健康情報(SHI)の保護に関する懸念を提起しています。
分析目的でのデータの有用性を維持しながら、この問題に対処するにはどうすればよいでしょうか。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、医療分野のプラットフォーム監査ログ内の機密性の高い健康情報の機密性を確保する方法を取り上げます。特に、サービス品質分析におけるデータの有用性を可能にするデータ保護戦略に焦点を当てています。
重要な用語:
データ損失防止 (DLP) API: データ検査、分類、および秘匿化機能を提供するサービス。これは、組織全体の機密データの管理、分類、編集を支援するように設計されています。
墨消し: ドキュメントまたは画像から機密情報を削除するプロセス。DLP のコンテキストでは、秘匿化により、機密データが表示されたりアクセスされたりしないようにします。
画像検査: 画像内の機密データを検出して検査できる DLP API の機能で、組織は画像の保存と共有に関連するリスクを管理できます。
正解解説:
(オプション)
・Data Loss Prevention (DLP) API の画像検査および秘匿化機能を使用して、監査ログに保存される前に画像から SHI を削除します。
データ損失防止 (DLP) API の画像検査および編集機能は、画像内の機密情報の識別と削除に特化しているため、この選択は適切です。これにより、医療機関は監査ログにSHIが誤って保存または共有されないようにし、ログの分析の有用性を犠牲にすることなくコンプライアンス上の懸念に対処できます。これらの機能により、画像の自動スキャンと、画像が保存される前に特定された機密コンテンツの削除が可能になり、データのプライバシーを維持できます。
不正解の説明:
オプション: Google Cloud Key Management Service を利用して、患者がアップロードした画像に含まれる SHI を、監査ログにコミットする前に暗号化します。
これが間違っている理由は、Google Cloud Key Management Service(KMS)はデータを暗号化しますが、画像内のデータは変更しないためです。SHIは監査ログの画像に残り、暗号化されたSHIは、承認されたエンティティがアクセスした場合にプライバシー上の懸念を引き起こす可能性があります。
オプション: オブジェクトライフサイクル管理を実装して、SHIを含むすべてのプラットフォームログが自動的に削除され、品質分析のために保持されないようにします。
これが間違っている理由は、オブジェクト・ライフサイクル管理はログの削除を自動的に管理できますが、SHIは無差別に削除されるためです。これにより、データがサービス品質分析に使用されなくなり、質問で表現されたニーズに反します。
オプション: データ損失防止 (DLP) API の一般化および分類機能を使用して、将来のレビューのためにログに記録される前に、テキスト データ内の SHI を難読化します。
これが間違っている理由は、DLP API の一般化および分類機能によってテキスト データ内の SHI を難読化できる一方で、この質問では、テキストベースのデータではなく SHI を含む画像に対処する必要があることが明記されているためです。
参考：
https://cloud.google.com/dlp/docs/transformations-reference
https://cloud.google.com/dlp/docs/automating-dlp
https://cloud.google.com/dlp/docs/concepts-limitations
</div></details>

### Q.  問題48: 未回答
Compute Engine でホストされているオンライン リテール プラットフォームへのアクセスで問題が発生しています。ファイアウォール設定の調整が原因である可能性があると思います。ファイアウォールの設定が正しく設定されているかどうかを確認する必要があります。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ファイアウォールの設定に関連する可能性のある Compute Engine 内のネットワークの問題の診断について説明します。推奨されるアクションは、ネットワークの動作を追跡および分析して接続の問題を特定して解決するための手法を中心に展開されます。
重要な用語:
ファイアウォールルールのログ記録: ファイアウォールルールイベントのログを記録、保持、アクセスし、ファイアウォールルールによって許可または拒否されたトラフィックを可視化できる機能。
Logs Explorer: Google Cloud のオペレーション スイート内のツールで、ログデータに対して複雑なクエリを実行するための包括的なインターフェースを提供し、ユーザーがログイベントを検索、並べ替え、分析できるようにします。
VPC フローログ: 仮想マシンインスタンスとの間で送受信されるネットワークフローのログ記録を可能にする機能で、ネットワークのパフォーマンスとセキュリティに関する貴重な洞察を提供します。
要塞ホスト: 外部アクセス・ポイントからプライベート・ネットワークへの入り口として使用される、セキュアで強化されたインスタンスで、通常はセキュアな管理タスクを容易にします。
正解解説:
(オプション)
・最近変更したファイアウォール設定のファイアウォールルールログを有効にする。ログエクスプローラーを使用して、構成が意図したとおりに機能しているかどうかを評価します。
この選択肢は、Google Cloud のネイティブ ログ機能を使用して接続の問題をトラブルシューティングすることを前提としています。ファイアウォールルールロギングは、ファイアウォールルールに関連するトラフィックの詳細な調査を提供し、ログエクスプローラーは、収集されたログデータを効率的に確認および問い合わせるための堅牢なプラットフォームを提供します。最近調整されたファイアウォール構成でログ記録を有効にし、ログエクスプローラーで結果を評価することは、お客様が経験した問題がこれらの変更によるものかどうかを検証する直接的な方法です。
不正解の説明:
オプション: VPC ネットワーク内で踏み台ホストを利用します。ネットワークトラフィックアナライザーを利用して、ネットワークトラフィックが妨害されている場所を特定します。
この選択が正しくない理由は、要塞ホストは管理アクセスのセキュリティ保護に役立ち、ネットワーク分析ツールはトラフィックの問題を診断できますが、この方法を使用しても、ファイアウォール構成が接続の問題の原因であるかどうかを直接特定できないためです。
オプション: ステージング環境では、各ファイアウォール ルールを体系的に非アクティブ化して、ユーザーへのトラフィックを妨害しているファイアウォール ルールを特定します。
この選択が間違っている理由は、ステージング環境でファイアウォールルールを体系的に非アクティブ化すると、問題のあるルールを特定するのに役立つ可能性がありますが、時間がかかり、本番環境の複雑さやデータトラフィックを複製できない可能性があるためです。
オプション: ネットワークの VPC フローログをオンにします。ログエクスプローラーを使用してネットワークトラフィックを分析し、ファイアウォール設定が正しく動作しているかどうかを推測します。
この選択が間違っている理由は、VPC フローログはすべてのネットワークフローの包括的な分析に使用でき、ファイアウォールルールが正しく設定されていないかどうかを推測するのに役立ちますが、ファイアウォールルールログのように個々のファイアウォールルールエンゲージメントに関する詳細な情報は提供されないためです。
参考：
https://cloud.google.com/network-connectivity/docs/firewall-insights/using-fw-insights
https://cloud.google.com/network-connectivity/docs/firewall-logging
https://cloud.google.com/compute/docs/instances/connecting-advanced#third_party_tools
</div></details>

### Q.  問題49: 未回答
お客様は、潜在的な脅威や不正な変更がないか電子メールの内容を評価する責任があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、クラウドネットワーク内のセキュリティの観点から、電子メールコンテンツの整合性を分析し、確保するために従うべき戦略を取り上げます。焦点は、電子メールトランザクションの潜在的な脅威や不正な変更を検出するための適切なツールを特定して適用することです。
重要な用語:
Packet Mirroring: ネットワーク パケットのストリームを複製し、そのコピーを指定された Compute Engine VM に送信するネットワーク機能で、セキュリティ ツールとモニタリング ツールを使用してリアルタイムのトラフィック インスペクションを可能にします。
セキュリティ分析ツール:ネットワークインフラストラクチャのセキュリティ体制を監視、評価、および管理するために使用されるソフトウェアアプリケーションまたはサービス。一般的な機能には、脅威の検出、侵入分析、コンプライアンス レポートなどがあります。
正解解説:
(オプション)
・Packet Mirroring を使用して、特定の Compute Engine インスタンスにトラフィックを複製する。セキュリティ分析ツールを使用して、複製されたトラフィックを調べます。
Packet Mirroring は、指定されたソースからミラーリングされたトラフィックをキャプチャし、セキュリティ分析ツールを使用できる監視対象インスタンスに送信するため、この選択は適切です。これにより、メールサーバーが送受信するデータを正確に調べることができ、メールの内容に不正な変更や潜在的な脅威などの悪意のあるアクティビティをほぼリアルタイムで正確かつ包括的に検出できます。
不正解の説明:
オプション: Virtual Private Cloud 内のすべてのサブネットワークで VPC フローログをアクティブ化します。Cloud Logging を使用してフローログ情報を分析します。
この選択が間違っている理由は、VPC フローログがネットワークパケットの実際のコンテンツではなく、ネットワークフローに関する洞察を提供するためです。VPC フローログは、ネットワークのモニタリングやフォレンジック分析に役立ちますが、メールコンテンツの脅威や改ざんを分析するために必要なペイロード検査は提供しません。
オプション: Virtual Private Cloud 内の各 Compute Engine インスタンスに Fluentd エージェントをインストールします。Cloud Logging を使用してログデータを分析します。
この選択が間違っている理由は、Fluentdが統合ロギングレイヤーを構築およびスケーリングするためのデータコレクターであるためです。さまざまなソースからログをキャプチャして Cloud Logging に転送できますが、パケット レベルでセキュリティ上の脅威についてメール コンテンツを特に評価するようには設計されていません。
オプション: Google Cloud Armor セキュリティ ポリシーを設定し、分析のためにセキュリティ ログを検査します。
この選択が間違っている理由は、Google Cloud Armor が DDoS 防御やアプリケーション認識型防御などの保護を提供するためです。Cloud Armor は、さまざまなタイプの攻撃からアプリケーションを保護するために重要ですが、パケットレベルの検査を実行しないため、メール コンテンツのモニタリングには適していません。
参考：
https://cloud.google.com/traffic-director/docs/packet-mirroring
https://cloud.google.com/vpc/docs/using-flow-logs
https://cloud.google.com/armor/docs/logging-and-monitoring
</div></details>

### Q.  問題50: 未回答
貴社は、Google Cloud のさまざまな環境に複数のデータベース スキーマと対応するデータ トランスフォームをデプロイするための新しいリリース自動化戦略を確立しています。エンジニアリング部門の各チームは、Google Cloud SQL でサポートされる独自のリリース自動化ワークフローを運用します。これらの自動化シーケンスは、Google Cloud サービスと安全に接続する必要があります。
これらのシーケンスはどのように構成する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Kubernetes 環境内でのサービス アカウント管理、アクセス制御、職務分掌に焦点を当てて、Google Cloud でのデータベース デプロイの安全な自動化戦略の構成に関する知識を評価します。
重要な用語:
Workload Identity: きめ細かな権限を持つ Kubernetes サービス アカウントに Google サービス アカウントを割り当てることで、GKE で実行されているアプリケーションが他の Google Cloud サービスに安全にアクセスできるようにする GCP の機能。
サービス アカウント: Google API のデータにアクセスするために認証と承認を必要とする、人間以外のユーザーを表すように設計された特別なタイプの Google アカウント。
名前空間: 複数のユーザー間でクラスター リソースを分離し、アクセス制御を管理するために使用される Kubernetes の機能。
データ変換プロセス: クエリと分析の目的で、ソース形式から必要な出力形式または構造にデータを操作または変換する ETL パイプライン内の操作。
正解解説:
(オプション)
・データベーススキーマ変更用とデータ変換用を2つのサービスアカウントに作成します。ワークロード ID を利用して、これらのタスクを実行するコンテナーがこれらのサービス アカウントで認証できるようにします。スキーマ変更シーケンスとデータ変換プロセス用に個別の名前空間を定義します。
この選択は、役割の分割と最小特権のベスト プラクティスを概説するため、推奨されます。データベース スキーマの変更用とデータ変換用の 2 つのサービス アカウントを作成することで、懸念事項を分離し、タスクの実行に必要最小限のアクセス許可を最小限に抑えます。ワークロード ID を使用して、キーをエクスポートせずにコンテナーをこれらのサービス アカウントに結合すると、セキュリティが強化されます。これらを別々の名前空間に整理すると、リソースが分離され、アクセス許可とアクセスがさらにカプセル化されます。
不正解の説明:
オプション: 自動化シーケンスの特定のサービス アカウントを生成します。Google Cloud SQL インスタンスの排他的なノードプールで実行する自動化シーケンスを設定します。サービス アカウントをプール内のノードのプリンシパルとして割り当て、Google Cloud サービスで認証します。
この選択が正しくない理由は、自動化シーケンスを 1 つのサービス アカウントに統合し、ノード プールに割り当てることで特権を過剰にするためです。また、Google Cloud SQL 上の 1 つの排他的ノードプールで実行すると、Google Cloud の分散アーキテクチャを効果的に活用できない可能性があります。
オプション: 個別のデータベーススキーマリリースおよびデータ変換操作ごとに個別のサービスアカウントを作成します。サービス アカウント名に識別ラベルを追加して、対応する操作を反映します。各操作が分離されたコンテナーで実行されるようにします。ワークロード ID を適用して、各データベースまたはデータ変換コンテナーを個別のサービス アカウントとペアリングします。
このオプションは、操作ごとに多数のサービス アカウントを作成することで不必要な複雑さを増すため、正しくありません。これほど多くのサービス アカウントの管理は負担になる可能性があり、ラベル付けではアクセス許可やセキュリティ上の利点は提供されません。ワークロード ID は、このような粒度がなくても活用できます。
オプション:スキーマおよびデータトランスフォーム操作ごとに個別のサービスアカウントを作成します。これらのサービス アカウントの秘密キーを作成してダウンロードします。Kubernetes シークレットの秘密キーを保護し、特定のスキーマまたは変換プロセスを実行するように設定されたコンテナーのみがそれらにアクセスできるようにします。
個々のサービス アカウントを作成し、秘密キーをダウンロードすると、これらのキーが侵害される可能性があるため、セキュリティ上のリスクが生じます。Kubernetes シークレットを使用して秘密キーを格納することは、スケーリングがうまくいかず、そのようなキーを管理する必要がないワークロード ID を使用するほど安全ではありません。
参考：
https://cloud.google.com/kubernetes-engine/docs/concepts/workload-identity
https://cloud.google.com/iam/docs/service-accounts
https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/
</div></details>

## 5

### Q.  問題1: 未回答
Google Cloud でホストされているクライアントの e コマース プラットフォームを確認したところ、複数の Compute Engine インスタンスにパブリック IP アドレスが割り当てられていることに気付きました。クライアントは、これらのインスタンスは支払い処理のためにさまざまな外部APIにアクセスする必要があると説明しています。
パブリック IP アドレスの必要性を排除しながら、インスタンスが外部サービスにアクセスできるようにするには、どのソリューションを提案できますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Compute Engine インスタンスにパブリック IP アドレスを割り当てることなく、外部サービスへの安全なプライベート アクセスを可能にする Google Cloud ネットワーキング コンポーネントに関する知識を評価します。プライベート・アクセス・オプションと、インスタンスをインターネットに公開することの影響を理解する必要があります。
重要な用語:
クラウドNAT: クラウド・ネットワーク・アドレス変換(NAT)を使用すると、パブリックIPアドレスを持たないインスタンスがインターネットへのアウトバウンド接続を開始できるため、直接公開されることなく外部APIにアクセスできます。
正解解説:
(オプション)
・クラウドNAT
クラウドNATは、仮想プライベートクラウド(VPC)のプライベートサブネット内のインスタンスがパブリックIPアドレスを割り当てられずにインターネットにアクセスする方法を提供するため、正しい選択です。Cloud NAT を使用することで、インスタンスはネットワークのセキュリティ体制を維持しながら、外部の決済処理 API へのアウトバウンド接続を行うことができます。これにより、パブリックインターネットの露出に関連するリスクが排除され、要件に基づいてVPCごとまたは個々のインスタンスごとに構成できます。
不正解の説明:
オプション: Google Cloud Armor
Google Cloud Armorが適していない理由は、Google CloudでホストされているリソースにDDoS保護とアプリケーションベースの防御を提供するためです。パブリックIPのないインスタンスからインターネットへのアウトバウンド接続を有効にするようには設計されていません。
オプション:クラウドルーター
Cloud Router が正しくない理由は、Cloud Router が Google VPC とオンプレミス ネットワーク間のハイブリッド ネットワーキングの動的ルーティングの目的を果たしているためです。これにより、外部APIへの安全なアクセスのためのパブリックIPアドレスの削除ではなく、BGPルーティングが容易になります。
オプション:クラウドVPN
Cloud VPN が適切なソリューションではない理由は、Google Cloud VPC と外部ネットワークの間に安全なトンネルを確立する一方で、パブリック IP アドレスのないインスタンスには送信インターネット アクセスを提供しず、外部 API アクセス用に設計されていないためです。
参考：
https://cloud.google.com/nat/docs/overview
https://cloud.google.com/compute/docs/ip-addresses/reserve-static-external-ip-address#reserve_new_static
Hatpas://cloud.google.com/vpc/doc/vpc
</div></details>

### Q.  問題2: 未回答
編集ソフトウェアがサブネット C のマネージド インスタンス グループでホストされ、メディア ファイルが同じ VPC ネットワーク内のサブネット D の Redis Compute Engine 仮想マシン(VM)に保存されている動画処理システムを管理します。サブネット C と D は、さまざまなタスク用に追加の Compute Engine VM もサポートしています。ビデオ編集フロントエンドのみが、特にポート 6379 を介して、アプリケーションの Redis インスタンスからデータを取得できるようにする必要があります。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud Platform 環境でのネットワーク アクセスの保護に関する理解度を評価します。これには、あるサブネット内のビデオ処理システムのフロントエンドが別のサブネット内の Redis インスタンスにアクセスする必要があるシナリオのサービス アカウント ベースのファイアウォール規則に関する知識が必要です。
重要な用語:
マネージド インスタンス グループ: 同一の VM のグループを管理し、フェイルオーバーを処理し、自動修復を行うことでアプリケーションの可用性を確保する Google Cloud の自動スケーリング サービス。
サービス アカウント: 個々のエンドユーザーではなく、アプリケーションまたは仮想マシンに属する特別な Google アカウント。これは、アプリケーションを認証し、API アクセスを許可するために使用されます。
イングレス・ファイアウォール・ルール: ネットワーク・エンドポイントへの到達が許可される接続を定義します。これらのルールは、さまざまなソースから Compute Engine VM への受信トラフィックを管理します。
エグレス ファイアウォール ルール: Google Cloud ネットワーク内の一連のインスタンスから出られる接続を指定します。エグレス・ルールは、アウトバウンド通信を制御します。
ネットワーク タグ: Google Cloud 仮想マシンに割り当てることができるラベルで、インスタンスとの間のトラフィックを識別するためにファイアウォール ルールによって使用されます。
VPC ネットワーク: Compute Engine VM、ロードバランサ、その他のネットワーク関連リソースにネットワーク機能を提供する Google Cloud のカスタム仮想ネットワーク。
Redis: インメモリ データ構造ストアで、データベース、キャッシュ、およびメッセージ ブローカーとして一般的に使用されます。この場合は、Compute Engine VM にデプロイされます。
正解解説:
(オプション)
・ポート6379で、編集ソフトウェア固有のサービスアカウントからRedis Compute Engine VMの一意のサービスアカウントへの通信を許可するイングレスファイアウォールルールを設定します。
この選択は、サービス アカウントの ID をセキュリティに活用し、IP アドレスやタグに依存するよりも柔軟で安全であるため、アクセスを制御するのに適した方法です。一意のサービスアカウントがアタッチされたマネージドインスタンスグループから、特にRedis VMのサービスアカウントへの通信をポート6379に対してのみ許可するファイアウォールルールを指定することで、ビデオ編集ソフトウェアのみがRedisインスタンスに接続できるようにし、これらの個別のサービスアカウント間のトラフィックのホワイトリストを効果的に作成します。
不正解の説明:
オプション: サブネット C の IP アドレス範囲から、ポート 6379 で Redis Compute Engine VM に割り当てられているタグ「media-tag」へのトラフィックを許可するイングレス ファイアウォール ルールを構成します。
この選択が正しくない理由は、サブネット C の IP アドレス範囲に依存しているためです。同じサブネットに他の VM インスタンスが存在する場合は、Redis インスタンスにアクセスできる可能性があります。また、特定のサービスやアカウントへのトラフィックを制限しないため、精度と柔軟性に欠けます。
オプション: サブネットCのすべてのインスタンスにネットワーク・タグ「editor-tag」を割り当て、サブネットDのすべてのインスタンスにネットワーク・タグ「media-tag」を割り当てます。 「media-tag」でマークされたインスタンスから「editor-tag」でマークされたインスタンスへのトラフィックを許可するエグレス・ファイアウォール・ルールを作成します。
この選択が正しくない理由は、間違った方向のトラフィックを許可するエグレス ファイアウォール ルールが作成されるためです。Redisインスタンスからのエグレスではなく、Redisインスタンスへのイングレスルールに関係しています。さらに、ビデオ編集ソフトウェアのみへのアクセスを効果的に制限するわけではありません。
オプション: サブネット C 内のすべての VM インスタンスにネットワーク タグ 'editor-tag' を割り当て、サブネット D のすべてのインスタンスにネットワーク タグ 'media-tag' を割り当てます。次に、"editor-tag" を持つ VM から "media-tag" を持つ VM へのトラフィックを許可するイングレス ファイアウォール規則を設定します。
この選択が正しくない理由は、サービス アカウント ベースのルールよりも安全性の低いネットワーク タグ ベースのファイアウォール ルールが設定されるためです。タグはサブネット C と D 内のすべてのインスタンスに適用され、目的の Redis インスタンスだけでなく、"editor-tag" を持つすべての VM が "media-tag" を持つ任意の VM にアクセスできる可能性があります。
参考：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/compute/docs/instances/managing-instance-access
https://cloud.google.com/iam/docs/understanding-service-accounts
</div></details>

### Q.  問題3: 未回答
医療会社は、重要でないと分類されたデータのキー管理オーバーヘッドを最小限に抑える必要があり、主要な地域とローテーション期間の管理を可能にすることでPHI(保護された医療情報)の保護を保証する保存データの暗号化ポリシーを実装しています。HIPAA規制への準拠は、すべてのカテゴリのデータで必須です。
あなたは何をするべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、HIPAA 規制への準拠と、重要な医療データと重要でない医療データの両方を保護しながら暗号化鍵を効率的に管理するために Google Cloud で利用できるデータ暗号化オプションに関する受験者の理解度を評価します。
重要な用語:
PHI:保護医療情報(PHI)は、HIPAAなどの厳しい規制基準の対象となる医療における機密情報であり、暗号化と管理の方法に特に注意を払う必要があります。
Google が管理する暗号化: Google がユーザーの介入なしに暗号鍵とそのライフサイクルを処理する暗号化サービスで、通常は機密性の低い情報に使用されます。
クラウドキー管理サービス:ユーザーが自分で暗号化キーを作成、管理、ローテーションできるクラウドサービスで、暗号化プロセスをより詳細に制御できます。
キーの地域: 暗号化キーが保存および管理される物理的な場所または管轄区域を指し、地域またはセクター固有の規制への準拠に影響を与える可能性があります。
HIPAA: 1996 年の医療保険の相互運用性と説明責任に関する法律は、米国における機密性の高い患者データの保護に関する基準を定めています。
キーローテーション: データのセキュリティ保護に使用される暗号化キーを定期的に変更することで、キーが侵害された場合に公開されるデータの量を制限する方法。
Cloud External Key Manager: Google のインフラストラクチャ外部にあるサードパーティの鍵管理システムに保存され、管理されている暗号鍵をお客様が使用できるようにする Google Cloud サービス。
正解解説:
(オプション)
・重要でないデータはGoogleが管理する暗号化で暗号化し、PHIはCloud Key Management Serviceで暗号化し、HIPAAへのコンプライアンスを確保します。
この選択は、重要でないデータに Google が管理する暗号化を使用することで、データ保護を確保しながら鍵管理のオーバーヘッドを削減することで、コンプライアンスと管理の効率化に最適です。より厳格な監視が必要なPHIの場合、HIPAAコンプライアンスを維持するために重要な主要な地域とローテーション期間を管理できるため、Cloud Key Management Serviceをお勧めします。この組み合わせは、効率性と規制遵守の両方のニーズを満たします。
不正解の説明:
オプション: Cloud External Key Manager を使用して、個別の管理設定を無視して、重要でないデータと PHI の両方を暗号化します。
この選択が間違っている理由は、重要でないデータのキー管理オーバーヘッドを最小限に抑えるという会社の要件に対応していないためです。さらに、Cloud External Key Manager を使用すると、会社の管理設定が無視され、コンプライアンスの取り組みが複雑になる可能性があります。
オプション: Cloud Key Management Service を適用して、重要でないデータと PHI の両方の暗号化を区別せずに処理します。
この選択が間違っている理由は、重要でないデータと PHI の両方に Cloud Key Management Service を使用した包括的な暗号化戦略を不必要に適用するためです。これでは、機密性の低いデータの管理オーバーヘッドが最小限に抑えられるわけではなく、重要でないデータや重要なデータに対する会社の差別化された管理設定とは一致しません。
オプション: 鍵管理ポリシーに関係なく、Google が管理する暗号化を使用して重要でないデータを保護し、Cloud External Key Manager を使用して PHI を保護します。
この選択が間違っている理由は、重要でないデータには Google が管理する暗号化を適切に使用する一方で、鍵管理に関する特定の企業ポリシーを考慮せずに PHI に Cloud External Key Manager を使用することを誤って提案しているため、鍵の地域とローテーションに関連する HIPAA コンプライアンスに違反する可能性があるためです。
参考：
https://cloud.google.com/security/encryption/default-encryption
https://cloud.google.com/kms/docs
https://cloud.google.com/docs/compliance/standards/fips
</div></details>

### Q.  問題4: 未回答
医療機関が Google Workspace を利用しており、Google App Engine でホストされる患者管理システムを開発している。特に従業員の資格情報が侵害された場合、権限のない個人がこのシステムにアクセスできないようにすることが重要です。
このような状況で、外部からのアクセスを最も効果的に防ぐことができるのはどの手段ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google App Engine 上の医療機関の患者管理システムを、従業員の認証情報の漏洩による不正アクセスから保護するための最適なセキュリティ対策を評価します。Google Workspace のセキュリティ機能とその適用範囲について理解する必要があります。
重要な用語:
2 段階認証: ユーザーが知っているもの (パスワード) とユーザーが持っているもの (確認コード用のデバイス) の 2 種類の認証を必要とするユーザー アカウント用の追加のセキュリティ層。
Cloud Identity-Aware Proxy(IAP): Cloud IAP は、ユーザーの ID を検証し、そのユーザーにアクセスを許可するかどうかを決定することで、Google Cloud で実行されているクラウド アプリケーションへのアクセスを制御します。
Google Workspace Password Sync: Google Workspace ユーザーのパスワードを Microsoft Active Directory または LDAP サーバーと同期し、内部サービスとクラウド サービス間で 1 つのパスワードを保持するツールです。
Cloud VPN: ユーザーは、暗号化されたトンネルを介して、パブリック インターネット経由でオンプレミス ネットワークを Google Cloud Platform のネットワークに安全に接続できます。
正解解説:
(オプション)
・Google Workspace 全体で全従業員に 2 段階認証を導入
この選択は、侵害された可能性のある資格情報を補正するセキュリティのレイヤーを追加することでリスクに直接対処できるため、最も効果的です。2 段階認証では、従業員が Google Workspace や Google Workspace に統合されたアプリ(App Engine の患者管理システムなど)にアクセスするために、パスワード以外の 2 つ目の身分証明書を提供する必要があります。これにより、攻撃者は従業員の二次的な検証デバイスや方法にもアクセスする必要があるため、資格情報の盗難による不正アクセスの可能性が大幅に減少します。
不正解の説明:
オプション: Cloud Identity Aware Proxy を実装して、App Engine アプリケーションをセキュリティで保護します。
これが間違っている理由は、Cloud Identity-Aware Proxy はユーザー ID の管理と検証によってセキュリティ レイヤを追加しますが、認証情報がすでに盗まれている場合にバイパスされる可能性のある最初の検証手順に依存しているため、認証情報の侵害から保護されないためです。
オプション: Google Workspace Password Sync を使用して従業員のパスワードを同期します。
これが間違っている理由は、Google Workspace Password Sync がセキュリティを強化することよりも、システム間でパスワードの統一性を維持することに重点を置いているためです。従業員の資格情報が侵害された場合、攻撃者は実際のパスワードを持っているため、不正アクセスを防ぐことはできません。
オプション: Cloud VPN を設定して、企業ネットワークと Google Cloud の間に安全な接続を確立します。
これが間違っている理由は、Cloud VPN がネットワーク間に安全な通信チャネルを作成するように設計されているためです。Google Cloud リソースへの暗号化されたアクセスを提供しますが、侵害された認証情報がシステムへのアクセスに使用されるのを防ぐことはできません。
参考：
https://cloud.google.com/identity/docs/how-to/setup-two-step-verification
https://cloud.google.com/iap/docs/app-engine-quickstart
https://cloud.google.com/vpn/docs/concepts/overview
</div></details>

### Q.  問題5: 未回答
あるヘルスケア企業は、コンピューティング インフラストラクチャの管理に Google Cloud の導入を検討しています。また、患者情報とアクセス管理を管理する堅牢な電子カルテ(EHR)システムを導入しています。同社は、このEHRシステムをユーザー管理用の信頼できるIDリポジトリとして保持したいと考えています。
現在の ID ディレクトリを Google Cloud サービスと同期したいという医療機関のニーズに合致する Google Cloud サービスはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、特にデータのセキュリティとコンプライアンスが重要な医療のコンテキストにおいて、ユーザー管理の目的で、既存のオンプレミスの ID ディレクトリを Google Cloud と統合するための適切な Google Cloud サービスを選択する受験者の能力を評価します。
重要な用語:
Google Cloud Directory Sync(GCDS): GCDS は、既存の LDAP 準拠ディレクトリ(Microsoft Active Directory など)と Google Cloud の ID サービスの間でユーザーデータを同期し、ユーザー アカウントとアクセス権を連携させるツールです。
正解解説:
(オプション)
・Google Cloud Directory Sync(GCDS)
Google Cloud Directory Sync(GCDS)は、EHR ID リポジトリなどの既存の LDAP 準拠ディレクトリから Google Cloud にユーザー アカウントを同期できるため、医療機関企業にとって適切な選択肢です。ユーザーとグループのプロビジョニングのプロセスが自動化されるため、新しいユーザーが EHR システムに追加されると、その情報が自動的に Google Cloud に反映され、ID 管理とアクセス制御が合理化されます。
不正解の説明:
オプション: Cloud Identity
この選択が間違っている理由は、Cloud Identity が ID 管理とデバイス管理機能を提供する Identity as a Service(IDaaS)ソリューションであるためです。同期機能を提供しますが、EHR システムなどのオンプレミス ディレクトリとの同期用に特別に設計されていません。
オプション: OpenID Connect (OIDC)
この選択が間違っている理由は、OpenID Connect (OIDC) が承認フレームワークである OAuth 2.0 の上位の認証レイヤーであるためです。これはフェデレーション ID に使用されますが、医療会社がユーザー管理のために EHR システムを保持する必要がある場合に必要なディレクトリ同期サービスは提供しません。
オプション: BigQuery
この選択が間違っている理由は、BigQuery が分析用のフルマネージド エンタープライズ データ ウェアハウスであるためです。ID の同期やユーザー管理とは関係がないため、EHR システムを Google Cloud サービスと同期するための医療機関の要件とは関係ありません。
参考：
https://cloud.google.com/identity/docs/sync
https://cloud.google.com/solutions/federating-Google Cloud-with-active-directory-introduction (クラウドとアクティブディレクトリの紹介)
</div></details>

### Q.  問題6: 未回答
XSS や SQLi などのユビキタスな脅威から財務報告ウェブアプリケーションを保護するために、Google Cloud Armor セキュリティ ポリシーを設定しようとしています。
Google Cloud Armor セキュリティ ポリシーを採用するための 2 つの前提条件は何ですか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ウェブ アプリケーションを保護するために Google Cloud Armor を実装するために必要な知識を評価します。具体的には、クロスサイト スクリプティング(XSS)や SQL インジェクション(SQLi)などの一般的なウェブの脅威に対する防御に関連する、Google Cloud Armor セキュリティ ポリシーを適用するために必要な前提条件を理解することに重点を置いています。
重要な用語:
外部負荷分散: Google Cloud では、外部ロードバランサが複数のリージョンにある Google Cloud リソース間で受信トラフィックを分散します。これは、グローバルなトラフィック管理とサービスの高可用性を確保するために重要な側面です。
HTTP(S) ロードバランサー: HTTP(S) ロードバランサーは、すべての HTTP および HTTPS トラフィックに対して完全に分散されたソフトウェア定義のマネージドサービスであり、URL マップやホストルールなどの高度なトラフィック管理機能を提供します。
正解解説:
(オプション)
・バックエンドサービスは、外部負荷分散スキームで設定する必要があります。
・Webアプリケーションは、外部HTTP(S)ロードバランサーの背後に配置する必要があります。
Google Cloud Armor のセキュリティ ポリシーは、外部 HTTP(S) 負荷分散を利用するウェブ アプリケーションを保護するように本質的に設計されているため、これらの選択は適切です。ロードバランサは受信トラフィックのエントリ ポイントとして機能し、Google Cloud Armor が脅威に対する保護フィルタを適用できるようにします。Google Cloud Armor はセキュリティ ポリシーの内部負荷分散スキームをサポートしていないため、外部ロードバランサを使用してバックエンド サービスを構成することは、Google Cloud Armor の実装に不可欠です。
不正解の説明:
オプション: 外部 TCP プロキシ ロード バランサを使用している必要があります。
この選択が間違っている理由は、Google Cloud Armor が外部 TCP プロキシ ロードバランサと互換性がないためです。Google Cloud Armor は、アプリケーション層(レイヤ 7)でのウェブベースの攻撃に対する保護など、アプリケーション認識型の防御を提供するため、HTTP(S) ロードバランサと連携するように設計されています。
オプション: Google Cloud Armor セキュリティ ポリシー ルールは、レイヤ 7(L7)特性でのみ照合するように制限されます。
この選択が間違っている理由は、Google Cloud Armor のセキュリティ ポリシーでレイヤ 7(L7)特性の照合が実際に許可されているためです。これは、そのセキュリティ機能の基本的な機能です。Google Cloud Armor は、L7 属性を使用して、アプリケーションレイヤ攻撃から保護するルールを作成します。
オプション: セットアップでは、Standard ネットワーク サービス レベルを使用する必要があります。
この選択が間違っている理由は、Google Cloud Armor が Premium と Standard の両方のネットワーク サービス階層で動作するため、Google Cloud Armor のセキュリティ ポリシーを採用するために Standard 階層のみを利用する必要がないという事実にあります。
参考：
https://cloud.google.com/armor/docs/security-policy-concepts
https://cloud.google.com/load-balancing/docs/https
https://cloud.google.com/armor/docs/supported-features
</div></details>

### Q.  問題7: 未回答
医療提供者は、患者がポータルを介してフィードバックや健康体験を送信できるようにします。プロバイダーは、フィードバックを公開する前に、フィードバックの内容に保護医療情報 (PHI) が含まれていないことを確認する必要があります。
この目的には、どの Google Cloud サービスを利用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ユーザーが送信したデータが機密情報の取り扱いに関する規制に準拠していることを確認するための Google Cloud のツールに関する知識を評価し、特に患者からのフィードバックから PHI を検出して編集するのに適したソリューションを求めています。
重要な用語:
保護医療情報(PHI):PHIには、HIPAAなどのプライバシー法で保護されている機密性の高い健康データが含まれます。その露出は法的およびプライバシーに影響を与える可能性があるため、堅牢な識別および保護メカニズムが必要です。
Cloud Data Loss Prevention API: 機密データの検出、分類、保護を支援するために設計された Google Cloud サービス。パターンマッチング、機械学習、その他の方法を使用して、機密情報を識別し、必要に応じて編集します。
正解解説:
(オプション)
・クラウドデータ損失防止API
Cloud Data Loss Prevention API は、PHI などの機密データの自動検出と秘匿化を提供するため、適切な選択肢です。このツールは、医療記録番号や非公開にする必要があるその他の個人情報など、さまざまな識別子を検出できるため、機密性を侵害することなくフィードバックを安全に公開できます。
不正解の説明:
オプション:クラウドキー管理サービス
Cloud Key Management Service が適していない理由は、さまざまな Google Cloud サービスで暗号鍵とその使用を管理するために使用されるためです。コンテンツ内の PHI のデータ検出機能や編集機能は提供されません。
オプション: BigQuery
BigQuery が適さない理由は、BigQuery はデータ分析のための強力なツールである一方で、公開前にデータセットから PHI を検出して編集する機能を本質的に提供していないためです。
オプション:Security Command Center
Security Command Center が正しくない理由は、Google Cloud リソースのセキュリティ管理とリスク評価を目的としているためです。患者フィードバックのPHIをスキャンして編集するための特定の機能は提供していません。
参考：
Hatpas://cloud.google.com/dlp/doc
https://cloud.google.com/kms/docs
https://cloud.google.com/web-security-scanner/docs
</div></details>

### Q.  問題8: 未回答
あなたは、会社のクラウドインフラストラクチャのネットワークセキュリティチームを担当しています。お客様の責任には、監査ログを参照として使用して、Cloud SQL インスタンス内の異常なデータ移動を監視および特定することが含まれます。次に、取引所の実際のコンテンツやヘッダーを含むデータトラフィックを分析することで、可視性を高めることを目指しています。
この要件に最も適した Google Cloud の機能はどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、クラウド ネットワーキングのセキュリティ機能に関する知識を評価し、特に、単なるアクセスやトランザクション ログだけでなく、コンテンツやヘッダーの検査など、データ トラフィックの分析を可能にする Google Cloud の機能に焦点を当てています。
重要な用語:
Packet Mirroring:セキュリティと監視の目的で、特定のネットワークサービスからコレクタの場所にトラフィックをコピーするネットワーク機能。ペイロードを含む徹底的なトラフィック分析に役立ちます。
監査ログ: クラウド サービス内の管理アクティビティとアクセスを記録するログで、リソースに対して実行された操作に関する分析情報を提供します。ガバナンス、コンプライアンス、およびリスク監査に役立ちます。
トラフィック分析:メッセージを傍受して調査し、通信のパターンから情報を推測するプロセス。侵入検知、ネットワーク管理、およびポリシーコンプライアンスの確保に使用できます。
正解解説:
(オプション)
・パケットミラーリング
Packet Mirroring は、仮想マシン (VM) からのネットワーク トラフィックをキャプチャしてミラーリングし、より詳細な検査のためにコレクタ VM またはセキュリティ アプライアンスに転送できるため、ヘッダーとコンテンツの両方を含むトラフィックを分析するための適切なオプションです。パケットミラーリングは、ネットワークタップと見なされ、クラウドネットワークインフラストラクチャ内の異常な動作を検出するのに役立ち、複雑なセキュリティ分析と潜在的な脅威の特定に必要なレベルの可視性を提供します。
不正解の説明:
オプション: Cloud IDS
Cloud IDS が不正解である理由は、ネットワーク トラフィックに悪意のあるアクティビティがないか検査する脅威検出サービスですが、質問で要求されるパケット ヘッダーとコンテンツのキャプチャと詳細な調査ではなく、主に侵入検知に重点を置いているためです。
オプション: Cloud SQL 監査ログ
Cloud SQL 監査ログが正しくない理由は、管理上の変更やアクセスなど、Cloud SQL の設定で実行された操作の記録は提供されますが、実際のデータ トラフィックやパケット コンテンツを分析する機能がないためです。
オプション: VPC フローログ
VPC フローログが正しくないのは、IP アドレス、パケットサイズ、タイムスタンプなどのネットワークトラフィックに関するメタデータをキャプチャし、詳細なトラフィック分析に必要なデータパケット自体の内容やヘッダーをキャプチャしないためです。
オプション: Google Cloud Armor
Google Cloud Armor が間違っている理由は、実際のネットワーク パケット コンテンツとヘッダーをミラーリングして分析する機能を持たない、ネットワーク エッジでセキュリティ ポリシーの適用と DDoS 攻撃の防止を提供するサービスであるためです。
参考：
https://cloud.google.com/traffic-director/docs/packet-mirroring
https://cloud.google.com/network-intelligence-center/docs/using-packet-mirroring
https://cloud.google.com/ids
</div></details>

### Q.  問題9: 未回答
重大なセキュリティ上の欠陥に対処するにはソフトウェア アップデートが必要であり、DevOps チームは Google Cloud の Google Kubernetes Engine(GKE)でアクティブなアプリケーションをアップグレードする必要があります。
DevOpsチームが従うべき適切な手順は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、GKE の継続的インテグレーションとデプロイのプロセスに対する理解度を評価します。これはセキュリティ更新プログラムを中心に展開され、ライブ アプリケーションに適したコンテナー管理、イメージの更新、およびデプロイ戦略に関する知識が必要です。
重要な用語:
コンテナイメージ:コンテナイメージは、アプリケーションの実行に必要なすべての依存関係(コード、ランタイム、システムツール、ライブラリ)を含む不変のファイルです。
CI/CD パイプライン: 継続的インテグレーション/継続的デプロイは、開発者がアプリケーションのテストとデプロイを自動化し、頻繁なコード変更を容易にする方法論です。
ローリング アップデート: ローリング アップデートでは、ポッドを新しいコンテナー イメージで段階的に更新することで、ダウンタイムなしでデプロイを更新できます。
正解解説:
(オプション)
・アプリケーションコードを変更するか、アップデートを適用し、新しいコンテナイメージを作成してから再デプロイします。
この選択は、Kubernetes 環境で更新プログラムをデプロイするためのベスト プラクティスを具体化しているため、正しいです。このプロセスでは、セキュリティ の問題に対処するためにアプリケーション コードを変更するか、更新プログラムを適用し、これらの変更を含む新しいコンテナー イメージをビルドして、クラスターに再デプロイします。その後、Kubernetes デプロイでは、ローリング アップデート戦略を使用して、更新されたイメージに基づいて既存のポッドを新しいポッドに置き換え、ダウンタイムをゼロにし、ライブ アプリケーションを中断しないようにします。
不正解の説明:
オプション: Puppet や Chef などの構成管理ツールを使用して、アクティブに実行されているコンテナーに更新を配布します。
このアプローチが間違っている理由は、Puppet や Chef などの構成管理ツールがインフラストラクチャ レベルで動作し、コンテナー イメージではなくサーバーの構成を管理するためです。Kubernetesはコンテナイメージと連携し、不変のアーティファクトとして構築して配布する必要があります。
オプション:ノードの自動アップグレードが有効になっているかどうかを確認します。そうであれば、Google は GKE クラスタ内のノードの更新を処理します。
この選択が間違っている理由は、ノードの自動アップグレードが基盤となる GKE ノードに関係し、コンテナ内で実行されているソフトウェアに関係しないためです。アプリケーション内のセキュリティ上の欠陥は、ノードだけでなく、コンテナイメージを更新することで対処する必要があります。
オプション: 新しいバージョンのベースイメージが Google Container Registry にプッシュされたときにコンテナが自動更新されるように設定します。
ベースイメージの更新時に(Kubernetes デプロイ機能として)コンテナを自動更新することは GKE には適用されず、アプリケーションの更新の制御と安定性を確保するために再デプロイを手動または CI / CD 自動化によってトリガーする必要があるため、このオプションは正しくありません。
参考：
https://cloud.google.com/kubernetes-engine/docs/how-to/updating-apps
https://cloud.google.com/kubernetes-engine/docs/concepts/node-auto-upgrades
https://cloud.google.com/container-registry/docs/managing-images
</div></details>

### Q.  問題10: 未回答
医療機関のセキュリティ アーキテクトは、Google のセキュリティに関する推奨事項に従って、組織のドメイン制限付き共有ポリシーを有効にし、Google Cloud で管理している患者データに特定のドメインのみがアクセスできるようにしています。研究部門は、この制限により、提携クリニックの共同研究者が研究プロジェクト内のリソースにアクセスできないことを報告しています。
意図したセキュリティのベストプラクティスを損なうことなく、このアフィリエイトクリニックのドメインへのアクセスを許可する適切な方法は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud 環境で組織のドメイン制限付き共有ポリシーを適切に適用し、セキュリティのベスト プラクティスを維持しながら、提携クリニックのアクセスを許可する方法について説明します。ポリシーの変更と例外処理の理解をテストします。
重要な用語:
ドメイン制限付き共有ポリシー: Google Cloud 内のリソース共有を特定のドメインに制限し、不正なドメインからのデータアクセスを防止することでセキュリティを強化する組織ポリシー。
カスタム ポリシー値: 組織のポリシーを構成するときに、より詳細なアプローチを可能にする設定で、一般的なルールに特定の例外を追加できるようにします。
Cloud Identity: Google Workspace、Cloud Identity、その他の Google サービス全体でユーザーとグループを一元管理する Google の Identity as a Service(IDaaS)ソリューション。
正解解説:
(オプション)
・ドメイン制限付き共有組織ポリシーの値を「カスタム」に設定して変更します。アフィリエイト クリニックの Cloud Identity または Google Workspace のお客様 ID をこのポリシーのドメイン例外リストに追加してから、ポリシーを再度有効にします。
この選択は、全体的なセキュリティ体制を弱めることなく例外を指定することで組織のポリシーを微調整できるため、最も適切です。ポリシーを「カスタム」に変更し、関連クリニックの特定のIDを追加することで、セキュリティアーキテクトは、必要なコラボレーションを確実に実行しながら、アクセスできるユーザーを制御し続けます。この戦略は、最小特権と正確なアクセス制御のベスト プラクティスと一致しています。
不正解の説明:
オプション: ドメイン制限付き共有組織ポリシーの値を [すべて許可] に変更して非アクティブ化します。
この選択が間違っている理由は、ドメイン制限が完全に非アクティブ化され、組織が潜在的な不正アクセスにさらされ、セキュリティのベストプラクティスに従わなくなるためです。
オプション: ドメイン制限付き共有組織ポリシーを無効にし、Google Identity and Access Management(IAM)を介して関連クリニックのユーザーに必要なアクセス権を付与します。
この選択が間違っている理由は、広範なセキュリティ層を提供することを目的としたポリシーを無効にする必要があるためです。個々のアクセスはIAMを介して管理できますが、ドメインレベルの制限の必要性は考慮されません。
オプション: ドメイン制限付きの共有組織ポリシーを無効にし、提携クリニックの Google Workspace お客様 ID を Google グループにグループ化します。その後、この Google グループをポリシーの例外に追加し、制限をオンに戻します。
この選択が間違っている理由は、Cloud Identity や Google Workspace のお客様 ID を使用する代わりに Google グループを含めるように組織のポリシーを変更しても、ドメインとお客様 ID に基づくドメイン制限付き共有ポリシーの中核的な側面に対処できないためです。
参考：
https://cloud.google.com/resource-manager/docs/organization-policy/restricting-domains
https://cloud.google.com/identity/docs/how-to/setup#creating-managing-groups
https://support.google.com/a/answer/7338880
</div></details>

### Q.  問題11: 未回答
製造会社は、機械のテレメトリの取り込み、データフロー分析、アクセス制御の仕様を頻繁に監査しています。彼らは、エンジニアリンググループが監査プロセス全体を経ることなく、新しいテレメトリプラットフォームを実装することを許可しようとしています。
この会社にはどのアプローチをお勧めしますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、製造会社が新しいテレメトリプラットフォームの実装のための監査プロセスを合理化する必要性に対処します。これは、エンジニアリンググループが新しいプラットフォームを導入するたびに完全な監査の必要性を軽減することに重点を置いています。
重要な用語:
コードとしてのインフラストラクチャ (IaC): IaC は、物理的なハードウェア構成ではなく、コンピューターが読み取り可能な定義ファイルを使用してコンピューティング インフラストラクチャを管理およびプロビジョニングする重要な DevOps プラクティスです。
静的分析ツール: これらのツールは、コードを実行せずに分析して、潜在的なセキュリティの脆弱性、標準への非準拠、およびその他のコード品質の問題を検出します。
CI/CD パイプライン: 継続的インテグレーション/継続的デプロイ パイプラインは、コード変更をビルド、テスト、デプロイすることで、ソフトウェアへの頻繁で信頼性の高い変更を可能にする自動化されたプロセスです。
正解解説:
(オプション)
・Infrastructure as Codeの採用を強制し、CI/CDパイプライン内に静的分析ツールを統合して、ポリシーへのコンプライアンスを確保します。
この選択は、コンプライアンスへの自動化された体系的なアプローチを提示するため、有益です。コードとしてのインフラストラクチャの使用を強制することで、エンジニアリング グループはソース管理を使用してインフラストラクチャを定義および管理できます。CI/CDパイプライン内に静的分析ツールを統合することで、デプロイ前にコードとインフラストラクチャの定義をコンプライアンスポリシーに照らして自動的に検証できるため、すべての新しい実装が監査され、設計に準拠していることを確認できます。
不正解の説明:
オプション: Security Command Center を使用して Forseti を実装し、非準拠のネットワーク構成をデプロイ後に監視および修復します。
この選択が間違っている理由は、Forseti と Security Command Center が展開後の問題の監視と修復を処理するためです。これでは、非準拠の展開を防ぐための予防的な対策が提供されないため、監査プロセスは合理化されません。
オプション:すべての相互接続トラフィックを特注の検査デバイスに誘導し、ライブ環境内の疑わしいトラフィックパターンを特定して軽減します。
この選択が間違っている理由は、特注のインスペクション デバイスを介してトラフィックを誘導すると、ライブ環境内の疑わしいトラフィックのみがチェックされるためです。監査プロセスを促進したり、展開前のコンプライアンスを支援したりすることはありません。
オプション: すべての本番環境レベルのテレメトリ プラットフォームのデプロイをオンプレミス インフラストラクチャに制限し、エンジニアは開発環境とテスト環境のために Google Cloud に無制限にアクセスできるようにします。
この選択が間違っている理由は、運用環境のデプロイをオンプレミス インフラストラクチャに制限する一方で、新しいテレメトリ プラットフォームの監査にも監査プロセスの簡素化にも対応していないためです。また、エンジニアは、開発やテストのために Google Cloud に自由にアクセスする必要もありません。
参考：
https://cloud.google.com/architecture/devops/devops-tech-infrastructure-as-code
https://cloud.google.com/security-command-center/docs/concepts-security-sources-forseti
https://cloud.google.com/vpc/docs/firewalls
</div></details>

### Q.  問題12: 未回答
あなたの会社では、ドメインスプーフィングの試みが繰り返し行われています。ネットワークインフラストラクチャを保護するには、ドメインクエリの信頼性を確保する必要があります。
このタスクに適した Google Cloud サービスはどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud サービス内のセキュリティ機能の理解度を評価します。具体的には、ドメイン名を模倣してネットワークインフラストラクチャの整合性を脅かすドメインネームシステムスプーフィング攻撃の軽減に関連しています。
重要な用語:
DNSSEC:DNSセキュリティ拡張機能(DNSSEC)は、デジタル署名で応答を検証し、DNSデータの整合性と信頼性を確保することで、ドメインネームシステムのルックアップにセキュリティレイヤーを追加します。
ドメインスプーフィング:ドメインスプーフィングとは、正規のサイトのドメイン名を模倣してユーザーを欺く悪意のある行為を指し、多くの場合、フィッシング攻撃の一環として、またはマルウェアを配布します。
正解解説:
(オプション)
・DNSSECによるクラウドDNS
DNSSEC を使用した Cloud DNS はドメイン名解決プロセスを保護し、応答する DNS サーバーが本物であり、クエリ結果が検証されるようにするため、この選択は適切です。DNSSECは、DNSデータをデジタル署名することで、攻撃者がDNSクエリを改ざんするのを防ぎ、改ざんされていない元のレコードを確実に受信することで、ドメインスプーフィングや同様の攻撃のリスクを効果的に軽減します。
不正解の説明:
オプション:クラウドルーター
Cloud Router が正しくない理由は、主に VPN 経由の Google Cloud Virtual Private Cloud(VPC)ネットワークとオンプレミス ネットワーク間のハイブリッド ネットワーキングの動的ルーティングを扱っているためです。ドメインクエリを認証したり、ドメインスプーフィングから保護したりするようには設計されていません。
オプション:クラウド負荷分散
クラウド負荷分散が正しくない理由は、その機能が複数のサーバーにネットワークトラフィックを分散して高可用性とパフォーマンスを確保することであり、DNSクエリを検証したり、なりすましの試みからドメインを保護したりすることではないためです。
オプション:Identity-Aware Proxy
Identity-Aware Proxy が正しくない理由は、DNS クエリをスプーフィングから保護するのではなく、ID とリクエストのコンテキスト(ユーザー ID、デバイスの正常性など)に基づいて Google Cloud で実行されているアプリケーションへのアクセスを制御するためです。
参考：
https://cloud.google.com/dns/docs/dnssec
https://cloud.google.com/armor/docs/ddos-protection
https://cloud.google.com/load-balancing/docs/https
</div></details>

### Q.  問題13: 未回答
ローカルの Hadoop クラスタを Dataproc、Compute Engine、永続ディスクに移行します。クラスタ内には、次のような組織の規制要件に沿ったセキュリティメカニズムを確立する必要があります。
- 包括的なキーライフサイクル管理ソリューションにより、保存データのセキュリティを確保します。
- データ処理サービスとは異なる独立した鍵管理サービスを使用する。
- 暗号化キーにアクセスするためのすべての要求の監視を維持します。
クラスタセキュリティ戦略に統合する必要があるのはどのサービスですか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ローカルの Hadoop クラスタからクラウド ソリューションに移行する際に、Google Cloud サービスで保存されているデータの保護に関する受験者の知識を調べます。具体的には、規制要件に準拠したキー管理と暗号化サービスの統合に重点を置いています。
重要な用語:
鍵アクセスの正当性: 顧客管理の暗号鍵(CMEK)の使用リクエストが承認された詳細な理由を提供する機能で、ユーザーは暗号鍵へのアクセスが必要だった理由を正当化できます。
Cloud External Key Manager(EKM): 外部のサードパーティの鍵管理システムを使用して Google Cloud データの暗号化を管理し、鍵のセキュリティを直接制御できるサービスです。
顧客管理の暗号鍵: 保存データの暗号化を制御するためにお客様が Google Cloud で生成、管理する鍵ですが、外部でホストされていません。
お客様提供の暗号鍵: クラウド データを保護するために、Google のインフラストラクチャに保存されていない独自の暗号鍵をお客様が提供するセキュリティ機能です。
アクセスの透明性と承認: Google の担当者が行ったアクションを記録することで Google スタッフの業務を可視化し、そのようなアクセス リクエストの承認ワークフローを可能にする機能。
正解解説:
(オプション)
・キーアクセスの正当性
・Cloud External Key Manager(クラウド外部キーマネージャー)
正解である Key Access Justifications と Cloud External Key Manager は、独立した鍵管理サービスで保存データを保護するという組織のニーズに合致しています。キーアクセスの正当な理由により、キーアクセスの詳細な理由が示され、コンプライアンスに不可欠なすべての要求の監視が維持されます。Cloud EKM では、サードパーティの鍵管理サービスを使用して鍵を外部で管理できるため、Google Cloud のデータ処理サービスとは異なる暗号鍵を保護するための独立したシステムが整っています。
不正解の説明:
オプション: 顧客管理の暗号化キー
顧客管理の暗号鍵(CMEK)が適切な選択ではない理由は、顧客が Google Cloud 内で独自の暗号鍵を管理できる一方で、保存データに必要な独立した鍵管理ソリューションが提供されていないためです。
オプション:お客様が用意した暗号化キー
顧客提供の暗号化キー (CSEK) が正しくない理由は、顧客がデータ暗号化のために独自のキーを提供および管理することはできますが、包括的なキー ライフサイクル管理や独立したキー管理サービスを促進しないためです。
オプション: アクセスの透明性と承認
アクセスの透明性と承認が正しくない理由は、Google の担当者によるデータへのアクセスを記録し、お客様がそのようなアクセスを承認または拒否できるようにする透明性ツールであり、暗号鍵の管理や保存データの保護のためのツールではないためです。
参考：
https://cloud.google.com/security-key-management
https://cloud.google.com/kms/docs/external-key-manager
https://cloud.google.com/bigquery/docs/encryption-key-management
</div></details>

### Q.  問題14: 未回答
組織内の新しいプロジェクトでは、専用のカスタム VPC 内の Compute Engine にマルチメディア処理サービスをデプロイする必要があります。ユーザーの役割は、次の基準に従った安全なネットワーク構成を確立することです。
- マルチメディア処理サービスコンポーネントのみが相互に通信できるようにします。
- 処理コンポーネントのスケーラビリティの変更時に、統一されたネットワークセキュリティルールを維持します。
- Compute Engine インスタンス管理者によるネットワーク セキュリティ設定の変更をブロックします。
どのような行動を取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、サービス コンポーネント間の安全な通信、スケーリング中の一貫したネットワーク セキュリティ、インスタンス管理者によるネットワーク セキュリティの変更の制限など、指定された基準に従って安全な Compute Engine ネットワーク環境を構成する能力を評価します。
重要な用語:
インスタンス テンプレート: 特定のマシン構成で Compute Engine インスタンスを作成するためのブループリントを提供するテンプレートで、組織の標準に統一性と準拠性を確保するのに役立ちます。
サービスアカウント:これらのアカウントは、アプリケーションまたはインスタンスにAPIリクエストの認証と承認に必要なIDを付与し、セキュリティを強化するために最小権限の原則を適用します。
VPCファイアウォールルール:仮想プライベートクラウドリソースに出入りするトラフィックフローを管理するルールにより、組織のポリシーや要件に沿ったきめ細かなネットワークセキュリティが可能になります。
正解解説:
(オプション)
・事前定義されたサービスアカウントを含むインスタンステンプレートを使用してマルチメディア処理サービスを設定し、これらのサービスアカウントをターゲット/ソースとして許可ポリシーを適用するVPCファイアウォールルールを確立します。
この選択は効果的であり、スケーラブルなソリューションを提供しながらネットワークセキュリティを確保します。事前定義されたサービスアカウントを持つインスタンステンプレートは、すべてのインスタンスでネットワーク構成の一貫性を保つことを容易にします。サービス アカウントに基づく VPC ファイアウォール ルールは、スケーリング時にルールを調整する必要性を回避し、Compute Engine インスタンス管理者が VPC ファイアウォール ルールを変更できないようにすることで、ネットワークの権限を分離して定義されたセキュリティ体制を維持します。
不正解の説明:
オプション:運用中のマルチメディア処理サービスに特定のネットワークタグを割り当て、これらのネットワークタグに基づくトラフィックをターゲット/ソースとして許可するVPCファイアウォールルールを実装します。
この選択が間違っている理由は、ネットワークタグの安全性が低く、管理が手作業が多いためです。この方法では機能しますが、Compute Engine インスタンス管理者によるネットワーク セキュリティ設定の変更を効果的に防ぐことができないため、基準の 1 つを満たせません。
オプション: すでに運用されているマルチメディア処理サービスで既存のサービスアカウントを保持し、これらのサービスアカウントをターゲット/ソースの基準として使用するトラフィックを許可する VPC ファイアウォールルールを設定します。
この選択が正しくない理由は、新しいプロジェクトの構成標準に準拠していない可能性がある既存のサービス アカウントを保持することにあります。確立された処理サービスと新しい処理サービスでは、セキュリティ設定が異なる場合があり、スケーラビリティの変更時に一貫したルールを維持できません。
オプション: 適切なネットワークタグを埋め込んだインスタンステンプレートを使用してマルチメディア処理コンポーネントを再デプロイし、ターゲット/ソース指定のためにこれらのネットワークタグを参照する許可ポリシーを VPC ファイアウォールルールに作成します。
この選択が間違っている理由は、最初の間違ったオプションの場合と同様で、ネットワークタグを使用すると制御が少なくなり、厳格なセキュリティポリシーに準拠しません。以前と同様に、インスタンス管理者ロールはこれらのタグを変更し、管理者がネットワークセキュリティ設定を変更できないようにするという要件と矛盾する可能性があります。
参考：
https://cloud.google.com/vpc/docs/firewalls
https://cloud.google.com/compute/docs/instances/service-accounts
https://cloud.google.com/compute/docs/instance-templates
</div></details>

### Q.  問題15: 未回答
ある企業は最近、Google Cloud の App Engine を通じて新しいサービスを開始し、OWASP のベスト プラクティスに沿ったウェブ アプリケーションの脆弱性をレビューするソリューションを模索しています。
これらのセキュリティ評価を実行できる Google Cloud の機能はどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、App Engine でホストされているウェブ アプリケーションを保護するための Open Web Application Security Project(OWASP)のベスト プラクティスに沿った Google Cloud セキュリティ ツールに関する受験者の理解度を評価します。
重要な用語:
OWASP: Open Web Application Security Project は、Web アプリケーションセキュリティの分野に関する記事、方法論、ドキュメント、ツール、およびテクノロジを自由に入手できるオンライン コミュニティです。
Web Security Scanner: Google Cloud が提供する組み込みサービスで、App Engine、Compute Engine、Google Kubernetes Engine の各アプリケーションを自動的にスキャンして、一般的なウェブの脆弱性を検出します。
正解解説:
(オプション)
・Webセキュリティスキャナー
Web Security Scanner は Google Cloud アプリケーションの脆弱性評価に特化しているため、この選択は正しいです。これは特に、Webアプリケーションのセキュリティに関するOWASPの推奨事項とベストプラクティスと一致しています。このスキャナーは、クロスサイトスクリプティング(XSS)、Flashインジェクション、混合コンテンツ、古いライブラリや安全でないライブラリなどの問題を検出し、企業がWebアプリケーションの防御を強化するのに役立ちます。
不正解の説明:
オプション:Cloud Armor
この選択が間違っている理由は、Google Cloud Armor が主にサービス セキュリティ サービス拒否(DoS)やウェブ攻撃からの保護を提供するネットワーク セキュリティ サービスであり、アプリケーション セキュリティ スキャンや OWASP ガイドラインに重点が置かれていないためです。
オプション: Google Cloud 監査ログ
この選択が間違っている理由は、Google Cloud 監査ログが Google Cloud 環境内の管理アクティビティとアクセスを記録するためです。監視とコンプライアンスには役立ちますが、OWASPの推奨事項に沿った脆弱性スキャンは提供されません。
オプション: 異常検出
この選択が間違っている理由は、Google Cloud の異常検出は通常、セキュリティ上の懸念や運用上の問題を示す可能性のある異常な動作を特定することを指すためです。OWASP のベスト プラクティスに従った Web アプリケーションの脆弱性評価は提供されません。
参考：
https://cloud.google.com/security-command-center/docs/concepts-web-security-scanner-overview
https://cloud.google.com/appengine/docs/standard
https://owasp.org/www-project-top-ten/
</div></details>

### Q.  問題16: 未回答
ある小売企業は、長年にわたるスタッフ割引の進化を分析して、異常を特定し、賃金の不均衡に対処したいと考えています。この分析は、個人の機密性の高い割引データを非公開にしながら、プロセスを逆にして異常を特定できる必要があります。
このタスクには、どの Google Cloud Data Loss Prevention API メソッドを使用する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、機密性の高いスタッフの割引データを分析して異常や給与の不均衡を特定して対処し、個別のデータ復元を可能にするタスクに最も適した Google Cloud Data Loss Prevention API の方法を尋ねます。
重要な用語:
CryptoReplaceFfxFpeConfig: Google Cloud の DLP API 内のメソッドで、形式保持暗号化(FPE)を有効にし、機密データを可逆的な暗号化表現に置き換えます。
匿名化:個人識別情報を削除または変更して、個人情報を明かすことなくデータを分析できるようにするプロセスで、データ分析におけるプライバシーの維持に適しています。
可逆変換: 通常は暗号化キーを使用して元のデータを再構築できるデータ変換の手段で、データのプライバシーを確保しながら詳細な分析を可能にします。
正解解説:
(オプション)
・CryptoReplaceFfxFpeConfig(クリプトリプレースFfxFpeコンフィグ)
CryptoReplaceFfxFpeConfig は、形式保持暗号化(FPE)専用に設計された Google Cloud Data Loss Prevention API のメソッドであるため、この選択は最適です。これにより、小売企業は、元のデータ形式と構造を保持する方法で暗号化することで、個人の機密性の高い割引データを保護できます。このプロセスは可逆的であるため、分析中にデータのプライバシーが維持されるようにしながら、特定の異常を調査したり、支払いの不均衡を調査したりするために、必要に応じてデータを復号化することができます。
不正解の説明:
オプション:バケット化
バケット化が正しくない理由は、データをバケットまたは範囲にグループ化し、プライバシーを保護するためにデータの粒度を下げるためです。ただし、可逆的な変換はできないため、必要に応じて分析後に個々の異常を特定することはできません。
オプション:抑制
抑制が正しくない理由は、この方法では、機密情報の開示を回避するために、データセット内のデータの列全体を削除する必要があるためです。データは不可逆的に削除されるため、企業は個々の異常を検査するプロセスを元に戻すことができなくなります。
オプション: CryptoDeterministicConfig
CryptoDeterministicConfig が正しくない理由は、このメソッドは決定論的暗号化による可逆的な変換も提供しますが、分析と異常の認識に不可欠な、説明されているタスクに必要な形式保持の側面をサポートしていないためです。
参考：
https://cloud.google.com/dlp/docs/transformations/reference
https://cloud.google.com/dlp/docs/concepts-format-preserving-encryption
https://cloud.google.com/dlp/docs/samples/dlp-deidentify-reidentification-fpe-with-surrogate
</div></details>

### Q.  問題17: 未回答
共有 VPC にリンクされた Kubernetes Engine クラスタからの API 呼び出しが、Cloud Storage バケットを操作しようとすると失敗します。バケットは、VPC Service Controls 境界によって保護されているプロジェクト内にあります。
どのような是正措置を取るべきか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud の VPC Service Controls を使用して、セキュリティで保護されたネットワーク内で失敗した API 呼び出しのトラブルシューティングに関する理解度を評価します。具体的には、共有 VPC 内の GKE クラスタとサービス境界内の Cloud Storage バケット間のやり取りに対応しています。
重要な用語:
共有 VPC: 共有 VPC を使用すると、組織は複数のプロジェクトのリソースを共通の仮想プライベート クラウドに接続できるため、参加しているすべてのプロジェクト間のアクセスを効率的に管理できます。
VPC Service Controls: VPC Service Controls は、データの周囲にセキュリティ境界を作成し、データ流出のリスクを制限することで、Cloud Storage 内の機密データのセキュリティを強化します。
サービス境界: サービス境界は、Google Cloud リソースが配置できるセキュリティ ゾーンを定義する境界です。境界内のリソースは安全に通信できます。
管理プロジェクト: これは共有 VPC セットアップのホスト プロジェクトであり、それ自体と接続されたサービス プロジェクトのネットワーク リソースの管理を担当します。
正解解説:
(オプション)
・共有VPCを収容する管理プロジェクトをサービス境界に追加します。
共有 VPC を保持する管理プロジェクトを VPC Service Controls 境界に追加すると、基盤となるインフラストラクチャに必要なアクセス許可が付与されるため、この選択は正しいアクションです。これはセキュリティ要件に準拠しており、共有 VPC 内の GKE クラスタが、サービス境界で保護されている別のプロジェクトの Cloud Storage バケットとやり取りできるようになります。
不正解の説明:
オプション: Kubernetes Engine クラスタがサービス境界にデプロイされているクライアント プロジェクトを含めます。
この選択が正しくない理由は、管理プロジェクトがネットワークを制御するため、基盤となる共有 VPC の管理プロジェクトがサービス境界内にない場合、クライアント プロジェクトを追加するだけでは問題が解決されないためです。
オプション: Kubernetes Engine クラスタを使用するクライアント プロジェクトと、共有 VPC を使用する管理プロジェクトの間にサービス境界を確立します。
この選択が正しくない理由は、プロジェクト間のサービス境界の確立は、既存の境界にプロジェクトを追加することと同じではないためです。この選択では、共有 VPC が保護されたリソースと対話する必要性には対応していません。
オプション: Kubernetes Engine クラスタを含むクライアント プロジェクトと、Cloud Storage バケットを保護する境界の間に境界ブリッジを設定します。
この選択が間違っている理由は、境界ブリッジは 2 つのサービス境界を接続するためのものであり、ここではそうではないためです。共有 VPC とサービス境界の設定が原因で失敗した API 呼び出しは解決されません。
参考：
https://cloud.google.com/vpc-service-controls/docs/set-up-private-connectivity
https://cloud.google.com/vpc-service-controls/docs/perimeters
https://cloud.google.com/bigquery/docs/datasets-access-controls
</div></details>

### Q.  問題18: 未回答
クラウドのプライバシーに特化したガイドラインを提供し、クラウド内の個人データを保護するための実施基準を提供している国際コンプライアンス標準はどれですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、クラウドのプライバシーとデータ保護に関連する国際標準に関する知識を評価します。具体的には、クラウドサービス内で管理される個人データを保護するためのフレームワークを提供する標準を特定することを目指しています。
重要な用語:
ISO 27018:パブリッククラウドサービスプロバイダー向けの個人データ保護に関するガイドラインを定めた国際規格で、クラウドにおけるプライバシー保証のための法的措置と技術的対策の両方に対応しています。
個人データ:識別された、または識別可能な個人に関連する情報を指します。この側面は、ISO 27018 などのプライバシーおよびコンプライアンス標準において重要です。
クラウドプライバシー:クラウドサービス上で消費者のプライバシーを保護し、個人情報を管理するための戦略と実践に関心があります。
正解解説:
(オプション)
・ISO27018認証取得
ISO 27018は、個人データの保護に関するクラウドサービスプロバイダー向けに特別に設計された行動規範であるため、正しい選択です。同意やデータの最小化などのプライバシー原則に従って、個人を特定できる情報 (PII) を保護するための対策を実施するための管理目的、管理、およびガイドラインを提供します。この標準は、クラウド サービスの信頼性を提供する上で重要であり、クラウド プライバシーに関する包括的な一連のベスト プラクティスを提供します。
不正解の説明:
オプション:ISO 27001
ISO 27001 が間違っている理由は、情報セキュリティ管理システム (ISMS) を確立、実装、維持、および継続的に改善するための要件を規定する広範な標準であり、クラウドのプライバシーに特に対処していないためです。
オプション:ISO 27002
ISO 27002 が正しくない理由は、クラウド固有のプライバシーの問題に焦点を当てずに、組織の情報セキュリティ標準と情報セキュリティ管理プラクティス (コントロールの選択、実装、管理を含む) のガイドラインを提供しているためです。
オプション:ISO 27017
ISO 27017 が正しくない理由は、クラウド サービスの提供と使用に適用される情報セキュリティ管理のガイドラインを提供しているためです。ただし、クラウド内の個人データのプライバシー保護ではなく、クラウドサービスのセキュリティに重点が置かれています。
参考：
https://cloud.google.com/security/compliance/iso-27001
https://cloud.google.com/security/compliance/iso-27017
Hatpas://vv.iso.org/Standard/43757.html
</div></details>

### Q.  問題19: 未回答
ある医療機関の Google Cloud セットアップは、約 150 のプロジェクトと 2,000 のコンテナ化されたワークロードで構成されています。一元化されたログ記録とイベント管理戦略の欠如が、コンプライアンス運用チームの監視機能を妨げています。可視性を高め、チームが環境の構成を効果的に検査できるログ管理ソリューションが必要です。
推奨される行動方針は何ですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、コンプライアンスを目的とした監視の有効性を高めるために、多くのプロジェクトとコンテナ化されたワークロードを含む大規模な医療機関のクラウド環境にログ管理ソリューションを実装するという課題に対処します。
重要な用語:
Log Sink: さまざまなクラウド サービスからのログデータを集約し、一元管理し、BigQuery や Pub/Sub などのさまざまな宛先にエクスポートできるようにする Google Cloud のメカニズム。
オンプレミスのSIEM:機関の内部インフラストラクチャ内で動作し、セキュリティイベント管理とセキュリティアラートのリアルタイム分析を提供するセキュリティ情報およびイベント管理システム。
Pub/Sub: Google Cloud のメッセージング サービスで、サービス間の非同期メッセージングを可能にし、オンプレミスやその他のクラウド システムへのログ取り込みのための永続的な通信チャネルを提供します。
ログ指標: Google Cloud のログ サービス内のユーザー定義のフィルタと条件で、ログデータを定量的データに変換し、モニタリングとアラートに使用できます。
正解解説:
(オプション)
・すべての子リソースを含む組織レベルのログシンクを作成します。オンプレミスの SIEM にログを取り込むには、シンクの宛先として Pub/Sub トピックを利用し、コンプライアンス運用チームに適切なアクセス権を提供します。
この選択は、すべてのログを共通の宛先に送る単一の組織レベルのログ シンクを作成することで、複数のプロジェクトからのログを処理する複雑さを簡素化するため、適切です。Pub/Sub を活用することで、コンプライアンス要件に準拠しながら、詳細な分析のためにオンプレミスの SIEM システムに安全でリアルタイムのログをエクスポートできます。また、コンプライアンス運用チームがログ データにアクセスして検査するための適切なアクセス許可を設定し、プロジェクト レベルの構成でチームを圧倒することなく、一元化された効率的な監視に貢献することも提案しています。
不正解の説明:
オプション: スコープ内のプロジェクトごとに個別のログ シンクを設定します。時間のパーティション分割が有効になっている BigQuery データセットを、これらのログシンクの宛先として指定します。すべてのプロジェクトにログメトリックベースのアラートを実装します。各プロジェクト内のコンプライアンス運用チームに "監視閲覧者" ロールを割り当てます。
この選択が間違っている理由は、プロジェクトごとに個別のログ シンクを設定するという非効率的なアプローチが原因で、管理が困難になり、構成エラーの可能性が高まります。BigQuery は強力な分析ツールですが、ログの取り込み、特にインスタント アラートや SIEM 統合を必要とするコンプライアンス モニタリングには適していませんが、ここでは直接説明しません。
オプション: ログ シンクを確立せずに、「Critical Infrastructure」フォルダー内のすべてのリソースに対してネットワーク ログとデータ アクセス ログの両方をアクティブ化して、不要な費用と待機時間を削減します。プロジェクト レベルの "ログ閲覧者" と "ブラウザー" の役割をコンプライアンス運用チームに割り当てます。
この選択が間違っている理由は、ログ シンクを確立しないことで、ログの集中管理の必要性を見落としているためです。費用とレイテンシーの削減は有益ですが、特定のフォルダー内のリソースのみに焦点を当て、専用のSIEMシステムにログをストリーミングしないため、コンプライアンスに必要な包括的な可視性が犠牲になります。
オプション: 子リソースを収集する "Critical Infrastructure" フォルダー用に 1 つのシンクを編成し、子リソースを含まない組織レベルのログ用に別のシンクを編成します。コンプライアンス チームがアクセス可能なプロジェクトで保持期間が 120 日以上に設定されたログ バケットを宛先として選択します。コンプライアンス運用チームに、組織レベルでの "セキュリティ レビュー担当者" ロール特権を付与します。
この選択が間違っている理由は、ログ管理戦略の不必要な分岐を前提としているため、監視プロセスが複雑になる可能性があるためです。長期保存にログバケットを使用することは実用的ですが、子リソースを含めずに組織レベルとフォルダレベルに異なるシンクを設定すると、効果的なコンプライアンス監視に必要な一元的なログ管理の一貫した戦略が失われます。
参考：
https://cloud.google.com/logging/docs/audit/configure-data-sources
https://cloud.google.com/logging/docs/solutions/siem-integration
https://cloud.google.com/iam/docs/understanding-roles
</div></details>

### Q.  問題20: 未回答
組織のセキュリティ ポリシーでは、クラウド上のデータベース サーバーにパブリック IP アドレスを割り当てないようにする必要があります。
ただし、これらのサーバーには、定期的なパッチ管理のために外部エンドポイントに接続する機能が必要です。
この要件を満たすには、どの Google Cloud サービスを実装する必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、データベースサーバーのメンテナンスとセキュリティ プロトコルに焦点を当てて、機密性の高いシステムをパブリック インターネットに公開することなく、プライベート インスタンスを外部サービスに接続できるようにする Google Cloud ネットワーキング サービスに関する受験者の理解度を評価します。
重要な用語:
Cloud NAT: プライベート ネットワーク内のリソースが、パブリック IP を割り当てることなくインターネットやその他の外部サービスにアクセスできるようにします。
パブリック IP: インターネットから到達可能な IP アドレス。パブリックIPを持つサーバーでホストされているサービスはグローバルにアクセスできるため、プライベートIPアドレスと比較して漏洩のリスクが高まります。
パッチ管理: ソフトウェアに更新プログラムを配布して適用するプロセス。これらのパッチには、セキュリティ修正、新機能、およびパフォーマンスの改善が含まれる場合があり、システムのセキュリティを維持するために重要です。
正解解説:
(オプション)
・クラウドNAT
Cloud NAT は、これらの要件に実装するのに適したサービスです。これにより、パブリック IP アドレスを持たない Google Cloud VPC の仮想マシン インスタンスが、パッチ管理などの重要なオペレーションのためにインターネットやその他の Google サービスに接続できるようになります。このサービスでは、パブリック IP アドレスをデータベース サーバーに割り当てないことでセキュリティ体制を維持しながら、更新プログラムまたは修正プログラムの送信接続を許可し、パブリック インターネットの公開に関する組織のポリシーを保持します。
不正解の説明:
オプション:Identity-Aware Proxy
Identity-Aware Proxyが正しくない理由は、パブリックIPを使用せずにインスタンスから外部エンドポイントへのアウトバウンド接続を容易にするためではなく、WebアプリケーションおよびVMへのアクセスを制御するツールとして機能するためです。
オプション: HTTP(S) 負荷分散
HTTP(S) 負荷分散が正しくない理由は、受信 HTTP または HTTPS トラフィックを複数のインスタンスに分散するために使用されるためです。パブリックIPアドレスのないインスタンスへのアウトバウンド・インターネット・アクセスは提供されません。
オプション: クラウド DNS
Cloud DNS が正しくない理由は、ドメイン名を受信インターネット ナビゲーション用の IP アドレスに変換し、データベース サーバーがパブリック IP なしで外部エンドポイントにアクセスする方法を提供しないためです。
参考：
https://cloud.google.com/nat/docs/overview
https://cloud.google.com/vpc/docs/configure-private-google-access
https://cloud.google.com/vpc/docs/using-nat-gateway
</div></details>

### Q.  問題21: 未回答
Google Cloud VPC でデフォルトで確立されている固有のファイアウォール ルールを 2 つ選びます。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、Google Cloud VPC(仮想プライベートクラウド)のデフォルトのネットワークファイアウォール構成を調べます。特に受信トラフィックと送信トラフィックに関して、ユーザーの介入なしにネットワークトラフィック管理のために設定された固有のルールを理解することに重点を置いています。
重要な用語:
固有のファイアウォール ルール: これらは、カスタム ルールによってオーバーライドされない限り、インスタンスのインバウンド トラフィックとアウトバウンド トラフィックを制御するために Google Cloud VPC によって自動的に作成されるデフォルトのネットワーク アクセス ルールです。
アウトバウンドトラフィック: これは、VPC 内から発信され、VPC の外部 (通常はインターネットまたは別のネットワーク) を宛先とするネットワークトラフィックを指します。
インバウンドトラフィック: VPC の外部から VPC へのネットワークトラフィックは、インバウンドトラフィックと呼ばれます。これには通常、VPC 内でホストされているリソースにアクセスするためのトラフィックリクエストが含まれます。
正解解説:
(オプション)
・すべてのポートでアウトバウンドトラフィックを許可するルール
・すべてのポートで着信トラフィックを遮断するルール
正しい選択により、Google Cloud の VPC のトラフィック方向に関するデフォルトのファイアウォール ルールが特定されます。デフォルトでは、VPC はすべてのポートを経由するアウトバウンドトラフィックを有効にし、VPC 内のインスタンスが外部への接続を開始できるようにすることで、ネットワークセキュリティのレベルを提供します。逆に、すべてのポートで未承諾の着信トラフィックをすべてブロックし、要件に基づいて特定の受信トラフィックを許可するように特定のルールが作成されない限り、不正アクセスに対するデフォルトの防御として機能します。
不正解の説明:
オプション: ポート 443 へのすべての送信トラフィックを拒否するルール
この選択が正しくない理由は、Google Cloud VPC がデフォルトですべての送信接続を拒否するわけではないためです。代わりに、すべてのポートでアウトバウンドトラフィックを許可し、インスタンスが外部ネットワークと自由に通信できるようにします。
オプション: すべての送信トラフィックを制限するルール
この選択は、Google Cloud VPC のデフォルトの動作(広範なネットワーク接続を制限なく送信トラフィックを許可し、外部サービスとの通信を妨げない)と矛盾するため、正しくありません。
オプション: ポート 8080 での受信トラフィックを許可する規則
既定でポート 8080 の受信トラフィックを許可する規則は、最小特権のセキュリティ原則を否定します。Google Cloud VPC では、このような制限の緩いルールは本質的に有効になっていません。代わりに、特定の受信トラフィックを許可するようにカスタム ファイアウォール規則を構成する必要があります。
参考：
https://cloud.google.com/vpc/docs/firewalls#default_firewall_rules
https://cloud.google.com/vpc/docs/firewalls#defaultrules
https://cloud.google.com/network-connectivity/docs/vpn/how-to/configuring-firewall-rules
</div></details>

### Q.  問題22: 未回答
あなたは、医療機関の Google Cloud セットアップにおけるユーザー認証プロセスを監督する任務を負っています。組織は、すべてのスタッフに多要素認証 (MFA) を要求しています。MFA デバイスを置き忘れたため、ユーザーがアカウントにアクセスできません。セキュリティ プロトコルを維持しながら、ユーザーがアクセスを回復できるようにする必要があります。
どのような行動を取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問は、医療機関の継続的な多要素認証という特定の要件の下でのユーザー アクセスの管理に対処します。MFAデバイスを紛失したスタッフのアクセスの問題を解決することに重点を置いています。
重要な用語:
Google 管理コンソール: 組織内のユーザーの Google アカウント機能(MFA などのセキュリティ プロトコルの適用や停止など)を管理者が管理できるウェブベースのインターフェースです。
多要素認証 (MFA): アプリケーション、オンライン アカウント、VPN などのリソースにアクセスするために、ユーザーが複数の検証要素を提供する必要がある高度なセキュリティ プロセス。
特権管理者アカウント: Google 管理コンソール内の管理者特権アカウントで、最高レベルの制御を持ち、可能なすべての管理タスクを実行できます。
バックアップコード: プライマリ MFA デバイスが使用できない場合にアカウントにアクセスするために使用できる、オンラインサービスによって提供される一連のコード。
正解解説:
(オプション)
・Google 管理コンソールで、特定のユーザーのプロフィールに移動し、このユーザーの MFA を一時的に停止します。ユーザーに新しい MFA デバイスの設定をリクエストし、アカウントで MFA を復元します。
この選択肢は、組織のセキュリティ設定とユーザー エクスペリエンスへの影響を最小限に抑えて問題に対処する最も安全なオプションです。特定のユーザーの MFA を一時的に停止すると、他のユーザー アカウントのセキュリティ体制を損なうことなく、アカウントへのアクセスを回復できます。また、アカウントの MFA が復元される前に、ユーザーは新しい MFA デバイスを設定するように求められるため、機密性の高い医療データの MFA を維持するベストプラクティスに従います。
不正解の説明:
オプション: Google 管理コンソールで、影響を受けるユーザーのプロフィールに移動し、ユーザーが自分のアカウントに再度ログインできるようにバックアップ コードを作成します。後で新しい MFA デバイスを設定するようにユーザーに求めます。
これが間違っている理由は、GoogleがMFAのバックアップコードを標準オプションとして提供していないためです。通常、バックアップコードは単一要素認証用であるため、このアプローチはMFAデバイスの損失に対処するための推奨手順に従いません。
オプション: Google 管理コンソールで、組織全体の MFA 要件を一時的に停止します。サインインして新しい MFA デバイスを登録するようにユーザーに指示します。その後、すべての担当者の MFA 要件を再アクティブ化します。
この選択が間違っている理由は、組織全体のMFAプロトコルを混乱させることを示唆しており、重大なセキュリティリスクをもたらすためです。すべての担当者の MFA を一時的に削除すると、システムが不正アクセスされる可能性があるため、1 人のユーザーの問題にはお勧めしません。
オプション: Google 管理コンソールで特権管理者アカウントを使用して、ユーザーのログイン認証情報の完全なリセットを開始します。最初のログイン後に新しいサインインの詳細を設定するようにユーザーにアドバイスします。
ユーザーのサインイン資格情報を完全にリセットすることは、必要以上に混乱を招く方法であるため、この最後のオプションは正しくありません。MFAデバイスの紛失という差し迫った問題には焦点を当てておらず、ユーザーは新しいアカウント資格情報を完全に設定することを余儀なくされますが、これは状況に応じて必要な範囲を超えています。
参考：
https://cloud.google.com/identity-platform/docs/managing-mfa
https://cloud.google.com/identity/docs/how-to/manage-2sv
Hatps://support.google.com/a/answer/2537800?hl=n
</div></details>

### Q.  問題23: 未回答
会社は、データベース監査ログをドイツの国境内に保持することを義務付けるデータ主権要件を遵守する必要があります。データベースは、新しいプロジェクトのために europe-west3 リージョンのフランクフルトで運用されます。すべてのログデータがドイツ国内にとどまるように Cloud Logging を設定する必要があります。
どのような行動を取るべきですか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、特定の地理的データ所在地の要件を満たすために Google Cloud Platform で Cloud Logging を構成するための知識を評価します。ログバケットの理解、ログ転送、およびログデータが定義されたリージョン内にとどまるようにすることで、データ主権法への準拠を維持することに重点を置いています。
重要な用語:
ログバケット: ログバケットは、ログエントリを保存する設定可能な Cloud Logging コンテナです。バケットを異なるリージョンに設定し、アクセスポリシーと保持ポリシーで管理できるため、地域のデータ法への準拠に役立ちます。
データ主権:データ主権とは、デジタルデータが処理または保存される国の法律に従うという概念を指します。これらの法律の遵守は、国際的な事業運営にとって非常に重要です。
ログ転送: Cloud Logging のログ転送では、1 つのログソースから指定されたログバケット、ストレージ、または外部サービスにログデータをリダイレクトして、一元管理またはさらなる処理を行います。
組織ポリシーの制約: 組織ポリシーの制約を使用すると、管理者はリソースの場所を制限する特定のポリシーを定義して、リソースが地理的な制約に準拠していることを確認できます。
正解解説:
(オプション)
・europe-west3にログバケットを新規作成し、新規バケットにログを転送するようにデフォルトバケットを設定します。
この選択は、必要なリージョン europe-west3 内にカスタムログバケットを作成し、新しく作成したバケットにログを転送するようにデフォルトのクラウドロギングバケットを設定するため、正しいです。リージョン ログ バケットは、指定された領域にログを物理的に格納することで、ドイツの国境内でのデータ常駐を保証します。ログ転送を設定すると、データベースからのすべての監査ログがローカルバケットにリダイレクトされ、データ主権の義務が遵守されます。
不正解の説明:
オプション: europe-west3 のみを含めるように組織ポリシー制約制約/resourceLocations を適用します。
この選択が間違っている理由は、組織のポリシー制約を適用すると、リソースを作成できる場所が実際に決まりますが、既存の Cloud Logging データの保存場所には直接影響しないためです。
オプション: europe-west3 にある Cloud Storage バケットにすべてのログを転送するようにログシンクを配置します。
この選択が間違っている理由は、ログが europe-west3 の Cloud Storage バケットに転送されているにもかかわらず、Cloud Logging 固有の機能を活用してログデータの所在地を管理していないため、設定が正しくないためにコンプライアンス違反が発生する可能性があるためです。
オプション: gcloud コマンドライン ツールを使用して、gcloud logging settings update でログの保存先を europe-west3 に更新します。
この選択が間違っている理由は、gcloud コマンドライン ツールを使用してログ設定を更新しても、構成が変更されるだけで、gcloud 設定を通じてログデータがリージョンの境界内にとどまるように強制する直接的なコマンドがないためです。
参考：
https://cloud.google.com/logging/docs/region-support
https://cloud.google.com/logging/docs/storage
https://cloud.google.com/resource-manager/docs/organization-policy/org-policy-constraints
</div></details>

### Q.  問題24: 未回答
企業は、コンピューティング リソースの大部分を Google Cloud に移行することを目指しています。既存のオンプレミスの Identity and Access Management(IAM)システムを Google Cloud でのユーザー認証に利用する予定です。
企業のオンプレミス IAM システムを Google Cloud と統合し、アクセス制御を確立するには、どのような 2 つのアクションを実装する必要がありますか?(2つ選択してください。
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、オンプレミスの Identity and Access Management(IAM)システムと Google Cloud を統合してユーザー認証とアクセス制御を行う際の知識を評価します。既存の IAM システムを Google Cloud サービスと同期するための正しい方法の理解度をテストします。
重要な用語:
Cloud Identity: Google Cloud サービス全体でユーザー作成やデバイス管理などの ID 管理を提供する一元化された ID サービスです。
SAML: Security Assertion Markup Language は、ID プロバイダーとサービス プロバイダーの間で認証および承認データを交換するためのオープン スタンダードです。
Google Cloud Directory Sync: オンプレミスの IAM に基づく LDAP(Lightweight Directory Access Protocol)のデータを Google の Cloud Identity サービスと同期するために使用されるツール。
正解解説:
(オプション)
・Cloud Identity SAML設定を採用し、Google Cloud内でユーザーやグループを割り当てます。
・Google Cloud Directory Syncを導入し、オンプレミスIAMやCloud Identityと連携
既存のオンプレミス IAM システムを Google Cloud と統合するための正しい選択は、Cloud Identity の SAML 構成を利用し、Google Cloud Directory Sync(GCDS)を使用することです。SAML 構成では、ID 認証をフェデレーションできるため、既存の IAM 認証情報を使用して Google Cloud にログインできます。Google Cloud Directory Sync は、オンプレミスの IAM と Cloud Identity をリンクして、両方のシステム間でユーザーとグループの情報の一貫性を保ち、統一された ID 管理プロセスを確保します。
不正解の説明:
オプション: Identity Platform を利用して、Google Cloud 内でユーザーとグループを割り当てます。
これが間違っている理由は、Google Identity Platform が既存のオンプレミス IAM システムを Google Cloud と統合するのではなく、アプリケーションに ID とアクセス管理を追加することを目的としているためです。
オプション: オンプレミス・システムの各IAMグループに合わせる権限を備えたIAMロールを構築します。
これが間違っている理由は、オンプレミスのIAMグループに基づいてIAMロールを構築しても、IAMシステムが統合されないためです。これは、Google Cloud でロールを手動で作成することを意味し、オンプレミスの IAM システムとは同期されません。
オプション: オンプレミス・システムのすべてのIAMグループに対応する権限を持つIAMグループを設定します。
これが間違っている理由は、オンプレミスの各 IAM グループに対応するように Google Cloud で IAM グループを設定するのは手動のプロセスであり、2 つのシステム間の直接統合や同期ができないためです。
参考：
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-synchronizing-user-accounts
https://cloud.google.com/architecture/identity/federating-Google Cloud-with-active-directory-configuring-single-sign-on
Hatps://support.google.com/a/answer/106368?hl=n
</div></details>

### Q.  問題25: 未回答
医療機関は、個人の健康情報を Google Cloud Storage で処理します。独自のデータセンターで生成および管理される暗号化キーを使用する必要があります。
どのようなアクションを取る必要がありますか?
1. 
2. 
3. 
4. 
<details><div>
    答え：
この質問では、ユーザー自身のデータセンターで生成、管理される鍵を使用して Google Cloud Storage 内の個人の健康情報を暗号化し、医療分野でのデータ処理に関する規制要件への準拠を確保する正しい方法を探ります。
重要な用語:
顧客管理の暗号鍵(CMEK): CMEK を使用すると、クライアントは Google Cloud サービスで暗号鍵を作成、使用、管理できます。これらのキーは、保存データを保護し、クライアントが暗号化プロセスを制御できるようにするために使用されます。
データ暗号化キー (DEK): DEK は、データを直接暗号化および復号化するキーです。Google Cloud では、セキュリティを強化するために DEK はキー暗号化キーで暗号化されます。
キー暗号化キー (KEK): KEK は、データ暗号化キーの暗号化 (ラップ) に使用される暗号化キーです。これにより、DEK の管理をデータ自体から分離することで、セキュリティのレイヤーが追加されます。
正解解説:
(オプション)
・顧客管理の暗号化キーを使用して、データ暗号化キー(DEK)を制御します。
顧客管理の暗号鍵(CMEK)を使用すると、組織は Google Cloud のデータに使用される暗号鍵を管理できるため、この選択は適切です。CMEK を使用することで、組織は自社のデータセンター内で生成および管理する鍵を使用でき、HIPAA などの規制の対象となる可能性のある個人の健康情報の取り扱いに関連する要件など、特定のコンプライアンス要件を満たすことができます。
不正解の説明:
オプション: Cloud Key Management Service を使用して、データ暗号化鍵(DEK)を調整します。
この選択が間違っている理由は、Cloud Key Management Service(KMS)を採用すると、Google のクラウドホスト型サービスを使用して DEK を調整する必要があるためです。これは、組織独自のデータセンター内でキーを生成して管理するという要件と一致しません。
オプション: Cloud Key Management Service を利用して、キー暗号化キー (KEK) を処理します。
この選択が間違っている理由は、KEK 管理に Cloud KMS を利用することは Google が生成する暗号化のコンポーネントですが、質問で必要とされているように、ユーザー自身のデータセンターで暗号鍵を作成して管理する必要があるシナリオでは十分ではないためです。
オプション: 顧客管理の暗号化キーを適用して、キー暗号化キー (KEK) を監視します。
この選択が正しくない理由は、DEK ではなく KEK に顧客管理の暗号化キーを使用することを意味するためです。KEK の管理は、実際のデータ暗号化 (DEK) にデータセンターで生成および管理された暗号化キーを使用するという要件を満たしていません。
参考：
https://cloud.google.com/storage/docs/encryption/customer-supplied-keys
https://cloud.google.com/kms/docs
https://cloud.google.com/storage/docs/encryption
</div></details>
