* [シラバス](https://www.jdla.org/business/certificate/?id=certificate_No03#)
* [Qitta](https://qiita.com/ea-yasuda/items/9831f11c189de43cb0be)
* [Study-ai](http://study-ai.com/generalist/)
	http://ai999.careers/tools/ :oF(DgV3IP*I(pgiY9K3zpo*(
* https://www.shoeisha.co.jp/book/present/9784798157559
* https://deeplearning.sakura.ne.jp/general/
	5kaku0mede10
	
### 人工知能（AI）とは（人工知能の定義）
### 人工知能をめぐる動向
* 歴史
	+ 第一次AIブームは1950年代に起こった。この頃に人工知能と呼ばれたプログラムは（ア）をもとに問題を解いていた。特に、1996年にIBMが開発した（イ）は、チェスの世界チャンピオンであるガルリ・カスパロフに勝利したことで有名である。しかし、ルールや設定が決まりきった迷路やパズルゲームなどの（ウ）と呼ばれる問題しか解けないという課題があったために、研究は下火になった。
	+ 第2次ブームは1980年代のエキスパートシステムと呼ばれるもの
		- シンボルグラウンディング問題
	+ 現在は、第3次ブーム。ビッグデータの活用から有用性が認められ、ブームとなった
* ILSVRC
	+ 現在は、kaggleに
* 探索・推論
* 知識表現
* 機械学習
* 深層学習
### 人工知能分野の問題
* 人工知能の定義
	+ まだ定まってはいない
* 人工知能の動向
	+ レベル1：単純な制御プログラム
	+ レベル2：古典的な人工知能
		- 第1次：探索と推論
			* 探索木
			* プランニング(STRIPS、SHRDLU)
			* Mini-Max法
				+ 囲碁などのゲームプログラムを行うときに、コンピュータはよく自分が打つ手がスコアが最大になるように、また相手が指すときにスコアが最小となるような戦略を立てる。この戦略を何と呼ぶか？
		- 第2次：知識表現
			* イライザ
			* エキスパートシステム（マイシン）
			* オントロジー(ライトウェイト、ヘビーウェイト)
				+ 専門家の知識を計算機のプログラムして移植していくというシステムのことをエキスパートシステムと呼ぶ。（A)は第【2】次人工知能ブームの終焉に伴い勢いは減速したが、1984年から引き続き研究され続けている【Cyc】というプロジェクトもあり、2001年に【OpenCyc】として一部が公開されている。
			* フレーム問題
			* シンボルクラウディング問題
	+ レベル3：機械学習
		- 機械学習
	+ レベル4：ディープラーニング
		- 
* トイプロブレム
	+ 明快なルールがあり，非常に限定された状況下での問題
	+ ヒューリスティックな知識
	+ ブルートフォース
現実的に解く必要のある問題に比べて比較的単純であり解きやすい
* 弱いAI
	+ 特化型人工知能
		- 定めた領域の中で複雑な処理を人間以上の能力で行える
* 強いAI
	+ 汎用人工知能
		- 人間の知能そのものを持つ
	+ AGI
* 身体性
	+ 物理的な身体があることによって、環境との相互作用ができることにより、学習や知能の構築にもたらす効果や性質を指す。
* フレーム問題
* シンボルグラウンディング問題
	+ あいまいな質問の意味を理解できない
* 特徴量設計
	+ どこに注目するべきかの特徴
* チューリングテスト
	+ アラン・チューリングが考案
		- 機械が知的（人工知能）かどうかを判定するテスト
	+ 【テスト方法】
		- 機会と人間との間で会話（人間側はディスプレイとキーボードで会話）させ、人間が機会か人間か確実に判断できなかった場合、合格となる
* シンギュラリティ
	+ 人間を追い越す、技術的特異点
* モラベックのパラドックス
	+ 子供の人工知能
		- 深層強化学習により自らで学んでいく
	+ 動物にとっては簡単なこと（例：エサをとる、敵を認識する）が、機械にとっては難しく、複雑な方程式の計算は機械にとって優しい。この矛盾を何と呼ぶか？ 
### 機械学習の具体的手法
	学習には時間が掛かり、タスクの実行には時間が掛からない
	タスクに使用する情報（特徴量）は人間が教える必要がある
* 代表的な手法
	+ 教師あり
		- 入力データと出力データ（特徴量と正解）をセットで渡して学習させモデルを作成する
	+ 教師なし
		- 入力データを渡してデータの一定のパターンやルールを抽出する
		データの共通点を見つけてクラスタに分けたり、頻出パターンの抽出を行う
* データの扱い
* 応用
### ディープラーニングの概要
	機械学習をする際の特徴量（変数）を自分で学習する
* ニューラルネットワークとディープラーニング
* 既存のニューラルネットワークにおける問題
* ディープラーニングのアプローチ
* CPU と GPU
* ディープラーニングにおけるデータ量
### ディープラーニングの手法
* 活性化関数
	+ 入力信号の総和をどのように活性化させて出力するかを制御する関数
		- ステップ関数
			* 単純パーセプトロンで使用される
		- シグモイド関数
			* 多層ニューラルネットワークで使用される
			* 主に隠れ層で使用する
			* シグモイド関数の導関数の最大値は【0.25】
		- ソフトマックス関数
			* 多層ニューラルネットワークで使用される
			* 分類問題の場合出力層で使用する
			* 多クラス分類が可能になる
		- 恒等関数
			* 多層ニューラルネットワークで使用される
			* 出力層で使用する
			* 入力をそのまま出力する
		- ReLU
			* 0以下の場合は0
			* 0より大きい場合はそのまま出力する
* 損失関数
	+ ニューラルネットワークの出力と教師データの相違を算出する関数。学習を重ねることで損失関数を最小化していく
		- 二乗和誤差
			* 回帰問題で使用する
		- クロスエントロピー誤差
			* 分類問題で使用する
* 学習率の最適化
* 更なるテクニック
* CNN
	+ AlexNet
* RNN
	+ 内部に閉路、ループ構造を持つRNN（再帰ニューラルネットワーク）は、（B)データを扱うことができるが、遠い過去の入力を保持（記憶）し、現在の出力に影響を与えることが難しい。ネットワークの構造自体は変えずに、ユニット（ノード）を工夫することでこの問題を解決する方法を（C)といい、それを更にシンプルにし計算コストを抑えたものを（D)という。ただし、（D)が（C)の改良版ということではなく、（D)よりも（C)の方が表現力が高いという主張もある。
	+ RNNは（A)のことである。その特徴は内部に【閉路】、【ループ構造】を持つことで、入力データに加え、（C)を入力として与えることで、【系列】データを扱える仕組みとなっている。
* 深層強化学習
* 深層生成モデル

### ディープラーニングの研究分野
* 画像認識
	+ ILSVRC
		- 2012: Alex Net, ジェフリーヒントン
		- 2014: VGG16, オックスフォード大学, GoogLeNet
		- 2015: 残差学習, Microsoft, ResNet
		- 2017: Squeeze and excitation
	+ SuperVision
* 自然言語処理
	「グラウンドされた意味構文解析」や「照応解析」、「談話構造解析」
	+ 機械翻訳で利用されるTransofomerやBERTなど、自然言語処理で今活躍しているものは（A)ベースのネットワークが用いられている。（A)の基本的な仕組みは、queryと（C)と【memory】である。queryは（C)により、取得する【memory】を決定し、対応する【value】を取得する。
	+ 自然言語処理において、形態素解析を基にして、その構文的（主語、述語など）の関係を明らかにする手法を【構文解析】と呼ぶ 
* 音声処理
* ロボティクス （強化学習）
* マルチモーダル

### ディープラーニングの応用に向けて 
* 産業への応用
	+ 自動運転
* 法律
* 倫理
* 現行の議論
* 活用状況
	+ 実用化が進んでおり、実績も多数ある。 
	+ 画像認識や音声認識などの分野を中心に実用化が進んでいる。
	+ ガートナーはこれから【幻滅期】に入ると予測している。


## E検定

### 回帰モデル
* 集合
#### 線形
* ベクトル
* 行列
#### ポアソン
### 解析
* 解析関数
* テイラー展開
### ベイズ統計モデル
### GLMM
### DARQ
	アクセンチュアが年次調査レポートで発表した【DARQ】とは、ブロックチェーン、人工知能、拡張・強化現実、量子コンピュータの4つのテクノロジーからとったものだ
### 中国製造2025
	中国が掲げる産業政策で、2015年5月に発表され、次世代情報技術や新エネルギー車など10の重点分野と23の品目を設定し、製造業の高度化を目指す
### seq2seq
	フリーテキストを入力とし、フリーテキストを出力するオートエンコーダデコーダを用いたモデル

## 導入

	1. 事例
	• 経営管理
		○ 経営分析
	• 営業
		○ 営業活動の成功失敗事例の抽出
	• 社内業務
		○ ヘルプデスク代行
			§ チャットボット
		○ 労務管理手続き補助
		○ 定型業務の自動化
		○ 文章校正
			§ 手書き文字のデジタル化
		○ 翻訳・多言語化
	• 品質管理
		○ 画像認識
		○ スペック判定
		○ 暗黙知のモデル化
		○ 社員教育補助
		○ クレーム対応
			§ 真のニーズ抽出

アンチパターン

## 推測統計
## 多変量解析
## 因子分析
## 記述統計

### 回帰モデル
* 集合
* パーセプトロン
#### 線形
* ベクトル
* 行列
#### ポアソン
### 解析
* 解析関数
* テイラー展開
### ベイズ統計モデル
### GLMM

# 1.人工知能
## 1-1. 人工知能とは？
### 1-1-1. 人工知能の定義
「人工知能 」とは、推論 、認識 、判断など 、人間と同じ知的な処理能力を持つ機械 （情報処理システム ）である。」・・・というのが大まかな定義。
但し、定義は人により様々みたいです。
試験としては、ジョン・マッカーシーの名前さえ覚えておけば、大丈夫。

#### 人名：ジョン・マッカーシー
「人工知能 （ A r t i f i c i a l I n t e l l i g e n c e ） 」という言葉は 、 1 9 5 6年にアメリカで開催されたダ ートマス会議において 、著名な人工知能研究者であるジョン ・マッカ ーシ ーが初めて使った言葉だそうです。

#### 名称：ダートマス会議
「人工知能 （ A r t i f i c i a l I n t e l l i g e n c e ） 」という言葉が初めて使われた会議。エニアックから10年後のことでした。

#### 人名：アーサー・サミュエル
機械学習の定義は、アーサー・サミュエルの「明示的にプログラムしなくても学習する能力をコンピューターに与える研究分野」が有名です。

### 1-2. 統計学
ここらへんも出るので、書いておきます。統計学とは、得られているデータから法則性や知見を数学的に得る分野であり、機械学習もある意味で統計学に含まれているといえます。記述統計と推計統計の2つに大別できます。「標本」や「母集団」（母集団と母数は異なる！）というキーワードも出てきます。

#### 用語：記述統計
手元のデータの分析を行うこと。

#### 用語：推計統計
手元のデータの背後にある母集団の性質を予測する。

* 統計には2種類ある。 【記述統計】は全データが対象で、【推計統計】は、元データからサンプリングしたデータから母集団の性質を推測する。

## 1-2. 人工知能の歴史
第1〜3次AIブームそれぞれの技術、具体的な取り組み、問題を抑えておきましょう。これらの歴史的経緯があって、現在の第3次AIブームがあるのですから。

### 1-2-1. 第1次AIブーム「推論・探索の時代」
1950年代後半〜1960年代、探索と推論 により問題を解く人工知能が台頭しました。但し、複雑に絡みあった現実の問題を解くには至らなかった。

#### 用語：検索と推論
あるルールとゴールが決められた枠組みの中で、なるべく早くゴールにたどり着く選択肢を選び続けること。

#### 用語：トイプロブレム
検索と推論で解ける問題はゲームの有利な手などトイプロブレム(おもちゃの問題)に限られることが第1次AIブームで明らかになり、ブームは終焉を迎えた。

#### 用語：ヒューリスティックな知識
「経験的な」知識という意味。ボードゲームの手などを効率的に探索するための「経験的な」知識。

#### 用語：ブルートフォース
「力任せ」の意味。

#### 用語：探索木
迷路をコンピューターの理解できる表現に直したもの。最短で階を得られるがメモリ使用量が多い幅優先探索と、最短で階を得られるとは限らないがメモリ使用量をセーブできる深さ優先探索がある。

#### 名称：STRIPS
プラニング（ロボットの行動計画）の技法。＜前提条件＞＜行動＞＜結果＞の3つの組み合わせで記述する。

#### 名称：SHRDLU
「積み木の世界」のプラニングを実現するテリー・ウィノグラードによって開発されたシステム。

#### 用語：Min-Max法
ゲーム戦略で、自分が指すときにスコアが最大化する手法。そのMin-Maz法の探索をできるだけ減らす手法はαβ法がある。

### 1-2-2. 第2次AIブーム「知識の時代」
1980年代には、エキスパートシステムにより問題を解く人工知能が台頭しました。しかし、専門家の知識の定式化は難しく、複雑な問題が解けるようにはならなかった。そして、第2次AIブームも終焉します。

#### 用語：エキスパートシステム
知識ベースと推論エンジンからなります。(私が作っている製品っぽいな、、、そうか、発想が古かったのか、、、と、自戒を込めて。)
* スタンフォード 大学 の エドワード・ファイゲンバウムが1960 年代 に 未知 の 有機化合物 を 特定 するエキスパートシステムを開発した。このシステムの名前は？ 【DENDRAL】

#### 知識ベース
「もし・・・ならば」という規則による知識の集まり

#### 推論エンジン
知識ベースを用いて推論を行うプログラムのこと。

#### 用語：オントロジー
知識を体系化する方法論。is-aとpart-ofという二つの関係性を覚えておきましょう。

#### 名称：Cyc（サイク）プロジェクト
全ての一般常識をコンピューターに取り込もうというプロジェクト。これは、ヘビーウェイトオントロジー（哲学的な考察が必要）の一つです。

#### 用語：ヘビーウェイトオントロジー と ライトウェイトオントロジー
Cycプロジェクトのように哲学的な考察が必要なのがヘビーウェイトオントロジーです。正確でなかったとしても、コンピューターで概念間の関係性を見つけようという取り組みがライトウェイトオントロジーとなります。ウェブマイニングや、データマイニングなどですね。

#### 名称：東ロボくん
読解力に難があり、なんらかのブレイクスルーが必要ということで、2016年に開発が凍結した。

### 1-2-3. 第3次AIブーム「機械学習と特徴表現学習の時代」
さて、2000年代以降の第3次AIブームです。発端はILSVRCという画像認識の精度を競うコンペディションでした。2012年のISLVRC2012にて、ジェフリー・ヒントン率いるトロント大学のSuperVisionチームがディープラーニングを用いて圧倒的な成績で優勝しました。これをきっかけとして、ディープラーニングが一気に脚光を浴びることとなり、現在の第3次AIブームにつながります。

#### 人名：ジェフリー・ヒントン
ディープラーニングを用いてILSVRCで2012年に優勝。

#### 名称：ILSVRC
ImageNet Large Scale Vosual Rocognition Comoetition

#### 名称：AlexNet
ILSVRC2012でジェフリー・ヒントンが用いた8層のディープニューラルネットワークで、畳み込みニューラルネットワーク(CNN)の一種。

#### 用語：特徴表現学習
機械学習自身に特徴量を発見させるアプローチのこと。

## 1-3. 人工知能にまつわる問題
試験対策としても、一般的な会話知識としても、押さえておく価値の高い内容ですね。いくつか書きます。

### 1-3-1. チューリングテスト
ある機械が人工知能かどうかを判定するためのテスト。人間の審査員に、相手がAIか否かを当ててもらうもの。

#### 人名：アラン・チューリング
1950年の論文でチューリングテストを発表した。

#### 名称：ELIZA(イライザ)
1966年に発表された自然言語処理プログラム。精神科セラピストの役割を演じリルプログラムで、かなりの判定者を惑わせたらしい。チューリングテストをめぐる大きなターニングポイント。ICCC,RFC439

#### 名称：PARRY(パリー)
イライザの後に開発され、これも多くの判定者を誤らせた。
１９７２年に偏執病的統合失調症患者をシミュレートする目的で作られたチャットボット

#### 名称：RFC439
イライザとパリーが会話した最初の記録はRFC439として残されている。

### 1-3–2. フレーム問題
どうやったって、AIは定められたフレーム内の問題しか取り扱えない。

#### 用語：強いAI（汎用AI）と弱いAI（特化型AI）
フレーム問題に捉われず人間のようにあらゆる問題に適切に対処できるAIを強いAI、フレーム問題に縛られたままのAIを弱いAIと呼びます。

#### 人名：ダニエル・デネット
「今しようとしていることに関係あることがらだけを選び出すことが、実は非常に難しい」

#### 用語：中国語の部屋
ジョン・サールが「強いAIは不可能だ」と証明するために用いた例え話。

### 1-3-3. シンギュラリティ
「人工知能が人間を超えて文明の主役に取って代わる」時点のこと。シンギュラリティ(技術的特異点)と呼ばれています。

#### 人名：レイ・カーワルツ
「シンギュラリティは2045年に到達する」

#### 人名：ヒューゴ・デ・ガリス
「シンギュラリティは21世紀後半に来る」
「そのとき、人工知能は人間の知能の1兆の1兆倍になる」

#### 人名：イーロン・マスク
シンギュラリティ到来に危機感を持ち、非営利の研究組織OpenAIを設立。テスラやスペースXの人ですね。

#### 人名：オレン・エツィオー二
「100万年後にシンギュラリティが来るかもしれないけど、そんな終末思想は馬鹿げてる」といった趣旨のことを言った人。

#### 人名：スティーブン・ホーキング
「AIの完成は人類の終焉を意味するかもしれない」

さて、最後に補足ですが有名なレイ・カーワルツさんは、AIが人間を超える程度だったら2029に訪れるといっているようです。でもそれはシンギュラリティじゃないですね。AI自身がAIを作り出すところをシンギュラリティ、すなわち特異点と捉え、それが2045年だといっているようですね。

### 1-3-4. シンボルグラウンディング問題(記号設置問題)
記号 （シンボル ）とその対象がいかにして結び付くかという問題です 。フレ ーム問題。コンピュ ータは 「記号 （文字 ） 」の意味が分かっていないので 、記号が意味するものと結び付けることができない。

### 1-3-5. 身体性
知能が成立するためには身体が不可欠であるという考え方。「外界と相互作用できる身体がないと 、概念はとらえきれない 」と考える。


### 1-3-6. AI効果
人工知能の原理が分かってしまうと、「それはAIではない」と思われてしまう人間心理。

### 1-3-7. LAWS
自律型致死兵器（LAWS）とは、AIなどにより完全に自律して、かつ強力な殺傷能力を持つ兵器のことです。まだ現段階では存在していませんが、議論は続いています。

#### 用語：アシロマAI原則
「AIによる軍拡競争は避けるべきである」

# 2. 機械学習

## 2-1. 機械学習の3種類
人工知能のプログラム自身が学習する仕組みで、データに潜むパターンを学習します 。それでは、教師あり学習、教師なし学習、強化学習の3種類を押さえましょう！

### 2-1-2. 教師あり機械学習
教師データを使って予測値を正解ラベルに近づけることを目標に学習を行う手法です。データ間の関係性が分かります。つきつめていくと、やることは「分類」と「回帰」の2つに収束します。いや、この2つだって、上手く分類できる線を引くか、上手くフィッティングできる線を引くか、といった違いでしかないので、つきつめていくと同じです。！

#### 用語：回帰(regression)
出力値の予測。代表的なものは線形回帰。線形回帰には単回帰分析と重回帰分析がある。深層学習でも回帰を行うことがある。

#### 用語：分類(classification)
サポートベクターマシン、決定木、ランダムフォレスト、ロジスティック回帰、kNN法などの手法がある。深層学習でも分類を行うことができる。

### 2-1-2. 教師なし機械学習
教師データを使わずに、データの本質的な構造を浮かび上がらせる手法です。代表的な手法はクラスタリングと次元削減です。
* 機械学習の中で、入力データのみからデータの本質的な特徴をあぶり出すために行われる学習のことをなんと呼ぶか？ 
* 自己符号化器はニューラルネットワークによる【教師なし学習】の代表的な応用であり、出力が入力に近づくようにニューラルネットを学習させる。主に【次元削減】のために利用されることが多く、活性化関数に恒等写像を用いた場合の3層の自己符号化器は【主成分分析】と同様の結果を返す。自己符号化器を多層化すると、ディープニューラルネット同様に勾配消失問題が生じるため、複雑な内部表現を得ることは困難であった。この問題に対して2006年頃に【ヒントん】らは、単層の自己符号化器に分割し入力層から繰り返し学習させる【層ごとの貪欲法】を積層自己符号化器に適用することで、汎用的な自己符号化器の利用を可能とした。また、自己符号化器の代表的な応用例として【仮想計測】がある。

#### 用語：クラスタリング
例えばk-means法などで与えられたデータ群をいくつかのあつまり(クラスタ)に分けることで、データの本質的な構造を浮かび上がらせる手法。クラス分類とは異なるものなので、注意。
* K-means法はデータの本質的な特徴をあぶり出すために有効な（A)という手法の一つです。（A)の手法には他に、【x-means】や【Ward法】などがある。

#### 用語：次元削減
データの情報を失わないように、データを低い次元に圧縮する手法の総称。例えば、身長と体重から肥満度を表すBMIを計算する手法がイメージしやすいですね。主成分分析が、よく用いられる手法です。

* 主成分分析とオートエンコーダの共通点は、どちらも【次元圧縮】、【教師なし学習】ができることである。
* 機械学習の手法の中で、分散が最大になる方向に新しい軸を定義しその軸にデータをマッピングしていくことで次元圧縮を実現する手法をなんと呼ぶか？【PCA】

#### 2-1-3. 強化学習
収益(報酬の和)を最大化する方策を獲得することを目的とした手法です。以下の用語を覚えておきましょう

エージェント=ある環境で動くプレイヤー
状態=エージェントが置かれている環境
行動=エージェントがとる行動
収益=エージェントが行動することで得られる評価値
価値関数=将来的に得られる収益の期待値を表す関数。
方策=ある状態のとき、どの行動をとるべきかを示す関数。(決定的に決めるものと確率的に決めるものがある。)というか、方策は関数なのね。
Deep-Q-Network (DQN) =価値関数を計算するディープニューラルネットワーク。ディープマインド社が作った。これを使うものは深層強化学習と呼ぶ。

* 2015年10月にこれまで人工知能には不可能だと言われていた、囲碁のプロ棋士を【google】社傘下の(B)社が開発した（C)というシステムが破った。この（C)には【DQN】というディープニューラルネットワークを用いた強化学習の手法が用いられた。

### 2-1-4. その他の機械学習
半教師学習という、教師あり学習におけるラベル付けのコストを低減するために用いられる手法もあるそうです。

## 2-2. 機械学習のプロセス
基礎集計 → 前処理 → 特徴量エンジニアリング → 計算(ここは割愛) → 性能評価のプロセスを、それぞれ見ていきましょう。
* 機械学習の前に、事前にデータの傾向や特徴を捉えるために散布図を確認したり、相関係数を計算することを何と呼ぶか？ 

### 2-2-1. 基礎集計
データの動向を事前に把握します。
各種代表値(平均や分散)を見たり、散布図行列をプロットしたり、相関行列を表示して傾向を見たりします。

### 2-2-2. 前処理
データをモデルに正しく入力できる形にします。

#### 用語：正規化
データをスケーリングする。

#### 用語：標準化
例えば、平均を0、分散を1に変換します。

#### 用語：名寄せ
表記の揺れなどの統一だそうです。

引っかけ問題で出題されやすい「正則化」は過学習を抑制するための手法であって、前処理の用語ではありません。

### 2-2-3. 特徴量エンジニアリング
モデルが認識しやすい特徴をデータから作ること。文字列の日付データを数値列に変換したり、多項式特徴量を生成したりすることなのだそうな。カテゴリカル変数(何かの種類を表す変)をカテゴリカル変数であるとわかるようにすることも、特徴量エンジニアリングです。

#### 用語：特徴量
扱っているデータをよく表す特徴を数値で示したもの。

#### 用語：one-hot-encoding
たった一つの成分だけが1、残りの成分が0という形の特徴量(ベクトル)に変換すること。
重回帰分析でやる多重共線性の検出も、このプロセスでやりますが、これについては後述。

* 単語をベクトルで表現することを何表現と呼ぶか？【分散表現】


### 2-2-4. 性能評価
データは、訓練データとテストデータに分けます。テストデータを使ってモデルの性能評価をするわけです。モデルが過学習を起こしていないかを調べましょう。

#### 用語：過学習(オーバーフィッティング)
学習に用いたデータに対しては高い精度で予測できるのに、学習に用いていないデータでは精度が上がらない事象のこと。機械学習における最大の問題と呼ばれています。

* 学習済みのモデルが、学習に使ったデータに対してはよく予測できるが、未知のデータにうまく適用できないことを何と呼ぶか？ 

* 過学習を防ぐ正則化について、【Lasso】のように、自動的に「特徴選択」が行われるため、【スパース】正則化と捉えることができる。【Ridge】は、パラメータのノルムを小さくおさえることができるという性質がある。【Lasso】と【スパース】を組み合わせたものを（D)という。

、、、さて、少し思うところがあるのですが、、、過学習って、学習データが多過ぎて学習しすぎて精度が下がる事象のことをいうと思っていたのですが、少しニュアンスが違うのですね！勘違いしていました、、、

モデルの性能評価に用いる手法にはホールドアウト法と交差検証法の2種類があります。

#### 用語：ホールドアウト法
#### 用語：交差検証法(クロスバリデーション法)
k分割交差検証という書き方になっていることもありますが同じものです。計算量は大きくなりますが、データが少なくてもホールドアウト法と比較して信頼できる精度が得られます。
* モデルが過学習をしていないかを確認するために行う検証の方法として、データを複数の方法で学習データとテストデータに分割し、その平均を用いて検証を行う方法をなんと呼ぶか？

#### 用語：正解率
混合行列をもとに、次の数式で正解率(accuracy)を求めます。
正解率 ＝（TP+TN）／（TP+TN+FP+FN）

正解率だけでなく、適合率、再現率、F値という数値を用いて評価することもあります。覚えておきましょう。というのも、陰陽のデータが半々なら問題はないのですが、半々じゃない場合は、考えた方がよいそうです。

##### 適合率
TP／（TP＋FP）
予測が正の中で、正だと予測できたもの。試験では、「予測が」という言葉から始まっていたら適合率のことです。


##### 再現率
TP／（TP＋FN）
実際に正であるものの中で、正だと予測出来た者の割合。試験では、「実際に」という言葉から始まっていたら適合率のことです。

##### F値
適合率と再現率の調和平均。適合率だけでも再現率だけでも予測が偏ってしまうことがあるために、こういう値を使うこともあります。

#### 用語：正則化
学習に用いる式に項を追加することによって、とりうる重みの範囲を制限して、過度に重みが訓練データに対してのみ調整されてしまうことを防ぐ手法です。ただし、やりすぎると、アンダーフィッティングを起こしてしまいます。

* 機械学習においては過学習を避けるために、訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である【正則化】を用いることが多い。また複数のモデルの予測結果の平均を利用する【アンサンブル学習】がある。他にもディープニューラルネットワークに対しては、ランダムに一定の割合のノードを削除して学習を行う【ドロップアウト】が有効とされている。【正則化】手法にはいくつかのパラメータをスパースにする【Lasso】などがある。

##### L1正則化
一部のパラメーターをゼロにすることで、特徴選択をおこなうことができる。これを線形回帰に適用した手法をラッソ回帰と呼ぶ。

##### L2正則化
パラメーターの大きさに応じてゼロに近づけることで汎化された滑らかなモデルを得ることができる。これを線形回帰に適用した手法をリッジ回帰と呼ぶ。そして、ラッソ回帰とリッジ回帰の両方を組み合わせた手法をElastic Netと呼びます。
* 過学習を防ぐ正則化について、（A）のように、自動的に「特徴選択」が行われるため、（B)正則化と捉えることができる。（C)は、パラメータのノルムを小さくおさえることができるという性質がある。（A)と（B）を組み合わせたものをElastic Netという。

## 2-3. 機械学習の具体的な手法
さて、ここまでがディープラーニング検定の前半です。

### 2-3-1. 線形回帰
回帰の代表的な手法です。

#### 用語：単回帰分析
1つの説明変数(例：その日の気温)から目的変数(例：その日の飲み物の売上)を予測する。

#### 用語：重回帰分析
複数の説明変数から目的変数を予測する。
重回帰分析をやる際には、多重共線性に注意しなくてはならない。

#### 用語：多重共線性
マルチコ(multicollinearity)とも呼ばれる。
相関係数が高い(1か-1に近い)特徴量の組みを同時に説明変数に選ぶと、予測が上手くいかなくなる事象のこと。

### 2-3-2. ロジスティック回帰
線形回帰の「回帰」ではなく「分類」版という説明が教科書に書かれていた。
線形回帰を分類問題に応用するためのアルゴリズムで、シグモイド関数を使います。
2種類の分類ではなく多クラスの分類となる場合は、ソフトマックス関数を使います。
ちなみに、ロジスティック回帰は、ニューラルネットワークの一種と考えることもできる。
対数オッズを線形回帰により予測し、出力の正規化によって予測結果を確率として解釈します。
目的関数としては尤度関数を使います。
* ロジスティック回帰は【回帰】問題を解くための手法であり、関数表現自体は、回帰問題を解く線形C.と変わらない。

### 2-3-3. kNN法
分類の一手法。未知のデータの近くからk個のデータを調べて多数決によって所属クラスを決定するアルゴリズム。欠点としては、クラスのサンプル数の偏りに弱い。ちなみに、kの値はエンジニアが事前に設定しておくパラメーターであり、こういったパラメーターはハイパーパラメーターと呼ばれます。

* ディープラーニニングする際に、ニューロン数や何層にするか、学習率はどの程度にするか等事前に決めておくことは、多数ある。これらのパラメータのことを何と呼ぶか？【ハイパーパラメータ】

### 2-3-4. 決定木
条件分岐を繰り返すことにより分類や回帰を行うためのアルゴリズム。情報利得の最大化を実現するように決定する。データのスケールを事前にそろえておく必要がなく、分析の説明が容易というメリットがあります。
* ジニ係数やエントロピーという不純度によって、データを分割するための分岐する[木構造]を作っていく機械学習の手法は何というか？ 【決定木】

### 2-3-5. ランダムフォレスト
決定木を用いる手法。特徴量をランダムに選び出して、ランダムに複数の決定木を作り出し、それぞれの決定木の結果を用いて多数決を採る手法。

#### 用語：ブーストストラップサンプリング
全てのデータをつかうのではなく、それぞれの決定木に対して一部のデータを取り出して学習させる。

#### 用語：アンサンブル学習
ランダムフォレストのように複数のモデルで学習させる手法のこと。

#### 用語：バギング
全体から一部のデータを用いて複数のモデルを用いて学習する手法。ランダムフォレストは、バギングの中でも決定木を用いる手法という位置づけです。

* 決定木を応用した【バギング】は複数モデルを並列に学習させ多数決をとる、(B)は直列（順番）に学習し前の分類器の弱点を克服するという違いがある。

### 2-3-6. ブースティング
バギングと同様に一部のデータを繰り返し抽出して複数のモデルを学習する手法です。バギングとの違いですが、複数のモデルを一気に並列作成する（バギング）か、逐次的に作成する（ブースティング）か、というところです。ブースティングもモデル部分には決定木が用いられており、AbaBoostや勾配ブースティングやXgBoostなんかが有名だそうな。ランダムフォレストと勾配ブースティングを比べた時、並列的なランダムフォレストの方が計算は速いが、精度は勾配ブースティングの方が良いといわれています。

### 2-3-7. 次元削減
データに複数ある変数のうち、分析に不要なものを削除します。寄与率を調べれば各成分の重要度が分かり、主成分を調べれば各成分の意味を推測することができます。

#### 用語：次元の呪い
機械学習において次元が増えると計算量や学習に必要なサンプル数が爆発的に増えて様々な不都合が生じるという法則。

### 2-3-8. サポートベクターマシン
もともとは2クラス分類のアルゴリズムです。「マージンの最大化」というコンセプトのもと、2つのクラスを線形分離します。ディープラーニング以前に「人気」ではあったが、汎化性能が高い手法であったわけではない(そのような汎化性能の差に明確な結論は出ていない)という引っ掛け問題が出ます。

#### 用語：カーネル法
SVMは、線形分離可能でないデータ(直線でないデータに対してもカーネル法を組み合わせることで決定境界を求めることができます。
データをあえて高次元空間に写像するための関数をカーネル関数、その計算をカーネルトリックといいます。
* マージンの最大化を行うことにより、分離境界平面（ハイパープレーン）を得て分類を行う教師あり学習の手法を次から選べ。 【SVM】
* 機械学習の２値分類問題における性能指標について、サンプル全体のうち予測が正解したものの割合のことをなんと呼びますか？【正解率】
* 機械学習の手法の中で、マージンを最大化するような分離超平面を得る手法のことをなんと呼ぶか

### 2-3-9. ニューラルネットワーク
以降に、ディープラーニングが控えているので、触りだけ書きます。

#### 用語：単純パーセプトロン
線形分離可能な(直線を使って分離できる)問題であれば、解けます。ステップ関数を使います。単純パーセプトロンの限界は、多層にしてバックプロパゲーション（誤差逆伝搬学習法）を用いて学習すれば克服できることが示された。
* 単純パーセプトロンで用いられる誤差関数を答えよ【ヒンジ損失関数】
* 単純パーセプトロンに用いられる活性化関数は何か　【ステップ関数】
* 単純パーセプトロンで解くことができる問題のことを、【線形分離可能問題】といい、解くことができない問題と呼ぶ。

#### 用語：多層パーセプトロン
非線形分離も可能です。これの層が深くなったやつがディープラーニングです。やっと、ディープラーニングに近づいてきましたね。

#### 用語：バイアス
* ニューラルネットワークには【バイアス】などの多くのハイパーパラメータが存在し、これらの値が精度に大きな影響を与える。ハイパーパラメータのチューニング方法としては、パラメータの候補値を指定し、それらの組み合わせを調べる【グリッドサーチ】などがある。また、近年は、ハイパーパラメータを含め最適化問題とする【ベイズ最適化】が効率的なチューニング方法として注目をあびている。

# 3. ディープラーニング
## 3-1. なぜ、今、ディープラーニング？
多層パーセプトロンの隠れ層を増やせば、より複雑な問題を解くことができる、、、というアイデアは、昔からあったそうです。
ですが、ディープニューラルネットワークが現実的につかえるようになったのは最近のこと。その背景には、いくつかのブレイクスルーがありました。よくいわれるのは、クラウド上の膨大なマシンスペックと、インターネット上の膨大なビッグデータがブレークスルーを引き起こしたということなのですが、、、実際にそれだけなのでしょうか。一つひとつ見ていきましょう！

* ディープラーニングは、ニューラルネットワークを多層化したものであり、観測データから本質的な情報である（ア）を自動的に抽出できる点が特徴である。また、従来の機械学習手法と比べると、【学習が必要なパラメータ数が多い、計算量が多い、より複雑な関数を近似できる】という性質も持っている。

### 3-1-1. 事前学習
さて、なかなかディープラーニングが実現しなかった理由の一つ目は、勾配消失問題です。これにたいしてブレイクスルーをもたらした手法が事前学習でした。ただし、事前学習は計算コストが非常に高くつくことから、最近では事前学習無しのアプローチとして、活性化関数を工夫する手法が主流になっているようです。それはさておき、ジェフリー・ヒントンが画像解析でブレイクスルーをもたらすに至ったアイデアですから、一つひとつの用語を抑えていきましょう。

#### 用語：勾配消失問題
ニューラルネットワークの隠れ層を深くしていくと、隠れ層を遡るごとに伝搬していく誤差が小さくなっていくことにより、勾配がなくなってしまうという事象。活性化関数であるシグモイド関数の微分値が最大でも0.25にしかならないため、掛け算していくと値がどんどん小さくなっていってしまうようです。

* ディープニューラルネットワークの普及に貢献した一つの要素に、【勾配消失問題】を克服する手法が提案されたことがある。【勾配消失問題】は誤差逆伝播法において、（イ）ことによって生じるとされている。【勾配消失問題】に対処するための一つの方法として、あらかじめ良い重みの初期値を計算する【事前学習】や、活性化関数に【ReLU】を利用するなどがある。

#### 用語：オートエンコーダ（自己符号化機）
ジェフリー・ヒントンが提唱した勾配消失問題の解決策です。可視層と隠れ層の2層からなるネットワークです。エンコーダとデコーダからなる。入力層と出力層の数はおなじだが、中間層のノード数はそれより少ない。「正解ラベル」として入力自身を用いることで、次元削減ができます。これだけだと、ディープニューラルネットワークではありませんので、次も見てみましょう。

#### 用語：積層オートエンコーダー（ディープオートエンコーダー）
ディープニューラルネットワークの全ての層を一気に学習させるのではなく、入力層に近い層から順番に学習させるという、逐次的な方法です。順番に学習していくことによって、それぞれの隠れ層の重みが調整されます。このオートエンコーダーを順番に学習していく手順のことを、事前学習（pre-training）と呼びます。積層オートエンコーダは、事前学習と（後述の）ファインチューニングの工程で構成されています。

#### 用語：ファインチューニング
オートエンコーダーを積み重ねるだけでは、最後にラベルを出すことはできません。積層オートエンコーダーを積み重ねていった最後に、別の層を足します。足される層は、2値分類ならシグモイド関数のロジスティック回帰、他項分類ならソフトマックス関数のロジスティック回帰、回帰なら線形回帰の層となります。最後に足した層も重みの調整が必要になります。事前学習により調整されているので、最後の仕上げとしてネットワーク全体を学習させると、誤差が上手いこと伝播されるのだそうな。この最後の工程をファインチューニングと呼びます。

#### 名称：深層信念ネットワーク（deep belief networks）と制限付きボルツマンマシン
ジェフリー・ヒントンが提唱した手法の名前です。事前学習を用いたディープラーニングの手法として、覚えておきましょう。

### 3-2-2. GPU
もちろん、ハードウェア性能工場、特にGPU登場は、ディープラーニング実現に重要なブレイクスルーとなりました。ムーアの法則に沿って、半導体の性能と集積は18か月おきに2倍になっているようですね。

#### 用語：GPGPU
CPUと異なり、様々なタスクをこなすのは不得意です。同じような並列計算処理が大規模に行われる場合に、パワーを発揮します。画像目的以外の仕様に最適化されたGPUのことをGPGPUと呼びます。GPGPUの開発をリードしたNVDIA社の名前は、頻出っぽいです。あと、Google社のテンソル計算処理に最適化された演算装置は、TPUと呼ばれているそうです。

### 3-2-3. データ量
ディープラーニングを実現するためには、データも大量に必要です。ですが、そんなの今さら当然ですよね。バーニーおじさんだけおぼえておきましょう。

#### 用語：バーニーおじさんのルール
「モデルのパラメーター数の10倍のデータが必要」という経験則です。とはいえ、これは明確な指標でも何でもない。バーニーおじさんって、だれなのか？については、次の記事を参照のこと。この検定を勉強している人は、誰でも気になりますよね。そういうネタなのかな。うーむ。
http://ikesala.com/g3/#i-9


## 3-2. ディープラーニングの理論
### 3-2-1. 活性化関数
活性化関数にシグモイド関数を利用したとき問題となったのが、勾配消失問題でした。さて、いくつかの関数が提案されています。どれが良くてどれが悪いというのはありません。

#### 用語：tanh関数（ハイパボリックタンジェント）
微分の最大値は1になります。
* ハイパボリックタンジェント(tanh)は以前はよく（A)として使われていたが、（B)の問題があるため、次第に【ReLU】に取って代わられた。

#### 用語：ReLU関数
xがゼロ以下のときは、微分値もゼロになってしまう。
* 昨今ディープラーニングで隠れ層によく用いられる活性化関数は何か？ 

#### 用語：Leakly ReLU関数
xがゼロ以下でもわずかな傾きを持っている。他にも、Parametric ReLUやRandomize ReLUなど、いろいろあります。

### 3-2-2. 勾配降下法
勾配に沿って降りていくことで階を探索する手法です。最適値を探すために使います。

* ディープニューラルネットワークの学習の目的は【出力関数】を最小化することであり、この最適化のために勾配降下法が利用される。しかし、勾配降下法にはパラメータの勾配を数値的に求めると【計算量が膨大となってしまう】問題があり、このような問題を避けるために誤差逆伝播法が利用される。またディープラーニングには過学習の問題もある。過学習とは【訓練誤差】は小さいにも関わらず、【汎化誤差】が小さくならないことであり、これらの問題を克服するために様々な手法の開発が進められている。

* 勾配降下法においてパラメータの更新量を決める【学習率】の決定は重要である。例えば【学習率】が小さすぎると【収束が遅くなる】などの課題が生じるため、【スタッキング】などの様々な【学習率】調整手法が提案されている。

* ディープニューラルネットワークのパラメータ最適化手法として【確定的こう配降下法】などの勾配降下法が適用される。しかし、勾配降下法には【大域的最適解への収束】などの問題があり、これらの問題に対処するために、学習率をパラメータに適応させることで自動的に学習率を調整することができる【Adagrad】や勾配の平均と分散をオンラインで推定し利用する【Adam】が利用されてきた

#### 用語：エポック
訓練データを何度学習に用いたか。


#### 用語：イテレーション
重みを何度更新したか。

#### 用語：逐次学習・ミニバッチ学習・バッチ学習
重みの更新タイミングのことです。バッチ学習ではエポックとイテレーションが同じになりますが、それ以外では異なります。ミニバッチでランダムにデータをピックアップして重みを更新する際の勾配降下法を、確率的勾配降下法と呼びます。
* オンライン学習とバッチ学習の中間とも呼ぶべき学習のことを何と呼ぶか？これはSGDとして知られている。 
【ミニバッチ学習】

#### 用語：学習率
勾配に沿って、一度にどれだけ降りていくか、を決めるハイパーパラメーター（計算時に指定する変数）のこと。

#### 用語：局所最適解 と 大域最適解
見せかけの最適解を局所最適解、本当の最適解を大域最適解と呼びます。最初は学習率を大きく設定して、適切なタイミングで学習率の値を小さくしていく工夫が必要になります。

#### 用語：鞍点
ディープラーニングでは次元が大きいので、鞍点にはまるって抜け出せなくなることがあります。そのような停留状態をプラトーといいます。抜け出る手法として、昔からモーメンタムがありますが、最近はAdamやRMSpropがあるそうな。

#### 用語：停留点
局所最適解でも大域最適解でもないのに勾配がゼロになる点のこと。例えば、山頂ですね。

### 3-2-3. その他のテクニック
#### 用語：ドロップアウト
オーバーフィッティングを解消する手法で、エポック毎にランダムにニューロンをドロップアウトさせて計算します。毎回モデルが変わることになるため、これはアンサンブル学習の一種です。

#### 用語：early stopping
過学習する前に、早めに学習を打ち切る方法です。シンプルで、どんなモデルにも適用できる手法です。ジェフリー・ヒントンは、”Beautiful FREE Lunch”と表現しているそうですが、、、この元ネタのノーフリーランチ定理は後述。

#### 用語：ノーフリーランチ定理
「あらゆる問題で性能の良い汎用最適化戦略は理論上不可能」という定理。

#### 用語：醜いアヒルの子の定理
* 機械学習の分野において有名な二つの定理について扱う。【醜いアヒルの子の定理】は、認知できる全ての客観的な特徴に基づくと全ての対象は同程度に類似している、つまり特徴を選択しなければ表現の類似度に基づく分類は不可能であることを示している。【ノーフリーランチ定理】は、全てのタスクに対して常に他よりすぐれている万能的なアルゴリズムは存在しないことを示している。

#### 用語：正規化
データ全体の調整。いろいろ種類はあるのですが、例えば、各特徴量を0～1の範囲に変換する処理です。

#### 用語：標準化
各特徴量の平均を0、分散を1にする、、、すなわち、各特徴量を正規分布に従うように変換することです。各特徴量の分散をそろえておくことで、それぞれの特徴量の動きに対する感度を揃えられます。

#### 用語：白色化
標準化より一歩踏み込んだ手法で、各特徴量を無相関化した上で、標準化します。

#### 用語：Xavierの初期値、Heの初期値
重みの初期値も、ディープラーニングの工夫しどころの一つです。単純にダンラブにするのではなく、乱数にネットワークの大きさに合わせた適当な係数をかけることで、データの分布が崩れにくい初期値が得られるのだそうな。シグモイド関数に対してはXavierの初期値、ReLU関数に対してはHeの初期値がよいとされているようです。

#### 用語：バッチ正規化
ディープラーニングの各層において、活性化関数を書ける前に伝播してきたデータを正規化する手法です。これで、オーバーフィッティングしづらくなることが知られています。

* 大規模なディープニューラルネットワークの学習では学習するべきパラメータ数が膨大となるため、処理の高速化が必要となる。2012年に提案された分散並列技術である【DistBelief】や画像処理に特化したプロセッサの【GPU】は大規模なニューラルネットワークの学習を実現するために利用されてきた。また、大規模なニューラルネットワークの学習が困難となる原因の一つとして、ある層の入力がそれより下層の学習が進むにつれて変化する【内部共変量シフト】がある。【内部共変量シフト】を防ぐために出力値の分布の偏りを抑制する【バッチ正規化】が2015年に提案されている。


## 3-3. ディープラーニングの具体的な手法
### 3-3-1. CNN（畳み込みニューラルネットワーク）
画像をそのまま2次元ので入力に用いられるモデルです。あのAlexNetもCNNですよ。ちなみに、ひっかけ問題で画像以外でもCNNは使えるか？というものが出てきます。音声認識ではCNNが良いという話もあるそうで、まぁ、使っても問題はないのですがという引っかけです。

* 畳み込みニューラルネットワークは【画像認識】のために作られたが、【自然言語処理】や【音声認識】にも応用されることがある。

* 画像の一定範囲ごとに入力の特徴量が得られるようなディープラーニングの手法を答えてください。 

* 畳み込みニューラルネットワーク(CNN)は時系列データを扱うのが苦手であるため、RNNのように音声認識や自然言語処理に使われることはまずない。これは正しい認識か？ 【誤り】

#### 用語：ネオコグニトロン
福島邦彦さんによって考えられた初期のモデルです。人間のもつ視覚野の神経細胞の2つの働きをもしてみようという試みです。

#### 用語：LeNet
その後、ヤン・ルカンによって作られたCNNのモデルです。こちらは誤差逆伝播法を使います。畳み込み層とプーリング層の2種類が交互に複数組み合わさります。

#### 用語：CNN
畳み込み層とプーリング層を積み重ねる順伝播型（逆伝播ではない）のディープニューラルネットワークです。
* CNNにおいて、特徴表現を抽出する層を、(A)といい、情報を集約する層のことを【プーリング】層という。

#### 用語：FFN
順伝播型のディープニューラルネットワークです。

#### 用語：畳み込み（Convolution）
カーネルとも呼ばれるフィルタを用いて画像から特徴を抽出する操作のことです。フィルタを画像の左上から順番に重ね合わせていき、画像とフィルタの値をそれぞれかけあわせたものの挿話をとった値を求めていく処理です。畳み込みによって新たに得られた二次元データを特徴マップと呼びます。CNNでは、各フィルタをどのような値にすれば良いかを学習していくとになります。つまり、このフィルタが、ニューラルネットワークでいうところの重みになります。この畳み込みの処理は、人間の視覚やが持つ局所受容野に対応していて、移動普遍性の獲得に貢献します。（但し、回転普遍性は持っていない。）「位置のズレ」に強いモデルができます。大きな畳み込みを1層とするよりも、小さな畳み込みを多層で積み重ねるのが、最近の流行りです。

#### 用語：プーリング
決められた演算を行うだけで、ダウンサンプリングやサブサンプリングともよばれいます。たとえば、Maxプーリングと呼ばれる処理では、画像の特徴マップの最大値を抽出していきます。avg（平均）プーリングという手法もあります。計算するだけなので、学習すべきパラメーターはありません。

* 畳み込みニューラルネットワークは、畳み込み層とプーリング層を積み上げた構成をしている。画像データを用いた場合、畳み込み層では、出力画像のサイズを調整するために元の画像の周りを固定の値で埋める【パッティング】行う。プーリング層では畳み込み層の出力を圧縮するプーリングを行う、【誤差プーリング】などの手法がある。

#### 用語：全結合層
最後は、イヌやネコといった一次元の出力になりますので、そういった層が必要です。但し、最近のCNNでは、全結合層を用いないケースも大きいです。全結合層の代わりに、1つの特徴マップに1つのクラスを対応させることで分類を行うGlobal Average Poolongと呼ばれる処理を行うことが多いみたいです。

#### 用語：データ拡張（data augmentation）
上下左右にずらしたり反転させたりする、データの「水増し」のこと。いまや、画像認識を行う上では必須の処理なのだそうな。


さて、CNNは発展形として、AlexNet以降にもVGCやGoogleLeNetが出てきて記録を更新しています。Google LeNetでは、Inceptionモジュールというブロックを構成し、それを積み重ねたネットワークとすることで並列計算を行いやすくしました。超深層ネットワークとなる場合には、さらなる工夫が必要で、Skip Connectionとよばれる層を超えた結合を加える工夫もあります。この結合が導入されたネットワークをResNetと呼びます。


#### 用語：転移学習
一から、こんなモデルを作るの、不可能ですよね。そこで、学習済のネットワークを利用して新しいタスクの識別に活用することを転移学習と呼んでいます。これで、世の中の皆様が、いろいろ画像認識で遊べるようになってきたわけなのですね。

### 3-3-2. RNN（リカレントニューラルネットワーク）
閉路を持つニューラルネットワークです。時間軸に対して何かのパターンを持っている場合の予測には、RNNを使います。通常のニューラルネットワークでは表現できない「過去の重み」を表現できます。RNNの基本形を見てみると、通常と異なり過去の隠れ層が追加されていることが分かります。逆伝播する誤差も過去にさかのぼって反映する必要があります。これは、BackPropagation Tough-Time(BPTT)と呼ばれています。

* 内部に（A)を持つRNN（再帰ニューラルネットワーク）は、【時系列】、【系列】データを扱うことができるが、遠い過去の入力を保持（記憶）し、現在の出力に影響を与えることが難しい。ネットワークの構造自体は変えずに、ユニット（ノード）を工夫することでこの問題を解決する方法を【LSTM】といい、それを更にシンプルにし計算コストを抑えたものを（D)という。ただし、（D)が【LSTM】の改良版ということではなく、（D)よりも【LSTM】の方が表現力が高いという主張もある。

* RNNは（ア）系列データの処理に長けているニューラルネットワークである。RNNは、【内部にループ構造を持つため】勾配消失問題が起きやすいという特徴を持っていたが、RNNの一種であるLSTMでは（ウ）を含むLSTM Blockを組み込むことで、長期間の系列情報に対しても勾配消失せずに学習を行うことができた。

#### 用語：LSTM
RNNの一種です。勾配消失問題、入力重み衝突、出力重み衝突といった問題を解決した手法です。LSTMを簡略化して、計算量を少なくしたGRUというモデルもあります。一応、どちらの手法が良い悪いというわけではありません。

### 3-3-3. 深層強化学習
用語：Deep-Q-Network
DeepMind社のDeep-Q-Network（DQN）が有名です。あの、Alpha Goも深層強化学習ですね。

* 深層学習を含めて機械学習において精度の高い学習をするためには、観測データの適切な前処理が必須である。異なるスケールの特徴量を同時に扱えるようにするために、平均を0に分散を1に規格化する【標準化】や、特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る【主成分分析】などは広く利用されている。また、画像処理の分野においては、減算正規化と除算正規化の処理を行う【局所コントラスト正規化】などが前処理として利用され、【OpenCV】などの画像処理に特化したライブラリで行うことができる。また、自然言語処理の分野においては、文章に単語が含まれているかどうかを考えてテキストデータを数値化する【bag-og-words】や文章に含まれる単語の重要度を特徴量とする【TF-IDF】などがある。

### 3-3-4. 深層生成モデル
ディープラーニングは、認識・識別タスクだけでなく生成タスクにも応用され始めています。

#### 用語：VAE（変分オートエンコーダー）
画像が生成できるらしい。
* オートエンコーダを応用した生成モデルで、画像を生成することができるのは次のうちどれか？ 

#### 用語：GAN（敵対的生成ネットワーク）
これはおもしろい手法だと思いました。偽物画像を作る学習をするジェネレータと、偽物をきちんと見抜けるようにする学習をするディスクリミネータという二つのネットワークで構成されています。二つが切磋琢磨して、最終的には本物と見分けがつかないような贋作ができるのだそうな。それぞれのネットワークにCNNを取り込んだものをDCGAN（Deep Convolutional GAN）といいます。イアン・グッドフェローが考案。ヤン・ルカンは「この10年で最もおもしろいアイデア」と絶賛しているそうだ。

* 【adversarial example】は深層学習における重要な課題の一つであり、学習済みのディープニューラルネットモデルを欺くように人工的に作られたサンプルのことである。サンプルに対して微小な摂動を加えることで、作為的にモデルの誤認識を引き起こすことができる。

* 強化学習では、行動を学習する【エージェント】と【エージェント】が行動を加える対象である【環境】を考え、行動に応じて【環境】は【エージェント】に状態と【報酬】を返す。行動と状態/【報酬】の獲得を繰り返し、最も多くの【報酬】をもらえるような方策を得ることが強化学習の目的である。

* 確率的勾配法は深層学習において最もよく知られる最適化アルゴリズムであり、いくつかの改善を加えたものが広く使われている。例えば、以前に適用した勾配の方向を現在のパラメータ更新にも影響させる【モメンタム】という手法や、勾配を２乗した値を蓄積し、すでに大きく更新されたパラメータほど更新量（学習率）を小さくする【AdaGrad】や、【AdaGrad】における一度更新量が飽和した重みはもう更新されないという欠点を、指数移動平均を蓄積することにより解決した【RMSprop】などがある。

* 大きなニューラルネットワークなどの入出力をより小さなネットワークに学習させる技術として、【蒸留】がある。【蒸留】とは、すでに学習されているモデル（教師モデル）を利用して、より小さくシンプルなモデル（生徒モデル）を学習させる手法である。こうすることにより、生徒モデルを単独で学習させる場合よりも【過学習を緩和する】ことができる。

# 4. 人工知能の応用
## 4-1. 研究分野
ディープラーニングが、どんどん発展しています！一つひとつがおもしろい！

### 4-1-1. 画像認識分野
一般画像認識へ至る研究動向を2つ紹介します。

#### 用語：R-CNN（Regional CNN）
イメージネット画像認識コンテストには、位置課題と検出課題という2つの課題があります。画像の中の「どこ」に「何」があるかを問う課題ですね。「どこ」の課題、すなわち関心領域（ROI：Region of Interest）の切り出しには、CNNではない手法を使います。領域の切り出しは、矩形領域（バンディングボックス：左上と右下の座標）を予測する回帰問題とみなせます。高速RCNN（fast RCNN）というモデルでは、領域の切り出しと切り出した領域の物体認識を同時に行うことが実現しました。さらに改良されたfaster RCNNでは、ほぼ実時間で入力画像からの関心領域の切り出しと認識ができるようになりました。YOLO（You Look Only Once）やSSD（Single Shot Detectorといった）といった発展形のモデルも登場しています。いずれも領域の切り出しと認識を同時に行うCNNです。

#### 用語：セマンティックセグメンテーションとインスタンスセグメンテーション
セマンティックセグメンテーションとは、RCNNのような矩形の領域を切り出すのではなく、より詳細な領域分割を得るモデルです。完全畳み込みネットワーク（FCN：Fully Convolutional Network）という、全ての層が畳み込みであるモデルを使います。FCNはセマンティックセグメンテーションに特化したモデルなので、それ単体では画像認識は行えません。個々の物体毎に認識させることは、インスタンスセグメンテーションと呼びます。

* 画像データに対しては、前処理を施すことが多い。カラー画像を白黒画像に変換して計算量を削減する【グレースケール】や、細かいノイズの影響を除去する【平滑化】、画素ごとの明るさをスケーリングする【ヒストグラム平均】などがこれに含まれる。

### 4-1-2. 言語処理分野
#### 用語：word2vec
「単語の意味は、その周辺の単語によって決まる」という言語学の主張をニューラルネットワークとして実現したもの。word2vecが、ベクトル空間モデルや単語埋め込みモデルとも呼ばれます。スキップグラムとCBOWという2つの手法があります。word2vecに触発されて、単語埋め込みモデルは爆発的に発展しました。

* 自然言語処理において、2013年にGoogle社より論文が公開された【word2vec】という技術は、単語の意味関係を（B)で表現することにより、辞書なしで関連度の高い単語を知ることができたり、「王」ー「男性」+「女性」＝「女王」というような意味的な計算が自動的にできるようになり、注目を集めた。　また、【2018】年に同社より提案された【BERT】という技術は（E)という【ディープラーニング】の手法を用いており、単語の一部を【マスキング】して学習させるという工夫により、一つの単語が複数の使われ方をするというような複雑な意味関係も表現でき【bidirectional transformer】により文章の文脈も学習しており、様々な、自然言語処理タスク（QA抽出、文書分類、品詞タグ付け等）で最高記録を樹立している。

#### 用語：fastText
word2vecの後継の一つ。トマス・ミコロフによって開発されたモデル。単語の表現に文字の情報を含めることで、訓練データに存在しない単語も表現できるようになった。また、学習に要する時間も短い。

#### 用語：ELMO
word2vecの後継の、文章表現を得るモデルです。


#### 用語：ニューラル画像脚注付け（NIC：Neural Image Caption） 
CNNとRNNを組み合わせたもの。CNNの最終層の出力を使うのではなく、全結合層の直下、すなわち畳み込み層の最上位を層をRNNで構成される文章生成ネットワークの入力とします。

#### 用語：シーケンス2シーケンス
自動翻訳技術で用いられます。

#### 用語：ニューラルチューリングマシン（NTM）
チューリングマシンをニューラルネットワークで実現する試み。

#### 用語：エルマンネット（エルマンのネットワーク）
RNNの一種で、文法解析をするモデルです。

#### 用語：形態素解析
さて、自然言語処理は、次のようなフローで実行されるそうです。
(1) 形態素解析で文章を単語などの最小単位に切り分ける → (2) データのクレンジングにより不要な文字列を取り除く → (3) BoW (Bug-of-words)などを用いてベクトル形式に変換する → (4) TF-IDなどを用いて各単語の重要度を評価する。※TF-IDFとは、「文書の特徴」を表現するために「文書に含まれる単語の重要度」を考慮する概念だそうです。

### 4-1-3. 音声認識分野
#### 用語：WaveNet
音声合成と音声認識の両方を行うことができるモデルです。「両方」ができるということが試験に出るポイントみたいです。

#### 用語：HMM（隠れマルコフモデル）
音声認識では、HMMという言語モデルを用いて、文章としての単語のつながりを確率的に表現して、文章の形を推測します。今、このHMMがディープラーニングに置き換えられて、飛躍的に音声認識精度が向上しているのだそうな。

### 4-1-4. ロボティクス分野
#### 用語：Alpha GO
碁盤の状況認識にCNNを用い、次の手の選択にモンテカルロ木探索を用いて成果を上げた。なんと、ここにもCNNが使われているのか。さらに強くなるためにセルフプレイを用いたアルファ碁ゼロは、さらに強いそうです。

#### 用語：強化学習
3つの改善手法を覚えておきましょう。全て含めるとRAINBOWモデルとなる。ちなみに、DQNで用いられている枠組みは、(2)の行動価値関数ベースです。
(1) 方策（ポリシー）ベース
(2) 行動価値関数ベース（Q関数ベース）
(3) モデルベース

#### 用語：一気通貫学習
ロボットの一連の動作を一つのニューラルネットワークで実現しようとする学習。
* 視覚・聴覚・触覚などのセンサ情報をロボットが統合的に扱おうとする試みを何学習と呼ぶか

#### 用語：マルチモーダル学習
互換や体性感覚といった複数の感覚の情報を組み合わせて処理すること。
* 視覚・聴覚・触覚などのセンサ情報を収集できるシステムを何システムと呼ぶか？ 【マルチモーダル】

## 4-2. 産業への応用
やはり、画像認識の応用事例が多いです。

### 4-2-1. 製造業での応用事例
#### 事例：自動車ギヤの不良品検出
そもそも不良品が発生する頻度が少ないので、不良品データを学習させるのは難しいです。良品データの特徴を抽出して、その特徴との差分を利用することで不良品を検出しています。（これもディープラーニングなのですね。）

#### 事例：射出成型機の予防保全
これまでは人間がデータ波形の形状変化を見て、摩耗状態や部品の交換時期を見ていた。このデータ波形の特徴量をディープラーニングで学習して、摩耗量を計算します。

#### 事例：バラ積みピッキング
複雑な教示作業無で、ロボットに作業をさせるアプローチで、ばらばらに置かれた部品をロボットがピッキングします。

#### 事例：食品製造ラインにおける不良品検出
分類機アプローチではなく、良品の特徴を学習してそうでないものをはじく異常検知アプローチ。

### 4-2-2.  自動運転
#### 用語：SEA J3016
6段階の自動運転レベルの定義があります。2025年を目途に、レベル4～5の完全自動運転の実用化が見込まれるのだそうな。
* （A)は自動運転のレベルの定義のことで、米国の団体が定義した。これによると、レベル（B）では、人間の運転者がすべて行い、レベル【3】では、自動化システムが要請した場合に人間が制御を取り戻せるようにしておかなければならない。レベル【5】は人間の運転者が運転できる条件下においてすべての運転タスクを自動で行うことができることをいう。
* 国土交通省が出した安全基準によると、2019/10/1以降に自動運転車を備えた新車に乗る場合、【６５秒以上手を離す】と手動運転に切り替える仕組みを義務付けた。 
* 自動車各社だけでなくインターネット大手に至るまでが参集している【Maas】は、あらゆる交通手段をニーズに合わせてパッケージ化して提供するサービスのことである。
* 情報処理に用いられる何らかのコンピューティングリソースを、インターネットを通じたサービスとして提供することや、そうしたサービスの総称を【Xaas】と呼ぶ

### 4-2-3. 医療への応用事例
#### 事例：診断支援
ディープラーニングの持つ特徴量抽出能力を使って、内視鏡画像からの胃がんの診断や、大腸がん診断、網膜剥離判定などの事例があるようです。

#### 事例：創薬
化合物とたんぱく質の相互作用予測モデルなどにディープラーニングが使われているのだそうな。

#### 事例：ゲノム解析
ディープラーニングを用いたゲノム解析ツールであるDeepVariantはオープンソースとしてgithubに公開されているらしい。

### 4-2-4. 介護への応用事例
#### 事例：着衣介助
それにしても、凄いロボットが登場したものだ。

### 4-2-5. インフラ・防犯・監視への応用事例
#### 事例：メンテナンス効率化
コンクリートのひび割れ検出、舗装道路損傷判断、橋梁内部の損傷度合いの推定、送電線点検などに用いられているようです。

#### 事例：建設現場における活用
トンネル切羽や掘削のり面の地質評価。

#### 事例：産業廃棄物選別
廃棄物の材質種類推定にディープラニングが用いられている。

#### 事例：防犯
新丸ビルでは、困っている方の動き検知をやっているらしい。

### 4-2-5. サービス業への応用事例
#### 事例：タクシーの需要予測
人口統計、気象、過去のタクシー運行データを使って、需要のある場所や時間を予測するそうです。

#### 事例：来店者情報把握
来店人数計測カメラと年齢・性別判定カメラを設置を使い、大型商業施設におけるテナントごとの分析。（この事例もABEJA社なんですね。）

#### 事例：無人コンビニ
JR東日本社が検証しているようです。

### 4-2-6. その他の応用事例
#### 事例：双腕型マルチモーダルロボット
DENSO社ですね。

#### 事例：物流
荷物の形状を自動的に判別する物流画像判定や倉庫運用最適化に使われている。

#### 事例：農業
収穫・仕分け支援、ピンポイント農薬散布に使われている。

#### 事例：金融
株価予測や不正取引検知に使わている。

#### 事例：教育
講義動画内の先生の声や黒板の文字の検索に使わたり、採点支援に使われたり。

#### 事例：インターネット関連
ユーザーのコメント分析にLSTMが使われるようです。それから、画像商品検索やレコメンドにも。

#### 事例：チャットボット
予め用意してある複数回答文から適切なものを選択して回答するタイプと、都度で回答文を生成するタイプがあるそうですが、現時点では前者が多い。

## 4-3. 倫理と法律
AIプロダクトを作る際に、倫理や法律の観点で注意すべきことを見ていきましょう。

### 4-3-1. バイ・デザイン
用語：プライバシー・バイ：デザイン（PbD）
サービスやプロダクトを設計する段階から、法的もしくは倫理的な検討が必要です。あらかじめプライバシーに配慮した設計やプロセスを目指せば、社会から信用を得られます。PbDだけでなく、セキュリティ・バイ・デザインやバリュー・バイ・デザインなどのバイ・デザインな考え方が注目されています。

### 4-3-2. データ収集
日本の著作権法は、世界的に見ても先進的だそうです。というのも、「情報解析を行うために著作物を複製すること」が営利・非営利を問わず適法とされているからです。インターネット上にアップロードされている画像を無断で使って学習しても適法なわけです。

### 用語：2018年の著作権法改正
従来は、学習用データセットを作ることまでが適法でしたが、2019年1月以降は、その学習データを販売したり公開したりしても適法となるそうです。試験に出ますね。

### 用語：GDPR（EU一般データ保護規則）
たとえEU域内に拠点を持っていないとしても、日本に対しても域外適用されます。EU向けにもサービスを提供する日本企業は法的規制を受けます。
* 欧州議会・欧州理事会および欧州委員会が欧州連合 (EU) 内の全ての個人のためにデータ保護を強化し統合することを意図している

### 4-3-3. 権利
AIによる創作物の著作物性を明示的に認めた法律は、2018年時点では存在していないそうです。

### 4-3-4. 過失の責任
AIには故意や過失という状態をあてはめられないため、AIの所有者が「不法行為責任」を負わなければいけない可能性があります。AIの製造者は「製造物責任」を問われる可能性があります。ただし、「製造物責任」は動産にたいして問われるものであるため、プログラムとしてのAIは「製造物責任」の対象となる可能性は低そうです。

## [ジェフリー・ヒントン](https://ja.wikipedia.org/wiki/%E3%82%B8%E3%82%A7%E3%83%95%E3%83%AA%E3%83%BC%E3%83%BB%E3%83%92%E3%83%B3%E3%83%88%E3%83%B3)
ディープラーニングの父。今は、トロント大学の教授で、Google Brainプロジェクトの研究者でもある。
2006年にはオートエンコーダや深層信念ネットワークという手法を提唱。ディープラーニングの基礎を築く。
2012年には人工知能を用いて画像の認識力を競うコンテスト、「ILSVRC」ではディープラーニング（**AlexNet**）を用いて圧倒的に優勝する。

## [アラン・チューリング](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%A9%E3%83%B3%E3%83%BB%E3%83%81%E3%83%A5%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0)
人工知能ができたかどうかを判定するテストである「チューリングテスト」を提唱。別の場所にいる人間がコンピュータと会話して、相手がコンピュータだと見抜けなければ知能があるとする。

## アンドリュー・ング
「Google Brain」や「coursera」の立ち上げにたずさわる。今はBaidu研究所に勤務。

## ヤン・ルカン
Facebookの人工知能研究所やニューヨーク大学に勤務。
LeNetと呼ばれる有名なCNNモデルを考えた。手書き数字を集めたデータセット「MNIST」を作った。
GANを高く評価した。

## レイ・カーツワイル
未来学者で「シンギュラリティ」という人工知能が人間よりも賢くなる年が来ることを予見する。

## ジョン・マッカーシー
パトリック・ヘイズとの共同論文でフレーム問題を提唱。余談だが、LISP言語を作った人。

## ジョセフ・アイゼンバウム
人工無能として有名な「ELIZA」を書き上げた人。

## ジョン・サール
[強いＡＩ・弱いＡＩ](https://ja.wikipedia.org/wiki/%E5%BC%B7%E3%81%84AI%E3%81%A8%E5%BC%B1%E3%81%84AI)という用語を作った人。[中国語の部屋](https://ja.wikipedia.org/wiki/%E4%B8%AD%E5%9B%BD%E8%AA%9E%E3%81%AE%E9%83%A8%E5%B1%8B)という思考実験をする。

## ロジャー・ペンローズ
『皇帝の新しい心』という著書の中で「強いＡＩ」は実現できないと主張。

## ダニエル・デネット
フレーム問題の難しさを伝えるために、ロボットのたとえを挙げた。

## スティーブン・ホーキング
「人工知能の進化は人類の終焉を意味する」と発言。

## [イーロン・マスク](https://ja.wikipedia.org/wiki/%E3%82%A4%E3%83%BC%E3%83%AD%E3%83%B3%E3%83%BB%E3%83%9E%E3%82%B9%E3%82%AF)
人工知能を研究する非営利団体の一つである「Open AI」の創業者の一人。
人工知能に対して「人工知能にはかなり慎重に取り組む必要がある。結果的に悪魔を呼び出していることになるからだ。」という脅威論を述べる。

## オレン・エツィオーニ
人工知能に対して「コンピュータが世界制覇するという終末論的構想は『馬鹿げている』としか言いようがない」と発言し脅威論をけん制した。

## 福島邦彦
CNNの原型ともいえる、単純型細胞と複雑型細胞の２つの細胞の働きを組み込んだモデルである「ネオコグニトロン」を提唱。

## アーサー・サミュエル
機械学習を「明示的にプログラムしなくても学習する能力をコンピュータに与える研究分野」と定義した。

## イアン・グッドフェロー
生成ネットワークと識別ネットワークからなる教師なし学習手法である**敵対的生成ネットワーク**を提唱した。ヤン・ルカンはGANについて「機械学習において、この10年間で最も面白いアイデア」であると評価した。

* 敵対生成ネットワーク（別名：(A)は、【イアン・グッドフェロー】によって提唱された非常に画期的な(C)機械学習の仕組みである。【ヤン・ルカン】によって「機械学習において10年に一度の面白いアイデアだ」と賞賛されるこの仕組みは、Generator生成という画像を生成するNNと、【Discriminator（識別）】という、それがNNによって生成されたものか、本当の画像かを判定するNNで構成される。

## デミス・ハサビス
DeepMindの設立者。

## 特徴マップ
* CNNによって、幅：1500、高さ：1500ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 736
* CNNによって幅x高さ=250x250ピクセルの画像を入力とし12x12ピクセルのフィルタを用いて、ストライド2で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 121*121
* CNNによって、幅：900、高さ：900ピクセルの画像を入力とし、幅：3、高さ：3ピクセルのフィルタを用いて、ストライド：3で、大きさ：3の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？302
* CNNによって、幅：400、高さ：400ピクセルの画像を入力とし、幅：70、高さ：70ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 333
* CNNによって、幅：777、高さ：777ピクセルの画像を入力とし、幅：7、高さ：7ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 387
* CNNによって、幅：114、高さ：114ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 43
* CNNによって、幅：918、高さ：918ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 445
* CNNによって幅x高さ=300x400ピクセルの画像を入力とし24x24ピクセルのフィルタを用いて、ストライド2で、大きさ2で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 141*191
* CNNによって、幅：500、高さ：500ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 236
* CNNによって、幅：200、高さ：200ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 86
* CNNによって、幅：40、高さ：40ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 20
* CNNによって、幅：100、高さ：100ピクセルの画像を入力とし、幅：10、高さ：10ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 93
* CNNによって、幅：100、高さ：100ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 50
* CNNによって、幅：13、高さ：13ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 8
* CNNによって、幅：450、高さ：450ピクセルの画像を入力とし、幅：20、高さ：20ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 433
* CNNによって、幅：418、高さ：418ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 195
* CNNによって、幅：112、高さ：112ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 42
* CNNによって幅x高さ=400x400ピクセルの画像を入力とし24x24ピクセルのフィルタを用いて、ストライド3で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 127
* CNNによって、幅：300、高さ：300ピクセルの画像を入力とし、幅：50、高さ：50ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 127
* CNNによって、幅：1600、高さ：1600ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 786
* CNNによって幅x高さ=300x300ピクセルの画像を入力とし12x12ピクセルのフィルタを用いて、ストライド1で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 291*291
* CNNによって、幅：200、高さ：200ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 86
* CNNによって、幅：333、高さ：333ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 166
* CNNによって、幅：300、高さ：300ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 271
* CNNによって、幅：800、高さ：800ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：5で、大きさ：5の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？162
* CNNによって、幅：1100、高さ：1100ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 536
* CNNによって、幅：20、高さ：20ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 18
* CNNによって、幅：110、高さ：110ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 109
* CNNによって、幅：80、高さ：80ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 26
* CNNによって、幅：700、高さ：700ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：3の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 338
* CNNによって、幅：50、高さ：50ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 25
* y=ax + by + czという式をzについて偏微分した答えを次から選べ。【c】
* CNNによって、幅：555、高さ：555ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 277
* CNNによって、幅：500、高さ：500ピクセルの画像を入力とし、幅：10、高さ：10ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 247
* f(x)=ax+by+czという関数がある。この関数をyについて偏微分せよ。【b】
* CNNによって、幅：95、高さ：95ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 47
* CNNによって、幅：916、高さ：916ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？444
* CNNによって、幅：300、高さ：300ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：3で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 91
* CNNによって、幅：200、高さ：200ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 86
* CNNによって、幅：900、高さ：900ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：4で、大きさ：4の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 227
* CNNによって幅x高さ=1200x1200ピクセルの画像を入力とし240x240ピクセルのフィルタを用いて、ストライド1で、大きさ10で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 981*981
* CNNによって、幅：1800、高さ：1800ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 886
* CNNによって、幅：400、高さ：400ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 186
* CNNによって、幅：100、高さ：100ピクセルの画像を入力とし、幅：16、高さ：16ピクセルのフィルタを用いて、ストライド：2で、大きさ：2の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか45
* CNNによって幅x高さ=764x900ピクセルの画像を入力とし32x32ピクセルのフィルタを用いて、ストライド2で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 368*436
* 
* 

問1
（ア）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークは高い表現力を持つ反面、過学習をしやすいという性質を持つため、それを改善させる方法が多数考案されている。例えば、学習の際に一部のノードを無効化する（ア）、一部の層の出力を正規化する（イ）、データの水増しをしてデータの不足を補う（ウ）、パラメータのノルムにペナルティを課す（エ）などがそれに当たる。
問2
（イ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークは高い表現力を持つ反面、過学習をしやすいという性質を持つため、それを改善させる方法が多数考案されている。例えば、学習の際に一部のノードを無効化する（ア）、一部の層の出力を正規化する（イ）、データの水増しをしてデータの不足を補う（ウ）、パラメータのノルムにペナルティを課す（エ）などがそれに当たる。
問3
（ウ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークは高い表現力を持つ反面、過学習をしやすいという性質を持つため、それを改善させる方法が多数考案されている。例えば、学習の際に一部のノードを無効化する（ア）、一部の層の出力を正規化する（イ）、データの水増しをしてデータの不足を補う（ウ）、パラメータのノルムにペナルティを課す（エ）などがそれに当たる。
問4
（エ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークは高い表現力を持つ反面、過学習をしやすいという性質を持つため、それを改善させる方法が多数考案されている。例えば、学習の際に一部のノードを無効化する（ア）、一部の層の出力を正規化する（イ）、データの水増しをしてデータの不足を補う（ウ）、パラメータのノルムにペナルティを課す（エ）などがそれに当たる。
問5
（ア）に最もよくあてはまる選択肢を１つ選べ。
学習率の値は学習の進み方に大きな影響を与える。例えば、学習率が過度に（ア）とコスト関数の高い局所的最適解から抜け出せなくなることがある。また、学習率が過度に（イ）と、ネットワークの重みが発散することがある。学習率を学習が進むに連れて変化させる方法もあり、一般に学習が進むに連れて学習率を（ウ）と最終的により最適解に近いパラメータになる。
問6
（イ）に最もよくあてはまる選択肢を１つ選べ。
学習率の値は学習の進み方に大きな影響を与える。例えば、学習率が過度に（ア）とコスト関数の高い局所的最適解から抜け出せなくなることがある。また、大域的最適解に向かって収束している場合でも、学習率が（イ）と、収束は速いがコスト関数の最終的な値が高く、逆に（ウ）と収束は遅いが最終的にはより最適解に近いパラメータになるため、コスト関数は小さな値に収束する。
問7
（ウ）に最もよくあてはまる選択肢を１つ選べ。
学習率の値は学習の進み方に大きな影響を与える。例えば、学習率が過度に（ア）とコスト関数の高い局所的最適解から抜け出せなくなることがある。また、大域的最適解に向かって収束している場合でも、学習率が（イ）と、収束は速いがコスト関数の最終的な値が高く、逆に（ウ）と収束は遅いが最終的にはより最適解に近いパラメータになるため、コスト関数は小さな値に収束する。
問8
生成モデルの一つであり、生成ネットワークと識別ネットワークの２つのネットワークを対抗させるように学習させることで、得られる生成モデルの名称として最も適切なものを１つ選べ。
問9
（ア）に最もよくあてはまる選択肢を１つ選べ。
データが少量しかないなどの理由で、対象のタスクを学習させることが困難なときに、関連する別のタスクで学習し、その学習済みの特徴やパラメータなどを利用することで効率的に対象のタスクを学習することがある。これを（ア）という。
問10
（ア）に最もよくあてはまる選択肢を１つ選べ。
ディープラーニングは、ニューラルネットワークを多層化したものであり、観測データから本質的な情報である（ア）を自動的に抽出できる点が特徴である。また、従来の機械学習手法と比べると、（ウ）という性質も持っている。
問11
（イ）に当てはまらない選択肢を１つ選べ。
ディープラーニングは、ニューラルネットワークを多層化したものであり、観測データから本質的な情報である（ア）を自動的に抽出できる点が特徴である。また、従来の機械学習手法と比べると、（イ）という性質も持っている。
問12
（ア）に最もよくあてはまる選択肢を１つ選べ。
機械学習においては過学習を避けるために、訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である（ア）を用いることが多い。また複数のモデルの予測結果の平均を利用する（イ）がある。他にもディープニューラルネットワークに対しては、ランダムに一定の割合のノードを削除して学習を行う（ウ）が有効とされている。（ア）手法にはいくつかのパラメータをスパースにする（エ）などがある。
問13
（イ）に最もよくあてはまる選択肢を１つ選べ。
機械学習においては過学習を避けるために、訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である（ア）を用いることが多い。また複数のモデルの予測結果の平均を利用する（イ）がある。他にもディープニューラルネットワークに対しては、ランダムに一定の割合のノードを削除して学習を行う（ウ）が有効とされている。（ア）手法にはいくつかのパラメータをスパースにする（エ）などがある。
問14
（ウ）に最もよくあてはまる選択肢を１つ選べ。
機械学習においては過学習を避けるために、訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である（ア）を用いることが多い。また複数のモデルの予測結果の平均を利用する（イ）がある。他にもディープニューラルネットワークに対しては、ランダムに一定の割合のノードを削除して学習を行う（ウ）が有効とされている。（ア）手法にはいくつかのパラメータをスパースにする（エ）などがある。
問15
（エ）に最もよくあてはまる選択肢を１つ選べ。
機械学習においては過学習を避けるために、訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である（ア）を用いることが多い。また複数のモデルの予測結果の平均を利用する（イ）がある。他にもディープニューラルネットワークに対しては、ランダムに一定の割合のノードを削除して学習を行う（ウ）が有効とされている。（ア）手法にはいくつかのパラメータをスパースにする（エ）などがある。
問16
（ア）に最もよくあてはまる選択肢を１つ選べ。
ディープニューラルネットワークの普及に貢献した一つの要素に、（ア）を克服する手法が提案されたことがある。（ア）は誤差逆伝播法において、（イ）ことによって生じるとされている。（ア）に対処するための一つの方法として、活性化関数に（ウ）を利用するなどがある。
問17
（イ）に最もよくあてはまる選択肢を１つ選べ。
ディープニューラルネットワークの普及に貢献した一つの要素に、（ア）を克服する手法が提案されたことがある。（ア）は誤差逆伝播法において、（イ）ことによって生じるとされている。（ア）に対処するための方法として、あらかじめ良い重みの初期値を計算する（ウ）や、活性化関数に（エ）を利用するなどがある。
問18
（ウ）に最もよくあてはまる選択肢を１つ選べ。
ディープニューラルネットワークの普及に貢献した一つの要素に、（ア）を克服する手法が提案されたことがある。（ア）は誤差逆伝播法において、（イ）ことによって生じるとされている。（ア）に対処するための方法として、あらかじめ良い重みの初期値を計算する（ウ）や、活性化関数に（エ）を利用するなどがある。
問19
（エ）にあてはまる選択肢を１つ選べ。
ディープニューラルネットワークの普及に貢献した一つの要素に、（ア）を克服する手法が提案されたことがある。（ア）は誤差逆伝播法において、（イ）ことによって生じるとされている。（ア）に対処するための方法として、あらかじめ良い重みの初期値を計算する（ウ）や、活性化関数に（エ）を利用するなどがある。
問20
（ア）に最もよくあてはまる選択肢を１つ選べ。
大規模なディープニューラルネットワークの学習では学習するべきパラメータ数が膨大となるため、処理の高速化が必要となる。2012年に提案された分散並列技術である（ア）や画像処理に特化したプロセッサの（イ）は大規模なニューラルネットワークの学習を実現するために利用されてきた。また、大規模なニューラルネットワークの学習が困難となる原因の一つとして、ある層の入力がそれより下層の学習が進むにつれて変化する（ウ）がある。（ウ）を防ぐために出力値の分布の偏りを抑制する（エ）が2015年に提案されている。
問21
（イ）に最もよくあてはまる選択肢を１つ選べ。
大規模なディープニューラルネットワークの学習では学習するべきパラメータ数が膨大となるため、処理の高速化が必要となる。2012年に提案された分散並列技術である（ア）や画像処理に特化したプロセッサの（イ）は大規模なニューラルネットワークの学習を実現するために利用されてきた。また、大規模なニューラルネットワークの学習が困難となる原因の一つとして、ある層の入力がそれより下層の学習が進むにつれて変化する（ウ）がある。（ウ）を防ぐために出力値の分布の偏りを抑制する（エ）が2015年に提案されている。
問22
（ウ）に最もよくあてはまる選択肢を１つ選べ。
大規模なディープニューラルネットワークの学習では学習するべきパラメータ数が膨大となるため、処理の高速化が必要となる。2012年に提案された分散並列技術である（ア）や画像処理に特化したプロセッサの（イ）は大規模なニューラルネットワークの学習を実現するために利用されてきた。また、大規模なニューラルネットワークの学習が困難となる原因の一つとして、ある層の入力がそれより下層の学習が進むにつれて変化する（ウ）がある。（ウ）を防ぐために出力値の分布の偏りを抑制する（エ）が2015年に提案されている。
問23
（エ）に最もよくあてはまる選択肢を１つ選べ。
大規模なディープニューラルネットワークの学習では学習するべきパラメータ数が膨大となるため、処理の高速化が必要となる。2012年に提案された分散並列技術である（ア）や画像処理に特化したプロセッサの（イ）は大規模なニューラルネットワークの学習を実現するために利用されてきた。また、大規模なニューラルネットワークの学習が困難となる原因の一つとして、ある層の入力がそれより下層の学習が進むにつれて変化する（ウ）がある。（ウ）を防ぐために出力値の分布の偏りを抑制する（エ）が2015年に提案されている。
問24
（ア）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークは、畳み込み層とプーリング層を積み上げた構成をしている。画像データを用いた場合、畳み込み層では、出力画像のサイズを調整するために元の画像の周りを固定の値で埋める（ア）を行う。プーリング層では畳み込み層の出力を圧縮するプーリングを行う、（イ）などの手法がある。
問25
（イ）に当てはまらないものを選べ。
畳み込みニューラルネットワークは、畳み込み層とプーリング層を積み上げた構成をしている。画像データを用いた場合、畳み込み層では、出力画像のサイズを調整するために元の画像の周りを固定の値で埋める（ア）を行う。プーリング層では畳み込み層の出力を圧縮するプーリングを行う、（イ）などの手法がある。
問26
（ア）にあてはまらない選択肢を一つ選べ。
ニューラルネットワークには（ア）などの多くのハイパーパラメータが存在し、これらの値が精度に大きな影響を与える。ハイパーパラメータのチューニング方法としては、パラメータの候補値を指定し、それらの組み合わせを調べる（イ）などがある。また、近年は、ハイパーパラメータを含め最適化問題とする（ウ）が効率的なチューニング方法として注目をあびている。
問27
（イ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークには（ア）などの多くのハイパーパラメータが存在し、これらの値が精度に大きな影響を与える。ハイパーパラメータのチューニング方法としては、パラメータの候補値を指定し、それらの組み合わせを調べる（イ）などがある。また、近年は、ハイパーパラメータを含め最適化問題とする（ウ）が効率的なチューニング方法として注目をあびている。
問28
（ウ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークには（ア）などの多くのハイパーパラメータが存在し、これらの値が精度に大きな影響を与える。ハイパーパラメータのチューニング方法としては、パラメータの候補値を指定し、それらの組み合わせを調べる（イ）などがある。また、近年は、ハイパーパラメータを含め最適化問題とする（ウ）が効率的なチューニング方法として注目をあびている。
問29
（ア）に最もよくあてはまる選択肢を１つ選べ。
自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり、出力が入力に近づくようにニューラルネットを学習させる。主に（イ）のために利用されることが多く、活性化関数に恒等写像を用いた場合の3層の自己符号化器は（ウ）と同様の結果を返す。自己符号化器を多層化すると、ディープニューラルネット同様に勾配消失問題が生じるため、複雑な内部表現を得ることは困難であった。この問題に対して2006年頃に（エ）らは、単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで、汎用的な自己符号化器の利用を可能とした。また、自己符号化器の代表的な応用例として（カ）がある。
問30
（イ）に最もよくあてはまる選択肢を１つ選べ。
自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり、出力が入力に近づくようにニューラルネットを学習させる。主に（イ）のために利用されることが多く、活性化関数に恒等写像を用いた場合の3層の自己符号化器は（ウ）と同様の結果を返す。自己符号化器を多層化すると、ディープニューラルネット同様に勾配消失問題が生じるため、複雑な内部表現を得ることは困難であった。この問題に対して2006年頃に（エ）らは、単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで、汎用的な自己符号化器の利用を可能とした。また、自己符号化器の代表的な応用例として（カ）がある。
問31
（ウ）に最もよくあてはまる選択肢を１つ選べ。
自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり、出力が入力に近づくようにニューラルネットを学習させる。主に（イ）のために利用されることが多く、活性化関数に恒等写像を用いた場合の3層の自己符号化器は（ウ）と同様の結果を返す。自己符号化器を多層化すると、ディープニューラルネット同様に勾配消失問題が生じるため、複雑な内部表現を得ることは困難であった。この問題に対して2006年頃に（エ）らは、単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで、汎用的な自己符号化器の利用を可能とした。また、自己符号化器の代表的な応用例として（カ）がある。
問32
（エ）に最もよくあてはまる選択肢を１つ選べ。
自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり、出力が入力に近づくようにニューラルネットを学習させる。主に（イ）のために利用されることが多く、活性化関数に恒等写像を用いた場合の3層の自己符号化器は（ウ）と同様の結果を返す。自己符号化器を多層化すると、ディープニューラルネット同様に勾配消失問題が生じるため、複雑な内部表現を得ることは困難であった。この問題に対して2006年頃に（エ）らは、単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで、汎用的な自己符号化器の利用を可能とした。また、自己符号化器の代表的な応用例として（カ）がある。
問33
（オ）に最もよくあてはまる選択肢を１つ選べ。
自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり、出力が入力に近づくようにニューラルネットを学習させる。主に（イ）のために利用されることが多く、活性化関数に恒等写像を用いた場合の3層の自己符号化器は（ウ）と同様の結果を返す。自己符号化器を多層化すると、ディープニューラルネット同様に勾配消失問題が生じるため、複雑な内部表現を得ることは困難であった。この問題に対して2006年頃に（エ）らは、単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで、汎用的な自己符号化器の利用を可能とした。また、自己符号化器の代表的な応用例として（カ）がある。
問34
（カ）に当てはまらない選択肢を１つ選べ。
自己符号化器はニューラルネットワークによる（ア）の代表的な応用であり、出力が入力に近づくようにニューラルネットを学習させる。主に（イ）のために利用されることが多く、活性化関数に恒等写像を用いた場合の3層の自己符号化器は（ウ）と同様の結果を返す。自己符号化器を多層化すると、ディープニューラルネット同様に勾配消失問題が生じるため、複雑な内部表現を得ることは困難であった。この問題に対して2006年頃に（エ）らは、単層の自己符号化器に分割し入力層から繰り返し学習させる（オ）を積層自己符号化器に適用することで、汎用的な自己符号化器の利用を可 能とした。また、自己符号化器の代表的な応用例として（カ）がある。
問35
（ア）に最もよくあてはまる選択肢を１つ選べ。
RNNは（ア）系列データの処理に長けているニューラルネットワークである。RNNは、（イ）勾配消失問題が起きやすいという特徴を持っていたが、RNNの一種であるLSTMでは（ウ）を含むLSTM Blockを組み込むことで、長期間の系列情報に対しても勾配消失せずに学習を行うことができた。
問36
（イ）に最もよくあてはまる選択肢を１つ選べ。
RNNは（ア）系列データの処理に長けているニューラルネットワークである。RNNは、（イ）勾配消失問題が起きやすいという特徴を持っていたが、RNNの一種であるLSTMでは（ウ）を含むLSTM Blockを組み込むことで、長期間の系列情報に対しても勾配消失せずに学習を行うことができた。
問37
（ウ）に当てはまらない選択肢を１つ選べ。
RNNは（ア）系列データの処理に長けているニューラルネットワークである。RNNは、（イ）勾配消失問題が起きやすいという特徴を持っていたが、RNNの一種であるLSTMでは（ウ）を含むLSTM Blockを組み込むことで、長期間の系列情報に対しても勾配消失せずに学習を行うことができた。
問38
RNNについての説明として誤っている選択肢を一つ選べ。
問39
（ア）に当てはまらない選択肢を１つ選べ。
ディープニューラルネットワークの学習の目的は（ア）を最小化することであり、この最適化のために勾配降下法が利用される。しかし、勾配降下法にはパラメータの勾配を数値的に求めると（イ）問題があり、このような問題を避けるために誤差逆伝播法が利用される。またディープラーニングには過学習の問題もある。過学習とは（ウ）は小さいにも関わらず、（エ）が小さくならないことであり、これらの問題を克服するために様々な手法の開発が進められている。
問40
（イ）に最もよくあてはまる選択肢を１つ選べ。
ディープニューラルネットワークの学習の目的は（ア）を最小化することであり、この最適化のために勾配降下法が利用される。しかし、勾配降下法にはパラメータの勾配を数値的に求めると（イ）問題があり、このような問題を避けるために誤差逆伝播法が利用される。またディープラーニングには過学習の問題もある。過学習とは（ウ）は小さいにも関わらず、（エ）が小さくならないことであり、これらの問題を克服するために様々な手法の開発が進められている。
問41
（ウ）に最もよくあてはまる選択肢を１つ選べ。
ディープニューラルネットワークの学習の目的は（ア）を最小化することであり、この最適化のために勾配降下法が利用される。しかし、勾配降下法にはパラメータの勾配を数値的に求めると（イ）問題があり、このような問題を避けるために誤差逆伝播法が利用される。またディープラーニングには過学習の問題もある。過学習とは（ウ）は小さいにも関わらず、（エ）が小さくならないことであり、これらの問題を克服するために様々な手法の開発が進められている。
問42
（エ）に最もよくあてはまる選択肢を１つ選べ。
ディープニューラルネットワークの学習の目的は（ア）を最小化することであり、この最適化のために勾配降下法が利用される。しかし、勾配降下法にはパラメータの勾配を数値的に求めると（イ）問題があり、このような問題を避けるために誤差逆伝播法が利用される。またディープラーニングには過学習の問題もある。過学習とは（ウ）は小さいにも関わらず、（エ）が小さくならないことであり、これらの問題を克服するために様々な手法の開発が進められている。
問43
（ア）に最もよくあてはまる選択肢を１つ選べ。
勾配降下法においてパラメータの更新量を決める（ア）の決定は重要である。例えば（ア）が小さすぎると（イ）などの課題が生じるため、（ウ）などの様々な（ア）調整手法が提案されている。
問44
（イ）に最もよくあてはまる選択肢を１つ選べ。
勾配降下法においてパラメータの更新量を決める（ア）の決定は重要である。例えば（ア）が小さすぎると（イ）などの課題が生じるため、（ウ）などの様々な（ア）調整手法が提案されている。
問45
（ウ）に当てはまらない選択肢を１つ選べ。
勾配降下法においてパラメータの更新量を決める（ア）の決定は重要である。例えば（ア）が小さすぎると（イ）などの課題が生じるため、（ウ）などの様々な（ア）調整手法が提案されている。
問46
CNNで行われる畳み込み演算の計算処理について考える。5×5のサイズの画像に対して、3×3のフィルタをパディング1、ストライド1で適当した場合の出力の図のサイズを答えよ。
問47
（ア）に当てはまらない選択肢を１つ選べ。
ディープニューラルネットワークのパラメータ最適化手法として（ア）などの勾配降下法が適用される。しかし、勾配降下法には（イ）などの問題があり、これらの問題に対処するために、学習率をパラメータに適応させることで自動的に学習率を調整することができる（ウ）や勾配の平均と分散をオンラインで推定し利用する（エ）が利用されてきた。
問48
（イ）に当てはまらない選択肢を１つ選べ。
ディープニューラルネットワークのパラメータ最適化手法として（ア）などの勾配降下法が適用される。しかし、勾配降下法には（イ）などの問題があり、これらの問題に対処するために、学習率をパラメータに適応させることで自動的に学習率を調整することができる（ウ）や勾配の平均と分散をオンラインで推定し利用する（エ）が利用されてきた。
問49
（ウ）に最もよくあてはまる選択肢を１つ選べ。
ディープニューラルネットワークのパラメータ最適化手法として（ア）などの勾配降下法が適用される。しかし、勾配降下法には（イ）などの問題があり、これらの問題に対処するために、学習率をパラメータに適応させることで自動的に学習率を調整することができる（ウ）や勾配の平均と分散をオンラインで推定し利用する（エ）が利用されてきた。
問50
（エ）に最もよくあてはまる選択肢を１つ選べ。
ディープニューラルネットワークのパラメータ最適化手法として（ア）などの勾配降下法が適用される。しかし、勾配降下法には（イ）などの問題があり、これらの問題に対処するために、学習率をパラメータに適応させることで自動的に学習率を調整することができる（ウ）や勾配の平均と分散をオンラインで推定し利用する（エ）が利用されてきた。
問51
（ア）に最もよくあてはまる選択肢を１つ選べ。
機械学習の分野において有名な二つの定理について扱う。（ア）は、認知できる全ての客観的な特徴に基づくと全ての対象は同程度に類似している、つまり特徴を選択しなければ表現の類似度に基づく分類は不可能であることを示している。（イ）は、全てのタスクに対して常に他よりすぐれている万能的なアルゴリズムは存在しないことを示している。
問52
（イ）に最もよくあてはまる選択肢を１つ選べ。
機械学習の分野において有名な二つの定理について扱う。（ア）は、認知できる全ての客観的な特徴に基づくと全ての対象は同程度に類似している、つまり特徴を選択しなければ表現の類似度に基づく分類は不可能であることを示している。（イ）は、全てのタスクに対して常に他よりすぐれている万能的なアルゴリズムは存在しないことを示している。
問53
（ア）に当てはまらない選択肢を１つ選べ。
深層学習のモデルは、確定的モデルと確率的モデルに分類することができる。これらのモデルの例として、確定的モデルに（ア）や確率的モデルに（イ）がある。
問54
（イ）に最もよくあてはまる選択肢を１つ選べ。
深層学習のモデルは、確定的モデルと確率的モデルに分類することができる。これらのモデルの例として、確定的モデルに（ア）や確率的モデルに（イ）がある。
問55
（ア）に最もよくあてはまる選択肢を１つ選べ。
深層学習を含めて機械学習において精度の高い学習をするためには、観測データの適切な前処理が必須である。異なるスケールの特徴量を同時に扱えるようにするために、平均を0に分散を1に規格化する（ア）や、特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る(イ）などは広く利用されている。また、画像処理の分野においては、減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され、（エ）などの画像処理に特化したライブラリで行うことができる。また、自然言語処理の分野においては、文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある。
問56
（イ）に最もよくあてはまる選択肢を１つ選べ。
深層学習を含めて機械学習において精度の高い学習をするためには、観測データの適切な前処理が必須である。異なるスケールの特徴量を同時に扱えるようにするために、平均を0に分散を1に規格化する（ア）や、特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る(イ）などは広く利用されている。また、画像処理の分野においては、減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され、（エ）などの画像処理に特化したライブラリで行うことができる。また、自然言語処理の分野においては、文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある。
問57
（ウ）に最もよくあてはまる選択肢を１つ選べ。
深層学習を含めて機械学習において精度の高い学習をするためには、観測データの適切な前処理が必須である。異なるスケールの特徴量を同時に扱えるようにするために、平均を0に分散を1に規格化する（ア）や、特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る(イ）などは広く利用されている。また、画像処理の分野においては、減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され、（エ）などの画像処理に特化したライブラリで行うことができる。また、自然言語処理の分野においては、文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある。
問58
（エ）に最もよくあてはまる選択肢を１つ選べ。
深層学習を含めて機械学習において精度の高い学習をするためには、観測データの適切な前処理が必須である。異なるスケールの特徴量を同時に扱えるようにするために、平均を0に分散を1に規格化する（ア）や、特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る(イ）などは広く利用されている。また、画像処理の分野においては、減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され、（エ）などの画像処理に特化したライブラリで行うことができる。また、自然言語処理の分野においては、文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある。
問59
（オ）に最もよくあてはまる選択肢を１つ選べ。
深層学習を含めて機械学習において精度の高い学習をするためには、観測データの適切な前処理が必須である。異なるスケールの特徴量を同時に扱えるようにするために、平均を0に分散を1に規格化する（ア）や、特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る(イ）などは広く利用されている。また、画像処理の分野においては、減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され、（エ）などの画像処理に特化したライブラリで行うことができる。また、自然言語処理の分野においては、文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある。
問60
（カ）に最もよくあてはまる選択肢を１つ選べ。
深層学習を含めて機械学習において精度の高い学習をするためには、観測データの適切な前処理が必須である。異なるスケールの特徴量を同時に扱えるようにするために、平均を0に分散を1に規格化する（ア）や、特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る(イ）などは広く利用されている。また、画像処理の分野においては、減算正規化と除算正規化の処理を行う（ウ）などが前処理として利用され、（エ）などの画像処理に特化したライブラリで行うことができる。また、自然言語処理の分野においては、文章に単語が含まれているかどうかを考えてテキストデータを数値化する（オ）や文章に含まれる単語の重要度を特徴量とする（カ）などがある。
問61
強化学習の説明として誤りであるものを選べ
問62
（ア）に最もよくあてはまる選択肢を１つ選べ。
生成モデルとは、訓練データからそのデータの特徴を学習し、類似したデータを生成することができるモデルである。ディープニューラルネットの生成モデルの例として、自己符号化器の潜在変数に確率分布を導入した（ア）や、訓練データと生成器が生成したデータを識別器で判別させることによって学習を進める（イ）がある。
問63
（イ）に最もよくあてはまる選択肢を１つ選べ。
生成モデルとは、訓練データからそのデータの特徴を学習し、類似したデータを生成することができるモデルである。ディープニューラルネットの生成モデルの例として、自己符号化器の潜在変数に確率分布を導入した（ア）や、訓練データと生成器が生成したデータを識別器で判別させることによって学習を進める（イ）がある。
問64
（ア）に最もよくあてはまる選択肢を１つ選べ。
（ア）は深層学習における重要な課題の一つであり、学習済みのディープニューラルネットモデルを欺くように人工的に作られたサンプルのことである。サンプルに対して微小な摂動を加えることで、作為的にモデルの誤認識を引き起こすことができる。
問65
（ア）に最もよくあてはまる選択肢を１つ選べ。
強化学習では、行動を学習する（ア）と（ア）が行動を加える対象である（イ）を考え、行動に応じて（イ）は（ア）に状態と（ウ）を返す。行動と状態/（ウ）の獲得を繰り返し、最も多くの（ウ）をもらえるような方策を得ることが強化学習の目的である。
問66
（イ）に最もよくあてはまる選択肢を１つ選べ。
強化学習では、行動を学習する（ア）と（ア）が行動を加える対象である（イ）を考え、行動に応じて（イ）は（ア）に状態と（ウ）を返す。行動と状態/（ウ）の獲得を繰り返し、最も多くの（ウ）をもらえるような方策を得ることが強化学習の目的である。
問67
（ウ）に最もよくあてはまる選択肢を１つ選べ。
強化学習では、行動を学習する（ア）と（ア）が行動を加える対象である（イ）を考え、行動に応じて（イ）は（ア）に状態と（ウ）を返す。行動と状態/（ウ）の獲得を繰り返し、最も多くの（ウ）をもらえるような方策を得ることが強化学習の目的である。
問68
（ア）に最もよくあてはまる選択肢を１つ選べ。
強化学習において、行動価値関数の関数近似に畳み込みニューラルネットワークを用いた手法が（ア）である。
問69
過学習とはどのような状態のことか。以下の文から最も適切なものを１つ選べ。
問70
内部共変量シフトについて以下の記述から最も適切なものを１つ選べ。
問71
（ア）に最もよくあてはまる選択肢を１つ選べ。
確率的勾配法は深層学習において最もよく知られる最適化アルゴリズムであり、いくつかの改善を加えたものが広く使われている。例えば、以前に適用した勾配の方向を現在のパラメータ更新にも影響させる（ア）という手法や、勾配を２乗した値を蓄積し、すでに大きく更新されたパラメータほど更新量（学習率）を小さくする（イ）や、（イ）における一度更新量が飽和した重みはもう更新されないという欠点を、指数移動平均を蓄積することにより解決した（ウ）などがある。
問72
（イ）に最もよくあてはまる選択肢を１つ選べ。
確率的勾配法は深層学習において最もよく知られる最適化アルゴリズムであり、いくつかの改善を加えたものが広く使われている。例えば、以前に適用した勾配の方向を現在のパラメータ更新にも影響させる（ア）という手法や、勾配を２乗した値を蓄積し、すでに大きく更新されたパラメータほど更新量（学習率）を小さくする（イ）や、（イ）における一度更新量が飽和した重みはもう更新されないという欠点を、指数移動平均を蓄積することにより解決した（ウ）などがある。
問73
（ウ）に最もよくあてはまる選択肢を１つ選べ。
確率的勾配法は深層学習において最もよく知られる最適化アルゴリズムであり、いくつかの改善を加えたものが広く使われている。例えば、以前に適用した勾配の方向を現在のパラメータ更新にも影響させる（ア）という手法や、勾配を２乗した値を蓄積し、すでに大きく更新されたパラメータほど更新量（学習率）を小さくする（イ）や、（イ）における一度更新量が飽和した重みはもう更新されないという欠点を、指数移動平均を蓄積することにより解決した（ウ）などがある。
問74
（ア）に最もよくあてはまる選択肢を１つ選べ。
ディープラーニングの技術を利用したシステムを開発する際、複雑な処理が比較的簡潔に記述できることから、既存のフレームワークを利用することも多い。ディープラーニングのフレームワークは複数あり、Google社提供の（ア）や（ア）のラッパーとして機能する（イ）、国内企業であるPreferredNetworksで開発された（ウ）などがある。また、（エ）は（ウ）と同じDefine-by-Run方式を採用している。
問75
（イ）に最もよくあてはまる選択肢を１つ選べ。
ディープラーニングの技術を利用したシステムを開発する際、複雑な処理が比較的簡潔に記述できることから、既存のフレームワークを利用することも多い。ディープラーニングのフレームワークは複数あり、Google社提供の（ア）や（ア）のラッパーとして機能する（イ）、国内企業であるPreferredNetworksで開発された（ウ）などがある。また、（エ）は（ウ）と同じDefine-by-Run方式を採用している。
問76
（ウ）に最もよくあてはまる選択肢を１つ選べ。
ディープラーニングの技術を利用したシステムを開発する際、複雑な処理が比較的簡潔に記述できることから、既存のフレームワークを利用することも多い。ディープラーニングのフレームワークは複数あり、Google社提供の（ア）や（ア）のラッパーとして機能する（イ）、国内企業であるPreferredNetworksで開発された（ウ）などがある。また、（エ）は（ウ）と同じDefine-by-Run方式を採用している。
問77
（エ）に最もよくあてはまる選択肢を１つ選べ。
ディープラーニングの技術を利用したシステムを開発する際、複雑な処理が比較的簡潔に記述できることから、既存のフレームワークを利用することも多い。ディープラーニングのフレームワークは複数あり、Google社提供の（ア）や（ア）のラッパーとして機能する（イ）、国内企業であるPreferredNetworksで開発された（ウ）などがある。また、（エ）は（ウ）と同じDefine-by-Run方式を採用している。
問78
（ア）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークの学習には独自の問題が生じる。層を深くするほど、入力層に近い層で学習が行われにくくなる（ア）問題が起こったり、パラメータがつくる空間が高次元になり、その空間内の局所最適解や（イ）にトラップされることが多くなる。
問79
（イ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークの学習には独自の問題が生じる。層を深くするほど、入力層に近い層で学習が行われにくくなる（ア）問題が起こったり、パラメータがつくる空間が高次元になり、その空間内の局所最適解や（イ）にトラップされることが多くなる。
問80
（ア）に最もよくあてはまる選択肢を１つ選べ。
自己符号化器（Autoencoder）は、出力が入力と同じものに近づくことを目指して学習する。（ア）のアルゴリズムであり、（イ）が可能になる。このときの（ウ）が入力の特徴を抽出した表現となる。
問81
（イ）に最もよくあてはまる選択肢を１つ選べ。
自己符号化器（Autoencoder）は、出力が入力と同じものに近づくことを目指して学習する。（ア）のアルゴリズムであり、（イ）が可能になる。このときの（ウ）が入力の特徴を抽出した表現となる。
問82
（ウ）に最もよくあてはまる選択肢を１つ選べ。
自己符号化器（Autoencoder）は、出力が入力と同じものに近づくことを目指して学習する。（ア）のアルゴリズムであり、（イ）が可能になる。このときの（ウ）が入力の特徴を抽出した表現となる。
問83
（ア）に最もよくあてはまる選択肢を１つ選べ。
機械学習において、重み更新に関わる単位として、（ア）と（イ）がある。（ア）は、重みが更新された回数であり、（イ）は訓練データを何回繰り返し学習したかを表す単位である。また一回の（ア）に用いるサンプル数は（ウ）と呼ばれる。
問84
（イ）に最もよくあてはまる選択肢を１つ選べ。
機械学習において、重み更新に関わる単位として、（ア）と（イ）がある。（ア）は、重みが更新された回数であり、（イ）は訓練データを何回繰り返し学習したかを表す単位である。また一回の（ア）に用いるサンプル数は（ウ）と呼ばれる。
問85
（ウ）に最もよくあてはまる選択肢を１つ選べ。
機械学習において、重み更新に関わる単位として、（ア）と（イ）がある。（ア）は、重みが更新された回数であり、（イ）は訓練データを何回繰り返し学習したかを表す単位である。また一回の（ア）に用いるサンプル数は（ウ）と呼ばれる。
問86
（ア）に最もよくあてはまる選択肢を１つ選べ。
活性化関数とは、ニューロンの出力に何らかの非線形な変数を加える関数である。単純パーセプトロンの出力層では（ア）が用いられ、ニューラルネットワークの中間層では、はじめ（イ）などの正規化の機能を持つ関数が好まれた。しかし現在では、誤差逆伝播で勾配が消失しやすいという問題から、中間層では勾配消失問題の影響を抑えられ、かつ簡単な（ウ）などが用いられている。また、出力層では出力の総和が１になるため確率的な解釈が可能になる（エ）がよく用いられる。
問87
（イ）に最もよくあてはまる選択肢を１つ選べ。
活性化関数とは、ニューロンの出力に何らかの非線形な変数を加える関数である。単純パーセプトロンの出力層では（ア）が用いられ、ニューラルネットワークの中間層では、はじめ（イ）などの正規化の機能を持つ関数が好まれた。しかし現在では、誤差逆伝播で勾配が消失しやすいという問題から、中間層では勾配消失問題の影響を抑えられ、かつ簡単な（ウ）などが用いられている。また、出力層では出力の総和が１になるため確率的な解釈が可能になる（エ）がよく用いられる。
問88
（ウ）に最もよくあてはまる選択肢を１つ選べ。
活性化関数とは、ニューロンの出力に何らかの非線形な変数を加える関数である。単純パーセプトロンの出力層では（ア）が用いられ、ニューラルネットワークの中間層では、はじめ（イ）などの正規化の機能を持つ関数が好まれた。しかし現在では、誤差逆伝播で勾配が消失しやすいという問題から、中間層では勾配消失問題の影響を抑えられ、かつ簡単な（ウ）などが用いられている。また、出力層では出力の総和が１になるため確率的な解釈が可能になる（エ）がよく用いられる。
問89
（エ）に最もよくあてはまる選択肢を１つ選べ。
活性化関数とは、ニューロンの出力に何らかの非線形な変数を加える関数である。単純パーセプトロンの出力層では（ア）が用いられ、ニューラルネットワークの中間層では、はじめ（イ）などの正規化の機能を持つ関数が好まれた。しかし現在では、誤差逆伝播で勾配が消失しやすいという問題から、中間層では勾配消失問題の影響を抑えられ、かつ簡単な（ウ）などが用いられている。また、出力層では出力の総和が１になるため確率的な解釈が可能になる（エ）がよく用いられる。
問90
（ア）に最もよくあてはまる選択肢を１つ選べ。
大きなニューラルネットワークなどの入出力をより小さなネットワークに学習させる技術として、（ア）がある。（ア）とは、すでに学習されているモデル（教師モデル）を利用して、より小さくシンプルなモデル（生徒モデル）を学習させる手法である。こうすることにより、生徒モデルを単独で学習させる場合よりも（イ）ことができる。
問91
（イ）に最もよくあてはまる選択肢を１つ選べ。
大きなニューラルネットワークなどの入出力をより小さなネットワークに学習させる技術として、（ア）がある。（ア）とは、すでに学習されているモデル（教師モデル）を利用して、より小さくシンプルなモデル（生徒モデル）を学習させる手法である。こうすることにより、生徒モデルを単独で学習させる場合よりも（イ）ことができる。
問92
（ア）に最もよくあてはまる選択肢を１つ選べ。
画像データに対しては、前処理を施すことが多い。カラー画像を白黒画像に変換して計算量を削減する（ア）や、細かいノイズの影響を除去する（イ）、画素ごとの明るさをスケーリングする（ウ）などがこれに含まれる。
問93
（イ）に最もよくあてはまる選択肢を１つ選べ。
画像データに対しては、前処理を施すことが多い。カラー画像を白黒画像に変換して計算量を削減する（ア）や、細かいノイズの影響を除去する（イ）、画素ごとの明るさをスケーリングする（ウ）などがこれに含まれる。
問94
（ウ）に最もよくあてはまる選択肢を１つ選べ。
画像データに対しては、前処理を施すことが多い。カラー画像を白黒画像に変換して計算量を削減する（ア）や、細かいノイズの影響を除去する（イ）、画素ごとの明るさをスケーリングする（ウ）などがこれに含まれる。
問95
（ア）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークの（ア）のパラメータ数は（イ）と比較して極めて少ない。これは（ウ）によって（エ）ため、パラメータ数が減り、計算量が少なくなるためである。
問96
（イ）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークの（ア）のパラメータ数は（イ）と比較して極めて少ない。これは（ウ）によって（エ）ため、パラメータ数が減り、計算量が少なくなるためである。
問97
（ウ）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークの（ア）のパラメータ数は（イ）と比較して極めて少ない。これは（ウ）によって（エ）ため、パラメータ数が減り、計算量が少なくなるためである。
問98
（エ）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークの（ア）のパラメータ数は（イ）と比較して極めて少ない。これは（ウ）によって（エ）ため、パラメータ数が減り、計算量が少なくなるためである。
問99
人工知能が進化するにつれ、人々の生活が格段に豊かになることが期待される一方で、悪用や乱用で公共の利益を損なう可能性も否定できない。人工知能という高度な専門的職業に従事するものとして、その社会における責任を自覚し、社会と対話をしていく行動が必要となる。一般社団法人人工知能学会は、9つの指針を定めた。以下のうち、この指針に含まれるものを答えよ。 
問100
人工知能の急激な進化により、様々なことが言われている。一つは、人工知能によって人類が危機にさらされるのではないかという議論である。2014年のテレビインタビューにおいて「人工知能の進化は人類の終焉を意味する」と発言したのは以下の誰か。 
問101
1980年代のAIの研究に関して、適切な選択肢を1つ選べ。
問102
Facebookが招いたディープラーニングの研究者として、正しいものを選択肢から1つ選べ。
問103
人工知能研究の変遷として、適切な選択肢を1つ選べ。
問104
空欄（ア）に最もよく当てはまる選択肢を1つ選べ。
現在、人工知能研究は抽象概念や知識理解に辿り着くために大きく分けて３つの路線を辿っている。この３ つの路線は、とりわけある企業や大学によって研究が進められている。
・言語データによるRNNや映像データからの概念・知識理解を目指す(ア)路線
・実世界を対象に研究を進め、知識理解を目指す(イ)路線
・オンライン空間上でできるをターゲットにするして、知識理解を目指す(ウ)路線 
問105
空欄（イ）に最もよく当てはまる選択肢を1つ選べ。
現在、人工知能研究は抽象概念や知識理解に辿り着くために大きく分けて３つの路線を辿っている。この３ つの路線は、とりわけある企業や大学によって研究が進められている。
・言語データによるRNNや映像データからの概念・知識理解を目指す(ア)路線
・実世界を対象に研究を進め、知識理解を目指す(イ)路線
・オンライン空間上でできることをターゲットにして、知識理解を目指す(ウ)路線 
問106
空欄（ウ）に最もよく当てはまる選択肢を1つ選べ。
現在、人工知能研究は抽象概念や知識理解に辿り着くために大きく分けて３つの路線を辿っている。この３ つの路線は、とりわけある企業や大学によって研究が進められている。
・言語データによるRNNや映像データからの概念・知識理解を目指す(ア)路線
・実世界を対象に研究を進め、知識理解を目指す(イ)路線
・オンライン空間上でできることをターゲットにして、知識理解を目指す(ウ)路線 
問107
空欄（ア）に最もよく当てはまる選択肢を1つ選べ。
（ア）はデータに潜む空間的構造をモデル化する。（イ）は時間的構造をモデル化する。
問108
空欄（イ）に最もよく当てはまる選択肢を1つ選べ。
（ア）はデータに潜む空間的構造をモデル化する。（イ）は時間的構造をモデル化する。
問109
次の(ア)、(イ)、(ウ)の組み合わせとして、適切な選択肢を1つ選べ。
人間の脳における学習の枠組みに基づいた３つの学習が機械学習には存在する。１つ目は小脳の働きを模 倣した（ア）である。これは学習者に対して、教師が間違いを指摘し、学習者が正しい解を得ることである。２つ 目は大脳皮質の働きを模倣した（イ）である。代表的な手法として主成分分析などの次元圧縮手法がある。３つ目 は大脳基底核の働きを模倣した（ウ）である。学習者は正解値でなく、行動した結果に基づいた報酬が与えられる。この報酬をなるべく大きくするように学習者が行動していく。
問110
空欄（ア）に最もよく当てはまる選択肢を1つ選べ。
狭い意味でのディープラーニングとは層の数が深いニューラルネットワークを用いた機械学習である。複数の層を持つ階層的ニューラルネットワークは、1980年代には(ア)という方法がすでに提案されていたが、現在ほど多くの層を持った学習をすることはできなかった。その理由として２つの理由が挙げられる。１つ目は、出力層における誤差を入力層に向けて伝播させる間に、誤差情報が徐々に拡散し、入力層に近い層では勾配の値が小さくなって学習がうまく進まないという問題が発生したからだ。このことを(イ)という。２つ目は、層の数が多いニューラルネットワークの学習の目的関数は多くの(ウ)を持ち、適切な結合の重みの初期値の設定が難しかった。
問111
空欄（イ）に最もよく当てはまる選択肢を1つ選べ。
狭い意味でのディープラーニングとは層の数が深いニューラルネットワークを用いた機械学習である。複数の層を持つ階層的ニューラルネットワークは、1980年代には(ア)という方法がすでに提案されていたが、現在ほど多くの層を持った学習をすることはできなかった。その理由として２つの理由が挙げられる。１つ目は、出力層における誤差を入力層に向けて伝播させる間に、誤差情報が徐々に拡散し、入力層に近い層では勾配の値が小さくなって学習がうまく進まないという問題が発生したからだ。このことを(イ)という。２つ目は、層の数が多いニューラルネットワークの学習の目的関数は多くの(ウ)を持ち、適切な結合の重みの初期値の設定が難しかった。
問112
空欄（ウ）に最もよく当てはまる選択肢を1つ選べ。
狭い意味でのディープラーニングとは層の数が深いニューラルネットワークを用いた機械学習である。複数の層を持つ階層的ニューラルネットワークは、1980年代には(ア)という方法がすでに提案されていたが、現在ほど多くの層を持った学習をすることはできなかった。その理由として２つの理由が挙げられる。１つ目は、出力層における誤差を入力層に向けて伝播させる間に、誤差情報が徐々に拡散し、入力層に近い層では勾配の値が小さくなって学習がうまく進まないという問題が発生したからだ。このことを(イ)という。２つ目は、層の数が多いニューラルネットワークの学習の目的関数は多くの(ウ)を持ち、適切な結合の重みの初期値の設定が難しかった。
問113
空欄（ア）に最もよく当てはまる選択肢を1つ選べ。
現在の教師あり学習は、与えられたデータがどの分類に当てはまるのかを識別する(ア)と、様々な関連性のある過去の数値から未知の数値を予測する(イ)という２つに分類される。(ア)を用いることで、(ウ)のようなことができる。また(イ)を用いることで、(エ)のようなことができる。
問114
空欄（イ）に最もよく当てはまる選択肢を1つ選べ。
現在の教師あり学習は、与えられたデータがどの分類に当てはまるのかを識別する(ア)と、様々な関連性のある過去の数値から未知の数値を予測する(イ)という２つに分類される。(ア)を用いることで、(ウ)のようなことができる。また(イ)を用いることで、(エ)のようなことができる。
問115
空欄（ウ）に最もよく当てはまる選択肢を1つ選べ。
現在の教師あり学習は、与えられたデータがどの分類に当てはまるのかを識別する(ア)と、様々な関連性のある過去の数値から未知の数値を予測する(イ)という２つに分類される。(ア)を用いることで、(ウ)のようなことができる。また(イ)を用いることで、(エ)のようなことができる。
問116
空欄（エ）に最もよく当てはまる選択肢を1つ選べ。
現在の教師あり学習は、与えられたデータがどの分類に当てはまるのかを識別する(ア)と、様々な関連性のある過去の数値から未知の数値を予測する(イ)という２つに分類される。(ア)を用いることで、(ウ)のようなことができる。また(イ)を用いることで、(エ)のようなことができる。
問117
表現学習とは、ディープラーニングを抽象化した概念で、画像、音、自然言語などの要素を、予測問題として解くことで分散表現（ベクトル）を得て、各々の要素を抽象化する手法である。こうした特徴表現は、通常は 人間の知識によって定義されるが、それによって機械学習の性能が大きく異なってしまう。こうした知的な情報処理を可能にしたのがディープラーニングである。ディープラーニングは観測データの説明要因を捉え、人間の知識では気がつくことができない共通点を捉えることができるが、この共通点のことをよい表現という。ヨシュ ア・ベンジオ氏は良い表現に共通する、世界に関する多くの一般的な事前知識として、いくつかを提唱している。よい表現として当てはまらないものを選択肢から1つ選べ。
問118
空欄(ア)、(イ)、(ウ)の組み合わせとして、適切な選択肢を1つ選べ。
良い表現として、ディープラーニングのアプローチは(ア)、 (イ)、(ウ)に着目している。このことから、(ア)、(イ)、(ウ)の事前知識を適切に活用できるなら、表現学習は必 ずしも層の数が多いニューラルネットワークの形をしていなくてもよいことになる。
問119
空欄（ア）に最もよく当てはまる選択肢を1つ選べ。
教師なし学習の中で有名なのは、未知の集合を、いくつかの集まりに分類させる(ア)という学習方法と、正常な行為がどのようなものかを学習し、それと大きく異なるものを識別する(イ)がある。(ア)は特に(ウ)というア ルゴリズムを使用して顧客の分類分けによるDM配信やレコメンドを行う。(イ)は(エ)というアルゴリズムを基に、セキュリティシステムなどに使用されている。
問120
空欄（イ）に最もよく当てはまる選択肢を1つ選べ。
教師なし学習の中で有名なのは、未知の集合を、いくつかの集まりに分類させる(ア)という学習方法と、正常な行為がどのようなものかを学習し、それと大きく異なるものを識別する(イ)がある。(ア)は特に(ウ)というア ルゴリズムを使用して顧客の分類分けによるDM配信やレコメンドを行う。(イ)は(エ)というアルゴリズムを基に、セキュリティシステムなどに使用されている。
問121
空欄（ウ）に最もよく当てはまる選択肢を1つ選べ。
教師なし学習の中で有名なのは、未知の集合を、いくつかの集まりに分類させる(ア)という学習方法と、正常な行為がどのようなものかを学習し、それと大きく異なるものを識別する(イ)がある。(ア)は特に(ウ)というア ルゴリズムを使用して顧客の分類分けによるDM配信やレコメンドを行う。(イ)は(エ)というアルゴリズムを基に、セキュリティシステムなどに使用されている。
問122
空欄（エ）に最もよく当てはまる選択肢を1つ選べ。
教師なし学習の中で有名なのは、未知の集合を、いくつかの集まりに分類させる(ア)という学習方法と、正常な行為がどのようなものかを学習し、それと大きく異なるものを識別する(イ)がある。(ア)は特に(ウ)というア ルゴリズムを使用して顧客の分類分けによるDM配信やレコメンドを行う。(イ)は(エ)というアルゴリズムを基に、セキュリティシステムなどに使用されている。
問123
空欄（ア）に最もよく当てはまる選択肢を1つ選べ。
画像の認識では、主に入力から出力に向かう結合のみを持つ階層的なニューラルネットワーク、特に画像などの信号に内在する局所的な特徴が集まって、より大域的な特徴を構成するという構造を反映した、(ア)がよく用いられる。一方、自然言語テキストや動画に代表される構造を持った系列情報を扱うために(イ)が用いられている。特にケプラー大学のゼップ・ホフレイター氏の提案した(ウ)は必要な文脈情報の長さを適応的に制御することで、時間を遡る誤差逆伝播の可能性向上させ、画像からの説明文の生成や機械翻訳など、多くの課題に適用されている。実際、2016年秋に、GoogleはGoogle翻訳に(ウ)を取り入れてアップデートし、非常に高精度な翻訳を提供することが可能になった。
問124
空欄（イ）に最もよく当てはまる選択肢を1つ選べ。
画像の認識では、主に入力から出力に向かう結合のみを持つ階層的なニューラルネットワーク、特に画像などの信号に内在する局所的な特徴が集まって、より大域的な特徴を構成するという構造を反映した、(ア)がよく用いられる。一方、自然言語テキストや動画に代表される構造を持った系列情報を扱うために(イ)が用いられている。特にケプラー大学のゼップ・ホフレイター氏の提案した(ウ)は必要な文脈情報の長さを適応的に制御することで、時間を遡る誤差逆伝播の可能性向上させ、画像からの説明文の生成や機械翻訳など、多くの課題に適用されている。実際、2016年秋に、GoogleはGoogle翻訳に(ウ)を取り入れてアップデートし、非常に高精度な翻訳を提供することが可能になった。
問125
空欄（ウ）に最もよく当てはまる選択肢を1つ選べ。
画像の認識では、主に入力から出力に向かう結合のみを持つ階層的なニューラルネットワーク、特に画像などの信号に内在する局所的な特徴が集まって、より大域的な特徴を構成するという構造を反映した、(ア)がよく用いられる。一方、自然言語テキストや動画に代表される構造を持った系列情報を扱うために(イ)が用いられている。特にケプラー大学のゼップ・ホフレイター氏の提案した(ウ)は必要な文脈情報の長さを適応的に制御することで、時間を遡る誤差逆伝播の可能性向上させ、画像からの説明文の生成や機械翻訳など、多くの課題に適用されている。実際、2016年秋に、GoogleはGoogle翻訳に(ウ)を取り入れてアップデートし、非常に高精度な翻訳を提供することが可能になった。
問126
2012に開催された一般物体認識のコンテスト「ILSVRC」(ImageNet Large Scale Visual Recognition Challenge)において、深い構造を持つCNNが、従来手法の分類性能を大幅に上回って以来、ディープラーニングが画像認識に盛んに用いられるようになった。ディープラーニングの画像認識への応用先として正しい組み合わせを選択肢から1つ選べ。
問127
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
クラス分類の領域では、CNNという沢山の層を重ねて、深い階層構造した手法によって研究が進めらてい
て、従来の手法よりも精度の高い認識や分類が可能となった。しかし、沢山の層を重ねた結果、学習に用いられ
るパラメータの数が膨大となり、学習が上手く進まないという問題が生じていた。その問題を解決するために提
案されたのが(ア)である。(ア)は、入力層から出力層まで伝播する値と入力層の値を足し合わせたモデルで、こ
の方法によって、入力層まで、勾配値がきちんと伝わり、今では1000層といったかなり深い構造でも学習が可
能となった。実際、2015年のILSVRCで(ア)は人間の成績を上回る成果をあげている
問128
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
物体検出とは(ア)である。一方物体セグメンテーションとは(イ)である。
問129
空欄(イ)に当てはまる適切な選択肢を1つ選べ。
物体検出とは(ア)である。一方物体セグメンテーションとは(イ)である。
問130
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
画像キャプションとは、ある画像からそこに写っているものの説明を生成する、画像処理と自然言語処理の融合分野である。キャプションは、対象となる画像を(ア)に入力し、そこから得られた特徴を(イ)に入力することで生成することが可能である。
問131
空欄(イ)に当てはまる適切な選択肢を1つ選べ。
画像キャプションとは、ある画像からそこに写っているものの説明を生成する、画像処理と自然言語処理の融合分野である。キャプションは、対象となる画像を(ア)に入力し、そこから得られた特徴を(イ)に入力することで生成することが可能である。
問132
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
画像生成とは、何もない状態、もしくはある入力値に応じて目標の画像を生成する技術である。今最も利用されている画像生成手法は、GANという生成敵対ネットワークである。特に、あるランダムな数値の入力値をもとに画像生成を行うDC（ア）やある文章から画像を生成するAttention（ア）などが有名である。このネットワー クは(イ)と(ウ)から構成されており、(イ)は(エ)を騙すような画像を出力し、(ウ)は(イ)から出力された画像と本物の画像とを分類するようにそれぞれ学習する。このように学習することで、(イ)は適切な画像を出力することが可能となる。 
問133
空欄(イ)に当てはまる適切な選択肢を1つ選べ。
画像生成とは、何もない状態、もしくはある入力値に応じて目標の画像を生成する技術である。今最も利用されている画像生成手法は、GANという生成敵対ネットワークである。特に、あるランダムな数値の入力値をもとに画像生成を行うDC（ア）やある文章から画像を生成するAttention（ア）などが有名である。このネットワー クは(イ)と(ウ)から構成されており、(イ)は(エ)を騙すような画像を出力し、(ウ)は(イ)から出力された画像と本物の画像とを分類するようにそれぞれ学習する。このように学習することで、(イ)は適切な画像を出力することが可能となる。 
問134
空欄(ウ)に当てはまる適切な選択肢を1つ選べ。
画像生成とは、何もない状態、もしくはある入力値に応じて目標の画像を生成する技術である。今最も利用されている画像生成手法は、GANという生成敵対ネットワークである。特に、あるランダムな数値の入力値をもとに画像生成を行うDC（ア）やある文章から画像を生成するAttention（ア）などが有名である。このネットワー クは(イ)と(ウ)から構成されており、(イ)は(エ)を騙すような画像を出力し、(ウ)は(イ)から出力された画像と本物の画像とを分類するようにそれぞれ学習する。このように学習することで、(イ)は適切な画像を出力することが可能となる。 
問135
空欄(エ)に当てはまる適切な選択肢を1つ選べ。
画像生成とは、何もない状態、もしくはある入力値に応じて目標の画像を生成する技術である。今最も利用されている画像生成手法は、GANという生成敵対ネットワークである。特に、あるランダムな数値の入力値をもとに画像生成を行うDC（ア）やある文章から画像を生成するAttention（ア）などが有名である。このネットワー クは(イ)と(ウ)から構成されており、(イ)は(エ)を騙すような画像を出力し、(ウ)は(イ)から出力された画像と本物の画像とを分類するようにそれぞれ学習する。このように学習することで、(イ)は適切な画像を出力することが可能となる。 
問136
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
従来は、現在のディープラーニングのように入力から出力までの処理を一括で行うことができない情報を扱うことがあった。そうした場合、まず用意したデータをある手法を用いて加工し、それが入力値となり、別の手法を用いて処理を行いといった、ステップバイステップの学習が必要だった。しかし、ディープラーニングの登場によって、処理を複数回に分けて行う必要がなくなったこのような、深層学習において重要な方法論のことを(ア)と呼ぶ。
問137
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
1990年代の音声認識は(ア)による、音自体を判別するための音響モデルと、(イ)による語と語のつながりを判別する言語モデルの両方でできている。しかし、ディープラーニングの登場、とりわけ(ウ)の登場により、音響特徴量から音素、文字列、更には単語列に直接変換するEnd to Endモデルというアプローチを取ることが可能になり、人的に前処理を行わなくても解析することが可能となった。
問138
空欄(イ)に当てはまる適切な選択肢を1つ選べ。
1990年代の音声認識は(ア)による、音自体を判別するための音響モデルと、(イ)による語と語のつながりを判別する言語モデルの両方でできている。しかし、ディープラーニングの登場、とりわけ(ウ)の登場により、音響特徴量から音素、文字列、更には単語列に直接変換するEnd to Endモデルというアプローチを取ることが可能になり、人的に前処理を行わなくても解析することが可能となった。
問139
空欄(ウ)に当てはまる適切な選択肢を1つ選べ。
1990年代の音声認識は(ア)による、音自体を判別するための音響モデルと、(イ)による語と語のつながりを判別する言語モデルの両方でできている。しかし、ディープラーニングの登場、とりわけ(ウ)の登場により、音響特徴量から音素、文字列、更には単語列に直接変換するEnd to Endモデルというアプローチを取ることが可能になり、人的に前処理を行わなくても解析することが可能となった。
問140
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
ディープラーニングはソフトウェアフレームワークを利用して実装するのが一般的である。多層のニュー
ラルネットワークモデルを定義し、データを用いて学習・予測を実行するのがフレームワークの役割だが、重要なのはネットワークの記述方法とその柔軟性である。ネットワークには大きく分けて２つの記述方法がある。１つ目は(ア)による記述方法である。これらの記述方法を採用しているソフトウェアには(イ)があげられる。この方法を用いることによって、モデルの定義がテキストで設定でき、簡単に学習を開始開始させることが出来るというメリットがある。一方で、ループ構造をもつようなRNNなど、複雑なモデルを扱う際には、モデルの定義を記述することは難しくなる傾向にある。２つ目は(ウ)による記述方法である。代表的なフレームワークとして(エ)があげられる。一度書き方を覚えてしまば、複雑なモデルでも比較的簡単に記述することが出来るが、モデルは、それぞれのフレームワーク固有のソースコードで出来上がるため、モデルが使用しているソフトウェアに依存してしまうという問題がある。
問141
空欄(イ)に当てはまる適切な選択肢を1つ選べ。
ディープラーニングはソフトウェアフレームワークを利用して実装するのが一般的である。多層のニュー
ラルネットワークモデルを定義し、データを用いて学習・予測を実行するのがフレームワークの役割だが、重要なのはネットワークの記述方法とその柔軟性である。ネットワークには大きく分けて２つの記述方法がある。１つ目は(ア)による記述方法である。これらの記述方法を採用しているソフトウェアには(イ)があげられる。この方法を用いることによって、モデルの定義がテキストで設定でき、簡単に学習を開始開始させることが出来るというメリットがある。一方で、ループ構造をもつようなRNNなど、複雑なモデルを扱う際には、モデルの定義を記述することは難しくなる傾向にある。２つ目は(ウ)による記述方法である。代表的なフレームワークとして(エ)があげられる。一度書き方を覚えてしまば、複雑なモデルでも比較的簡単に記述することが出来るが、モデルは、それぞれのフレームワーク固有のソースコードで出来上がるため、モデルが使用しているソフトウェアに依存してしまうという問題がある。
問142
空欄(ウ)に当てはまる適切な選択肢を1つ選べ。
ディープラーニングはソフトウェアフレームワークを利用して実装するのが一般的である。多層のニュー
ラルネットワークモデルを定義し、データを用いて学習・予測を実行するのがフレームワークの役割だが、重要なのはネットワークの記述方法とその柔軟性である。ネットワークには大きく分けて２つの記述方法がある。１つ目は(ア)による記述方法である。これらの記述方法を採用しているソフトウェアには(イ)があげられる。この方法を用いることによって、モデルの定義がテキストで設定でき、簡単に学習を開始開始させることが出来るというメリットがある。一方で、ループ構造をもつようなRNNなど、複雑なモデルを扱う際には、モデルの定義を記述することは難しくなる傾向にある。２つ目は(ウ)による記述方法である。代表的なフレームワークとして(エ)があげられる。一度書き方を覚えてしまば、複雑なモデルでも比較的簡単に記述することが出来るが、モデルは、それぞれのフレームワーク固有のソースコードで出来上がるため、モデルが使用しているソフトウェアに依存してしまうという問題がある。
問143
空欄(エ)に当てはまる適切な選択肢を1つ選べ。
ディープラーニングはソフトウェアフレームワークを利用して実装するのが一般的である。多層のニュー
ラルネットワークモデルを定義し、データを用いて学習・予測を実行するのがフレームワークの役割だが、重要なのはネットワークの記述方法とその柔軟性である。ネットワークには大きく分けて２つの記述方法がある。１つ目は(ア)による記述方法である。これらの記述方法を採用しているソフトウェアには(イ)があげられる。この方法を用いることによって、モデルの定義がテキストで設定でき、簡単に学習を開始開始させることが出来るというメリットがある。一方で、ループ構造をもつようなRNNなど、複雑なモデルを扱う際には、モデルの定義を記述することは難しくなる傾向にある。２つ目は(ウ)による記述方法である。代表的なフレームワークとして(エ)があげられる。一度書き方を覚えてしまば、複雑なモデルでも比較的簡単に記述することが出来るが、モデルは、それぞれのフレームワーク固有のソースコードで出来上がるため、モデルが使用しているソフトウェアに依存してしまうという問題がある。
問144
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
線形モデルとは、(ア)を含む項の線形結合で、(ア)を含んだ数式の出力値は(イ)と呼ばれる。この線形結合で、特に(ア)も(イ)も一次元のデータの場合は、y = b0 + b1 * xと表される。こういったモデルを単回帰モデルと呼んだりもする。この数式に置いて、各項の係数(例えばb0, b1)を(ウ)と呼び、このモデルを用いてテストデータを学習し、測定した実データを推定する。注意点として、(イ)が連続の値を取り扱う場合(エ)と呼ばれるが、離散の値を取り扱われる場合は(オ)と呼ばれ、それぞれ名称が異なる。ただ、実際のデータを扱うときに、(ア)が１次元であることはほとんどなく、２次元以上になることが一般的である。このような場合、(ア)の次元数分だけ、係数パラメータを増やして、モデルを拡張する必要がある。このように(ア)が２つ以上の場合を(カ)モデルと呼び、各項の係数パラメーターを(キ)という。またモデルによって出力された値と実際の測定値の誤差を(ク)という。この(ク)を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある。
問145
空欄(イ)に当てはまる適切な選択肢を1つ選べ。
線形モデルとは、(ア)を含む項の線形結合で、(ア)を含んだ数式の出力値は(イ)と呼ばれる。この線形結合で、特に(ア)も(イ)も一次元のデータの場合は、y = b0 + b1 * xと表される。こういったモデルを単回帰モデルと呼んだりもする。この数式に置いて、各項の係数(例えばb0, b1)を(ウ)と呼び、このモデルを用いてテストデータを学習し、測定した実データを推定する。注意点として、(イ)が連続の値を取り扱う場合(エ)と呼ばれるが、離散の値を取り扱われる場合は(オ)と呼ばれ、それぞれ名称が異なる。ただ、実際のデータを扱うときに、(ア)が１次元であることはほとんどなく、２次元以上になることが一般的である。このような場合、(ア)の次元数分だけ、係数パラメータを増やして、モデルを拡張する必要がある。このように(ア)が２つ以上の場合を(カ)モデルと呼び、各項の係数パラメーターを(キ)という。またモデルによって出力された値と実際の測定値の誤差を(ク)という。この(ク)を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある。
問146
空欄(ウ)に当てはまる適切な選択肢を1つ選べ。
線形モデルとは、(ア)を含む項の線形結合で、(ア)を含んだ数式の出力値は(イ)と呼ばれる。この線形結合で、特に(ア)も(イ)も一次元のデータの場合は、y = b0 + b1 * xと表される。こういったモデルを単回帰モデルと呼んだりもする。この数式に置いて、各項の係数(例えばb0, b1)を(ウ)と呼び、このモデルを用いてテストデータを学習し、測定した実データを推定する。注意点として、(イ)が連続の値を取り扱う場合(エ)と呼ばれるが、離散の値を取り扱われる場合は(オ)と呼ばれ、それぞれ名称が異なる。ただ、実際のデータを扱うときに、(ア)が１次元であることはほとんどなく、２次元以上になることが一般的である。このような場合、(ア)の次元数分だけ、係数パラメータを増やして、モデルを拡張する必要がある。このように(ア)が２つ以上の場合を(カ)モデルと呼び、各項の係数パラメーターを(キ)という。またモデルによって出力された値と実際の測定値の誤差を(ク)という。この(ク)を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある。
問147
空欄(エ)に当てはまる適切な選択肢を1つ選べ。
線形モデルとは、(ア)を含む項の線形結合で、(ア)を含んだ数式の出力値は(イ)と呼ばれる。この線形結合で、特に(ア)も(イ)も一次元のデータの場合は、y = b0 + b1 * xと表される。こういったモデルを単回帰モデルと呼んだりもする。この数式に置いて、各項の係数(例えばb0, b1)を(ウ)と呼び、このモデルを用いてテストデータを学習し、測定した実データを推定する。注意点として、(イ)が連続の値を取り扱う場合(エ)と呼ばれるが、離散の値を取り扱われる場合は(オ)と呼ばれ、それぞれ名称が異なる。ただ、実際のデータを扱うときに、(ア)が１次元であることはほとんどなく、２次元以上になることが一般的である。このような場合、(ア)の次元数分だけ、係数パラメータを増やして、モデルを拡張する必要がある。このように(ア)が２つ以上の場合を(カ)モデルと呼び、各項の係数パラメーターを(キ)という。またモデルによって出力された値と実際の測定値の誤差を(ク)という。この(ク)を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある。
問148
空欄(オ)に当てはまる適切な選択肢を1つ選べ。
線形モデルとは、(ア)を含む項の線形結合で、(ア)を含んだ数式の出力値は(イ)と呼ばれる。この線形結合で、特に(ア)も(イ)も一次元のデータの場合は、y = b0 + b1 * xと表される。こういったモデルを単回帰モデルと呼んだりもする。この数式に置いて、各項の係数(例えばb0, b1)を(ウ)と呼び、このモデルを用いてテストデータを学習し、測定した実データを推定する。注意点として、(イ)が連続の値を取り扱う場合(エ)と呼ばれるが、離散の値を取り扱われる場合は(オ)と呼ばれ、それぞれ名称が異なる。ただ、実際のデータを扱うときに、(ア)が１次元であることはほとんどなく、２次元以上になることが一般的である。このような場合、(ア)の次元数分だけ、係数パラメータを増やして、モデルを拡張する必要がある。このように(ア)が２つ以上の場合を(カ)モデルと呼び、各項の係数パラメーターを(キ)という。またモデルによって出力された値と実際の測定値の誤差を(ク)という。この(ク)を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある。
問149
空欄(カ)に当てはまる適切な選択肢を1つ選べ。
線形モデルとは、(ア)を含む項の線形結合で、(ア)を含んだ数式の出力値は(イ)と呼ばれる。この線形結合で、特に(ア)も(イ)も一次元のデータの場合は、y = b0 + b1 * xと表される。こういったモデルを単回帰モデルと呼んだりもする。この数式に置いて、各項の係数(例えばb0, b1)を(ウ)と呼び、このモデルを用いてテストデータを学習し、測定した実データを推定する。注意点として、(イ)が連続の値を取り扱う場合(エ)と呼ばれるが、離散の値を取り扱われる場合は(オ)と呼ばれ、それぞれ名称が異なる。ただ、実際のデータを扱うときに、(ア)が１次元であることはほとんどなく、２次元以上になることが一般的である。このような場合、(ア)の次元数分だけ、係数パラメータを増やして、モデルを拡張する必要がある。このように(ア)が２つ以上の場合を(カ)モデルと呼び、各項の係数パラメーターを(キ)という。またモデルによって出力された値と実際の測定値の誤差を(ク)という。この(ク)を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある。
問150
空欄(キ)に当てはまる適切な選択肢を1つ選べ。
線形モデルとは、(ア)を含む項の線形結合で、(ア)を含んだ数式の出力値は(イ)と呼ばれる。この線形結合で、特に(ア)も(イ)も一次元のデータの場合は、y = b0 + b1 * xと表される。こういったモデルを単回帰モデルと呼んだりもする。この数式に置いて、各項の係数(例えばb0, b1)を(ウ)と呼び、このモデルを用いてテストデータを学習し、測定した実データを推定する。注意点として、(イ)が連続の値を取り扱う場合(エ)と呼ばれるが、離散の値を取り扱われる場合は(オ)と呼ばれ、それぞれ名称が異なる。ただ、実際のデータを扱うときに、(ア)が１次元であることはほとんどなく、２次元以上になることが一般的である。このような場合、(ア)の次元数分だけ、係数パラメータを増やして、モデルを拡張する必要がある。このように(ア)が２つ以上の場合を(カ)モデルと呼び、各項の係数パラメーターを(キ)という。またモデルによって出力された値と実際の測定値の誤差を(ク)という。この(ク)を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある。
問151
空欄(ク)に当てはまる適切な選択肢を1つ選べ。
線形モデルとは、(ア)を含む項の線形結合で、(ア)を含んだ数式の出力値は(イ)と呼ばれる。この線形結合で、特に(ア)も(イ)も一次元のデータの場合は、y = b0 + b1 * xと表される。こういったモデルを単回帰モデルと呼んだりもする。この数式に置いて、各項の係数(例えばb0, b1)を(ウ)と呼び、このモデルを用いてテストデータを学習し、測定した実データを推定する。注意点として、(イ)が連続の値を取り扱う場合(エ)と呼ばれるが、離散の値を取り扱われる場合は(オ)と呼ばれ、それぞれ名称が異なる。ただ、実際のデータを扱うときに、(ア)が１次元であることはほとんどなく、２次元以上になることが一般的である。このような場合、(ア)の次元数分だけ、係数パラメータを増やして、モデルを拡張する必要がある。このように(ア)が２つ以上の場合を(カ)モデルと呼び、各項の係数パラメーターを(キ)という。またモデルによって出力された値と実際の測定値の誤差を(ク)という。この(ク)を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある。
問152
最小二乗法の説明として最も適切な選択肢を1つ選べ。
問153
最尤推定法の説明として最も適切な選択肢を1つ選べ。
問154
最小二乗法の説明として誤った選択肢を1つ選べ 
問155
ディープラーニングの使用の注意点として、最も適切な選択肢を1つ選べ。
問156
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
ディープラーニングの学習の目的は、損失関数の値をできるだけ小さくするパラメータを見つけることで ある。このような問題を解くことを(ア)という。このパラメータを見つけるアルゴリズムとして有名なのは(イ) である。ただ、(イ)は対象の関数の形がある分布や方向に依存すると非効率な経路でパラメータを探索してしまい、学習に時間がかかってしまうというデメリットがある。そこで、現在では(イ)の欠点を改善するために(ウ) などのアルゴリズムが使用されている。
問157
空欄(イ)に当てはまる適切な選択肢を1つ選べ。
ディープラーニングの学習の目的は、損失関数の値をできるだけ小さくするパラメータを見つけることで ある。このような問題を解くことを(ア)という。このパラメータを見つけるアルゴリズムとして有名なのは(イ) である。ただ、(イ)は対象の関数の形がある分布や方向に依存すると非効率な経路でパラメータを探索してしまい、学習に時間がかかってしまうというデメリットがある。そこで、現在では(イ)の欠点を改善するために(ウ) などのアルゴリズムが使用されている。
問158
空欄(ウ)に当てはまる適切な選択肢を1つ選べ。
ディープラーニングの学習の目的は、損失関数の値をできるだけ小さくするパラメータを見つけることで ある。このような問題を解くことを(ア)という。このパラメータを見つけるアルゴリズムとして有名なのは(イ) である。ただ、(イ)は対象の関数の形がある分布や方向に依存すると非効率な経路でパラメータを探索してしまい、学習に時間がかかってしまうというデメリットがある。そこで、現在では(イ)の欠点を改善するために(ウ) などのアルゴリズムが使用されている。
問159
空欄(ア)に当てはまる適切な選択肢を1つ選べ。
機械が試行錯誤することで、取るべき最善の行動を決定する問題を扱うことができる学習方法を(ア)という。(ア)はボードゲームや自動運転、またロボットの歩行動作などに活用されている。代表的なアルゴリズムに (イ)があげられる。(ア)の課題として、主に(ウ)や(エ)などが挙げられる。理論的には無限に学習するが、実世界では全てが限られている。ロボットの場合、無限の試行を繰り返すことができず、損耗し、実験の続行が困難になる。そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される。また(エ)に関して、例として、２体のロボット同士で学習を開始させようとすると、お互いに初期状態であるタスクについての何も知識がない状態だと、学習過程の不安定化が見られる。現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した(オ)などが適用され始めている。
問160
空欄(イ)に当てはまる適切な選択肢を1つ選べ。
機械が試行錯誤することで、取るべき最善の行動を決定する問題を扱うことができる学習方法を(ア)という。(ア)はボードゲームや自動運転、またロボットの歩行動作などに活用されている。代表的なアルゴリズムに (イ)があげられる。(ア)の課題として、主に(ウ)や(エ)などが挙げられる。理論的には無限に学習するが、実世界では全てが限られている。ロボットの場合、無限の試行を繰り返すことができず、損耗し、実験の続行が困難になる。そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される。また(エ)に関して、例として、２体のロボット同士で学習を開始させようとすると、お互いに初期状態であるタスクについての何も知識がない状態だと、学習過程の不安定化が見られる。現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した(オ)などが適用され始めている。
問161
空欄(ウ)に当てはまる適切な選択肢を1つ選べ。
機械が試行錯誤することで、取るべき最善の行動を決定する問題を扱うことができる学習方法を(ア)という。(ア)はボードゲームや自動運転、またロボットの歩行動作などに活用されている。代表的なアルゴリズムに (イ)があげられる。(ア)の課題として、主に(ウ)や(エ)などが挙げられる。理論的には無限に学習するが、実世界では全てが限られている。ロボットの場合、無限の試行を繰り返すことができず、損耗し、実験の続行が困難になる。そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される。また(エ)に関して、例として、２体のロボット同士で学習を開始させようとすると、お互いに初期状態であるタスクについての何も知識がない状態だと、学習過程の不安定化が見られる。現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した(オ)などが適用され始めている。
問162
空欄(エ)に当てはまる適切な選択肢を1つ選べ。
機械が試行錯誤することで、取るべき最善の行動を決定する問題を扱うことができる学習方法を(ア)という。(ア)はボードゲームや自動運転、またロボットの歩行動作などに活用されている。代表的なアルゴリズムに (イ)があげられる。(ア)の課題として、主に(ウ)や(エ)などが挙げられる。理論的には無限に学習するが、実世界では全てが限られている。ロボットの場合、無限の試行を繰り返すことができず、損耗し、実験の続行が困難になる。そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される。また(エ)に関して、例として、２体のロボット同士で学習を開始させようとすると、お互いに初期状態であるタスクについての何も知識がない状態だと、学習過程の不安定化が見られる。現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した(オ)などが適用され始めている。
問163
空欄(オ)に当てはまる適切な選択肢を1つ選べ。
機械が試行錯誤することで、取るべき最善の行動を決定する問題を扱うことができる学習方法を(ア)という。(ア)はボードゲームや自動運転、またロボットの歩行動作などに活用されている。代表的なアルゴリズムに (イ)があげられる。(ア)の課題として、主に(ウ)や(エ)などが挙げられる。理論的には無限に学習するが、実世界では全てが限られている。ロボットの場合、無限の試行を繰り返すことができず、損耗し、実験の続行が困難になる。そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される。また(エ)に関して、例として、２体のロボット同士で学習を開始させようとすると、お互いに初期状態であるタスクについての何も知識がない状態だと、学習過程の不安定化が見られる。現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した(オ)などが適用され始めている。
問164
以下の文章をよく読み、末尾の設問に答えよ。
昨今、ディープラーニングを活用した音声認識技術、音声生成技術の向上に伴い、スマートスピーカーが普及しつつある。下記の選択肢のうち、スマートスピーカーの音声アシスタントソフトウェアの名称とその提供元の組み合わせとして正しいものを選択肢から１つ選べ。
問165
以下の文章をよく読み、末尾の設問に答えよ。
AIの研究開発が進むにつれて、実世界への社会実装で最も期待されている分野の１つに自動走行車の開発が挙げられる。現在AIを用いた自動走行車には、その自動運転導入の程度に応じてレベルづけがなされており、各社でどのように最終的なゴールであるレベル５の完全自動走行に近づくかが議論されている。
各レベルにおける自動運転の概要について説明した文章のうち、自動運転レベル３に対応しているものを選択肢より一つ選べ。
問166
空欄 (ア) に当てはまる選択肢として適切な選択肢を１つ選べ。
自動運転レベル５に至るには、２つのアプローチが存在している。１つは自動運転レベル１から徐々に運転自動化の範囲を広げていくアプローチ、もう１つは直接レベル３以上の自動運転を目指そうとするものである。この時、前者のレベル１から徐々に運転自動化を目指すアプローチを採っているプレイヤーは (ア) などである。他方で、後者の直接レベル３以上の運転自動化を目指すアプローチを採っているプレイヤーは (イ) である。また後者のアプローチを採る企業として著名なのは、Google 傘下の (ウ) 社である。
問167
空欄 (イ) に当てはまる選択肢として適切な選択肢を１つ選べ。
自動運転レベル５に至るには、２つのアプローチが存在している。１つは自動運転レベル１から徐々に運転自動化の範囲を広げていくアプローチ、もう１つは直接レベル３以上の自動運転を目指そうとするものである。この時、前者のレベル１から徐々に運転自動化を目指すアプローチを採っているプレイヤーは (ア) などである。他方で、後者の直接レベル３以上の運転自動化を目指すアプローチを採っているプレイヤーは (イ) である。また後者のアプローチを採る企業として著名なのは、Google 傘下の (ウ) 社である。
問168
以下の文章をよく読み、空欄 (ウ) に当てはまる選択肢として最も適切な選択肢を一つ選べ。
自動運転レベル５に至るには、２つのアプローチが存在している。１つは自動運転レベル１から徐々に運転自動化の範囲を広げていくアプローチ、もう１つは直接レベル３以上の自動運転を目指そうとするものである。この時、前者のレベル１から徐々に運転自動化を目指すアプローチを採っているプレイヤーは (ア) などである。他方で、後者の直接レベル３以上の運転自動化を目指すアプローチを採っているプレイヤーは (イ) である。また後者のアプローチを採る企業として著名なのは、Google 傘下の (ウ) 社である。
問169
以下の文章をよく読み、末尾の設問に答えよ。
AI 技術の進展により一般に普及する可能性が急激に高まってきたのが、小型無人機 (以下ドローン) である。他方でこれまでに存在しなかった新しいプロダクトで、人々がこれまで意識することのなかった空域などの問題が生じてきた。例えば、ドローンを飛ばす空域は、飛ばすのに許可が必要な空域がある。

選択肢のうち、ドローンを飛ばすのに許可を必要とする空域の説明として「正しくないもの」を選択肢より一つ選択せよ。
問170
以下の文章をよく読み、末尾の設問に答えよ。
AI 技術の進展により一般に普及する可能性が急激に高まってきたのが、小型無人機 (以下ドローン) である。他方でこれまでに存在しなかった新しいプロダクトで、人々がこれまで意識することのなかった空域などの問題が生じてきた。例えば、ドローンを飛ばす空域は、飛ばすのに許可が必要な空域がある。またドローンはその利用方法に応じて、承認が必要となることがある。

ドローンの飛行規制について、「正しくないもの」を選択肢から一つ選べ。
問171
以下の文章をよく読み、末尾の設問に答えよ。
AIの社会実装を進めていくにあたり、AIがもたらす倫理的リスクを事前に考慮しておく必要性が近年強く叫ばれている。各国政府はそれに対応すべく様々な取り組みを行っている。
米国政府の例を取ると、米国政府は2016年10月に "PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" を発行し、続けさまに同年 "THE NATIONAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN" 、そして2016年12月に発行した "ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" などで、これから表面化するであろうリスクへの対応策を事前に協議している。

このうち、"PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" で協議された内容として最も適切なものを１つ選べ。
問172
以下の文章をよく読み、末尾の設問に答えよ。
AIの社会実装を進めていくにあたり、AIがもたらす倫理的リスクを事前に考慮しておく必要性が近年強く叫ばれている。各国政府はそれに対応すべく様々な取り組みを行っている。
米国政府の例を取ると、米国政府は2016年10月に "PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" を発行し、続けさまに同年 "THE NATIONAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN" 、そして2016年12月に発行した "ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" などで、これから表面化するであろうリスクへの対応策を事前に協議している。

このうち、"THE NATIONAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN"で協議された内容として最も適切なものを一つ選べ。
問173
以下の文章をよく読み、末尾の設問に答えよ。
AIの社会実装を進めていくにあたり、AIがもたらす倫理的リスクを事前に考慮しておく必要性が近年強く叫ばれている。各国政府はそれに対応すべく様々な取り組みを行なっている。
米国政府の例を取ると、米国政府は2016年10月に "PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" を発行し、続けさまに同年 "THE NATIONAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN" 、そして2016年12月に発行した "ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" などで、これから表面化するであろうリスクへの対応策を事前に協議している。

このうち、"ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" で協議された内容として最も適切なものを一つ選べ。
問174
以下の文章をよく読み、空欄 (ア) に最もよく当てはまる選択肢を選べ。
ディープラーニングの活用を進めていく必要性の高まりに対して、日本国内においてはそうした先端IT技術に精通した人材不足が懸念されている。
例えば、経済産業省が定めた先端IT人材がどのような人材需給状況にあるかの推定によると、2020年には需給ギャップが広がり人材の不足は (ア) に及ぶと言われている。
こうした人材不足を解消するべく、様々な方法でAIに理解のある人材育成が試みられている。そのような試みの一つとして、MOOCs は期待を寄せられている。著名な例としては、AI研究の第一人者で、2014年から2017年にかけて Baidu の AI 研究所所長を務めた (イ) が創業した Coursera などは入門から上級まで様々なレベルの AI 講義が開かれており、多くの受講者を惹きつけるに至っている。
問175
以下の文章をよく読み、空欄 (イ) に最よく当てはまる選択肢を選べ。
ディープラーニングの活用を進めていく必要性の高まりに対して、日本国内においてはそうした先端IT技術に精通した人材不足が懸念されている。
例えば、経済産業省が定めた先端IT人材がどのような人材需給状況にあるかの推定によると、2020年には需給ギャップが広がり人材の不足は (ア) に及ぶと言われている。
こうした人材不足を解消するべく、様々な方法でAIに理解のある人材育成が試みられている。そのような試みの一つとして、MOOCs は期待を寄せられている。著名な例としては、AI研究の第一人者で、2014年から2017年にかけて Baidu の AI 研究所所長を務めた (イ) が創業した Coursera などは入門から上級まで様々なレベルの AI 講義が開かれており、多くの受講者を惹きつけるに至っている。
問176
以下の文章をよく読み、末尾の設問に答えよ。
自動運転の実現に向けては、現行の法の枠組の中では公道での実験の可否や、事故が起きた際の責任の所在などの点で捉えづらい面が県zないかしており、こうした点の解釈のすり合わせや、新たな法の策定などが求められている。
以下の自動運転走行許可の各国・各地域のスタンスに関する説明文として正しいものを選択肢から一つ選べ。
問177
以下の文章をよく読み、末尾の設問に答えよ。
AIの活用が国の経済成長を牽引する柱の１つになるという共通認識から、先進国各国では国の経済成長戦略の一部にAIの研究開発戦略が盛り込まれるようになっている。
こうした各国とその国の経済成長戦略の組み合わせとして正しいものを１つ選べ。
問178
以下の文章をよく読み、下記の空欄 (ア) に最もよく当てはまる選択肢１つ選べ。
ディープラーニングでの学習を効率的に行うにあたって、共有データセットの整備が徐々に進められている。しかしながら、現在広く普及しているものには、いくつかの問題点が指摘されている。
第一は、 (ア) の問題である。現在は公正な利用がなされているとされているが、企業が共有データセットを利用して学習したモデルを自社のプロダクトに転用して売り上げを上げようとした場合に問題はないのかという議論が巻き起こっている。
他の問題として、これは日本にとっての問題であるが、多くのデータセットが (イ) であることが挙げられる。これにより、日本固有の食べ物を認識しようとすると、それが全く別の国の食べ物としてのみ認識されるという不具合が生じるに至っている。
問179
以下の文章をよく読み、下記の空欄 (イ) に最もよく当てはまる選択肢を１つ選べ。
ディープラーニングでの学習を効率的に行うにあたって、共有データセットの整備が徐々に進められている。しかしながら、現在広く普及しているものには、いくつかの問題点が指摘されている。
第一は、 (ア) の問題である。現在は公正な利用がなされているとされているが、企業が共有データセットを利用して学習したモデルを自社のプロダクトに転用して売り上げを上げようとした場合に問題はないのかという議論が巻き起こっている。
他の問題として、これは日本にとっての問題であるが、多くのデータセットが (イ) であることが挙げられる。これにより、日本固有の食べ物を認識しようとすると、それが全く別の国の食べ物としてのみ認識されるという不具合が生じるに至っている。
問180
以下の文章をよく読み、空欄 (ア) に当てはまる選択肢として最も適切なものを１つ選べ。
高度なAIモデルを作成していく為には、こうした共有のデータセットの拡充を進めると共に、学習モデルの共有を進め、こうした公開共有されたモデルを基にして独自のデータセットを適用して調整をしながら新たに学習をさせる (ア) が実用上鍵となるのではないかと言われている。
問181
下記の文章をよく読み、末尾の設問に答えよ。
ディープラーニングの利活用は各産業で進められているが、それが実際にディープラーニングによるブレイクスルーによってもたらされたものであるのかどうかの認識が曖昧な場合も少なくない。

選択肢のうち、ディープラーニングの産業への利活用事例として適切でないものを１つ選べ。
問182
下記の空欄 (ア) を埋めるものとして最も適切なものを述べよ。
全ての欠損値が完全に生じている場合には、様々な手法を使ってこれに対処することができる。１つは欠損があるサンプルをそのまま削除してしまう (ア) である。これは欠損に偏りがあった場合には、データ全体の傾向を大きく変えてしまうことになるので使用する際には欠損に特定の偏りがないかを確認して使用することが肝要である。
他の事例としては、欠損しているある特徴量と相関が強い他の特徴量が存在している場合は、(イ) という方法もある。
問183
下記の空欄 (イ) を埋めるものとして最も適切なものを述べよ。
全ての欠損値が完全に生じている場合には、様々な手法を使ってこれに対処することができる。１つは欠損があるサンプルをそのまま削除してしまう (ア) である。これは欠損に偏りがあった場合には、データ全体の傾向を大きく変えてしまうことになるので使用する際には欠損に特定の偏りがないかを確認して使用することが肝要である。
他の事例としては、欠損しているある特徴量と相関が強い他の特徴量が存在している場合は、(イ) という方法もある。
問184
下記の文章をよく読み、空欄 (ア) に最もよく当てはまる選択肢を以下から選べ。
機械学習による分析を行う際、カテゴリーデータをそのまま扱うのは非常に難しい。このため、これを数値に変換して扱いやすくすることが一般的である。
ドリンクのサイズS, M, Lなどの順序を持つ文字列のカテゴリーデータの場合、それぞれの値に対応する数値を辞書型データで用意し、これを数値に変化する方法 (ア) を利用して変換を行うことがある。
また順序を持たない名義特徴量のカテゴリーデータについては、各変数に対応したダミー変数を新たに作り出す (イ) が有用である。
問185
下記の文章をよく読み、空欄 (イ) に最もよく当てはまる選択肢を以下から選べ。
機械学習による分析を行う際、カテゴリーデータをそのまま扱うのは非常に難しい。このため、これを数値に変換して扱いやすくすることが一般的である。
ドリンクのサイズS, M, Lなどの順序を持つ文字列のカテゴリーデータの場合、それぞれの値に対応する数値を辞書型データで用意し、これを数値に変化する方法 (ア) を利用して変換を行うことがある。
また順序を持たない名義特徴量のカテゴリーデータについては、各変数に対応したダミー変数を新たに作り出す (イ) が有用である。
問186
（ア）に最もよくあてはまる選択肢を１つ選べ。
既存の学習済みニューラルネットワークモデルを活用する手法に（ア）と（イ）がある。（ア）では、学習済みモデルに対して新たに別の課題を学習させることで、少量のデータセットかつ少ない計算量で高い性能のモデルを得ることができる。また、（イ）は、学習済みの大規模モデルの入力と出力を小規模なモデルの教師データとして利用することで、少ない計算資源で従来のモデルと同程度の性能を実現することが可能となる。
問187
（イ）に最もよくあてはまる選択肢を１つ選べ。
既存の学習済みニューラルネットワークモデルを活用する手法に（ア）と（イ）がある。（ア）では、学習済みモデルに対して新たに別の課題を学習させることで、少量のデータセットかつ少ない計算量で高い性能のモデルを得ることができる。また、（イ）は、学習済みの大規模モデルの入力と出力を小規模なモデルの教師データとして利用することで、少ない計算資源で従来のモデルと同程度の性能を実現することが可能となる。
問188
（ア）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークの手法について扱う。
(ア)は1998年に提案された、現在広く使われているCNNの元となるモデルであり、初めて多層CNNに誤差逆伝播法を適用した手法である。2012年に提案された(イ)は、画像認識のコンペティションILSVRCで他手法に圧倒的な差をつけて優勝し、画像認識におけるディープラーニング活用の火付け役となった。しかし、一般にCNNは層を深くすると、パラメータ数が膨大となり学習が困難になってしまう傾向があった。層が深くなってもうまく学習を行うことができるモデルとして、ILSVRC2015において多くの部門でトップの成績を収めた（ウ）がある。（ウ）は出力を入力と入力からの差分の和で表現したニューラルネットワークモデルである。
問189
（イ）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークの手法について扱う。
(ア)は1998年に提案された、現在広く使われているCNNの元となるモデルであり、初めて多層CNNに誤差逆伝播法を適用した手法である。2012年に提案された(イ)は、画像認識のコンペティションILSVRCで他手法に圧倒的な差をつけて優勝し、画像認識におけるディープラーニング活用の火付け役となった。しかし、一般にCNNは層を深くすると、パラメータ数が膨大となり学習が困難になってしまう傾向があった。層が深くなってもうまく学習を行うことができるモデルとして、ILSVRC2015において多くの部門でトップの成績を収めた（ウ）がある。（ウ）は出力を入力と入力からの差分の和で表現したニューラルネットワークモデルである。
問190
（ウ）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークの手法について扱う。
(ア)は1998年に提案された、現在広く使われているCNNの元となるモデルであり、初めて多層CNNに誤差逆伝播法を適用した手法である。2012年に提案された(イ)は、画像認識のコンペティションILSVRCで他手法に圧倒的な差をつけて優勝し、画像認識におけるディープラーニング活用の火付け役となった。しかし、一般にCNNは層を深くすると、パラメータ数が膨大となり学習が困難になってしまう傾向があった。層が深くなってもうまく学習を行うことができるモデルとして、ILSVRC2015において多くの部門でトップの成績を収めた（ウ）がある。（ウ）は出力を入力と入力からの差分の和で表現したニューラルネットワークモデルである。
問191
（ア）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークで用いられる活性化関数について扱う。出力層の活性化関数には、回帰では（ア）が、多クラス分類では(イ)が一般的に利用されてきた。また中間層の活性化関数として、従来は（ウ）などが一般的に利用されてきた。しかし、これらの活性化関数を利用すると勾配消失問題が起きやすいという問題があったため、近年は、入力が0を超えていれば入力をそのまま出力に渡し、0未満であれば出力を0とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている。
問192
（イ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークで用いられる活性化関数について扱う。出力層の活性化関数には、回帰では（ア）が、多クラス分類では(イ)が一般的に利用されてきた。また中間層の活性化関数として、従来は（ウ）などが一般的に利用されてきた。しかし、これらの活性化関数を利用すると勾配消失問題が起きやすいという問題があったため、近年は、入力が0を超えていれば入力をそのまま出力に渡し、0未満であれば出力を0とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている。
問193
（ウ）に当てはまらない選択肢を１つ選べ。
ニューラルネットワークで用いられる活性化関数について扱う。出力層の活性化関数には、回帰では（ア）が、多クラス分類では(イ)が一般的に利用されてきた。また中間層の活性化関数として、従来は（ウ）などが一般的に利用されてきた。しかし、これらの活性化関数を利用すると勾配消失問題が起きやすいという問題があったため、近年は、入力が0を超えていれば入力をそのまま出力に渡し、0未満であれば出力を0とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている。
問194
（エ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークで用いられる活性化関数について扱う。出力層の活性化関数には、回帰では（ア）が、多クラス分類では(イ)が一般的に利用されてきた。また中間層の活性化関数として、従来は（ウ）などが一般的に利用されてきた。しかし、これらの活性化関数を利用すると勾配消失問題が起きやすいという問題があったため、近年は、入力が0を超えていれば入力をそのまま出力に渡し、0未満であれば出力を0とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている。
問195
（オ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークで用いられる活性化関数について扱う。出力層の活性化関数には、回帰では（ア）が、多クラス分類では(イ)が一般的に利用されてきた。また中間層の活性化関数として、従来は（ウ）などが一般的に利用されてきた。しかし、これらの活性化関数を利用すると勾配消失問題が起きやすいという問題があったため、近年は、入力が0を超えていれば入力をそのまま出力に渡し、0未満であれば出力を0とする（エ）や複数の線形関数の中での最大値を利用する（オ）などが利用されている。
問196
（ア）に最もよくあてはまる選択肢を１つ選べ。
正則化とは、機械学習の学習において汎化誤差をできるだけ小さくするための手法の総称である。ディープニューラルネットワークの学習で一般に用いられる正則化の手法に（ア）があり、誤差関数に重みのL2ノルムを加えることで重みの発散を抑えることができる。また、L2ノルムの代わりにL1ノルムを用いるL1正則化は、（イ）の一種であり、重要でないパラメータを0に近づけることができる。 L1正則化を回帰に利用した場合、（ウ）と呼ばれる。
問197
（イ）に最もよくあてはまる選択肢を１つ選べ。
正則化とは、機械学習の学習において汎化誤差をできるだけ小さくするための手法の総称である。ディープニューラルネットワークの学習で一般に用いられる正則化の手法に（ア）があり、誤差関数に重みのL2ノルムを加えることで重みの発散を抑えることができる。また、L2ノルムの代わりにL1ノルムを用いるL1正則化は、（イ）の一種であり、重要でないパラメータを0に近づけることができる。 L1正則化を回帰に利用した場合、（ウ）と呼ばれる。
問198
（ウ）に最もよくあてはまる選択肢を１つ選べ。
正則化とは、機械学習の学習において汎化誤差をできるだけ小さくするための手法の総称である。ディープニューラルネットワークの学習で一般に用いられる正則化の手法に（ア）があり、誤差関数に重みのL2ノルムを加えることで重みの発散を抑えることができる。また、L2ノルムの代わりにL1ノルムを用いるL1正則化は、（イ）の一種であり、重要でないパラメータを0に近づけることができる。 L1正則化を回帰に利用した場合、（ウ）と呼ばれる。
問199
（ア）に最もよくあてはまる選択肢を１つ選べ。
深層学習の実験に用いられるデータセットについて扱う。（ア）はアメリカの国立標準技術研究所によって提供されている手書き数字のデータベースである。また、スタンフォード大学がインターネット上から画像を集めて分類したデータセットである（イ）は、約1400万枚の自然画像を有しており、画像認識の様々なタスクに利用される。
問200
（イ）に最もよくあてはまる選択肢を１つ選べ。
深層学習の実験に用いられるデータセットについて扱う。（ア）はアメリカの国立標準技術研究所によって提供されている手書き数字のデータベースである。また、スタンフォード大学がインターネット上から画像を集めて分類したデータセットである（イ）は、約1400万枚の自然画像を有しており、画像認識の様々なタスクに利用される。
問201
（ア）に最もよくあてはまる選択肢を１つ選べ。
機械学習の手法は学習の枠組みに応じて主に3つに分類することができる。
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で、（イ）などが（ア）に含まれる。（ウ）は入力の集合だけから学習を行う手法であり、（エ）などが（ウ）に含まれる。最後に（オ）は、最終結果または連続した行動の結果に対して報酬を与え、報酬ができるだけ大きくなるような行動を探索する手法である。
問202
（イ）に当てはまらない選択肢を１つ選べ。
機械学習の手法は学習の枠組みに応じて主に3つに分類することができる。
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で、（イ）などが（ア）に含まれる。（ウ）は入力の集合だけから学習を行う手法であり、（エ）などが（ウ）に含まれる。最後に（オ）は、最終結果または連続した行動の結果に対して報酬を与え、報酬ができるだけ大きくなるような行動を探索する手法である。
問203
（ウ）に最もよくあてはまる選択肢を１つ選べ。
機械学習の手法は学習の枠組みに応じて主に3つに分類することができる。
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で、（イ）などが（ア）に含まれる。（ウ）は入力の集合だけから学習を行う手法であり、（エ）などが（ウ）に含まれる。最後に（オ）は、最終結果または連続した行動の結果に対して報酬を与え、報酬ができるだけ大きくなるような行動を探索する手法である。
問204
（エ）に当てはまらない選択肢を１つ選べ。
機械学習の手法は学習の枠組みに応じて主に3つに分類することができる。
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で、（イ）などが（ア）に含まれる。（ウ）は入力の集合だけから学習を行う手法であり、（エ）などが（ウ）に含まれる。最後に（オ）は、最終結果または連続した行動の結果に対して報酬を与え、報酬ができるだけ大きくなるような行動を探索する手法である。
問205
（オ）に最もよくあてはまる選択肢を１つ選べ。
機械学習の手法は学習の枠組みに応じて主に3つに分類することができる。
（ア）は入力とそれに対する出力のペアの集合を学習用データとする手法で、（イ）などが（ア）に含まれる。（ウ）は入力の集合だけから学習を行う手法であり、（エ）などが（ウ）に含まれる。最後に（オ）は、最終結果または連続した行動の結果に対して報酬を与え、報酬ができるだけ大きくなるような行動を探索する手法である。
問206
（ア）に最もよくあてはまる選択肢を１つ選べ。
機械学習の種類を大きく分類すると教師あり学習、教師なし学習、強化学習がある。ニューラルネットワークにもそれらに対応するものがある。例えば、教師あり学習には（ア）、教師なし学習には（イ）、強化学習には（ウ）などがある。
問207
（イ）に最もよくあてはまる選択肢を１つ選べ。
機械学習の種類を大きく分類すると教師あり学習、教師なし学習、強化学習がある。ニューラルネットワークにもそれらに対応するものがある。例えば、教師あり学習には（ア）、教師なし学習には（イ）、強化学習には（ウ）などがある。
問208
（ウ）に最もよくあてはまる選択肢を１つ選べ。
機械学習の種類を大きく分類すると教師あり学習、教師なし学習、強化学習がある。ニューラルネットワークにもそれらに対応するものがある。例えば、教師あり学習には（ア）、教師なし学習には（イ）、強化学習には（ウ）などがある。
問209
（ア）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークに特有の構造として、畳み込み層とプーリング層がある。これらは画像から特徴量を抽出するために用いられる。逆に特徴量（特徴マップ）から画像を生成する際には、それらと逆の操作を行う。代表的な構造として、畳込み層の逆操作である（ア）やプーリングの逆操作である（イ）がある。これらの構造を用いるタスクの例として（ウ）がある。
問210
（イ）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークに特有の構造として、畳み込み層とプーリング層がある。これらは画像から特徴量を抽出するために用いられる。逆に特徴量（特徴マップ）から画像を生成する際には、それらと逆の操作を行う。代表的な構造として、畳込み層の逆操作である（ア）やプーリングの逆操作である（イ）がある。これらの構造を用いるタスクの例として（ウ）がある。
問211
（ウ）に最もよくあてはまる選択肢を１つ選べ。
畳み込みニューラルネットワークに特有の構造として、畳み込み層とプーリング層がある。これらは画像から特徴量を抽出するために用いられる。逆に特徴量（特徴マップ）から画像を生成する際には、それらと逆の操作を行う。代表的な構造として、畳込み層の逆操作である（ア）やプーリングの逆操作である（イ）がある。これらの構造を用いるタスクの例として（ウ）がある。
問212
（ア）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークの学習は、損失関数（コスト関数）の最適化により行われる。そして、その損失関数は学習の目的に応じて決定する。よく使われる損失関数として、回帰問題には（ア）、分類問題には（イ）がある。また分布を直接学習する際には（ウ）が用いられることもある。さらに、損失関数にパラメータの二乗ノルムを加えると（エ）となる。
問213
（イ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークの学習は、損失関数（コスト関数）の最適化により行われる。そして、その損失関数は学習の目的に応じて決定する。よく使われる損失関数として、回帰問題には（ア）、分類問題には（イ）がある。また分布を直接学習する際には（ウ）が用いられることもある。さらに、損失関数にパラメータの二乗ノルムを加えると（エ）となる。
問214
（ウ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークの学習は、損失関数（コスト関数）の最適化により行われる。そして、その損失関数は学習の目的に応じて決定する。よく使われる損失関数として、回帰問題には（ア）、分類問題には（イ）がある。また分布を直接学習する際には（ウ）が用いられることもある。さらに、損失関数にパラメータの二乗ノルムを加えると（エ）となる。
問215
（エ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークの学習は、損失関数（コスト関数）の最適化により行われる。そして、その損失関数は学習の目的に応じて決定する。よく使われる損失関数として、回帰問題には（ア）、分類問題には（イ）がある。また分布を直接学習する際には（ウ）が用いられることもある。さらに、損失関数にパラメータの二乗ノルムを加えると（エ）となる。
問216
（ア）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークには様々なモデルがあり、タスクによって適切な選択をする必要がある。例えば、画像を扱う際には（ア）、自然言語処理などの系列データには（イ）がよく使われる。他にも次元削減には（ウ）、画像生成には（エ）などが用いられる。
問217
（イ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークには様々なモデルがあり、タスクによって適切な選択をする必要がある。例えば、画像を扱う際には（ア）、自然言語処理などの系列データには（イ）がよく使われる。他にも次元削減には（ウ）、画像生成には（エ）などが用いられる。
問218
（ウ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークには様々なモデルがあり、タスクによって適切な選択をする必要がある。例えば、画像を扱う際には（ア）、自然言語処理などの系列データには（イ）がよく使われる。他にも次元削減には（ウ）、画像生成には（エ）などが用いられる。
問219
（エ）に最もよくあてはまる選択肢を１つ選べ。
ニューラルネットワークには様々なモデルがあり、タスクによって適切な選択をする必要がある。例えば、画像を扱う際には（ア）、自然言語処理などの系列データには（イ）がよく使われる。他にも次元削減には（ウ）、画像生成には（エ）などが用いられる。
問220
ニューラルネットワークの学習には勾配降下法が用いられる。勾配降下法の手順を適切な順番に並べ替えたとき、１番目になるのはどれか。
A．重みとバイアスを初期化する。
B．誤差を減らすように重み（バイアス）を修正する。
C．最適な重みやバイアスになるなるまで繰り返す。
D．ネットワークの出力と正解ラベルとの誤差を計算する。
E．データ（ミニバッチ）をネットワークに入力し出力を得る。
問221
ニューラルネットワークの学習には勾配降下法が用いられる。勾配降下法の手順を適切な順番に並べ替えたとき、２番目になるのはどれか。
A．重みとバイアスを初期化する。
B．誤差を減らすように重み（バイアス）を修正する。
C．最適な重みやバイアスになるなるまで繰り返す。
D．ネットワークの出力と正解ラベルとの誤差を計算する。
E．データ（ミニバッチ）をネットワークに入力し出力を得る。
問222
ニューラルネットワークの学習には勾配降下法が用いられる。勾配降下法の手順を適切な順番に並べ替えたとき、３番目になるのはどれか。
A．重みとバイアスを初期化する。
B．誤差を減らすように重み（バイアス）を修正する。
C．最適な重みやバイアスになるなるまで繰り返す。
D．ネットワークの出力と正解ラベルとの誤差を計算する。
E．データ（ミニバッチ）をネットワークに入力し出力を得る。
問223
ニューラルネットワークの学習には勾配降下法が用いられる。勾配降下法の手順を適切な順番に並べ替えたとき、４番目になるのはどれか。
A．重みとバイアスを初期化する。
B．誤差を減らすように重み（バイアス）を修正する。
C．最適な重みやバイアスになるなるまで繰り返す。
D．ネットワークの出力と正解ラベルとの誤差を計算する。
E．データ（ミニバッチ）をネットワークに入力し出力を得る。
問224
ニューラルネットワークの学習には勾配降下法が用いられる。勾配降下法の手順を適切な順番に並べ替えたとき、５番目になるのはどれか。
A．重みとバイアスを初期化する。
B．誤差を減らすように重み（バイアス）を修正する。
C．最適な重みやバイアスになるなるまで繰り返す。
D．ネットワークの出力と正解ラベルとの誤差を計算する。
E．データ（ミニバッチ）をネットワークに入力し出力を得る。
問225
（ア）に最もよくあてはまる選択肢を１つ選べ。
画像認識のモデルとしてResNetがある。これは求めたい関数と入力との差である（ア）を学習するようにしたことで深いネットワークの学習を容易にした。