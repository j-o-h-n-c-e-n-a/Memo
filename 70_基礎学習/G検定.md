* [シラバス](https://www.jdla.org/business/certificate/?id=certificate_No03#)
* [Qitta](https://qiita.com/ea-yasuda/items/9831f11c189de43cb0be)
* [Study-ai](http://study-ai.com/generalist/)
* [深層学習教科書 ディープラーニング G検定（ジェネラリスト） 公式テキスト](https://www.shoeisha.co.jp/book/detail/9784798157559)
* [データ解析の実務プロセス入門](https://www.amazon.co.jp/データ解析の実務プロセス入門-あんちべ/dp/4627817711)

## 最新動向
### 技術関連
#### Google
#### Amazon
#### Facebook
#### 中国など
### 法律関連
#### 国内
#### 国外
* 事件

### 人工知能（AI）とは（人工知能の定義）
#### 人工知能をめぐる動向
* 歴史
	+ 第一次AIブームは1950年代に起こった。この頃に人工知能と呼ばれたプログラムは（ア）をもとに問題を解いていた。特に、1996年にIBMが開発した（イ）は、チェスの世界チャンピオンであるガルリ・カスパロフに勝利したことで有名である。しかし、ルールや設定が決まりきった迷路やパズルゲームなどの（ウ）と呼ばれる問題しか解けないという課題があったために、研究は下火になった。
	+ 第2次ブームは1980年代のエキスパートシステムと呼ばれるもの
		- シンボルグラウンディング問題
	+ 現在は、第3次ブーム。ビッグデータの活用から有用性が認められ、ブームとなった
* ILSVRC
	+ 現在は、kaggleに
* 探索・推論
* 知識表現
* 機械学習
* 深層学習
#### 人工知能分野の問題
* 人工知能の定義
	+ まだ定まってはいない
* 人工知能の動向
	+ レベル1：単純な制御プログラム
	+ レベル2：古典的な人工知能
		- 第1次：探索と推論
			* 探索木
			* プランニング(STRIPS、SHRDLU)
				+ ロボットの行動計画も探索機で表現できる
			* Mini-Max法
				+ 囲碁などのゲームプログラムを行うときに、コンピュータはよく自分が打つ手がスコアが最大になるように、また相手が指すときにスコアが最小となるような戦略を立てる。この戦略を何と呼ぶか？
			* トイプロブレム
		- 第2次：知識表現
			* 知識をたくさんインプットすればAIは賢くなるという考え
				+ 知識がありそうに見える方法
			* イライザ：コンピュータと人間がテキストデータでやり取りして、対話しているように見えるシステム
			* エキスパートシステム（マイシン）
			* 課題
				+ 専門家から知識を取り出すコストがかかる
				+ 知識の数が増えると知識に矛盾が発生することがあり、維持管理が大変
			* オントロジー
				+ ヘビーウェイト
					- 人間がきちんと考えて知識を記述していくためにどうしたらよいかを考える
				+ ライトウェイト
					- コンピュータにデータを読み込ませて自動で概念間の関係性を見つける
					- 例）IBM,ワトソン
				+ 専門家の知識を計算機のプログラムして移植していくというシステムのことをエキスパートシステムと呼ぶ。（A)は第【2】次人工知能ブームの終焉に伴い勢いは減速したが、1984年から引き続き研究され続けている【Cyc】というプロジェクトもあり、2001年に【OpenCyc】として一部が公開されている。
			* フレーム問題
			* シンボルクラウディング問題
	+ レベル3：機械学習
		- 検索エンジンとビッグデータのデータ分析 
		- 機械学習
	+ レベル4：ディープラーニング
		- 
* 強いAI
	+ 汎用人工知能
		- 人間の知能そのものを持つ
	+ AGI
* 弱いAI
	+ 特化型人工知能
		- 定めた領域の中で複雑な処理を人間以上の能力で行える
* トイプロブレム
	+ 明快なルールがあり，非常に限定された状況下での問題
	+ 現実的に解く必要のある問題に比べて比較的単純であり解きやすい
	+ ヒューリスティックな知識
	+ ブルートフォース
* 身体性
	+ 物理的な身体があることによって、環境との相互作用ができることにより、学習や知能の構築にもたらす効果や性質を指す。
* フレーム問題
	+ コンピュータでは、ある課題を実行するのに「関係ある知識だけを取り出して使う」という作業できないという問題
* シンボルグラウンディング問題
	+ コンピュータに与えたもの（文字列・言葉）がどのようにして実世界の意味と結びつけられるかという問題
	+ あいまいな質問の意味を理解できない
* モラベックのパラドックス
	+ 子供の人工知能
		- 深層強化学習により自らで学んでいく
	+ 動物にとっては簡単なこと（例：エサをとる、敵を認識する）が、機械にとっては難しく、複雑な方程式の計算は機械にとって優しい。この矛盾を何と呼ぶか？ 

### 機械学習の具体的手法
	学習には[時間が掛かり]、タスクの実行には時間が掛からない
	タスクに使用する情報（特徴量）は[人間が教える必要]がある
* 代表的な手法
	+ 教師あり
		- 入力データと出力データ（特徴量と正解）をセットで渡して学習させモデルを作成する
	+ 教師なし
		- 入力データを渡してデータの一定のパターンやルールを抽出する
		データの共通点を見つけてクラスタに分けたり、頻出パターンの抽出を行う
* データの扱い
* 応用
#### 特徴量設計
	どこに注目するべきかの特徴

* チューリングテスト
	+ アラン・チューリングが考案
		- 機械が知的（人工知能）かどうかを判定するテスト
	+ 【テスト方法】
		- 機会と人間との間で会話（人間側はディスプレイとキーボードで会話）させ、人間が機会か人間か確実に判断できなかった場合、合格となる
* シンギュラリティ
	+ 人間を追い越す、技術的特異点

### ディープラーニング
#### ディープラーニングの概要
	機械学習をする際の特徴量（変数）を自分で学習する

* ニューラルネットワークとディープラーニング
* 既存のニューラルネットワークにおける問題
* ディープラーニングのアプローチ
* CPU と GPU
* ディープラーニングにおけるデータ量

#### ディープラーニングの手法
* 活性化関数
	+ 入力信号の総和をどのように活性化させて出力するかを制御する関数
		- ステップ関数
			* 単純パーセプトロンで使用される
		- シグモイド関数
			* 多層ニューラルネットワークで使用される
			* 主に隠れ層で使用する
			* シグモイド関数の導関数の最大値は【0.25】
		- ソフトマックス関数
			* 多層ニューラルネットワークで使用される
			* 分類問題の場合出力層で使用する
			* 多クラス分類が可能になる
		- 恒等関数
			* 多層ニューラルネットワークで使用される
			* 出力層で使用する
			* 入力をそのまま出力する
		- ReLU
			* 0以下の場合は0
			* 0より大きい場合はそのまま出力する
* 損失関数
	+ ニューラルネットワークの出力と教師データの相違を算出する関数。学習を重ねることで損失関数を最小化していく
		- 二乗和誤差
			* 回帰問題で使用する
		- クロスエントロピー誤差
			* 分類問題で使用する
* 学習率の最適化
* 更なるテクニック
* CNN
	+ AlexNet
* RNN
	+ 内部に閉路、ループ構造を持つRNN（再帰ニューラルネットワーク）は、（B)データを扱うことができるが、遠い過去の入力を保持（記憶）し、現在の出力に影響を与えることが難しい。ネットワークの構造自体は変えずに、ユニット（ノード）を工夫することでこの問題を解決する方法を（C)といい、それを更にシンプルにし計算コストを抑えたものを（D)という。ただし、（D)が（C)の改良版ということではなく、（D)よりも（C)の方が表現力が高いという主張もある。
	+ RNNは（A)のことである。その特徴は内部に【閉路】、【ループ構造】を持つことで、入力データに加え、（C)を入力として与えることで、【系列】データを扱える仕組みとなっている。
* 深層強化学習
* 深層生成モデル
##### 回帰モデル
* 集合
##### 線形
* ベクトル
* 行列
##### ポアソン
##### 解析
* 解析関数
* テイラー展開
#### ベイズ統計モデル
#### GLMM

#### ディープラーニングの研究分野
* 画像認識
	+ ILSVRC
		- 2012: Alex Net, ジェフリーヒントン
		- 2014: VGG16, オックスフォード大学, GoogLeNet
		- 2015: 残差学習, Microsoft, ResNet
		- 2017: Squeeze and excitation
	+ SuperVision
* 自然言語処理
	「グラウンドされた意味構文解析」や「照応解析」、「談話構造解析」
	+ 機械翻訳で利用されるTransofomerやBERTなど、自然言語処理で今活躍しているものは（A)ベースのネットワークが用いられている。（A)の基本的な仕組みは、queryと（C)と【memory】である。queryは（C)により、取得する【memory】を決定し、対応する【value】を取得する。
	+ 自然言語処理において、形態素解析を基にして、その構文的（主語、述語など）の関係を明らかにする手法を【構文解析】と呼ぶ 
* 音声処理
* ロボティクス （強化学習）
* マルチモーダル

#### ディープラーニングの応用に向けて 
* 産業への応用
	+ 自動運転
* 法律
* 倫理
* 現行の議論
* 活用状況
	+ 実用化が進んでおり、実績も多数ある。 
	+ 画像認識や音声認識などの分野を中心に実用化が進んでいる。
	+ ガートナーはこれから【幻滅期】に入ると予測している。

##### 導入
1. 事例
• 経営管理
	○ 経営分析
• 営業
	○ 営業活動の成功失敗事例の抽出
• 社内業務
	○ ヘルプデスク代行
		§ チャットボット
	○ 労務管理手続き補助
	○ 定型業務の自動化
	○ 文章校正
		§ 手書き文字のデジタル化
	○ 翻訳・多言語化
• 品質管理
	○ 画像認識
	○ スペック判定
	○ 暗黙知のモデル化
	○ 社員教育補助
	○ クレーム対応
		§ 真のニーズ抽出

2. アンチパターン

### 用語集 
#### DARQ
	アクセンチュアが年次調査レポートで発表した【DARQ】とは、ブロックチェーン、人工知能、拡張・強化現実、量子コンピュータの4つのテクノロジーからとったものだ
#### 中国製造2025
	中国が掲げる産業政策で、2015年5月に発表され、次世代情報技術や新エネルギー車など10の重点分野と23の品目を設定し、製造業の高度化を目指す
#### seq2seq
	フリーテキストを入力とし、フリーテキストを出力するオートエンコーダデコーダを用いたモデル


# 1.人工知能
## 1-1. 人工知能とは？
### 1-1-1. 人工知能の定義
「人工知能 」とは、推論 、認識 、判断など 、人間と同じ知的な処理能力を持つ機械 （情報処理システム ）である。」・・・というのが大まかな定義。
但し、定義は人により様々みたいです。
試験としては、ジョン・マッカーシーの名前さえ覚えておけば、大丈夫。

#### 人名：ジョン・マッカーシー
「人工知能 （ A r t i f i c i a l I n t e l l i g e n c e ） 」という言葉は 、 1 9 5 6年にアメリカで開催されたダ ートマス会議において 、著名な人工知能研究者であるジョン ・マッカ ーシ ーが初めて使った言葉だそうです。

#### 名称：ダートマス会議
「人工知能 （ A r t i f i c i a l I n t e l l i g e n c e ） 」という言葉が初めて使われた会議。エニアックから10年後のことでした。

#### 人名：アーサー・サミュエル
機械学習の定義は、アーサー・サミュエルの「明示的にプログラムしなくても学習する能力をコンピューターに与える研究分野」が有名です。

### 1-2. 統計学
ここらへんも出るので、書いておきます。統計学とは、得られているデータから法則性や知見を数学的に得る分野であり、機械学習もある意味で統計学に含まれているといえます。記述統計と推計統計の2つに大別できます。「標本」や「母集団」（母集団と母数は異なる！）というキーワードも出てきます。

#### 用語：記述統計
手元のデータの分析を行うこと。

#### 用語：推計統計
手元のデータの背後にある母集団の性質を予測する。

* 統計には2種類ある。 【記述統計】は全データが対象で、【推計統計】は、元データからサンプリングしたデータから母集団の性質を推測する。

## 1-2. 人工知能の歴史
第1〜3次AIブームそれぞれの技術、具体的な取り組み、問題を抑えておきましょう。これらの歴史的経緯があって、現在の第3次AIブームがあるのですから。

### 1-2-1. 第1次AIブーム「推論・探索の時代」
1950年代後半〜1960年代、探索と推論 により問題を解く人工知能が台頭しました。但し、複雑に絡みあった現実の問題を解くには至らなかった。

#### 用語：検索と推論
あるルールとゴールが決められた枠組みの中で、なるべく早くゴールにたどり着く選択肢を選び続けること。

#### 用語：トイプロブレム
検索と推論で解ける問題はゲームの有利な手などトイプロブレム(おもちゃの問題)に限られることが第1次AIブームで明らかになり、ブームは終焉を迎えた。

#### 用語：ヒューリスティックな知識
「経験的な」知識という意味。ボードゲームの手などを効率的に探索するための「経験的な」知識。

#### 用語：ブルートフォース
「力任せ」の意味。

#### 用語：探索木
迷路をコンピューターの理解できる表現に直したもの。最短で階を得られるがメモリ使用量が多い幅優先探索と、最短で階を得られるとは限らないがメモリ使用量をセーブできる深さ優先探索がある。

#### 名称：STRIPS
プラニング（ロボットの行動計画）の技法。＜前提条件＞＜行動＞＜結果＞の3つの組み合わせで記述する。

#### 名称：SHRDLU
「積み木の世界」のプラニングを実現するテリー・ウィノグラードによって開発されたシステム。

#### 用語：Min-Max法
ゲーム戦略で、自分が指すときにスコアが最大化する手法。そのMin-Maz法の探索をできるだけ減らす手法はαβ法がある。

### 1-2-2. 第2次AIブーム「知識の時代」
1980年代には、エキスパートシステムにより問題を解く人工知能が台頭しました。しかし、専門家の知識の定式化は難しく、複雑な問題が解けるようにはならなかった。そして、第2次AIブームも終焉します。

#### 用語：エキスパートシステム
知識ベースと推論エンジンからなります。(私が作っている製品っぽいな、、、そうか、発想が古かったのか、、、と、自戒を込めて。)
* スタンフォード 大学 の エドワード・ファイゲンバウムが1960 年代 に 未知 の 有機化合物 を 特定 するエキスパートシステムを開発した。このシステムの名前は？ 【DENDRAL】

#### 知識ベース
「もし・・・ならば」という規則による知識の集まり

#### 推論エンジン
知識ベースを用いて推論を行うプログラムのこと。

#### 用語：オントロジー
知識を体系化する方法論。is-aとpart-ofという二つの関係性を覚えておきましょう。

#### 名称：Cyc（サイク）プロジェクト
全ての一般常識をコンピューターに取り込もうというプロジェクト。これは、ヘビーウェイトオントロジー（哲学的な考察が必要）の一つです。

#### 用語：ヘビーウェイトオントロジー と ライトウェイトオントロジー
Cycプロジェクトのように哲学的な考察が必要なのがヘビーウェイトオントロジーです。正確でなかったとしても、コンピューターで概念間の関係性を見つけようという取り組みがライトウェイトオントロジーとなります。ウェブマイニングや、データマイニングなどですね。

#### 名称：東ロボくん
読解力に難があり、なんらかのブレイクスルーが必要ということで、2016年に開発が凍結した。

### 1-2-3. 第3次AIブーム「機械学習と特徴表現学習の時代」
さて、2000年代以降の第3次AIブームです。発端はILSVRCという画像認識の精度を競うコンペディションでした。2012年のISLVRC2012にて、ジェフリー・ヒントン率いるトロント大学のSuperVisionチームがディープラーニングを用いて圧倒的な成績で優勝しました。これをきっかけとして、ディープラーニングが一気に脚光を浴びることとなり、現在の第3次AIブームにつながります。

#### 人名：ジェフリー・ヒントン
ディープラーニングを用いてILSVRCで2012年に優勝。

#### 名称：ILSVRC
ImageNet Large Scale Vosual Rocognition Comoetition

#### 名称：AlexNet
ILSVRC2012でジェフリー・ヒントンが用いた8層のディープニューラルネットワークで、畳み込みニューラルネットワーク(CNN)の一種。

#### 用語：特徴表現学習
機械学習自身に特徴量を発見させるアプローチのこと。

## 1-3. 人工知能にまつわる問題
試験対策としても、一般的な会話知識としても、押さえておく価値の高い内容ですね。いくつか書きます。

### 1-3-1. チューリングテスト
ある機械が人工知能かどうかを判定するためのテスト。人間の審査員に、相手がAIか否かを当ててもらうもの。

#### 人名：アラン・チューリング
1950年の論文でチューリングテストを発表した。

#### 名称：ELIZA(イライザ)
1966年に発表された自然言語処理プログラム。精神科セラピストの役割を演じリルプログラムで、かなりの判定者を惑わせたらしい。チューリングテストをめぐる大きなターニングポイント。ICCC,RFC439

#### 名称：PARRY(パリー)
イライザの後に開発され、これも多くの判定者を誤らせた。
１９７２年に偏執病的統合失調症患者をシミュレートする目的で作られたチャットボット

#### 名称：RFC439
イライザとパリーが会話した最初の記録はRFC439として残されている。

### 1-3–2. フレーム問題
どうやったって、AIは定められたフレーム内の問題しか取り扱えない。

#### 用語：強いAI（汎用AI）と弱いAI（特化型AI）
フレーム問題に捉われず人間のようにあらゆる問題に適切に対処できるAIを強いAI、フレーム問題に縛られたままのAIを弱いAIと呼びます。

#### 人名：ダニエル・デネット
「今しようとしていることに関係あることがらだけを選び出すことが、実は非常に難しい」

#### 用語：中国語の部屋
ジョン・サールが「強いAIは不可能だ」と証明するために用いた例え話。

### 1-3-3. シンギュラリティ
「人工知能が人間を超えて文明の主役に取って代わる」時点のこと。シンギュラリティ(技術的特異点)と呼ばれています。

#### 人名：レイ・カーワルツ
「シンギュラリティは2045年に到達する」

#### 人名：ヒューゴ・デ・ガリス
「シンギュラリティは21世紀後半に来る」
「そのとき、人工知能は人間の知能の1兆の1兆倍になる」

#### 人名：イーロン・マスク
シンギュラリティ到来に危機感を持ち、非営利の研究組織OpenAIを設立。テスラやスペースXの人ですね。

#### 人名：オレン・エツィオー二
「100万年後にシンギュラリティが来るかもしれないけど、そんな終末思想は馬鹿げてる」といった趣旨のことを言った人。

#### 人名：スティーブン・ホーキング
「AIの完成は人類の終焉を意味するかもしれない」

さて、最後に補足ですが有名なレイ・カーワルツさんは、AIが人間を超える程度だったら2029に訪れるといっているようです。でもそれはシンギュラリティじゃないですね。AI自身がAIを作り出すところをシンギュラリティ、すなわち特異点と捉え、それが2045年だといっているようですね。

### 1-3-4. シンボルグラウンディング問題(記号設置問題)
記号 （シンボル ）とその対象がいかにして結び付くかという問題です 。フレ ーム問題。コンピュ ータは 「記号 （文字 ） 」の意味が分かっていないので 、記号が意味するものと結び付けることができない。

### 1-3-5. 身体性
知能が成立するためには身体が不可欠であるという考え方。「外界と相互作用できる身体がないと 、概念はとらえきれない 」と考える。

### 1-3-6. AI効果
人工知能の原理が分かってしまうと、「それはAIではない」と思われてしまう人間心理。

### 1-3-7. LAWS
自律型致死兵器（LAWS）とは、AIなどにより完全に自律して、かつ強力な殺傷能力を持つ兵器のことです。まだ現段階では存在していませんが、議論は続いています。

#### 用語：アシロマAI原則
「AIによる軍拡競争は避けるべきである」

# 2. 機械学習

## 2-1. 機械学習の3種類
人工知能のプログラム自身が学習する仕組みで、データに潜むパターンを学習します 。それでは、教師あり学習、教師なし学習、強化学習の3種類を押さえましょう！

### 2-1-2. 教師あり機械学習
教師データを使って予測値を正解ラベルに近づけることを目標に学習を行う手法です。データ間の関係性が分かります。つきつめていくと、やることは「分類」と「回帰」の2つに収束します。いや、この2つだって、上手く分類できる線を引くか、上手くフィッティングできる線を引くか、といった違いでしかないので、つきつめていくと同じです。！

#### 用語：回帰(regression)
出力値の予測。代表的なものは線形回帰。線形回帰には単回帰分析と重回帰分析がある。深層学習でも回帰を行うことがある。

#### 用語：分類(classification)
サポートベクターマシン、決定木、ランダムフォレスト、ロジスティック回帰、kNN法などの手法がある。深層学習でも分類を行うことができる。

### 2-1-2. 教師なし機械学習
教師データを使わずに、データの本質的な構造を浮かび上がらせる手法です。代表的な手法はクラスタリングと次元削減です。

* 機械学習の中で、入力データのみからデータの本質的な特徴をあぶり出すために行われる学習のことをなんと呼ぶか？ 

#### 用語：クラスタリング
例えばk-means法などで与えられたデータ群をいくつかのあつまり(クラスタ)に分けることで、データの本質的な構造を浮かび上がらせる手法。クラス分類とは異なるものなので、注意。

* K-means法はデータの本質的な特徴をあぶり出すために有効な（A)という手法の一つです。（A)の手法には他に、【x-means】や【Ward法】などがある。

#### 用語：次元削減
データの情報を失わないように、データを低い次元に圧縮する手法の総称。例えば、身長と体重から肥満度を表すBMIを計算する手法がイメージしやすいですね。主成分分析が、よく用いられる手法です。

* 主成分分析とオートエンコーダの共通点は、どちらも【次元圧縮】、【教師なし学習】ができることである。

* 機械学習の手法の中で、分散が最大になる方向に新しい軸を定義しその軸にデータをマッピングしていくことで次元圧縮を実現する手法をなんと呼ぶか？【PCA】

#### 2-1-3. 強化学習
収益(報酬の和)を最大化する方策を獲得することを目的とした手法です。以下の用語を覚えておきましょう

エージェント=ある環境で動くプレイヤー
状態=エージェントが置かれている環境
行動=エージェントがとる行動
収益=エージェントが行動することで得られる評価値
価値関数=将来的に得られる収益の期待値を表す関数。
方策=ある状態のとき、どの行動をとるべきかを示す関数。(決定的に決めるものと確率的に決めるものがある。)というか、方策は関数なのね。
Deep-Q-Network (DQN) =価値関数を計算するディープニューラルネットワーク。ディープマインド社が作った。これを使うものは深層強化学習と呼ぶ。

* 2015年10月にこれまで人工知能には不可能だと言われていた、囲碁のプロ棋士を【google】社傘下の(B)社が開発した（C)というシステムが破った。この（C)には【DQN】というディープニューラルネットワークを用いた強化学習の手法が用いられた。

### 2-1-4. その他の機械学習
半教師学習という、教師あり学習におけるラベル付けのコストを低減するために用いられる手法もあるそうです。

## 2-2. 機械学習のプロセス
基礎集計 → 前処理 → 特徴量エンジニアリング → 計算(ここは割愛) → 性能評価のプロセスを、それぞれ見ていきましょう。

* 機械学習の前に、事前にデータの傾向や特徴を捉えるために散布図を確認したり、相関係数を計算することを何と呼ぶか？ 【】

### 2-2-1. 基礎集計
データの動向を事前に把握します。
各種代表値(平均や分散)を見たり、散布図行列をプロットしたり、相関行列を表示して傾向を見たりします。

### 2-2-2. 前処理
データをモデルに正しく入力できる形にします。

#### 用語：正規化
データをスケーリングする。

#### 用語：標準化
例えば、平均を0、分散を1に変換します。

#### 用語：名寄せ
表記の揺れなどの統一だそうです。

引っかけ問題で出題されやすい「正則化」は過学習を抑制するための手法であって、前処理の用語ではありません。

### 2-2-3. 特徴量エンジニアリング
モデルが認識しやすい特徴をデータから作ること。文字列の日付データを数値列に変換したり、多項式特徴量を生成したりすることなのだそうな。カテゴリカル変数(何かの種類を表す変)をカテゴリカル変数であるとわかるようにすることも、特徴量エンジニアリングです。

#### 用語：特徴量
扱っているデータをよく表す特徴を数値で示したもの。

#### 用語：one-hot-encoding
たった一つの成分だけが1、残りの成分が0という形の特徴量(ベクトル)に変換すること。
重回帰分析でやる多重共線性の検出も、このプロセスでやりますが、これについては後述。

* 単語をベクトルで表現することを何表現と呼ぶか？【分散表現】


### 2-2-4. 性能評価
データは、訓練データとテストデータに分けます。テストデータを使ってモデルの性能評価をするわけです。モデルが過学習を起こしていないかを調べましょう。

#### 用語：過学習(オーバーフィッティング)
学習に用いたデータに対しては高い精度で予測できるのに、学習に用いていないデータでは精度が上がらない事象のこと。機械学習における最大の問題と呼ばれています。

、、、さて、少し思うところがあるのですが、、、過学習って、学習データが多過ぎて学習しすぎて精度が下がる事象のことをいうと思っていたのですが、少しニュアンスが違うのですね！勘違いしていました、、、

モデルの性能評価に用いる手法にはホールドアウト法と交差検証法の2種類があります。

#### 用語：ホールドアウト法
#### 用語：交差検証法(クロスバリデーション法)
k分割交差検証という書き方になっていることもありますが同じものです。計算量は大きくなりますが、データが少なくてもホールドアウト法と比較して信頼できる精度が得られます。

* モデルが過学習をしていないかを確認するために行う検証の方法として、データを複数の方法で学習データとテストデータに分割し、その平均を用いて検証を行う方法をなんと呼ぶか？

* 学習済みのモデルが、学習に使ったデータに対してはよく予測できるが、未知のデータにうまく適用できないことを何と呼ぶか？ 

* 過学習を防ぐ正則化について、【Lasso】のように、自動的に「特徴選択」が行われるため、【スパース】正則化と捉えることができる。【Ridge】は、パラメータのノルムを小さくおさえることができるという性質がある。【Lasso】と【スパース】を組み合わせたものを【】という。

#### 用語：正解率
混合行列をもとに、次の数式で正解率(accuracy)を求めます。
正解率 ＝（TP+TN）／（TP+TN+FP+FN）

正解率だけでなく、適合率、再現率、F値という数値を用いて評価することもあります。覚えておきましょう。というのも、陰陽のデータが半々なら問題はないのですが、半々じゃない場合は、考えた方がよいそうです。

##### 適合率
TP／（TP＋FP）
予測が正の中で、正だと予測できたもの。試験では、「予測が」という言葉から始まっていたら適合率のことです。

##### 再現率
TP／（TP＋FN）
実際に正であるものの中で、正だと予測出来た者の割合。試験では、「実際に」という言葉から始まっていたら適合率のことです。

##### F値
適合率と再現率の調和平均。適合率だけでも再現率だけでも予測が偏ってしまうことがあるために、こういう値を使うこともあります。

#### 用語：正則化
学習に用いる式に項を追加することによって、とりうる重みの範囲を制限して、過度に重みが訓練データに対してのみ調整されてしまうことを防ぐ手法です。ただし、やりすぎると、アンダーフィッティングを起こしてしまいます。

##### L1正則化
一部のパラメーターをゼロにすることで、特徴選択をおこなうことができる。これを線形回帰に適用した手法をラッソ回帰と呼ぶ。

##### L2正則化
パラメーターの大きさに応じてゼロに近づけることで汎化された滑らかなモデルを得ることができる。これを線形回帰に適用した手法をリッジ回帰と呼ぶ。そして、ラッソ回帰とリッジ回帰の両方を組み合わせた手法をElastic Netと呼びます。

* 過学習を防ぐ正則化について、（A）のように、自動的に「特徴選択」が行われるため、（B)正則化と捉えることができる。（C)は、パラメータのノルムを小さくおさえることができるという性質がある。（A)と（B）を組み合わせたものをElastic Netという。

## 2-3. 機械学習の具体的な手法
さて、ここまでがディープラーニング検定の前半です。

### 2-3-1. 線形回帰
回帰の代表的な手法です。

#### 用語：単回帰分析
1つの説明変数(例：その日の気温)から目的変数(例：その日の飲み物の売上)を予測する。

#### 用語：重回帰分析
複数の説明変数から目的変数を予測する。
重回帰分析をやる際には、多重共線性に注意しなくてはならない。

#### 用語：多重共線性
マルチコ(multicollinearity)とも呼ばれる。
相関係数が高い(1か-1に近い)特徴量の組みを同時に説明変数に選ぶと、予測が上手くいかなくなる事象のこと。

### 2-3-2. ロジスティック回帰
線形回帰の「回帰」ではなく「分類」版という説明が教科書に書かれていた。
線形回帰を分類問題に応用するためのアルゴリズムで、シグモイド関数を使います。
2種類の分類ではなく多クラスの分類となる場合は、ソフトマックス関数を使います。
ちなみに、ロジスティック回帰は、ニューラルネットワークの一種と考えることもできる。
対数オッズを線形回帰により予測し、出力の正規化によって予測結果を確率として解釈します。
目的関数としては尤度関数を使います。

### 2-3-3. kNN法
分類の一手法。未知のデータの近くからk個のデータを調べて多数決によって所属クラスを決定するアルゴリズム。欠点としては、クラスのサンプル数の偏りに弱い。ちなみに、kの値はエンジニアが事前に設定しておくパラメーターであり、こういったパラメーターはハイパーパラメーターと呼ばれます。

* ディープラーニニングする際に、ニューロン数や何層にするか、学習率はどの程度にするか等事前に決めておくことは、多数ある。これらのパラメータのことを何と呼ぶか？【ハイパーパラメータ】

### 2-3-4. 決定木
条件分岐を繰り返すことにより分類や回帰を行うためのアルゴリズム。情報利得の最大化を実現するように決定する。データのスケールを事前にそろえておく必要がなく、分析の説明が容易というメリットがあります。

* ジニ係数やエントロピーという不純度によって、データを分割するための分岐する[木構造]を作っていく機械学習の手法は何というか？ 【決定木】

### 2-3-5. ランダムフォレスト
決定木を用いる手法。特徴量をランダムに選び出して、ランダムに複数の決定木を作り出し、それぞれの決定木の結果を用いて多数決を採る手法。

#### 用語：ブーストストラップサンプリング
全てのデータをつかうのではなく、それぞれの決定木に対して一部のデータを取り出して学習させる。

#### 用語：アンサンブル学習
ランダムフォレストのように複数のモデルで学習させる手法のこと。

#### 用語：バギング
全体から一部のデータを用いて複数のモデルを用いて学習する手法。ランダムフォレストは、バギングの中でも決定木を用いる手法という位置づけです。

* 決定木を応用した【バギング】は複数モデルを並列に学習させ多数決をとる、(B)は直列（順番）に学習し前の分類器の弱点を克服するという違いがある。

### 2-3-6. ブースティング
バギングと同様に一部のデータを繰り返し抽出して複数のモデルを学習する手法です。バギングとの違いですが、複数のモデルを一気に並列作成する（バギング）か、逐次的に作成する（ブースティング）か、というところです。ブースティングもモデル部分には決定木が用いられており、AbaBoostや勾配ブースティングやXgBoostなんかが有名だそうな。ランダムフォレストと勾配ブースティングを比べた時、並列的なランダムフォレストの方が計算は速いが、精度は勾配ブースティングの方が良いといわれています。

### 2-3-7. 次元削減
データに複数ある変数のうち、分析に不要なものを削除します。寄与率を調べれば各成分の重要度が分かり、主成分を調べれば各成分の意味を推測することができます。

#### 用語：次元の呪い
機械学習において次元が増えると計算量や学習に必要なサンプル数が爆発的に増えて様々な不都合が生じるという法則。

### 2-3-8. サポートベクターマシン
もともとは2クラス分類のアルゴリズムです。「マージンの最大化」というコンセプトのもと、2つのクラスを線形分離します。ディープラーニング以前に「人気」ではあったが、汎化性能が高い手法であったわけではない(そのような汎化性能の差に明確な結論は出ていない)という引っ掛け問題が出ます。

#### 用語：カーネル法
SVMは、線形分離可能でないデータ(直線でないデータに対してもカーネル法を組み合わせることで決定境界を求めることができます。
データをあえて高次元空間に写像するための関数をカーネル関数、その計算をカーネルトリックといいます。

* マージンの最大化を行うことにより、分離境界平面（ハイパープレーン）を得て分類を行う教師あり学習の手法を次から選べ。 【SVM】

* 機械学習の２値分類問題における性能指標について、サンプル全体のうち予測が正解したものの割合のことをなんと呼びますか？【正解率】

* 機械学習の手法の中で、マージンを最大化するような分離超平面を得る手法のことをなんと呼ぶか【】

### 2-3-9. ニューラルネットワーク
以降に、ディープラーニングが控えているので、触りだけ書きます。

#### 用語：単純パーセプトロン
線形分離可能な(直線を使って分離できる)問題であれば、解けます。（分類問題など）ステップ関数を使います。単純パーセプトロンの限界は、多層にしてバックプロパゲーション（誤差逆伝搬学習法）を用いて学習すれば克服できることが示された。

* 単純パーセプトロンで用いられる誤差関数を答えよ【ヒンジ損失関数】
* 単純パーセプトロンに用いられる活性化関数は何か　【ステップ関数】
* 単純パーセプトロンで解くことができる問題のことを、【線形分離可能問題】といい、解くことができない問題と呼ぶ。

#### 用語：多層パーセプトロン
非線形分離も可能です。これの層が深くなったやつがディープラーニングです。やっと、ディープラーニングに近づいてきましたね。

#### 用語：バイアス


# 3. ディープラーニング
## 3-1. なぜ、今、ディープラーニング？
多層パーセプトロンの隠れ層を増やせば、より複雑な問題を解くことができる、、、というアイデアは、昔からあったそうです。
ですが、ディープニューラルネットワークが現実的につかえるようになったのは最近のこと。その背景には、いくつかのブレイクスルーがありました。よくいわれるのは、クラウド上の膨大なマシンスペックと、インターネット上の膨大なビッグデータがブレークスルーを引き起こしたということなのですが、、、実際にそれだけなのでしょうか。一つひとつ見ていきましょう！

### 3-1-1. 事前学習
さて、なかなかディープラーニングが実現しなかった理由の一つ目は、勾配消失問題です。これにたいしてブレイクスルーをもたらした手法が事前学習でした。ただし、事前学習は計算コストが非常に高くつくことから、最近では事前学習無しのアプローチとして、活性化関数を工夫する手法が主流になっているようです。それはさておき、ジェフリー・ヒントンが画像解析でブレイクスルーをもたらすに至ったアイデアですから、一つひとつの用語を抑えていきましょう。

#### 用語：勾配消失問題
ニューラルネットワークの隠れ層を深くしていくと、隠れ層を遡るごとに伝搬していく誤差が小さくなっていくことにより、勾配がなくなってしまうという事象。活性化関数であるシグモイド関数の微分値が最大でも0.25にしかならないため、掛け算していくと値がどんどん小さくなっていってしまうようです。

#### 用語：オートエンコーダ（自己符号化機）
ジェフリー・ヒントンが提唱した勾配消失問題の解決策です。可視層と隠れ層の2層からなるネットワークです。エンコーダとデコーダからなる。入力層と出力層の数はおなじだが、中間層のノード数はそれより少ない。「正解ラベル」として入力自身を用いることで、次元削減ができます。これだけだと、ディープニューラルネットワークではありませんので、次も見てみましょう。

#### 用語：積層オートエンコーダー（ディープオートエンコーダー）
ディープニューラルネットワークの全ての層を一気に学習させるのではなく、入力層に近い層から順番に学習させるという、逐次的な方法です。順番に学習していくことによって、それぞれの隠れ層の重みが調整されます。このオートエンコーダーを順番に学習していく手順のことを、事前学習（pre-training）と呼びます。積層オートエンコーダは、事前学習と（後述の）ファインチューニングの工程で構成されています。

#### 用語：ファインチューニング
オートエンコーダーを積み重ねるだけでは、最後にラベルを出すことはできません。積層オートエンコーダーを積み重ねていった最後に、別の層を足します。足される層は、2値分類ならシグモイド関数のロジスティック回帰、他項分類ならソフトマックス関数のロジスティック回帰、回帰なら線形回帰の層となります。最後に足した層も重みの調整が必要になります。事前学習により調整されているので、最後の仕上げとしてネットワーク全体を学習させると、誤差が上手いこと伝播されるのだそうな。この最後の工程をファインチューニングと呼びます。

#### 名称：深層信念ネットワーク（deep belief networks）と制限付きボルツマンマシン
ジェフリー・ヒントンが提唱した手法の名前です。事前学習を用いたディープラーニングの手法として、覚えておきましょう。

### 3-1-2. GPU
もちろん、ハードウェア性能工場、特にGPU登場は、ディープラーニング実現に重要なブレイクスルーとなりました。ムーアの法則に沿って、半導体の性能と集積は18か月おきに2倍になっているようですね。

#### 用語：GPGPU
CPUと異なり、様々なタスクをこなすのは不得意です。同じような並列計算処理が大規模に行われる場合に、パワーを発揮します。画像目的以外の仕様に最適化されたGPUのことをGPGPUと呼びます。GPGPUの開発をリードしたNVDIA社の名前は、頻出っぽいです。あと、Google社のテンソル計算処理に最適化された演算装置は、TPUと呼ばれているそうです。

### 3-1-3. データ量
ディープラーニングを実現するためには、データも大量に必要です。ですが、そんなの今さら当然ですよね。バーニーおじさんだけおぼえておきましょう。

#### 用語：バーニーおじさんのルール
「モデルのパラメーター数の10倍のデータが必要」という経験則です。とはいえ、これは明確な指標でも何でもない。バーニーおじさんって、だれなのか？については、次の記事を参照のこと。この検定を勉強している人は、誰でも気になりますよね。そういうネタなのかな。うーむ。
http://ikesala.com/g3/#i-9

### 3-1-3. 画損認識コンペでの成果

### 3-1-4. 深層学習ライブラリのOSS
#### TensorFlow
#### Keras
#### Chainer

## 3-2. ディープラーニングの理論
### 3-2-1. 活性化関数
活性化関数にシグモイド関数を利用したとき問題となったのが、勾配消失問題でした。さて、いくつかの関数が提案されています。どれが良くてどれが悪いというのはありません。

#### 用語：tanh関数（ハイパボリックタンジェント）
微分の最大値は1になります。

#### 用語：ReLU関数
xがゼロ以下のときは、微分値もゼロになってしまう。

#### 用語：Leakly ReLU関数
xがゼロ以下でもわずかな傾きを持っている。他にも、Parametric ReLUやRandomize ReLUなど、いろいろあります。

### 3-2-2. 勾配降下法
勾配に沿って降りていくことで階を探索する手法です。最適値を探すために使います。

#### 用語：エポック
訓練データを何度学習に用いたか。

#### 用語：イテレーション
重みを何度更新したか。

#### 用語：逐次学習・ミニバッチ学習・バッチ学習
重みの更新タイミングのことです。バッチ学習ではエポックとイテレーションが同じになりますが、それ以外では異なります。ミニバッチでランダムにデータをピックアップして重みを更新する際の勾配降下法を、確率的勾配降下法（ミニバッチ学習：SGD）と呼びます。

* SGDの進化
	+ Adagrad：稀なパラメータには大きな更新
	+ Adadelta
	+ Momentum：慣性項
	+ RMSprop
	+ Adam: こう配の２乗の指数関数的減衰平均、移動平均

#### 用語：学習率
勾配に沿って、一度にどれだけ降りていくか、を決めるハイパーパラメーター（計算時に指定する変数）のこと。

#### 用語：局所最適解 と 大域最適解
見せかけの最適解を局所最適解、本当の最適解を大域最適解と呼びます。最初は学習率を大きく設定して、適切なタイミングで学習率の値を小さくしていく工夫が必要になります。

#### 用語：停留点
局所最適解でも大域最適解でもないのに勾配がゼロになる点のこと。例えば、山頂ですね。

#### 用語：鞍点
停留点のなかでも、ある次元では最小だが別の次元では最大になってしまうもののこと。
ディープラーニングでは次元が大きいので、鞍点にはまるって抜け出せなくなることがあります。そのような停留状態をプラトーといいます。抜け出る手法として、昔からモーメンタムがありますが、最近はAdamやRMSpropがあるそうな。

### 3-2-3. その他のテクニック
#### 用語：ドロップアウト
オーバーフィッティングを解消する手法で、エポック毎にランダムにニューロンをドロップアウトさせて計算します。毎回モデルが変わることになるため、これはアンサンブル学習の一種です。

#### 用語：early stopping
過学習する前に、早めに学習を打ち切る方法です。シンプルで、どんなモデルにも適用できる手法です。ジェフリー・ヒントンは、”Beautiful FREE Lunch”と表現しているそうですが、、、この元ネタのノーフリーランチ定理は後述。

#### 用語：ノーフリーランチ定理
「あらゆる問題で性能の良い汎用最適化戦略は理論上不可能」という定理。

#### 用語：醜いアヒルの子の定理

#### 用語：正規化
データ全体の調整。いろいろ種類はあるのですが、例えば、各特徴量を0～1の範囲に変換する処理です。

#### 用語：標準化
各特徴量の平均を0、分散を1にする、、、すなわち、各特徴量を正規分布に従うように変換することです。各特徴量の分散をそろえておくことで、それぞれの特徴量の動きに対する感度を揃えられます。

#### 用語：白色化
標準化より一歩踏み込んだ手法で、各特徴量を無相関化した上で、標準化します。

#### 用語：Xavierの初期値、Heの初期値
重みの初期値も、ディープラーニングの工夫しどころの一つです。単純にダンラブにするのではなく、乱数にネットワークの大きさに合わせた適当な係数をかけることで、データの分布が崩れにくい初期値が得られるのだそうな。シグモイド関数に対してはXavierの初期値、ReLU関数に対してはHeの初期値がよいとされているようです。

#### 用語：バッチ正規化
ディープラーニングの各層において、活性化関数を書ける前に伝播してきたデータを正規化する手法です。これで、オーバーフィッティングしづらくなることが知られています。


## 3-3. ディープラーニングの具体的な手法
### 3-3-1. CNN（畳み込みニューラルネットワーク）
画像をそのまま2次元ので入力に用いられるモデルです。あのAlexNetもCNNですよ。ちなみに、ひっかけ問題で画像以外でもCNNは使えるか？というものが出てきます。音声認識ではCNNが良いという話もあるそうで、まぁ、使っても問題はないのですがという引っかけです。

* 畳み込みニューラルネットワークは【画像認識】のために作られたが、【自然言語処理】や【音声認識】にも応用されることがある。

* 畳み込みニューラルネットワーク(CNN)は時系列データを扱うのが苦手であるため、RNNのように音声認識や自然言語処理に使われることはまずない。これは正しい認識か？ 【誤り】

#### 用語：ネオコグニトロン
福島邦彦さんによって考えられた初期のモデルです。人間のもつ視覚野の神経細胞の2つの働きをもしてみようという試みです。

#### 用語：LeNet
その後、ヤン・ルカンによって作られたCNNのモデルです。こちらは誤差逆伝播法を使います。畳み込み層とプーリング層の2種類が交互に複数組み合わさります。

#### 用語：CNN
畳み込み層とプーリング層を積み重ねる順伝播型（逆伝播ではない）のディープニューラルネットワークです。

#### 用語：FFN
順伝播型（全結合型）のディープニューラルネットワークです。
このネットワークで画像認識を行おうとすると、積和演算では、隣り合うピクセル同士の関連をうまくとらえることができない。

#### 用語：畳み込み（Convolution）
カーネルとも呼ばれるフィルタを用いて画像から特徴を抽出する操作のことです。フィルタを画像の左上から順番に重ね合わせていき、画像とフィルタの値をそれぞれかけあわせたものの挿話をとった値を求めていく処理です。畳み込みによって新たに得られた二次元データを特徴マップと呼びます。CNNでは、各フィルタをどのような値にすれば良いかを学習していくとになります。つまり、このフィルタが、ニューラルネットワークでいうところの重みになります。この畳み込みの処理は、人間の視覚やが持つ局所受容野に対応していて、移動普遍性の獲得に貢献します。（但し、回転普遍性は持っていない。）「位置のズレ」に強いモデルができます。大きな畳み込みを1層とするよりも、小さな畳み込みを多層で積み重ねるのが、最近の流行りです。

#### 用語：プーリング
決められた演算を行うだけで、ダウンサンプリングやサブサンプリングともよばれいます。
たとえば、Maxプーリングと呼ばれる処理では、画像の特徴マップの最大値を抽出していきます。
avg（平均）プーリングという手法もあります。計算するだけなので、学習すべきパラメーターはありません。

#### 用語：全結合層
最後は、イヌやネコといった一次元の出力になりますので、そういった層が必要です。但し、最近のCNNでは、全結合層を用いないケースも大きいです。全結合層の代わりに、1つの特徴マップに1つのクラスを対応させることで分類を行うGlobal Average Poolongと呼ばれる処理を行うことが多いみたいです。

#### 用語：データ拡張（data augmentation）
上下左右にずらしたり反転させたりする、データの「水増し」のこと。いまや、画像認識を行う上では必須の処理なのだそうな。

さて、CNNは発展形として、AlexNet以降にもVGCやGoogleLeNetが出てきて記録を更新しています。Google LeNetでは、Inceptionモジュールというブロックを構成し、それを積み重ねたネットワークとすることで並列計算を行いやすくしました。超深層ネットワークとなる場合には、さらなる工夫が必要で、Skip Connectionとよばれる層を超えた結合を加える工夫もあります。この結合が導入されたネットワークをResNetと呼びます。

#### 用語：転移学習
一から、こんなモデルを作るの、不可能ですよね。そこで、学習済のネットワークを利用して新しいタスクの識別に活用することを転移学習と呼んでいます。これで、世の中の皆様が、いろいろ画像認識で遊べるようになってきたわけなのですね。


### 3-3-2. RNN（リカレントニューラルネットワーク）
閉路を持つニューラルネットワークです。時間軸に対して何かのパターンを持っている場合の予測には、RNNを使います。通常のニューラルネットワークでは表現できない「過去の重み」を表現できます。RNNの基本形を見てみると、通常と異なり過去の隠れ層が追加されていることが分かります。逆伝播する誤差も過去にさかのぼって反映する必要があります。これは、BackPropagation Tough-Time(BPTT)と呼ばれています。

#### 用語：LSTM
RNNの一種です。勾配消失問題、入力重み衝突、出力重み衝突といった問題を解決した手法です。LSTM ブロック は、 セル（ CEC: Constant Error Carousel) と、 ゲート（ 入力 ゲート、 出力 ゲート、 忘却 ゲート） から 構成 さ れ ます。LSTMを簡略化して、計算量を少なくした【GRU】というモデルもあります。一応、どちらの手法が良い悪いというわけではありません。

### 3-3-3. 深層強化学習
用語：Deep-Q-Network
DeepMind社のDeep-Q-Network（DQN）が有名です。あの、Alpha Goも深層強化学習ですね。

### 3-3-4. 深層生成モデル
ディープラーニングは、認識・識別タスクだけでなく生成タスクにも応用され始めています。

#### 用語：VAE（変分オートエンコーダー）
変分オートエンコーダ（VAE)も生成モデルの一種で、自己符号化器（オートエンコーダ）にエンコーダとデコーダの間の潜在変数が正規分布であることを仮定し、そのパラメタである平均と分散を出力させ学習させます。
画像が生成できるらしい。
* オートエンコーダを応用した生成モデルで、画像を生成することができるのは次のうちどれか？ 

#### 用語：GAN（敵対的生成ネットワーク）
これはおもしろい手法だと思いました。偽物画像を作る学習をするジェネレータ(生成機)と、偽物をきちんと見抜けるようにする学習をするディスクリミネータ（識別機）という二つのネットワークで構成されています。二つが切磋琢磨して、最終的には本物と見分けがつかないような贋作ができるのだそうな。それぞれのネットワークにCNNを取り込んだものをDCGAN（Deep Convolutional GAN）といいます。イアン・グッドフェローが考案。
LeNetを発案した、ヤン・ルカンは「この10年で最もおもしろいアイデア」と絶賛しているそうだ。


# 4. 人工知能の応用
## 4-1. 研究分野
ディープラーニングが、どんどん発展しています！一つひとつがおもしろい！

### 4-1-1. 画像認識分野
一般画像認識へ至る研究動向を2つ紹介します。

#### 用語：R-CNN（Regional CNN）
イメージネット画像認識コンテストには、位置課題と検出課題という2つの課題があります。画像の中の「どこ」に「何」があるかを問う課題ですね。「どこ」の課題、すなわち関心領域（ROI：Region of Interest）の切り出しには、CNNではない手法を使います。領域の切り出しは、矩形領域（バンディングボックス：左上と右下の座標）を予測する回帰問題とみなせます。高速RCNN（fast RCNN）というモデルでは、領域の切り出しと切り出した領域の物体認識を同時に行うことが実現しました。さらに改良されたfaster RCNNでは、ほぼ実時間で入力画像からの関心領域の切り出しと認識ができるようになりました。YOLO（You Look Only Once）やSSD（Single Shot Detectorといった）といった発展形のモデルも登場しています。いずれも領域の切り出しと認識を同時に行うCNNです。

#### 用語：セマンティックセグメンテーションとインスタンスセグメンテーション
セマンティックセグメンテーションとは、RCNNのような矩形の領域を切り出すのではなく、より詳細な領域分割を得るモデルです。完全畳み込みネットワーク（FCN：Fully Convolutional Network）という、全ての層が畳み込みであるモデルを使います。FCNはセマンティックセグメンテーションに特化したモデルなので、それ単体では画像認識は行えません。個々の物体毎に認識させることは、インスタンスセグメンテーションと呼びます。

### 4-1-2. 言語処理分野
#### 用語：word2vec
「単語の意味は、その周辺の単語によって決まる」という言語学の主張をニューラルネットワークとして実現したもの。word2vecが、ベクトル空間モデルや単語埋め込みモデルとも呼ばれます。スキップグラムとCBOWという2つの手法があります。word2vecに触発されて、単語埋め込みモデルは爆発的に発展しました。

* ライブラリ：gensim, Magnitude

* 自然言語処理において、2013年にGoogle社より論文が公開された【word2vec】という技術は、単語の意味関係を（B)で表現することにより、辞書なしで関連度の高い単語を知ることができたり、「王」ー「男性」+「女性」＝「女王」というような意味的な計算が自動的にできるようになり、注目を集めた。　また、【2018】年に同社より提案された【BERT】という技術は（E)という【ディープラーニング】の手法を用いており、単語の一部を【マスキング】して学習させるという工夫により、一つの単語が複数の使われ方をするというような複雑な意味関係も表現でき【bidirectional transformer】により文章の文脈も学習しており、様々な、自然言語処理タスク（QA抽出、文書分類、品詞タグ付け等）で最高記録を樹立している。

#### 用語：fastText
word2vecの後継の一つ。トマス・ミコロフによって開発されたモデル。単語の表現に文字の情報を含めることで、訓練データに存在しない単語も表現できるようになった。また、学習に要する時間も短い。

#### 用語：GolVe
Word2Vecは、ニューラルネットワークの重みを学習させて予測を行うモデルであるのに対し、GloVeは、カウントベースのモデルとなります。

#### 用語：ELMO
word2vecの後継の、文章表現を得るモデルです。

#### 用語：BERT
GoogleAI から ２０１８ 年 １０月 １１ 日 に 衝撃的 な 論文 が Arxiv 公開 さ れ まし た。 この 論文 では、 双方向 Transformer で 言語 モデル を 事前 学習 する こと で、 汎用 性 を 獲得 し、 転移 学習 さ せる と、 ８つ の ベンチマーク タスク で SOTA( State of the Art: 現在 最も 優れ て いる 手法） を 達成 し た そう です。

#### 用語：ニューラル画像脚注付け（NIC：Neural Image Caption） 
CNNとRNNを組み合わせたもの。CNNの最終層の出力を使うのではなく、全結合層の直下、すなわち畳み込み層の最上位を層をRNNで構成される文章生成ネットワークの入力とします。

#### 用語：シーケンス2シーケンス（seq2seq）
自動翻訳技術で用いられます。

#### 用語：ニューラルチューリングマシン（NTM）
チューリングマシンをニューラルネットワークで実現する試み。

#### 用語：エルマンネット（エルマンのネットワーク）
RNNの一種で、文法解析をするモデルです。

#### 用語：形態素解析
	さて、自然言語処理は、次のようなフローで実行されるそうです。
(1) 形態素解析で文章を単語などの最小単位に切り分ける（分かち書き、Mecab） →
(2) データのクレンジングにより不要な文字列を取り除く → 
(3) BoW (Bug-of-words)などを用いてベクトル形式に変換する → 
(4) TF-IDなどを用いて各単語の重要度を評価する。
※TF-IDFとは、「文書の特徴」を表現するために「文書に含まれる単語の重要度」を考慮する概念だそうです。


### 4-1-3. 音声認識分野
#### 用語：WaveNet
音声合成と音声認識の両方を行うことができるモデルです。「両方」ができるということが試験に出るポイントみたいです。

#### 用語：HMM（隠れマルコフモデル）
音声認識では、HMMという言語モデルを用いて、文章としての単語のつながりを確率的に表現して、文章の形を推測します。今、このHMMがディープラーニングに置き換えられて、飛躍的に音声認識精度が向上しているのだそうな。

### 4-1-4. ロボティクス分野
#### 用語：Alpha GO
碁盤の状況認識にCNNを用い、次の手の選択にモンテカルロ木探索を用いて成果を上げた。なんと、ここにもCNNが使われているのか。さらに強くなるためにセルフプレイを用いたアルファ碁ゼロは、さらに強いそうです。

#### 用語：強化学習
3つの改善手法を覚えておきましょう。全て含めるとRAINBOWモデルとなる。ちなみに、DQNで用いられている枠組みは、(2)の行動価値関数ベースです。
(1) 方策（ポリシー）ベース
(2) 行動価値関数ベース（Q関数ベース）
(3) モデルベース

#### 用語：一気通貫学習
ロボットの一連の動作を一つのニューラルネットワークで実現しようとする学習。

* 視覚・聴覚・触覚などのセンサ情報をロボットが統合的に扱おうとする試みを何学習と呼ぶか【一気通貫学習】

#### 用語：マルチモーダル学習
互換や体性感覚といった複数の感覚の情報を組み合わせて処理すること。

* 視覚・聴覚・触覚などのセンサ情報を収集できるシステムを何システムと呼ぶか？ 【マルチモーダル】


## 4-2. 産業への応用
やはり、画像認識の応用事例が多いです。

### 4-2-1. 製造業での応用事例
#### 事例：自動車ギヤの不良品検出
そもそも不良品が発生する頻度が少ないので、不良品データを学習させるのは難しいです。良品データの特徴を抽出して、その特徴との差分を利用することで不良品を検出しています。（これもディープラーニングなのですね。）

#### 事例：射出成型機の予防保全
これまでは人間がデータ波形の形状変化を見て、摩耗状態や部品の交換時期を見ていた。このデータ波形の特徴量をディープラーニングで学習して、摩耗量を計算します。

#### 事例：バラ積みピッキング
複雑な教示作業無で、ロボットに作業をさせるアプローチで、ばらばらに置かれた部品をロボットがピッキングします。

#### 事例：食品製造ラインにおける不良品検出
分類機アプローチではなく、良品の特徴を学習してそうでないものをはじく異常検知アプローチ。

### 4-2-2.  自動運転
#### 用語：SEA J3016
6段階の自動運転レベルの定義があります。2025年を目途に、レベル4～5の完全自動運転の実用化が見込まれるのだそうな。
* （A)は自動運転のレベルの定義のことで、米国の団体が定義した。これによると、レベル（B）では、人間の運転者がすべて行い、レベル【3】では、自動化システムが要請した場合に人間が制御を取り戻せるようにしておかなければならない。レベル【5】は人間の運転者が運転できる条件下においてすべての運転タスクを自動で行うことができることをいう。
* 国土交通省が出した安全基準によると、2019/10/1以降に自動運転車を備えた新車に乗る場合、【６５秒以上手を離す】と手動運転に切り替える仕組みを義務付けた。 
* 自動車各社だけでなくインターネット大手に至るまでが参集している【Maas】は、あらゆる交通手段をニーズに合わせてパッケージ化して提供するサービスのことである。
* 情報処理に用いられる何らかのコンピューティングリソースを、インターネットを通じたサービスとして提供することや、そうしたサービスの総称を【Xaas】と呼ぶ
* レベル5：すべての運転を自動化
* レベル4：一定の環境や条件の下ですべての運転を自動化
* レベル3：すべての運転を自動化するが、緊急時は運転手が操作
* レベル2：アクセル、ブレーキ、ハンドル操作のうち、複数を自動化
* レベル1：アクセル、ブレーキ、ハンドル操作のうち、１つを自動化

### 4-2-3. 医療への応用事例
#### 事例：診断支援
ディープラーニングの持つ特徴量抽出能力を使って、内視鏡画像からの胃がんの診断や、大腸がん診断、網膜剥離判定などの事例があるようです。

#### 事例：創薬
化合物とたんぱく質の相互作用予測モデルなどにディープラーニングが使われているのだそうな。

#### 事例：ゲノム解析
ディープラーニングを用いたゲノム解析ツールであるDeepVariantはオープンソースとしてgithubに公開されているらしい。

### 4-2-4. 介護への応用事例
#### 事例：着衣介助
それにしても、凄いロボットが登場したものだ。

### 4-2-5. インフラ・防犯・監視への応用事例
#### 事例：メンテナンス効率化
コンクリートのひび割れ検出、舗装道路損傷判断、橋梁内部の損傷度合いの推定、送電線点検などに用いられているようです。

#### 事例：建設現場における活用
トンネル切羽や掘削のり面の地質評価。

#### 事例：産業廃棄物選別
廃棄物の材質種類推定にディープラニングが用いられている。

#### 事例：防犯
新丸ビルでは、困っている方の動き検知をやっているらしい。

### 4-2-5. サービス業への応用事例
#### 事例：タクシーの需要予測
人口統計、気象、過去のタクシー運行データを使って、需要のある場所や時間を予測するそうです。

#### 事例：来店者情報把握
来店人数計測カメラと年齢・性別判定カメラを設置を使い、大型商業施設におけるテナントごとの分析。（この事例もABEJA社なんですね。）

#### 事例：無人コンビニ
JR東日本社が検証しているようです。

### 4-2-6. その他の応用事例
#### 事例：双腕型マルチモーダルロボット
DENSO社ですね。

#### 事例：物流
荷物の形状を自動的に判別する物流画像判定や倉庫運用最適化に使われている。

#### 事例：農業
収穫・仕分け支援、ピンポイント農薬散布に使われている。

#### 事例：金融
株価予測や不正取引検知に使わている。

#### 事例：教育
講義動画内の先生の声や黒板の文字の検索に使わたり、採点支援に使われたり。

#### 事例：インターネット関連
ユーザーのコメント分析にLSTMが使われるようです。それから、画像商品検索やレコメンドにも。

#### 事例：チャットボット
予め用意してある複数回答文から適切なものを選択して回答するタイプと、都度で回答文を生成するタイプがあるそうですが、現時点では前者が多い。

## 4-3. 倫理と法律
AIプロダクトを作る際に、倫理や法律の観点で注意すべきことを見ていきましょう。

### 4-3-1. バイ・デザイン
用語：プライバシー・バイ：デザイン（PbD）
サービスやプロダクトを設計する段階から、法的もしくは倫理的な検討が必要です。あらかじめプライバシーに配慮した設計やプロセスを目指せば、社会から信用を得られます。PbDだけでなく、セキュリティ・バイ・デザインやバリュー・バイ・デザインなどのバイ・デザインな考え方が注目されています。

### 4-3-2. データ収集
日本の著作権法は、世界的に見ても先進的だそうです。というのも、「情報解析を行うために著作物を複製すること」が営利・非営利を問わず適法とされているからです。インターネット上にアップロードされている画像を無断で使って学習しても適法なわけです。

### 用語：2018年の著作権法改正
従来は、学習用データセットを作ることまでが適法でしたが、2019年1月以降は、その学習データを販売したり公開したりしても適法となるそうです。試験に出ますね。

### 用語：GDPR（EU一般データ保護規則）
たとえEU域内に拠点を持っていないとしても、日本に対しても域外適用されます。EU向けにもサービスを提供する日本企業は法的規制を受けます。
* 欧州議会・欧州理事会および欧州委員会が欧州連合 (EU) 内の全ての個人のためにデータ保護を強化し統合することを意図している

### 4-3-3. 権利
AIによる創作物の著作物性を明示的に認めた法律は、2018年時点では存在していないそうです。

### 4-3-4. 過失の責任
AIには故意や過失という状態をあてはめられないため、AIの所有者が「不法行為責任」を負わなければいけない可能性があります。AIの製造者は「製造物責任」を問われる可能性があります。ただし、「製造物責任」は動産にたいして問われるものであるため、プログラムとしてのAIは「製造物責任」の対象となる可能性は低そうです。

# 人物

## [ジェフリー・ヒントン](https://ja.wikipedia.org/wiki/%E3%82%B8%E3%82%A7%E3%83%95%E3%83%AA%E3%83%BC%E3%83%BB%E3%83%92%E3%83%B3%E3%83%88%E3%83%B3)
ディープラーニングの父。今は、トロント大学の教授で、Google Brainプロジェクトの研究者でもある。
2006年にはオートエンコーダや深層信念ネットワークという手法を提唱。ディープラーニングの基礎を築く。
2012年には人工知能を用いて画像の認識力を競うコンテスト、「ILSVRC」ではディープラーニング（**AlexNet**）を用いて圧倒的に優勝する。

## [アラン・チューリング](https://ja.wikipedia.org/wiki/%E3%82%A2%E3%83%A9%E3%83%B3%E3%83%BB%E3%83%81%E3%83%A5%E3%83%BC%E3%83%AA%E3%83%B3%E3%82%B0)
人工知能ができたかどうかを判定するテストである「チューリングテスト」を提唱。別の場所にいる人間がコンピュータと会話して、相手がコンピュータだと見抜けなければ知能があるとする。

## アンドリュー・ング
「Google Brain」や「coursera」の立ち上げにたずさわる。今はBaidu研究所に勤務。

## ヤン・ルカン
Facebookの人工知能研究所やニューヨーク大学に勤務。
LeNetと呼ばれる有名なCNNモデルを考えた。手書き数字を集めたデータセット「MNIST」を作った。
GANを高く評価した。

## レイ・カーツワイル
未来学者で「シンギュラリティ」という人工知能が人間よりも賢くなる年が来ることを予見する。

## ジョン・マッカーシー
パトリック・ヘイズとの共同論文でフレーム問題を提唱。余談だが、LISP言語を作った人。

## ジョセフ・アイゼンバウム
人工無能として有名な「ELIZA」を書き上げた人。

## ジョン・サール
[強いＡＩ・弱いＡＩ](https://ja.wikipedia.org/wiki/%E5%BC%B7%E3%81%84AI%E3%81%A8%E5%BC%B1%E3%81%84AI)という用語を作った人。[中国語の部屋](https://ja.wikipedia.org/wiki/%E4%B8%AD%E5%9B%BD%E8%AA%9E%E3%81%AE%E9%83%A8%E5%B1%8B)という思考実験をする。

## ロジャー・ペンローズ
『皇帝の新しい心』という著書の中で「強いＡＩ」は実現できないと主張。

## ダニエル・デネット
フレーム問題の難しさを伝えるために、ロボットのたとえを挙げた。

## スティーブン・ホーキング
「人工知能の進化は人類の終焉を意味する」と発言。

## [イーロン・マスク](https://ja.wikipedia.org/wiki/%E3%82%A4%E3%83%BC%E3%83%AD%E3%83%B3%E3%83%BB%E3%83%9E%E3%82%B9%E3%82%AF)
人工知能を研究する非営利団体の一つである「Open AI」の創業者の一人。
人工知能に対して「人工知能にはかなり慎重に取り組む必要がある。結果的に悪魔を呼び出していることになるからだ。」という脅威論を述べる。

## オレン・エツィオーニ
人工知能に対して「コンピュータが世界制覇するという終末論的構想は『馬鹿げている』としか言いようがない」と発言し脅威論をけん制した。

## 福島邦彦
CNNの原型ともいえる、単純型細胞と複雑型細胞の２つの細胞の働きを組み込んだモデルである「ネオコグニトロン」を提唱。

## アーサー・サミュエル
機械学習を「明示的にプログラムしなくても学習する能力をコンピュータに与える研究分野」と定義した。

## イアン・グッドフェロー
生成ネットワークと識別ネットワークからなる教師なし学習手法である**敵対的生成ネットワーク**を提唱した。ヤン・ルカンはGANについて「機械学習において、この10年間で最も面白いアイデア」であると評価した。

* 敵対生成ネットワーク（別名：(A)は、【イアン・グッドフェロー】によって提唱された非常に画期的な(C)機械学習の仕組みである。【ヤン・ルカン】によって「機械学習において10年に一度の面白いアイデアだ」と賞賛されるこの仕組みは、Generator生成という画像を生成するNNと、【Discriminator（識別）】という、それがNNによって生成されたものか、本当の画像かを判定するNNで構成される。

## デミス・ハサビス
DeepMindの設立者。

* 欧州連合（EU)の欧州委員会は２０１９年４月８日、人工知能（AI)の倫理指針を公表した。指針は現行の法律や規制を遵守することを念頭においた上で、「人間中心」のアプローチで、「信頼できる」を目指す方針を示した。AI倫理指針の７つの柱は、「人間の監督」「信頼できる安全性」「プライバシーとデータ保護」「透明性」「多様性、非差別、公平性」「社会、環境の幸福」「説明責任」となっており、２０１８年１２月の段階で１０項目あった柱をよりわかりやすくスリム化した形となっている。
