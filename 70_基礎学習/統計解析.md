## 統計検定
	専門統計調査士（午前）/統計調査士（午後）：2019/11/24
	2級/統計調査士（3級）：CBTあり、いつでも（9月中）
* [hp](http://www.toukei-kentei.jp/)
* [総務省統計局](http://www.stat.go.jp/)

## 参考
* [Chainer チュートリアル](https://tutorials.chainer.org/ja/06_Basics_of_Probability_Statistics.html)
* [統計学Web](https://bellcurve.jp/statistics/course/)
* [toukei net](https://to-kei.net/)
* [統計学](http://starpentagon.net/analytics/statistics/)
* [Pythonで学ぶあたらしい統計学の教科書を書いた人](https://logics-of-blue.com/)
* [Sci-pursuit](https://sci-pursuit.com/index.html#statistics)

https://logics-of-blue.com/chi-squared-test/
https://logics-of-blue.com/t-test/

https://atarimae.biz/archives/category/%e6%95%b0/%e7%b5%b1%e8%a8%88%e5%ad%a6/page/3

https://best-biostatistics.com/summary/sd-se-chigai.html

## データの縮約
### 図を用いた縮約法
  * 箱ひげ図
  * ヒストグラム
  * パレート図
  * 折れ線グラフ
  * 散布図
  * レーダーチャート
### 数値を用いた縮約法

## 記述統計
### データの分布
#### 度数分布・ヒストグラム

## 推測統計
### データ収集法
#### 母集団
#### 標本
### 確率
#### ベイズ統計モデル
#### 確率変数
#### 確率分布
##### ポアソン分布
* [サッカーの勝敗予測](https://introndatalab.com/203)
##### 正規分布
#### 統計量の分布
##### 無作為標本
##### 標本平均・標本比率・標本分散
### 推定
#### 区間推定
##### 平均
##### 比率
##### 分散
#### 信頼区間
### 検定
#### 仮説検定
##### 平均
##### 比率
##### 分散
#### カイ二乗検定

## 線形モデル
### 相関
### 回帰分析
#### 直線回帰
#### 重回帰

## 分散分析
### 2項分布

## 統計的決定理論
### 統計的決定問題
### 決定方式の評価
### ベイズ的評価法
### ミニマックス決定方式

## データサイエンス
### バランススコアカード
### 戦略マップ
### KPI
#### 標準的なKPI
### PDCA

## 品質管理への応用
	品質管理検定.ｍｄ参照

## 統計解析のツール
#### R言語
	S言語を参考としており、データ処理部分はSchemeの影響を受けている。
##### 利用例
* 品質：多変量統計的プロセス管理
* 探索的分析
#### S言語
	有料。
#### SAS
	有料。個人利用での無料版あり。R言語からも実行可能となっており、優良なだけに信頼性が高い。
#### SPSS
	有料。
#### Python
	R言語で分析を行い、モデルを定めた上でシステムに組み込むことに利用すると良い。

## データサイエンティストのスキル抜粋
### データ理解と検証
#### 統計情報への正しい理解
* 単なるローデータとしての実数だけを見ても判断出来ない事象が大多数であり、母集団に占める割合などの比率的な指標でなければ数字の比較に意味がないことがわかっている
* ニュース記事などで統計情報に接したときに、数字やグラフの持つメッセージを理解できる
* 自身の判断に必要となる統計情報を積極的に収集するとともに、表現に惑わされず数字を正当に評価できる（原点が0ではないグラフ、不要な3D化、不要な2軸化、目盛りの未記載など）
* 数字やデータの検証のために、何と比較するべきかすみやかに把握し、収集・利用できる（業務データや過去に接触した統計情報の想起・活用を含む）
#### データ理解
* どのような知見を得たいのか、目的に即して集計し、データから事実を把握できる
* データから事実を正しく浮き彫りにするために、集計の切り口や比較対象の設定が重要であることを理解している
* 普段業務で扱っているデータの発生トリガー・タイミング・頻度などを説明でき、また基本統計量や分布の形状を把握している
* 時系列データとは何か、その基礎的な扱いについて説明できる（時系列グラフによる周期性やトレンドの確認、移動平均の計算など）
* 生データを眺めて、どのような切り口で集計・比較すればデータの理解や事実の把握につながるか検討できる
* 扱ったことのない新たなデータに内容の不明な項目があっても、生データの閲覧や集計を通して何の項目かあたりをつけられる
* 扱っているデータの関連業務の知識と分析目的を踏まえて、どんな説明変数が効きそうか、あたりをつけて洗い出し、構造的に整理できる（変数のグループ化や階層化など）
* データの変化から起きている事象の背景を構造的に推察し、仮説を立て、検証方法を企画実行できる
* データを入手する前に、存在するであろうデータとその分布を想定して基礎俯瞰の方向性やその結果の想定ができ、それを前提とした解析方法の検討・ラフ設計をすることができる
* 扱ったことのない新たなデータであっても、ER図やテーブル定義、生データなどを見ることによってデータの発生源や欠損値の意味などのあたりをつけられる
### 洞察
* 分析、図表から直接的な意味合いを抽出できる（バラツキ、有意性、分布傾向、特異性、関連性、変曲点、関連度の高低など）
* 想定に影響されず、分析結果の数値を客観的に解釈できる
* 各種の解析手法（主成分分析、クラスター分析、決定木分析など）の結果を解釈し、意味合いを適切に表現・説明できる
### 予測
#### 回帰・分類
* Cox回帰（比例ハザードモデル）を用いて対象イベントの発生確率を予測する生存分析モデルを構築できる
* 対象の個体差やグループ毎の差が認められるデータに対し、階層ベイズモデルの構築ができる
* 予測アルゴリズムに応じ、必要な変数加工処理を設計し、実施できる（標準化やダミー変数化など、採用したアルゴリズムに適した変数加工）
* 予測モデル構築において頑健性（Robustness）を維持するための具体的な方法を設計、実施できる
#### 評価
* ROC曲線、AUC(Area under the curve)、を用いてモデルの精度を評価できる
* 混同行列（正誤分布のクロス表）、Accuracy、Precision、Recall、F値、macro平均、micro平均、重み付き平均といった評価尺度を理解し、精度を評価できる
* RMSE（Root Mean Square Error）、MAE（Mean Absolute Error）、MAPE（Mean Absolute Percentage Error）、決定係数といった評価尺度を理解し、精度を評価できる
* 不均衡データ（Imbalanced data）に対する分類モデルの評価尺度を、Precision、Recall、F値、PR（Presicion Recall）曲線、マシューズ相関係数などを用いてビジネス課題に合わせて適切に設定できる
* 目的（予測・真のモデル推定など）に応じて、適切な損失関数とモデル選択基準（AIC：赤池情報量規準、BIC：ベイズ情報量規準、MDL：最小記述長など）を選択し、モデル評価ができる
* MSE、AUC、F値などは評価データ全体に対する平均的評価であることを理解し、必要に応じて予測値・誤差の可視化、データの部分集合に対する評価などを実施できる
### グルーピング
* 階層クラスター分析において、デンドログラムの見方を理解し、適切に解釈できる
* 非階層クラスター分析において、分析対象となるデータの特性や分析目的に応じ、適切なクラスター数を決定できる
* 階層クラスター分析における代表的なクラスター間距離（Ward法、群平均法、最長一致法など）の概念を理解し、目的に合致した最適な手法で分析できる
* クラスター分析を実行する際、各種距離関数（ユークリッド距離、マンハッタン距離、マハラノビス距離など）を理解し、分析目的に合致した最適な距離計算で分析できる
* 距離の公理を満たさない場合（1-cos類似度など）においてもクラスター分析を適切に実行できる
* 自己組織化マップ（SOM）、Affinity Propagation、混合分布モデル、ディリクレ過程混合モデルなどを理解し、試行の中で最適な手法を選択できる
### 性質・関係性の把握
* コレスポンデンス（対応）分析と数量化III類を説明し、実施できる
* コンジョイント分析を自ら設計し、効用値と寄与率からモデルを評価できる
* 空間的自己相関の手法を用いて空間的な類似性を数値化できる
* 行列分解（非負値行列因子分解[Nonｰnegative Matrix Factorization:NMF]、特異値分解）を、目的に応じてパラメータを最適化して分析できる
* テンソル分解（非負値テンソル因子分解[Non-negative Tensor Factorization:NTF]、CP分解[Canonical Polyadic Decomposition:CPD]、Tucker分解など）を、対象データの特性や目的に応じて適用する事で、より複合的な要因の性質や関係性を分析できる
#### 因果推論
* 統計的因果推論における因果効果（平均処置効果、Average Treatment Effect; ATEなど）について説明できる
* ある変数の影響（因果効果）を推定したいがランダム化比較試験の実施が難しい場合、傾向スコアによる手法（傾向スコアマッチング、IPW、Doubly Robustなど）を用いることで観測されている共変量の影響を最小限に抑えることができる
### 特徴量エンジニアリング
* ドメイン知識に基づく洞察から有効な特徴量を効率的に作成できる（類似商品との価格差、借入額と返済額の比など）
* 有用と思われるデータを新たに調達し、既知のデータと組み合わせることで有効な特徴量を作成できる（業界特有なカレンダー、地理空間的な類似度を考慮した集計値など）
### データ可視化
#### 方向性定義
* データ量が膨大で構造が捉えにくい場合や、アウトプットが想像しにくい場合であっても、可視化の役割・方向性を判断できる（ビッグデータ中の要素間の関連性をダイナミックに表現する、細部に入りきらずに問に対して答えを出すなど）
#### 軸出し
* 非構造データから分析の軸になりうる候補を抽出し、付加すべき属性候補を適切に出せる
#### データ加工
* 高次元の非線形な（高次の曲線、渦状の分布などの）データであっても、適切に1～3次元のデータに圧縮して、特徴（データの総分散量および各データの位置関係）を損なわずに可視化できる
* ネットワーク構造、グラフ構造などの表現において、ノードとエッジが増えすぎて特徴抽出が困難であっても、データの絞り込みや抽象度を上げることで適切に可視化できる
* データ量が膨大（ペタバイト以上）なために、処理しきれず描画できない規模のデータに対しても、適度なデータや情報の抽出（間引き）、クラスター分析などにより可視化しうる状態にデータを加工できる
* 大規模なデータへのリアルタイムな可視化が求められる場合であっても、特異点の抽出や次元圧縮を通じてデータを圧縮し、リアルタイム表示できる
* 大規模なデータへのリアルタイムな可視化が求められる場合であっても、データの分割転送、復元を通じて可視化できる
#### 表現・実装技法
* 人体、標高を持つ地図、球面など３次元空間上にデータを重ね合わせた可視化ができる
* 地図上で同時に動く数百以上のポイントにおける時間変化を動的に表現できる（多地点での風の動き、飛行物の軌跡など）
* 複雑で総合的な表現が求められる場合に、ユーザインターフェースの設計に加え、内部のアルゴリズム設計やシステム環境への負荷調整なども踏まえた可視化ができる
#### 意味抽出
* 分類・グルーピングの分析において、分布傾向から原因を追究し、活用方針を計画・主導できる（分類に応じたDM発送による反応率の向上など）
* 予測の分析において、関連性、特異点、変曲点から原因を追究し、活用方針を計画・主導できる（予測結果に基づく発注管理など）
* 関係性の分析において関連が高い/低い原因を追究し、活用方針を計画・主導できる（レコメンドなど）
#### 時系列分析
* グレンジャー因果などの手法を用い、時系列データにおける変数間の因果関係を把握できる
* 状態空間モデルにおいて、カルマンフィルタを用いた欠測値の補完や予測モデルの構築ができる
* 非線形・非ガウス型状態空間モデルにおいて、モンテカルロ・フィルタを用いて、複雑な時系列システムの予測モデルを構築できる
#### パターン発見	
* 行動履歴に加え、アイテム属性、ユーザ属性、時間変化などの情報を用いて、目的に応じた推薦アルゴリズムを実装・評価できる
#### シミュレーション・データ同化	
* データ同化の概念を理解し、実行できる（データを用いてシミュレーション内の不確実性を減少させる計算技法など）
* シミュレーションにおける問題を理解し、対処を考えることができる（初期条件・境界条件・パラメータの不確実性、データ分布の不均一性、実験計画の最適性など）
* MCMC（マルコフ連鎖モンテカルロ法）における各種アルゴリズム（メトロポリス-ヘイスティングス法、ギブスサンプラー、ハミルトニアン・モンテカルロ法など）について理解し、活用できる
#### 最適化	
* 一定の制約下で最適解の識別と報酬の最大化がともに求められ、かつ報酬分布が時間経過で変化するような問題に対して、多腕バンディットアルゴリズムを適用・実装できる
* ビジネス課題にあわせて、変数、目的関数、制約を定式化し、線形・非線形を問わず、最適化モデリングができる
* 代表的な最適化問題に関して、モデリングを行い、ソルバーを使い、最適化できる（ナップザック問題、ネットワークフロー問題、巡回路問題など）
