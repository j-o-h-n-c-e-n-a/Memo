## 問題集

1. ニューラルネットワークは高い表現力を持つ反面、過学習をしやすいという性質を持つため、それを改善させる方法が多数考案されている。例えば、学習の際に一部のノードを無効化する[ドロップアウト]、一部の層の出力を正規化する[バッチ正規化]、データの水増しをしてデータの不足を補う[データ拡張]、パラメータのノルムにペナルティを課す[L2正規化]などがそれに当たる。

2. 学習率の値は学習の進み方に大きな影響を与える。例えば、学習率が過度に[小さい]とコスト関数の高い局所的最適解から抜け出せなくなることがある。また、大域的最適解に向かって収束している場合でも、学習率が[大きい]と、収束は速いがコスト関数の最終的な値が高く、逆に[小さくする]と収束は遅いが最終的にはより最適解に近いパラメータになるため、コスト関数は小さな値に収束する。

3. 生成モデルの一つであり、生成ネットワークと識別ネットワークの２つのネットワークを対抗させるように学習させることで、得られる生成モデルの名称として最も適切なものを１つ選べ。[GAN]

4. データが少量しかないなどの理由で、対象のタスクを学習させることが困難なときに、関連する別のタスクで学習し、その学習済みの特徴やパラメータなどを利用することで効率的に対象のタスクを学習することがある。これを[転移学習]という。

5. ディープラーニングは、ニューラルネットワークを多層化したものであり、観測データから本質的な情報である[特徴量]を自動的に抽出できる点が特徴である。また、従来の機械学習手法と比べると、[学習が必要なパラメータ数が多い、計算量が多い、より複雑な関数を近似できる]という性質も持っている。

6. 機械学習においては過学習を避けるために、訓練誤差ではなく汎化誤差を可能なかぎり小さくする手法である[正則化]を用いることが多い。また複数のモデルの予測結果の平均を利用する[アンサンブル学習]がある。他にもディープニューラルネットワークに対しては、ランダムに一定の割合のノードを削除して学習を行う[ドロップアウト]が有効とされている。[正則化]手法にはいくつかのパラメータをスパースにする[Lasso]などがある。

7. ディープニューラルネットワークの普及に貢献した一つの要素に、[勾配消失問題]を克服する手法が提案されたことがある。[勾配消失問題]は誤差逆伝播法において、[入力層に近づくにつれて誤差が急速に小さくなってしまう]ことによって生じるとされている。[勾配消失問題]に対処するための一つの方法として、あらかじめ良い重みの初期値を計算する[事前学習]や、活性化関数に[ReLU]を利用するなどがある。

9. 大規模なディープニューラルネットワークの学習では学習するべきパラメータ数が膨大となるため、処理の高速化が必要となる。2012年に提案された分散並列技術である[DistBelief]や画像処理に特化したプロセッサの[GPU]は大規模なニューラルネットワークの学習を実現するために利用されてきた。また、大規模なニューラルネットワークの学習が困難となる原因の一つとして、ある層の入力がそれより下層の学習が進むにつれて変化する[内部共変量シフト]がある。[内部共変量シフト]を防ぐために出力値の分布の偏りを抑制する[バッチ正規化]が2015年に提案されている。

10. 畳み込みニューラルネットワークは、畳み込み層とプーリング層を積み上げた構成をしている。画像データを用いた場合、畳み込み層では、出力画像のサイズを調整するために元の画像の周りを固定の値で埋める[パッティング]行う。プーリング層では畳み込み層の出力を圧縮するプーリングを行う、[誤差プーリング]などの手法がある。

11. ニューラルネットワークには[バイアス]などの多くのハイパーパラメータが存在し、これらの値が精度に大きな影響を与える。ハイパーパラメータのチューニング方法としては、パラメータの候補値を指定し、それらの組み合わせを調べる[グリッドサーチ]などがある。また、近年は、ハイパーパラメータを含め最適化問題とする[ベイズ最適化]が効率的なチューニング方法として注目をあびている。

12. 自己符号化器はニューラルネットワークによる[教師なし学習]の代表的な応用であり、出力が入力に近づくようにニューラルネットを学習させる。主に[次元削減]のために利用されることが多く、活性化関数に恒等写像を用いた場合の3層の自己符号化器は[主成分分析]と同様の結果を返す。自己符号化器を多層化すると、ディープニューラルネット同様に勾配消失問題が生じるため、複雑な内部表現を得ることは困難であった。この問題に対して2006年頃に[ヒントん]らは、単層の自己符号化器に分割し入力層から繰り返し学習させる[層ごとの貪欲法]を積層自己符号化器に適用することで、汎用的な自己符号化器の利用を可能とした。また、自己符号化器の代表的な応用例として[ノイズ除去,事前学習,異常検知]がある。

13. RNNは[時間依存の情報が含まれる]系列データの処理に長けているニューラルネットワークである。RNNは、[内部にループ構造を持つため]勾配消失問題が起きやすいという特徴を持っていたが、RNNの一種であるLSTMでは[メモリー・セル,入力ゲート,忘却ゲート]を含むLSTM Blockを組み込むことで、長期間の系列情報に対しても勾配消失せずに学習を行うことができた。

* RNNについての説明として誤っている選択肢を一つ選べ。
[×]RNNではネットワークにループ構造が含まれるため、中間層が1層であっても勾配消失問題が起きてしまう。
[×]音声認識ではRNNの一種であるエルマン・ネットワークが利用されてきた。
[●]RNNの学習には勾配消失問題を避けることのできる通時的誤差逆伝播法[back-propagation through time法]が利用される
[×]RNNの一種であるLSTMは機械翻訳や画像からのキャプション生成などに応用できる。

14. ディープニューラルネットワークの学習の目的は[出力関数]を最小化することであり、この最適化のために勾配降下法が利用される。しかし、勾配降下法にはパラメータの勾配を数値的に求めると[計算量が膨大となってしまう]問題があり、このような問題を避けるために誤差逆伝播法が利用される。またディープラーニングには過学習の問題もある。過学習とは[訓練誤差]は小さいにも関わらず、[汎化誤差]が小さくならないことであり、これらの問題を克服するために様々な手法の開発が進められている。

15. 勾配降下法においてパラメータの更新量を決める[学習率]の決定は重要である。例えば[学習率]が小さすぎると[収束が遅くなる]などの課題が生じるため、[スタッキング]などの様々な[学習率]調整手法が提案されている。

16. CNNで行われる畳み込み演算の計算処理について考える。5×5のサイズの画像に対して、3×3のフィルタをパディング1、ストライド1で適当した場合の出力の図のサイズを答えよ。[5*5]

17. ディープニューラルネットワークのパラメータ最適化手法として[確定的勾配降下法]などの勾配降下法が適用される。しかし、勾配降下法には[大域的最適解への収束]などの問題があり、これらの問題に対処するために、学習率をパラメータに適応させることで自動的に学習率を調整することができる[Adagrad]や勾配の平均と分散をオンラインで推定し利用する[Adam]が利用されてきた。

18. 機械学習の分野において有名な二つの定理について扱う。[醜いアヒルの子の定理]は、認知できる全ての客観的な特徴に基づくと全ての対象は同程度に類似している、つまり特徴を選択しなければ表現の類似度に基づく分類は不可能であることを示している。[ノーフリーランチ定理]は、全てのタスクに対して常に他よりすぐれている万能的なアルゴリズムは存在しないことを示している。

19. 深層学習のモデルは、確定的モデルと確率的モデルに分類することができる。これらのモデルの例として、確定的モデルに[深層信念ネットワーク]や確率的モデルに[深層ボルツマンマシン]がある。

20. 深層学習を含めて機械学習において精度の高い学習をするためには、観測データの適切な前処理が必須である。異なるスケールの特徴量を同時に扱えるようにするために、平均を0に分散を1に規格化する[標準化]や、特徴量の線形結合からデータ内の分散が大きくなるような特徴量を得る[主成分分析]などは広く利用されている。また、画像処理の分野においては、減算正規化と除算正規化の処理を行う[局所コントラスト正規化]などが前処理として利用され、[OpenCV]などの画像処理に特化したライブラリで行うことができる。また、自然言語処理の分野においては、文章に単語が含まれているかどうかを考えてテキストデータを数値化する[bag-og-words]や文章に含まれる単語の重要度を特徴量とする[TF-IDF]などがある。

* 強化学習の説明として誤りであるものを選べ
[×]正解データ付きの訓練データを用意する必要がない。
[×]一般的に学習には時間がかかる。
[×]状態遷移を考慮することができる。
[●]汎用性が高く異なるタスクへの転移が容易である。

22. 生成モデルとは、訓練データからそのデータの特徴を学習し、類似したデータを生成することができるモデルである。ディープニューラルネットの生成モデルの例として、自己符号化器の潜在変数に確率分布を導入した[VAE]や、訓練データと生成器が生成したデータを識別器で判別させることによって学習を進める[GAN]がある。

23. [adversarial example]は深層学習における重要な課題の一つであり、学習済みのディープニューラルネットモデルを欺くように人工的に作られたサンプルのことである。サンプルに対して微小な摂動を加えることで、作為的にモデルの誤認識を引き起こすことができる。

24. 強化学習では、行動を学習する[エージェント]と[エージェント]が行動を加える対象である[環境]を考え、行動に応じて[環境]は[エージェント]に状態と[報酬]を返す。行動と状態/[報酬]の獲得を繰り返し、最も多くの[報酬]をもらえるような方策を得ることが強化学習の目的である。

25. 強化学習において、行動価値関数の関数近似に畳み込みニューラルネットワークを用いた手法が[DQN]である。

* 過学習とはどのような状態のことか。以下の文から最も適切なものを１つ選べ。
[×]重みの状態が0になること
[×]活性化関数が機能しなくなること
[●]特定の訓練サンプルに対して、特化して学習すること
[×]バイアスが0になること

* 内部共変量シフトについて以下の記述から最も適切なものを１つ選べ。
[●]入力の分布が学習途中で大きく変わってくる問題
[×]入力の平均と分散を特定の値にする手法
[×]重みの初期値を設定する手法
[×]パラメータの勾配が0になる問題

26. 確率的勾配法は深層学習において最もよく知られる最適化アルゴリズムであり、いくつかの改善を加えたものが広く使われている。例えば、以前に適用した勾配の方向を現在のパラメータ更新にも影響させる[モメンタム]という手法や、勾配を２乗した値を蓄積し、すでに大きく更新されたパラメータほど更新量[学習率]を小さくする[AdaGrad]や、[AdaGrad]における一度更新量が飽和した重みはもう更新されないという欠点を、指数移動平均を蓄積することにより解決した[RMSprop]などがある。

27. ディープラーニングの技術を利用したシステムを開発する際、複雑な処理が比較的簡潔に記述できることから、既存のフレームワークを利用することも多い。ディープラーニングのフレームワークは複数あり、Google社提供の[TensorFlow]や[TensorFlow]のラッパーとして機能する[Keras]、国内企業であるPreferredNetworksで開発された[Chainer]などがある。また、[PyTorch]は[Chainer]と同じDefine-by-Run方式を採用している。

28. ニューラルネットワークの学習には独自の問題が生じる。層を深くするほど、入力層に近い層で学習が行われにくくなる[勾配消失]問題が起こったり、パラメータがつくる空間が高次元になり、その空間内の局所最適解や[鞍点]にトラップされることが多くなる。

29. 自己符号化器[Autoencoder]は、出力が入力と同じものに近づくことを目指して学習する。[教師なし学習]のアルゴリズムであり、[次元削減]が可能になる。このときの[隠れ層]が入力の特徴を抽出した表現となる。

30. 機械学習において、重み更新に関わる単位として、[イテレーション]と[エポック]がある。[イテレーション]は、重みが更新された回数であり、[エポック]は訓練データを何回繰り返し学習したかを表す単位である。また一回の[イテレーション]に用いるサンプル数は[バッチサイズ]と呼ばれる。

31. 活性化関数とは、ニューロンの出力に何らかの非線形な変数を加える関数である。単純パーセプトロンの出力層では[ステップ関数]が用いられ、ニューラルネットワークの中間層では、はじめ[シグモイド関数]などの正規化の機能を持つ関数が好まれた。しかし現在では、誤差逆伝播で勾配が消失しやすいという問題から、中間層では勾配消失問題の影響を抑えられ、かつ簡単な[ReLU]などが用いられている。また、出力層では出力の総和が１になるため確率的な解釈が可能になる[ソフトマックス関数]がよく用いられる。

32. 大きなニューラルネットワークなどの入出力をより小さなネットワークに学習させる技術として、[蒸留]がある。[蒸留]とは、すでに学習されているモデル[教師モデル]を利用して、より小さくシンプルなモデル[生徒モデル]を学習させる手法である。こうすることにより、生徒モデルを単独で学習させる場合よりも[過学習を緩和する]ことができる。

33. 画像データに対しては、前処理を施すことが多い。カラー画像を白黒画像に変換して計算量を削減する[グレースケール]や、細かいノイズの影響を除去する[平滑化]、画素ごとの明るさをスケーリングする[ヒストグラム平均]などがこれに含まれる。

34. 畳み込みニューラルネットワークの[畳み込み層]のパラメータ数は[全結合層]と比較して極めて少ない。これは[重み共有]によって[有用な特徴量を画像の位置によって大きく変化させない]ため、パラメータ数が減り、計算量が少なくなるためである。

* 人工知能が進化するにつれ、人々の生活が格段に豊かになることが期待される一方で、悪用や乱用で公共の利益を損なう可能性も否定できない。人工知能という高度な専門的職業に従事するものとして、その社会における責任を自覚し、社会と対話をしていく行動が必要となる。一般社団法人人工知能学会は、9つの指針を定めた。以下のうち、この指針に含まれるものを答えよ。 
[×]人類への貢献
[×]法規制の遵守
[×]他者のプライバシーの尊重
[●]上記のすべて

* 人工知能の急激な進化により、様々なことが言われている。一つは、人工知能によって人類が危機にさらされるのではないかという議論である。2014年のテレビインタビューにおいて「人工知能の進化は人類の終焉を意味する」と発言したのは以下の誰か。 
[×]イーロン・マスク氏（テスラ社長）
[●]スティーブン・ホーキング氏（宇宙物理学博士）
[×]ビル・ゲイツ氏（マイクロソフト創業者）
[×]ニック・ボストロム（哲学者）

* 1980年代のAIの研究に関して、適切な選択肢を1つ選べ。
[×]セマンティックウェブ
[●]エキスパートシステム
[×]オントロジー
[×]マルチエージェント

* Facebookが招いたディープラーニングの研究者として、正しいものを選択肢から1つ選べ。
[×]Andrew Ng
[●]Yann LeCun
[×]Geoffrey Hinton
[×]Terry Winograd

* 人工知能研究の変遷として、適切な選択肢を1つ選べ。
[●]パターン処理 -> 記号処理 -> 知識の蓄積
[×]記号処理 -> 知識の蓄積 -> パターン処理
[×]知識の蓄積 -> 記号処理 -> パターン処理 


35. 現在、人工知能研究は抽象概念や知識理解に辿り着くために大きく分けて３つの路線を辿っている。この３ つの路線は、とりわけある企業や大学によって研究が進められている。
・言語データによるRNNや映像データからの概念・知識理解を目指す[Google/Facebook]路線
・実世界を対象に研究を進め、知識理解を目指す[UCバークレー]路線
・オンライン空間上でできることをターゲットにして、知識理解を目指す[DeepMind]路線 

36. [CNN]はデータに潜む空間的構造をモデル化する。[RNN]は時間的構造をモデル化する。

37. 人間の脳における学習の枠組みに基づいた３つの学習が機械学習には存在する。１つ目は小脳の働きを模倣した[教師あり学習]である。これは学習者に対して、教師が間違いを指摘し、学習者が正しい解を得ることである。２つ目は大脳皮質の働きを模倣した[教師なし学習]である。代表的な手法として主成分分析などの次元圧縮手法がある。３つ目は大脳基底核の働きを模倣した[強化学習]である。学習者は正解値でなく、行動した結果に基づいた報酬が与えられる。この報酬をなるべく大きくするように学習者が行動していく。

38. 狭い意味でのディープラーニングとは層の数が深いニューラルネットワークを用いた機械学習である。複数の層を持つ階層的ニューラルネットワークは、1980年代には[誤差逆伝播学習]という方法がすでに提案されていたが、現在ほど多くの層を持った学習をすることはできなかった。その理由として２つの理由が挙げられる。１つ目は、出力層における誤差を入力層に向けて伝播させる間に、誤差情報が徐々に拡散し、入力層に近い層では勾配の値が小さくなって学習がうまく進まないという問題が発生したからだ。このことを[勾配消失現象]という。２つ目は、層の数が多いニューラルネットワークの学習の目的関数は多くの[極小値]を持ち、適切な結合の重みの初期値の設定が難しかった。

39. 現在の教師あり学習は、与えられたデータがどの分類に当てはまるのかを識別する[クラス分類]と、様々な関連性のある過去の数値から未知の数値を予測する[回帰]という２つに分類される。[クラス分類]を用いることで、[画像の識別]のようなことができる。また[回帰]を用いることで、[売上の予測]のようなことができる。

40. 表現学習とは、ディープラーニングを抽象化した概念で、画像、音、自然言語などの要素を、予測問題として解くことで分散表現[ベクトル]を得て、各々の要素を抽象化する手法である。こうした特徴表現は、通常は 人間の知識によって定義されるが、それによって機械学習の性能が大きく異なってしまう。こうした知的な情報処理を可能にしたのがディープラーニングである。ディープラーニングは観測データの説明要因を捉え、人間の知識では気がつくことができない共通点を捉えることができるが、この共通点のことをよい表現という。ヨシュ ア・ベンジオ氏は良い表現に共通する、世界に関する多くの一般的な事前知識として、いくつかを提唱している。よい表現として当てはまらないものを選択肢から1つ選べ。

41. 良い表現として、ディープラーニングのアプローチは[ア]、 [イ]、[ウ]に着目している。このことから、[説明要因の階層的構造]、[タスク間の共通要因]、[要因の依存の単純性]の事前知識を適切に活用できるなら、表現学習は必 ずしも層の数が多いニューラルネットワークの形をしていなくてもよいことになる。

42. 教師なし学習の中で有名なのは、未知の集合を、いくつかの集まりに分類させる[クラスタリング]という学習方法と、正常な行為がどのようなものかを学習し、それと大きく異なるものを識別する[異常検知]がある。[クラスタリング]は特に[K-means]というアルゴリズムを使用して顧客の分類分けによるDM配信やレコメンドを行う。[異常検知]は[SVM]というアルゴリズムを基に、セキュリティシステムなどに使用されている。

43. 画像の認識では、主に入力から出力に向かう結合のみを持つ階層的なニューラルネットワーク、特に画像などの信号に内在する局所的な特徴が集まって、より大域的な特徴を構成するという構造を反映した、[CNN]がよく用いられる。一方、自然言語テキストや動画に代表される構造を持った系列情報を扱うために[RNN]が用いられている。特にケプラー大学のゼップ・ホフレイター氏の提案した[LSTM]は必要な文脈情報の長さを適応的に制御することで、時間を遡る誤差逆伝播の可能性向上させ、画像からの説明文の生成や機械翻訳など、多くの課題に適用されている。実際、2016年秋に、GoogleはGoogle翻訳に[LSTM]を取り入れてアップデートし、非常に高精度な翻訳を提供することが可能になった。

44. 2012に開催された一般物体認識のコンテスト「ILSVRC」[ImageNet Large Scale Visual Recognition Challenge]において、深い構造を持つCNNが、従来手法の分類性能を大幅に上回って以来、ディープラーニングが画像認識に盛んに用いられるようになった。ディープラーニングの画像認識への応用先として正しい組み合わせを選択肢から1つ選べ。[クラス分類]、[物体検出]

45. クラス分類の領域では、CNNという沢山の層を重ねて、深い階層構造した手法によって研究が進めらていて、従来の手法よりも精度の高い認識や分類が可能となった。しかし、沢山の層を重ねた結果、学習に用いられるパラメータの数が膨大となり、学習が上手く進まないという問題が生じていた。その問題を解決するために提案されたのが[ResNet]である。[ResNet]は、入力層から出力層まで伝播する値と入力層の値を足し合わせたモデルで、この方法によって、入力層まで、勾配値がきちんと伝わり、今では1000層といったかなり深い構造でも学習が可能となった。実際、2015年のILSVRCで[ResNet]は人間の成績を上回る成果をあげている

46. 物体検出とは[対象物がどこにあるかをボックスに切り分けて、対象物を推定するタスク]である。一方物体セグメンテーションとは[対象物体と背景をピクセルごとに詳細に切り分けて、そのピクセルごとが示す意味を推定するタスク]である。
* 物体検出で有名なアルゴリズムは、2014年に考案されたR-CNN、2015に考案されたFaster R-CNN、2016年に 考案されたYOLOで、全てのアルゴリCNNの技術が内部で使用されている。

47. 画像キャプションとは、ある画像からそこに写っているものの説明を生成する、画像処理と自然言語処理の融合分野である。キャプションは、対象となる画像を[CNN]に入力し、そこから得られた特徴を[LSTM]に入力することで生成することが可能である。

48. 画像生成とは、何もない状態、もしくはある入力値に応じて目標の画像を生成する技術である。今最も利用されている画像生成手法は、GANという生成敵対ネットワークである。特に、あるランダムな数値の入力値をもとに画像生成を行うDC[GAN]やある文章から画像を生成するAttention[GAN]などが有名である。このネットワー クは[画像生成機]と[画像識別機]から構成されており、[画像生成機]は[画像分類器]を騙すような画像を出力し、[画像識別機]は[画像生成機]から出力された画像と本物の画像とを分類するようにそれぞれ学習する。このように学習することで、[画像生成機]は適切な画像を出力することが可能となる。 

49. 従来は、現在のディープラーニングのように入力から出力までの処理を一括で行うことができない情報を扱うことがあった。そうした場合、まず用意したデータをある手法を用いて加工し、それが入力値となり、別の手法を用いて処理を行いといった、ステップバイステップの学習が必要だった。しかし、ディープラーニングの登場によって、処理を複数回に分けて行う必要がなくなった。このような、深層学習において重要な方法論のことを[End to End Learning]と呼ぶ。

50. 1990年代の音声認識は[隠れマルコフモデル(HMM)]による、音自体を判別するための音響モデルと、[Nグラム法]による語と語のつながりを判別する言語モデルの両方でできている。しかし、ディープラーニングの登場、とりわけ[RNN]の登場により、音響特徴量から音素、文字列、更には単語列に直接変換するEnd to Endモデルというアプローチを取ることが可能になり、人的に前処理を行わなくても解析することが可能となった。

51. ディープラーニングはソフトウェアフレームワークを利用して実装するのが一般的である。多層のニューラルネットワークモデルを定義し、データを用いて学習・予測を実行するのがフレームワークの役割だが、重要なのはネットワークの記述方法とその柔軟性である。ネットワークには大きく分けて２つの記述方法がある。１つ目は[設定ファイル]による記述方法である。これらの記述方法を採用しているソフトウェアには[CaffeやCNTK]があげられる。この方法を用いることによって、モデルの定義がテキストで設定でき、簡単に学習を開始開始させることが出来るというメリットがある。一方で、ループ構造をもつようなRNNなど、複雑なモデルを扱う際には、モデルの定義を記述することは難しくなる傾向にある。２つ目は[プログラム]による記述方法である。代表的なフレームワークとして[TensorFlowやChainer]があげられる。一度書き方を覚えてしまば、複雑なモデルでも比較的簡単に記述することが出来るが、モデルは、それぞれのフレームワーク固有のソースコードで出来上がるため、モデルが使用しているソフトウェアに依存してしまうという問題がある。

52. 線形モデルとは、[説明変数]を含む項の線形結合で、[説明変数]を含んだ数式の出力値は[被説明変数]と呼ばれる。この線形結合で、特に[説明変数]も[被説明変数]も一次元のデータの場合は、y = b0 + b1 * xと表される。こういったモデルを単回帰モデルと呼んだりもする。この数式に置いて、各項の係数[例えばb0, b1]を[パラメータ]と呼び、このモデルを用いてテストデータを学習し、測定した実データを推定する。注意点として、[被説明変数]が連続の値を取り扱う場合[回帰]と呼ばれるが、離散の値を取り扱われる場合は[分類]と呼ばれ、それぞれ名称が異なる。ただ、実際のデータを扱うときに、[説明変数]が１次元であることはほとんどなく、２次元以上になることが一般的である。このような場合、[説明変数]の次元数分だけ、係数パラメータを増やして、モデルを拡張する必要がある。このように[説明変数]が２つ以上の場合を[重回帰]モデルと呼び、各項の係数パラメーターを[偏回帰係数]という。またモデルによって出力された値と実際の測定値の誤差を[残差]という。この[残差]を用いて係数パラメータを推定する代表的なアルゴリズムに最小二乗法と最尤推定法がある。

* 最小二乗法の説明として最も適切な選択肢を1つ選べ。
[●]モデルの予測値と実データの差が最小になるような係数パラメーターを求める方法
[×]各クラスの最も近いデータの距離を最大化することで係数パラメータを得る
[×]ある係数パラメーターが与えられたときに、モデルが実データを予測する確率（尤度）を最大化する ような 係数パラメーターを求める方法
[×]モデルの予測値と実データの差から損失関数を算出して、それを減少させるようにパラメータを更新させる 方法

* 最尤推定法の説明として最も適切な選択肢を1つ選べ。
[×]モデルの予測値と実データの差が最小になるような係数パラメーターを求める方法
[×]各クラスの最も近いデータの距離を最大化することで係数パラメータを得る
[●]ある係数パラメーターが与えられたときに、モデルが実データを予測する確率（尤度）を最大化する ような 係数パラメーターを求める方法
[×]モデルの予測値と実データの差から損失関数を算出して、それを減少させるようにパラメータを更新させる 方法

* 最小二乗法の説明として誤った選択肢を1つ選べ 
[●]答えが常に絶対値になり計算しやすくなる
[×]符号を考えなくてよくなり計算がしやすくなる
[×]サンプル中に大きく外れた異常値が混じっている場合、この異常値に線が大きく引っ張られるので異常値を 考慮する必要がある

53. ディープラーニングの学習の目的は、損失関数の値をできるだけ小さくするパラメータを見つけることである。このような問題を解くことを[最適化]という。このパラメータを見つけるアルゴリズムとして有名なのは[SGD] である。ただ、[SGD]は対象の関数の形がある分布や方向に依存すると非効率な経路でパラメータを探索してしまい、学習に時間がかかってしまうというデメリットがある。そこで、現在では[SGD]の欠点を改善するために[Adam] などのアルゴリズムが使用されている。

54. 機械が試行錯誤することで、取るべき最善の行動を決定する問題を扱うことができる学習方法を[強化学習]という。[強化学習]はボードゲームや自動運転、またロボットの歩行動作などに活用されている。代表的なアルゴリズムに [Q学習]があげられる。[強化学習]の課題として、主に[学習時間]や[マルチエージェント応用]などが挙げられる。理論的には無限に学習するが、実世界では全てが限られている。ロボットの場合、無限の試行を繰り返すことができず、損耗し、実験の続行が困難になる。そこで人間側がタスクを上手く切り分けてやさしいタスクからの学習をすることが期待される。また[マルチエージェント応用]に関して、例として、２体のロボット同士で学習を開始させようとすると、お互いに初期状態であるタスクについての何も知識がない状態だと、学習過程の不安定化が見られる。現在はこれに対応するために逆強化学習やディープラーニングの技術を適用した[DQN]などが適用され始めている。

55. 以下の文章をよく読み、末尾の設問に答えよ。
昨今、ディープラーニングを活用した音声認識技術、音声生成技術の向上に伴い、スマートスピーカーが普及しつつある。下記の選択肢のうち、スマートスピーカーの音声アシスタントソフトウェアの名称とその提供元の組み合わせとして正しいものを選択肢から１つ選べ。
[×]Apple - Alexa
[×]NTTドコモ - Siri 
[●]Microsoft - Cortana
[×]Amazon - しゃべってコンシェルジュ

56. 以下の文章をよく読み、末尾の設問に答えよ。
AIの研究開発が進むにつれて、実世界への社会実装で最も期待されている分野の１つに自動走行車の開発が挙げられる。現在AIを用いた自動走行車には、その自動運転導入の程度に応じてレベルづけがなされており、各社でどのように最終的なゴールであるレベル５の完全自動走行に近づくかが議論されている。
各レベルにおける自動運転の概要について説明した文章のうち、自動運転レベル３に対応しているものを選択肢より一つ選べ。
[×]部分運転自動化
[●]条件付き運転自動化
[×]高度運転自動化
[×]運転支援

57. 自動運転レベル５に至るには、２つのアプローチが存在している。１つは自動運転レベル１から徐々に運転自動化の範囲を広げていくアプローチ、もう１つは直接レベル３以上の自動運転を目指そうとするものである。この時、前者のレベル１から徐々に運転自動化を目指すアプローチを採っているプレイヤーは [自動車メーカー] などである。他方で、後者の直接レベル３以上の運転自動化を目指すアプローチを採っているプレイヤーは [大手IT企業] である。また後者のアプローチを採る企業として著名なのは、Google 傘下の [Waymo] 社である。

58. AI 技術の進展により一般に普及する可能性が急激に高まってきたのが、小型無人機 [以下ドローン] である。他方でこれまでに存在しなかった新しいプロダクトで、人々がこれまで意識することのなかった空域などの問題が生じてきた。例えば、ドローンを飛ばす空域は、飛ばすのに許可が必要な空域がある。またドローンはその利用方法に応じて、承認が必要となることがある。
選択肢のうち、ドローンを飛ばすのに許可を必要とする空域の説明として「正しくないもの」を選択肢より一つ選択せよ。
[×]150m 以上の高さの空域
[×]人口集中地区の上空
[×]空港等の周辺の上空
[●]電波塔が張り巡らされている地域

* 以下の文章をよく読み、末尾の設問に答えよ。
AI 技術の進展により一般に普及する可能性が急激に高まってきたのが、小型無人機 (以下ドローン) である。他方でこれまでに存在しなかった新しいプロダクトで、人々がこれまで意識することのなかった空域などの問題が生じてきた。例えば、ドローンを飛ばす空域は、飛ばすのに許可が必要な空域がある。またドローンはその利用方法に応じて、承認が必要となることがある。

ドローンの飛行規制について、「正しくないもの」を選択肢から一つ選べ。
[×]夜間飛行の禁止
[×]イベントなど大勢の人が集まる場所での飛行の禁止
[●]ヒト・モノから15m以内の飛行の禁止
[×]物の投下の禁止

* 以下の文章をよく読み、末尾の設問に答えよ。
AIの社会実装を進めていくにあたり、AIがもたらす倫理的リスクを事前に考慮しておく必要性が近年強く叫ばれている。各国政府はそれに対応すべく様々な取り組みを行っている。
米国政府の例を取ると、米国政府は2016年10月に "PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" を発行し、続けさまに同年 "THE NATIONAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN" 、そして2016年12月に発行した "ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" などで、これから表面化するであろうリスクへの対応策を事前に協議している。

このうち、"PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE"(人工知能の未来のための準備) で協議された内容として最も適切なものを１つ選べ。
[×]AIの普及が最大で300万件越えの雇用に影響を与える可能性があることを説いている
[●]AI実務家や学生に対して倫理観が必要であることを主張している
[×]判断結果の理由を実証的に説明できるAIプログラムを開発することが必要であることを主張した
[×]ロボット技術が進展した場合の法律のあり方について協議がなされた

* 以下の文章をよく読み、末尾の設問に答えよ。
AIの社会実装を進めていくにあたり、AIがもたらす倫理的リスクを事前に考慮しておく必要性が近年強く叫ばれている。各国政府はそれに対応すべく様々な取り組みを行っている。
米国政府の例を取ると、米国政府は2016年10月に "PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" を発行し、続けさまに同年 "THE NATIONAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN" 、そして2016年12月に発行した "ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" などで、これから表面化するであろうリスクへの対応策を事前に協議している。

このうち、"THE NATIONAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN"(国家インテリジェンス研究と開発戦略計画)で協議された内容として最も適切なものを一つ選べ。
[×]AIの普及が最大で300万件越えの雇用に影響を与える可能性があることを説いている
[×]AI実務家や学生に対して倫理観が必要であることを主張している
[●]判断結果の理由を実施て雨滴に説明できるAIプログラムを開発することが必要であることを主張した
[×]ロボット技術が進展した場合の法律のあり方について協議がなされた

* 以下の文章をよく読み、末尾の設問に答えよ。
AIの社会実装を進めていくにあたり、AIがもたらす倫理的リスクを事前に考慮しておく必要性が近年強く叫ばれている。各国政府はそれに対応すべく様々な取り組みを行なっている。
米国政府の例を取ると、米国政府は2016年10月に "PREPARING FOR THE FUTURE OF ARTIFICIAL INTELLIGENCE" を発行し、続けさまに同年 "THE NATIONAL INTELLIGENCE RESEARCH AND DEVELOPMENT STRATEGIC PLAN" 、そして2016年12月に発行した "ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY" などで、これから表面化するであろうリスクへの対応策を事前に協議している。

このうち、"ARTIFICIAL INTELLIGENCE AUTOMATION, AND THE ECONOMY"(人工知能オートメーションと経済) で協議された内容として最も適切なものを一つ選べ。
[●]AIの普及が最大で300万件越えの雇用に影響を与える可能性があることを説いている
[×]AI実務家や学生に対して倫理観が必要であることを主張している
[×]判断結果の理由を実施て雨滴に説明できるAIプログラムを開発することが必要であることを主張した
[×]ロボット技術が進展した場合の法律のあり方について協議がなされた

59. ディープラーニングの活用を進めていく必要性の高まりに対して、日本国内においてはそうした先端IT技術に精通した人材不足が懸念されている。
例えば、経済産業省が定めた先端IT人材がどのような人材需給状況にあるかの推定によると、2020年には需給ギャップが広がり人材の不足は [4.8万人] に及ぶと言われている。
こうした人材不足を解消するべく、様々な方法でAIに理解のある人材育成が試みられている。そのような試みの一つとして、MOOCs は期待を寄せられている。著名な例としては、AI研究の第一人者で、2014年から2017年にかけて Baidu の AI 研究所所長を務めた [Andrew Ng] が創業した Coursera などは入門から上級まで様々なレベルの AI 講義が開かれており、多くの受講者を惹きつけるに至っている。

* 以下の文章をよく読み、末尾の設問に答えよ。
自動運転の実現に向けては、現行の法の枠組の中では公道での実験の可否や、事故が起きた際の責任の所在などの点で捉えづらい面が県zないかしており、こうした点の解釈のすり合わせや、新たな法の策定などが求められている。
以下の自動運転走行許可の各国・各地域のスタンスに関する説明文として正しいものを選択肢から一つ選べ。
[×]英国では現行の法制度上では公道において自動運転の実証実験を行うのは法違反であるという見解が示されている
[●]米国ネバダ州では自動運転の走行や運転免許が許可制にて認められた
[×]日本国内では自動運転車の公道での走行は無制限に許可されている
[×]上記の選択肢の中に正しい選択肢は存在しない

* 以下の文章をよく読み、末尾の設問に答えよ。
AIの活用が国の経済成長を牽引する柱の１つになるという共通認識から、先進国各国では国の経済成長戦略の一部にAIの研究開発戦略が盛り込まれるようになっている。
こうした各国とその国の経済成長戦略の組み合わせとして正しいものを１つ選べ。
[×]中国 - デジタル戦略2025
[×]ドイツ - RAS 2020 戦略
[×]英国 - インターネットプラスAI3年行動実施法案
[●]日本 - 新産業構造ビジョン

60. ディープラーニングでの学習を効率的に行うにあたって、共有データセットの整備が徐々に進められている。しかしながら、現在広く普及しているものには、いくつかの問題点が指摘されている。
第一は、 [著作権] の問題である。現在は公正な利用がなされているとされているが、企業が共有データセットを利用して学習したモデルを自社のプロダクトに転用して売り上げを上げようとした場合に問題はないのかという議論が巻き起こっている。
他の問題として、これは日本にとっての問題であるが、多くのデータセットが [欧米圏で作成されたデータセット] であることが挙げられる。これにより、日本固有の食べ物を認識しようとすると、それが全く別の国の食べ物としてのみ認識されるという不具合が生じるに至っている。

61. 高度なAIモデルを作成していく為には、こうした共有のデータセットの拡充を進めると共に、学習モデルの共有を進め、こうした公開共有されたモデルを基にして独自のデータセットを適用して調整をしながら新たに学習をさせる [転移学習] が実用上鍵となるのではないかと言われている。

* 下記の文章をよく読み、末尾の設問に答えよ。
ディープラーニングの利活用は各産業で進められているが、それが実際にディープラーニングによるブレイクスルーによってもたらされたものであるのかどうかの認識が曖昧な場合も少なくない。

選択肢のうち、ディープラーニングの産業への利活用事例として適切でないものを１つ選べ。
[×]ある自動車タイヤメーカーは熟練技術者の熟達した技をディープラーニングで学ばせ、生産工程における自動化を図ろうとしている
[×]インフラ産業において、機械設備の老朽化や故障、その他異常を重大な過失に至る前に検知し対策を示唆する為にディープラーニングの活用が行われている
[●]チケットの転売を防ぐために、チケットを全て電子化し、転売がどのようなルートで行われたのかを捕捉できるようにする為にディープラーニングを利用したサービスが話題となった
[×]サイバーセキュリティ産業において、マルウェアを素早く検知して対策を打つ為のより効率の高いプログラムをディープラーニングを用いて作成しようとしている
+ 正解はブロックチェーンがキーとなって成立したサービス群

62. 全ての欠損値が完全に生じている場合には、様々な手法を使ってこれに対処することができる。１つは欠損があるサンプルをそのまま削除してしまう [リストワイズ法] である。これは欠損に偏りがあった場合には、データ全体の傾向を大きく変えてしまうことになるので使用する際には欠損に特定の偏りがないかを確認して使用することが肝要である。
他の事例としては、欠損しているある特徴量と相関が強い他の特徴量が存在している場合は、[回帰補完] という方法もある。

63. 機械学習による分析を行う際、カテゴリーデータをそのまま扱うのは非常に難しい。このため、これを数値に変換して扱いやすくすることが一般的である。
ドリンクのサイズS, M, Lなどの順序を持つ文字列のカテゴリーデータの場合、それぞれの値に対応する数値を辞書型データで用意し、これを数値に変化する方法 [マッピング] を利用して変換を行うことがある。
また順序を持たない名義特徴量のカテゴリーデータについては、各変数に対応したダミー変数を新たに作り出す [One-Hotエンコーディング] が有用である。

64. 既存の学習済みニューラルネットワークモデルを活用する手法に[転移学習]と[蒸留]がある。[転移学習]では、学習済みモデルに対して新たに別の課題を学習させることで、少量のデータセットかつ少ない計算量で高い性能のモデルを得ることができる。また、[蒸留]は、学習済みの大規模モデルの入力と出力を小規模なモデルの教師データとして利用することで、少ない計算資源で従来のモデルと同程度の性能を実現することが可能となる。

65. 畳み込みニューラルネットワークの手法について扱う。
[LeNet]は1998年に提案された、現在広く使われているCNNの元となるモデルであり、初めて多層CNNに誤差逆伝播法を適用した手法である。2012年に提案された[AlexNet]は、画像認識のコンペティションILSVRCで他手法に圧倒的な差をつけて優勝し、画像認識におけるディープラーニング活用の火付け役となった。しかし、一般にCNNは層を深くすると、パラメータ数が膨大となり学習が困難になってしまう傾向があった。層が深くなってもうまく学習を行うことができるモデルとして、ILSVRC2015において多くの部門でトップの成績を収めた[ResNet]がある。[ResNet]は出力を入力と入力からの差分の和で表現したニューラルネットワークモデルである。

66. ニューラルネットワークで用いられる活性化関数について扱う。出力層の活性化関数には、回帰では[恒等関数]が、多クラス分類では[ソフトマックス関数]が一般的に利用されてきた。また中間層の活性化関数として、従来は[双曲線余弦関数]などが一般的に利用されてきた。しかし、これらの活性化関数を利用すると勾配消失問題が起きやすいという問題があったため、近年は、入力が0を超えていれば入力をそのまま出力に渡し、0未満であれば出力を0とする[ReLU]や複数の線形関数の中での最大値を利用する[Maxout]などが利用されている。

67. 正則化とは、機械学習の学習において汎化誤差をできるだけ小さくするための手法の総称である。ディープニューラルネットワークの学習で一般に用いられる正則化の手法に[荷重減衰]があり、誤差関数に重みのL2ノルムを加えることで重みの発散を抑えることができる。また、L2ノルムの代わりにL1ノルムを用いるL1正則化は、[スパース正則化]の一種であり、重要でないパラメータを0に近づけることができる。 L1正則化を回帰に利用した場合、[Lasso回帰]と呼ばれる。

68. 深層学習の実験に用いられるデータセットについて扱う。[MNIST]はアメリカの国立標準技術研究所によって提供されている手書き数字のデータベースである。また、スタンフォード大学がインターネット上から画像を集めて分類したデータセットである[ImageNet]は、約1400万枚の自然画像を有しており、画像認識の様々なタスクに利用される。

69. 機械学習の手法は学習の枠組みに応じて主に3つに分類することができる。
[教師あり学習]は入力とそれに対する出力のペアの集合を学習用データとする手法で、[ｋ平均法]などが[教師あり学習]に含まれる。[教師なし学習]は入力の集合だけから学習を行う手法であり、[ｋ近傍法]などが[講師なし学習]に含まれる。最後に[強化学習]は、最終結果または連続した行動の結果に対して報酬を与え、報酬ができるだけ大きくなるような行動を探索する手法である。

70. 機械学習の種類を大きく分類すると教師あり学習、教師なし学習、強化学習がある。ニューラルネットワークにもそれらに対応するものがある。例えば、教師あり学習には[VGG16]、教師なし学習には[オートエンコーダー]、強化学習には[DQN]などがある。

71. 畳み込みニューラルネットワークに特有の構造として、畳み込み層とプーリング層がある。これらは画像から特徴量を抽出するために用いられる。逆に特徴量[特徴マップ]から画像を生成する際には、それらと逆の操作を行う。代表的な構造として、畳込み層の逆操作である[逆畳み込み層]やプーリングの逆操作である[アンプーリング層]がある。これらの構造を用いるタスクの例として[画像セグメンテーション]がある。

72. ニューラルネットワークの学習は、損失関数[コスト関数]の最適化により行われる。そして、その損失関数は学習の目的に応じて決定する。よく使われる損失関数として、回帰問題には[平均二乗誤差関数]、分類問題には[交差エントロピー誤差関数]がある。また分布を直接学習する際には[KLダイバージェンス]が用いられることもある。さらに、損失関数にパラメータの二乗ノルムを加えると[L2正則化]となる。

73. ニューラルネットワークには様々なモデルがあり、タスクによって適切な選択をする必要がある。例えば、画像を扱う際には[CNN]、自然言語処理などの系列データには[RNN]がよく使われる。他にも次元削減には[オートエンコーダー]、画像生成には[GAN]などが用いられる。

75. ニューラルネットワークの学習には勾配降下法が用いられる。勾配降下法の手順を適切な順番に並べ替えたとき、１番目になるのはどれか。
A．重みとバイアスを初期化する。
E．データ[ミニバッチ]をネットワークに入力し出力を得る。
D．ネットワークの出力と正解ラベルとの誤差を計算する。
B．誤差を減らすように重み[バイアス]を修正する。
C．最適な重みやバイアスになるなるまで繰り返す。

80. 画像認識のモデルとしてResNetがある。これは求めたい関数と入力との差である[残差]を学習するようにしたことで深いネットワークの学習を容易にした。

## 特徴マップの問題
* CNNによって、幅：1500、高さ：1500ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 736
* CNNによって幅x高さ=250x250ピクセルの画像を入力とし12x12ピクセルのフィルタを用いて、ストライド2で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 121*121
* CNNによって、幅：900、高さ：900ピクセルの画像を入力とし、幅：3、高さ：3ピクセルのフィルタを用いて、ストライド：3で、大きさ：3の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？302
* CNNによって、幅：400、高さ：400ピクセルの画像を入力とし、幅：70、高さ：70ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 333
* CNNによって、幅：777、高さ：777ピクセルの画像を入力とし、幅：7、高さ：7ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 387
* CNNによって、幅：114、高さ：114ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 43
* CNNによって、幅：918、高さ：918ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 445
* CNNによって幅x高さ=300x400ピクセルの画像を入力とし24x24ピクセルのフィルタを用いて、ストライド2で、大きさ2で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 141*191
* CNNによって、幅：500、高さ：500ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 236
* CNNによって、幅：200、高さ：200ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 86
* CNNによって、幅：40、高さ：40ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 20
* CNNによって、幅：100、高さ：100ピクセルの画像を入力とし、幅：10、高さ：10ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 93
* CNNによって、幅：100、高さ：100ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 50
* CNNによって、幅：13、高さ：13ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 8
* CNNによって、幅：450、高さ：450ピクセルの画像を入力とし、幅：20、高さ：20ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 433
* CNNによって、幅：418、高さ：418ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 195
* CNNによって、幅：112、高さ：112ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 42
* CNNによって幅x高さ=400x400ピクセルの画像を入力とし24x24ピクセルのフィルタを用いて、ストライド3で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 127
* CNNによって、幅：300、高さ：300ピクセルの画像を入力とし、幅：50、高さ：50ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 127
* CNNによって、幅：1600、高さ：1600ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 786
* CNNによって幅x高さ=300x300ピクセルの画像を入力とし12x12ピクセルのフィルタを用いて、ストライド1で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 291*291
* CNNによって、幅：200、高さ：200ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 86
* CNNによって、幅：333、高さ：333ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 166
* CNNによって、幅：300、高さ：300ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 271
* CNNによって、幅：800、高さ：800ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：5で、大きさ：5の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？162
* CNNによって、幅：1100、高さ：1100ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 536
* CNNによって、幅：20、高さ：20ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 18
* CNNによって、幅：110、高さ：110ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 109
* CNNによって、幅：80、高さ：80ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 26
* CNNによって、幅：700、高さ：700ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：3の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 338
* CNNによって、幅：50、高さ：50ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 25
* y=ax + by + czという式をzについて偏微分した答えを次から選べ。[c]
* CNNによって、幅：555、高さ：555ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 277
* CNNによって、幅：500、高さ：500ピクセルの画像を入力とし、幅：10、高さ：10ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 247
* f[x]=ax+by+czという関数がある。この関数をyについて偏微分せよ。[b]
* CNNによって、幅：95、高さ：95ピクセルの画像を入力とし、幅：5、高さ：5ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 47
* CNNによって、幅：916、高さ：916ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？444
* CNNによって、幅：300、高さ：300ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：3で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 91
* CNNによって、幅：200、高さ：200ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 86
* CNNによって、幅：900、高さ：900ピクセルの画像を入力とし、幅：4、高さ：4ピクセルのフィルタを用いて、ストライド：4で、大きさ：4の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 227
* CNNによって幅x高さ=1200x1200ピクセルの画像を入力とし240x240ピクセルのフィルタを用いて、ストライド1で、大きさ10で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 981*981
* CNNによって、幅：1800、高さ：1800ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 886
* CNNによって、幅：400、高さ：400ピクセルの画像を入力とし、幅：32、高さ：32ピクセルのフィルタを用いて、ストライド：2で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 186
* CNNによって、幅：100、高さ：100ピクセルの画像を入力とし、幅：16、高さ：16ピクセルのフィルタを用いて、ストライド：2で、大きさ：2の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか45
* CNNによって幅x高さ=764x900ピクセルの画像を入力とし32x32ピクセルのフィルタを用いて、ストライド2で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 368*436

* 
[×]

No. 1
問題文：
CNNは特徴として間違っているものを全て選べ。 
選択肢：
[×]空間的特徴を捉えることができるため、画像認識に向いている 
[●]画像認識に特化しており自然言語処理には向いていない 
[×]畳み込みニューラルネットワークのこと である 
[×]順伝播型ニューラルネットワークの一種である 

No. 2
問題文：
主成分分析とオートエンコーダの共通点は、どちらも（ア）ができることである。（ア）に入る言葉を全て選べ。 
選択肢：
[●]次元圧縮 
[×]検索 
[●]教師なし学習 
[×]教師あり学習 

No. 3
問題文：
バーニーおじさんのルールとは何のことか？次から選べ。 
選択肢：
[●]機械学習に必要なデータはモデルのパラメタ数の10倍以上であるという法則 
[×]人間や動物には簡単な歩く・食べるなどの行動が機械にとっては難しいという矛盾 
[×]知識表現の限界 
[×]記号と言葉の意味は結びつかないという法則 

No. 4
問題文：
機械学習の手法の中で、分散が最大になる方向に新しい軸を定義しその軸にデータをマッピングしていくことで次元圧縮を実現する手法をなんと呼ぶか？次のうち正しいものを選べ。 
選択肢：
[●]PCA 
[×]PPFM 
[×]K-means 
[×]Doc2Vec 

No. 5
問題文：
初期のチャットボットELIZAとPARRYどうしでの会話は、A.やB.に納められている。適切なものを２つ選択せよ（順不同） 
選択肢：
[●]ICCC 
[●]RFC439 
[×]ISO27001 
[×]IEEE 802.11n 

No. 6
問題文：
学習済みのモデルが、学習に使ったデータに対してはよく予測できるが、未知のデータにうまく適用できないことを何と呼ぶか？当てはまるものをすべて選べ。 
選択肢：
[●]過学習 
[×]未学習 
[●]オーバーフィッティング 
[×]アンダーフィッティング 

No. 7
問題文：
単純パーセプトロンで解くことができる問題のことを、A.問題といい、解くことができない問題と呼ぶ。A.には何が入るか？ 
選択肢：
[×]非線形分離可能 
[●]線形分離可能 
[×]NP困難 
[×]巡回セールスマン 

No. 8
問題文：
ロジスティック回帰はA.問題を解くための手法であり、関数表現自体は、B.問題を解く線形C.と変わらない。Aに入る言葉を求めよ。 
選択肢：
[×]ソフトマックス 
[×]非線形分離可能 
[●]分類 
[×]G検定 

No. 9
問題文：
ジニ係数やエントロピーという不純度によって、データを分割するための分岐する木構造を作っていく機械学習の手法は何というか？ 
選択肢：
[●]決定木 
[×]k-means法 
[×]Ward法 
[×]最尤推定法 

No. 10
問題文：
決定木を応用した(A)は複数モデルを並列に学習させ多数決をとる、(B)は直列（順番）に学習し前の分類器の弱点を克服するという違いがある。(A)に入る言葉はなにか。 
選択肢：
[×]勾配降下法 
[×]ニュートン法 
[×]線形代数 
[●]バギング 

No. 11
問題文：
決定木を応用した(A)は複数モデルを並列に学習させ多数決をとる、(B)は直列（順番）に学習し前の分類器の弱点を克服するという違いがある。(B)に入る言葉はなにか。 
選択肢：
[×]逐次学習 
[×]バッチ学習 
[●]ブースティング 
[×]オンライン学習 

No. 12
問題文：
統計には2種類ある。 （A)は全データが対象で、（B)は、元データからサンプリングしたデータから母集団の性質を推測する。（A)に入る言葉を答えよ。 
選択肢：
[●]記述統計 
[×]推計統計 
[×]推量統計 
[×]基礎集計 

No. 13
問題文：
あるクラスにおいて「身長」と「体重」の相関係数は「0.8」であった。「身長」と「体重」にはどのような相関関係があるか？ 
選択肢：
[●]強い正の相関がある。 
[×]強い負の相関がある。 
[×]どちらでもない 
[×]弱い負の相関がある 

No. 14
問題文：
動物にとっては簡単なこと（例：エサをとる、敵を認識する）が、機械にとっては難しく、複雑な方程式の計算は機械にとって優しい。この矛盾を何と呼ぶか？ 
選択肢：
[×]シンボルグランディング問題 
[●]モラベックスのパラドックス 
[×]中国語の部屋 
[×]逆説定理 

No. 15
問題文：
単純パーセプトロンで用いられる誤差関数を答えよ。 
選択肢：
[×]恒等関数 
[●]ヒンジ損失関数 
[×]クロスエントロピー関数 
[×]シグモイド関数 

No. 16
問題文：
CNNにおいて、特徴表現を抽出する層を、(A)といい、情報を集約する層のことを(B)層という。(A)に入る言葉を求めよ。 
選択肢：
[×]全結合 
[×]順伝播ネットワーク 
[●]畳み込み層 
[×]プーリング層 

No. 17
問題文：
CNNにおいて、特徴表現を抽出する層を、(A)といい、情報を集約する層のことを(B)層という。(B)に入る言葉を求めよ。 
選択肢：
[×]全結合 
[×]順伝播ネットワーク 
[×]畳み込み層 
[●]プーリング層 

No. 18
問題文：
畳み込みニューラルネットワーク(CNN)は時系列データを扱うのが苦手であるため、RNNのように音声認識や自然言語処理に使われることはまずない。これは正しい認識か？ 
選択肢：
[×]正しい 
[●]誤り 
[×]どちらでもない 
[×]RNNがすべてにおいてCNNより優れていると証明されている。 

No. 19
問題文：
インセプションモジュールが入っているILSVRC2014で優勝したネットワークの名称を答えてください。 
選択肢：
[●]GoogLeNet 
[×]ResNet 
[×]AlexNet 
[×]VGG16 

No. 20
問題文：
畳み込み層13層で、全結合層が3層のオックスフォード大学が提案し、ILSVRC2014で準優勝したネットワークの名称を答えてください。 
選択肢：
[×]GoogLeNet 
[×]ResNet 
[×]AlexNet 
[●]VGG16 

No. 21
問題文：
残差学習を行う158層のマイクロソフトが提案し、ILSVRC2015で優勝したネットワークの名称を答えよ。 
選択肢：
[×]GoogLeNet 
[●]ResNet 
[×]AlexNet 
[×]VGG16 

No. 22
問題文：
敵対生成ネットワーク（別名：(A)は、(B)によって提唱された非常に画期的な(C)機械学習の仕組みである。(D)によって「機械学習において10年に一度の面白いアイデアだ」と賞賛されるこの仕組みは、（E)という画像を生成するNNと、（F)という、それがNNによって生成されたものか、本当の画像かを判定するNNで構成される。(C)に当てはまるものを答えよ。 
選択肢：
[×]教師あり 
[●]教師なし 
[×]強化学習 
[×]異常検知 

No. 23
問題文：
敵対生成ネットワーク（別名：(A)は、(B)によって提唱された非常に画期的な(C)機械学習の仕組みである。(D)によって「機械学習において10年に一度の面白いアイデアだ」と賞賛されるこの仕組みは、（E)という画像を生成するNNと、（F)という、それがNNによって生成されたものか、本当の画像かを判定するNNで構成される。(D)に当てはまるものを答えよ。 
選択肢：
[×]イアン・グッドフェロー 
[×]イアン・ゴールドバーグ 
[×]ジェフリー・ヒントン 
[●]ヤン・ルカン 

No. 24
問題文：
敵対生成ネットワーク（別名：(A)は、(B)によって提唱された非常に画期的な(C)機械学習の仕組みである。(D)によって「機械学習において10年に一度の面白いアイデアだ」と賞賛されるこの仕組みは、（E)という画像を生成するNNと、（F)という、それがNNによって生成されたものか、本当の画像かを判定するNNで構成される。(E)に当てはまるものを答えよ。 
選択肢：
[●]Generator 
[×]認識 
[●]生成 
[×]学習 

No. 25
問題文：
敵対生成ネットワーク（別名：(A)は、(B)によって提唱された非常に画期的な(C)機械学習の仕組みである。(D)によって「機械学習において10年に一度の面白いアイデアだ」と賞賛されるこの仕組みは、（E)という画像を生成するNNと、（F)という、それがNNによって生成されたものか、本当の画像かを判定するNNで構成される。(F)に当てはまるものを答えよ。 
選択肢：
[×]次元圧縮 
[●]識別 
[×]プーリング 
[●]Discriminator 

No. 26
問題文：
CNNによって幅x高さ=400x400ピクセルの画像を入力とし24x24ピクセルのフィルタを用いて、ストライド1で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 
選択肢：
[●]379x379 
[×]400x400 
[×]401x401 
[×]384x384 

No. 27
問題文：
CNNによって幅x高さ=1200x1200ピクセルの画像を入力とし240x240ピクセルのフィルタを用いて、ストライド1で、大きさ10で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 
選択肢：
[×]1000x1000 
[●]981x981 
[×]1201x1201 
[×]1111x1111 

No. 28
問題文：
内部に（A)を持つRNN（再帰ニューラルネットワーク）は、（B)データを扱うことができるが、遠い過去の入力を保持（記憶）し、現在の出力に影響を与えることが難しい。ネットワークの構造自体は変えずに、ユニット（ノード）を工夫することでこの問題を解決する方法を（C)といい、それを更にシンプルにし計算コストを抑えたものを（D)という。ただし、（D)が（C)の改良版ということではなく、（D)よりも（C)の方が表現力が高いという主張もある。（A)に入る言葉をすべて選べ。 
選択肢：
[●]閉路 
[●]ループ構造 
[×]行き止まり 
[×]分岐 

No. 29
問題文：
内部に（A)を持つRNN（再帰ニューラルネットワーク）は、（B)データを扱うことができるが、遠い過去の入力を保持（記憶）し、現在の出力に影響を与えることが難しい。ネットワークの構造自体は変えずに、ユニット（ノード）を工夫することでこの問題を解決する方法を（C)といい、それを更にシンプルにし計算コストを抑えたものを（D)という。ただし、（D)が（C)の改良版ということではなく、（D)よりも（C)の方が表現力が高いという主張もある。（B)に入る言葉をすべて選べ。 
選択肢：
[●]時系列 
[×]物理的 
[●]系列 
[×]NPハード 

No. 30
問題文：
内部に（A)を持つRNN（再帰ニューラルネットワーク）は、（B)データを扱うことができるが、遠い過去の入力を保持（記憶）し、現在の出力に影響を与えることが難しい。ネットワークの構造自体は変えずに、ユニット（ノード）を工夫することでこの問題を解決する方法を（C)といい、それを更にシンプルにし計算コストを抑えたものを（D)という。ただし、（D)が（C)の改良版ということではなく、（D)よりも（C)の方が表現力が高いという主張もある。（D)に入る言葉をすべて選べ。 
選択肢：
[×]LSTM 
[×]Softmax 
[●]GRU 
[×]ReLU 

No. 31
問題文：
自然言語処理において、2013年にGoogle社より論文が公開された（A)という技術は、単語の意味関係を（B)で表現することにより、辞書なしで関連度の高い単語を知ることができたり、「王」ー「男性」+「女性」＝「女王」というような意味的な計算が自動的にできるようになり、注目を集めた。　また、（C)年に同社より提案された（D)という技術は（E)という（F)の手法を用いており、単語の一部を（G)して学習させるという工夫により、一つの単語が複数の使われ方をするというような複雑な意味関係も表現でき（E)により文章の文脈も学習しており、様々な、自然言語処理タスク（QA抽出、文書分類、品詞タグ付け等）で最高記録を樹立している。（C)に入る言葉を選べ。 
選択肢：
[×]2013 
[×]2015 
[●]2018 
[×]2019 

No. 32
問題文：
自然言語処理において、2013年にGoogle社より論文が公開された（A)という技術は、単語の意味関係を（B)で表現することにより、辞書なしで関連度の高い単語を知ることができたり、「王」ー「男性」+「女性」＝「女王」というような意味的な計算が自動的にできるようになり、注目を集めた。　また、（C)年に同社より提案された（D)という技術は（E)という（F)の手法を用いており、単語の一部を（G)して学習させるという工夫により、一つの単語が複数の使われ方をするというような複雑な意味関係も表現でき（E)により文章の文脈も学習しており、様々な、自然言語処理タスク（QA抽出、文書分類、品詞タグ付け等）で最高記録を樹立している。（F）に入る言葉を選べ。 
選択肢：
[×]隠れマルコフモデル 
[×]ベイズ推定 
[×]ベイジアンフィルタ 
[●]ディープラーニング 

No. 33
問題文：
自然言語処理において、2013年にGoogle社より論文が公開された（A)という技術は、単語の意味関係を（B)で表現することにより、辞書なしで関連度の高い単語を知ることができたり、「王」ー「男性」+「女性」＝「女王」というような意味的な計算が自動的にできるようになり、注目を集めた。　また、（C)年に同社より提案された（D)という技術は（E)という（F)の手法を用いており、単語の一部を（G)して学習させるという工夫により、一つの単語が複数の使われ方をするというような複雑な意味関係も表現でき（E)により文章の文脈も学習しており、様々な、自然言語処理タスク（QA抽出、文書分類、品詞タグ付け等）で最高記録を樹立している。（G）に入る言葉を選べ。 
選択肢：
[×]サニタイジング 
[×]クレンジング 
[●]マスキング 
[×]平滑化 

No. 34
問題文：
（A)は自動運転のレベルの定義のことで、米国の団体が定義した。これによると、レベル（B）では、人間の運転者がすべて行い、レベル（C）では、自動化システムが要請した場合に人間が制御を取り戻せるようにしておかなければならない。レベル（D）は人間の運転者が運転できる条件下においてすべての運転タスクを自動で行うことができることをいう。（B)に入る言葉を示せ。 
選択肢：
[●]0 
[×]1 
[×]2 
[×]3 

No. 35
問題文：
（A)は自動運転のレベルの定義のことで、米国の団体が定義した。これによると、レベル（B）では、人間の運転者がすべて行い、レベル（C）では、自動化システムが要請した場合に人間が制御を取り戻せるようにしておかなければならない。レベル（D）は人間の運転者が運転できる条件下においてすべての運転タスクを自動で行うことができることをいう。（C)に入る言葉を示せ。 
選択肢：
[×]1 
[×]2 
[●]3 
[×]4 

No. 36
問題文：
（A)は自動運転のレベルの定義のことで、米国の団体が定義した。これによると、レベル（B）では、人間の運転者がすべて行い、レベル（C）では、自動化システムが要請した場合に人間が制御を取り戻せるようにしておかなければならない。レベル（D）は人間の運転者が運転できる条件下においてすべての運転タスクを自動で行うことができることをいう。（D)に入る言葉を示せ。 
選択肢：
[×]2 
[×]3 
[×]4 
[●]5 

No. 37
問題文：
アクセンチュアが年次調査レポートで発表した（A)とは、ブロックチェーン、人工知能、拡張・強化現実、量子コンピュータの4つのテクノロジーからとったものだ。（A)に入る言葉を示せ。 
選択肢：
[×]DARK 
[●]DARQ 
[×]BARQ 
[×]BARK 

No. 38
問題文：
自動車各社だけでなくインターネット大手に至るまでが参集している（A)は、あらゆる交通手段をニーズに合わせてパッケージ化して提供するサービスのことである。（A)に入る言葉を選べ。 
選択肢：
[×]PaaS 
[×]SaaS 
[●]Maas 
[×]Xaas 

No. 39
問題文：
過学習を防ぐ正則化について、（A）のように、自動的に「特徴選択」が行われるため、（B)正則化と捉えることができる。（C)は、パラメータのノルムを小さくおさえることができるという性質がある。（A)と（B）を組み合わせたものを（D)という。（A)には何が入るか選択せよ。 
選択肢：
[×]Ridge 
[●]Lasso 
[×]ノルム 
[×]バッチ正則化 

No. 40
問題文：
過学習を防ぐ正則化について、（A）のように、自動的に「特徴選択」が行われるため、（B)正則化と捉えることができる。（C)は、パラメータのノルムを小さくおさえることができるという性質がある。（A)と（B）を組み合わせたものを（D)という。（C)には何が入るか選択せよ。 
選択肢：
[●]Ridge 
[×]Lasso 
[×]ノルム 
[×]バッチ正則化 

No. 41
問題文：
過学習を防ぐ正則化について、（A）のように、自動的に「特徴選択」が行われるため、（B)正則化と捉えることができる。（C)は、パラメータのノルムを小さくおさえることができるという性質がある。（A)と（B）を組み合わせたものを（D)という。（D)には何が入るか選択せよ。 
選択肢：
[×]Ridge 
[×]Lasso 
[×]ノルム 
[●]Elastic Net 

No. 42
問題文：
CNNによって幅x高さ=400x400ピクセルの画像を入力とし24x24ピクセルのフィルタを用いて、ストライド3で、大きさ1で0パディングして畳み込み層で学習を行った結果得られる特徴マップのサイズは次のうちどれか？ 
選択肢：
[×]117 
[●]127 
[×]137 
[×]147 

No. 43
問題文：
マージンの最大化を行うことにより、分離境界平面（ハイパープレーン）を得て分類を行う教師あり学習の手法を次から選べ。 
選択肢：
[×]SVR 
[×]SVC 
[●]SVM 
[×]kNN 

No. 44
問題文：
CNNによって、幅：450、高さ：450ピクセルの画像を入力とし、幅：20、高さ：20ピクセルのフィルタを用いて、ストライド：1で、大きさ：1の0パディングを行った結果、特徴マップのサイズは次のうちどれと等しくなるか？ 
選択肢：
[●]433 
[×]423 
[×]500 
[×]450 

No. 45
問題文：
幅：512、高さ：512ピクセルの高解像度画像を条件付きで生成できる(A)は歴史史上最強の(B)と呼び声が高い。ところが、2019/6に(C)社より発表された(D)は(B)を使わずにHD大の画像を生成できる。(A)に入る言葉を次から選べ。 
選択肢：
[×]DeepMind 
[×]VAE 
[×]GAN 
[●]BigGAN 

No. 46
問題文：
幅：512、高さ：512ピクセルの高解像度画像を条件付きで生成できる(A)は歴史史上最強の(B)と呼び声が高い。ところが、2019/6に(C)社より発表された(D)は(B)を使わずにHD大の画像を生成できる。(B)に入る言葉を次から選べ。 
選択肢：
[×]AutoEncoder 
[×]VAE 
[●]GAN 
[×]BigGAN 

No. 47
問題文：
幅：512、高さ：512ピクセルの高解像度画像を条件付きで生成できる(A)は歴史史上最強の(B)と呼び声が高い。ところが、2019/6に(C)社より発表された(D)は(B)を使わずにHD大の画像を生成できる。(D)に入る言葉を次から選べ。 
選択肢：
[●]VQ-VAE-2 
[×]GAN 
[×]BigGAN 
[×]VAE 

No. 48
問題文：
自然言語処理における言語モデルとして2018/11にGoogleから発表された(A)よりも２０以上のタスクで性能が良いとされる（B）が2019/6/19に(C)に投稿された。(D)の一種を元の順序情報は保持しつつ単語の順序を入れ替えたことで自己回帰モデルで双方向の意味依存関係を取得できるようになったと主張されている。(B)に入る言葉を次から選べ。 
選択肢：
[●]XLNet 
[×]BERT 
[×]Arxiv 
[×]Transformer 

No. 49
問題文：
自然言語処理における言語モデルとして2018/11にGoogleから発表された(A)よりも２０以上のタスクで性能が良いとされる（B）が2019/6/19に(C)に投稿された。(D)の一種を元の順序情報は保持しつつ単語の順序を入れ替えたことで自己回帰モデルで双方向の意味依存関係を取得できるようになったと主張されている。(C)に入る言葉を次から選べ。 
選択肢：
[×]XLNet 
[×]BERT 
[●]Arxiv 
[×]Transformer 

No. 50
問題文：
自然言語処理における言語モデルとして2018/11にGoogleから発表された(A)よりも２０以上のタスクで性能が良いとされる（B）が2019/6/19に(C)に投稿された。(D)の一種を元の順序情報は保持しつつ単語の順序を入れ替えたことで自己回帰モデルで双方向の意味依存関係を取得できるようになったと主張されている。(D)に入る言葉を次から選べ。 
選択肢：
[×]XLNet 
[×]BERT 
[×]Arxiv 
[●]Transformer 

No. 51
問題文：
東京大学合格を目指す人工知能(A)は、2011年にスタートされたプロジェクトで2016年まで続けられた。2016年6月の進研模試では、偏差値(B)をマークしたが、その後(C)を理解する難しさから、読解力に問題があり、(D)という判断から開発が凍結された。(B)に入る言葉を次から選べ。 
選択肢：
[×]56.8 
[●]57.8 
[×]62.5 
[×]47.8 

No. 52
問題文：
ランダムフォレストは(A)を用いる手法で、(B)に属する。それぞれの(A)に対してランダムに一部のデータを取り出して学習に用いることを(C)と呼ぶ。複数の(A)を作成するので、(D)をとることでモデルの最終出力を決定するという仕組みで動作する。(B)に入る言葉を次から全て選べ。 
選択肢：
[●]教師あり学習 
[×]教師なし学習 
[×]強化学習 
[●]機械学習 

No. 53
問題文：
ランダムフォレストは(A)を用いる手法で、(B)に属する。それぞれの(A)に対してランダムに一部のデータを取り出して学習に用いることを(C)と呼ぶ。複数の(A)を作成するので、(D)をとることでモデルの最終出力を決定するという仕組みで動作する。(C)に入る言葉を次から選べ。 
選択肢：
[●]ブートストラップサンプリング 
[×]ホールドアウト法 
[×]クロスバリデーション 
[×]ランダムオプティミゼーション 

No. 54
問題文：
ランダムフォレストは(A)を用いる手法で、(B)に属する。それぞれの(A)に対してランダムに一部のデータを取り出して学習に用いることを(C)と呼ぶ。複数の(A)を作成するので、(D)をとることでモデルの最終出力を決定するという仕組みで動作する。(D)に入る言葉を次から選べ。 
選択肢：
[×]中央値 
[×]平均値 
[●]多数決 
[×]最大値 

No. 55
問題文：
2006年に(A)大学の(B)が(C)というニューラルネットワークを提唱した。(C)は可視層（入力層・出力層）と隠れ層の2層からなるネットワークで、入力層と出力層の値が同じになるように、学習します。入力層から隠れ層における処理を(D)、隠れ層から出力層における処理を(E)と言います。(A)に入る言葉を次から選べ。 
選択肢：
[×]MIT 
[●]トロント大学 
[×]スタンフォード大学 
[×]ボストン大学 

No. 56
問題文：
2006年に(A)大学の(B)が(C)というニューラルネットワークを提唱した。(C)は可視層（入力層・出力層）と隠れ層の2層からなるネットワークで、入力層と出力層の値が同じになるように、学習します。入力層から隠れ層における処理を(D)、隠れ層から出力層における処理を(E)と言います。(C)に入る言葉を次から選べ。 
選択肢：
[×]DARQ 
[×]ARPANET 
[●]AutoEncoder 
[×]多層パーセプトロン 

No. 57
問題文：
(A)とは自己符号化器を何層もつなぎ合わせて構成したDNNのことである。これは入力層に近い層から順に学習させるという逐次的な学習方法をとる。この順番に学習することを(B)と呼び、(B)が終わると最後に、DNN全体で学習を行うが、これを(C)と呼ぶ。(A)に入る言葉を選べ。 
選択肢：
[×]Deep AutoEncoder 
[●]stacked autoencoder 
[×]VAE 
[×]Multiple Autoencoder 

No. 58
問題文：
制限付きボルツマンマシンを用いた(A)は、（B）により提案された手法である。(A)に入る言葉を選べ。 
選択肢：
[●]深層信念ネットワーク 
[×]知識マップ 
[×]自己組織化マップ 
[×]深層ニューラルネットワーク 

No. 59
問題文：
制限付きボルツマンマシンを用いた(A)は、（B）により提案された手法である。(B)に入る言葉を選べ。 
選択肢：
[×]ヤン・ルカン 
[●]ジェフリー・ヒントン 
[×]イアン・グッドフェロー 
[×]ジョン・マッカーシー 

No. 60
問題文：
人工ニューラルネットワークを学習するときにUnit数や層の数などあらかじめ決めておく必要のあるもののことを(A)と呼ぶ。(A)を効率的に決定する為に(B)などの方法があるが、計算時間がかかるなどのデメリットもあり、（C）が用いられることも多い。(B)に入る言葉を選べ。 
選択肢：
[×]スーパーパラメータ 
[×]ハイパーパラメータ 
[●]ベイズ最適化 
[×]グリッドサーチ 

No. 61
問題文：
人工ニューラルネットワークを学習するときにUnit数や層の数などあらかじめ決めておく必要のあるもののことを(A)と呼ぶ。(A)を効率的に決定する為に(B)などの方法があるが、計算時間がかかるなどのデメリットもあり、（C）が用いられることも多い。(C)に入る言葉を選べ。 
選択肢：
[×]スーパーパラメータ 
[×]ハイパーパラメータ 
[×]ベイズ最適化 
[●]グリッドサーチ 

No. 62
問題文：
人工ニューラルネットワークの学習に置いて、各レイヤーに伝わるデータの分布が重要であり、その初期値を工夫する為にシグモイド関数には(A)、ReLUには(B)の初期値が良いことが知られている。また、(C)ではもっと直接的に、各レイヤーに伝わってきたデータをそのレイヤーでまた(D)するということにより(E)というメリットを享受できる。(C)に入る言葉を選べ。 
選択肢：
[×]He 
[×]Xavier 
[×]バッチ正則化 
[●]バッチ正規化 

No. 63
問題文：
(A)とはイメージネット画像認識コンテストのことであり、(B)年に従来手法の(C)に代わり、(D)が圧倒的な精度で優勝したことが、今日のAIブームに少なからず寄与していると言われている。(C)に入る言葉を選べ。 
選択肢：
[●]SVN 
[×]K-means 
[×]勾配ブースティング 
[×]GBDT 

No. 64
問題文：
(A)とはイメージネット画像認識コンテストのことであり、(B)年に従来手法の(C)に代わり、(D)が圧倒的な精度で優勝したことが、今日のAIブームに少なからず寄与していると言われている。(D)に入る言葉を選べ。 
選択肢：
[×]word2vec 
[×]LSI 
[×]LDA 
[●]DNN 

No. 65
問題文：
(A)により開発された(B)や(C)は単語を(D)で表現することで、「王様」ー「男性」＋「女性」＝「女王」といったアナロジータスクができるようになり、単語の意味は(E)単語によって決まるという(F)の主張を(G)で実現したものである。(A)に入る言葉を選べ。 
選択肢：
[×]ジェフリーヒントン 
[×]ヤンルカン 
[×]マービンミンスキー 
[●]トマス・ミコロフ 

No. 66
問題文：
(A)により開発された(B)や(C)は単語を(D)で表現することで、「王様」ー「男性」＋「女性」＝「女王」といったアナロジータスクができるようになり、単語の意味は(E)単語によって決まるという(F)の主張を(G)で実現したものである。(C)に入る言葉を選べ。 
選択肢：
[●]fastText 
[×]ELMo 
[×]BERT 
[×]XLNet 

No. 67
問題文：
(A)により開発された(B)や(C)は単語を(D)で表現することで、「王様」ー「男性」＋「女性」＝「女王」といったアナロジータスクができるようになり、単語の意味は(E)単語によって決まるという(F)の主張を(G)で実現したものである。(E)に入る言葉を選べ。 
選択肢：
[●]周辺 
[×]中心 
[×]品詞 
[×]構文 

No. 68
問題文：
オートエンコーダを応用した生成モデルで、画像を生成することができるのは次のうちどれか？ 
選択肢：
[×]GAN 
[×]seqGAN 
[●]VAE 
[×]AGI 

No. 69
問題文：
単語をベクトルで表現することを何表現と呼ぶか？ 
選択肢：
[×]偏差表現 
[●]分散表現 
[×]最小二乗法 
[×]ニューラル翻訳 

No. 70
問題文：
フリーテキストを入力とし、フリーテキストを出力するオートエンコーダデコーダを用いたモデルのことをなんと呼ぶか？ 
選択肢：
[×]変分オートエンコーダ 
[×]GAN 
[●]seq2seq 
[×]text2text 

No. 71
問題文：
機械翻訳で利用されるTransoformerやBERTなど、自然言語処理で今活躍しているものは（A)ベースのネットワークが用いられている。（A)の基本的な仕組みは、queryと（C)と（D）である。queryは（C)により、取得する（D)を決定し、対応する（E)を取得する。（A)に入る言葉を選べ。 
選択肢：
[×]key 
[×]memory 
[●]attention 
[×]value 

No. 72
問題文：
機械翻訳で利用されるTransofomerやBERTなど、自然言語処理で今活躍しているものは（A)ベースのネットワークが用いられている。（A)の基本的な仕組みは、queryと（C)と（D）である。queryは（C)により、取得する（D)を決定し、対応する（E)を取得する。（D)に入る言葉を選べ。 
選択肢：
[×]key 
[●]memory 
[×]query 
[×]value 

No. 73
問題文：
機械翻訳で利用されるTransofomerやBERTなど、自然言語処理で今活躍しているものは（A)ベースのネットワークが用いられている。（A)の基本的な仕組みは、queryと（C)と（D）である。queryは（C)により、取得する（D)を決定し、対応する（E)を取得する。（E)に入る言葉を選べ。 
選択肢：
[×]key 
[×]memory 
[×]query 
[●]value 

No. 74
問題文：
次のうち、順伝播型ニューラルネットワークをすべて選べ。 
選択肢：
[●]FFN 
[●]CNN 
[×]RNN 
[×]ReLU 

No. 75
問題文：
次のうち、再帰型ニューラルネットワークをすべて選べ。 
選択肢：
[●]GRU 
[×]CNN 
[●]RNN 
[●]LSTM 

No. 76
問題文：
深層生成モデルとしてふさわしくないものを次から選べ。 
選択肢：
[×]VAE 
[×]seqGAN 
[●]word2vec 
[×]GAN 

No. 77
問題文：
RNNは（A)のことである。その特徴は（B)を持つことで、入力データに加え、（C)を入力として与えることで、（D」データを扱える仕組みとなっている。（A)にあてはまるものをすべて選べ。 
選択肢：
[●]再帰型ニューラルネットワーク 
[×]フィードフォワードニューラルネットワーク 
[×]階層型ニュートンネゲーション 
[×]再帰処理 

No. 78
問題文：
RNNは（A)のことである。その特徴は（B)を持つことで、入力データに加え、（C)を入力として与えることで、（D」データを扱える仕組みとなっている。（B)にあてはまるものをすべて選べ。 
選択肢：
[●]内部に閉路 
[×]内部に分岐 
[●]内部にループ構造 
[×]内部に畳み込み層 

No. 79
問題文：
RNNは（A)のことである。その特徴は（B)を持つことで、入力データに加え、（C)を入力として与えることで、（D」データを扱える仕組みとなっている。（D)にあてはまるものをすべて選べ。 
選択肢：
[×]少量 
[×]離散的 
[●]系列 
[×]階層 

No. 80
問題文：
SuperVisionとは何年のILSVRCで優勝したシステムか？ 
選択肢：
[×]2011 
[●]2012 
[×]2013 
[×]2014 

No. 81
問題文：
AGIと最も近い意味の単語を次より選べ。 
選択肢：
[●]強いAI 
[×]特化型AI 
[×]弱いAI 
[×]機械学習 

No. 82
問題文：
国際的な画像コンテストでいま成果を上げているのは次の打ちどれか？すべて選べ。 
選択肢：
[×]強いAI 
[●]特化型AI 
[●]弱いAI 
[●]機械学習 

No. 83
問題文：
仮想空間において、積み木を積んだり下ろしたりを英語で指示できる1968-1970年にテリー・ウィノグラードを中心に開発されたシステムを何と呼ぶか？ 
選択肢：
[×]STRIPS 
[×]マルチモーダルシステム 
[●]SHRDLU 
[×]SuperVision 

No. 84
問題文：
1971年、Richard Fikes と Nils Nilsson が開発した自動計画に関する人工知能システムを何と呼ぶか？ 
選択肢：
[●]STRIPS 
[×]マルチモーダルシステム 
[×]SHRDLU 
[×]SuperVision 

No. 85
問題文：
国際的な画像認識のコンペティションであるILSVRC2017で優勝したニューラルネットワークの名称は次のうちどれか？ 
選択肢：
[×]Squeeze and extraction network 
[●]Squeeze and excitation 
[×]ResNet 
[×]AlexNet 

No. 86
問題文：
アレンインスティテュートにより提案された双方向リカレントネットワークにより実現された単語埋め込みモデルを何とよぶか？ 
選択肢：
[×]BERT 
[●]ELMo 
[×]word2vec 
[×]para2vec 
